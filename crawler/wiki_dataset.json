[
{"id": "ac8b3b54df41", "content": "A Manchester United and Ipswich Town football matchwas played atOld Trafford(pictured), Manchester, in March 1995 as part of the1994–95FA Premier League. It finished in a9–0victory for the home team. The result is a joint record for thelargest winning margin in the Premier League, later equalled by three other matches with the same scorelinein 2019,in 2021andin 2022. Manchester United and Ipswich Town went into the match at opposite ends of the table; United were second, while Ipswich were second-last. In the corresponding fixture at Ipswich'sPortman Roadin September 1994, they beat United3–2. United were missingEric Cantona, who was on a nine-month suspension, and their attacking partnership ofAndy ColeandMark Hugheswas not well regarded bypundits. Ipswich's victory at Portman Road proved to be the more significant result with regard to the final placings, as United missed out on the title by one point. (Full article...) October 21 Tiharis a five-day Hindu festival of lights, celebrated in Nepal and parts of India (Sikkim,DarjeelingandAssam) by theNepaleseandIndian Gorkhapeople. The festival coincides and shares similarities withDiwali, the festival of lights celebrated by Hindus across theIndian subcontinentand elsewhere, but also has some distinct features, such as the celebration of animals associated with the Hindu deityYama. Today (21 October 2025) is the third day of the festival,Lakshmi Puja, representing the cow, and is considered the most important day of Tihar. This photograph shows a woman lightingdiyasfor Tihar, in theTelghaarea of Nepal. Photograph credit:Mithun Kunwar Wikipedia is written by volunteer editors and hosted by theWikimedia Foundation, a non-profit organization that also hosts a range of other volunteerprojects: This Wikipedia is written inEnglish. Manyother Wikipedias are available; some of the largest are listed below.", "metadata": {"url": "https://en.wikipedia.org/wiki/Main_Page", "title": "Main Page", "headings": ["From today's featured article", "Did you know ...", "In the news", "On this day", "Today's featured picture", "Other areas of Wikipedia", "Wikipedia's sister projects", "Wikipedia languages"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Wikipedia", "https://en.wikipedia.org/wiki/Free_content", "https://en.wikipedia.org/wiki/Encyclopedia", "https://en.wikipedia.org/wiki/English_language", "https://en.wikipedia.org/wiki/Manchester_United_F.C._9%E2%80%930_Ipswich_Town_F.C."]}},
{"id": "f69d9e095416", "content": " Artificial intelligence(AI) is the capability ofcomputational systemsto perform tasks typically associated withhuman intelligence, such aslearning,reasoning,problem-solving,perception, anddecision-making. It is afield of researchincomputer sciencethat develops and studies methods andsoftwarethat enable machines toperceive their environmentand uselearningandintelligenceto take actions that maximize their chances of achieving defined goals. High-profileapplications of AIinclude advancedweb search engines(e.g.,Google Search);recommendation systems(used byYouTube,Amazon, andNetflix);virtual assistants(e.g.,Google Assistant,Siri, andAlexa);autonomous vehicles(e.g.,Waymo);generativeandcreativetools (e.g.,language modelsandAI art); andsuperhumanplay and analysis instrategy games(e.g.,chessandGo). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it'snot labeled AI anymore.\" Various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning,reasoning,knowledge representation,planning,natural language processing,perception, and support forrobotics.To reach these goals, AI researchers have adapted and integrated a wide range of techniques, includingsearchandmathematical optimization,formal logic,artificial neural networks, and methods based onstatistics,operations research, andeconomics.AI also draws uponpsychology,linguistics,philosophy,neuroscience, and other fields.Some companies, such asOpenAI,Google DeepMindandMeta,aim to createartificial general intelligence(AGI)—AI that can complete virtually any cognitive task at least as well as a human. Artificial intelligence was founded as an academic discipline in 1956,and the field went through multiple cycles of optimism throughoutits history,followed by periods of disappointment and loss of funding, known asAI winters.Funding and interest vastly increased after 2012 whengraphics processing unitsstarted being used to accelerate neural networks anddeep learningoutperformed previous AI techniques.This growth accelerated further after 2017 with thetransformer architecture.In the 2020s, an ongoing period of rapidprogressin advanced generative AI became known as theAI boom. Generative AI's ability to create and modify content has led to several unintended consequences and harms, which has raisedethical concernsaboutAI's long-term effectsandpotential existential risks, prompting discussions aboutregulatory policiesto ensurethe safetyand benefits of the technology. The general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research. Early researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logicaldeductions.By the late 1980s and 1990s, methods were developed for dealing withuncertainor incomplete information, employing concepts fromprobabilityandeconomics. Many of these algorithms are insufficient for solving large reasoning problems because they experience a \"combinatorial explosion\": They become exponentially slower as the problems grow.Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.Accurate and efficient reasoning is an unsolved problem. Knowledge representationandknowledge engineeringallow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval,scene interpretation,clinical decision support,knowledge discovery (mining \"interesting\" and actionable inferences from largedatabases),and other areas. Aknowledge baseis a body of knowledge represented in a form that can be used by a program. Anontologyis the set of objects, relations, concepts, and properties used by a particular domain of knowledge.Knowledge bases need to represent things such as objects, properties, categories, and relations between objects;situations, events, states, and time;causes and effects;knowledge about knowledge (what we know about what other people know);default reasoning(things that humans assume are true until they are told differently and will remain true even when other facts are changing);and many other aspects and domains of knowledge. Among the most difficult problems in knowledge representation are the breadth ofcommonsense knowledge(the set of atomic facts that the average person knows is enormous);and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as \"facts\" or \"statements\" that they could express verbally).There is also the difficulty ofknowledge acquisition, the problem of obtaining knowledge for AI applications. An \"agent\" is anything that perceives and takes actions in the world. Arational agenthas goals or preferences and takes actions to make them happen.Inautomated planning, the agent has a specific goal.Inautomated decision-making, the agent has preferences—there are some situations it would prefer to be in, and some situations it is trying to avoid. The decision-making agent assigns a number to each situation (called the \"utility\") that measures how much the agent prefers it. For each possible action, it can calculate the \"expected utility\": theutilityof all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility. Inclassical planning, the agent knows exactly what the effect of any action will be.In most real-world problems, however, the agent may not be certain about the situation they are in (it is \"unknown\" or \"unobservable\") and it may not know for certain what will happen after each possible action (it is not \"deterministic\"). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked. In some problems, the agent's preferences may be uncertain, especially if there are other agents or humans involved. These can be learned (e.g., withinverse reinforcement learning), or the agent can seek information to improve its preferences.Information value theorycan be used to weigh the value of exploratory or experimental actions.The space of possible future actions and situations is typicallyintractablylarge, so the agents must take actions and evaluate situations while being uncertain of what the outcome will be. AMarkov decision processhas atransition modelthat describes the probability that a particular action will change the state in a particular way and a reward function that supplies the utility of each state and the cost of each action. Apolicyassociates a decision with each possible state. The policy could be calculated (e.g., byiteration), beheuristic, or it can be learned. Game theorydescribes the rational behavior of multiple interacting agents and is used in AI programs that make decisions that involve other agents. Machine learningis the study of programs that can improve their performance on a given task automatically.It has been a part of AI from the beginning. There are several kinds of machine learning.Unsupervised learninganalyzes a stream of data and finds patterns and makes predictions without any other guidance.Supervised learningrequires labeling the training data with the expected answers, and comes in two main varieties:classification(where the program must learn to predict what category the input belongs in) andregression(where the program must deduce a numeric function based on numeric input). Inreinforcement learning, the agent is rewarded for good responses and punished for bad ones. The agent learns to choose responses that are classified as \"good\".Transfer learningis when the knowledge gained from one problem is applied to a new problem.Deep learningis a type of machine learning that runs inputs through biologically inspiredartificial neural networksfor all of these types of learning. Computational learning theorycan assess learners bycomputational complexity, bysample complexity(how much data is required), or by other notions ofoptimization. Natural language processing(NLP) allows programs to read, write and communicate in human languages.Specific problems includespeech recognition,speech synthesis,machine translation,information extraction,information retrievalandquestion answering. Early work, based onNoam Chomsky'sgenerative grammarandsemantic networks, had difficulty withword-sense disambiguationunless restricted to small domains called \"micro-worlds\" (due to thecommon sense knowledge problem).Margaret Mastermanbelieved that it was meaning and not grammar that was the key to understanding languages, and thatthesauriand not dictionaries should be the basis of computational language structure. Modern deep learning techniques for NLP includeword embedding(representing words, typically asvectorsencoding their meaning),transformers(a deep learning architecture using anattentionmechanism),and others.In 2019,generative pre-trained transformer(or \"GPT\") language models began to generate coherent text,and by 2023, these models were able to get human-level scores on thebar exam,SATtest,GREtest, and many other real-world applications. Machine perceptionis the ability to use input from sensors (such as cameras, microphones, wireless signals, activelidar, sonar, radar, andtactile sensors) to deduce aspects of the world.Computer visionis the ability to analyze visual input. The field includesspeech recognition,image classification,facial recognition,object recognition,object tracking,androbotic perception. Affective computingis a field that comprises systems that recognize, interpret, process, or simulate humanfeeling, emotion, and mood.For example, somevirtual assistantsare programmed to speak conversationally or even to banter humorously; it makes them appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitatehuman–computer interaction. However, this tends to give naïve users an unrealistic conception of the intelligence of existing computer agents.Moderate successes related to affective computing include textualsentiment analysisand, more recently,multimodal sentiment analysis, wherein AI classifies the effects displayed by a videotaped subject. A machine withartificial general intelligencewould be able to solve a wide variety of problems with breadth and versatility similar tohuman intelligence. AI research uses a wide variety of techniques to accomplish the goals above. AI can solve many problems by intelligently searching through many possible solutions.There are two very different kinds of search used in AI:state space searchandlocal search. State space searchsearches through a tree of possible states to try to find a goal state.For example,planningalgorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process calledmeans-ends analysis. Simple exhaustive searchesare rarely sufficient for most real-world problems: thesearch space(the number of places to search) quickly grows toastronomical numbers. The result is a search that istoo slowor never completes.\"Heuristics\" or \"rules of thumb\" can help prioritize choices that are more likely to reach a goal. Adversarial searchis used forgame-playingprograms, such as chess or Go. It searches through atreeof possible moves and countermoves, looking for a winning position. Local searchusesmathematical optimizationto find a solution to a problem. It begins with some form of guess and refines it incrementally. Gradient descentis a type of local search that optimizes a set of numerical parameters by incrementally adjusting them to minimize aloss function. Variants of gradient descent are commonly used to trainneural networks,through thebackpropagationalgorithm. Another type of local search isevolutionary computation, which aims to iteratively improve a set of candidate solutions by \"mutating\" and \"recombining\" them,selectingonly the fittest to survive each generation. Distributed search processes can coordinate viaswarm intelligencealgorithms. Two popular swarm algorithms used in search areparticle swarm optimization(inspired by birdflocking) andant colony optimization(inspired byant trails). Formallogicis used forreasoningandknowledge representation.Formal logic comes in two main forms:propositional logic(which operates on statements that are true or false and useslogical connectivessuch as \"and\", \"or\", \"not\" and \"implies\")andpredicate logic(which also operates on objects, predicates and relations and usesquantifierssuch as \"EveryXis aY\" and \"There aresomeXs that areYs\"). Deductive reasoningin logic is the process ofprovinga new statement (conclusion) from other statements that are given and assumed to be true (thepremises).Proofs can be structured as prooftrees, in which nodes are labelled by sentences, and children nodes are connected to parent nodes byinference rules. Given a problem and a set of premises, problem-solving reduces to searching for a proof tree whose root node is labelled by a solution of the problem and whoseleaf nodesare labelled by premises oraxioms. In the case ofHorn clauses, problem-solving search can be performed by reasoningforwardsfrom the premises orbackwardsfrom the problem.In the more general case of the clausal form offirst-order logic,resolutionis a single, axiom-free rule of inference, in which a problem is solved by proving a contradiction from premises that include the negation of the problem to be solved. Inference in both Horn clause logic and first-order logic isundecidable, and thereforeintractable. However, backward reasoning with Horn clauses, which underpins computation in thelogic programminglanguageProlog, isTuring complete. Moreover, its efficiency is competitive with computation in othersymbolic programminglanguages. Fuzzy logicassigns a \"degree of truth\" between 0 and 1. It can therefore handle propositions that are vague and partially true. Non-monotonic logics, including logic programming withnegation as failure, are designed to handledefault reasoning.Other specialized versions of logic have been developed to describe many complex domains. Many problems in AI (including reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of tools to solve these problems using methods fromprobabilitytheory and economics.Precise mathematical tools have been developed that analyze how an agent can make choices and plan, usingdecision theory,decision analysis,andinformation value theory.These tools include models such asMarkov decision processes,dynamicdecision networks,game theoryandmechanism design. Bayesian networksare a tool that can be used forreasoning(using theBayesian inferencealgorithm),learning(using theexpectation–maximization algorithm),planning(usingdecision networks)andperception(usingdynamic Bayesian networks). Probabilistic algorithms can also be used for filtering, prediction, smoothing, and finding explanations for streams of data, thus helping perception systems analyze processes that occur over time (e.g.,hidden Markov modelsorKalman filters). The simplest AI applications can be divided into two types: classifiers (e.g., \"if shiny then diamond\"), on one hand, and controllers (e.g., \"if diamond then pick up\"), on the other hand.Classifiersare functions that usepattern matchingto determine the closest match. They can be fine-tuned based on chosen examples usingsupervised learning. Each pattern (also called an \"observation\") is labeled with a certain predefined class. All the observations combined with their class labels are known as adata set. When a new observation is received, that observation is classified based on previous experience. There are many kinds of classifiers in use.Thedecision treeis the simplest and most widely used symbolic machine learning algorithm.K-nearest neighboralgorithm was the most widely used analogical AI until the mid-1990s, andKernel methodssuch as thesupport vector machine(SVM) displaced k-nearest neighbor in the 1990s.Thenaive Bayes classifieris reportedly the \"most widely used learner\"at Google, due in part to its scalability.Neural networksare also used as classifiers. An artificial neural network is based on a collection of nodes also known asartificial neurons, which loosely model theneuronsin a biological brain. It is trained to recognise patterns; once trained, it can recognise those patterns in fresh data. There is an input, at least one hidden layer of nodes and an output. Each node applies a function and once theweightcrosses its specified threshold, the data is transmitted to the next layer. A network is typically called a deep neural network if it has at least 2 hidden layers. Learning algorithms for neural networks uselocal searchto choose the weights that will get the right output for each input during training. The most common training technique is thebackpropagationalgorithm.Neural networks learn to model complex relationships between inputs and outputs andfind patternsin data. In theory, a neural network can learn any function. Infeedforward neural networksthe signal passes in only one direction.The termperceptrontypically refers to a single-layer neural network.In contrast, deep learning uses many layers.Recurrent neural networks(RNNs) feed the output signal back into the input, which allows short-term memories of previous input events.Long short-term memorynetworks (LSTMs) are recurrent neural networks that better preserve longterm dependencies and are less sensitive to thevanishing gradient problem.Convolutional neural networks(CNNs) use layers ofkernelsto more efficiently process local patterns. This local processing is especially important inimage processing, where the early CNN layers typically identify simple local patterns such as edges and curves, with subsequent layers detecting more complex patterns like textures, and eventually whole objects. Deep learninguses several layers of neurons between the network's inputs and outputs.The multiple layers can progressively extract higher-level features from the raw input. For example, inimage processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits, letters, or faces. Deep learning has profoundly improved the performance of programs in many important subfields of artificial intelligence, includingcomputer vision,speech recognition,natural language processing,image classification,and others. The reason that deep learning performs so well in so many applications is not known as of 2021.The sudden success of deep learning in 2012–2015 did not occur because of some new discovery or theoretical breakthrough (deep neural networks and backpropagation had been described by many people, as far back as the 1950s)but because of two factors: the incredible increase in computer power (including the hundred-fold increase in speed by switching toGPUs) and the availability of vast amounts of training data, especially the giantcurated datasetsused for benchmark testing, such asImageNet. Generative pre-trained transformers(GPT) arelarge language models(LLMs) that generate text based on the semantic relationships between words in sentences. Text-based GPT models are pre-trained on a largecorpus of textthat can be from the Internet. The pretraining consists of predicting the nexttoken(a token being usually a word, subword, or punctuation). Throughout this pretraining, GPT models accumulate knowledge about the world and can then generate human-like text by repeatedly predicting the next token. Typically, a subsequent training phase makes the model more truthful, useful, and harmless, usually with a technique calledreinforcement learning from human feedback(RLHF). Current GPT models are prone to generating falsehoods called \"hallucinations\". These can be reduced with RLHF and quality data, but the problem has been getting worse for reasoning systems.Such systems are used inchatbots, which allow people to ask a question or request a task in simple text. Current models and services includeChatGPT,Claude,Gemini,Copilot, andMeta AI.MultimodalGPT models can process different types of data (modalities) such as images, videos, sound, and text. In the late 2010s,graphics processing units(GPUs) that were increasingly designed with AI-specific enhancements and used with specializedTensorFlowsoftware had replaced previously usedcentral processing unit(CPUs) as the dominant means for large-scale (commercial and academic)machine learningmodels' training.Specializedprogramming languagessuch asPrologwere used in early AI research,butgeneral-purpose programming languageslikePythonhave become predominant. The transistor density inintegrated circuitshas been observed to roughly double every 18 months—a trend known asMoore's law, named after theIntelco-founderGordon Moore, who first identified it. Improvements inGPUshave been even faster,a trend sometimes calledHuang's law,named afterNvidiaco-founder and CEOJensen Huang. AI and machine learning technology is used in most of the essential applications of the 2020s, including:search engines(such asGoogle Search),targeting online advertisements,recommendation systems(offered byNetflix,YouTubeorAmazon), drivinginternet traffic,targeted advertising(AdSense,Facebook),virtual assistants(such asSiriorAlexa),autonomous vehicles(includingdrones,ADASandself-driving cars),automatic language translation(Microsoft Translator,Google Translate),facial recognition(Apple'sFaceIDorMicrosoft'sDeepFaceandGoogle'sFaceNet) andimage labeling(used byFacebook, Apple'sPhotosandTikTok). The deployment of AI may be overseen by achief automation officer(CAO). The application of AI inmedicineandmedical researchhas the potential to increase patient care and quality of life.Through the lens of theHippocratic Oath, medical professionals are ethically compelled to use AI, if applications can more accurately diagnose and treat patients. For medical research, AI is an important tool for processing and integratingbig data. This is particularly important fororganoidandtissue engineeringdevelopment which usemicroscopyimaging as a key technique in fabrication.It has been suggested that AI can overcome discrepancies in funding allocated to different fields of research.New AI tools can deepen the understanding of biomedically relevant pathways. For example,AlphaFold 2(2021) demonstrated the ability to approximate, in hours rather than months, the 3Dstructure of a protein.In 2023, it was reported that AI-guided drug discovery helped find a class of antibiotics capable of killing two different types of drug-resistant bacteria.In 2024, researchers used machine learning to accelerate the search forParkinson's diseasedrug treatments. Their aim was to identify compounds that block the clumping, or aggregation, ofalpha-synuclein(the protein that characterises Parkinson's disease). They were able to speed up the initial screening process ten-fold and reduce the cost by a thousand-fold. Game playingprograms have been used since the 1950s to demonstrate and test AI's most advanced techniques.Deep Bluebecame the first computer chess-playing system to beat a reigning world chess champion,Garry Kasparov, on 11 May 1997.In 2011, in aJeopardy!quiz showexhibition match,IBM'squestion answering system,Watson, defeated the two greatestJeopardy!champions,Brad RutterandKen Jennings, by a significant margin.In March 2016,AlphaGowon 4 out of 5 games ofGoin a match with Go championLee Sedol, becoming the firstcomputer Go-playing system to beat a professional Go player withouthandicaps. Then, in 2017, itdefeated Ke Jie, who was the best Go player in the world.Other programs handleimperfect-informationgames, such as thepoker-playing programPluribus.DeepMinddeveloped increasingly generalisticreinforcement learningmodels, such as withMuZero, which could be trained to play chess, Go, orAtarigames.In 2019, DeepMind's AlphaStar achieved grandmaster level inStarCraft II, a particularly challenging real-time strategy game that involves incomplete knowledge of what happens on the map.In 2021, an AI agent competed in a PlayStationGran Turismocompetition, winning against four of the world's best Gran Turismo drivers using deep reinforcement learning.In 2024, Google DeepMind introduced SIMA, a type of AI capable of autonomously playing nine previously unseenopen-worldvideo games by observing screen output, as well as executing short, specific tasks in response to natural language instructions. Large language models, such asGPT-4,Gemini,Claude,LlamaorMistral, are increasingly used in mathematics. These probabilistic models are versatile, but can also produce wrong answers in the form ofhallucinations. They sometimes need a large database of mathematical problems to learn from, but also methods such assupervisedfine-tuningor trainedclassifierswith human-annotated data to improve answers for new problems and learn from corrections.A February 2024 study showed that the performance of some language models for reasoning capabilities in solving math problems not included in their training data was low, even for problems with only minor deviations from trained data.One technique to improve their performance involves training the models to produce correctreasoningsteps, rather than just the correct result.TheAlibaba Groupdeveloped a version of itsQwenmodels calledQwen2-Math, that achieved state-of-the-art performance on several mathematical benchmarks, including 84% accuracy on the MATH dataset of competition mathematics problems.In January 2025, Microsoft proposed the techniquerStar-Maththat leveragesMonte Carlo tree searchand step-by-step reasoning, enabling a relatively small language model likeQwen-7Bto solve 53% of theAIME2024 and 90% of the MATH benchmark problems. Alternatively, dedicated models for mathematical problem solving with higher precision for the outcome including proof of theorems have been developed such asAlphaTensor,AlphaGeometry,AlphaProofandAlphaEvolveall fromGoogle DeepMind,LlemmafromEleutherAIorJulius. When natural language is used to describe mathematical problems, converters can transform such prompts into a formal language such asLeanto define mathematical tasks. The experimental modelGemini Deep Thinkaccepts natural language prompts directly and achieved gold medal results in theInternational Math Olympiadof 2025. Some models have been developed to solve challenging problems and reach good results in benchmark tests, others to serve as educational tools in mathematics. Topological deep learningintegrates varioustopologicalapproaches. Finance is one of the fastest growing sectors where applied AI tools are being deployed: from retail online banking to investment advice and insurance, where automated \"robot advisers\" have been in use for some years. According to Nicolas Firzli, director of theWorld Pensions & Investments Forum, it may be too early to see the emergence of highly innovative AI-informed financial products and services. He argues that \"the deployment of AI tools will simply further automatise things: destroying tens of thousands of jobs in banking, financial planning, and pension advice in the process, but I'm not sure it will unleash a new wave of [e.g., sophisticated] pension innovation.\" Various countries are deploying AI military applications.The main applications enhancecommand and control, communications, sensors, integration and interoperability.Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous andautonomous vehicles.AI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions,target acquisition, coordination and deconfliction of distributedJoint Firesbetween networked combat vehicles, both human-operated andautonomous. AI has been used in military operations in Iraq, Syria, Israel and Ukraine. Generative artificial intelligence(Generative AI, GenAI,or GAI) is a subfield of artificial intelligence that usesgenerative modelsto produce text,images,videos,audio,software codeor other forms of data.These modelslearnthe underlying patterns and structures of theirtraining dataand use them to produce new databased on the input, which often comes in the form of natural languageprompts. Generative AI tools have become more common since theAI boomin the 2020s. This boom was made possible by improvements intransformer-baseddeepneural networks, particularlylarge language models(LLMs). Major tools includechatbotssuch asChatGPT,Copilot,Gemini,Claude,Grok, andDeepSeek;text-to-imagemodels such asStable Diffusion,Midjourney, andDALL-E; andtext-to-videomodels such asVeoandSora.Technology companies developing generative AI includeOpenAI,xAI,Anthropic,Meta AI,Microsoft,Google,Mistral AI,DeepSeek,BaiduandYandex. AI agents are software entities designed to perceive their environment, make decisions, and take actions autonomously to achieve specific goals. These agents can interact with users, their environment, or other agents. AI agents are used in various applications, includingvirtual assistants,chatbots,autonomous vehicles,game-playing systems, andindustrial robotics. AI agents operate within the constraints of their programming, available computational resources, and hardware limitations. This means they are restricted to performing tasks within their defined scope and have finite memory and processing capabilities. In real-world applications, AI agents often face time constraints for decision-making and action execution. Many AI agents incorporate learning algorithms, enabling them to improve their performance over time through experience or training. Using machine learning, AI agents can adapt to new situations and optimise their behaviour for their designated tasks. Microsoft introducedCopilot Searchin February 2023 under the nameBing Chat, as a built-in feature for Microsoft Edge and Bing mobile app. Copilot Search provides AI-generated summariesand step-by-step reasoning based of information from web publishers, ranked in Bing Search.For safety, Copilot uses AI-based classifiers and filters to reduce potentially harmful content. Google officially pushed its AI Search at its Google I/O event on May 20, 2025.It keeps people looking at Google instead of clicking on a search result.AI Overviewsuses Gemini 2.5 to provide contextual answers to user queries based on web content. Applications of AI in this domain include AI-enabled menstruation and fertility trackers that analyze user data to offer predictions,AI-integrated sex toys (e.g.,teledildonics),AI-generated sexual education content,and AI agents that simulate sexual and romantic partners (e.g.,Replika).AI is also used for the production of non-consensualdeepfake pornography, raising significant ethical and legal concerns. AI technologies have also been used to attempt to identifyonline gender-based violenceand onlinesexual groomingof minors. There are also thousands of successful AI applications used to solve specific problems for specific industries or institutions. In a 2017 survey, one in five companies reported having incorporated \"AI\" in some offerings or processes.A few examples areenergy storage, medical diagnosis, military logistics, applications that predict the result of judicial decisions,foreign policy, or supply chain management. AI applications for evacuation anddisastermanagement are growing. AI has been used to investigate patterns in large-scale and small-scale evacuations using historical data from GPS, videos or social media. Furthermore, AI can provide real-time information on the evacuation conditions. In agriculture, AI has helped farmers to increase yield and identify areas that need irrigation, fertilization, pesticide treatments. Agronomists use AI to conduct research and development. AI has been used to predict the ripening time for crops such as tomatoes, monitor soil moisture, operate agricultural robots, conductpredictive analytics, classify livestock pig call emotions, automate greenhouses, detect diseases and pests, and save water. Artificial intelligence is used in astronomy to analyze increasing amounts of available data and applications, mainly for \"classification, regression, clustering, forecasting, generation, discovery, and the development of new scientific insights.\" For example, it is used for discovering exoplanets, forecasting solar activity, and distinguishing between signals and instrumental effects in gravitational wave astronomy. Additionally, it could be used for activities in space, such as space exploration, including the analysis of data from space missions, real-time science decisions of spacecraft, space debris avoidance, and more autonomous operation. During the2024 Indian elections, US$50 million was spent on authorized AI-generated content, notably by creatingdeepfakesof allied (including sometimes deceased) politicians to better engage with voters, and by translating speeches to various local languages. AI has potential benefits and potential risks.AI may be able to advance science and find solutions for serious problems:Demis HassabisofDeepMindhopes to \"solve intelligence, and then use that to solve everything else\".However, as the use of AI has become widespread, several unintended consequences and risks have been identified.In-production systems can sometimes not factor ethics and bias into their AI training processes, especially when the AI algorithms are inherently unexplainable in deep learning. Machine learning algorithms require large amounts of data. The techniques used to acquire this data have raised concerns aboutprivacy,surveillanceandcopyright. AI-powered devices and services, such as virtual assistants and IoT products, continuously collect personal information, raising concerns about intrusive data gathering and unauthorized access by third parties. The loss of privacy is further exacerbated by AI's ability to process and combine vast amounts of data, potentially leading to a surveillance society where individual activities are constantly monitored and analyzed without adequate safeguards or transparency. Sensitive user data collected may include online activity records, geolocation data, video, or audio.For example, in order to buildspeech recognitionalgorithms,Amazonhas recorded millions of private conversations and allowedtemporary workersto listen to and transcribe some of them.Opinions about this widespread surveillance range from those who see it as anecessary evilto those for whom it is clearlyunethicaland a violation of theright to privacy. AI developers argue that this is the only way to deliver valuable applications and have developed several techniques that attempt to preserve privacy while still obtaining the data, such asdata aggregation,de-identificationanddifferential privacy.Since 2016, some privacy experts, such asCynthia Dwork, have begun to view privacy in terms offairness.Brian Christianwrote that experts have pivoted \"from the question of 'what they know' to the question of 'what they're doing with it'.\" Generative AI is often trained on unlicensed copyrighted works, including in domains such as images or computer code; the output is then used under the rationale of \"fair use\". Experts disagree about how well and under what circumstances this rationale will hold up in courts of law; relevant factors may include \"the purpose and character of the use of the copyrighted work\" and \"the effect upon the potential market for the copyrighted work\".Website owners who do not wish to have their content scraped can indicate it in a \"robots.txt\" file.In 2023, leading authors (includingJohn GrishamandJonathan Franzen) sued AI companies for using their work to train generative AI.Another discussed approach is to envision a separatesui generissystem of protection for creations generated by AI to ensure fair attribution and compensation for human authors. The commercial AI scene is dominated byBig Techcompanies such asAlphabet Inc.,Amazon,Apple Inc.,Meta Platforms, andMicrosoft.Some of these players already own the vast majority of existingcloud infrastructureandcomputingpower fromdata centers, allowing them to entrench further in the marketplace. In January 2024, theInternational Energy Agency(IEA) releasedElectricity 2024, Analysis and Forecast to 2026, forecasting electric power use.This is the first IEA report to make projections for data centers and power consumption for artificial intelligence and cryptocurrency. The report states that power demand for these uses might double by 2026, with additional electric power usage equal to electricity used by the whole Japanese nation. Prodigious power consumption by AI is responsible for the growth of fossil fuel use, and might delay closings of obsolete, carbon-emitting coal energy facilities. There is a feverish rise in the construction of data centers throughout the US, making large technology firms (e.g., Microsoft, Meta, Google, Amazon) into voracious consumers of electric power. Projected electric consumption is so immense that there is concern that it will be fulfilled no matter the source. A ChatGPT search involves the use of 10 times the electrical energy as a Google search. The large firms are in haste to find power sources – from nuclear energy to geothermal to fusion. The tech firms argue that – in the long view – AI will be eventually kinder to the environment, but they need the energy now. AI makes the power grid more efficient and \"intelligent\", will assist in the growth of nuclear power, and track overall carbon emissions, according to technology firms. A 2024Goldman SachsResearch Paper,AI Data Centers and the Coming US Power Demand Surge, found \"US power demand (is) likely to experience growth not seen in a generation....\" and forecasts that, by 2030, US data centers will consume 8% of US power, as opposed to 3% in 2022, presaging growth for the electrical power generation industry by a variety of means.Data centers' need for more and more electrical power is such that they might max out the electrical grid. The Big Tech companies counter that AI can be used to maximize the utilization of the grid by all. In 2024, theWall Street Journalreported that big AI companies have begun negotiations with the US nuclear power providers to provide electricity to the data centers. In March 2024 Amazon purchased a Pennsylvania nuclear-powered data center for US$650 million.NvidiaCEOJensen Huangsaid nuclear power is a good option for the data centers. In September 2024,Microsoftannounced an agreement withConstellation Energyto re-open theThree Mile Islandnuclear power plant to provide Microsoft with 100% of all electric power produced by the plant for 20 years. Reopening the plant, which suffered a partial nuclear meltdown of its Unit 2 reactor in 1979, will require Constellation to get through strict regulatory processes which will include extensive safety scrutiny from the USNuclear Regulatory Commission. If approved (this will be the first ever US re-commissioning of a nuclear plant), over 835 megawatts of power – enough for 800,000 homes – of energy will be produced. The cost for re-opening and upgrading is estimated at US$1.6 billion and is dependent on tax breaks for nuclear power contained in the 2022 USInflation Reduction Act.The US government and the state of Michigan are investing almost US$2 billion to reopen thePalisades Nuclearreactor on Lake Michigan. Closed since 2022, the plant is planned to be reopened in October 2025. The Three Mile Island facility will be renamed the Crane Clean Energy Center after Chris Crane, a nuclear proponent and former CEO ofExelonwho was responsible for Exelon's spinoff of Constellation. After the last approval in September 2023,Taiwansuspended the approval of data centers north ofTaoyuanwith a capacity of more than 5 MW in 2024, due to power supply shortages.Taiwan aims tophase out nuclear powerby 2025.On the other hand,Singaporeimposed a ban on the opening of data centers in 2019 due to electric power, but in 2022, lifted this ban. Although most nuclear plants in Japan have been shut down after the 2011Fukushima nuclear accident, according to an October 2024Bloombergarticle in Japanese, cloud gaming services company Ubitus, in which Nvidia has a stake, is looking for land in Japan near a nuclear power plant for a new data center for generative AI.Ubitus CEO Wesley Kuo said nuclear power plants are the most efficient, cheap and stable power for AI. On 1 November 2024, theFederal Energy Regulatory Commission(FERC) rejected an application submitted byTalen Energyfor approval to supply some electricity from the nuclear power stationSusquehannato Amazon's data center.According to the Commission ChairmanWillie L. Phillips, it is a burden on the electricity grid as well as a significant cost shifting concern to households and other business sectors. In 2025, a report prepared by the International Energy Agency estimated thegreenhouse gas emissionsfrom the energy consumption of AI at 180 million tons. By 2035, these emissions could rise to 300–500 million tonnes depending on what measures will be taken. This is below 1.5% of the energy sector emissions. The emissions reduction potential of AI was estimated at 5% of the energy sector emissions, butrebound effects(for example if people switch from public transport to autonomous cars) can reduce it. YouTube,Facebookand others userecommender systemsto guide users to more content. These AI programs were given the goal ofmaximizinguser engagement (that is, the only goal was to keep people watching). The AI learned that users tended to choosemisinformation,conspiracy theories, and extremepartisancontent, and, to keep them watching, the AI recommended more of it. Users also tended to watch more content on the same subject, so the AI led people intofilter bubbleswhere they received multiple versions of the same misinformation.This convinced many users that the misinformation was true, and ultimately undermined trust in institutions, the media and the government.The AI program had correctly learned to maximize its goal, but the result was harmful to society. After the U.S. election in 2016, major technology companies took some steps to mitigate the problem. In the early 2020s,generative AIbegan to create images, audio, and texts that are virtually indistinguishable from real photographs, recordings, or human writing,while realistic AI-generated videos became feasible in the mid-2020s.It is possible for bad actors to use this technology to create massive amounts of misinformation or propaganda;one such potential malicious use is deepfakes forcomputational propaganda.AI pioneerGeoffrey Hintonexpressed concern about AI enabling \"authoritarian leaders to manipulate their electorates\" on a large scale, among other risks. AI researchers atMicrosoft,OpenAI, universities and other organisations have suggested using \"personhood credentials\" as a way to overcome online deception enabled by AI models. Machine learning applications will bebiasedif they learn from biased data.The developers may not be aware that the bias exists.Bias can be introduced by the waytraining datais selected and by the way a model is deployed.If a biased algorithm is used to make decisions that can seriouslyharmpeople (as it can inmedicine,finance,recruitment,housingorpolicing) then the algorithm may causediscrimination.The field offairnessstudies how to prevent harms from algorithmic biases. On June 28, 2015,Google Photos's new image labeling feature mistakenly identified Jacky Alcine and a friend as \"gorillas\" because they were black. The system was trained on a dataset that contained very few images of black people,a problem called \"sample size disparity\".Google \"fixed\" this problem by preventing the system from labellinganythingas a \"gorilla\". Eight years later, in 2023, Google Photos still could not identify a gorilla, and neither could similar products from Apple, Facebook, Microsoft and Amazon. COMPASis a commercial program widely used byU.S. courtsto assess the likelihood of adefendantbecoming arecidivist. In 2016,Julia AngwinatProPublicadiscovered that COMPAS exhibited racial bias, despite the fact that the program was not told the races of the defendants. Although the error rate for both whites and blacks was calibrated equal at exactly 61%, the errors for each race were different—the system consistently overestimated the chance that a black person would re-offend and would underestimate the chance that a white person would not re-offend.In 2017, several researchersshowed that it was mathematically impossible for COMPAS to accommodate all possible measures of fairness when the base rates of re-offense were different for whites and blacks in the data. A program can make biased decisions even if the data does not explicitly mention a problematic feature (such as \"race\" or \"gender\"). The feature will correlate with other features (like \"address\", \"shopping history\" or \"first name\"), and the program will make the same decisions based on these features as it would on \"race\" or \"gender\".Moritz Hardt said \"the most robust fact in this research area is that fairness through blindness doesn't work.\" Criticism of COMPAS highlighted that machine learning models are designed to make \"predictions\" that are only valid if we assume that the future will resemble the past. If they are trained on data that includes the results of racist decisions in the past, machine learning models must predict that racist decisions will be made in the future. If an application then uses these predictions asrecommendations, some of these \"recommendations\" will likely be racist.Thus, machine learning is not well suited to help make decisions in areas where there is hope that the future will bebetterthan the past. It is descriptive rather than prescriptive. Bias and unfairness may go undetected because the developers are overwhelmingly white and male: among AI engineers, about 4% are black and 20% are women. There are various conflicting definitions and mathematical models of fairness. These notions depend on ethical assumptions, and are influenced by beliefs about society. One broad category isdistributive fairness, which focuses on the outcomes, often identifying groups and seeking to compensate for statistical disparities. Representational fairness tries to ensure that AI systems do not reinforce negativestereotypesor render certain groups invisible. Procedural fairness focuses on the decision process rather than the outcome. The most relevant notions of fairness may depend on the context, notably the type of AI application and the stakeholders. The subjectivity in the notions of bias and fairness makes it difficult for companies to operationalize them. Having access to sensitive attributes such as race or gender is also considered by many AI ethicists to be necessary in order to compensate for biases, but it may conflict withanti-discrimination laws. At its 2022Conference on Fairness, Accountability, and Transparency(ACM FAccT 2022), theAssociation for Computing Machinery, in Seoul, South Korea, presented and published findings that recommend that until AI and robotics systems are demonstrated to be free of bias mistakes, they are unsafe, and the use of self-learning neural networks trained on vast, unregulated sources of flawed internet data should be curtailed. Many AI systems are so complex that their designers cannot explain how they reach their decisions.Particularly withdeep neural networks, in which there are many non-linearrelationships between inputs and outputs. But some popular explainability techniques exist. It is impossible to be certain that a program is operating correctly if no one knows how exactly it works. There have been many cases where a machine learning program passed rigorous tests, but nevertheless learned something different than what the programmers intended. For example, a system that could identify skin diseases better than medical professionals was found to actually have a strong tendency to classify images with aruleras \"cancerous\", because pictures of malignancies typically include a ruler to show the scale.Another machine learning system designed to help effectively allocate medical resources was found to classify patients with asthma as being at \"low risk\" of dying from pneumonia. Having asthma is actually a severe risk factor, but since the patients having asthma would usually get much more medical care, they were relatively unlikely to die according to the training data. The correlation between asthma and low risk of dying from pneumonia was real, but misleading. People who have been harmed by an algorithm's decision have a right to an explanation.Doctors, for example, are expected to clearly and completely explain to their colleagues the reasoning behind any decision they make. Early drafts of the European Union'sGeneral Data Protection Regulationin 2016 included an explicit statement that this right exists.Industry experts noted that this is an unsolved problem with no solution in sight. Regulators argued that nevertheless the harm is real: if the problem has no solution, the tools should not be used. DARPAestablished theXAI(\"Explainable Artificial Intelligence\") program in 2014 to try to solve these problems. Several approaches aim to address the transparency problem. SHAP enables to visualise the contribution of each feature to the output.LIME can locally approximate a model's outputs with a simpler, interpretable model.Multitask learningprovides a large number of outputs in addition to the target classification. These other outputs can help developers deduce what the network has learned.Deconvolution,DeepDreamand othergenerativemethods can allow developers to see what different layers of a deep network for computer vision have learned, and produce output that can suggest what the network is learning.Forgenerative pre-trained transformers,Anthropicdeveloped a technique based ondictionary learningthat associates patterns of neuron activations with human-understandable concepts. Artificial intelligence provides a number of tools that are useful tobad actors, such asauthoritarian governments,terrorists,criminalsorrogue states. A lethal autonomous weapon is a machine that locates, selects and engages human targets without human supervision.Widely available AI tools can be used by bad actors to develop inexpensive autonomous weapons and, if produced at scale, they are potentiallyweapons of mass destruction.Even when used in conventional warfare, they currently cannot reliably choose targets and could potentiallykill an innocent person.In 2014, 30 nations (including China) supported a ban on autonomous weapons under theUnited Nations'Convention on Certain Conventional Weapons, however theUnited Statesand others disagreed.By 2015, over fifty countries were reported to be researching battlefield robots. AI tools make it easier forauthoritarian governmentsto efficiently control their citizens in several ways.Faceandvoice recognitionallow widespreadsurveillance.Machine learning, operating this data, canclassifypotential enemies of the state and prevent them from hiding.Recommendation systemscan precisely targetpropagandaandmisinformationfor maximum effect.Deepfakesandgenerative AIaid in producing misinformation. Advanced AI can make authoritariancentralized decision-makingmore competitive than liberal and decentralized systems such asmarkets. It lowers the cost and difficulty ofdigital warfareandadvanced spyware.All these technologies have been available since 2020 or earlier—AIfacial recognition systemsare already being used formass surveillancein China. There are many other ways in which AI is expected to help bad actors, some of which can not be foreseen. For example, machine-learning AI is able to design tens of thousands of toxic molecules in a matter of hours. Economists have frequently highlighted the risks of redundancies from AI, and speculated about unemployment if there is no adequate social policy for full employment. In the past, technology has tended to increase rather than reduce total employment, but economists acknowledge that \"we're in uncharted territory\" with AI.A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-termunemployment, but they generally agree that it could be a net benefit ifproductivitygains areredistributed.Risk estimates vary; for example, in the 2010s, Michael Osborne andCarl Benedikt Freyestimated 47% of U.S. jobs are at \"high risk\" of potential automation, while an OECD report classified only 9% of U.S. jobs as \"high risk\".The methodology of speculating about future employment levels has been criticised as lacking evidential foundation, and for implying that technology, rather than social policy, creates unemployment, as opposed to redundancies.In April 2023, it was reported that 70% of the jobs for Chinese video game illustrators had been eliminated by generative artificial intelligence. Unlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence;The Economiststated in 2015 that \"the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution\" is \"worth taking seriously\".Jobs at extreme risk range fromparalegalsto fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy.In July 2025,FordCEOJim Farleypredicted that \"artificial intelligence is going to replace literally half of allwhite-collar workersin the U.S.\" From the early days of the development of artificial intelligence, there have been arguments, for example, those put forward byJoseph Weizenbaum, about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculation and qualitative, value-based judgement. It has been argued AI will become so powerful that humanity may irreversibly lose control of it. This could, as physicistStephen Hawkingstated, \"spell the end of the human race\".This scenario has been common in science fiction, when a computer or robot suddenly develops a human-like \"self-awareness\" (or \"sentience\" or \"consciousness\") and becomes a malevolent character.These sci-fi scenarios are misleading in several ways. First, AI does not require human-likesentienceto be an existential risk. Modern AI programs are given specific goals and use learning and intelligence to achieve them. PhilosopherNick Bostromargued that if one givesalmost anygoal to a sufficiently powerful AI, it may choose to destroy humanity to achieve it (he used the example of apaperclip maximizer).Stuart Russellgives the example of household robot that tries to find a way to kill its owner to prevent it from being unplugged, reasoning that \"you can't fetch the coffee if you're dead.\"In order to be safe for humanity, asuperintelligencewould have to be genuinelyalignedwith humanity's morality and values so that it is \"fundamentally on our side\". Second,Yuval Noah Harariargues that AI does not require a robot body or physical control to pose an existential risk. The essential parts of civilization are not physical. Things likeideologies,law,government,moneyand theeconomyare built onlanguage; they exist because there are stories that billions of people believe. The current prevalence ofmisinformationsuggests that an AI could use language to convince people to believe anything, even to take actions that are destructive. The opinions amongst experts and industry insiders are mixed, with sizable fractions both concerned and unconcerned by risk from eventual superintelligent AI.Personalities such asStephen Hawking,Bill Gates, andElon Musk,as well as AI pioneers such asYoshua Bengio,Stuart Russell,Demis Hassabis, andSam Altman, have expressed concerns about existential risk from AI. In May 2023,Geoffrey Hintonannounced his resignation from Google in order to be able to \"freely speak out about the risks of AI\" without \"considering how this impacts Google\".He notably mentioned risks of anAI takeover,and stressed that in order to avoid the worst outcomes, establishing safety guidelines will require cooperation among those competing in use of AI. In 2023, many leading AI experts endorsedthe joint statementthat \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war\". Some other researchers were more optimistic. AI pioneerJürgen Schmidhuberdid not sign the joint statement, emphasising that in 95% of all cases, AI research is about making \"human lives longer and healthier and easier.\"While the tools that are now being used to improve lives can also be used by bad actors, \"they can also be used against the bad actors.\"Andrew Ngalso argued that \"it's a mistake to fall for the doomsday hype on AI—and that regulators who do will only benefit vested interests.\"Yann LeCun\"scoffs at his peers' dystopian scenarios of supercharged misinformation and even, eventually, human extinction.\"In the early 2010s, experts argued that the risks are too distant in the future to warrant research or that humans will be valuable from the perspective of a superintelligent machine.However, after 2016, the study of current and future risks and possible solutions became a serious area of research. Friendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans.Eliezer Yudkowsky, who coined the term, argues that developing friendly AI should be a higher research priority: it may require a large investment and it must be completed before AI becomes an existential risk. Machines with intelligence have the potential to use their intelligence to make ethical decisions. The field of machine ethics provides machines with ethical principles and procedures for resolving ethical dilemmas.The field of machine ethics is also called computational morality,and was founded at anAAAIsymposium in 2005. Other approaches includeWendell Wallach's \"artificial moral agents\"andStuart J. Russell'sthree principlesfor developing provably beneficial machines. Active organizations in the AI open-source community includeHugging Face,Google,EleutherAIandMeta.Various AI models, such asLlama 2,MistralorStable Diffusion, have been made open-weight,meaning that their architecture and trained parameters (the \"weights\") are publicly available. Open-weight models can be freelyfine-tuned, which allows companies to specialize them with their own data and for their own use-case.Open-weight models are useful for research and innovation but can also be misused. Since they can be fine-tuned, any built-in security measure, such as objecting to harmful requests, can be trained away until it becomes ineffective. Some researchers warn that future AI models may develop dangerous capabilities (such as the potential to drastically facilitatebioterrorism) and that once released on the Internet, they cannot be deleted everywhere if needed. They recommend pre-release audits and cost-benefit analyses. Artificial intelligence projects can be guided by ethical considerations during the design, development, and implementation of an AI system. An AI framework such as the Care and Act Framework, developed by theAlan Turing Instituteand based on the SUM values, outlines four main ethical dimensions, defined as follows: Other developments in ethical frameworks include those decided upon during theAsilomar Conference, the Montreal Declaration for Responsible AI, and the IEEE's Ethics of Autonomous Systems initiative, among others;however, these principles are not without criticism, especially regarding the people chosen to contribute to these frameworks. Promotion of the wellbeing of the people and communities that these technologies affect requires consideration of the social and ethical implications at all stages of AI system design, development and implementation, and collaboration between job roles such as data scientists, product managers, data engineers, domain experts, and delivery managers. TheUK AI Safety Institutereleased in 2024 a testing toolset called 'Inspect' for AI safety evaluations available under an MIT open-source licence which is freely available on GitHub and can be improved with third-party packages. It can be used to evaluate AI models in a range of areas including core knowledge, ability to reason, and autonomous capabilities. The regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating AI; it is therefore related to the broader regulation of algorithms.The regulatory and policy landscape for AI is an emerging issue in jurisdictions globally.According to AI Index atStanford, the annual number of AI-related laws passed in the 127 survey countries jumped from one passed in 2016 to 37 passed in 2022 alone.Between 2016 and 2020, more than 30 countries adopted dedicated strategies for AI.Most EU member states had released national AI strategies, as hadCanada, China, India, Japan, Mauritius, the Russian Federation, Saudi Arabia, United Arab Emirates, U.S., and Vietnam. Others were in the process of elaborating their own AI strategy, including Bangladesh, Malaysia and Tunisia.TheGlobal Partnership on Artificial Intelligencewas launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology.Henry Kissinger,Eric Schmidt, andDaniel Huttenlocherpublished a joint statement in November 2021 calling for a government commission to regulate AI.In 2023, OpenAI leaders published recommendations for the governance of superintelligence, which they believe may happen in less than 10 years.In 2023, the United Nations also launched an advisory body to provide recommendations on AI governance; the body comprises technology company executives, government officials and academics.On 1 August 2024, the EUArtificial Intelligence Actentered into force, establishing the first comprehensive EU-wide AI regulation.In 2024, theCouncil of Europecreated the first international legally binding treaty on AI, called the \"Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law\". It was adopted by the European Union, the United States, the United Kingdom, and other signatories. In a 2022Ipsossurvey, attitudes towards AI varied greatly by country; 78% of Chinese citizens, but only 35% of Americans, agreed that \"products and services using AI have more benefits than drawbacks\".A 2023Reuters/Ipsos poll found that 61% of Americans agree, and 22% disagree, that AI poses risks to humanity.In a 2023Fox Newspoll, 35% of Americans thought it \"very important\", and an additional 41% thought it \"somewhat important\", for the federal government to regulate AI, versus 13% responding \"not very important\" and 8% responding \"not at all important\". In November 2023, the first globalAI Safety Summitwas held inBletchley Parkin the UK to discuss the near and far term risks of AI and the possibility of mandatory and voluntary regulatory frameworks.28 countries including the United States, China, and the European Union issued a declaration at the start of the summit, calling for international co-operation to manage the challenges and risks of artificial intelligence.In May 2024 at theAI Seoul Summit, 16 global AI tech companies agreed to safety commitments on the development of AI. The study of mechanical or \"formal\" reasoning began with philosophers and mathematicians in antiquity. The study of logic led directly toAlan Turing'stheory of computation, which suggested that a machine, by shuffling symbols as simple as \"0\" and \"1\", could simulate any conceivable form of mathematical reasoning.This, along with concurrent discoveries incybernetics,information theoryandneurobiology, led researchers to consider the possibility of building an \"electronic brain\".They developed several areas of research that would become part of AI,such asMcCullochandPittsdesign for \"artificial neurons\" in 1943,and Turing's influential 1950 paper 'Computing Machinery and Intelligence', which introduced theTuring testand showed that \"machine intelligence\" was plausible. The field of AI research was founded ata workshopatDartmouth Collegein 1956.The attendees became the leaders of AI research in the 1960s.They and their students produced programs that the press described as \"astonishing\":computers were learningcheckersstrategies, solving word problems in algebra, provinglogical theoremsand speaking English.Artificial intelligence laboratories were set up at a number of British and U.S. universities in the latter 1950s and early 1960s. Researchers in the 1960s and the 1970s were convinced that their methods would eventually succeed in creating a machine withgeneral intelligenceand considered this the goal of their field.In 1965Herbert Simonpredicted, \"machines will be capable, within twenty years, of doing any work a man can do\".In 1967Marvin Minskyagreed, writing that \"within a generation ... the problem of creating 'artificial intelligence' will substantially be solved\".They had, however, underestimated the difficulty of the problem.In 1974, both the U.S. and British governments cut off exploratory research in response to thecriticismofSir James Lighthilland ongoing pressure from the U.S. Congress tofund more productive projects.MinskyandPapert's bookPerceptronswas understood as proving thatartificial neural networkswould never be useful for solving real-world tasks, thus discrediting the approach altogether.The \"AI winter\", a period when obtaining funding for AI projects was difficult, followed. In the early 1980s, AI research was revived by the commercial success ofexpert systems,a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan'sfifth generation computerproject inspired the U.S. and British governments to restore funding foracademic research.However, beginning with the collapse of theLisp Machinemarket in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began. Up to this point, most of AI's funding had gone to projects that used high-levelsymbolsto representmental objectslike plans, goals, beliefs, and known facts. In the 1980s, some researchers began to doubt that this approach would be able to imitate all the processes of human cognition, especiallyperception,robotics,learningandpattern recognition,and began to look into \"sub-symbolic\" approaches.Rodney Brooksrejected \"representation\" in general and focussed directly on engineering machines that move and survive.Judea Pearl,Lotfi Zadeh, and others developed methods that handled incomplete and uncertain information by making reasonable guesses rather than precise logic.But the most important development was the revival of \"connectionism\", including neural network research, byGeoffrey Hintonand others.In 1990,Yann LeCunsuccessfully showed thatconvolutional neural networkscan recognize handwritten digits, the first of many successful applications of neural networks. AI gradually restored its reputation in the late 1990s and early 21st century by exploiting formal mathematical methods and by finding specific solutions to specific problems. This \"narrow\" and \"formal\" focus allowed researchers to produce verifiable results and collaborate with other fields (such asstatistics,economicsandmathematics).By 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as \"artificial intelligence\" (a tendency known as theAI effect).However, several academic researchers became concerned that AI was no longer pursuing its original goal of creating versatile, fully intelligent machines. Beginning around 2002, they founded the subfield ofartificial general intelligence(or \"AGI\"), which had several well-funded institutions by the 2010s. Deep learningbegan to dominate industry benchmarks in 2012 and was adopted throughout the field.For many specific tasks, other methods were abandoned.Deep learning's success was based on both hardware improvements (faster computers,graphics processing units,cloud computing) and access tolarge amounts of data(including curated datasets,such asImageNet). Deep learning's success led to an enormous increase in interest and funding in AI.The amount of machine learning research (measured by total publications) increased by 50% in the years 2015–2019. In 2016, issues offairnessand the misuse of technology were catapulted into center stage at machine learning conferences, publications vastly increased, funding became available, and many researchers re-focussed their careers on these issues. Thealignment problembecame a serious field of academic study. In the late 2010s and early 2020s, AGI companies began to deliver programs that created enormous interest. In 2015,AlphaGo, developed byDeepMind, beat the world championGo player. The program taught only the game's rules and developed a strategy by itself.GPT-3is alarge language modelthat was released in 2020 byOpenAIand is capable of generating high-quality human-like text.ChatGPT, launched on November 30, 2022, became the fastest-growing consumer software application in history, gaining over 100 million users in two months.It marked what is widely regarded as AI's breakout year, bringing it into the public consciousness.These programs, and others, inspired an aggressiveAI boom, where large companies began investing billions of dollars in AI research. According to AI Impacts, about US$50 billion annually was invested in \"AI\" around 2022 in the U.S. alone and about 20% of the new U.S. Computer Science PhD graduates have specialized in \"AI\".About 800,000 \"AI\"-related U.S. job openings existed in 2022.According to PitchBook research, 22% of newly fundedstartupsin 2024 claimed to be AI companies. Philosophical debates have historically sought to determine the nature of intelligence and how to make intelligent machines.Another major focus has been whether machines can be conscious, and the associated ethical implications.Many other topics in philosophy are relevant to AI, such asepistemologyandfree will.Rapid advancements have intensified public discussions on the philosophy andethics of AI. Alan Turingwrote in 1950 \"I propose to consider the question 'can machines think'?\"He advised changing the question from whether a machine \"thinks\", to \"whether or not it is possible for machinery to show intelligent behaviour\".He devised theTuring test, which measures the ability of a machine to simulate human conversation.Since we can only observe the behavior of the machine, it does not matter if it is \"actually\" thinking or literally has a \"mind\". Turing notes thatwe can not determine these things about other peoplebut \"it is usual to have a polite convention that everyone thinks.\" RussellandNorvigagree with Turing that intelligence must be defined in terms of external behavior, not internal structure.However, they are critical that the test requires the machine to imitate humans. \"Aeronautical engineeringtexts\", they wrote, \"do not define the goal of their field as making 'machines that fly so exactly likepigeonsthat they can fool other pigeons.'\"AI founderJohn McCarthyagreed, writing that \"Artificial intelligence is not, by definition, simulation of human intelligence\". McCarthy defines intelligence as \"the computational part of the ability to achieve goals in the world\".Another AI founder,Marvin Minsky, similarly describes it as \"the ability to solve hard problems\".The leading AI textbook defines it as the study of agents that perceive their environment and take actions that maximize their chances of achieving defined goals.These definitions view intelligence in terms of well-defined problems with well-defined solutions, where both the difficulty of the problem and the performance of the program are direct measures of the \"intelligence\" of the machine—and no other philosophical discussion is required, or may not even be possible. Another definition has been adopted by Google,a major practitioner in the field of AI. This definition stipulates the ability of systems to synthesize information as the manifestation of intelligence, similar to the way it is defined in biological intelligence. As a result of the many circulating definitions scholars have started to critically analyze and order the AI discourse itselfincluding discussing the many AI narratives and myths to be found within societal, political and academic discourses.Similarly, in practice, some authors have suggested that the term 'AI' is often used too broadly and vaguely. This raises the question of where the line should be drawn between AI and classical algorithms,with many companies during the early 2020s AI boom using the term as a marketingbuzzword, often even if they did \"not actually use AI in a material way\". There has been debate over whetherlarge language modelsexhibit genuine intelligence or merely simulate it byimitating human text. No established unifying theory orparadigmhas guided AI research for most of its history.The unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term \"artificial intelligence\" to mean \"machine learning with neural networks\"). This approach is mostlysub-symbolic,softandnarrow. Critics argue that these questions may have to be revisited by future generations of AI researchers. Symbolic AI(or \"GOFAI\")simulated the high-level conscious reasoning that people use when they solve puzzles, express legal reasoning and do mathematics. They were highly successful at \"intelligent\" tasks such as algebra or IQ tests. In the 1960s, Newell and Simon proposed thephysical symbol systems hypothesis: \"A physical symbol system has the necessary and sufficient means of general intelligent action.\" However, the symbolic approach failed on many tasks that humans solve easily, such as learning, recognizing an object orcommonsense reasoning.Moravec's paradoxis the discovery that high-level \"intelligent\" tasks were easy for AI, but low level \"instinctive\" tasks were extremely difficult.PhilosopherHubert Dreyfushadarguedsince the 1960s that human expertise depends on unconscious instinct rather than conscious symbol manipulation, and on having a \"feel\" for the situation, rather than explicit symbolic knowledge.Although his arguments had been ridiculed and ignored when they were first presented, eventually, AI research came to agree with him. The issue is not resolved:sub-symbolicreasoning can make many of the same inscrutable mistakes that human intuition does, such asalgorithmic bias. Critics such asNoam Chomskyargue continuing research into symbolic AI will still be necessary to attain general intelligence,in part because sub-symbolic AI is a move away fromexplainable AI: it can be difficult or impossible to understand why a modern statistical AI program made a particular decision. The emerging field ofneuro-symbolic artificial intelligenceattempts to bridge the two approaches. \"Neats\" hope that intelligent behavior is described using simple, elegant principles (such aslogic,optimization, orneural networks). \"Scruffies\" expect that it necessarily requires solving a large number of unrelated problems. Neats defend their programs with theoretical rigor, scruffies rely mainly on incremental testing to see if they work. This issue was actively discussed in the 1970s and 1980s,but eventually was seen as irrelevant. Modern AI has elements of both. Finding a provably correct or optimal solution isintractablefor many important problems.Soft computing is a set of techniques, includinggenetic algorithms,fuzzy logicand neural networks, that are tolerant of imprecision, uncertainty, partial truth and approximation. Soft computing was introduced in the late 1980s and most successful AI programs in the 21st century are examples of soft computing with neural networks. AI researchers are divided as to whether to pursue the goals of artificial general intelligence andsuperintelligencedirectly or to solve as many specific problems as possible (narrow AI) in hopes these solutions will lead indirectly to the field's long-term goals.General intelligence is difficult to define and difficult to measure, and modern AI has had more verifiable successes by focusing on specific problems with specific solutions. The sub-field of artificial general intelligence studies this area exclusively. There is no settled consensus inphilosophy of mindon whether a machine can have amind,consciousnessandmental statesin the same sense that human beings do. This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant because it does not affect the goals of the field: to build machines that can solve problems using intelligence.RussellandNorvigadd that \"[t]he additional project of making a machine conscious in exactly the way humans are is not one that we are equipped to take on.\"However, the question has become central to the philosophy of mind. It is also typically the central question at issue inartificial intelligence in fiction. David Chalmersidentified two problems in understanding the mind, which he named the \"hard\" and \"easy\" problems of consciousness.The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how thisfeelsor why it should feel like anything at all, assuming we are right in thinking that it truly does feel like something (Dennett's consciousness illusionism says this is an illusion). While humaninformation processingis easy to explain, humansubjective experienceis difficult to explain. For example, it is easy to imagine a color-blind person who has learned to identify which objects in their field of view are red, but it is not clear what would be required for the person toknow what red looks like. Computationalism is the position in thephilosophy of mindthat the human mind is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to themind–body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophersJerry FodorandHilary Putnam. PhilosopherJohn Searlecharacterized this position as \"strong AI\": \"The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.\"Searle challenges this claim with hisChinese roomargument, which attempts to show that even a computer capable of perfectly simulating human behavior would not have a mind. It is difficult or impossible to reliably evaluate whether an advancedAI is sentient(has the ability to feel), and if so, to what degree.But if there is a significant chance that a given machine can feel and suffer, then it may be entitled to certain rights or welfare protection measures, similarly to animals.Sapience(a set of capacities related to high intelligence, such as discernment orself-awareness) may provide another moral basis for AI rights.Robot rightsare also sometimes proposed as a practical way to integrate autonomous agents into society. In 2017, the European Union considered granting \"electronic personhood\" to some of the most capable AI systems. Similarly to the legal status of companies, it would have conferred rights but also responsibilities.Critics argued in 2018 that granting rights to AI systems would downplay the importance ofhuman rights, and that legislation should focus on user needs rather than speculative futuristic scenarios. They also noted that robots lacked the autonomy to take part in society on their own. Progress in AI increased interest in the topic. Proponents of AI welfare and rights often argue that AI sentience, if it emerges, would be particularly easy to deny. They warn that this may be amoral blind spotanalogous toslaveryorfactory farming, which could lead tolarge-scale sufferingif sentient AI is created and carelessly exploited. Asuperintelligenceis a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind.If research intoartificial general intelligenceproduced sufficiently intelligent software, it might be able toreprogram and improve itself. The improved software would be even better at improving itself, leading to whatI. J. Goodcalled an \"intelligence explosion\" andVernor Vingecalled a \"singularity\". However, technologies cannot improve exponentially indefinitely, and typically follow anS-shaped curve, slowing when they reach the physical limits of what the technology can do. Robot designerHans Moravec, cyberneticistKevin Warwickand inventorRay Kurzweilhave predicted that humans and machines may merge in the future intocyborgsthat are more capable and powerful than either. This idea, called transhumanism, has roots in the writings ofAldous HuxleyandRobert Ettinger. Edward Fredkinargues that \"artificial intelligence is the next step in evolution\", an idea first proposed bySamuel Butler's \"Darwin among the Machines\" as far back as 1863, and expanded upon byGeorge Dysonin his 1998 bookDarwin Among the Machines: The Evolution of Global Intelligence. Thought-capable artificial beings have appeared as storytelling devices since antiquity,and have been a persistent theme inscience fiction. A commontropein these works began withMary Shelley'sFrankenstein, where a human creation becomes a threat to its masters. This includes such works asArthur C. Clarke'sandStanley Kubrick's2001: A Space Odyssey(both 1968), withHAL 9000, the murderous computer in charge of theDiscovery Onespaceship, as well asThe Terminator(1984) andThe Matrix(1999). In contrast, the rare loyal robots such as Gort fromThe Day the Earth Stood Still(1951) and Bishop fromAliens(1986) are less prominent in popular culture. Isaac Asimovintroduced theThree Laws of Roboticsin many stories, most notably with the \"Multivac\" super-intelligent computer. Asimov's laws are often brought up during lay discussions of machine ethics;while almost all artificial intelligence researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity. Several works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that havethe ability to feel, and thus to suffer. This appears inKarel Čapek'sR.U.R., the filmsA.I. Artificial IntelligenceandEx Machina, as well as the novelDo Androids Dream of Electric Sheep?, byPhilip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence. The two most widely used textbooks in 2023 (see theOpen Syllabus): The four most widely used AI textbooks in 2008: Other textbooks:", "metadata": {"url": "https://en.wikipedia.org/wiki/Artificial_intelligence", "title": "Artificial intelligence", "headings": ["Contents", "Goals", "Reasoning and problem-solving", "Knowledge representation", "Planning and decision-making", "Learning", "Natural language processing", "Perception", "Social intelligence", "General intelligence", "Techniques", "Search and optimization", "Logic", "Probabilistic methods for uncertain reasoning", "Classifiers and statistical learning methods", "Artificial neural networks", "Deep learning", "GPT", "Hardware and software", "Applications", "Health and medicine", "Games", "Mathematics", "Finance", "Military", "Generative AI", "Agents", "Web search", "Sexuality", "Other industry-specific tasks", "Ethics", "Risks and harm", "Ethical machines and alignment", "Open source", "Frameworks", "Regulation", "History", "Philosophy", "Defining artificial intelligence", "Evaluating approaches to AI", "Machine consciousness, sentience, and mind", "Future", "Superintelligence and the singularity", "Transhumanism", "In fiction", "See also", "Explanatory notes", "References", "AI textbooks", "History of AI", "Other sources", "Further reading", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Artificial_intelligence", "https://en.wikipedia.org/wiki/Artificial_intelligence", "https://en.wikipedia.org/wiki/Artificial_intelligence", "https://en.wikipedia.org/wiki/AI_(disambiguation)", "https://en.wikipedia.org/wiki/Artificial_intelligence_(disambiguation)", "https://en.wikipedia.org/wiki/Artificial_general_intelligence", "https://en.wikipedia.org/wiki/Intelligent_agent", "https://en.wikipedia.org/wiki/Recursive_self-improvement"]}},
{"id": "34e224ca1f6a", "content": " Intelligencehas been defined in many ways: the capacity forabstraction,logic,understanding,self-awareness,learning,emotional knowledge,reasoning,planning,creativity,critical thinking, andproblem-solving. It can be described as the ability to perceive or inferinformationand to retain it asknowledgeto be applied to adaptive behaviors within an environment or context. The term rose to prominence during the early 1900s.Mostpsychologistsbelieve that intelligence can be divided into various domains or competencies. Intelligence has been long-studiedin humans, and across numerous disciplines. It has also been observed in thecognition of non-human animals.Some researchers have suggested thatplantsexhibit forms of intelligence, though this remains controversial. The wordintelligencederives from the Latinnounsintelligentiaorintellēctus, which in turn stem from the verbintelligere, to comprehend or perceive. In theMiddle Ages, the wordintellectusbecame the scholarly technical term for understanding and a translation for the Greek philosophical termnous. This term, however, was strongly linked to themetaphysicalandcosmologicaltheories ofteleologicalscholasticism, including theories of the immortality of the soul, and the concept of theactive intellect(also known as the active intelligence). This approach to the study of nature was strongly rejected byearly modern philosopherssuch asFrancis Bacon,Thomas Hobbes,John Locke, andDavid Hume, all of whom preferred \"understanding\" (in place of \"intellectus\" or \"intelligence\") in their English philosophical works.Hobbes for example, in his LatinDe Corpore, used \"intellectus intelligit\", translated in the English version as \"the understanding understandeth\", as a typical example of a logicalabsurdity.\"Intelligence\" has therefore become less common in English language philosophy, but it has later been taken up (with the scholastic theories that it now implies) in more contemporarypsychology. There is controversy over how to define intelligence. Scholars describe its constituent abilities in various ways, and differ in the degree to which they conceive of intelligence as quantifiable. A consensus report calledIntelligence: Knowns and Unknowns, published in 1995 by the Board of Scientific Affairs of theAmerican Psychological Association, states: Individuals differ from one another in their ability to understand complex ideas, to adapt effectively to the environment, to learn from experience, to engage in various forms of reasoning, to overcome obstacles by taking thought. Although these individual differences can be substantial, they are never entirely consistent: a given person's intellectual performance will vary on different occasions, in different domains, as judged by different criteria. Concepts of \"intelligence\" are attempts to clarify and organize this complex set of phenomena. Although considerable clarity has been achieved in some areas, no such conceptualization has yet answered all the important questions, and none commands universal assent. Indeed, when two dozen prominent theorists were recently asked to define intelligence, they gave two dozen, somewhat different, definitions. Psychologistsandlearningresearchers also have suggested definitions of intelligence such as the following: \"Intelligence is a force, F, that acts so as to maximize future freedom of action. It acts to maximize future freedom of action, or keep options open, with some strength T, with the diversity of possible accessible futures, S, up to some future time horizon, τ. In short, intelligence doesn't like to get trapped\". Human intelligence is the intellectual power of humans, which is marked by complexcognitivefeats and high levels ofmotivationandself-awareness.Intelligence enables humans to remember descriptions of things and use those descriptions in future behaviors. It gives humans the cognitive abilities tolearn,form concepts,understand, andreason, including the capacities torecognize patterns, innovate,plan,solve problems, and employlanguagetocommunicate. These cognitive abilities can be organized into frameworks likefluid vs. crystallizedand the Unified Cattell-Horn-Carroll model,which contains abilities like fluid reasoning, perceptual speed, verbal abilities, and others. Intelligence is different fromlearning. Learning refers to the act of retaining facts and information or abilities and being able to recall them for future use. Intelligence, on the other hand, is the cognitive ability of someone to perform these and other processes. There have been various attempts to quantify intelligence viapsychometrictesting. Prominent among these are the variousIntelligence Quotient(IQ) tests, which were first developed in the early 20th century to screen children forintellectual disability.Over time, IQ tests became more pervasive, being used to screen immigrants, military recruits, and job applicants.As the tests became more popular, belief that IQ tests measure a fundamental and unchanging attribute that all humans possess became widespread. An influential theory that promoted the idea that IQ measures a fundamental quality possessed by every person is the theory ofGeneral Intelligence, orgfactor.Thegfactor is a construct that summarizes thecorrelationsobserved between an individual's scores on a range of cognitive tests. Today, most psychologists agree that IQ measures at least some aspects of human intelligence, particularly the ability to thrive in an academic context.However, many psychologists question thevalidityof IQ tests as a measure of intelligence as a whole. There is debate about theheritability of IQ, that is, what proportion of differences in IQ test performance between individuals are explained bygeneticorenvironmentalfactors.The scientific consensus is that genetics does not explainaverage differences in IQ test performance between racial groups. Emotional intelligence is thought to be the ability to conveyemotionto others in an understandable way as well as to read the emotions of others accurately.Some theories imply that a heightened emotional intelligence could also lead to faster generating and processing of emotions in addition to the accuracy.In addition, higher emotional intelligence is thought to help us manage emotions, which is beneficial for our problem-solving skills. Emotional intelligence is important to ourmental healthand has ties to social intelligence. Social intelligence is the ability to understand thesocial cuesand motivations of others and oneself in social situations. It is thought to be distinct from other types of intelligence, but has relations to emotional intelligence. Social intelligence has coincided with other studies that focus on how we make judgements of others, the accuracy with which we do so, and why people would be viewed as having positive or negativesocial character. There is debate as to whether or not these studies and social intelligence come from the same theories or if there is a distinction between them, and they are generally thought to be of two differentschools of thought. Moral intelligence is the capacity to understand right from wrong and to behave based on the value that is believed to be right.It is considered a distinct form of intelligence, independent to both emotional and cognitive intelligence. Concepts of \"book smarts\" and \"street smart\" are contrasting views based on the premise that some people have knowledge gained through academic study, but may lack the experience to sensibly apply that knowledge, while others have knowledge gained through practical experience, but may lack accurate information usually gained through study by which to effectively apply that knowledge.Artificial intelligenceresearcherHector Levesquehas noted that: Given the importance of learning through text in our own personal lives and in our culture, it is perhaps surprising how utterly dismissive we tend to be of it. It is sometimes derided as being merely \"book knowledge\", and having it is being \"book smart\". In contrast, knowledge acquired through direct experience and apprenticeship is called \"street knowledge\", and having it is being \"street smart\". Although humans have been the primary focus of intelligence researchers, scientists have also attempted to investigate animal intelligence, or more broadly, animal cognition. These researchers are interested in studying both mental ability in a particularspecies, and comparing abilities between species. They study various measures of problem solving, as well as numerical and verbal reasoning abilities. Some challenges include defining intelligence so it has the same meaning across species, andoperationalizinga measure that accurately compares mental ability across species and contexts. Wolfgang Köhler's research on the intelligence of apes is an example of research in this area, as is Stanley Coren's book,The Intelligence of Dogs.Non-human animals particularly noted and studied for their intelligence includechimpanzees,bonobos(notably the language-usingKanzi) and othergreat apes,dolphins,elephantsand to some extentparrots,ratsandravens. Cephalopod intelligenceprovides an important comparative study.Cephalopodsappear to exhibit characteristics of significant intelligence, yet theirnervous systemsdiffer radically from those of backboned animals. Vertebrates such asmammals,birds,reptilesandfishhave shown a fairly high degree of intellect that varies according to each species. The same is true witharthropods. Evidence of a general factor of intelligence has been observed in non-human animals. First described inhumans, thegfactor has since been identified in a number of non-human species. Cognitive ability and intelligence cannot be measured using the same, largely verbally dependent, scales developed for humans. Instead, intelligence is measured using a variety of interactive and observational tools focusing oninnovation,habitreversal,social learning, and responses tonovelty. Studies have shown thatgis responsible for 47% of the individual variance in cognitive ability measures inprimatesand between 55% and 60% of the variance inmice(Locurto, Locurto). These values are similar to the accepted variance inIQexplained bygin humans (40–50%). It has been argued that plants should also be classified as intelligent based on their ability to sense and model external and internal environments and adjust theirmorphology,physiologyandphenotypeaccordingly to ensure self-preservation and reproduction. A counter argument is that intelligence is commonly understood to involve the creation and use of persistent memories as opposed to computation that does not involve learning. If this is accepted as definitive of intelligence, then it includes the artificial intelligence of robots capable of \"machine learning\", but excludes those purely autonomic sense-reaction responses that can be observed in many plants. Plants are not limited to automated sensory-motor responses, however, they are capable of discriminating positive and negative experiences and of \"learning\" (registering memories) from their past experiences. They are also capable of communication, accurately computing their circumstances, using sophisticatedcost–benefit analysisand taking tightly controlled actions to mitigate and control the diverse environmental stressors. Scholars studying artificial intelligence have proposed definitions of intelligence that include the intelligence demonstrated by machines. Some of these definitions are meant to be general enough to encompass human and other animal intelligence as well. Anintelligent agentcan be defined as a system that perceives its environment and takes actions which maximize its chances of success.Kaplanand Haenlein define artificial intelligence as \"a system's ability to correctly interpret external data, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation\".Progress in artificial intelligencecan be demonstrated in benchmarks ranging from games to practical tasks such asprotein folding.Existing AI lags humans in terms of general intelligence, which is sometimes defined as the \"capacity to learn how to carry out a huge range of tasks\". MathematicianOlle Häggströmdefines intelligence in terms of \"optimization power\", an agent's capacity for efficient cross-domainoptimizationof the world according to the agent's preferences, or more simply the ability to \"steer the future into regions of possibility ranked high in a preference ordering\". In this optimization framework,Deep Bluehas the power to \"steer a chessboard's future into a subspace of possibility which it labels as 'winning', despite attempts byGarry Kasparovto steer the future elsewhere.\"HutterandLegg, after surveying the literature, define intelligence as \"an agent's ability to achieve goals in a wide range of environments\".While cognitive ability is sometimes measured as a one-dimensional parameter, it could also be represented as a \"hypersurfacein a multidimensional space\" to compare systems that are good at different intellectual tasks.Some skeptics believe that there is no meaningful way to define intelligence, aside from \"just pointing to ourselves\".", "metadata": {"url": "https://en.wikipedia.org/wiki/Intelligence", "title": "Intelligence", "headings": ["Contents", "Etymology", "Definitions", "Human", "Intelligence quotient (IQ)", "Emotional", "Social", "Moral", "Book smart and street smart", "Nonhuman animal", "gfactor in non-humans", "Plant", "Artificial", "See also", "References", "Further reading", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Intelligence", "https://en.wikipedia.org/wiki/Intelligence", "https://en.wikipedia.org/wiki/Intelligence", "https://en.wikipedia.org/wiki/Intellect", "https://en.wikipedia.org/wiki/Human_intelligence", "https://en.wikipedia.org/wiki/Intelligence_(disambiguation)", "https://en.wikipedia.org/wiki/Psychology", "https://en.wikipedia.org/wiki/Outline_of_psychology"]}},
{"id": "7f9186b0ac4f", "content": " Artificial intelligenceis the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making.Artificial intelligence(AI) has been used in applications throughout industry and academia. Within the field of Artificial Intelligence, there are multiple subfields. The subfield ofMachine learninghas been used for various scientific and commercial purposesincludinglanguage translation,image recognition,decision-making,credit scoring, ande-commerce. In recent years, there have been massive advancements in the field ofGenerative Artificial Intelligence, which uses generative models to produce text, images, videos or other forms of data. This article describes applications of AI in different sectors. In agriculture, AI has been proposed as a way for farmers to identify areas that need irrigation, fertilization, or pesticide treatments to increase yields, thereby improving efficiency.AI has been used to attempt toclassify livestock pig call emotions,automategreenhouses,detect diseases and pests,and optimize irrigation. Artificial intelligence in architectureis the use ofartificial intelligencein automation, design, and planning in the architectural process or in assisting human skills in the field of architecture. A 2023 study found that generative AI increased productivity by 15% in contact centers.Another 2023 study found it increased productivity by up to 40% in writing tasks.An August 2025 review by MIT found that of surveyed companies, 95% did not report any improvement in revenue from the use of AI.A September 2025 article by theHarvard Business Reviewdescribes how increased use of AI does not automatically lead to increases in revenue or actual productivity. Referring to \"AI generated work content that masquerades as good work, but lacks the substance to meaningfully advance a given task\" the article coins the termworkslop. Per studies done in collaboration with the Stanford Social Media Lab, workslop does not improve productivity and undermines trust and collaboration among colleagues. AI can be used for real-time code completion, chat, and automated test generation. These tools are typically integrated with editors andIDEsasplugins. They differ in functionality, quality, speed, and approach to privacy. Code suggestions could be incorrect, and should be carefully reviewed by software developers before accepted.GitHub Copilotis one example. It was developed byGitHubandOpenAIand is able to autocomplete code in multiple programming languages. AI can be used to create other AIs. For example, around November 2017, Google's AutoML project to evolve new neural net topologies createdNASNet, a system optimized forImageNetand POCO F1. NASNet's performance exceeded all previously published performance on ImageNet. Machine learning has been used for noise-cancelling inquantum technology,includingquantum sensors.Moreover, there is substantial research and development of using quantum computers with machine learning algorithms. For example, there is a prototype, photonic,quantummemristive deviceforneuromorphic (quantum-)computers(NC)/artificial neural networksand NC-using quantum materials with some variety of potential neuromorphic computing-related applications,andquantum machine learningis a field with some variety of applications under development. AI could be used forquantum simulatorswhich may have the application of solving physics andchemistryproblems as well as forquantum annealersfor training of neural networks for AI applications.There may also be some usefulness in chemistry, e.g. for drug discovery, and in materials science, e.g. for materials optimization/discovery (with possible relevance to quantum materials manufacturing). AI researchers have created many tools to solve the most difficult problems in computer science. Many of their inventions have been adopted by mainstream computer science and are no longer considered AI. All of the following were originally developed in AI laboratories: Another application of AI is in human resources. AI can screen resumes and rank candidates based on their qualifications, predict candidate success in given roles, and automate repetitive communication tasks via chatbots. AI underliesavatars(automated online assistants) on web pages.It can reduce operation and training costs.Pypestreamautomated customer service for its mobile application to streamline communication with customers. A Google app analyzes language and converts speech into text.The platform can identify angry customers through their language and respond appropriately.Amazon uses a chatbot for customer service that can perform tasks like checking the status of an order, cancelling orders, offering refunds and connecting the customer with a human representative.Generative AI (GenAI), such as ChatGPT, is increasingly used in business to automate tasks and enhance decision-making. In the hospitality industry, AI is used to reduce repetitive tasks, analyze trends, interact with guests, and predict customer needs.AI hotel services come in the form of a chatbot,application, virtual voice assistant and service robots. In educational institutions, AI has been used to automate routine tasks like attendance tracking, grading and marking. AI tools have been used to attempt to monitor student progress and analyze learning behaviors, with the intention of facilitating interventions for students facing academic problems. Power electronicsconverters are used inrenewable energy,energy storage,electric vehiclesandhigh-voltage direct currenttransmission.These converters are failure-prone, which can interrupt service and require costly maintenance or catastrophic consequences in mission critical applications.AI can guide the design process for reliable power electronics converters, by calculating exact design parameters that ensure the required lifetime. The U.S. Department of Energy wrote in an April 2024 report that AI may have applications in modeling power grids, reviewing federal permits withlarge language models, predicting levels of renewable energy production, and improving the planning process forelectrical vehiclecharging networks.Other studies have suggested that machine learning can be used for energy consumption prediction and scheduling, e.g. to help withrenewable energy intermittency management(see also:smart gridandclimate change mitigation in the power grid). Autonomous ships that monitor the ocean, AI-driven satellite data analysis,passive acousticsorremote sensingand other applications ofenvironmental monitoringmake use of machine learning. For example, \"Global Plastic Watch\" is an AI-basedsatellite monitoring-platform for analysis/tracking ofplastic wastesites to helppreventionofplastic pollution– primarilyocean pollution– by helping identify who and where mismanages plastic waste, dumping it into oceans. Machine learning can be used tospot early-warning signsof disasters and environmental issues, possibly including naturalpandemics,earthquakes,landslides,heavy rainfall,long-term water supply vulnerability,tipping-points ofecosystem collapse,cyanobacterial bloomoutbreaks,and droughts. AI for Goodis a platform launched in 2017 by theInternational Telecommunication Union(ITU) agency of the United Nations (UN). The goal of the platform is to use AI to help achieve the UN'sSustainable Development Goals. TheUniversity of Southern Californialaunched the Center for Artificial Intelligence in Society, with the goal of using AI to address problems such as homelessness.Stanfordresearchers useAIto analyze satellite images to identify high poverty areas. AI applications analyze media content such as movies, TV programs, advertisement videos oruser-generated content. The solutions often involvecomputer vision. Typical scenarios include the analysis of images usingobject recognitionor face recognition techniques, or theanalysis of videofor scene recognizing scenes, objects or faces. AI-based media analysis can facilitate media search, the creation of descriptive keywords for content, content policy monitoring (such as verifying the suitability of content for a particular TV viewing time),speech to textfor archival or other purposes, and the detection of logos, products or celebrity faces for ad placement. Deep-fakescan be used for comedic purposes but are better known forfake newsand hoaxes. Deepfakes can portray individuals in harmful or compromising situations, causing significant reputational damage and emotional distress, especially when the content is defamatory or violates personal ethics. While defamation and false light laws offer some recourse, their focus on false statements rather than fabricated images or videos often leaves victims with limited legal protection and a challenging burden of proof. In January 2016,theHorizon 2020program financed the InVID Projectto help journalists and researchers detect fake documents, made available as browser plugins. In June 2016, the visual computing group of theTechnical University of Munichand fromStanford Universitydeveloped Face2Face,a program that animates photographs of faces, mimicking the facial expressions of another person. The technology has been demonstrated animating the faces of people includingBarack ObamaandVladimir Putin. Other methods have been demonstrated based ondeep neural networks, from which the namedeep fakewas taken. In September 2018, U.S. SenatorMark Warnerproposed to penalizesocial mediacompanies that allow sharing of deep-fake documents on their platforms. In 2018, Darius Afchar and Vincent Nozick found a way to detect faked content by analyzing the mesoscopic properties of video frames.DARPAgave 68 million dollars to work on deep-fake detection. Audio deepfakesand AI software capable of detecting deep-fakes and cloning human voices have been developed. Respeecheris a program that enables one person to speak with the voice of another. AI algorithms have been used to detect deepfake videos. Artificial intelligenceis also starting to be used in video production, with tools and software being developed that utilize generative AI in order to create new video, or alter existing video. Some of the major tools that are being used in these processes currently are DALL-E, Mid-journey, and Runway.Way mark Studios utilized the tools offered by bothDALL-EandMid-journeyto create a fully AI generated film calledThe Frostin the summer of 2023.Way mark Studios is experimenting with using these AI tools to generate advertisements and commercials for companies in mere seconds.Yves Bergquist, a director of the AI &Neurosciencein Media Project at USC's Entertainment Technology Center, says post production crews in Hollywood are already using generative AI, and predicts that in the future more companies will embrace this new technology. AI has been used to compose music of various genres. David Copecreated an AI calledEmily Howellthat managed to become well known in the field of algorithmic computer music.The algorithm behind Emily Howell is registered as a US patent. In 2012, AIIamuscreated the first complete classical album. AIVA(Artificial Intelligence Virtual Artist), composes symphonic music, mainlyclassical musicforfilm scores.It achieved a world first by becoming the first virtual composer to be recognized by a musicalprofessional association. Melomicscreates computer-generated music for stress and pain relief. At Sony CSL Research Laboratory, the Flow Machines software creates pop songs by learning music styles from a huge database of songs. It can compose in multiple styles. The Watson Beat usesreinforcement learninganddeep belief networksto compose music on a simple seed input melody and a select style. The software was open sourcedand musicians such asTaryn Southerncollaborated with the project to create music. South Korean singer, Hayeon's, debut song, \"Eyes on You\" was composed using AI which was supervised by real composers, including NUVO. Narrative Sciencesellscomputer-generated newsand reports. It summarizes sporting events based on statistical data from the game. It also creates financial reports and real estate analyses.Automated Insightsgenerates personalized recaps and previews forYahoo SportsFantasy Football. Yseop, uses AI to turn structured data into natural language comments and recommendations.Yseopwrites financial reports, executive summaries, personalized sales or marketing documents and more in multiple languages, including English, Spanish, French, and German. TALESPIN made up stories similar to thefables of Aesop. The program started with a set of characters who wanted to achieve certain goals. The story narrated their attempts to satisfy these goals.Mark Riedl and Vadim Bulitko asserted that the essence of storytelling was experience management, or \"how to balance the need for a coherent story progression with user agency, which is often at odds\". While AI storytelling focuses on story generation (character and plot), story communication also received attention. In 2002, researchers developed an architectural framework for narrative prose generation. They faithfully reproduced text variety and complexity on stories such asLittle Red Riding Hood.In 2016, a Japanese AI co-wrote a short story and almost won a literary prize. South Korean company Hanteo Global uses a journalism bot to write articles. Literary authors are also exploring uses of AI. An example isDavid Jhave Johnston's workReRites(2017–2019), where the poet created a daily rite of editing the poetic output of a neural network to create a series of performances and publications. In 2010, artificial intelligence usedbaseballstatistics to automatically generate news articles. This was launched byThe Big Ten Networkusing software fromNarrative Science. After being unable to cover everyMinor League Baseballgame with a large team,Associated Presscollaborated withAutomated Insightsin 2016 to create game recaps that were automated by artificial intelligence. UOL in Brazil expanded the use of AI in its writing. Rather than just generating news stories, they programmed the AI to include commonly searched words onGoogle. El Pais, a Spanish news site that covers many things including sports, allows users to make comments on each news article. They use thePerspective APIto moderate these comments and if the software deems a comment to contain toxic language, the commenter must modify it in order to publish it. A local Dutch media group used AI to create automatic coverage of amateur soccer, set to cover 60,000 games in just a single season. NDC partnered with United Robots to create this algorithm and cover what would have never been possible before without an extremely large team. Lede AI has been used in 2023 to take scores fromhigh school footballgames to generate stories automatically for the local newspaper. This was met with significant criticism from readers for the very robotic diction that was published. With some descriptions of games being a \"close encounter of the athletic kind,\" readers were not pleased and let the publishing company,Gannett, know on social media. Gannett has since halted their used of Lede AI until they come up with a solution for what they call an experiment. Artificial intelligenceis used inWikimedia projectsfor the purpose of developing those projects. Various articles onWikipediahave been created entirely with or with the help ofartificial intelligence. AI-generated content can be detrimental to Wikipedia when unreliable or containing fake citations. Millions of its articles have been edited by botswhich however are usually not artificial intelligence software. Many AI platforms use Wikipedia data,mainly for training machine learning applications. There is research and development of various artificial intelligence applications for Wikipedia such as for identifying outdated sentences,detecting covert vandalismor recommending articles and tasks to new editors. Machine translation(seeabove)has also be used for translating Wikipedia articles and could play a larger role in creating, updating, expanding, and generally improving articles in the future. A content translation tool allows editors of some Wikipedias to more easily translate articles across several select languages. In video games, AI is routinely used to generate behavior innon-player characters(NPCs). In addition, AI is used forpathfinding. Some researchers consider NPC AI in games to be a \"solved problem\" for most production tasks.Games with less typical AI include the AI director ofLeft 4 Dead(2008) and the neuroevolutionary training of platoons inSupreme Commander 2(2010).AI is also used inAlien Isolation(2014) as a way to control the actions the Alien will perform next. Games have been a major applicationof AI's capabilities since the 1950s. In the 21st century, AIs have beaten human players in many games, includingchess(Deep Blue),Jeopardy!(Watson),Go(AlphaGo),poker(PluribusandCepheus),E-sports(StarCraft),andgeneral game playing(AlphaZeroandMuZero). Kuki AI is a set ofchatbotsand other apps which were designed for entertainment and as a marketing tool.Character.aiis another example of a chatbot being used for recreation. Kinect, which provides a 3D body–motion interface for theXbox 360and theXbox One, uses algorithms that emerged from AI research. The first AI art program, calledAARON, was developed byHarold Cohenin 1968with the goal of being able to code the act of drawing. It started by creating simple black and white drawings, and later to painting using special brushes and dyes that were chosen by the program itself without mediation from Cohen. AI platforms such asDALL-E,Stable Diffusion,Imagen,andMidjourneyhave been used for generating visual images from inputs such as text or other images.Some AI tools allow users to input images and output changed versions of that image, such as to display an object or product in different environments. AI image models can also attempt to replicate the specific styles of artists, and can add visual complexity to rough sketches. AI has been used to generate quantitative analysis of existing digital art collections.Two computational methods, close reading and distant viewing, are the typical approaches used to analyze digitized art.While distant viewing includes the analysis of large collections, close reading involves one piece of artwork. Pixarbegan experimenting with a machine learning project called \"Genesis\" in the early 2000s. It was designed to learn algorithms and create 3D models for its characters and props. In 2023, Netflix of Japan's usage of AI to generate background images for shortThe Dog & the Boywas met with backlash online. Financial institutionshave long usedartificial neural networksystems to detect charges or claims outside of the norm, flagging these for human investigation. The use of AI inbankingbegan in 1987 whenSecurity Pacific National Banklaunched a fraud prevention task-force to counter the unauthorized use of debit cards. Banks use AI to organize operations for bookkeeping, investing in stocks, and managing properties. AI can adapt to changes during non-business hours.AI is used to combat fraudand financial crimes by monitoring behavioral patterns for anyabnormal changes or anomalies. The use of AI in applications such as online trading and decision-making has changed major economic theories.For example, AI-based buying and selling platforms estimate personalized demand and supply curves, thus enabling individualizedpricing. AI systems reduceinformation asymmetryin the market and thusmake markets more efficient.The application of artificial intelligence in the financial industry can alleviate the financing constraints of non-state-owned enterprises, especially for smaller and more innovative enterprises. Algorithmic tradinginvolves using AI systems to make trading decisions at speeds of magnitude greater than any human is capable of, making millions of trades in a day without human intervention. Suchhigh-frequency tradingrepresents a fast-growing sector. Many banks, funds, and proprietary trading firms now have AI-managed portfolios.Automated trading systemsare typically used by large institutional investors but include smaller firms trading with their own AI systems. Large financial institutions use AI to assist with their investment practices.BlackRock's AI engine,Aladdin, is used both within the company and by clients to help with investment decisions. Its functions include the use ofnatural language processingto analyze text such as news, broker reports, and social media feeds. It then gauges the sentiment on the companies mentioned and assigns a score. Banks such asUBSandDeutsche Bankuse SQREEM (Sequential Quantum Reduction and Extraction Model) to mine data to develop consumer profiles and match them withwealth managementproducts. Online lenderUpstartuses machine learning forunderwriting. ZestFinance's Zest Automated Machine Learning (ZAML) platform is used for credit underwriting.This platform uses machine learning to analyze data, including purchase transactions and how a customer fills out a form, to score borrowers. The platform is handy for assigning credit scores to those with limited credit histories. AI makes continuous auditing possible. Potential benefits include reducing audit risk, increasing the level of assurance, and reducing audit duration. Continuous auditing with AI allows real-time monitoring and reporting of financial activities and provides businesses with timely insights that can lead to quick decision-making. AI software, such as LaundroGraph which uses contemporary suboptimal datasets, could be used foranti–money laundering(AML).Anti–money laundering In recent years, thedebt collectionindustry has begun to adopt AI-driven \"agents\" to automate routine outreach and negotiation tasks. Platforms use natural-language processing and machine learning to interact with consumers. Proponents claim these systems can handle high volumes of standard enquiries, freeing human collectors to focus on more complex cases, while delivering more consistent, 24/7 service. However, critics warn of potential compliance pitfalls, such as the risk of unintended bias in algorithmic decision-making. In the 1980s, AI started to become prominent in finance asexpert systemswere commercialized. For example, Dupont created 100 expert systems, which helped them to save almost $10 million per year.One of the first systems was the Pro-trader expert system that predicted the 87-point drop in theDow Jones Industrial Averagein 1986. \"The major junctions of the system were to monitor premiums in the market, determine the optimum investment strategy, execute transactions when appropriate and modify the knowledge base through a learning mechanism.\" One of the first expert systems to help with financial plans was PlanPowerm and Client Profiling System, created by Applied Expert Systems (APEX). It was launched in 1986. It helped create personal financial plans for people. In the 1990s, AI was applied tofraud detection. In 1993, FinCEN Artificial Intelligence System (FAIS) was launched. It was able to review over 200,000 transactions per week, and over two years, it helped identify 400 potential cases ofmoney launderingequal to $1 billion.These expert systems were later replaced by machine learning systems. Outside finance, the late 1980s and early 1990s also saw expert systems used in technical and environmental domains. For example, researchers built a fishway design advisor to recommend fish passage structures under varying hydraulic and biological conditions using the VP-Expert shell.Transportation researchers applied the same shell to balance airport capacity with noise-mitigation plans.In agriculture, a potato insect expert system (PIES) supported pest management decisions for Colorado potato beetle.The U.S. Environmental Protection Agency’s CORMIX system for modeling pollutant discharges combined rules with Fortran hydrodynamic models. AI can enhance entrepreneurial activity, and AI is one of the most dynamic areas for start-ups, with significant venture capital flowing into AI. In theEuropean Union, theArtificial Intelligence Act(Regulation (EU) 2024/1689) classifies several finance‑sector uses of AI as \"high‑risk\", including systems used to evaluate the creditworthiness of natural persons or to establish a credit score and AI used for risk assessment and pricing in life or health insurance.These systems must meet requirements on risk management, data governance, technical documentation and logging, transparency, and human oversight.The Act's obligations are phased in: prohibitions and AI‑literacy rules apply from 2 February 2025, governance and most GPAI duties from 2 August 2025, the bulk of obligations from 2 August 2026, and certain safety‑component high‑risk obligations from 2 August 2027. AI in healthcare is often used for classification, to evaluate aCT scanorelectrocardiogramor to identify high-risk patients for population health. AI is helping with the high-cost problem of dosing. One study suggested that AI could save $16 billion. In 2016, a study reported that an AI-derived formula derived the proper dose of immunosuppressant drugs to give to transplant patients.Current research has indicated that non-cardiac vascular illnesses are also being treated with artificial intelligence (AI). For certain disorders, AI algorithms can aid in diagnosis, recommended treatments, outcome prediction, and patient progress tracking. As AI technology advances, it is anticipated that it will become more significant in the healthcare industry. The early detection of diseases like cancer is made possible by AI algorithms, which diagnose diseases by analyzing complex sets of medical data. For example, the IBM Watson system might be used to comb through massive data such as medical records and clinical trials to help diagnose a problem.Microsoft's AI project Hanover helps doctors choosecancer treatmentsfrom among the more than 800 medicines and vaccines.Its goal is to memorize all the relevant papers to predict which (combinations of) drugs will be most effective for each patient.Myeloid leukemiais one target. Another study reported on an AI that was as good as doctors in identifying skin cancers.Another project monitors multiple high-risk patients by asking each patient questions based on data acquired from doctor/patient interactions.In one study done withtransfer learning, an AI diagnosed eye conditions similar to anophthalmologistand recommended treatment referrals. Another study demonstrated surgery with an autonomous robot. The team supervised the robot while it performed soft-tissue surgery, stitching together a pig's bowel judged better than a surgeon. Artificial neural networksare used asclinical decision support systemsfor medical diagnosis,such as inconcept processingtechnology inEMRsoftware. Other healthcare tasks thought suitable for an AI that are in development include: AI-enabledchatbotsdecrease the need for humans to perform basic call center tasks, and machine learning insentiment analysiscan spot fatigue in order to preventoverwork. Decision support systemscan potentially preventindustrial disastersand makedisaster responsemore efficient.For manual workers inmaterial handling,predictive analyticshas been proposed to reducemusculoskeletal injury. AI can attempt to processworkers' compensationclaims.AI has been proposed for detection of accidentnear misses, which are underreported. Machine learning has been used fordrug design,drug discoveryand development,drug repurposing, improving pharmaceutical productivity, and clinical trials. Computer-planned syntheses via computational reaction networks, described as a platform that combines \"computational synthesis with AI algorithms to predict molecular properties\",has been used in drug-syntheses, and developing routes forrecycling200 industrialwaste chemicalsinto important drugs and agrochemicals (chemical synthesis design).It has also been used to explore theorigins of life on Earth. Deep learning has been used with databases for the development of a 46-day process to design, synthesize and test a drug which inhibits enzymes of a particular gene,DDR1. DDR1 is involved in cancers and fibrosis which is one reason for the high-quality datasets that enabled these results. The AI programAlphaFold 2can determine the 3D structure of a (folded) protein in hours rather than the months required by earlier automated approaches and was used to provide the likely structures of all proteins in the human body and essentially all proteins known to science (more than 200 million). Speech translation technology attempts to convert one language's spoken words into another language. This potentially reduces language barriers in global commerce and cross-cultural exchange, enabling speakers of various languages to communicate with one another. AI has been used to automatically translate spoken language and textual content in products such asMicrosoft Translator,Google Translate, andDeepL Translator.Additionally, research and development are in progress to decode and conduct animal communication. Meaning is conveyed not only by text, but also through usage and context (seesemanticsandpragmatics). As a result, the two primary categorization approaches for machine translations arestatistical machine translation(SMT) andneural machine translations(NMTs). The old method of performing translation was to use statistical methodology to forecast the best probable output with specific algorithms. However, with NMT, the approach employs dynamic algorithms to achieve better translations based on context. AIfacial recognition systemsare used formass surveillance, notably in China.In 2019,Bengaluru, Indiadeployed AI-managed traffic signals. This system uses cameras to monitor traffic density and adjust signal timing based on the interval needed to clear traffic. AI is a mainstay of law-related professions. Algorithms and machine learning do some tasks previously done by entry-level lawyers.While its use is common, it is not expected to replace most work done by lawyers in the near future. Theelectronic discoveryindustry uses machine learning to reduce manual searching. Law enforcement has begun usingfacial recognition systems(FRS) to identify suspects from visual data. FRS results have proven to be more accurate when compared to eyewitness results. Furthermore, FRS has shown to have much a better ability to identify individuals when video clarity and visibility are low in comparison to human participants. COMPASis a commercial system used byU.S. courtsto assess the likelihood ofrecidivism. One concern relates toalgorithmic bias, AI programs may become biased after processing data that exhibits bias.ProPublicaclaims that the average COMPAS-assigned recidivism risk level of black defendants is significantly higher than that of white defendants. In 2019, the city ofHangzhou, China established a pilot program artificial intelligence-based Internet Court to adjudicate disputes related to ecommerce and internet-relatedintellectual propertyclaims.Parties appear before the court via videoconference and AI evaluates the evidence presented and applies relevant legal standards. Artificial intelligence has been combined with digitalspectrometryby IdeaCuria Inc.,enable applications such as at-home water quality monitoring. In the 1990s, early artificial intelligence tools controlledTamagotchisandGiga Pets, theInternet, and the first widely released robot,Furby.Aibowas adomestic robotin the form of a robotic dog with intelligent features andautonomy. Mattel created an assortment of AI-enabled toys that \"understand\" conversations, give intelligent responses, and learn. Oil and gascompanies have used artificial intelligence tools to automate functions, foresee equipment issues, and increase oil and gas output. Various countries are deploying AI military applications.The main applications enhancecommand and control, communications, sensors, integration and interoperability.Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous andautonomous vehicles.AI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions,target acquisition, coordination and deconfliction of distributedJoint Firesbetween networked combat vehicles involving manned and unmanned teams. AI has been used in military operations in Iraq, Syria, Israel and Ukraine. Machine learning has been used forrecommendation systemsin determining which posts should show up insocial media feeds.Various types ofsocial media analysisalso make use of machine learningand there is research into its use for (semi-)automated tagging/enhancement/correction ofonline misinformationand relatedfilter bubbles. AI has been used to customize shopping options and personalize offers.Online gamblingcompanies have used AI for targeting gamblers. Intelligent personal assistantsuse AI to attempt to respond to natural language requests.Siri, released in 2010 for Apple smartphones, popularized the concept. Bing Chathas used artificial intelligence as part of itssearch engine. Machine learning can be used to combat spam, scams, andphishing. It can scrutinize the contents of spam and phishing attacks to attempt to identify malicious elements.Some models built via machine learning algorithms have over 90% accuracy in distinguishing between spam and legitimate emails.These models can be refined using new data and evolving spam tactics. Machine learning also analyzes traits such as sender behavior, email header information, and attachment types, potentially enhancing spam detection. AI has been used infacial recognition systems. Some examples are Apple'sFace IDand Android'sFace Unlock, which are used to secure mobile devices. China has used facial recognition andartificial intelligencetechnology inXinjiang. In 2017, reporters visiting the region found surveillance cameras installed every hundred meters or so in several cities, as well as facial recognition checkpoints at areas like gas stations, shopping centers, and mosque entrances.Human rights groups have criticized the Chinese government for using artificial intelligence facial recognition technology for use in political suppression. TheNetherlandshas deployed facial recognition and artificial intelligence technology since 2016.The database of the Dutch police currently contains over 2.2 million pictures of 1.3 million Dutch citizens. This accounts for about 8% of the population. In The Netherlands, face recognition is not used by the police on municipal CCTV. Image labeling has been used byGoogle Image Labelerto detect products in photos and to allow people to search based on a photo. Image labeling has also been demonstrated to generate speech to describe images to blind people.Facebook'sDeepFaceidentifies human faces in digital images. In April 2024, theScientific Advice Mechanismto theEuropean Commissionpublished adviceincluding a comprehensive evidence review of the opportunities and challenges posed by artificial intelligence in scientific research. As benefits, the evidence reviewhighlighted: As challenges: Machine learning can help to restore and attribute ancient texts.It can help to index texts for example to enable better and easier searching and classification of fragments. Artificial intelligence can also be used to investigate genomes to uncovergenetic history, such asinterbreeding between archaic and modern humansby which for example the past existence of aghost population, notNeanderthalorDenisovan, was inferred. It can also be used for \"non-invasive and non-destructive access to internal structures of archaeological remains\". Adeep learningsystem was reported to learn intuitive physics from visual data (of virtual 3D environments) based on anunpublishedapproach inspired by studies of visual cognition in infants.Other researchers have developed a machine learning algorithm that could discover sets of basic variables of various physical systems and predict the systems' future dynamics from video recordings of their behavior.In the future, it may be possible that such can be used to automate the discovery of physical laws of complex systems. In November 2023, researchers atGoogle DeepMindandLawrence Berkeley National Laboratoryannounced that the AI system GNoME had documented over 2 million new materials. GNoME uses deep learning techniques to examine potential material structures, and identify stable inorganiccrystal structures. The system's predictions were validated through autonomous robotic experiments, with a success rate of 71%. The data of newly discovered materials is publicly available through theMaterials Projectdatabase. Machine learning is used in diverse types ofreverse engineering. For example, machine learning has been used to reverse engineer a composite material part, enabling unauthorized production of high quality parts,and for quickly understanding the behavior ofmalware.It can be used to reverse engineer artificial intelligence models.It can also design components by engaging in a type of reverse engineering of not-yet existent virtual components such as inverse molecular design for particular desired functionalityorprotein designfor pre-specifiedfunctional sites.Biological network reverse engineering could model interactions in a human understandable way, e.g. bas on time series data of gene expression levels. Artificial intelligence is used inastronomyto analyze increasing amounts of available dataand applications, mainly for \"classification, regression, clustering, forecasting, generation, discovery, and the development of new scientific insights\" for example for discoveringexoplanets, forecasting solar activity, and distinguishing between signals and instrumental effects ingravitational wave astronomy.It could also be used for activities in space such asspace exploration, including analysis of data from space missions, real-time science decisions of spacecraft, space debris avoidance,and more autonomous operation. In thesearch for extraterrestrial intelligence(SETI), machine learning has been used in attempts to identify artificially generatedelectromagnetic wavesin available data– such as real-time observations– and othertechnosignatures, e.g. viaanomaly detection.Inufology, the SkyCAM-5 project headed by Prof. Hakan Kayaland theGalileo Projectheaded byAvi Loebuse machine learning to attempt to detect and classify types of UFOs.The Galileo Project also seeks to detect two further types of potential extraterrestrial technological signatures with the use of AI:'Oumuamua-likeinterstellar objects, and non-manmade artificial satellites. Machine learning can also be used to produce datasets of spectral signatures of molecules that may be involved in the atmospheric production or consumption of particular chemicals – such asphosphine possibly detected on Venus– which could prevent miss assignments and, if accuracy is improved, be used in future detections and identifications of molecules on other planets. There is research about which types of computer-aided chemistry would benefit from machine learning.A deep learning AI-based process has been developed that usesgenome databasestodesign novel proteinsbased onevolutionary algorithms.Machine learning has also been used for protein design with pre-specifiedfunctional sites,predicting molecular properties, and exploring large chemical/reaction spaces. Usingdrug discoveryAI algorithms, researchers generated 40,000 potential chemical weapon candidates, helping in theregulation of such chemicalsto prevent synthesizing them for real harm. There are various types of applications for machine learning in decoding human biology, such as helping to mapgene expressionpatterns to functional activation patternsor identifying functionalDNA motifs.It is widely used in genetic research.There also is some use of machine learning insynthetic biology,disease biology,nanotechnology (e.g. nanostructured materials andbionanotechnology),andmaterials science. Cyber securitycompanies are adoptingneural networks,machine learning, andnatural language processingto improve their systems. Applications of AI in cyber security include: Transportation's complexity means that in most cases, training an AI in a real-world driving environment is impractical, and is achieved through simulator-based testing.AI-based systems control functions such as braking, lane changing, collision prevention, navigation and mapping.AI-basedfuzzy logiccontrollers operategearboxes. AI-baseddriver-assist systemsinclude features such asself-parkingandadaptive cruise control. Some autonomous vehicles do not allow human drivers (they have no steering wheels or pedals). There are prototypes of autonomous automotive public transport vehicles such asautonomous rail transportinoperation,electric mini-buses,and autonomous delivery vehicles,includingdelivery robots. Autonomous trucks are in the testing phase. The UK government passed legislation to begin testing of autonomous truck platoons in 2018.A group of autonomous trucks follow closely behind each other. German corporationDaimleris testing itsFreightliner Inspiration. AI has been used to optimize traffic management, which can reduce wait times, energy use, and emissions. Aircraft simulators use AI for training aviators. Flight conditions can be simulated that allow pilots to make mistakes without risking themselves or expensive aircraft. Air combat can also be simulated. AI can also be used to operate planes analogously to their control of ground vehicles. Autonomous drones can fly independently or inswarms. AOD uses the Interactive Fault Diagnosis and Isolation System, or IFDIS, which is a rule-based expert system using information fromTF-30documents and expert advice from mechanics that work on the TF-30. This system was designed to be used for the development of the TF-30 for theF-111C. The system replaced specialized workers. The system allowed regular workers to communicate with the system and avoid mistakes, miscalculations, or having to speak to one of the specialized workers. Speech recognitionallows traffic controllers to give verbal directions to drones. Artificial intelligence supported design of aircraft,or AIDA, is used to help designers in the process of creating conceptual designs of aircraft. This program allows the designers to focus more on the design itself and less on the design process. The software also allows the user to focus less on the software tools. The AIDA uses rule-based systems to compute its data. This is a diagram of the arrangement of the AIDA modules. Although simple, the program is proving effective. In 2003 aDryden Flight Research Centerproject created software that could enable a damaged aircraft to continue flight until a safe landing can be achieved.The software compensated for damaged components by relying on the remaining undamaged components. The 2016 Intelligent Autopilot System combinedapprenticeship learningand behavioral cloning whereby the autopilot observed low-level actions required to maneuver the airplane and high-level strategy used to apply those actions. Neural networksare used bysituational awarenesssystems in ships and boats.There also areautonomous boats.", "metadata": {"url": "https://en.wikipedia.org/wiki/Applications_of_AI", "title": "Applications of artificial intelligence", "headings": ["Contents", "Agriculture", "Architecture and design", "Business", "Computer science", "Programming assistance", "Historical contributions", "Customer service", "Human resources", "Online and telephone customer service", "Hospitality", "Education", "Energy and environment", "Energy system", "Environmental monitoring", "Early-warning systems", "Economic and social challenges", "Entertainment and media", "Media", "Deep-fakes", "Video surveillance analysis and manipulated media detection", "Video production", "Music", "Writing and reporting", "Wikipedia", "Video games", "Visual images", "Computer animation", "Finance", "Trading and investment", "Underwriting", "Audit", "Anti–money laundering", "Collections and Account Receivables", "History", "Regulatory developments in the EU", "Health", "Healthcare", "Workplace health and safety", "Biochemistry", "Language processing", "Language translation", "Law and government", "Government", "Law", "Manufacturing", "Sensors", "Toys and games", "Oil and gas", "Military", "Internet and e-commerce", "Web feeds and posts", "Virtual assistants and search", "Spam filtering", "Facial recognition and image labeling", "Scientific research", "Evidence of general impacts", "Archaeology, history and imaging of sites", "Physics", "Materials science", "Reverse engineering", "Astronomy, space activities and ufology", "Chemistry and biology", "Security and surveillance", "Cyber security", "Transportation and logistics", "Automotive and public transit", "Military", "NASA", "Maritime", "See also", "Footnotes", "Further reading"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Applications_of_artificial_intelligence", "https://en.wikipedia.org/wiki/Applications_of_artificial_intelligence", "https://en.wikipedia.org/wiki/Applications_of_artificial_intelligence", "https://en.wikipedia.org/wiki/Artificial_intelligence", "https://en.wikipedia.org/wiki/Artificial_general_intelligence", "https://en.wikipedia.org/wiki/Intelligent_agent", "https://en.wikipedia.org/wiki/Recursive_self-improvement", "https://en.wikipedia.org/wiki/Automated_planning_and_scheduling"]}},
{"id": "cfffd3cba595", "content": "Machine perceptionis the capability of a computer system to interpretdatain a manner that is similar to the wayhumansuse theirsensesto relate to the world around them.The basic method that thecomputerstake in and respond to theirenvironmentis through the attachedhardware.  Until recentlyinputwas limited to a keyboard, or a mouse, but advances in technology, both in hardware andsoftware, have allowed computers to take insensoryinput in a way similar to humans. Machineperceptionallows the computer to use this sensory input, as well as conventionalcomputationalmeans of gatheringinformation, to gather information with greater accuracy and to present it in a way that is more comfortable for theuser.These includecomputer vision,machine hearing, machine touch, andmachine smelling, as artificialscentsare, at achemical compound,molecular,atomiclevel, indiscernible andidentical. The end goal of machine perception is to give machines the ability tosee,feelandperceivethe world as humans do and therefore for them to be able toexplainin a human way why they are making their decisions, to warn us when it is failing and more importantly, the reason why it is failing.Thispurposeis very similar to the proposed purposes forartificial intelligencegenerally, except that machine perception would only grant machines limitedsentience, rather than bestow upon machines fullconsciousness,self-awareness, andintentionality. Computer visionis a field that includes methods for acquiring, processing, analyzing, and understanding images and high-dimensional data from the real world to produce numerical or symbolic information, e.g., in the forms of decisions.  Computer vision has many applications already in use today such asfacial recognition, geographical modeling, and even aesthetic judgment. However, machines still struggle to interpret visual impute accurately if it is blurry or if theviewpointat which stimuli are viewed varies often. Computers also struggle to determine the proper nature of some stimulus if overlapped by or seamlessly touching another stimulus. This refers to thePrinciple of Good Continuation. Machines also struggle to perceive and record stimulus functioning according to the Apparent Movement principle which is a field of research inGestalt psychology. Machine hearing, also known as machine listening orcomputer auditionis the ability of a computer or machine to take in and process sound data such as speech or music.This area has a wide range of application including music recording and compression, speech synthesis andspeech recognition.Moreover, this technology allows the machine to replicate the human brain's ability to selectively focus on a specific sound against many other competing sounds and background noise. This ability is called \"auditory scene analysis\". The technology enables the machine to segment several streams occurring at the same time.Many commonly used devices such as a smartphones, voice translators and cars make use of some form of machine hearing. Present technology still has challenges inspeech segmentation. This  means it is occasionally unable to correctly split words within sentences especially when spoken in an atypical accent. Machine touch is an area of machine perception where tactile information is processed by a machine or computer.  Applications includetactile perceptionof surface properties anddexteritywhereby tactile information can enable intelligent reflexes and interaction with the environment.Though this could possibly be done through measuring when and where friction occurs and also the nature and intensity of the friction, machines however still do not have any way of measuring few ordinary physical human experiences including physical pain. For example, scientists have yet to invent a mechanical substitute for theNociceptorsin the body and brain that are responsible for noticing and measuring physical human discomfort and suffering. Scientists are developing computers known asmachine olfactionwhich can recognize and measuresmellsas well. Airbornechemicalsare sensed and classified with a device sometimes known as anelectronic nose. Theelectronic tongueis an instrument that measures and comparestastes. As per the IUPAC technical report, an “electronic tongue” as analytical instrument including an array of non-selective chemical sensors with partial specificity to different solution components and an appropriate pattern recognition instrument, capable to recognize quantitative and qualitative compositions of simple and complex solutions Chemical compoundsresponsible for taste are detected by humantaste receptors. Similarly, the multi-electrode sensors of electronic instruments detect the same dissolvedorganicandinorganic compounds. Like human receptors, each sensor has a spectrum of reactions different from the other. The information given by each sensor is complementary, and the combination of all sensors' results generates a unique fingerprint. Most of thedetection thresholdsof sensors are similar to or better than human receptors. In the biological mechanism, taste signals are transduced by nerves in the brain into electric signals. E-tongue sensors process is similar: they generate electric signals asvoltammetricandpotentiometricvariations. Other than those listed above, some of the future hurdles that the science of machine perception still has to overcome include, but are not limited to: -Embodied cognition- The theory that cognition is a full body experience, and therefore can only exist, and therefore be measure and analyzed, in fullness if all required human abilities and processes are working together through a mutually aware and supportive systems network. - TheMoravec's paradox(see the link) - ThePrinciple of similarity- The ability young children develop to determine what family a newly introduced stimulus falls under even when the said stimulus is different from the members with which the child usually associates said family with. (An example could be a child figuring that a chihuahua is a dog and house pet rather than vermin.) - TheUnconscious inference: The natural human behavior of determining if a new stimulus is dangerous or not, what it is, and then how to relate to it without ever requiring any new conscious effort. - The innate human ability to follow thelikelihood principlein order to learn from circumstances and others over time. - Therecognition-by-components theory- being able to mentally analyze and break even complicated mechanisms into manageable parts with which to interact with. For example: A person seeing both the cup and the handle parts that make up a mug full of hot cocoa, in order to use the handle to hold the mug so as to avoid being burned. - Thefree energy principle- determining long before hand how much energy one can safely delegate to being aware of things outside one's self without the loss of the needed energy one requires for sustaining their life and function satisfactorily. This allows one to become both optimally aware of the world around them self without depleting their energy so much that they experience damaging stress, decision fatigue, and/or exhaustion.", "metadata": {"url": "https://en.wikipedia.org/wiki/Machine_perception", "title": "Machine perception", "headings": ["Contents", "Machine vision", "Machine hearing", "Machine touch", "Machine olfaction", "Machine taste", "Future", "See also", "References"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Machine_perception", "https://en.wikipedia.org/wiki/Machine_perception", "https://en.wikipedia.org/wiki/Machine_perception", "https://en.wikipedia.org/wiki/Data", "https://en.wikipedia.org/wiki/Human", "https://en.wikipedia.org/wiki/Sense", "https://en.wikipedia.org/wiki/Computer", "https://en.wikipedia.org/wiki/Environment_(systems)"]}},
{"id": "ce5b1d6b0b75", "content": " Softwareconsists ofcomputer programsthat instruct theexecutionof acomputer.Software also includes design documents and specifications. The history of software is closely tied to the development of digital computers in the mid-20th century. Early programs were written in themachine languagespecific to the hardware. The introduction ofhigh-level programming languagesin 1958 allowed for more human-readable instructions, makingsoftware developmenteasier and more portable across differentcomputer architectures. Software in a programming language is run through acompilerorinterpretertoexecuteon the architecture's hardware. Over time, software has become complex, owing to developments innetworking,operating systems, anddatabases. Software can generally be categorized into two main types: The rise ofcloud computinghas introduced the new software delivery modelSoftware as a Service(SaaS). In SaaS, applications are hosted by aproviderandaccessedover theInternet. The process of developing software involves several stages. The stages includesoftware design,programming,testing,release, andmaintenance.Software quality assuranceandsecurityare critical aspects of software development, asbugsandsecurity vulnerabilitiescan lead to system failures and security breaches. Additionally, legal issues such as software licenses and intellectual property rights play a significant role in the distribution of software products. The first use of the wordsoftwareto describe computer programs is credited to mathematicianJohn Wilder Tukeyin 1958.The first programmable computers, which appeared at the end of the 1940s,were programmed inmachine language. Machine language is difficult to debug and notportableacross different computers.Initially, hardware resources were more expensive thanhuman resources.As programs became complex,programmer productivitybecame the bottleneck. The introduction ofhigh-level programming languagesin 1958hidthe details of the hardware and expressed the underlyingalgorithmsinto the code .Early languages includeFortran,Lisp, andCOBOL. There are two main types of software: Software can also be categorized by how it isdeployed. Traditional applications are purchased with a perpetuallicensefor a specific version of the software, downloaded, and run on hardware belonging to the purchaser.The rise ofthe Internetandcloud computingenabled a new model,software as a service(SaaS),in which the provider hosts the software (usually built on top of rentedinfrastructureorplatforms)and provides the use of the software to customers, often in exchange for asubscription fee.By 2023, SaaS products—which are usually delivered via aweb application—had become the primary method that companies deliver applications. Software companies aim to deliver a high-quality product on time and under budget. A challenge is thatsoftware development effort estimationis often inaccurate.Software developmentbegins by conceiving the project, evaluating its feasibility, analyzing the business requirements, and making asoftware design.Most software projects speed up their development byreusingor incorporating existing software, either in the form ofcommercial off-the-shelf(COTS) oropen-source software.Software quality assuranceis typically a combination of manualcode reviewby other engineersand automatedsoftware testing. Due to time constraints, testing cannot cover all aspects of the software's intended functionality, so developers often focus on the most critical functionality.Formal methodsare used in some safety-critical systems to prove the correctness of code,whileuser acceptance testinghelps to ensure that the product meets customer expectations.There are a variety ofsoftware development methodologies, which vary from completing all steps in order to concurrent and iterative models.Software development is driven byrequirementstaken from prospective users, as opposed to maintenance, which is driven by events such as a change request. Frequently, software isreleasedin an incomplete state when the development team runs out of time or funding.Despitetestingandquality assurance, virtually all software containsbugswhere the system does not work as intended. Post-releasesoftware maintenanceis necessary to remediate these bugs when they are found and keep the software working as the environment changes over time.New features are often added after the release. Over time, the level of maintenance becomes increasingly restricted before being cut off entirely when the product is withdrawn from the market.As softwareages, it becomes known aslegacy softwareand can remain in use for decades, even if there is no one left who knows how to fix it.Over the lifetime of the product, software maintenance is estimated to comprise 75 percent or more of the total development cost. Completing a software project involves various forms of expertise, not just insoftware programmersbut also testing, documentation writing,project management,graphic design,user experience, user support,marketing, and fundraising. Software qualityis defined as meeting the stated requirements as well as customer expectations.Quality is an overarching term that can refer to a code's correct and efficient behavior, its reusability andportability, or the ease of modification.It is usually more cost-effective to build quality into the product from the beginning rather than try to add it later in the development process.Higher quality code will reduce lifetime cost to both suppliers and customers as it is more reliable andeasier to maintain.Software failures insafety-critical systemscan be very serious including death.By some estimates, the cost of poor quality software can be as high as 20 to 40 percent of sales.Despite developers' goal of delivering a product that works entirely as intended, virtually all software contains bugs. The rise of the Internet also greatly increased the need forcomputer securityas it enabled malicious actors to conductcyberattacksremotely.If a bug creates a security risk, it is called avulnerability.Software patchesare often released to fix identified vulnerabilities, but those that remain unknown (zero days) as well as those that have not been patched are still liable for exploitation.Vulnerabilities vary in their ability to beexploitedby malicious actors,and the actual risk is dependent on the nature of the vulnerability as well as the value of the surrounding system.Although some vulnerabilities can only be used fordenial of serviceattacks that compromise a system's availability, others allow the attacker toinjectand run their own code (calledmalware), without the user being aware of it.To thwart cyberattacks, all software in the system must be designed to withstand and recover from external attack.Despite efforts to ensure security, a significant fraction of computers are infected with malware. Programming languages are the format in which software is written. Since the 1950s, thousands of different programming languages have been invented; some have been in use for decades, while others have fallen into disuse.Some definitions classifymachine code—the exact instructions directly implemented by the hardware—andassembly language—a more human-readable alternative to machine code whose statements can be translated one-to-one into machine code—as programming languages.Programs written in thehigh-level programming languagesused to create software share a few main characteristics: knowledge of machine code is not necessary to write them, they can beportedto other computer systems, and they are more concise and human-readable than machine code.They must be both human-readable and capable of being translated into unambiguous instructions for computer hardware. The invention of high-level programming languages was simultaneous with thecompilersneeded to translate them automatically into machine code.Most programs do not contain all the resources needed to run them and rely on externallibraries. Part of the compiler's function is to link these files in such a way that the program can be executed by the hardware. Once compiled, the program can be saved as anobject fileand theloader(part of the operating system) can take this saved file andexecuteit as aprocesson the computer hardware.Some programming languages use aninterpreterinstead of a compiler. An interpreter converts the program into machine code atrun time, which makes them 10 to 100 times slower than compiled programming languages. Software is often released with the knowledge that it is incomplete or contains bugs.Purchasers knowingly buy it in this state,which has led to a legal regime whereliabilityfor software products is significantly curtailed compared to other products. Since the mid-1970s, software and its source code have been protected bycopyright lawthat vests the owner with the exclusive right to copy the code. The underlying ideas or algorithms are not protected by copyright law, but are sometimes treated as atrade secretand concealed by such methods asnon-disclosure agreements.Asoftware copyrightis often owned by the person or company that financed or made the software (depending on their contracts with employees orcontractorswho helped to write it).Some software is in thepublic domainand has no restrictions on who can use it, copy or share it, or modify it; a notable example is software written by theUnited States Government.Free and open-source softwarealso allow free use, sharing, and modification, perhaps with a few specified conditions.The use of some software is governed by an agreement (software license) written by the copyright holder and imposed on the user.Proprietary softwareis usually sold under a restrictive license that limits its use and sharing.Some free software licenses require that modified versions must be released under the same license, which prevents the software from being sold\nor distributed under proprietary restrictions. Patentsgive an inventor an exclusive, time-limited license for a novel product or process.Ideas about what software could accomplish are not protected by law and concrete implementations are instead covered bycopyright law. In some countries, a requirement for the claimed invention to have an effect on the physical world may also be part of the requirements for a software patent to be held valid.Software patentshave beenhistorically controversial. Before the 1998 caseState Street Bank & Trust Co. v. Signature Financial Group, Inc., software patents were generally not recognized in the United States. In that case, theSupreme Courtdecided that business processes could be patented.Patent applications are complex and costly, and lawsuits involving patents can drive up the cost of products.Unlike copyrights, patents generally only apply in the jurisdiction where they were issued. EngineerCapers Joneswrites that \"computers and software are making profound changes to every aspect of human life: education, work, warfare, entertainment, medicine, law, and everything else\".It has become ubiquitous ineveryday lifeindeveloped countries.In many cases, software augments the functionality of existing technologies such as householdappliancesandelevators.Software also spawned entirely new technologies such asthe Internet,video games,mobile phones, andGPS.New methods of communication, includingemail,forums,blogs,microblogging,wikis, andsocial media, were enabled by the Internet.Massive amounts of knowledge exceeding any paper-based library are now available with a quickweb search.Most creative professionals have switched to software-based tools such ascomputer-aided design,3D modeling, digitalimage editing, andcomputer animation.Almost every complex device is controlled by software.", "metadata": {"url": "https://en.wikipedia.org/wiki/Software", "title": "Software", "headings": ["Contents", "History", "Types", "Software development and maintenance", "Quality and security", "Encoding and execution", "Programming languages", "Compilation,  interpretation, and execution", "Legal issues", "Liability", "Licenses", "Patents", "Impact", "References", "Sources"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Software", "https://en.wikipedia.org/wiki/Software", "https://en.wikipedia.org/wiki/Software", "https://en.wikipedia.org/wiki/Software_(disambiguation)", "https://en.wikipedia.org/wiki/JavaScript", "https://en.wikipedia.org/wiki/Computer_program", "https://en.wikipedia.org/wiki/Execution_(computing)", "https://en.wikipedia.org/wiki/Computer"]}},
{"id": "eadd1655e27d", "content": " Computer scienceis the study ofcomputation,information, andautomation.Computer science spanstheoretical disciplines(such asalgorithms,theory of computation, andinformation theory) toapplied disciplines(including the design and implementation ofhardwareandsoftware). Algorithms anddata structuresare central to computer science.The theory of computation concerns abstractmodels of computationand general classes ofproblemsthat can be solved using them. The fields ofcryptographyandcomputer securityinvolve studying the means for secure communication and preventingsecurity vulnerabilities.Computer graphicsandcomputational geometryaddress the generation of images.Programming language theoryconsiders different ways to describe computational processes, anddatabasetheory concerns the management of repositories of data.Human–computer interactioninvestigates the interfaces through which humans and computers interact, and software engineering focuses on the design and principles behind developing software. Areas such asoperating systems,networksandembedded systemsinvestigate the principles and design behindcomplex systems. Computer architecture describes the construction of computer components and computer-operated equipment.Artificial intelligenceandmachine learningaim to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation,planningand learning found in humans and animals. Within artificial intelligence,computer visionaims to understand and process image and video data, whilenatural language processingaims to understand and process textual and linguistic data. The fundamental concern of computer science is determining what can and cannot be automated.TheTuring Awardis generally recognized as the highest distinction in computer science. The earliest foundations of what would become computer science predate the invention of the moderndigital computer. Machines for calculating fixed numerical tasks such as theabacushave existed since antiquity, aiding in computations such as multiplication and division.Algorithmsfor performing computations have existed since antiquity, even before the development of sophisticated computing equipment. Wilhelm Schickarddesigned and constructed the first workingmechanical calculatorin 1623.In 1673,Gottfried Leibnizdemonstrated a digital mechanical calculator, called theStepped Reckoner.Leibniz may be considered the firstcomputer scientistand information theorist, because of various reasons, including the fact that he documented the binary number system. In 1820,Thomas de Colmarlaunched the mechanical calculator industrywhen he invented his simplifiedarithmometer, the first calculating machine strong enough and reliable enough to be used daily in an office environment.Charles Babbagestarted the design of the firstautomatic mechanical calculator, hisDifference Engine, in 1822, which eventually gave him the idea of the firstprogrammable mechanical calculator, hisAnalytical Engine.He started developing this machine in 1834, and \"in less than two years, he had sketched out many of thesalientfeatures of the modern computer\".\"A crucial step was the adoption of a punched card system derived from theJacquard loom\"making it infinitely programmable.In 1843, during the translation of a French article on the Analytical Engine,Ada Lovelacewrote, in one of the many notes she included, an algorithm to compute theBernoulli numbers, which is considered to be the first published algorithm ever specifically tailored for implementation on a computer.Around 1885,Herman Hollerithinvented thetabulator, which usedpunched cardsto process statistical information; eventually his company became part ofIBM. Following Babbage, although unaware of his earlier work,Percy Ludgatein 1909 publishedthe 2nd of the only two designs for mechanical analytical engines in history. In 1914, the Spanish engineerLeonardo Torres Quevedopublished hisEssays on Automatics,and designed, inspired by Babbage, a theoretical electromechanical calculating machine which was to be controlled by a read-only program. The paper also introduced the idea offloating-point arithmetic.In 1920, to celebrate the 100th anniversary of the invention of the arithmometer, Torres presented in Paris theElectromechanical Arithmometer, a prototype that demonstrated the feasibility of an electromechanical analytical engine,on which commands could be typed and the results printed automatically.In 1937, one hundred years after Babbage's impossible dream,Howard Aikenconvinced IBM, which was making all kinds of punched card equipment and was also in the calculator businessto develop his giant programmable calculator, theASCC/Harvard Mark I, based on Babbage's Analytical Engine, which itself used cards and a central computing unit. When the machine was finished, some hailed it as \"Babbage's dream come true\". During the 1940s, with the development of new and more powerfulcomputingmachines such as theAtanasoff–Berry computerandENIAC, the termcomputercame to refer to the machines rather than their human predecessors.As it became clear that computers could be used for more than just mathematical calculations, the field of computer science broadened to studycomputationin general. In 1945, IBM founded theWatson Scientific Computing LaboratoryatColumbia UniversityinNew York City. The renovated fraternity house on Manhattan's West Side was IBM's first laboratory devoted to pure science. The lab is the forerunner of IBM's Research Division, which today operates research facilities around the world.Ultimately, the close relationship between IBM and Columbia University was instrumental in the emergence of a new scientific discipline, with Columbia offering one of the first academic-credit courses in computer science in 1946.Computer science began to be established as a distinct academic discipline in the 1950s and early 1960s.The world's first computer science degree program, theCambridge Diploma in Computer Science, began at theUniversity of Cambridge Computer Laboratoryin 1953. The first computer science department in the United States was formed atPurdue Universityin 1962.Since practical computers became available, many applications of computing have become distinct areas of study in their own rights. Although first proposed in 1956,the term \"computer science\" appears in a 1959 article inCommunications of the ACM,in which Louis Fein argues for the creation of aGraduate School in Computer Sciencesanalogous to the creation ofHarvard Business Schoolin 1921.Louis justifies the name by arguing that, likemanagement science, the subject is applied and interdisciplinary in nature, while having the characteristics typical of an academic discipline.This effort, and those of others such asnumerical analystGeorge Forsythe, were successful, and universities went on to create such departments, starting with Purdue in 1962.Despite its name, a significant amount of computer science does not involve the study of computers themselves. Because of this, several alternative names have been proposed.Certain departments of major universities prefer the termcomputing science, to emphasize precisely that difference. Danish scientistPeter Naursuggested the termdatalogy,to reflect the fact that the scientific discipline revolves around data and data treatment, while not necessarily involving computers. The first scientific institution to use the term was the Department of Datalogy at the University of Copenhagen, founded in 1969, with Peter Naur being the first professor in datalogy. The term is used mainly in the Scandinavian countries. An alternative term, also proposed by Naur, isdata science; this is now used for amulti-disciplinaryfield of data analysis, including statistics and databases. In the early days of computing, a number of terms for the practitioners of the field of computing were suggested (albeit facetiously) in theCommunications of the ACM—turingineer,turologist,flow-charts-man,applied meta-mathematician, andappliedepistemologist.Three months later in the same journal,comptologistwas suggested, followed next year byhypologist.The termcomputicshas also been suggested.In Europe, terms derived from contracted translations of the expression \"automatic information\" (e.g. \"informazione automatica\" in Italian) or \"information and mathematics\" are often used, e.g.informatique(French),Informatik(German),informatica(Italian, Dutch),informática(Spanish, Portuguese),informatika(Slavic languagesandHungarian) orpliroforiki(πληροφορική, which means informatics) inGreek. Similar words have also been adopted in the UK (as in theSchool of Informatics, University of Edinburgh).\"In the U.S., however,informaticsis linked with applied computing, or computing in the context of another domain.\" A folkloric quotation, often attributed to—but almost certainly not first formulated by—Edsger Dijkstra, states that \"computer science is no more about computers than astronomy is about telescopes.\"The design and deployment of computers and computer systems is generally considered the province of disciplines other than computer science. For example, the study of computer hardware is usually considered part ofcomputer engineering, while the study of commercialcomputer systemsand their deployment is often called information technology orinformation systems. However, there has been exchange of ideas between the various computer-related disciplines. Computer science research also often intersects other disciplines, such ascognitive science,linguistics,mathematics,physics,biology,Earth science,statistics,philosophy, andlogic. Computer science is considered by some to have a much closer relationship with mathematics than many scientific disciplines, with some observers saying that computing is a mathematical science.Early computer science was strongly influenced by the work of mathematicians such asKurt Gödel,Alan Turing,John von Neumann,Rózsa Péter,Stephen Kleene,andAlonzo Churchand there continues to be a useful interchange of ideas between the two fields in areas such asmathematical logic,category theory,domain theory, andalgebra. The relationship between computer science and software engineering is a contentious issue, which is further muddied bydisputesover what the term \"software engineering\" means, and how computer science is defined.David Parnas, taking a cue from the relationship between other engineering and science disciplines, has claimed that the principal focus of computer science is studying the properties of computation in general, while the principal focus of software engineering is the design of specific computations to achieve practical goals, making the two separate but complementary disciplines. The academic, political, and funding aspects of computer science tend to depend on whether a department is formed with a mathematical emphasis or with an engineering emphasis. Computer science departments with a mathematics emphasis and with a numerical orientation consider alignment withcomputational science. Both types of departments tend to make efforts to bridge the field educationally if not across all research. Despite the wordsciencein its name, there is debate over whether or not computer science is a discipline of science,mathematics,or engineering.Allen NewellandHerbert A. Simonargued in 1975, Computer science is an empirical discipline. We would have called it an experimental science, but like astronomy, economics, and geology, some of its unique forms of observation and experience do not fit a narrow stereotype of the experimental method. Nonetheless, they are experiments. Each new machine that is built is an experiment. Actually constructing the machine poses a question to nature; and we listen for the answer by observing the machine in operation and analyzing it by all analytical and measurement means available. It has since been argued that computer science can be classified as an empirical science since it makes use of empirical testing to evaluate thecorrectness of programs, but a problem remains in defining the laws and theorems of computer science (if any exist) and defining the nature of experiments in computer science.Proponents of classifying computer science as an engineering discipline argue that the reliability of computational systems is investigated in the same way as bridges incivil engineeringand airplanes inaerospace engineering.They also argue that while empirical sciences observe what presently exists, computer science observes what is possible to exist and while scientists discover laws from observation, no proper laws have been found in computer science and it is instead concerned with creating phenomena. Proponents of classifying computer science as a mathematical discipline argue that computer programs are physical realizations of mathematical entities and programs that can bedeductively reasonedthrough mathematicalformal methods.Computer scientistsEdsger W. DijkstraandTony Hoareregard instructions for computer programs as mathematical sentences and interpret formal semantics for programming languages as mathematicalaxiomatic systems. A number of computer scientists have argued for the distinction of three separate paradigms in computer science.Peter Wegnerargued that those paradigms are science, technology, and mathematics.Peter Denning's working group argued that they are theory, abstraction (modeling), and design.Amnon H. Eden described them as the \"rationalist paradigm\" (which treats computer science as a branch of mathematics, which is prevalent in theoretical computer science, and mainly employs deductive reasoning), the \"technocratic paradigm\" (which might be found in engineering approaches, most prominently in software engineering), and the \"scientific paradigm\" (which approaches computer-related artifacts from the empirical perspective ofnatural sciences,identifiable in some branches ofartificial intelligence).Computer science focuses on methods involved in design, specification, programming, verification, implementation and testing of human-made computing systems. As a discipline, computer science spans a range of topics from theoretical studies of algorithms and the limits of computation to the practical issues of implementing computing systems in hardware and software.CSAB, formerly called Computing Sciences Accreditation Board—which is made up of representatives of theAssociation for Computing Machinery(ACM), and theIEEE Computer Society(IEEE CS)—identifies four areas that it considers crucial to the discipline of computer science:theory of computation,algorithms and data structures,programming methodology and languages, andcomputer elements and architecture. In addition to these four areas, CSAB also identifies fields such as software engineering, artificial intelligence, computer networking and communication, database systems, parallel computation, distributed computation, human–computer interaction, computer graphics, operating systems, and numerical andsymbolic computationas being important areas of computer science. Theoretical computer scienceis mathematical and abstract in spirit, but it derives its motivation from practical and everyday computation. It aims to understand the nature of computation and, as a consequence of this understanding, provide more efficient methodologies. According to Peter Denning, the fundamental question underlying computer science is, \"What can be automated?\"Theory of computation is focused on answering fundamental questions about what can be computed and what amount of resources are required to perform those computations. In an effort to answer the first question,computability theoryexamines which computational problems are solvable on various theoreticalmodels of computation. The second question is addressed bycomputational complexity theory, which studies the time and space costs associated with different approaches to solving a multitude of computational problems. The famousP = NP?problem, one of theMillennium Prize Problems,is an open problem in the theory of computation. Information theory, closely related toprobabilityandstatistics, is related to the quantification of information. This was developed byClaude Shannonto find fundamental limits onsignal processingoperations such as compressing data and on reliably storing and communicating data.Coding theory is the study of the properties ofcodes(systems for converting information from one form to another) and their fitness for a specific application. Codes are used fordata compression,cryptography,error detection and correction, and more recently also fornetwork coding. Codes are studied for the purpose of designing efficient and reliabledata transmissionmethods. Data structures and algorithms are the studies of commonly used computational methods and their computational efficiency. Programming language theory is a branch of computer science that deals with the design, implementation, analysis, characterization, and classification ofprogramming languagesand their individualfeatures. It falls within the discipline of computer science, both depending on and affecting mathematics, software engineering, andlinguistics. It is an active research area, with numerous dedicated academic journals. Formal methods are a particular kind of mathematically based technique for thespecification, development andverificationof software andhardwaresystems.The use of formal methods for software and hardware design is motivated by the expectation that, as in other engineering disciplines, performing appropriate mathematical analysis can contribute to the reliability and robustness of a design. They form an important theoretical underpinning for software engineering, especially where safety or security is involved. Formal methods are a useful adjunct to software testing since they help avoid errors and can also give a framework for testing. For industrial use, tool support is required. However, the high cost of using formal methods means that they are usually only used in the development of high-integrity andlife-critical systems, where safety orsecurityis of utmost importance. Formal methods are best described as the application of a fairly broad variety oftheoretical computer sciencefundamentals, in particularlogiccalculi,formal languages,automata theory, andprogram semantics, but alsotype systemsandalgebraic data typesto problems in software and hardware specification and verification. Computer graphics is the study of digital visual contents and involves the synthesis and manipulation of image data. The study is connected to many other fields in computer science, includingcomputer vision,image processing, andcomputational geometry, and is heavily applied in the fields of special effects andvideo games. Informationcan take the form of images, sound, video or other multimedia.Bitsof information can be streamed viasignals. Itsprocessingis the central notion of informatics, the European view on computing, which studies information processing algorithms independently of the type of information carrier – whether it is electrical, mechanical or biological. This field plays important role ininformation theory,telecommunications,information engineeringand has applications inmedical image computingandspeech synthesis, among others.What is the lower bound on the complexity offast Fourier transformalgorithms?is one of theunsolved problems in theoretical computer science. Scientific computing(or computational science) is the field of study concerned with constructingmathematical modelsandquantitative analysistechniques and using computers to analyze and solvescientificproblems. A major usage of scientific computing issimulationof various processes, including computationalfluid dynamics, physical, electrical, and electronic systems and circuits, societies and social situations (notably war games) along with their habitats, and interactions among biological cells. Modern computers enable optimization of such designs as complete aircraft. Notable in electrical and electronic circuit design are SPICE,as well as software for physical realization of new (or modified) designs. The latter includes essential design software forintegrated circuits. Human–computer interaction (HCI) is the field of study and research concerned with the design and use ofcomputer systems, mainly based on the analysis of the interaction betweenhumansandcomputer interfaces. HCI has severalsubfieldsthat focus on the relationship betweenemotions,social behaviorandbrain activitywithcomputers. Software engineering is the study of designing, implementing, and modifying the software in order to ensure it is of high quality, affordable, maintainable, and fast to build. It is a systematic approach to software design, involving the application of engineering practices to software. Software engineering deals with the organizing and analyzing of software—it does not just deal with the creation or manufacture of new software, but its internal arrangement and maintenance. For examplesoftware testing,systems engineering,technical debtandsoftware development processes. Artificial intelligence (AI) aims to or is required to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, learning, and communication found in humans and animals. From its origins incyberneticsand in theDartmouth Conference(1956), artificial intelligence research has been necessarily cross-disciplinary, drawing on areas of expertise such asapplied mathematics, symbolic logic,semiotics,electrical engineering,philosophy of mind,neurophysiology, andsocial intelligence. AI is associated in the popular mind withrobotic development, but the main field of practical application has been as an embedded component in areas ofsoftware development, which require computational understanding. The starting point in the late 1940s was Alan Turing's question \"Can computers think?\", and the question remains effectively unanswered, although theTuring testis still used to assess computer output on the scale of human intelligence. But the automation of evaluative and predictive tasks has been increasingly successful as a substitute for human monitoring and intervention in domains of computer application involving complex real-world data. Computer architecture, or digital computer organization, is the conceptual design and fundamental operational structure of a computer system. It focuses largely on the way by which the central processing unit performs internally and accesses addresses in memory.Computer engineers studycomputational logicand design of computer hardware, from individualprocessorcomponents,microcontrollers,personal computerstosupercomputersandembedded systems. The term \"architecture\" in computer literature can be traced to the work of Lyle R. Johnson andFrederick P. Brooks Jr., members of the Machine Organization department in IBM's main research center in 1959. Concurrency is a property of systems in which several computations are executing simultaneously, and potentially interacting with each other.A number of mathematical models have been developed for general concurrent computation includingPetri nets,process calculiand theparallel random access machinemodel.When multiple computers are connected in a network while using concurrency, this is known as a distributed system. Computers within that distributed system have their own private memory, and information can be exchanged to achieve common goals. This branch of computer science aims studies the construction and behavior of computer networks. It addresses their performance, resilience, security, scalability, and cost-effectiveness, along with the variety of services they can provide. Computer security is a branch of computer technology with the objective of protecting information from unauthorized access, disruption, or modification while maintaining the accessibility and usability of the system for its intended users. Historicalcryptographyis the art of writing and deciphering secret messages. Modern cryptography is the scientific study of problems relating to distributed computations that can be attacked.Technologies studied in modern cryptography include symmetric and asymmetricencryption,digital signatures,cryptographic hash functions,key-agreement protocols,blockchain,zero-knowledge proofs, andgarbled circuits. A database is intended to organize, store, and retrieve large amounts of data easily. Digital databases are managed using database management systems to store, create, maintain, and search data, throughdatabase modelsandquery languages. Data mining is a process of discovering patterns in large data sets. The philosopher of computingBill Rapaportnoted threeGreat Insights of Computer Science: Programming languages can be used to accomplish different tasks in different ways. Common programming paradigms include: Many languages offer support for multipleparadigms, making the distinction more a matter of style than of technical capabilities. Conferences are important events for computer science research. During these conferences, researchers from the public and private sectors present their recent work and meet. Unlike in most other academic fields, in computer science, the prestige ofconference papersis greater than that of journal publications.One proposed explanation for this is the quick development of this relatively new field requires rapid review and distribution of results, a task better handled by conferences than by journals.", "metadata": {"url": "https://en.wikipedia.org/wiki/Computer_science", "title": "Computer science", "headings": ["Contents", "History", "Etymology and scope", "Philosophy", "Epistemology of computer science", "Paradigms of computer science", "Fields", "Theoretical computer science", "Applied computer science", "Computer systems", "Discoveries", "Programming paradigms", "Research", "See also", "Notes", "References", "Further reading", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Computer_science", "https://en.wikipedia.org/wiki/Computer_science", "https://en.wikipedia.org/wiki/Computer_science", "https://en.wikipedia.org/wiki/Computer_science_(disambiguation)", "https://en.wikipedia.org/wiki/Programming_language_theory", "https://en.wikipedia.org/wiki/Computer_architecture", "https://en.wikipedia.org/wiki/Artificial_intelligence", "https://en.wikipedia.org/wiki/Computational_complexity_theory"]}},
{"id": "aa96c1d4b0a6", "content": "Anacademic disciplineoracademic fieldis a subdivision ofknowledgethat is taught and researched at the college or university level. Disciplines are defined (in part) and recognized by theacademic journalsin whichresearchis published, and thelearned societiesandacademic departmentsor faculties within colleges and universities to which their practitioners belong. Academic disciplines are conventionally divided into thehumanities(includingphilosophy,language,artandcultural studies), thescientific disciplines(such asphysics,chemistry, andbiology); and theformal scienceslikemathematicsandcomputer science.Thesocial sciencesare sometimes considered a fourth category.It is also known as afield of study,field of inquiry,research fieldandbranch of knowledge.The different terms are used in different countries and fields. Individuals associated with academic disciplines are commonly referred to asexpertsorspecialists. Others, who may have studiedliberal artsorsystems theoryrather than concentrating in a specific academic discipline, are classified asgeneralists. While each academic discipline is a more or less focused practice, scholarly approaches such asmultidisciplinarity/interdisciplinarity,transdisciplinarity, andcross-disciplinarityintegrate aspects from multiple disciplines, thereby addressing any problems that may arise from narrow concentration within specialized fields of study.For example, professionals may encounter trouble communicating across academic disciplines because of differences in jargon, specified concepts, ormethodology. Some researchers believe that academic disciplines may, in the future, be replaced by what is known asMode 2or \"post-academic science\",which involves the acquisition of cross-disciplinary knowledge through the collaboration of specialists from various academic disciplines. TheUniversity of Parisin 1231 consisted of fourfaculties:Theology,Medicine,Canon LawandArts.Educational institutions originally used the term \"discipline\" to catalog and archive the new and expanding body of information produced by the scholarly community. Disciplinary designations originated in German universities during the beginning of the nineteenth century. Most academic disciplines have their roots in the mid-to-late-nineteenth centurysecularizationof universities, when the traditionalcurriculawere supplemented with non-classical languages andliteratures,social sciencessuch aspolitical science,economics,sociologyandpublic administration, andnatural scienceandtechnologydisciplines such asphysics,chemistry,biology, andengineering. In the early twentieth century, new academic disciplines such aseducationandpsychologywere added. In the 1970s and 1980s, there was an explosion of new academic disciplines focusing on specific themes, such asmedia studies,women's studies, andAfricana studies. Many academic disciplines designed as preparation for careers and professions, such asnursing,hospitality management, andcorrections, also emerged in the universities. Finally, interdisciplinary scientific fields of study such asbiochemistryandgeophysicsgained prominence as their contribution to knowledge became widely recognized. Some new disciplines, such aspublic administration, can be found in more than one disciplinary setting; some public administration programs are associated with business schools (thus emphasizing management), while others are linked to  political science  (emphasizingpolicy analysis). As the twentieth century approached, these designations were gradually adopted by other countries and became the accepted conventional subjects. However, these designations differed between various countries.In the twentieth century, the natural science disciplines included:physics,chemistry,biology,geology, andastronomy. The social science disciplines included:economics,politics,sociology, andpsychology. Prior to the twentieth century, categories were broad and general, which was expected due to the lack of interest in science at the time.  Most practitioners of science were amateurs and were referred to as \"natural historians\" and \"natural philosophers\"—labels that date back to Aristotle—instead of \"scientists\".Natural historyreferred to what we now call life sciences andnatural philosophyreferred to the current physical sciences. Prior to the twentieth century, few opportunities existed for science as an occupation outside the educational system. Higher education provided the institutional structure for scientific investigation, as well as economic support for research and teaching. Soon, the volume of scientific information rapidly increased and researchers realized the importance of concentrating on smaller, narrower fields of scientific activity. Because of this narrowing, scientific specializations emerged. As these specializations developed, modern scientific disciplines in universities also improved their sophistication. Eventually, academia's identified disciplines became the foundations for scholars of specific specialized interests and expertise. An influential critique of the concept of academic disciplines came fromMichel Foucaultin his 1975 book,Discipline and Punish. Foucault asserts that academic disciplines originate from the same social movements and mechanisms of control that established the modern prison and penal system in eighteenth-centuryFrance, and that this fact reveals essential aspects they continue to have in common: \"The disciplines characterize, classify, specialize; they distribute along a scale, around a norm, hierarchize individuals in relation to one another and, if necessary, disqualify and invalidate.\" (Foucault, 1975/1979, p. 223) Communities of academic disciplines can be found outside academia within corporations, government agencies, and independent organizations, where they take the form of associations of professionals with common interests and specific knowledge. Such communities include corporatethink tanks,NASA, andIUPAC. Communities such as these exist to benefit the organizations affiliated with them by providing specialized new ideas, research, and findings. Nations at various developmental stages will find the need for different academic disciplines during different times of growth. A newly developing nation will likely prioritize government, political matters and engineering over those of the humanities, arts and social sciences. On the other hand, a well-developed nation may be capable of investing more in the arts and social sciences. Communities of academic disciplines would contribute at varying levels of importance during different stages of development. These categories explain how the different academic disciplines interact with one another. Multidisciplinary (or pluridisciplinary) knowledge is associated with more than one existing academic discipline or profession. A multidisciplinary community or project is made up of people from different academic disciplines and professions. One key question is how well the challenge can be decomposed into subparts, and then addressed via the distributed knowledge in the community. The lack of shared vocabulary between people and communication overhead can sometimes be an issue in these communities and projects. If challenges of a particular type need to be repeatedly addressed so that each one can be properly decomposed, a multidisciplinary community can be exceptionally efficient and effective. There are many examples of a particular idea appearing in different academic disciplines, all of which came about around the same time. One example of this scenario is the shift from the approach of focusing on sensory awareness of the whole, \"an attention to the 'total field'\", a \"sense of the whole pattern, of form and function as a unity\", an \"integral idea of structure and configuration\". This has happened in art (in the form of cubism), physics, poetry, communication and educational theory. According toMarshall McLuhan, this paradigm shift was due to the passage from the era of mechanization, which brought sequentiality, to the era of the instant speed of electricity, which brought simultaneity. Multidisciplinary approaches also encourage people to help shape the innovation of the future. The political dimensions of forming new multidisciplinary partnerships to solve the so-called societal Grand Challenges were presented in the Innovation Union and in the European Framework Programme, theHorizon 2020operational overlay. Innovation across academic disciplines is considered the pivotal foresight of the creation of new products, systems, and processes for the benefit of all societies' growth and wellbeing. Regional examples such as Biopeople and industry-academia initiatives in translational medicine such as SHARE.ku.dk in Denmark provide evidence of the successful endeavour of multidisciplinary innovation and facilitation of the paradigm shift. In practice, transdisciplinary can be thought of as the union of all interdisciplinary efforts. While interdisciplinary teams may be creating new knowledge that lies between several existing disciplines, a transdisciplinary team is more holistic and seeks to relate all disciplines into a coherent whole. Cross-disciplinary knowledge is that which explains aspects of one discipline in terms of another. Common examples of cross-disciplinary approaches are studies of thephysicsofmusicor thepoliticsofliterature. Bibliometricscan be used to map several issues in relation to disciplines, for example, the flow of ideas within and among disciplines (Lindholm-Romantschuk, 1998)or the existence of specific national traditions within disciplines.Scholarly impact and influence of one discipline on another may be understood by analyzing the flow of citations. The Bibliometrics approach is described as straightforward because it is based on simple counting. The method is also objective but the quantitative method may not be compatible with a qualitative assessment and therefore manipulated. The number of citations is dependent on the number of persons working in the same domain instead of inherent quality or published result's originality.", "metadata": {"url": "https://en.wikipedia.org/wiki/Field_of_research", "title": "Academic discipline", "headings": ["Contents", "History of the concept", "Functions and criticism", "Communities of academic disciplines", "Interactions", "Multidisciplinary", "Transdisciplinary", "Cross-disciplinary", "Bibliometric studies of disciplines", "See also", "References", "Further reading", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Academic_discipline", "https://en.wikipedia.org/wiki/Academic_discipline", "https://en.wikipedia.org/wiki/Academic_discipline", "https://en.wikipedia.org/wiki/School_discipline", "https://en.wikipedia.org/wiki/Knowledge", "https://en.wikipedia.org/wiki/Academic_journal", "https://en.wikipedia.org/wiki/Research", "https://en.wikipedia.org/wiki/Learned_society"]}},
{"id": "e8e85ad8f5ff", "content": "Inpsychology,decision-making(also spelleddecision makinganddecisionmaking) is regarded as thecognitive processresulting in the selection of a belief or a course of action among several possible alternative options. It could be eitherrationalor irrational. The decision-making process is a reasoning process based on assumptions ofvalues,preferencesand beliefs of the decision-maker.Every decision-making process produces a finalchoice, which may or may not prompt action. Research about decision-making is also published under the labelproblem solving, particularly in Europeanpsychological research. Decision-making can be regarded as aproblem-solvingactivity yielding a solution deemed to be optimal, or at least satisfactory. It is therefore a process which can be more or lessrationalorirrationaland can be based onexplicitortacit knowledgeand beliefs. Tacit knowledge is often used to fill the gaps in complex decision-making processes.Usually, both of these types of knowledge, tacit and explicit, are used together in the decision-making process. Human performance has been the subject of active research from several perspectives: A major part of decision-making involves the analysis of a finite set of alternatives described in terms of evaluative criteria. Then the task might be to rank these alternatives in terms of how attractive they are to the decision-maker(s) when all the criteria are considered simultaneously. Another task might be to find the best alternative or to determine the relative total priority of each alternative (for instance, if alternatives represent projects competing for funds) when all the criteria are considered simultaneously. Solving such problems is the focus ofmultiple-criteria decision analysis(MCDA). This area of decision-making, although long established, has attracted the interest of many researchers and practitioners and is still highly debated as there are many MCDA methods which may yield very different results when they are applied to exactly the same data.This leads to the formulation of adecision-making paradox.Logicaldecision-making is an important part of all science-based professions, where specialists apply theirknowledgein a given area to make informed decisions. For example, medical decision-making often involves adiagnosisand the selection of appropriate treatment. Butnaturalistic decision-makingresearch shows that in situations with higher time pressure, higher stakes, or increased ambiguities, experts may useintuitive decision-makingrather than structured approaches. They may follow arecognition-primed decisionthat fits their experience, and arrive at a course of action without weighing alternatives. The decision-maker's environment can play a part in the decision-making process. For example, environmental complexity is a factor that influences cognitive function.A complex environment is an environment with a large number of different possible states which come and go over time.Studies done at theUniversity of Coloradohave shown that more complex environments correlate with higher cognitive function, which means that a decision can be influenced by the location. One experiment measured complexity in a room by the number of small objects and appliances present; a simple room had less of those things.Cognitive functionwas greatly affected by the higher measure of environmental complexity, making it easier to think about the situation and make a better decision. It is important to differentiate betweenproblem solving, or problem analysis, and decision-making. Problem solving is the process of investigating the given information and finding all possible solutions through invention or discovery. Traditionally, it is argued that problem solving is a step towards decision making, so that the information gathered in that process may be used towards decision-making. When a group or individual is unable to make it through theproblem-solvingstep on the way to making a decision, they could be experiencing analysis paralysis.Analysis paralysisis the state that a person enters where they are unable to make a decision, in effect paralyzing the outcome.Some of the main causes for analysis paralysis is the overwhelming flood of incoming data or the tendency to overanalyze the situation at hand.There are said to be three different types of analysis paralysis. On the opposite side of analysis paralysis is the phenomenon called extinction by instinct. Extinction by instinct is the state that a person is in when they make careless decisions without detailed planning or thorough systematic processes.Extinction by instinct can possibly be fixed by implementing a structural system, like checks and balances into a group or one's life. Analysis paralysis is the exact opposite where a group's schedule could be saturated by too much of a structural checks and balance system. Groupthink is another occurrence that falls under the idea of extinction by instinct. Groupthink is when members in a group become more involved in the \"value of the group (and their being part of it) higher than anything else\"; thus, creating a habit of making decisions quickly and unanimously. In other words, a group stuck in groupthink is participating in the phenomenon of extinction by instinct. Information overload is \"a gap between the volume of information and the tools we have to assimilate it\".Information used in decision-making is to reduce or eliminate the uncertainty.Excessive information affects problem processing and tasking, which affects decision-making.Psychologist George Armitage Miller suggests that humans' decision making becomes inhibited because human brains can only hold a limited amount of information.Crystal C. Hall and colleagues described an \"illusion of knowledge\", which means that as individuals encounter too much knowledge, it can interfere with their ability to make rational decisions.Other names for information overload are information anxiety, information explosion, infobesity, and infoxication. Decision fatigueis when a sizable amount of decision-making leads to a decline in decision-making skills. People who make decisions in an extended period of time begin to losemental energyneeded to analyze all possible solutions. Impulsive decision-making and decision avoidance are two possible paths that extend from decision fatigue. Impulse decisions are made more often when a person is tired of analysis situations or solutions; the solution they make is to act and not think.Decision avoidanceis when a person evades the situation entirely by not ever making a decision. Decision avoidance is different from analysis paralysis because this sensation is about avoiding the situation entirely, while analysis paralysis is continually looking at the decisions to be made but still unable to make a choice. Evaluation and analysis of past decisions are complementary to decision-making. See alsomental accountingandPostmortem documentation. Decision-making is a region of intense study in the fields ofsystems neuroscience, andcognitive neuroscience. Several brain structures, including theanterior cingulate cortex(ACC),orbitofrontal cortex, and the overlappingventromedial prefrontal cortexare believed to be involved in decision-making processes. Aneuroimagingstudyfound distinctive patterns of neural activation in these regions depending on whether decisions were made on the basis of perceived personalvolitionor following directions from someone else. Patients with damage to theventromedial prefrontal cortexhave difficulty making advantageous decisions. A common laboratory paradigm for studying neural decision-making is thetwo-alternative forced choicetask (2AFC), in which a subject has to choose between two alternatives within a certain time. A study of atwo-alternative forced choicetask involvingrhesus monkeysfound that neurons in theparietal cortexnot only represent the formation of a decisionbut also signal the degree of certainty (or \"confidence\") associated with the decision.A 2012 study found that rats and humans can optimally accumulate incoming sensory evidence, to make statistically optimal decisions.Another study found that lesions to the ACC in themacaqueresulted in impaired decision-making in the long run of reinforcement guided tasks suggesting that the ACC may be involved in evaluating past reinforcement information and guiding future action.It has recently been argued that the development of formal frameworks will allow neuroscientists to study richer and more naturalistic paradigms than simple 2AFC decision tasks; in particular, such decisions may involveplanningand information search across temporally extended environments. Emotionappears able to aid the decision-making process. Decision-making often occurs in the face ofuncertaintyabout whether one's choices will lead to benefit or harm (see alsoRisk). Thesomatic marker hypothesisis aneurobiologicaltheory of how decisions are made in the face of uncertain outcomes.This theory holds that such decisions are aided by emotions, in the form of bodily states, that are elicited during the deliberation of future consequences and that mark different options for behavior as being advantageous or disadvantageous. This process involves an interplay between neural systems that elicit emotional/bodily states and neural systems that map these emotional/bodily states.A recent lesion mapping study of 152 patients with focal brain lesions conducted byAron K. Barbeyand colleagues provided evidence to help discover the neural mechanisms ofemotional intelligence. Decision-making techniques can be separated into two broad categories:group decision-makingtechniques and individual decision-making techniques. Individual decision-making techniques can also often be applied by a group. A variety of researchers have formulated similar prescriptive steps aimed at improving decision-making. In the 1980s, psychologist Leon Mann and colleagues developed a decision-making process called GOFER, which they taught to adolescents, as summarized in the bookTeaching Decision Making To Adolescents.The process was based on extensive earlier research conducted with psychologistIrving Janis.GOFER is anacronymfor five decision-making steps: In 2007, Pam Brown ofSingleton HospitalinSwansea,Wales, divided the decision-making process into seven steps: In 2008, Kristina Guo published the DECIDE model of decision-making, which has six parts: In 2009, professor John Pijanowski described how the Arkansas Program, an ethics curriculum at theUniversity of Arkansas, used eight stages ofmoraldecision-making based on the work ofJames Rest: There are four stages or phases that should be involved in all group decision-making: It is said that establishing critical norms in a group improves the quality of decisions, while the majority of opinions (called consensus norms) do not. Conflicts in socialization are divided in to functional and dysfunctional types. Functional conflicts are mostly the questioning the managers assumptions in their decision making and dysfunctional conflicts are like personal attacks and every action which decrease team effectiveness. Functional conflicts are the better ones to gain higher quality decision-making caused by the increased team knowledge and shared understanding. Ineconomics, it is thought that if humans are rational and free to make their own decisions, then they would behave according torational choice theory.Rational choice theory says that a person consistently makes choices that lead to the best situation for themselves, taking into account all available considerations including costs and benefits; the rationality of these considerations is from the point of view of the person themselves, so a decision is not irrational just because someone else finds it questionable. In reality, however, there are some factors that affect decision-making abilities and cause people to make irrational decisions – for example, to make contradictory choices when faced with the same problemframedin two different ways (see alsoAllais paradox). Rational decision-making is a multi-step process for making choices between alternatives. The process of rational decision-making favors logic, objectivity, and analysis over subjectivity and insight. The irrational decision is more counter to logic. The decisions are made in haste and outcomes are not considered. One of the most prominent theories of decision-making issubjective expected utility(SEU) theory, which describes the rational behavior of the decision-maker.The decision maker assesses different alternatives by their utilities and the subjective probability of occurrence. Rational decision-making is often grounded on experience and theories that are able to put this approach on solid mathematical grounds so that subjectivity is reduced to a minimum, see e.g.scenario optimization. Rational decision is generally seen as the best or most\nlikely decision to achieve the set goals or outcome. It has been found that, unlike adults, children are less likely to have research strategy behaviors. One such behavior is adaptive decision-making, which is described as funneling and then analyzing the more promising information provided if the number of options to choose from increases. Adaptive decision-making behavior is somewhat present for children, ages 11–12 and older, but decreases in the presence the younger they are.The reason children are not as fluid in their decision making is that they lack the ability to weigh the cost and effort needed to gather information in the decision-making process. Some possibilities that explain this inability are knowledge deficits and lack of utilization skills. Children lack the metacognitive knowledge necessary to know when to use any strategies they do possess to change their approach to decision-making. When it comes to the idea of fairness in decision-making, children and adults differ much less. Children are able to understand the concept of fairness in decision-making from an early age. Toddlers and infants, ranging from 9–21 months, understand basic principles of equality. The main difference found is that more complex principles of fairness in decision making such as contextual and intentional information do not come until children get older. During their adolescent years, teens are known for their high-risk behaviors and rash decisions. Researchhas shown that there are differences in cognitive processes between adolescents and adults during decision-making. Researchers have concluded that differences in decision-making are not due to a lack of logic or reasoning, but more due to the immaturity ofpsychosocialcapacities that influence decision-making. Examples of their undeveloped capacities which influence decision-making would be impulse control, emotion regulation,delayed gratificationand resistance topeer pressure. In the past, researchers have thought that adolescent behavior was simply due to incompetency regarding decision-making. Currently, researchers have concluded that adults and adolescents are both competent decision-makers, not just adults. However, adolescents' competent decision-making skills decrease when psychosocial capacities become present. Researchhas shown that risk-taking behaviors in adolescents may be the product of interactions between the socioemotional brain network and itscognitive-control network. The socioemotional part of the brain processes social and emotional stimuli and has been shown to be important inreward processing. The cognitive-control network assists in planning and self-regulation. Both of these sections of the brain change over the course ofpuberty. However, the socioemotional network changes quickly and abruptly, while the cognitive-control network changes more gradually. Because of this difference in change, the cognitive-control network, which usually regulates the socioemotional network, struggles to control the socioemotional network when psychosocial capacities are present. When adolescents are exposed to social and emotional stimuli, their socioemotional network is activated as well as areas of the brain involved in reward processing. Because teens often gain a sense of reward from risk-taking behaviors, their repetition becomes ever more probable due to the reward experienced. In this, the process mirrorsaddiction. Teens can become addicted to risky behavior because they are in a high state of arousal and are rewarded for it not only by their own internal functions but also by their peers around them. A recent study suggests that adolescents have difficulties adequately adjusting beliefs in response to bad news (such as reading that smoking poses a greater risk to health than they thought), but do not differ from adults in their ability to alter beliefs in response to good news.This creates biased beliefs, which may lead to greater risk-taking. Adults are generally better able to control their risk-taking because their cognitive-control system has matured enough to the point where it can control the socioemotional network, even in the context of high arousal or when psychosocial capacities are present. Also, adults are less likely to find themselves in situations that push them to do risky things. For example, teens are more likely to be around peers who peer pressure them into doing things, while adults are not as exposed to this sort of social setting. Biasesusually affects decision-making processes. They appear more when decision task has time pressure, is done under high stress and/or are highly complex. Here is a list of commonly debatedbiases in judgment and decision-making: In groups, people generate decisions through active and complex processes. One method consists of three steps: initial preferences are expressed by members; the members of the group then gather and share information concerning those preferences; finally, the members combine their views and make a single choice about how to face the problem. Although these steps are relatively ordinary, judgements are often distorted by cognitive and motivational biases, including \"sins of commission\", \"sins of omission\", and \"sins of imprecision\". Herbert A. Simoncoined the phrase \"bounded rationality\" to express the idea that human decision-making is limited by available information, available time and the mind's information-processing ability. Further psychological research has identified individual differences between two cognitive styles:maximizerstry to make anoptimal decision, whereassatisficerssimply try to find a solution that is \"good enough\". Maximizers tend to take longer to make decisions due to the need to maximize performance across all variables and make tradeoffs carefully; they also tend to more often regret their decisions (perhaps because they are more able than satisficers to recognize that a decision turned out to be sub-optimal). The psychologistDaniel Kahneman, adopting terms originally proposed by the psychologistsKeith Stanovichand Richard West, has theorized that a person's decision-making is the result of an interplay between two kinds ofcognitive processes: an automatic intuitive system (called \"System 1\") and an effortful rational system (called \"System 2\"). System 1 is a bottom-up, fast, and implicit system of decision-making, while system 2 is a top-down, slow, and explicit system of decision-making.System 1 includes simpleheuristics in judgment and decision-makingsuch as theaffect heuristic, theavailability heuristic, thefamiliarity heuristic, and therepresentativeness heuristic. Styles and methods of decision-making were elaborated byAron Katsenelinboigen, the founder ofpredispositioning theory. In his analysis of styles and methods, Katsenelinboigen referred to the game of chess, saying that \"chess does disclose various methods of operation, notably the creation of predisposition methods which may be applicable to other, more complex systems.\" Katsenelinboigen states that apart from the methods (reactive and selective) and sub-methodsrandomization, predispositions, programming), there are two major styles: positional and combinational. Both styles are utilized in the game of chess. The two styles reflect two basic approaches touncertainty: deterministic (combinational style) and indeterministic (positional style). Katsenelinboigen's definition of the two styles is the following. The combinational style is characterized by: In defining the combinational style in chess, Katsenelinboigen wrote: \"The combinational style features a clearly formulated limited objective, namely the capture of material (the main constituent element of a chess position). The objective is implemented via a well-defined, and in some cases, unique sequence of moves aimed at reaching the set goal. As a rule, this sequence leaves no options for the opponent. Finding a combinational objective allows the player to focus all his energies on efficient execution, that is, the player's analysis may be limited to the pieces directly partaking in the combination. This approach is the crux of the combination and the combinational style of play. The positional style is distinguished by: \"Unlike the combinational player, the positional player is occupied, first and foremost, with the elaboration of the position that will allow him to develop in the unknown future. In playing the positional style, the player must evaluate relational and material parameters as independent variables. ... The positional style gives the player the opportunity to develop a position until it becomes pregnant with a combination. However, the combination is not the final goal of the positional player – it helps him to achieve the desirable, keeping in mind a predisposition for future development. Thepyrrhic victoryis the best example of one's inability to think positionally.\" The positional style serves to: According toIsabel Briggs Myers, a person's decision-making process depends to a significant degree on their cognitive style.Myers developed a set of four bi-polar dimensions, called theMyers–Briggs Type Indicator(MBTI). The terminal points on these dimensions are:thinkingandfeeling;extroversionandintroversion;judgmentandperception; andsensingandintuition. She claimed that a person's decision-making style correlates well with how they score on these four dimensions. For example, someone who scored near the thinking, extroversion, sensing, and judgment ends of the dimensions would tend to have a logical, analytical, objective, critical, and empirical decision-making style. However, some psychologists say that the MBTI lacks reliability and validity and is poorly constructed. Other studies suggest that these national orcross-cultural differences in decision-makingexist across entire societies. For example,Maris Martinsonshas found that American, Japanese and Chinese business leaders each exhibit a distinctive national style of decision-making. The Myers–Briggs typology has been the subject of criticism regarding its poor psychometric properties. In the general decision-making style (GDMS) test developed by Suzanne Scott and Reginald Bruce, there are five decision-making styles: rational, intuitive, dependent, avoidant, and spontaneous.These five different decision-making styles change depending on the context and situation, and one style is not necessarily better than any other. In the examples below, the individual is working for a company and is offered a job from a different company.", "metadata": {"url": "https://en.wikipedia.org/wiki/Decision-making", "title": "Decision-making", "headings": ["Contents", "Overview", "Problem solving vs. decision making", "Analysis paralysis", "Extinction by instinct", "Information overload", "Decision fatigue", "Post-decision analysis", "Neuroscience", "Emotions", "Decision-making techniques", "Group", "Individual", "Steps", "GOFER", "Other", "Group stages", "Rational and irrational", "Children, adolescents, and adults", "Children", "Adolescents", "Adults", "Cognitive and personal biases", "Cognitive limitations in groups", "Cognitive styles", "Optimizing vs. satisficing", "Intuitive vs. rational", "Combinatorial vs. positional", "Influence of Myers–Briggs type", "General decision-making style (GDMS)", "See also", "References", "Further reading", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Decision-making", "https://en.wikipedia.org/wiki/Decision-making", "https://en.wikipedia.org/wiki/Decision-making", "https://en.wikipedia.org/wiki/Decision_theory", "https://en.wikipedia.org/wiki/Group_decision-making", "https://en.wikipedia.org/wiki/Flowchart", "https://en.wikipedia.org/wiki/Psychology", "https://en.wikipedia.org/wiki/Cognition"]}},
{"id": "becd1bb1d270", "content": "  Perception(fromLatinperceptio'gathering, receiving') is the organization, identification, and interpretation ofsensoryinformation in order to represent and understand the presented information or environment.All perception involves signals that go through thenervous system, which in turn result from physical or chemical stimulation of thesensory system.Visioninvolveslightstriking theretinaof theeye;smellis mediated byodor molecules; andhearinginvolvespressure waves. Perception is not only the passive receipt of thesesignals, but it is also shaped by the recipient'slearning,memory,expectation, andattention.Sensory input is a process that transforms this low-level information to higher-level information (e.g., extracts shapes forobject recognition).The following process connects a person's concepts and expectations (orknowledge) with restorative and selective mechanisms, such asattention, that influence perception. Perception depends on complex functions of thenervous system, but subjectively seems mostly effortless because this processing happens outsideconsciousawareness.Since the rise ofexperimental psychologyin the 19th century,psychology's understanding of perceptionhas progressed by combining a variety of techniques.Psychophysicsquantitativelydescribes the relationships between the physical qualities of the sensory input and perception.Sensory neurosciencestudies the neural mechanisms underlying perception. Perceptual systems can also be studiedcomputationally, in terms of the information they process.Perceptual issues in philosophyinclude the extent to which sensory qualities such assound, smell orcolorexist in objective reality rather than in the mind of the perceiver. Although people traditionally viewed the senses as passive receptors, the study ofillusionsandambiguous imageshas demonstrated that thebrain's perceptual systems actively and pre-consciously attempt to make sense of their input.There is still active debate about the extent to which perception is an active process ofhypothesistesting, analogous toscience, or whether realistic sensory information is rich enough to make this process unnecessary. Theperceptual systemsof the brain enable individuals to see the world around them as stable, even though the sensory information is typically incomplete and rapidly varying. Human and other animal brains are structured in amodular way, with different areas processing different kinds of sensory information. Some of these modules take the form ofsensory maps, mapping some aspect of the world across part of the brain's surface. These different modules are interconnected and influence each other. For instance,tasteis strongly influenced by smell. The process of perception begins with an object in the real world, known as thedistalstimulusordistal object.By means of light, sound, or another physical process, the object stimulates the body's sensory organs. These sensory organs transform the input energy into neural activity—a process calledtransduction.This raw pattern of neural activity is called theproximal stimulus.These neural signals are then transmitted to the brain and processed.The resulting mental re-creation of the distal stimulus is thepercept. To explain the process of perception, an example could be an ordinary shoe. The shoe itself is the distal stimulus. When light from the shoe enters a person's eye and stimulates the retina, that stimulation is the proximal stimulus.The image of the shoe reconstructed by the brain of the person is the percept. Another example could be a ringing telephone. The ringing of the phone is the distal stimulus. The sound stimulating a person's auditory receptors is the proximal stimulus. The brain's interpretation of this as the \"ringing of a telephone\" is the percept. The different kinds of sensation (such as warmth, sound, and taste) are calledsensory modalitiesorstimulus modalities. PsychologistJerome Brunerdeveloped a model of perception, in which people put \"together the information contained in\" a target and a situation to form \"perceptions of ourselves and others based on social categories.\"This model is composed of three states: According to Alan Saks and Gary Johns, there are three components to perception: Stimuli are not necessarily translated into a percept and rarely does a single stimulus translate into a percept. An ambiguous stimulus may sometimes be transduced into one or more percepts, experienced randomly, one at a time, in a process termedmultistable perception. The same stimuli, or absence of them, may result in different percepts depending on subject's culture and previous experiences. Ambiguous figures demonstrate that a single stimulus can result in more than one percept. For example, theRubin vasecan be interpreted either as a vase or as two faces. The percept can bind sensations from multiple senses into a whole. A picture of a talking person on a television screen, for example, is bound to the sound of speech from speakers to form a percept of a talking person. In many ways, vision is the primary human sense. Light is taken in through each eye and focused in a way which sorts it on the retina according to direction of origin. A dense surface of photosensitive cells, including rods, cones, andintrinsically photosensitive retinal ganglion cellscaptures information about the intensity, color, and position of incoming light. Some processing of texture and movement occurs within the neurons on the retina before the information is sent to the brain. In total, about 15 differing types of information are then forwarded to the brain proper via the optic nerve. The timing of perception of a visual event, at points along the visual circuit, have been measured. A sudden alteration of light at a spot in the environment first alters photoreceptor cells in theretina, which send a signal to theretina bipolar celllayer which, in turn, can activate a retinal ganglion neuron cell. A retinal ganglion cell is a bridging neuron that connects visual retinal input to the visual processing centers within the central nervous system.Light-altered neuron activation occurs within about 5–20 milliseconds in a rabbit retinal ganglion,although in a mouse retinal ganglion cell the initial spike takes between 40 and 240 milliseconds before the initial activation.The initial activation can be detected by anaction potentialspike, a sudden spike in neuron membrane electric voltage. A perceptual visual event measured in humans was the presentation to individuals of an anomalous word. If these individuals are shown a sentence, presented as a sequence of single words on a computer screen, with a puzzling word out of place in the sequence, the perception of the puzzling word can register on an electroencephalogram (EEG). In an experiment, human readers wore an elastic cap with 64 embedded electrodes distributed over their scalp surface.Within 230 milliseconds of encountering the anomalous word, the human readers generated an event-related electrical potential alteration of their EEG at the left occipital-temporal channel, over the left occipital lobe and temporal lobe. Hearing(oraudition) is the ability to perceivesoundby detectingvibrations(i.e.,sonicdetection). Frequencies capable of being heard by humans are calledaudiooraudiblefrequencies, the range of which is typically considered to be between 20Hzand 20,000 Hz.Frequencies higher than audio are referred to asultrasonic, while frequencies below audio are referred to asinfrasonic. Theauditory systemincludes theouter ears, which collect and filter sound waves; themiddle ear, which transforms the sound pressure (impedance matching); and theinner ear, which produces neural signals in response to the sound. By the ascendingauditory pathwaythese are led to theprimary auditory cortexwithin thetemporal lobeof the human brain, from where the auditory information then goes to thecerebral cortexfor further processing. Sound does not usually come from a single source: in real situations, sounds from multiple sources and directions aresuperimposedas they arrive at the ears. Hearing involves the computationally complex task of separating out sources of interest, identifying them and often estimating their distance and direction. The process of recognizing objects through touch is known ashaptic perception. It involves a combination ofsomatosensoryperception of patterns on the skin surface (e.g., edges, curvature, and texture) andproprioceptionof hand position and conformation. People can rapidly and accurately identify three-dimensional objects by touch.This involves exploratory procedures, such as moving the fingers over the outer surface of the object or holding the entire object in the hand.Haptic perception relies on the forces experienced during touch. ProfessorGibsondefined the haptic system as \"the sensibility of the individual to the world adjacent to his body by use of his body.\"Gibson and others emphasized the close link between body movement and haptic perception, where the latter isactive exploration. The concept of haptic perception is related to the concept ofextended physiological proprioceptionaccording to which, when using a tool such as a stick, perceptual experience is transparently transferred to the end of the tool. Taste (formally known asgustation) is the ability to perceive theflavorof substances, including, but not limited to,food. Humans receive tastes through sensory organs concentrated on the upper surface of thetongue, calledtaste budsorgustatory calyculi.The human tongue has 100 to 150 taste receptor cells on each of its roughly-ten thousand taste buds. Traditionally, there have been four primary tastes:sweetness,bitterness,sourness, andsaltiness. The recognition and awareness ofumami, which is considered the fifth primary taste, is a relatively recent development inWestern cuisine.Other tastes can be mimicked by combining these basic tastes,all of which contribute only partially to the sensation andflavorof food in the mouth. Other factors includesmell, which is detected by theolfactory epitheliumof the nose;texture, which is detected through a variety ofmechanoreceptors, muscle nerves, etc.;and temperature, which is detected bythermoreceptors.All basic tastes are classified as eitherappetitiveoraversive, depending upon whether the things they sense are harmful or beneficial. Smell is the process of absorbing molecules througholfactory organs, which are absorbed by humans through thenose. These molecules diffuse through a thick layer ofmucus; come into contact with one of thousands ofciliathat are projected from sensory neurons; and are then absorbed into a receptor (one of 347 or so).It is this process that causes humans to understand the concept of smell from a physical standpoint. Smell is also a very interactive sense as scientists have begun to observe that olfaction comes into contact with the other sense in unexpected ways.It is also the most primal of the senses, as it is known to be the first indicator of safety or danger, therefore being the sense that drives the most basic of human survival skills. As such, it can be a catalyst for human behavior on asubconsciousandinstinctivelevel. Social perceptionis the part of perception that allows people to understand the individuals and groups of their social world. Thus, it is an element ofsocial cognition. Speech perceptionis the process by whichspoken languageis heard, interpreted and understood. Research in this field seeks to understand how human listeners recognize the sound of speech (orphonetics) and use such information to understand spoken language. Listeners manage to perceive words across a wide range of conditions, as the sound of a word can vary widely according to words that surround it and thetempoof the speech, as well as the physical characteristics,accent,tone, and mood of the speaker.Reverberation, signifying the persistence of sound after the sound is produced, can also have a considerable impact on perception. Experiments have shown that people automatically compensate for this effect when hearing speech. The process of perceiving speech begins at the level of the sound within the auditory signal and the process ofaudition. The initial auditory signal is compared with visual information—primarily lip movement—to extract acoustic cues and phonetic information. It is possible other sensory modalities are integrated at this stage as well.This speech information can then be used for higher-level language processes, such asword recognition. Speech perception is not necessarily uni-directional. Higher-level language processes connected withmorphology,syntax, and/orsemanticsmay also interact with basic speech perception processes to aid in recognition of speech sounds.It may be the case that it is not necessary (maybe not even possible) for a listener to recognizephonemesbefore recognizing higher units, such as words. In an experiment, professor Richard M. Warren replaced one phoneme of a word with a cough-like sound. His subjects restored the missing speech sound perceptually without any difficulty. Moreover, they were not able to accurately identify which phoneme had even been disturbed. Facial perceptionrefers to cognitive processes specialized in handlinghuman faces(including perceiving the identity of an individual) and facial expressions (such as emotional cues.) Thesomatosensory cortexis a part of the brain that receives and encodes sensory information from receptors of the entire body. Affective touchis a type of sensory information that elicits an emotional reaction and is usually social in nature. Such information is actually coded differently than other sensory information. Though the intensity of affective touch is still encoded in the primary somatosensory cortex, the feeling of pleasantness associated with affective touch is activated more in theanterior cingulate cortex. Increasedblood oxygen level-dependent(BOLD) contrast imaging, identified duringfunctional magnetic resonance imaging(fMRI), shows that signals in the anterior cingulate cortex, as well as theprefrontal cortex, are highly correlated with pleasantness scores of affective touch. Inhibitorytranscranial magnetic stimulation(TMS) of the primary somatosensory cortex inhibits the perception of affective touch intensity, but not affective touch pleasantness. Therefore, the S1 is not directly involved in processing socially affective touch pleasantness, but still plays a role in discriminating touch location and intensity. Multi-modal perceptionrefers to concurrent stimulation in more than one sensory modality and the effect such has on the perception of events and objects in the world. Chronoceptionrefers to how the passage oftimeis perceived and experienced. Although thesense of timeis not associated with a specificsensory system, the work ofpsychologistsandneuroscientistsindicates that human brains do have a system governing the perception of time,composed of a highly distributed system involving thecerebral cortex,cerebellum, andbasal ganglia. One particular component of the brain, thesuprachiasmatic nucleus, is responsible for thecircadian rhythm(commonly known as one's \"internal clock\"), while other cell clusters appear to be capable of shorter-range timekeeping, known as anultradianrhythm. One or moredopaminergic pathwaysin thecentral nervous systemappear to have a strong modulatory influence onmental chronometry, particularlyinterval timing. Sense of agencyrefers to the subjective feeling of having chosen a particular action. Some conditions, such asschizophrenia, can cause a loss of this sense, which may lead a person into delusions, such as feeling like a machine or like an outside source is controlling them. An opposite extreme can also occur, where people experience everything in their environment as though they had decided that it would happen. Even in non-pathologicalcases, there is a measurable difference between the making of a decision and the feeling of agency. Through methods such asthe Libet experiment, a gap of half a second or more can be detected from the time when there are detectable neurological signs of a decision having been made to the time when the subject actually becomes conscious of the decision. There are also experiments in which an illusion of agency is induced in psychologically normal subjects. In 1999, psychologistsWegnerand Wheatley gave subjects instructions to move a mouse around a scene and point to an image about once every thirty seconds. However, a second person—acting as a test subject but actually a confederate—had their hand on the mouse at the same time, and controlled some of the movement. Experimenters were able to arrange for subjects to perceive certain \"forced stops\" as if they were their own choice. Recognition memoryis sometimes divided into two functions by neuroscientists:familiarityandrecollection.A strong sense of familiarity can occur without any recollection, for example in cases ofdeja vu. Thetemporal lobe(specifically theperirhinal cortex) responds differently to stimuli that feel novel compared to stimuli that feel familiar.Firing ratesin the perirhinal cortex are connected with the sense of familiarity in humans and other mammals. In tests, stimulating this area at 10–15 Hz caused animals to treat even novel images as familiar, and stimulation at 30–40 Hz caused novel images to be partially treated as familiar.In particular, stimulation at 30–40 Hz led to animals looking at a familiar image for longer periods, as they would for an unfamiliar one, though it did not lead to the same exploration behavior normally associated with novelty. Recent studies onlesionsin the area concluded that rats with a damaged perirhinal cortex were still more interested in exploring when novel objects were present, but seemed unable to tell novel objects from familiar ones—they examined both equally. Thus, other brain regions are involved with noticing unfamiliarity, while the perirhinal cortex is needed to associate the feeling with a specific source. Sexual stimulationis anystimulus(including bodily contact) that leads to, enhances, and maintainssexual arousal, possibly even leading toorgasm. Distinct from the general sense oftouch, sexual stimulation is strongly tied tohormonal activityand chemical triggers in the body. Although sexual arousal may arise withoutphysical stimulation, achieving orgasm usually requires physical sexual stimulation (stimulation of the Krause-Fingercorpusclesfound in erogenous zones of the body.) Other senses enable perception ofbody balance(vestibular sense);acceleration, includinggravity;position of body parts(proprioception sense). They can also enable perception of internal senses (interoception sense), such as temperature, pain,suffocation,gag reflex,abdominal distension, fullness ofrectumandurinary bladder, and sensations felt in thethroatandlungs. In the case of visual perception, some people can see the percept shift in theirmind's eye.Others, who are notpicture thinkers, may not necessarily perceive the 'shape-shifting' as their world changes. Thisesemplasticnature has been demonstrated by an experiment that showed thatambiguous imageshave multiple interpretations on the perceptual level. The confusing ambiguity of perception is exploited in human technologies such ascamouflageand biologicalmimicry. For example, the wings ofEuropean peacock butterfliesbeareyespotsthat birds respond to as though they were the eyes of a dangerous predator. There is also evidence that the brain in some ways operates on a slight \"delay\" in order to allow nerve impulses from distant parts of the body to be integrated into simultaneous signals. Perception is one of the oldest fields in psychology. The oldestquantitativelaws in psychology areWeber's law, which states that the smallest noticeable difference in stimulus intensity is proportional to the intensity of the reference; andFechner's law, which quantifies the relationship between the intensity of the physical stimulus and its perceptual counterpart (e.g., testing how much darker a computer screen can get before the viewer actually notices). The study of perception gave rise to theGestalt School of Psychology, with an emphasis on aholisticapproach. Asensory systemis a part of the nervous system responsible for processingsensoryinformation. A sensory system consists ofsensory receptors,neural pathways, and parts of the brain involved in sensory perception. Commonly recognized sensory systems are those forvision,hearing,somatic sensation(touch),tasteandolfaction(smell), as listed above. It has been suggested that the immune system is an overlooked sensory modality.In short, senses aretransducersfrom the physical world to the realm of the mind. Thereceptive fieldis the specific part of the world to which a receptor organ and receptor cells respond. For instance, the part of the world an eye can see, is its receptive field; the light that eachrodorconecan see, is its receptive field.Receptive fields have been identified for thevisual system,auditory systemandsomatosensory system, so far. Research attention is currently focused not only on external perception processes, but also to \"interoception\", considered as the process of receiving, accessing and appraising internal bodily signals. Maintaining desired physiological states is critical for an organism's well-being and survival. Interoception is an iterative process, requiring the interplay between perception of body states and awareness of these states to generate proper self-regulation. Afferent sensory signals continuously interact with higher order cognitive representations of goals, history, and environment, shaping emotional experience and motivating regulatory behavior. Perceptual constancyis the ability of perceptual systems to recognize the same object from widely varying sensory inputs.For example, individual people can be recognized from views, such as frontal and profile, which form very different shapes on the retina. A coin looked at face-on makes a circular image on the retina, but when held at angle it makes an elliptical image.In normal perception these are recognized as a single three-dimensional object. Without this correction process, an animal approaching from the distance would appear to gain in size.One kind of perceptual constancy iscolor constancy: for example, a white piece of paper can be recognized as such under different colors and intensities of light.Another example isroughness constancy: when a hand is drawn quickly across a surface, the touch nerves are stimulated more intensely. The brain compensates for this, so the speed of contact does not affect the perceived roughness.Other constancies include melody, odor, brightness and words.These constancies are not always total, but the variation in the percept is much less than the variation in the physical stimulus.The perceptual systems of the brain achieve perceptual constancy in a variety of ways, each specialized for the kind of information being processed,withphonemic restorationas a notable example from hearing. Theprinciples of grouping(orGestalt laws of grouping) are a set of principles inpsychology, first proposed byGestalt psychologists, to explain how humans naturally perceive objects with patterns and objects. Gestalt psychologists argued that these principles exist because the mind has an innate disposition toperceivepatterns in the stimulus based on certain rules. These principles areorganized into six categories: Later research has identified additional grouping principles. A common finding across many different kinds of perception is that the perceived qualities of an object can be affected by the qualities of context. If one object is extreme on some dimension, then neighboring objects are perceived as further away from that extreme. \"Simultaneous contrast effect\" is the term used when stimuli are presented at the same time, whereassuccessive contrastapplies when stimuli are presented one after another. The contrast effect was noted by the 17th Century philosopherJohn Locke, who observed that lukewarm water can feel hot or cold depending on whether the hand touching it was previously in hot or cold water.In the early 20th Century,Wilhelm Wundtidentified contrast as a fundamental principle of perception, and since then the effect has been confirmed in many different areas.These effects shape not only visual qualities like color and brightness, but other kinds of perception, including how heavy an object feels.One experiment found that thinking of the name \"Hitler\" led to subjects rating a person as more hostile.Whether a piece of music is perceived as good or bad can depend on whether the music heard before it was pleasant or unpleasant.For the effect to work, the objects being compared need to be similar to each other: a television reporter can seem smaller when interviewing a tall basketball player, but not when standing next to a tall building.In the brain, brightness contrast exerts effects on both neuronalfiring ratesandneuronal synchrony. Cognitive theoriesof perception assume there is apoverty of the stimulus. This is the claim thatsensations, by themselves, are unable to provide a unique description of the world.Sensations require 'enriching', which is the role of themental model. Theperceptual ecologyapproach was introduced by professorJames J. Gibson, who rejected the assumption of apoverty of stimulusand the idea that perception is based upon sensations. Instead, Gibson investigated what information is actually presented to the perceptual systems. His theory \"assumes the existence of stable, unbounded, and permanent stimulus-information in theambient optic array. And it supposes that the visual system can explore and detect this information. The theory is information-based, not sensation-based.\"He and the psychologists who work within thisparadigmdetailed how the world could be specified to a mobile, exploring organism via the lawful projection of information about the world into energy arrays.\"Specification\" would be a 1:1 mapping of some aspect of the world into a perceptual array. Given such a mapping, no enrichment is required and perception isdirect. From Gibson's early work derived an ecological understanding of perception known asperception-in-action,which argues that perception is a requisite property of animate action. It posits that, without perception, action would be unguided, and without action, perception would serve no purpose. Animate actions require both perception and motion, which can be described as \"two sides of the same coin, the coin is action.\" Gibson works from the assumption that singular entities, which he callsinvariants,already exist in the real world and that all that the perception process does is home in upon them. Theconstructivist view, held by such philosophers asErnst von Glasersfeld, regards the continual adjustment of perception and action to the external input as precisely what constitutes the \"entity,\" which is therefore far from being invariant.Glasersfeld considers aninvariantas a target to be homed in upon, and a pragmatic necessity to allow an initial measure of understanding to be established prior to the updating that a statement aims to achieve. The invariant does not, and need not, represent an actuality. Glasersfeld describes it as extremely unlikely that what is desired orfearedby an organism will never suffer change as time goes on. Thissocial constructionisttheory thus allows for a needful evolutionary adjustment. A mathematical theory of perception-in-action has been devised and investigated in many forms of controlled movement, and has been described in many different species of organism using theGeneral Tau Theory. According to this theory, \"tau information\", or time-to-goal information is the fundamentalperceptin perception. Many philosophers, such asJerry Fodor, write that the purpose of perception is knowledge. However,evolutionary psychologistshold that the primary purpose of perception is to guide action.They give the example ofdepth perception, which seems to have evolved not to aid in knowing the distances to other objects but rather to aid movement.Evolutionary psychologists argue that animals ranging fromfiddler crabsto humans use eyesight forcollision avoidance, suggesting that vision is basically for directing action, not providing knowledge.Neuropsychologistsshowed that perception systems evolved along the specifics of animals' activities. This explains why bats and worms can perceive different frequency of auditory and visual systems than, for example, humans. Building and maintaining sense organs ismetabolicallyexpensive. More than half the brain is devoted to processing sensory information, and the brain itself consumes roughly one-fourth of one's metabolic resources. Thus, such organs evolve only when they provide exceptional benefits to an organism's fitness. Scientists who study perception and sensation have long understood the human senses as adaptations.Depth perception consists of processing over half a dozen visual cues, each of which is based on a regularity of the physical world.Vision evolved to respond to the narrow range of electromagnetic energy that is plentiful and that does not pass through objects.Sound waves provide useful information about the sources of and distances to objects, with larger animals making and hearing lower-frequency sounds and smaller animals making and hearing higher-frequency sounds.Taste and smell respond to chemicals in the environment that were significant for fitness in the environment of evolutionary adaptedness.The sense of touch is actually many senses, including pressure, heat, cold, tickle, and pain.Pain, while unpleasant, is adaptive.An important adaptation for senses is range shifting, by which the organism becomes temporarily more or less sensitive to sensation.For example, one's eyes automatically adjust to dim or bright ambient light.Sensory abilities of different organisms often co-evolve, as is the case with the hearing of echolocating bats and that of the moths that have evolved to respond to the sounds that the bats make. Evolutionary psychologists claim that perception demonstrates the principle of modularity, with specialized mechanisms handling particular perception tasks.For example, people with damage to a particular part of the brain are not able to recognize faces (prosopagnosia).Evolutionary psychology suggests that this indicates a so-called face-reading module. The theory ofclosed-loop perceptionproposes dynamic motor-sensory closed-loop process in which information flows through the environment and the brain in continuous loops.Closed-loop perception appears consistent with anatomy and with the fact that perception is typically an incremental process. Repeated encounters with an object, whether conscious or not, enable an animal to refine its impressions of that object. This can be achieved more easily with a circular closed-loop system than with a linear open-loop one. Closed-loop perception can explain many of the phenomena that open-loop perception struggles to account for. This is largely because closed-loop perception considers motion to be an integral part of perception, and not an interfering component that must be corrected for. Furthermore, an environment perceived via sensor motion, and not despite sensor motion, need not be further stabilized by internal processes. Anne Treisman's feature integration theory (FIT) attempts to explain how characteristics of a stimulus such as physical location in space, motion, color, and shape are merged to form one percept despite each of these characteristics activating separate areas of the cortex. FIT explains this through a two part system of perception involving the preattentive and focused attention stages. The preattentive stage of perception is largely unconscious, and analyzes an object by breaking it down into its basic features, such as the specific color, geometric shape, motion, depth, individual lines, and many others.Studies have shown that, when small groups of objects with different features (e.g., red triangle, blue circle) are briefly flashed in front of human participants, many individuals later report seeing shapes made up of the combined features of two different stimuli, thereby referred to asillusory conjunctions. The unconnected features described in the preattentive stage are combined into the objects one normally sees during the focused attention stage.The focused attention stage is based heavily around the idea of attention in perception and 'binds' the features together onto specific objects at specific spatial locations (see thebinding problem). A fundamentally different approach to understanding the perception of objects relies upon the essential role ofShared intentionality.Cognitive psychologist professorMichael Tomasellohypothesized that social bonds between children and caregivers would gradually increase through the essential motive force of shared intentionality beginning from birth.The notion of shared intentionality, introduced by Michael Tomasello, was developed by later researchers, who tended to explain this collaborative interaction from different perspectives, e.g.,psychophysiology,and neurobiology.TheShared intentionalityapproach considers perception occurrence at an earlier stage of organisms' development than other theories, even before the emergence ofIntentionality. Because many theories build their knowledge about perception based on its main features of the organization, identification, and interpretation of sensory information to represent the holistic picture of the environment,Intentionalityis the central issue in perception development. Nowadays, only one hypothesis attempts to explainShared intentionalityin all its integral complexity from the level of interpersonal dynamics to interaction at the neuronal level. Introduced by Latvian professor Igor Val Danilov, the hypothesis of neurobiological processes occurring during Shared intentionalityhighlights that, at the beginning of cognition, very young organisms cannot distinguish relevant sensory stimuli independently. Because the environment is the cacophony of stimuli (electromagnetic waves, chemical interactions, and pressure fluctuations), their sensation is too limited by the noise to solve the cue problem. The relevant stimulus cannot overcome the noise magnitude if it passes through the senses. Therefore,Intentionalityis a difficult problem for them since it needs the representation of the environment already categorized into objects (see alsobinding problem). The perception of objects is also problematic since it cannot appear without Intentionality. From the perspective of this hypothesis,Shared intentionalityis collaborative interactions in which participants share the essential sensory stimulus of the actual cognitive problem. This social bond enables ecological training of the young immature organism, starting at the reflexes stage of development, for processing the organization, identification, and interpretation of sensory information in developing perception.From this account perception emerges due toShared intentionalityin the embryonic stage of development, i.e., even before birth. With experience,organismscan learn to make finer perceptual distinctions, and learn new kinds of categorization. Wine-tasting, the reading of X-ray images and music appreciation are applications of this process in thehumansphere.Researchhas focused on the relation of this to other kinds oflearning, and whether it takes place in peripheralsensorysystems or in the brain's processing of sense information.Empiricalresearchshow that specific practices (such asyoga,mindfulness,Tai Chi,meditation, Daoshi and other mind-body disciplines) can modify human perceptual modality. Specifically, these practices enable perception skills to switch from the external (exteroceptive field) towards a higher ability to focus on internal signals (proprioception). Also, when asked to provide verticality judgments, highly self-transcendentyogapractitioners were significantly less influenced by a misleading visual context. Increasing self-transcendence may enable yoga practitioners to optimize verticality judgment tasks by relying more on internal (vestibular and proprioceptive) signals coming from their own body, rather than on exteroceptive, visual cues. Past actions and events that transpire right before an encounter or any form of stimulation have a strong degree of influence on how sensory stimuli are processed and perceived. On a basic level, the information our senses receive is often ambiguous and incomplete. However, they are grouped together in order for us to be able to understand the physical world around us. But it is these various forms of stimulation, combined with our previous knowledge and experience that allows us to create our overall perception. For example, when engaging in conversation, we attempt to understand their message and words by not only paying attention to what we hear through our ears but also from the previous shapes we have seen our mouths make. Another example would be if we had a similar topic come up in another conversation, we would use our previous knowledge to guess the direction the conversation is headed in. Aperceptual set(also calledperceptual expectancyor simplyset) is a predisposition to perceive things in a certain way.It is an example of how perception can be shaped by \"top-down\" processes such as drives and expectations.Perceptual sets occur in all the different senses.They can be long term, such as a special sensitivity to hearing one's own name in a crowded room, or short-term, as in the ease with which hungry people notice the smell of food.A simple demonstration of the effect involved very brief presentations of non-words such as \"sael\". Subjects who were told to expect words about animals read it as \"seal\", but others who were expecting boat-related words read it as \"sail\". Sets can be created bymotivationand so can result in people interpreting ambiguous figures so that they see what they want to see.For instance, how someone perceives what unfolds during a sports game can be biased if they strongly support one of the teams.In one experiment, students were allocated to pleasant or unpleasant tasks by a computer. They were told that either a number or a letter would flash on the screen to say whether they were going to taste an orange juice drink or an unpleasant-tasting health drink. In fact, an ambiguous figure was flashed on screen, which could either be read as the letter B or the number 13. When the letters were associated with the pleasant task, subjects were more likely to perceive a letter B, and when letters were associated with the unpleasant task they tended to perceive a number 13. Perceptual set has been demonstrated in many social contexts. When someone has a reputation for being funny, an audience is more likely to find them amusing.Individual's perceptual sets reflect their own personality traits. For example, people with an aggressive personality are quicker to correctly identify aggressive words or situations.In general, perceptual speed as a mental ability is positively correlated with personality traits such as conscientiousness, emotional stability, and agreeableness suggesting its evolutionary role in preserving homeostasis. One classic psychological experiment showed slower reaction times and less accurate answers when a deck ofplaying cardsreversed the color of thesuitsymbol for some cards (e.g. red spades and black hearts). PhilosopherAndy Clarkexplains that perception, although it occurs quickly, is not simply a bottom-up process (where minute details are put together to form larger wholes). Instead, our brains use what he callspredictive coding. It starts with very broad constraints and expectations for the state of the world, and as expectations are met, it makes more detailed predictions (errors lead to new predictions, orlearningprocesses). Clark says this research has various implications; not only can there be no completely \"unbiased, unfiltered\" perception, but this means that there is a great deal of feedback between perception and expectation (perceptual experiences often shape our beliefs, but those perceptions were based on existing beliefs).Indeed, predictive coding provides an account where this type of feedback assists in stabilizing our inference-making process about the physical world, such as with perceptual constancy examples. Embodied cognitionchallenges the idea of perception as internal representations resulting from a passive reception of (incomplete) sensory inputs coming from the outside world. According to O'Regan (1992), the major issue with this perspective is that it leaves the subjective character of perception unexplained.Thus, perception is understood as an active process conducted by perceiving and engaged agents (perceivers). Furthermore, perception is influenced by agents' motives and expectations, their bodily states, and the interaction between the agent's body and the environment around it. Perception is an important part of the theories of many philosophers it has been famously addressed byRene Descartes,George Berkeley, andImmanuel Kantto name a few. In his work The Meditations Descartes begins by doubting all of his perceptions proving his existence with the famous phrase \"I think therefore I am\", and then works to the conclusion that perceptions are God-given.George Berkely took the stance that all things that we see have a reality to them and that our perceptions were sufficient to know and understand that thing because our perceptions are capable of responding to a true reality.Kant almost meets the rationalists and the empiricists half way. His theory utilizes the reality of a noumenon, the actual objects that cannot be understood, and then a phenomenon which is human understanding through the mind lens interpreting that noumenon.", "metadata": {"url": "https://en.wikipedia.org/wiki/Perception", "title": "Perception", "headings": ["Contents", "Process and terminology", "Bruner's model of the perceptual process", "Saks and John's three components to perception", "Types of perception", "Vision", "Sound", "Touch", "Taste", "Smell", "Social", "Multi-modal perception", "Other senses", "Reality", "Physiology", "Features", "Constancy", "Grouping (Gestalt)", "Contrast effects", "Theories", "Perception as direct perception (Gibson)", "Perception-in-action", "Evolutionary psychology", "Closed-loop perception", "Feature integration theory", "Shared Intentionality theory", "Other theories of perception", "Effects on perception", "Effect of experience", "Effect of motivation and expectation", "Philosophy", "See also", "References", "Citations", "Sources", "Bibliography", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Perception", "https://en.wikipedia.org/wiki/Perception", "https://en.wikipedia.org/wiki/Perception", "https://en.wikipedia.org/wiki/Perception_(disambiguation)", "https://en.wikipedia.org/wiki/Percept_(disambiguation)", "https://en.wikipedia.org/wiki/Necker_cube", "https://en.wikipedia.org/wiki/Rubin_vase", "https://en.wikipedia.org/wiki/Computer_vision"]}},
{"id": "b49805ba94b1", "content": "Problem solvingis the process of achieving a goal by overcoming obstacles, a frequent part of most activities. Problems in need of solutions range from simple personal tasks (e.g. how to turn on an appliance) to complex issues in business and technical fields. The former is an example ofsimple problem solving(SPS) addressing one issue, whereas the latter iscomplex problem solving(CPS) with multiple interrelated obstacles.Another classification of problem-solving tasks is into well-defined problems with specific obstacles and goals, and ill-defined problems in which the current situation is troublesome but it is not clear what kind of resolution to aim for.Similarly, one may distinguish formal or fact-based problems requiringpsychometric intelligence, versus socio-emotional problems which depend on the changeable emotions of individuals or groups, such astactfulbehavior, fashion, or gift choices. Solutions require sufficient resources and knowledge to attain the goal. Professionals such as lawyers, doctors, programmers, and consultants are largely problem solvers for issues that require technical skills and knowledge beyond general competence. Many businesses have found profitable markets by recognizing a problem and creating a solution: the more widespread and inconvenient the problem, the greater the opportunity to develop ascalablesolution. There are many specialized problem-solving techniques and methods in fields such asscience,engineering,business,medicine,mathematics,computer science,philosophy, andsocial organization. The mental techniques to identify, analyze, and solve problems are studied inpsychologyandcognitive sciences. Also widely researched are the mental obstacles that prevent people from finding solutions; problem-solving impediments includeconfirmation bias,mental set, andfunctional fixedness. The termproblem solvinghas a slightly different meaning depending on the discipline. For instance, it is a mental process inpsychologyand a computerized process incomputer science. There are two different types of problems: ill-defined and well-defined; different approaches are used for each. Well-defined problems have specific end goals and clearly expected solutions, while ill-defined problems do not. Well-defined problems allow for more initial planning than ill-defined problems.Solving problems sometimes involves dealing withpragmatics(the way that context contributes to meaning) andsemantics(the interpretation of the problem). The ability to understand what the end goal of the problem is, and what rules could be applied, represents the key to solving the problem. Sometimes a problem requiresabstract thinkingor coming up with a creative solution. Problem solving has two major domains:mathematical problem solvingand personal problem solving. Each concerns some difficulty or barrier that is encountered. Problem solving in psychology refers to the process of finding solutions to problems encountered in life.Solutions to these problems are usually situation- or context-specific. The process starts withproblem findingandproblem shaping, in which the problem is discovered and simplified. The next step is to generate possible solutions and evaluate them. Finally a solution is selected to be implemented and verified. Problems have anend goalto be reached; how you get there depends upon problem orientation (problem-solving coping style and skills) and systematic analysis. Mental health professionals study the human problem-solving processes using methods such asintrospection,behaviorism,simulation,computer modeling, andexperiment. Social psychologists look into the person-environment relationship aspect of the problem and independent and interdependent problem-solving methods.Problem solving has been defined as a higher-ordercognitiveprocess andintellectual functionthat requires the modulation and control of more routine or fundamental skills. Empirical research shows many different strategies and factors influence everyday problem solving.Rehabilitation psychologistsstudying people with frontal lobe injuries have found that deficits in emotional control and reasoning can be re-mediated with effective rehabilitation and could improve the capacity of injured persons to resolve everyday problems.Interpersonal everyday problem solving is dependent upon personal motivational and contextual components. One such component is theemotional valenceof \"real-world\" problems, which can either impede or aid problem-solving performance. Researchers have focused on the role of emotions in problem solving,demonstrating that poor emotional control can disrupt focus on the target task, impede problem resolution, and lead to negative outcomes such as fatigue, depression, and inertia.In conceptualization,human problem solving consists of two related processes: problem orientation, and the motivational/attitudinal/affective approach to problematic situations and problem-solving skills.People's strategies cohere with their goalsand stem from the process of comparing oneself with others. Among the first experimental psychologists to study problem solving were theGestaltistsinGermany, such asKarl DunckerinThe Psychology of Productive Thinking(1935).Perhaps best known is the work ofAllen NewellandHerbert A. Simon. Experiments in the 1960s and early 1970s asked participants to solve relatively simple, well-defined, but not previously seen laboratory tasks.These simple problems, such as theTower of Hanoi, admittedoptimal solutionsthat could be found quickly, allowing researchers to observe the full problem-solving process. Researchers assumed that these model problems would elicit the characteristiccognitive processesby which more complex \"real world\" problems are solved. An outstanding problem-solving technique found by this research is the principle ofdecomposition. Much of computer science andartificial intelligenceinvolves designing automated systems to solve a specified type of problem: to accept input data and calculate a correct or adequate response, reasonably quickly.Algorithmsare recipes or instructions that direct such systems, written intocomputer programs. Steps for designing such systems include problem determination,heuristics,root cause analysis,de-duplication, analysis, diagnosis, and repair. Analytic techniques include linear and nonlinear programming,queuing systems, and simulation.A large, perennial obstacle is to find and fix errors in computer programs:debugging. Formallogicconcerns issues like validity, truth, inference, argumentation, and proof. In a problem-solving context, it can be used to formally represent a problem as a theorem to be proved, and to represent the knowledge needed to solve the problem as the premises to be used in a proof that the problem has a solution. The use of computers to prove mathematical theorems using formal logic emerged as the field ofautomated theorem provingin the 1950s. It included the use ofheuristicmethods designed to simulate human problem solving, as in theLogic Theory Machine, developed by Allen Newell, Herbert A. Simon and J. C. Shaw, as well as algorithmic methods such as theresolutionprinciple developed byJohn Alan Robinson. In addition to its use for finding proofs of mathematical theorems, automated theorem-proving has also been used forprogram verificationin computer science. In 1958,John McCarthyproposed theadvice taker, to represent information in formal logic and to derive answers to questions using automated theorem-proving. An important step in this direction was made byCordell Greenin 1969, who used a resolution theorem prover for question-answering and for such other applications in artificial intelligence as robot planning. The resolution theorem-prover used by Cordell Green bore little resemblance to human problem solving methods. In response to criticism of that approach from researchers at MIT,Robert Kowalskidevelopedlogic programmingandSLD resolution,which solves problems by problem decomposition. He has advocated logic for both computer and human problem solvingand computational logic to improve human thinking. When products or processes fail, problem solving techniques can be used to develop corrective actions that can be taken to prevent furtherfailures. Such techniques can also be applied to a product or process prior to an actual failure event—to predict, analyze, and mitigate a potential problem in advance. Techniques such asfailure mode and effects analysiscan proactively reduce the likelihood of problems. In either the reactive or the proactive case, it is necessary to build a causal explanation through a process of diagnosis. In deriving an explanation of effects in terms of causes,abductiongenerates new ideas or hypotheses (asking \"how?\");deductionevaluates and refines hypotheses based on other plausible premises (asking \"why?\"); andinductionjustifies a hypothesis with empirical data (asking \"how much?\").The objective of abduction is to determine which hypothesis or proposition to test, not which one to adopt or assert.In thePeirceanlogical system, the logic of abduction and deduction contribute to our conceptual understanding of a phenomenon, while the logic of induction adds quantitative details (empirical substantiation) to our conceptual knowledge. Forensic engineeringis an important technique offailure analysisthat involves tracing product defects and flaws. Corrective action can then be taken to prevent further failures. Reverse engineering attempts to discover the original problem-solving logic used in developing a product by disassembling the product and developing a plausible pathway to creating and assembling its parts. In physics, problem solving refers to the process by which one transforms an initial physical situation into a goal state by applying physics-specific reasoning and analysis. This involves identifying the relevant physical principles, making assumptions, formulating and manipulating equations, and checking whether the result is reasonable. A physics problem is not simply application or recall of a formula, but requires understanding the underlying concepts and navigating through a “problem space” of possible knowledge states toward the goal. Inmilitary science, problem solving is linked to the concept of \"end-states\", the conditions or situations which are the aims of the strategy.Ability to solve problems is important at anymilitary rank, but is essential at thecommand and controllevel. It results from deep qualitative and quantitative understanding of possible scenarios.Effectivenessin this context is an evaluation of results: to what extent the end states were accomplished.Planningis the process of determining how to effect those end states. Some models of problem solving involve identifying agoaland then a sequence of subgoals towards achieving this goal. Andersson, who introduced theACT-Rmodel of cognition, modelled this collection of goals and subgoals as agoal stackin which the mind contains a stack of goals and subgoals to be completed, and a single task being carried out at any time. Knowledge of how to solve one problem can be applied to another problem, in a process known astransfer. Problem-solving strategies are steps to overcoming the obstacles to achieving a goal. The iteration of such strategies over the course of solving a problem is the \"problem-solving cycle\". Common steps in this cycle include recognizing the problem, defining it, developing a strategy to fix it, organizing knowledge and resources available, monitoring progress, and evaluating the effectiveness of the solution. Once a solution is achieved, another problem usually arises, and the cycle starts again. Insight is the suddenaha!solution to a problem, the birth of a new idea to simplify a complex situation. Solutions found through insight are often more incisive than those from step-by-step analysis. A quick solution process requires insight to select productive moves at different stages of the problem-solving cycle. Unlike Newell and Simon's formal definition of amove problem, there is no consensus definition of aninsight problem. Some problem-solving strategies include: Common barriers to problem solving include mental constructs that impede an efficient search for solutions. Five of the most common identified by researchers are:confirmation bias,mental set,functional fixedness, unnecessary constraints, and irrelevant information. Confirmation bias is an unintentional tendency to collect and use data which favors preconceived notions. Such notions may be incidental rather than motivated by important personal beliefs: the desire to be right may be sufficient motivation. Scientific and technical professionals also experience confirmation bias. One online experiment, for example, suggested that professionals within the field of psychological research are likely to view scientific studies that agree with their preconceived notions more favorably than clashing studies.According to Raymond Nickerson, one can see the consequences of confirmation bias in real-life situations, which range in severity from inefficient government policies to genocide. Nickerson argued that those who killed people accused ofwitchcraftdemonstrated confirmation bias with motivation.Researcher Michael Allen found evidence for confirmation bias with motivation in school children who worked to manipulate their science experiments to produce favorable results. However, confirmation bias does not necessarily require motivation. In 1960,Peter Cathcart Wasonconducted an experiment in which participants first viewed three numbers and then created a hypothesis in the form of a rule that could have been used to create that triplet of numbers. When testing their hypotheses, participants tended to only create additional triplets of numbers that would confirm their hypotheses, and tended not to create triplets that would negate or disprove their hypotheses. Mental set is the inclination to re-use a previously successful solution, rather than search for new and better solutions. It is a reliance on habit. It was first articulated byAbraham S. Luchinsin the 1940s with his well-known water jug experiments.Participants were asked to fill one jug with a specific amount of water by using other jugs with different maximum capacities. After Luchins gave a set of jug problems that could all be solved by a single technique, he then introduced a problem that could be solved by the same technique, but also by a novel and simpler method. His participants tended to use the accustomed technique, oblivious of the simpler alternative.This was again demonstrated inNorman Maier's 1931 experiment, which challenged participants to solve a problem by using a familiar tool (pliers) in an unconventional manner. Participants were often unable to view the object in a way that strayed from its typical use, a type of mental set known as functional fixedness (see the following section). Rigidly clinging to a mental set is calledfixation, which can deepen to an obsession or preoccupation with attempted strategies that are repeatedly unsuccessful.In the late 1990s, researcher Jennifer Wiley found that professional expertise in a field can create a mental set, perhaps leading to fixation. Groupthink, in which each individual takes on the mindset of the rest of the group, can produce and exacerbate mental set.Social pressure leads to everybody thinking the same thing and reaching the same conclusions. Functional fixedness is the tendency to view an object as having only one function, and to be unable to conceive of any novel use, as in the Maier pliers experiment described above. Functional fixedness is a specific form of mental set, and is one of the most common forms of cognitive bias in daily life. As an example, imagine a man wants to kill a bug in his house, but the only thing at hand is a can of air freshener. He may start searching for something to kill the bug instead of squashing it with the can, thinking only of its main function of deodorizing. Tim German and Clark Barrett describe this barrier: \"subjects become 'fixed' on the design function of the objects, and problem solving suffers relative to control conditions in which the object's function is not demonstrated.\"Their research found that young children's limited knowledge of an object's intended function reduces this barrierResearch has also discovered functional fixedness in educational contexts, as an obstacle to understanding: \"functional fixedness may be found in learning concepts as well as in solving chemistry problems.\" There are several hypotheses in regards to how functional fixedness relates to problem solving.It may waste time, delaying or entirely preventing the correct use of a tool. Unnecessary constraints are arbitrary boundaries imposed unconsciously on the task at hand, which foreclose a productive avenue of solution. The solver may become fixated on only one type of solution, as if it were an inevitable requirement of the problem. Typically, this combines with mental set—clinging to a previously successful method. Visual problems can also produce mentally invented constraints.A famous example is the dot problem: nine dots arranged in a three-by-three grid pattern must be connected by drawing four straight line segments, without lifting pen from paper or backtracking along a line. The subject typically assumes the pen must stay within the outer square of dots, but the solution requires lines continuing beyond this frame, and researchers have found a 0% solution rate within a brief allotted time. This problem has produced the expression \"think outside the box\".Such problems are typically solved via a sudden insight which leaps over the mental barriers, often after long toil against them.This can be difficult depending on how the subject has structured the problem in their mind, how they draw on past experiences, and how well they juggle this information in their working memory. In the example, envisioning the dots connected outside the framing square requires visualizing an unconventional arrangement, which is a strain on working memory. Irrelevant information is a specification or data presented in a problem that is unrelated to the solution.If the solver assumes that all information presented needs to be used, this often derails the problem solving process, making relatively simple problems much harder. For example: \"Fifteen percent of the people in Topeka have unlisted telephone numbers. You select 200 names at random from the Topeka phone book. How many of these people have unlisted phone numbers?\"The \"obvious\" answer is 15%, but in fact none of the unlisted people would be listed among the 200. This kind of \"trick question\" is often used in aptitude tests or cognitive evaluations.Though not inherently difficult, they require independent thinking that is not necessarily common. Mathematicalword problemsoften include irrelevant qualitative or numerical information as an extra challenge. The disruption caused by the above cognitive biases can depend on how the information is represented:visually, verbally, or mathematically. A classic example is the Buddhist monk problem: A Buddhist monk begins at dawn one day walking up a mountain, reaches the top at sunset, meditates at the top for several days until one dawn when he begins to walk back to the foot of the mountain, which he reaches at sunset. Making no assumptions about his starting or stopping or about his pace during the trips, prove that there is a place on the path which he occupies at the same hour of the day on the two separate journeys. The problem cannot be addressed in a verbal context, trying to describe the monk's progress on each day. It becomes much easier when the paragraph is represented mathematically by a function: one visualizes agraphwhose horizontal axis is time of day, and whose vertical axis shows the monk's position (or altitude) on the path at each time. Superimposing the two journey curves, which traverse opposite diagonals of a rectangle, one sees they must cross each other somewhere. The visual representation by graphing has resolved the difficulty. Similar strategies can often improve problem solving on tests. People who are engaged in problem solving tend to overlook subtractive changes, even those that are critical elements of efficient solutions. For example, a city planner may decide that the solution to decrease traffic congestion would be to add another lane to a highway, rather than finding ways to reduce the need for the highway in the first place. This tendency to solve by first, only, or mostly creating or adding elements, rather than by subtracting elements or processes is shown to intensify with highercognitive loadssuch asinformation overload. People can also solve problems while they are asleep. There are many reports of scientists and engineers who solved problems in theirdreams. For example,Elias Howe, inventor of the sewing machine, figured out the structure of the bobbin from a dream. The chemistAugust Kekuléwas considering how benzene arranged its six carbon and hydrogen atoms. Thinking about the problem, he dozed off, and dreamt of dancing atoms that fell into a snakelike pattern, which led him to discover the benzene ring. As Kekulé wrote in his diary, One of the snakes seized hold of its own tail, and the form whirled mockingly before my eyes. As if by a flash of lightning I awoke; and this time also I spent the rest of the night in working out the consequences of the hypothesis. There also are empirical studies of how people can think consciously about a problem before going to sleep, and then solve the problem with a dream image. Dream researcherWilliam C. Dementtold his undergraduate class of 500 students that he wanted them to think about an infinite series, whose first elements were OTTFF, to see if they could deduce the principle behind it and to say what the next elements of the series would be.He asked them to think about this problem every night for 15 minutes before going to sleep and to write down any dreams that they then had. They were instructed to think about the problem again for 15 minutes when they awakened in the morning. The sequence OTTFF is the first letters of the numbers: one, two, three, four, five. The next five elements of the series are SSENT (six, seven, eight, nine, ten). Some of the students solved the puzzle by reflecting on their dreams. One example was a student who reported the following dream: I was standing in an art gallery, looking at the paintings on the wall. As I walked down the hall, I began to count the paintings: one, two, three, four, five. As I came to the sixth and seventh, the paintings had been ripped from their frames. I stared at the empty frames with a peculiar feeling that some mystery was about to be solved. Suddenly I realized that the sixth and seventh spaces were the solution to the problem! With more than 500 undergraduate students, 87 dreams were judged to be related to the problems students were assigned (53 directly related and 34 indirectly related). Yet of the people who had dreams that apparently solved the problem, only seven were actually able to consciously know the solution. The rest (46 out of 53) thought they did not know the solution. Albert Einsteinbelieved that much problem solving goes on unconsciously, and the person must then figure out and formulate consciously what the mindbrainhas already solved. He believed this was his process in formulating the theory of relativity: \"The creator of the problem possesses the solution.\"Einstein said that he did his problem solving without words, mostly in images. \"The words or the language, as they are written or spoken, do not seem to play any role in my mechanism of thought. The psychical entities which seem to serve as elements in thought are certain signs and more or less clear images which can be 'voluntarily' reproduced and combined.\" Problem-solving processes differ across knowledge domains and across levels of expertise.For this reason,cognitive sciencesfindings obtained in the laboratory cannot necessarily generalize to problem-solving situations outside the laboratory. This has led to a research emphasis on real-world problem solving, since the 1990s. This emphasis has been expressed quite differently in North America and Europe, however. Whereas North American research has typically concentrated on studying problem solving in separate, natural knowledge domains, much of the European research has focused on novel, complex problems, and has been performed with computerized scenarios. In Europe, two main approaches have surfaced, one initiated byDonald Broadbentin the United Kingdom and the other one byDietrich Dörnerin Germany. The two approaches share an emphasis on relatively complex, semantically rich, computerized laboratory tasks, constructed to resemble real-life problems. The approaches differ somewhat in their theoretical goals and methodology. The tradition initiated by Broadbent emphasizes the distinction between cognitive problem-solving processes that operate under awareness versus outside of awareness, and typically employs mathematically well-defined computerized systems. The tradition initiated by Dörner, on the other hand, has an interest in the interplay of the cognitive, motivational, and social components of problem solving, and utilizes very complex computerized scenarios that contain up to 2,000 highly interconnected variables. In North America, initiated by the work of Herbert A. Simon on \"learning by doing\" insemanticallyrich domains,researchers began to investigate problem solving separately in different naturalknowledge domains—such as physics, writing, orchessplaying—rather than attempt to extract a global theory of problem solving.These researchers have focused on the development of problem solving within certain domains, that is on the development ofexpertise. Areas that have attracted rather intensive attention in North America include: Complex problem solving (CPS) is distinguishable from simple problem solving (SPS). In SPS there is a singular and simple obstacle. In CPS there may be multiple simultaneous obstacles. For example, a surgeon at work has far more complex problems than an individual deciding what shoes to wear. As elucidated by Dietrich Dörner, and later expanded upon by Joachim Funke, complex problems have some typical characteristics, which include: People solve problems on many different levels—from the individual to the civilizational. Collective problem solving refers to problem solving performed collectively.Social issuesand global issues can typically only be solved collectively. The complexity of contemporary problems exceeds the cognitive capacity of any individual and requires different but complementary varieties of expertise and collective problem solving ability. Collective intelligenceis shared or group intelligence that emerges from thecollaboration, collective efforts, and competition of many individuals. In collaborative problem solving peoplework togetherto solve real-world problems. Members of problem-solving groups share a common concern, a similar passion, and/or a commitment to their work. Members can ask questions, wonder, and try to understand common issues. They share expertise, experiences, tools, and methods.Groups may be fluid based on need, may only occur temporarily to finish an assigned task, or may be more permanent depending on the nature of the problems. For example, in the educational context, members of a group may all have input into the decision-making process and a role in the learning process. Members may be responsible for the thinking, teaching, and monitoring of all members in the group. Group work may be coordinated among members so that each member makes an equal contribution to the whole work. Members can identify and build on their individual strengths so that everyone can make a significant contribution to the task.Collaborative group work has the ability to promote critical thinking skills, problem solving skills,social skills, andself-esteem. By using collaboration and communication, members often learn from one another and construct meaningful knowledge that often leads to better learning outcomes than individual work. Collaborative groups require joint intellectual efforts between the members and involvesocial interactionsto solve problems together. Theknowledge sharedduring these interactions is acquired during communication, negotiation, and production of materials.Members actively seek information from others by asking questions. The capacity to use questions to acquire new information increases understanding and the ability to solve problems. In a 1962 research report,Douglas Engelbartlinked collective intelligence to organizational effectiveness, and predicted that proactively \"augmenting human intellect\" would yield a multiplier effect in group problem solving: \"Three people working together in this augmented mode [would] seem to be more than three times as effective in solving a complex problem as is one augmented person working alone\". Henry Jenkins, a theorist of new media and media convergence, draws on the theory that collective intelligence can be attributed to media convergence andparticipatory culture.He criticizes contemporary education for failing to incorporate online trends of collective problem solving into the classroom, stating \"whereas a collective intelligence community encourages ownership of work as a group, schools grade individuals\". Jenkins argues that interaction within a knowledge community builds vital skills for young people, and teamwork through collective intelligence communities contributes to the development of such skills. Collective impactis the commitment of a group of actors from different sectors to a common agenda for solving a specific social problem, using a structured form of collaboration. AfterWorld War IItheUN, theBretton Woods organization, and theWTOwere created. Collective problem solving on the international level crystallized around these three types of organization from the 1980s onward. As these global institutions remain state-like or state-centric it is unsurprising that they perpetuate state-like or state-centric approaches to collective problem solving rather than alternative ones. Crowdsourcingis a process of accumulating ideas, thoughts, or information from many independent participants, with aim of finding the best solution for a given challenge. Moderninformation technologiesallow for many people to be involved and facilitate managing their suggestions in ways that provide good results.TheInternetallows for a new capacity of collective (including planetary-scale) problem solving.", "metadata": {"url": "https://en.wikipedia.org/wiki/Problem_solving", "title": "Problem solving", "headings": ["Contents", "Definition", "Psychology", "Cognitive sciences", "Computer science", "Logic", "Engineering", "Physics", "Military science", "Processes", "Problem-solving strategies", "Problem-solving methods", "Common barriers", "Confirmation bias", "Mental set", "Functional fixedness", "Unnecessary constraints", "Irrelevant information", "Avoiding barriers by changing problem representation", "Other barriers for individuals", "Dreaming: problem solving without waking consciousness", "Cognitive sciences: two schools", "Europe", "North America", "Characteristics of complex problems", "Collective problem solving", "See also", "Notes", "Further reading", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Problem_solving", "https://en.wikipedia.org/wiki/Problem_solving", "https://en.wikipedia.org/wiki/Problem_solving", "https://en.wikipedia.org/wiki/Problem_(disambiguation)", "https://en.wikipedia.org/wiki/Cognitive_psychology", "https://en.wikipedia.org/wiki/Perception", "https://en.wikipedia.org/wiki/Visual_perception", "https://en.wikipedia.org/wiki/Visual_object_recognition"]}},
{"id": "f52a4b5b5378", "content": "Reasonis the capacity ofconsciouslyapplyinglogicbydrawing valid conclusionsfrom new or existinginformation, with the aim of seekingtruth.It is associated with such characteristicallyhumanactivities asphilosophy,religion,science,language, andmathematics, and is normally considered to be a distinguishing ability possessed by humans.Reason is sometimes referred to asrationality,although the latter is more about its application. Reasoninginvolves using more-or-less rational processes ofthinkingandcognitionto extrapolate from one's existing knowledge to generate new knowledge, and involves the use of one'sintellect. The field oflogicstudies the ways in which humans can useformal reasoningto producelogically validargumentsand true conclusions.Reasoning may be subdivided intoformsoflogical reasoning, such asdeductive reasoning,inductive reasoning, andabductive reasoning. Aristotledrew a distinction between logicaldiscursive reasoning(reason proper), andintuitive reasoning,in which the reasoning process through intuition—however valid—may tend toward the personal and the subjectively opaque. In some social and political settings logical and intuitive modes of reasoning may clash, while in other contexts intuition and formal reason are seen as complementary rather than adversarial. For example, inmathematics, intuition is often necessary for the creative processes involved with arriving at aformal proof, arguably the most difficult of formal reasoning tasks. Reasoning, likehabitorintuition, is one of the ways by which thinking moves from one idea to a related idea. For example, reasoning is the means by which rational individuals understand the significance of sensory information from their environments, or conceptualize abstract dichotomies such ascause and effect,truthandfalsehood, orgood and evil. Reasoning, as a part ofexecutive decision making, is also closely identified with the ability to self-consciously change, in terms ofgoals,beliefs,attitudes,traditions, andinstitutions, and therefore with the capacity forfreedomandself-determination. Psychologistsandcognitive scientistshave attempted to study and explainhow people reason, e.g. which cognitive and neural processes are engaged, and how cultural factors affect the inferences that people draw. The field ofautomated reasoningstudies how reasoning may or may not be modeled computationally.Animal psychologyconsiders the question of whether animals other than humans can reason. In theEnglish languageand other modernEuropean languages, \"reason\", and related words, represent words which have always been used to translate Latin and classical Greek terms in their philosophical sense. The earliest major philosophers to publish in English, such asFrancis Bacon,Thomas Hobbes, andJohn Lockealso routinely wrote in Latin and French, and compared their terms to Greek, treating the words \"logos\", \"ratio\", \"raison\" and \"reason\" as interchangeable. The meaning of the word \"reason\" in senses such as \"human reason\" also overlaps to a large extent with \"rationality\" and the adjective of \"reason\" in philosophical contexts is normally \"rational\", rather than \"reasoned\" or \"reasonable\".Some philosophers, Hobbes for example, also used the wordratiocinationas a synonym for \"reasoning\". In contrast to the use of \"reason\" as anabstract noun,areasonis a consideration that either explains or justifies events, phenomena, orbehavior.Reasons justify decisions, reasons support explanations of natural phenomena, and reasons can be given to explain the actions (conduct) of individuals. The words are connected in this way: using reason, or reasoning, means providing good reasons. For example, when evaluating a moral decision, \"morality is, at the very least, the effort to guide one's conduct byreason—that is, doing what there are the best reasons for doing—while giving equal [and impartial] weight to the interests of all those affected by what one does.\" The proposal that reason gives humanity a special position in nature has been arguedto be a defining characteristic ofwesternphilosophyand later westernscience, starting with classical Greece. Philosophy can be described as a way of life based upon reason, while reason has been among the major subjects of philosophical discussion since ancient times. Reason is often said to bereflexive, or \"self-correcting\", and the critique of reason has been a persistent theme in philosophy. For many classicalphilosophers, nature was understoodteleologically, meaning that every type of thing had a definitive purpose that fit within a natural order that was itself understood to have aims. Perhaps starting withPythagorasorHeraclitus, thecosmoswas even said to have reason.Reason, by this account, is not just a characteristic that people happen to have. Reason was considered of higher stature than other characteristics of human nature, because it is something people share with nature itself, linking an apparently immortal part of the human mind with the divine order of the cosmos. Within the humanmindorsoul(psyche), reason was described byPlatoas being the natural monarch which should rule over the other parts, such as spiritedness (thumos) and the passions.Aristotle, Plato's student, defined human beings asrational animals, emphasizing reason as a characteristic ofhuman nature. He described the highest human happiness or well being (eudaimonia) as a life which is lived consistently, excellently, and completely in accordance with reason. The conclusions to be drawn from the discussions of Aristotle and Plato on this matter are amongst the most debated in the history of philosophy.But teleological accounts such as Aristotle's were highly influential for those who attempt to explain reason in a way that is consistent withmonotheismand the immortality and divinity of the human soul. For example, in theneoplatonistaccount ofPlotinus, thecosmoshas one soul, which is the seat of all reason, and the souls of all people are part of this soul. Reason is for Plotinus both the provider of form to material things, and the light which brings people's souls back into line with their source. The classical view of reason was adopted by the early Church.The greatest among the earlyChurch FathersandDoctors of the Churchsuch asAugustine of Hippo,Basil of Caesarea, andGregory of Nyssawere as much Neoplatonic philosophers as they were Christian theologians, and they adopted the Neoplatonic view of human reason and its implications for our relationship to creation, to ourselves, and to God. The Neoplatonic conception of the rational aspect of the human soul was widely adopted by medieval Islamic philosophers and continues to hold significance inIranian philosophy.As European intellectual life reemerged from theDark Ages, the ChristianPatristictradition and the influence of esteemed Islamic scholars likeAverroesandAvicennacontributed to the development of theScholasticview of reason, which laid the foundation for our modern understanding of this concept. Among the Scholastics who relied on the classical concept of reason for the development of their doctrines, none were more influential thanSaint Thomas Aquinas, who put this concept at the heart of hisNatural Law. In this doctrine, Thomas concludes that because humans have reason and because reason is a spark of the divine, every single human life is invaluable, all humans are equal, and every human is born with an intrinsic and permanent set of basic rights.On this foundation, the idea of human rights would later be constructed by Spanish theologians at theSchool of Salamanca. Other Scholastics, such asRoger BaconandAlbertus Magnus, following the example of Islamic scholars such asAlhazen, emphasised reason an intrinsic human ability to decode the created order and the structures that underlie our experienced physical reality. This interpretation of reason was instrumental to the development of the scientific method in the early Universities of the high Middle Ages. Theearly modern erawas marked by a number of significant changes in the understanding of reason, starting inEurope. One of the most important of these changes involved a change in themetaphysicalunderstanding of human beings. Scientists and philosophers began to question theteleologicalunderstanding of the world.Nature was no longer assumed to be human-like, with its own aims or reason, and human nature was no longer assumed to work according to anything other than the same \"laws of nature\" which affect inanimate things. This new understanding eventually displaced the previousworld viewthat derived from a spiritual understanding of the universe. Accordingly, in the 17th century,René Descartesexplicitly rejected the traditional notion of humans as \"rational animals\", suggesting instead that they are nothing more than \"thinking things\" along the lines of other \"things\" in nature. Any grounds of knowledge outside that understanding was, therefore, subject to doubt. In his search for a foundation of all possible knowledge, Descartes brought into doubtallknowledge—exceptthat of the mind itself in the process of thinking: At this time I admit nothing that is not necessarily true. I am therefore precisely nothing but a thinking thing; that is a mind, or intellect, or understanding, or reason—words of whose meanings I was previously ignorant. This eventually became known asepistemologicalor \"subject-centred\" reason, because it is based on theknowing subject, who perceives the rest of the world and itself as a set of objects to be studied, and successfully mastered, by applying the knowledge accumulated through such study. Breaking with tradition and with many thinkers after him, Descartes explicitly did not divide the incorporeal soul into parts, such as reason and intellect, describing them instead as one indivisible incorporeal entity. A contemporary of Descartes,Thomas Hobbesdescribed reason as a broader version of \"addition and subtraction\" which is not limited to numbers.This understanding of reason is sometimes termed \"calculative\" reason. Similar to Descartes, Hobbes asserted that \"No discourse whatsoever, can end in absolute knowledge of fact, past, or to come\" but that \"sense and memory\" is absolute knowledge. In the late 17th century through the 18th century,John LockeandDavid Humedeveloped Descartes's line of thought still further. Hume took it in an especiallyskepticaldirection, proposing that there could be no possibility ofdeducingrelationships of cause and effect, and therefore no knowledge is based on reasoning alone, even if it seems otherwise. Hume famously remarked that, \"We speak not strictly and philosophically when we talk of the combat of passion and of reason. Reason is, and ought only to be the slave of the passions, and can never pretend to any other office than to serve and obey them.\"Hume also took his definition of reason to unorthodox extremes by arguing, unlike his predecessors, that human reason is not qualitatively different from either simply conceiving individual ideas, or from judgments associating two ideas,and that \"reason is nothing but a wonderful and unintelligible instinct in our souls, which carries us along a certain train of ideas, and endows them with particular qualities, according to their particular situations and relations.\"It followed from this that animals have reason, only much less complex than human reason. In the 18th century,Immanuel Kantattempted to show that Hume was wrong by demonstrating that a \"transcendental\" self, or \"I\", was a necessary condition of all experience. Therefore, suggested Kant, on the basis of such a self, it is in fact possible to reason both about the conditions and limits of human knowledge. And so long as these limits are respected, reason can be the vehicle of morality, justice, aesthetics, theories of knowledge (epistemology), and understanding. In the formulation of Kant, who wrote some of the most influential modern treatises on the subject, the great achievement of reason (German:Vernunft) is that it is able to exercise a kind of universal law-making. Kant was able therefore to reformulate the basis of moral-practical, theoretical, and aesthetic reasoning on \"universal\" laws. Here,practical reasoningis the self-legislating or self-governing formulation of universalnorms, andtheoreticalreasoning is the way humans posit universallaws of nature. Under practical reason, the moralautonomyor freedom of people depends on their ability, by the proper exercise of that reason, to behave according to laws that are given to them. This contrasted with earlier forms of morality, which depended onreligious understandingand interpretation, or onnature, for their substance. According to Kant, in a free society each individual must be able to pursue their goals however they see fit, as long as their actions conform to principles given by reason. He formulated such a principle, called the \"categorical imperative\", which would justify an action only if it could be universalized: Act only according to that maxim whereby you can, at the same time, will that it should become a universal law. In contrast to Hume, Kant insisted that reason itself (GermanVernunft) could be used to find solutions to metaphysical problems, especially the discovery of the foundations of morality. Kant claimed that these solutions could be found with his \"transcendental logic\", which unlike normal logic is not just an instrument that can be used indifferently, as it was for Aristotle, but a theoretical science in its own right and the basis of all the others. According toJürgen Habermas, the \"substantive unity\" of reason has dissolved in modern times, such that it can no longer answer the question \"How should I live?\" Instead, the unity of reason has to be strictly formal, or \"procedural\". He thus described reason as a group of three autonomous spheres (on the model of Kant's three critiques): For Habermas, these three spheres are the domain of experts, and therefore need to be mediated with the \"lifeworld\" by philosophers. In drawing such a picture of reason, Habermas hoped to demonstrate that the substantive unity of reason, which in pre-modern societies had been able to answer questions about the good life, could be made up for by the unity of reason's formalizable procedures. Hamann,Herder,Kant,Hegel,Kierkegaard,Nietzsche,Heidegger,Foucault,Rorty, and many other philosophers have contributed to a debate about what reason means, or ought to mean. Some, like Kierkegaard, Nietzsche, and Rorty, are skeptical about subject-centred, universal, or instrumental reason, and even skeptical toward reason as a whole. Others, including Hegel, believe that it has obscured the importance ofintersubjectivity, or \"spirit\" in human life, and they attempt to reconstruct a model of what reason should be. Some thinkers, e.g. Foucault, believe there are otherformsof reason, neglected but essential to modern life, and to our understanding of what it means to live a life according to reason.Others suggest that there is not just one reason or rationality, but multiple possible systems of reason or rationality which may conflict (in which case there is no super-rational system one can appeal to in order to resolve the conflict). In the last several decades, a number of proposals have been made to \"re-orient\" this critique of reason, or to recognize the \"other voices\" or \"new departments\" of reason: For example, in opposition to subject-centred reason, Habermas has proposed a model ofcommunicative reasonthat sees it as an essentially cooperative activity, based on the fact of linguisticintersubjectivity. Nikolas Kompridisproposed a widely encompassing view of reason as \"that ensemble of practices that contributes to the opening and preserving of openness\" in human affairs, and a focus on reason's possibilities for social change. The philosopherCharles Taylor, influenced by the 20th century German philosopherMartin Heidegger, proposed that reason ought to include the faculty ofdisclosure, which is tied to the way we make sense of things in everyday life, as a new \"department\" of reason. In the essay \"What is Enlightenment?\", Michel Foucault proposed a critique based on Kant's distinction between \"private\" and \"public\" uses of reason: The termslogicorlogicalare sometimes used as if they were identical withreasonorrational, or sometimes logic is seen as the most pure or the defining form of reason: \"Logic is about reasoning—about going from premises to a conclusion. ... When you do logic, you try to clarify reasoning and separate good from bad reasoning.\"In moderneconomics,rational choiceis assumed to equate to logicallyconsistentchoice. However, reason and logic can be thought of as distinct—although logic is one important aspect of reason. AuthorDouglas Hofstadter, inGödel, Escher, Bach, characterizes the distinction in this way: Logic is done inside a system while reason is done outside the system by such methods as skipping steps, working backward, drawing diagrams, looking at examples, or seeing what happens if you change the rules of the system.Psychologists Mark H. Bickard and Robert L. Campbell argue that \"rationality cannot be simply assimilated to logicality\"; they note that \"human knowledge of logic andlogical systemshas developed\" over time through reasoning, and logical systems \"can't construct new logical systems more powerful than themselves\", so reasoning and rationality must involve more than a system of logic.Psychologist David Moshman, citing Bickhard and Campbell, argues for a \"metacognitiveconception of rationality\" in which a person's development of reason \"involves increasing consciousness and control of logical and other inferences\". Reason is a type ofthought, andlogicinvolves the attempt to describe a system of formal rules or norms of appropriate reasoning.The oldest surviving Western writings to explicitly consider and systematically codify the rules by which reason operates, are the works of theGreekphilosopherAristotle, especiallyPrior AnalyticsandPosterior Analytics.Although the Ancient Greeks had no separate word for logic as distinct from language and reason, Aristotle'snewly coined word\"syllogism\" (syllogismos) identified logic clearly for the first time as a distinct field of study.When Aristotle referred to \"the logical\" (hē logikē), he was referring more broadly to rational thought. As pointed out by philosophers such as Hobbes, Locke, and Hume, some animals are also clearly capable of a type of \"associative thinking\", even to the extent of associating causes and effects. A dog once kicked, can learn how to recognize the warning signs and avoid being kicked in the future, but this does not mean the dog has reason in any strict sense of the word. It also does not mean that humans acting on the basis of experience or habit are using their reason. Human reason requires more than being able to associate two ideas—even if those two ideas might be described by a reasoning human as a cause and an effect—perceptions of smoke, for example, and memories of fire. For reason to be involved, the association of smoke and the fire would have to be thought through in a way that can be explained, for example as cause and effect. In the explanation ofLocke, for example, reason requires the mental use of a third idea in order to make this comparison by use ofsyllogism. More generally, according toCharles Sanders Peirce, reason in the strict sense requires the ability to create and manipulate a system ofsymbols, as well asindices and icons, the symbols having only a nominal, though habitual, connection to either (for example) smoke or fire.One example of such a system of symbols and signs islanguage. The connection of reason to symbolic thinking has been expressed in different ways by philosophers.Thomas Hobbesdescribed the creation of \"Markes, or Notes of remembrance\" asspeech.He used the wordspeechas an English version of the Greek wordlogosso that speech did not need to be communicated.When communicated, such speech becomes language, and the marks or notes or remembrance are called \"Signes\" by Hobbes. Going further back, although Aristotle is a source of the idea that only humans have reason (logos), he does mention that animals with imagination, for whom sense perceptions can persist, come closest to having something like reasoning andnous, and even uses the word \"logos\" in one place to describe the distinctions which animals can perceive in such cases. Reason andimaginationrely on similarmental processes.Imagination is not only found in humans. Aristotle asserted thatphantasia(imagination: that which can hold images orphantasmata) andphronein(a type of thinking that can judge and understand in some sense) also exist in some animals.According to him, both are related to the primary perceptive ability of animals, which gathers the perceptions of different senses and defines the order of the things that are perceived without distinguishing universals, and without deliberation orlogos. But this is not yet reason, because human imagination is different. Terrence DeaconandMerlin Donald, writing about theorigin of language, connect reason not only tolanguage, but alsomimesis.They describe the ability to create language as part of an internal modeling ofreality, and specific to humankind. Other results areconsciousness, andimaginationorfantasy. Modern proponents of a genetic predisposition to language itself includeNoam ChomskyandSteven Pinker. If reason is symbolic thinking, and peculiarly human, then this implies that humans have a special ability to maintain a clear consciousness of the distinctness of \"icons\" or images and the real things they represent. Merlin Donald writes: A dog might perceive the \"meaning\" of a fight that was realistically play-acted by humans, but it could not reconstruct the message or distinguish the representation from its referent (a real fight).... Trained apes are able to make this distinction; young children make this distinction early—hence, their effortless distinction between play-acting an event and the event itself In classical descriptions, an equivalent description of this mental faculty iseikasia, in the philosophy of Plato.This is the ability to perceive whether a perception is an image of something else, related somehow but not the same, and therefore allows humans to perceive that a dream or memory or a reflection in a mirror is not reality as such. What Klein refers to asdianoetic eikasiais theeikasiaconcerned specifically with thinking and mental images, such as those mental symbols, icons,signes, and marks discussed above as definitive of reason. Explaining reason from this direction: human thinking is special in that we often understand visible things as if they were themselves images of our intelligible \"objects of thought\" as \"foundations\" (hypothēsesin Ancient Greek). This thinking (dianoia) is \"...an activity which consists in making the vast and diffuse jungle of the visible world depend on a plurality of more 'precise'noēta\". Both Merlin Donald and the Socratic authors such as Plato and Aristotle emphasize the importance ofmimēsis, often translated asimitationorrepresentation. Donald writes: Imitation is found especially in monkeys and apes [...but...] Mimesis is fundamentally different from imitation and mimicry in that it involves the invention of intentional representations.... Mimesis is not absolutely tied to external communication. Mimēsisis a concept, now popular again in academic discussion, that was particularly prevalent in Plato's works. In Aristotle, it is discussed mainly in thePoetics. In Michael Davis's account of the theory of man in that work: It is the distinctive feature of human action, that whenever we choose what we do, we imagine an action for ourselves as though we were inspecting it from the outside. Intentions are nothing more than imagined actions, internalizings of the external. All action is therefore imitation of action; it is poetic... Donald, like Plato (and Aristotle, especially inOn Memory and Recollection), emphasizes the peculiarity in humans of voluntary initiation of a search through one's mental world. The ancient Greekanamnēsis, normally translated as \"recollection\" was opposed tomnemeor \"memory\". Memory, shared with some animals,requires a consciousness not only of what happened in the past, but alsothatsomething happened in the past, which is in other words a kind ofeikasia\"...but nothing except man is able to recollect.\"Recollection is a deliberate effort to search for and recapture something once known. Klein writes that, \"To become aware of our having forgotten something means to begin recollecting.\"Donald calls the same thingautocueing, which he explains as follows:\"Mimetic acts are reproducible on the basis of internal, self-generated cues. This permits voluntary recall of mimetic representations, without the aid of external cues—probably the earliest form of representationalthinking.\" In a celebrated paper, the fantasy author and philologistJ.R.R. Tolkienwrote in his essay \"On Fairy Stories\" that the terms \"fantasy\" and \"enchantment\" are connected to not only \"the satisfaction of certain primordial human desires\" but also \"the origin of language and of the mind\". A subdivision ofphilosophyand a variety of reasoning islogic. The traditional main division made in philosophy is betweendeductive reasoningandinductive reasoning.Formal logichas been described asthe science of deduction.The study of inductive reasoning is generally carried out within the field known asinformal logicorcritical thinking. Deduction is a form of reasoning in which a conclusion follows necessarily from the stated premises. A deduction is also the name for the conclusion reached by a deductive reasoning process. A classic example of deductive reasoning is evident insyllogismslike the following: The reasoning in this argument is deductivelyvalidbecause there is no way in which both premises could be true and the conclusion be false. Induction is a form of inference that producesproperties or relationsabout unobserved objects ortypesbased onprevious observations or experiences, or that formulates general statements orlawsbased on limited observations of recurringphenomenalpatterns. Inductive reasoning contrasts with deductive reasoning in that, even in the strongest cases of inductive reasoning, the truth of the premises does not guarantee the truth of the conclusion. Instead, the conclusion of an inductive argument follows with some degree ofprobability. For this reason also, the conclusion of an inductive argument contains more information than is already contained in the premises. Thus, this method of reasoning is ampliative. A classic example of inductive reasoning comes from theempiricistDavid Hume: Analogical reasoning is a form of inductive reasoning from a particular to a particular. It is often used incase-based reasoning, especially legal reasoning.An example follows: Analogical reasoning is a weaker form of inductive reasoning from a single example, because inductive reasoning typically uses a large number of examples to reason from the particular to the general.Analogical reasoning often leads to wrong conclusions. For example: Abductive reasoning, or argument to the best explanation, is a form of reasoning that does not fit in either the deductive or inductive categories, since it starts with incomplete set of observations and proceeds with likely possible explanations. The conclusion in an abductive argument does not follow with certainty from its premises and concerns something unobserved. What distinguishes abduction from the other forms of reasoning is an attempt to favour one conclusion above others, by subjective judgement or by attempting to falsify alternative explanations or by demonstrating the likelihood of the favoured conclusion, given a set of more or less disputable assumptions. For example, when a patient displays certain symptoms, there might be various possible causes, but one of these is preferred above others as being more probable. Flawed reasoning in arguments is known asfallacious reasoning. Bad reasoning within arguments can result from either aformal fallacyor aninformal fallacy. Formal fallacies occur when there is a problem with the form, or structure, of the argument. The word \"formal\" refers to this link to theformof the argument. An argument that contains a formal fallacy will always be invalid. An informal fallacy is an error in reasoning that occurs due to a problem with thecontent, rather than the form or structure, of the argument. In law relating to the actions of an employer or apublic body, a decision or action which falls outside the range of actions or decision available when acting in good faith can be described as \"unreasonable\". Use of the term is considered in theEnglish lawcases ofShort v Poole Corporation(1926),Associated Provincial Picture Houses Ltd v Wednesbury Corporation(1947) andBraganza v BP Shipping Limited(2015). Philosophy is often characterized as a pursuit of rational understanding, entailing a more rigorous and dedicated application of human reasoning than commonly employed. Philosophers have long debated two fundamental questions regarding reason, essentially examining reasoning itself as a human endeavor, or philosophizing about philosophizing. The first question delves into whether we can place our trust in reason's ability to attainknowledgeandtruthmore effectively than alternative methods. The second question explores whether a life guided by reason, a life that aims to be guided by reason, can be expected to lead to greaterhappinesscompared to other approaches to life. Sinceclassical antiquitya question has remained constant in philosophical debate (sometimes seen as a conflict betweenPlatonismandAristotelianism) concerning the role of reason in confirmingtruth. People use logic,deduction, andinductionto reach conclusions they think are true. Conclusions reached in this way are considered, according to Aristotle, more certain than sense perceptions on their own.On the other hand, if such reasoned conclusions are only built originally upon a foundation of sense perceptions, then our most logical conclusions can never be said to be certain because they are built upon the very same fallible perceptions they seek to better. This leads to the question of what types offirst principles, or starting points of reasoning, are available for someone seeking to come to true conclusions. In Greek, \"first principles\" arearchai, \"starting points\",and the faculty used to perceive them is sometimes referred to in Aristotleand Platoasnouswhich was close in meaning toawarenessorconsciousness. Empiricism(sometimes associated with Aristotlebut more correctly associated withBritishphilosophers such asJohn LockeandDavid Hume, as well as their ancient equivalents such asDemocritus) asserts that sensory impressions are the only available starting points for reasoning and attempting to attain truth. This approach always leads to the controversial conclusion thatabsolute knowledgeis not attainable.Idealism, (associated with Plato and his school), claims that there is a \"higher\" reality, within which certain people can directly discover truth without needing to rely only upon the senses, and that this higher reality is therefore the primary source of truth. Philosophers such asPlato,Aristotle,Al-Farabi,Avicenna,Averroes,Maimonides,Aquinas, andHegelargued that reason must be fixed and discoverable—perhaps by dialectic, analysis, or study. Religious philosophers such asThomas AquinasandÉtienne Gilsonattempted to show that reason andrevelationare compatible. According to Hegel, \"...the only thought which Philosophy brings with it to the contemplation ofHistory, is the simple conception of reason; that reason is the Sovereign of the World; that the history of the world, therefore, presents us with a rational process.\" Since the 17th centuryrationalists, reason has often been taken to be asubjective faculty, or rather the unaided ability (pure reason) to form concepts. ForDescartes,Spinoza, andLeibniz, this was associated withmathematics.Kantattempted to show that pure reason could form concepts (timeandspace) that are the conditions of experience. Kant made his argument in opposition to Hume, who denied that reason had any role to play in experience. After Plato and Aristotle,western literatureoften treated reason as being the faculty that trained the passions and appetites.Stoic philosophy, by contrast, claimed most emotions were merely false judgements.According to the Stoics the only good is virtue, and the only evil is vice, therefore emotions that judged things other than vice to be bad (such as fear or distress), or things other than virtue to be good (such as greed) were simply false judgements and should be discarded (though positive emotions based on true judgements, such as kindness, were acceptable).After the critiques of reason in the early Enlightenment the appetites were rarely discussed or were conflated with the passions.Some Enlightenment camps took after the Stoics to say reason should oppose passion rather than order it, while others like the Romantics believed that passion displaces reason, as in the maxim \"follow your heart\". Reason has been seen as cold, an \"enemy of mystery and ambiguity\",a slave, or judge, of the passions, notably in the work ofDavid Hume. More recently,Freudwrote, “It seems as though the activity of the other agencies of the mind is able only to modify the pleasure principle but not to nullify it; and it remains a question of the greatest theoretical importance, and one that has not yet been answered, when and how it is ever possible for the pleasure principle to be overcome.” Reasoning that claims the object of a desire is demanded by logic alone is calledrationalization. Rousseaufirst proposed, in his secondDiscourse, that reason and political life is not natural and is possibly harmful to mankind.He asked what really can be said about what is natural to mankind. What, other than reason and civil society, \"best suits his constitution\"? Rousseau saw \"two principles prior to reason\" in human nature. First we hold an intense interest in our own well-being. Secondly we object to the suffering or death of any sentient being, especially one like ourselves.These two passions lead us to desire more than we could achieve. We become dependent upon each other, and on relationships of authority and obedience. This effectively puts the human race into slavery. Rousseau says that he almost dares to assert that nature does not destine men to be healthy. According toRichard Velkley, \"Rousseau outlines certain programs of rational self-correction, most notably the political legislation of theContrat Socialand the moral education inÉmile. All the same, Rousseau understands such corrections to be only ameliorations of an essentially unsatisfactory condition, that of socially and intellectually corrupted humanity.\" This quandary presented by Rousseau led toKant's new way of justifying reason as freedom to create good and evil. These therefore are not to be blamed on nature or God. In various ways,German Idealismafter Kant, and major later figures suchNietzsche,Bergson,Husserl,Scheler, andHeidegger, remain preoccupied with problems coming from the metaphysical demands or urges of reason.Rousseau and these later writers also exerted a large influence on art and politics. Many writers (such asNikos Kazantzakis) extol passion and disparage reason. In politics modernnationalismcomes from Rousseau's argument that rationalistcosmopolitanismbrings man ever further from his natural state. InDescartes' Error,Antonio Damasiopresents the \"Somatic Marker Hypothesis\" which states that emotions guide behavior and decision-making. Damasio argues that these somatic markers (known collectively as \"gut feelings\") are \"intuitive signals\" that direct our decision making processes in a certain way that cannot be solved with rationality alone. Damasio further argues that rationality requires emotional input in order to function. There are many religious traditions, some of which are explicitlyfideistand others of which claim varying degrees ofrationalism. Secular critics sometimes accuse all religious adherents of irrationality; they claim such adherents are guilty of ignoring, suppressing, or forbidding some kinds of reasoning concerning some subjects (such as religious dogmas, moral taboos, etc.).Thoughtheologiesandreligionssuch asclassical monotheismtypically do not admit to beingirrational, there is often a perceived conflict or tension betweenfaithandtraditionon the one hand, and reason on the other, as potentially competing sources ofwisdom,law, andtruth. Religious adherents sometimes respond by arguing that faith and reason can be reconciled, or have different non-overlapping domains, or that critics engage in a similar kind of irrationalism: Some commentators have claimed thatWestern civilizationcan be almost defined by its serious testing of the limits of tension between \"unaided\" reason andfaithin \"revealed\" truths—figuratively summarized asAthensandJerusalem, respectively.Leo Straussspoke of a \"GreaterWest\" that included all areas under the influence of the tension between Greek rationalism andAbrahamicrevelation, including theMuslimlands. He was particularly influenced by theMuslim philosopherAl-Farabi. To consider to what extentEastern philosophymight have partaken of these important tensions, Strauss thought it best to consider whetherdharmaortaomay be equivalent toNature(physisin Greek). According to Strauss the beginning of philosophy involved the \"discovery or invention of nature\" and the \"pre-philosophical equivalent of nature\" was supplied by \"such notions as 'custom' or 'ways'\", which appear to be really universal in all times and places. The philosophical concept of nature or natures as a way of understandingarchai(first principles of knowledge) brought about a peculiar tension between reasoning on the one hand, and tradition or faith on the other. Scientific research into reasoning is carried out within the fields ofpsychologyandcognitive science. Psychologists attempt to determine whether or not people are capable of rational thought in a number of different circumstances. Assessing how well someone engages in reasoning is the project of determining the extent to which the person isrationalor acts rationally. It is a key research question in thepsychology of reasoningand cognitive science of reasoning.Rationalityis often divided into its respectivetheoretical and practical counterparts. Experimental cognitive psychologists research reasoning behaviour. Such research may focus, for example, on how people perform on tests of reasoning such asintelligenceorIQtests, or on how well people's reasoning matches ideals set by logic (see, for example, theWason test).Experiments examine how people make inferences from conditionals likeif A then Band how they make inferences about alternatives likeA or else B.They test whether people can make valid deductions about spatial and temporal relations likeA is to the left of BorA happens after B, and about quantified assertions likeall the A are B.Experiments investigate how people make inferences about factual situations, hypothetical possibilities, probabilities, andcounterfactualsituations. Developmental psychologists investigate the development of reasoning from birth to adulthood. Piaget'stheory of cognitive developmentwas the first complete theory of reasoning development. Subsequently, several alternative theories were proposed, including theneo-Piagetian theories of cognitive development. The biological functioning of the brain is studied byneurophysiologists,cognitive neuroscientists, andneuropsychologists. This includes research into the structure and function of normally functioning brains, as well as of damaged or otherwise unusual brains. In addition to carrying out research into reasoning, some psychologists—for exampleclinical psychologistsandpsychotherapists—work to alter people's reasoning habits when those habits are unhelpful. Inartificial intelligenceandcomputer science, scientists study and useautomated reasoningfor diverse applications includingautomated theorem provingtheformal semantics of programming languages, andformal specificationinsoftware engineering. Meta-reasoningis reasoning about reasoning. In computer science, a system performs meta-reasoning when reasoning about its operation.This requires a programming language capable ofreflection, the ability to observe and modify its own structure and behaviour. A species could benefit greatly from better abilities to reason about, predict, and understand the world. French social and cognitive scientistsDan Sperberand Hugo Mercier argue that, aside from these benefits, other forces could have been driving the evolution of reason. They point out that reasoning is very difficult for humans to do effectively, and that it is hard for individuals to doubt their own beliefs (confirmation bias). Reasoning is most effective when done as a collective—as demonstrated by the success of projects likescience. They suggest that there are pressures not just individual, butgroup selectionat play. Any group that managed to find ways of reasoning effectively would reap benefits for all its members, increasing theirfitness. This could also help explain why humans, according to Sperber, are not optimized to reason effectively alone. Sperber's & Mercier's argumentative theory of reasoning claims that reason may have more to do with winning arguments than searching for the truth. Aristotlefamously described reason (with language) as a part ofhuman nature, because of which it is best for humans to live \"politically\" meaning in communities of about the size and type of a smallcity state(polisin Greek). For example: It is clear, then, that a human being is more of a political [politikon= of thepolis] animal [zōion] than is any bee or than any of those animals that live in herds. For nature, as we say, makes nothing in vain, and humans are the only animals who possess reasoned speech [logos]. Voice, of course, serves to indicate what is painful and pleasant; that is why it is also found in other animals, because their nature has reached the point where they can perceive what is painful and pleasant and express these to each other. But speech [logos] serves to make plain what is advantageous and harmful and so also what is just and unjust. For it is a peculiarity of humans, in contrast to the other animals, to have perception of good and bad, just and unjust, and the like; and the community in these things makes a household or city [polis].... By nature, then, the drive for such a community exists in everyone, but the first to set one up is responsible for things of very great goodness. For as humans are the best of all animals when perfected, so they are the worst when divorced from law and right. The reason is that injustice is most difficult to deal with when furnished with weapons, and the weapons a human being has are meant by nature to go along with prudence and virtue, but it is only too possible to turn them to contrary uses. Consequently, if a human being lacks virtue, he is the most unholy and savage thing, and when it comes to sex and food, the worst. But justice is something political [to do with thepolis], for right is the arrangement of the political community, and right is discrimination of what is just. If human nature is fixed in this way, we can define what type of community is always best for people. This argument has remained a central argument in all political, ethical, and moral thinking since then, and has become especially controversial since firstlyRousseau's Second Discourse, and secondly, theTheory of Evolution. Already in Aristotle there was an awareness that thepolishad not always existed and had to be invented or developed by humans themselves. The household came first, and the first villages and cities were just extensions of that, with the first cities being run as if they were still families with Kings acting like fathers. Friendshipseems to prevail in man and woman according tonature[kata phusin]; for people are by nature [tēi phusei] pairing more than political [politikon], in as much as the household [oikos] is prior and more necessary than thepolisand making children is more common [koinoteron] with the animals. In the other animals, community [koinōnia] goes no further than this, but people live together [sumoikousin] not only for the sake of making children, but also for the things for life; for from the start the functions [erga] are divided, and are different for man and woman. Thus they supply each other, putting their own into the common [eis to koinon]. It is for these reasons that both utility and pleasure seem to be found in this kind of friendship. Rousseauin his Second Discourse finally took the shocking step of claiming that this traditional account has things in reverse: with reason, language, and rationally organized communities all having developed over a long period of time merely as a result of the fact that some habits of cooperation were found to solve certain types of problems, and that once such cooperation became more important, it forced people to develop increasingly complex cooperation—often only to defend themselves from each other. In other words, according to Rousseau, reason, language, and rational community did not arise because of any conscious decision or plan by humans or gods, nor because of any pre-existing human nature. As a result, he claimed, living together in rationally organized communities like modern humans is a development with many negative aspects compared to the original state of man as an ape. If anything is specifically human in this theory, it is the flexibility and adaptability of humans. This view of the animal origins of distinctive human characteristics later received support fromCharles Darwin'sTheory of Evolution. The two competing theories concerning the origins of reason are relevant to political and ethical thought because, according to the Aristotelian theory, a best way of living together exists independently of historical circumstances. According to Rousseau, we should even doubt that reason, language, and politics are a good thing, as opposed to being simply the best option given the particular course of events that led to today. Rousseau's theory, that human nature is malleable rather than fixed, is often taken to imply (for example byKarl Marx) a wider range of possible ways of living together than traditionally known. However, while Rousseau's initial impact encouraged bloody revolutions against traditional politics, including both theFrench Revolutionand theRussian Revolution, his own conclusions about the best forms of community seem to have been remarkably classical, in favor of city-states such asGeneva, andrural living.", "metadata": {"url": "https://en.wikipedia.org/wiki/Reason", "title": "Reason", "headings": ["Contents", "Etymology and related words", "Philosophical history", "Classical philosophy", "Christian and Islamic philosophy", "Subject-centred reason in early modern philosophy", "Substantive and formal reason", "The critique of reason", "Reason compared to related concepts", "Reason compared to logic", "Reason compared to cause-and-effect thinking, and symbolic thinking", "Reason, imagination, mimesis, and memory", "Logical reasoning methods and argumentation", "Unreasonable decisions and actions", "Traditional problems raised concerning reason", "Reason versus truth, and \"first principles\"", "Reason versus emotion or passion", "Reason versus faith or tradition", "Reason in particular fields of study", "Psychology and cognitive science", "Computer science", "Evolution of reason", "Reason in political philosophy and ethics", "See also", "References", "Further reading"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Reason", "https://en.wikipedia.org/wiki/Reason", "https://en.wikipedia.org/wiki/Reason", "https://en.wikipedia.org/wiki/Reason_(disambiguation)", "https://en.wikipedia.org/wiki/Epistemology", "https://en.wikipedia.org/wiki/Outline_of_epistemology", "https://en.wikipedia.org/wiki/Coherentism", "https://en.wikipedia.org/wiki/Contextualism"]}},
{"id": "8a04388bf00f", "content": "Learningis the process of acquiring newunderstanding,knowledge,behaviors,skills,values,attitudes, andpreferences.The ability to learn is possessed byhumans, non-humananimals, and somemachines; there is also evidence for some kind of learning in certainplants.Some learning is immediate, induced by a single event (e.g. beingburnedby ahotstove), but much skill and knowledge accumulate from repeated experiences.The changes induced by learning often last a lifetime, and it is hard to distinguish learned material that seems to be \"lost\" from that which cannot be retrieved. Human learning starts at birth (it might even start before) and continues until death as a consequence of ongoing interactions between people and their environment. The nature and processes involved in learning are studied in many established fields (includingeducational psychology,neuropsychology,experimental psychology,cognitive sciences, andpedagogy), as well as emerging fields of knowledge (e.g. with a shared interest in the topic oflearning from safety events such as incidents/accidents,or in collaborative learning health systems). Research in such fields has led to the identification of various sorts of learning. For example, learning may occur as a result ofhabituation, orclassical conditioning,operant conditioningor as a result of more complex activities such asplay, seen only in relatively intelligent animals.Learning may occurconsciouslyor without conscious awareness. Learning that an aversive event cannot be avoided or escaped may result in a condition calledlearned helplessness.There is evidence for human behavioral learningprenatally, in whichhabituationhas been observed as early as 32 weeks intogestation, indicating that thecentral nervous systemis sufficiently developed and primed for learning andmemoryto occur very early on indevelopment. Play has been approached by several theorists as a form of learning. Children experiment with the world, learn the rules, and learn to interact through play.Lev Vygotskyagrees that play is pivotal for children's development, since they make meaning of their environment through playing educational games. For Vygotsky, however, play is the first form of learning language and communication, and the stage where a child begins to understand rules and symbols.This has led to a view that learning in organisms is always related tosemiosis,and is often associated with representational systems/activity. There are various functional categorizations of memory which have developed. Some memory researchers distinguish memory based on the relationship between the stimuli involved (associative vs non-associative) or based to whether the content can be communicated through language (declarative/explicit vs procedural/implicit). Some of these categories can, in turn, be parsed into sub-types. For instance,declarative memorycomprises bothepisodicandsemanticmemory. Non-associative learningrefers to \"a relatively permanent change in the strength of response to a single stimulus due to repeated exposure to that stimulus.\"This definition exempts the changes caused bysensory adaptation,fatigue, or injury. Non-associative learning can be divided intohabituationandsensitization. Habituationis an example of non-associative learning in which one or more components of an innate response (e.g., response probability, response duration) to a stimulus diminishes when the stimulus is repeated. Thus, habituation must be distinguished fromextinction, which is an associative process. In operant extinction, for example, a response declines because it is no longer followed by a reward. An example of habituation can be seen in small song birds—if a stuffedowl(or similarpredator) is put into the cage, the birds initially react to it as though it were a real predator. Soon the birds react less, showing habituation. If another stuffed owl is introduced (or the same one removed and re-introduced), the birds react to it again as though it were a predator, demonstrating that it is only a very specific stimulus that is habituated to (namely, one particular unmoving owl in one place). The habituation process is faster for stimuli that occur at a high rather than for stimuli that occur at a low rate as well as for the weak and strong stimuli, respectively.Habituation has been shown in essentially every species of animal, as well as the sensitive plantMimosa pudicaand the large protozoanStentor coeruleus.This concept acts in direct opposition to sensitization. Sensitizationis an example of non-associative learning in which the progressive amplification of a response follows repeated administrations of astimulus.This is based on the notion that a defensive reflex to a stimulus such as withdrawal or escape becomes stronger after the exposure to a different harmful or threatening stimulus.An everyday example of this mechanism is the repeated tonic stimulation of peripheral nerves that occurs if a person rubs their arm continuously. After a while, this stimulation creates a warm sensation that can eventually turn painful. This pain results from a progressively amplified synaptic response of the peripheral nerves. This sends a warning that the stimulation is harmful.Sensitization is thought to underlie both adaptive as well as maladaptive learning processes in the organism. Active learningoccurs when a person takes control of their learning experience. Since understanding information is the key aspect of learning, it is important for learners to recognize what they understand and what they do not. By doing so, they can monitor their own mastery of subjects. Active learning encourages learners to have an internal dialogue in which they verbalize understandings. This and other meta-cognitive strategies can be taught to a child over time. Studies withinmetacognitionhave proven the value in active learning, claiming that the learning is usually at a stronger level as a result.In addition, learners have more incentive to learn when they have control over not only how they learn but also what they learn.Active learning is a key characteristic ofstudent-centered learning. Conversely,passive learninganddirect instructionare characteristics of teacher-centered learning (ortraditional education). Associative learningis the process by which a person or animal learns anassociationbetween two stimuli or events.Inclassical conditioning, a previously neutral stimulus is repeatedly paired with a reflex-eliciting stimulus until eventually the neutral stimulus elicits a response on its own. In operant conditioning, a behavior that is reinforced or punished in the presence of a stimulus becomes more or less likely to occur in the presence of that stimulus. Operant conditioningis a way in which behavior can be shaped or modified according to the desires of the trainer or head individual. Operant conditioning uses the thought that living things seek pleasure and avoid pain, and that an animal or human can learn through receiving either reward or punishment at a specific time called trace conditioning. Trace conditioning is the small and ideal period of time between the subject performing the desired behavior, and receiving the positive reinforcement as a result of their performance. The reward needs to be given immediately after the completion of the wanted behavior. Operant conditioning is different from classical conditioning in that it shapes behavior not solely on bodily reflexes that occur naturally to a specific stimulus, but rather focuses on the shaping of wanted behavior that requires conscious thought, and ultimately requires learning. Punishment and reinforcement are the two principal ways in which operant conditioning occurs. Punishment is used to reduce unwanted behavior, and ultimately (from the learner's perspective) leads to avoidance of the punishment, not necessarily avoidance of the unwanted behavior. Punishment is not an appropriate way to increase wanted behavior for animals or humans. Punishment can be divided into two subcategories, positive punishment and negative punishment. Positive punishment is when an aversive aspect of life or thing is added to the subject, for this reason it is called positive punishment. For example, the parent spanking their child would be considered a positive punishment, because a spanking was added to the child. Negative punishment is considered the removal of something loved or desirable from the subject. For example, when a parent puts his child in time out, in reality, the child is losing the opportunity to be with friends, or to enjoy the freedom to do as he pleases. In this example, negative punishment is the removal of the child's desired rights to play with his friends etc. Reinforcement on the other hand is used to increase a wanted behavior either through negative reinforcement or positive reinforcement. Negative reinforcement is defined by removing an undesirable aspect of life, or thing. For example, a dog might learn to sit as the trainer scratches his ears, which ultimately is removing his itches (undesirable aspect). Positive reinforcement is defined by adding a desirable aspect of life or thing. For example, a dog might learn to sit if he receives a treat. In this example the treat was added to the dog's life. The typical paradigm forclassical conditioninginvolves repeatedly pairing an unconditioned stimulus (which unfailingly evokes a reflexive response) with another previously neutral stimulus (which does not normally evoke the response). Following conditioning, the response occurs both to the unconditioned stimulus and to the other, unrelated stimulus (now referred to as the \"conditioned stimulus\"). The response to the conditioned stimulus is termed aconditioned response. The classic example isIvan Pavlovand his dogs.Pavlov fed his dogs meat powder, which naturally made the dogs salivate—salivating is a reflexive response to the meat powder. Meat powder is the unconditioned stimulus (US) and the salivation is the unconditioned response (UR). Pavlov rang a bell before presenting the meat powder. The first time Pavlov rang the bell, the neutral stimulus, the dogs did not salivate, but once he put the meat powder in their mouths they began to salivate. After numerous pairings of bell and food, the dogs learned that the bell signaled that food was about to come, and began to salivate when they heard the bell. Once this occurred, the bell became the conditioned stimulus (CS) and the salivation to the bell became the conditioned response (CR). Classical conditioning has been demonstrated in many species. For example, it is seen in honeybees, in theproboscis extension reflexparadigm.It was recently also demonstrated in garden pea plants. Another influential person in the world of classical conditioning isJohn B. Watson. Watson's work was very influential and paved the way forB.F. Skinner's radical behaviorism. Watson's behaviorism (and philosophy of science) stood in direct contrast to Freud and other accounts based largely on introspection. Watson's view was that the introspective method was too subjective and that we should limit the study of human development to directly observable behaviors. In 1913, Watson published the article \"Psychology as the Behaviorist Views\", in which he argued that laboratory studies should serve psychology best as a science. Watson's most famous, and controversial, experiment was \"Little Albert\", where he demonstrated how psychologists can account for the learning of emotion through classical conditioning principles. Observational learningis learning that occurs through observing the behavior of others. It is a form of social learning which takes various forms, based on various processes. In humans, this form of learning seems to not need reinforcement to occur, but instead, requires a social model such as a parent, sibling, friend, or teacher with surroundings. Imprintingis a kind of learning occurring at a particular life stage that is rapid and apparently independent of the consequences of behavior. In filial imprinting, young animals, particularly birds, form an association with another individual or in some cases, an object, that they respond to as they would to a parent. In 1935, the Austrian Zoologist Konrad Lorenz discovered that certain birds follow and form a bond if the object makes sounds. Playgenerally describes behavior with no particular end in itself, but that improves performance in similar future situations. This is seen in a wide variety of vertebrates besides humans, but is mostly limited tomammalsandbirds. Cats are known to play with a ball of string when young, which gives them experience with catching prey. Besides inanimate objects, animals may play with other members of their own species or other animals, such asorcasplaying with seals they have caught. Play involves a significant cost to animals, such as increased vulnerability topredatorsand the risk ofinjuryand possiblyinfection. It also consumesenergy, so there must be significant benefits associated with play for it to have evolved. Play is generally seen in younger animals, suggesting a link with learning. However, it may also have other benefits not associated directly with learning, for example improvingphysical fitness. Play, as it pertains to humans as a form of learning is central to a child's learning and development. Through play, children learn social skills such as sharing and collaboration. Children develop emotional skills such as learning to deal with the emotion of anger, through play activities. As a form of learning, play also facilitates the development of thinking and language skills in children. There are five types of play: These five types of play are often intersecting. All types of play generate thinking andproblem-solvingskills in children. Children learn to think creatively when they learn through play.Specific activities involved in each type of play change over time as humans progress through the lifespan. Play as a form of learning, can occur solitarily, or involve interacting with others. Enculturationis the process by which people learn values and behaviors that are appropriate or necessary in their surroundingculture.Parents, other adults, and peers shape the individual's understanding of these values.If successful, enculturation results in competence in the language, values, and rituals of the culture.This is different fromacculturation, where a person adopts the values and societal rules of a culture different from their native one. Multiple examples of enculturation can be found cross-culturally. Collaborative practices in the Mazahua people have shown that participation in everyday interaction and later learning activities contributed to enculturation rooted in nonverbal social experience.As the children participated in everyday activities, they learned the cultural significance of these interactions. The collaborative and helpful behaviors exhibited by Mexican and Mexican-heritage children is a cultural practice known as being \"acomedido\".Chillihuani girls in Peru described themselves as weaving constantly, following behavior shown by the other adults. Episodic learningis a change in behavior that occurs as a result of an event.For example, a fear of dogs that follows being bitten by a dog is episodic learning. Episodic learning is so named because events are recorded intoepisodic memory, which is one of the three forms of explicit learning and retrieval, along with perceptual memory andsemantic memory.Episodic memory remembers events and history that are embedded in experience and this is distinguished from semantic memory, which attempts to extract facts out of their experiential contextor – as some describe – a timeless organization of knowledge.For instance, if a person remembers theGrand Canyonfrom a recent visit, it is an episodic memory. He would use semantic memory to answer someone who would ask him information such as where the Grand Canyon is. A study revealed that humans are very accurate in the recognition of episodic memory even without deliberate intention to memorize it.This is said to indicate a very large storage capacity of the brain for things that people pay attention to. Multimedia learningis where a person uses both auditory and visual stimuli to learn information.This type of learning relies ondual-coding theory. Electronic learningor e-learning is computer-enhanced learning. A specific and always more diffused e-learning ismobile learning(m-learning), which uses different mobile telecommunication equipment, such ascellular phones. When a learner interacts with the e-learning environment, it is calledaugmented learning. By adapting to the needs of individuals, the context-driven instruction can be dynamically tailored to the learner's natural environment. Augmented digital content may include text, images, video, audio (music and voice). By personalizing instruction, augmented learning has been shown to improve learning performance for a lifetime.See alsominimally invasive education. Moore (1989)purported that three core types of interaction are necessary for quality, effective online learning: In his theory of transactional distance, Moore (1993)contented that structure and interaction or dialogue bridge the gap in understanding and communication that is created by geographical distances (known as transactional distance). Rote learningismemorizinginformation so that it can berecalledby the learner exactly the way it was read or heard. The major technique used for rote learning islearning by repetition, based on the idea that a learner can recall the material exactly (but not its meaning) if the information is repeatedly processed. Rote learning is used in diverse areas, from mathematics to music to religion. Meaningful learningis the concept that learned knowledge (e.g., a fact) is fully understood to the extent that it relates to other knowledge. To this end, meaningful learning contrasts withrote learningin which information is acquired without regard to understanding. Meaningful learning, on the other hand, implies there is a comprehensive knowledge of the context of the facts learned. Evidence-based learning is the use of evidence from well designed scientific studies to accelerate learning. Evidence-based learning methods such asspaced repetitioncan increase the rate at which a student learns. Formal learningis a deliberate way attaining of knowledge, which takes place within a teacher-student environment, such as in a school system or work environment.The term formal learning has nothing to do with the formality of the learning, but rather the way it is directed and organized. In formal learning, the learning or training departments set out the goals and objectives of the learning and oftentimes learners will be awarded with a diploma, or a type of formal recognition. Non-formal learningis organized learning outside the formal learning system. For example, learning by coming together with people with similar interests and exchanging viewpoints, in clubs or in (international) youth organizations, and workshops. From the organizer's point of reference, non-formal learning does not always need a main objective or learning outcome. From the learner's point of view, non-formal learning, although not focused on outcomes, often results in an intentional learning opportunity. Informal learningis less structured than \"non-formal learning\". It may occur through the experience of day-to-day situations (for example, one would learn to look ahead while walking because of the possible dangers inherent in not paying attention to where one is going). It is learning from life, during a meal at the table with parents, duringplay, and while exploring etc.. For the learner, informal learning is most often an experience of happenstance, and not a deliberately planned experience. Thus this does not require enrollment into any class. Unlike formal learning, informal learning typically does not lead to accreditation.Informal learning begins to unfold as the learner ponders his or her situation. This type of learning does not require a professor of any kind, and learning outcomes are unforeseen following the learning experience. Informal learning is self-directed and because it focuses on day-to-day situations, the value of informal learning can be considered high. As a result, information retrieved from informal learning experiences will likely be applicable to daily life.Children with informal learning can at times yield stronger support than subjects with formal learning in the topic of mathematics.Daily life experiences take place in the workforce, family life, and any other situation that may arise during one's lifetime. Informal learning is voluntary from the learner's viewpoint, and may require making mistakes and learning from them. Informal learning allows the individual to discover coping strategies for difficult emotions that may arise while learning. From the learner's perspective, informal learning can become purposeful, because the learner chooses which rate is appropriate to learn and because this type of learning tends to take place within smaller groups or by oneself. The educational system may use a combination of formal, informal, and nonformal learning methods. The UN and EU recognize these different forms of learning (cf. links below). In some schools, students can get points that count in the formal-learning systems if they get work done in informal-learning circuits. They may be given time to assist international youth workshops and training courses, on the condition they prepare, contribute, share, and can prove this offered valuable new insight, helped to acquire new skills, a place to get experience in organizing,teaching, etc. To learn a skill, such as solving aRubik's Cubequickly, several factors come into play at once: Tangential learningis the process by which peopleself-educateif a topic is exposed to them in a context that they already enjoy. For example, after playing a music-based video game, some people may be motivated to learn how to play a real instrument, or after watching a TV show that references Faust and Lovecraft, some people may be inspired to read the original work.Self-education can be improved with systematization. According to experts in natural learning, self-oriented learning training has proven an effective tool for assisting independent learners with the natural phases of learning. Extra Creditswriter and game designer James Portnow was the first to suggest games as a potential venue for \"tangential learning\".Mozeliuset al.points out that intrinsic integration of learning content seems to be a crucial design factor, and that games that include modules for further self-studies tend to present good results. The built-in encyclopedias in theCivilizationgames are presented as an example – by using these modules gamers can dig deeper for knowledge about historical events in the gameplay. The importance of rules that regulate learning modules and game experience is discussed by Moreno, C.,in a case study about the mobile gameKiwaka. In this game, developed byLandkain collaboration withESAandESO, progress is rewarded with educational content, as opposed to traditionaleducation gameswhere learning activities are rewarded with gameplay. Dialogic learningis a type of learning based on dialogue. Inincidental teachinglearning is not planned by the instructor or the student, it occurs as a byproduct of another activity — an experience, observation, self-reflection, interaction, unique event (e.g. in response to incidents/accidents), or common routine task. This learning happens in addition to or apart from the instructor's plans and the student's expectations. An example of incidental teaching is when the instructor places a train set on top of a cabinet. If the child points or walks towards the cabinet, the instructor prompts the student to say \"train\". Once the student says \"train\", he gets access to the train set. Here are some steps most commonly used in incidental teaching: Incidental learning is an occurrence that is not generally accounted for using the traditional methods of instructional objectives and outcomes assessment. This type of learning occurs in part as a product of social interaction and active involvement in both online and onsite courses. Research implies that some un-assessed aspects of onsite and online learning challenge the equivalency of education between the two modalities. Both onsite and online learning have distinct advantages with traditional on-campus students experiencing higher degrees of incidental learning in three times as many areas as online students. Additional research is called for to investigate the implications of these findings both conceptually and pedagogically. Benjamin Bloomhas suggested three domains of learning inhis taxonomywhich are: These domains are not mutually exclusive. For example, in learning to playchess, the person must learn the rules (cognitive domain)—but must also learn how to set up the chess pieces and how to properly hold and move a chess piece (psychomotor). Furthermore, later in the game the person may even learn to love the game itself, value its applications in life, and appreciate itshistory(affective domain). Transfer of learningis the application of skill, knowledge or understanding to resolve a novel problem or situation that happens when certain conditions are fulfilled. Research indicates that learning transfer is infrequent; most common when \"... cued, primed, and guided...\"and has sought to clarify what it is, and how it might be promoted through instruction. Over the history of its discourse, various hypotheses and definitions have been advanced. First, it is speculated that different types of transfer exist, including: near transfer, the application of skill to solve a novel problem in a similar context; and far transfer, the application of skill to solve a novel problem presented in a different context.Furthermore, Perkins and Salomon (1992) suggest that positive transfer in cases when learning supports novel problem solving, and negative transfer occurs when prior learning inhibits performance on highly correlated tasks, such as second or third-language learning.Concepts of positive and negative transfer have a long history; researchers in the early 20th century described the possibility that \"...habits or mental acts developed by a particular kind of training may inhibit rather than facilitate other mental activities\".Finally, Schwarz, Bransford and Sears (2005) have proposed that transferring knowledge into a situation may differ from transferring knowledge out to a situation as a means to reconcile findings that transfer may both be frequent and challenging to promote. A significant and long research history has also attempted to explicate the conditions under which transfer of learning might occur. Early research by Ruger, for example, found that the \"level of attention\", \"attitudes\", \"method of attack\" (or method for tackling a problem), a \"search for new points of view\", a \"careful testing of hypothesis\" and \"generalization\" were all valuable approaches for promoting transfer.To encourage transfer through teaching, Perkins and Salomon recommend aligning (\"hugging\") instruction with practice and assessment, and \"bridging\", or encouraging learners to reflect on past experiences or make connections between prior knowledge and current content. Certain techniques and factors can affectlong-term retention: Some aspects of intelligence are inherited genetically, so different learners to some degree have different abilities with regard to learning and speed of learning. Problems likemalnutrition,fatigue, and poor physical health can slow learning, as can bad ventilation or poor lighting at home, and unhygienic living conditions. The design, quality, and setting of alearning space, such as a school or classroom, can each be critical to the success of alearning environment. Size, configuration, comfort—fresh air, temperature, light, acoustics, furniture—can all affect a student's learning. The tools used by both instructors and students directly affect how information is conveyed, from the display and writing surfaces (blackboards, markerboards, tack surfaces) to digital technologies. For example, if a room is too crowded, stress levels rise, student attention is reduced, and furniture arrangement is restricted. If furniture is incorrectly arranged, sightlines to the instructor or instructional material are limited and the ability to suit the learning or lesson style is restricted. Aesthetics can also play a role, for if student morale suffers, so does motivation to attend school. Intrinsic motivation, such as a student's own intellectual curiosity or desire to experiment or explore, has been found to sustain learning more effectively than extrinsic motivations such as grades or parental requirements.Rote learninginvolves repetition in order to reinforce facts in memory, but has been criticized as ineffective and \"drill and kill\" since it kills intrinsic motivation.  Alternatives to rote learning includeactive learningandmeaningful learning. The speed, accuracy, and retention, depend uponaptitude,attitude, interest, attention, energy level, andmotivationof the students. Students who answer a question properly or give good results should be praised. This encouragement increases their ability and helps them produce better results. Certain attitudes, such as always finding fault in a student's answer or provoking or embarrassing the student in front of a class are counterproductive. The underlying molecular basis of learning appears to be dynamic changes ingene expressionoccurring inbrainneuronsthat are introduced byepigeneticmechanisms.  Epigenetic regulation of gene expression involves, most notably, chemical modification ofDNAor DNA-associatedhistoneproteins.  These chemical modifications can cause long-lasting changes in gene expression. Epigenetic mechanisms involved in learning include themethylationanddemethylationof neuronal DNA as well asmethylation,acetylation and deacetylation of neuronal histone proteins. During learning, information processing in the brain involves induction ofoxidative modification in neuronal DNAfollowed by the employment ofDNA repairprocesses that introduce epigenetic alterations.  In particular, the DNA repair processes ofnon-homologous end joiningandbase excision repairare employed in learning and memory formation. The nervous system continues to develop during adulthood untilbrain death. For example: Learning is oftenmore efficientinchildrenand takes longer or is more difficult withage. A study usingneuroimagingidentified rapidneurotransmitterGABAboosting as a major potential explanation-component for why that is. Children's brains contain more \"silent synapses\" that are inactiveuntil recruitedas part ofneuroplasticityand flexible learning ormemories.Neuroplasticity is heightened during critical or sensitive periods of brain development, mainly referring to brain development duringchild development. However researchers, after subjecting late middle aged participants to university courses, suggest perceived age differences in learning may be a result of differences in time, support, environment, and attitudes, rather than inherent ability. What humans learn at the early stages, and what they learn to apply, sets humans on course for life or has a disproportional impact.Adults usually have a higher capacity to select what they learn, to what extent and how. For example, children may learnthe given subjects and topics of school curricula via classroom blackboard-transcription handwriting, instead of being able to choose specific topics/skills or jobs to learn and the styles of learning. For instance, children may not have developed consolidated interests, ethics, interest in purpose and meaningful activities, knowledge about real-world requirements and demands, and priorities. Animals gain knowledge in two ways. First is learning—in which an animal gathers information about its environment and uses this information. For example, if an animal eats something that hurts its stomach, it learns not to eat that again. The second is innate knowledge that is genetically inherited. An example of this is when a horse is born and can immediately walk. The horse has not learned this behavior; it simply knows how to do it.In some scenarios,innate knowledgeis more beneficial than learned knowledge. However, in other scenarios the opposite is true—animals must learn certain behaviors when it is disadvantageous to have a specific innate behavior. In these situations, learningevolvesin the species. In a changing environment, an animal must constantly gain new information to survive. However, in a stable environment, this same individual needs to gather the information it needs once, and then rely on it for the rest of its life. Therefore, different scenarios better suit either learning or innate knowledge.\nEssentially, the cost of obtaining certain knowledge versus the benefit of already having it determines whether an animal evolved to learn in a given situation, or whether it innately knew the information. If the cost of gaining the knowledge outweighs the benefit of having it, then the animal does not evolve to learn in this scenario—but instead, non-learning evolves. However, if the benefit of having certain information outweighs the cost of obtaining it, then the animal is far more likely to evolve to have to learn this information. Non-learning is more likely to evolve in two scenarios. If an environment is static and change does not or rarely occurs, then learning is simply unnecessary. Because there is no need for learning in this scenario—and because learning could prove disadvantageous due to the time it took to learn the information—non-learning evolves. Similarly, if an environment is in a constant state of change, learning is also disadvantageous, as anything learned is immediately irrelevant because of the changing environment.The learned information no longer applies. Essentially, the animal would be just as successful if it took a guess as if it learned. In this situation, non-learning evolves. In fact, a study ofDrosophila melanogastershowed that learning can actually lead to a decrease in productivity, possibly because egg-laying behaviors and decisions were impaired by interference from the memories gained from the newly learned materials or because of the cost of energy in learning. However, in environments where change occurs within an animal's lifetime but is not constant, learning is more likely to evolve. Learning is beneficial in these scenarios because an animal canadaptto the new situation, but can still apply the knowledge that it learns for a somewhat extended period of time. Therefore, learning increases the chances of success as opposed to guessing.An example of this is seen in aquatic environments with landscapes subject to change. In these environments, learning is favored because the fish are predisposed to learn the specific spatial cues where they live. In recent years, plant physiologists have examined the physiology of plant behavior andcognition. The concepts of learning and memory are relevant in identifying how plants respond to external cues, a behavior necessary for survival.Monica Gagliano, an Australian professor ofevolutionary ecology, makes an argument for associative learning in the garden pea,Pisum sativum. The garden pea is not specific to a region, but rather grows in cooler, higher altitude climates. Gagliano and colleagues' 2016 paper aims to differentiate between innate phototropism behavior and learned behaviors.Plants use light cues in various ways, such as to sustain their metabolic needs and to maintain their internal circadian rhythms.Circadian rhythmsin plants are modulated by endogenous bioactive substances that encourage leaf-opening and leaf-closing and are the basis of nyctinastic behaviors. Gagliano and colleagues constructed a classical conditioning test in which pea seedlings were divided into two experimental categories and placed in Y-shaped tubes.In a series of training sessions, the plants were exposed to light coming down different arms of the tube. In each case, there was a fan blowing lightly down the tube in either the same or opposite arm as the light. The unconditioned stimulus (US) was the predicted occurrence of light and the conditioned stimulus (CS) was the wind blowing by the fan. Previous experimentation shows that plants respond to light by bending and growing towards it through differential cell growth and division on one side of the plant stem mediated by auxin signaling pathways. During the testing phase of Gagliano's experiment, the pea seedlings were placed in different Y-pipes and exposed to the fan alone. Their direction of growth was subsequently recorded. The 'correct' response by the seedlings was deemed to be growing into the arm where the light was \"predicted\" from the previous day. The majority of plants in both experimental conditions grew in a direction consistent with the predicted location of light based on the position of the fan the previous day.For example, if the seedling was trained with the fan and light coming down the same arm of the Y-pipe, the following day the seedling grew towards the fan in the absence of light cues despite the fan being placed in the opposite side of the Y-arm. Plants in the control group showed no preference to a particular arm of the Y-pipe. The percentage difference in population behavior observed between the control and experimental groups is meant to distinguish innate phototropism behavior from active associative learning. While the physiological mechanism of associative learning in plants is not known, Telewski et al. describes a hypothesis that describes photoreception as the basis of mechano-perception in plants.One mechanism for mechano-perception in plants relies on MS ion channels and calcium channels. Mechanosensory proteins in cell lipid bilayers, known as MS ion channels, are activated once they are physically deformed in response to pressure or tension. Ca2+ permeable ion channels are \"stretch-gated\" and allow for the influx of osmolytes and calcium, a well-known second messenger, into the cell. This ion influx triggers a passive flow of water into the cell down its osmotic gradient, effectively increasing turgor pressure and causing the cell to depolarize.Gagliano hypothesizes that the basis of associative learning inPisum sativumis the coupling of mechanosensory and photosensory pathways and is mediated by auxin signaling pathways. The result is directional growth to maximize a plant's capture of sunlight. Gagliano et al. published another paper on habituation behaviors in theMimosa pudicaplant whereby the innate behavior of the plant was diminished by repeated exposure to a stimulus.There has been controversy around this paper and more generally around the topic of plant cognition. Charles Abrahmson, a psychologist and behavioral biologist, says that part of the issue of why scientists disagree about whether plants have the ability to learn is that researchers do not use a consistent definition of \"learning\" and \"cognition\".Similarly,Michael Pollan, an author, and journalist, says in his pieceThe Intelligent Plantthat researchers do not doubt Gagliano's data but rather her language, specifically her use of the term \"learning\" and \"cognition\" with respect to plants.A direction for future research is testing whether circadian rhythms in plants modulate learning and behavior and surveying researchers' definitions of \"cognition\" and \"learning\". Machine learning, a branch ofartificial intelligence, concerns the construction and study of systems that can learn from data. For example, a machine learning system could be trained on email messages to learn to distinguish between spam and non-spam messages. Most of the Machine Learning models are based on probabilistic theories where each input (e.g. an image ) is associated with a probability to become the desired output.", "metadata": {"url": "https://en.wikipedia.org/wiki/Learning", "title": "Learning", "headings": ["Contents", "Types", "Non-associative learning", "Active learning", "Associative learning", "Play", "Enculturation", "Episodic learning", "Multimedia learning", "E-learning and augmented learning", "Rote learning", "Meaningful learning", "Evidence-based learning", "Formal learning", "Non-formal learning", "Informal learning", "Nonformal learning and combined approaches", "Tangential learning", "Dialogic learning", "Incidental learning", "Domains", "Transfer", "Factors affecting learning", "Instructional techniques", "Genetics", "Socioeconomic and physical conditions", "Psychological factors", "Epigenetic factors", "General cognition-related factors", "Adult learning vs children's learning", "In animal evolution", "Costs and benefits of learned and innate knowledge", "In plants", "Machine learning", "See also", "Information theory", "Types of education", "References", "Notes", "Further reading", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Learning", "https://en.wikipedia.org/wiki/Learning", "https://en.wikipedia.org/wiki/Learning", "https://en.wikipedia.org/wiki/Learning_(album)", "https://en.wikipedia.org/wiki/Learn_(disambiguation)", "https://en.wikipedia.org/wiki/Learned_(disambiguation)", "https://en.wikipedia.org/wiki/Learners_(film)", "https://en.wikipedia.org/wiki/Sushi"]}},
{"id": "618d0ff3850e", "content": "Human intelligenceis theintellectualcapability ofhumans, which is marked by complexcognitivefeats and high levels ofmotivationandself-awareness. Using theirintelligence, humans are able tolearn,form concepts,understand, and applylogicandreason. Human intelligence is also thought to encompass their capacities torecognize patterns,plan,innovate,solve problems,make decisions,retain information, and uselanguagetocommunicate. There are conflicting ideas about how intelligence should be conceptualized and measured. Inpsychometrics, human intelligence is commonly assessed byintelligence quotient(IQ) tests, although thevalidityof these tests is disputed. Several subcategories of intelligence, such asemotional intelligenceandsocial intelligence, have been proposed, and there remains significant debate as to whether these represent distinct forms of intelligence. There is also ongoing debate regarding how an individual's level of intelligence is formed, ranging from the idea that intelligence is fixed at birth to the idea that it is malleable and can change depending on a person's mindset and efforts. As a construct and as measured byintelligence tests, intelligence is one of the most useful concepts inpsychology, because it correlates with many relevant variables, for instance the probability of suffering an accident, or the amount of one's salary.Other examples include: According to a 2018metastudyof educational effects on intelligence, education appears to be the \"most consistent, robust, and durable method\" known for raising intelligence. Inpsychology, human intelligence is commonly assessed byIQ scoresthat are determined by IQ tests. In general, higher IQ scores are associated with better outcomes in life.However, while IQ test scores show a high degree of inter-testreliability, and predict certain forms of achievement effectively, theirconstruct validityas a holistic measure of human intelligence is considered dubious.While IQ tests are generally understood to measure some forms of intelligence, they may fail to serve as an accurate measure of broader definitions of human intelligence inclusive ofcreativityandsocial intelligence.According to psychologist Wayne Weiten, \"IQ tests are valid measures of the kind of intelligence necessary to do well in academic work. But if the purpose is to assess intelligence in a broader sense, the validity of IQ tests is questionable.\" Howard Gardner'stheory of multiple intelligencesis based on studies of normal children and adults, of gifted individuals (including so-called \"savants\"), of persons who have suffered brain damage, of experts andvirtuosos, and of individuals from diverse cultures. Gardner breaks intelligence down into components. In the first edition of his bookFrames of Mind(1983), he described seven distinct types of intelligence: logical-mathematical,linguistic,spatial, musical,kinesthetic,interpersonal, andintrapersonal. In a second edition, he added two more types of intelligence: naturalist and existential intelligences.He argues thatpsychometric(IQ) tests address only linguistic and logical plus some aspects of spatial intelligence.A criticism of Gardner's theory is that it has never been tested, or subjected to peer review, by Gardner or anyone else, and indeed that it isunfalsifiable.Others (e.g. Locke, 2005) suggest that recognizing many specific forms of intelligence (specific aptitude theory) implies a political—rather than scientific—agenda, intended to appreciate the uniqueness in all individuals, rather than recognizing potentially true and meaningful differences in individual capacities. Schmidt and Huntersuggest that the predictive validity of specific aptitudes over and above that of general mental ability, or\"g\", has not received empirical support. On the other hand,Jerome Bruneragreed with Gardner that the intelligences were \"useful fictions\", and went on to state that \"his approach is so far beyond the data-crunching of mental testers that it deserves to be cheered.\" Robert Sternbergproposed thetriarchic theory of intelligenceto provide a more comprehensive description of intellectual competence than traditional differential or cognitive theories of human ability.The triarchic theory describes three fundamental aspects of intelligence: The triarchic theory does not argue against the validity of a general intelligence factor; instead, the theory posits that general intelligence is part of analytic intelligence, and only by considering all three aspects of intelligence can the full range of intellectual functioning be understood. Sternberg updated the triarchic theory and renamed it to the Theory of Successful Intelligence.He now defines intelligence as an individual's assessment of success in life by the individual's own (idiographic) standards and within the individual's sociocultural context. Success is achieved by using combinations of analytical, creative, and practical intelligence. The three aspects of intelligence are referred to as processing skills. The processing skills are applied to the pursuit of success through what were the three elements of practical intelligence: adapting to, shaping of, and selecting of one's environments. The mechanisms that employ the processing skills to achieve success include utilizing one's strengths and compensating or correcting for one's weaknesses. Sternberg's theories and research on intelligence remain contentious within the scientific community. Based onA. R. Luria's (1966) seminal work on the modularization of brain function,and supported by decades of neuroimaging research, thePASS Theory of Intelligence(Planning/Attention/Simultaneous/Successive) proposes that cognition is organized in three systems and the following four processes: These four processes are functions of four areas of the brain. Planning is broadly located in the front part of our brains, the frontal lobe. Attention and arousal are combined functions of the frontal lobe and the lower parts of the cortex, although the parietal lobes are also involved in attention as well. Simultaneous processing and Successive processing occur in the posterior region or the back of the brain. Simultaneous processing is broadly associated with the occipital and the parietal lobes while Successive processing is broadly associated with the frontal-temporal lobes. The PASS theory is heavily indebted both to Luriaand to studies in cognitive psychology involved in promoting a better look at intelligence. InPiaget's theory of cognitive developmentthe focus is not on mental abilities but rather on a child's mental models of the world. As a child develops, the child creates increasingly more accurate models of the world which enable the child to interact with the world more effectively. One example isobject permanencewith which the child develops a model in which objects continue to exist even when they cannot be seen, heard, or touched. Piaget's theory described four main stages and many sub-stages in the development. These four main stages are: Progress through these stages is correlated with, but not identical to psychometric IQ.Piaget conceptualizes intelligence as an activity more than as a capacity. One of Piaget's most famous studies focused purely on the discriminative abilities of children between the ages of two and a half years old, and four and a half years old. He began the study by taking children of different ages and placing two lines of sweets, one with the sweets in a line spread further apart, and one with the same number of sweets in a line placed more closely together. He found that, \"Children between 2 years, 6 months old and 3 years, 2 months old correctly discriminate the relative number of objects in two rows; between 3 years, 2 months and 4 years, 6 months they indicate a longer row with fewer objects to have 'more'; after 4 years, 6 months they again discriminate correctly\".Initially younger children were not studied, because if at the age of four years a child could not conserve quantity, then a younger child presumably could not either. The results show however that children that are younger than three years and two months have quantity conservation, but as they get older they lose this quality, and do not recover it until four and a half years old. This attribute may be lost temporarily because of an overdependence on perceptual strategies, which correlates more candy with a longer line of candy, or because of the inability for a four-year-old to reverse situations. This experiment demonstrated several results. First, younger children have a discriminative ability that shows the logical capacity for cognitive operations exists earlier than previously acknowledged. Also, young children can be equipped with certain qualities for cognitive operations, depending on how logical the structure of the task is. Research also shows that children develop explicit understanding at age five and as a result, the child will count the sweets to decide which has more. Finally the study found that overall quantity conservation is not a basic characteristic of humans' native inheritance. Piaget's theory has been criticized on the grounds that the age of appearance of a new model of the world, such as object permanence, is dependent on how the testing is done (see the article onobject permanence). More generally, the theory may be very difficult to test empirically because of the difficulty of proving or disproving that a mental model is the explanation for the results of the testing. Neo-Piagetian theories of cognitive developmentexpand Piaget's theory in various ways such as also considering psychometric-like factors such as processing speed and working memory, \"hypercognitive\" factors like self-monitoring, more stages, and more consideration on how progress may vary in different domains such as spatial or social. Based on a review of 37neuroimagingstudies, Jung and Haier proposed that the biological basis of intelligence stems from how well thefrontalandparietalregions of the brain communicate and exchange information with each other.Subsequent neuroimaging and lesion studies report general consensus with the theory.A review of the neuroscience and intelligence literature concludes that the parieto-frontal integration theory is the best available explanation for human intelligence differences. Based on theCattell–Horn–Carroll theory, the tests of intelligence most often used in therelevantstudies include measures offluid ability (gf) and crystallized ability (gc); that differ in their trajectory of development in people.The \"investment theory\" by Cattellstates that theindividual differencesobserved in the procurement of skills and knowledge (gc) are partially attributed to the \"investment\" ofgf, thus suggesting the involvement offluid intelligencein every aspect of the learning process.The investment theory suggests that personality traits affect \"actual\" ability, and not scores on anIQtest. Hebb's theory of intelligence suggested a bifurcation as well, Intelligence A (physiological), that could be seen as a semblance offluid intelligenceand Intelligence B (experiential), similar tocrystallized intelligence. The intelligence compensation theorystates that individuals who are comparatively less intelligent work harder and more methodically, and become more resolute and thorough (more conscientious) in order to achieve goals, to compensate for their \"lack of intelligence\" whereas more intelligent individuals do not require traits/behaviours associated with the personality factorconscientiousnessto progress as they can rely on the strength of their cognitive abilities as opposed to structure or effort.The theory suggests the existence of a causal relationship between intelligence and conscientiousness, such that the development of the personality trait of conscientiousness is influenced by intelligence. This assumption is deemed plausible as it is unlikely that the reverse causal relationship could occur;implying that the negative correlation would be higher betweenfluid intelligence(gf) and conscientiousness. This is justified by the timeline of development ofgf,gc, and personality, ascrystallized intelligencewould not have developed completely when personality traits develop. Subsequently, during school-going ages, more conscientious children would be expected to gain more crystallized intelligence (knowledge) through education, as they would be more efficient, thorough, hard-working, and dutiful. This theory has recently been contradicted by evidence that identifiescompensatory sample selectionwhich attributes the findings to the bias that comes from selecting samples containing people above a certain threshold of achievement. The view of cognitive ability has evolved over the years, andit is no longer viewed as a fixed property held by an individual. Instead, the current perspective describes it as a general capacity, comprising not only cognitive, but motivational, social, and behavioural aspects as well. These facets work together to perform numerous tasks. An essential skill often overlooked is that of managing emotions and aversive experiences that can compromise one's quality of thought and activity. Bandura bridges the link between intelligence and success by crediting individual differences inself-efficacy. Bandura's theory identifies the difference between possessing skills and being able to apply them in challenging situations. The theory suggests that individuals with the same level of knowledge and skill may perform badly, averagely, or excellently based on differences in self-efficacy. A key role of cognition is to allow for one to predict events and in turn devise methods to deal with these events effectively. These skills are dependent on processing of unclear and ambiguous stimuli. People must be able to rely on their reserve of knowledge to identify, develop, and execute options. They must be able to apply the learning acquired from previous experiences. Thus, a stable sense of self-efficacy is essential to stay focused on tasks in the face of challenging situations. Bandura's theory of self-efficacy and intelligence suggests that individuals with a relatively low sense of self-efficacy in any field will avoid challenges. This effect is heightened when they perceive the situations aspersonal threats. When failure occurs, they recover from it more slowly than others, and credit the failure to an insufficient aptitude. On the other hand, persons with high levels of self-efficacy holda task-diagnostic aimthat leads to effective performance. Developed by Ackerman, the PPIK (process, personality, intelligence, and knowledge) theory further develops the approach on intelligence as proposed by Cattell, theInvestment theory, andHebb, suggesting a distinction betweenintelligence as knowledgeandintelligence as process(two concepts that are comparable and related togcandgfrespectively, but broader and closer to Hebb's notions of \"Intelligence A\" and \"Intelligence B\") and integrating these factors with elements such as personality, motivation, and interests. Ackerman describes the difficulty of distinguishing process from knowledge, as content cannot be eliminated from any ability test. Personality traits are not significantly correlated with theintelligence as processaspect except in the context of psychopathology. One exception to this generalization has been the finding ofsex differencesin cognitive abilities, specifically abilities in mathematical and spatial form. On the other hand, theintelligence as knowledgefactor has been associated with personality traits of Openness and Typical Intellectual Engagement,which also strongly correlate with verbal abilities (associated withcrystallized intelligence). It appears thatLatent inhibition, the phenomenon of familiar stimuli having a postponed reaction time when compared with unfamiliar stimuli, has a positive correlation withcreativity. Because intelligence appears to be at least partly dependent on brain structure and the genes shaping brain development, it has been proposed thatgenetic engineeringcould be used to enhance intelligence, a process sometimes calledbiological upliftinscience fiction. Genetic enhancement experiments on mice have demonstrated superior ability in learning and memory in various behavioral tasks. Higher IQ leads to greater success in education,but independently, education raises IQ scores.A 2017 meta-analysis suggests education increases IQ by 1–5 points per year of education, or at least increases IQ test-taking ability. Substances which actually or purportedly improve intelligence or other mental functions are callednootropics. A meta analysis showsomega-3 fatty acidsimprove cognitive performance among those with cognitive deficits, but not among healthy subjects.A meta-regression shows omega-3 fatty acids improve themoodsof patients with major depression (major depression is associated with cognitive nutrient deficits). There is research and development about the cognitive impacts ofsmartphonesand digital technology. Some educators and experts have raised some concerns about how technology may negatively affect students' thinking abilities and academic performance. Attempts to raise IQ withbrain traininghave led to increases on aspects related with the training tasks – for instanceworking memory– but it is yet unclear if these increases generalize to increased intelligence per se. A 2008 research paper claimed that practicing a dualn-backtask can increasefluid intelligence(gf), as measured in several different standard tests.This finding received some attention from popular media, including an article inWired.However, a subsequent criticism of the paper's methodology questioned the experiment's validity and took issue with the lack of uniformity in the tests used to evaluate the control and test groups.For example, the progressive nature ofRaven's Advanced Progressive Matrices(APM) test may have been compromised by modifications of time restrictions (i.e., 10 minutes were allowed to complete a normally 45-minute test). Efforts to influence intelligence raise ethical issues.Neuroethicsconsiders the ethical, legal, and social implications of neuroscience, and deals with issues such as the difference between treating a humanneurologicaldisease and enhancing the human brain, and how wealth impacts access toneurotechnology. Neuroethical issues interact with the ethics ofhuman genetic engineering. Transhumanisttheorists study the possibilities and consequences of developing and using techniques to enhance human abilities and aptitudes. Eugenicsis a social philosophy that advocates the improvement of human hereditary traits through various forms of intervention.Eugenics has variously been regarded as meritorious or deplorable in different periods of history, falling greatly into disrepute after the defeat ofNazi GermanyinWorld War II. The approach to understanding intelligence with the most supporters and published research over the longest period of time is based onpsychometrictesting. It is also by far the most widely used in practical settings.Intelligence quotient(IQ) tests include theStanford-Binet,Raven's Progressive Matrices, theWechsler Adult Intelligence Scaleand theKaufman Assessment Battery for Children. There are also psychometric tests that are not intended to measure intelligence itself but some closely related construct such as scholastic aptitude. In the United States examples include theSSAT, theSAT, theACT, theGRE, theMCAT, theLSAT, and theGMAT.Regardless of the method used, almost any test that requires examinees to reason and has a wide range of question difficulty will produce intelligence scores that are approximatelynormally distributedin the general population. Intelligence tests are widely used in educational,business, and military settings because of their efficacy in predicting behavior. IQ andg(discussed in the next section) are correlated with many important social outcomes—individuals with low IQs are more likely to be divorced, have a child out of marriage, be incarcerated, and need long-term welfare support, while individuals with high IQs are associated with more years of education, higher status jobs and higher income.Intelligence as measured by Psychometric tests has been found to be highly correlated with successful training and performance outcomes (e.g., adaptive performance),and IQ/gis the single best predictor of successful job performance; however, some researchers although largely concurring with this finding have advised caution in citing the strength of the claim due to a number of factors, these include: statistical assumptions imposed underlying some of these studies, studies done prior to 1970 which appear inconsistent with more recent studies, and ongoing debates within the Psychology literature as to the validity of current IQ measurement tools. There are many different kinds of IQ tests using a wide variety of test tasks. Some tests consist of a single type of task, others rely on a broad collection of tasks with different contents (visual-spatial,verbal, numerical) and asking for different cognitive processes (e.g., reasoning, memory, rapid decisions, visual comparisons, spatial imagery, reading, and retrieval ofgeneral knowledge). The psychologistCharles Spearmanearly in the 20th century carried out the first formalfactor analysisofcorrelationsbetween various test tasks. He found a trend for all such tests to correlate positively with each other, which is called apositive manifold. Spearman found that a single common factor explained the positive correlations among tests. Spearman named itgfor \"general intelligence factor\". He interpreted it as the core of human intelligence that, to a larger or smaller degree, influences success in all cognitive tasks and thereby creates the positive manifold. This interpretation ofgas a common cause of test performance is still dominant in psychometrics. (Although, an alternative interpretation was recently advanced by van der Maas and colleagues.Theirmutualism modelassumes that intelligence depends on several independent mechanisms, none of which influences performance on all cognitive tests. These mechanisms support each other so that efficient operation of one of them makes efficient operation of the others more likely, thereby creating the positive manifold.) IQ tests can be ranked by how highly they load on thegfactor. Tests with highg-loadings are those that correlate highly with most other tests. One comprehensive study investigating the correlations between a large collection of tests and taskshas found that theRaven's Progressive Matriceshave a particularly high correlation with most other tests and tasks. TheRaven'sis a test of inductive reasoning with abstract visual material. It consists of a series of problems, sorted approximately by increasing difficulty. Each problem presents a 3 x 3 matrix of abstract designs with one empty cell; the matrix is constructed according to a rule, and the person must find out the rule to determine which of 8 alternatives fits into the empty cell. Because of its high correlation with other tests, the Raven's Progressive Matrices are generally acknowledged as a good indicator of general intelligence. This is problematic, however, because there are substantial gender differences on theRaven's,which are not found whengis measured directly by computing the general factor from a broad collection of tests. Several critics, such asStephen Jay Gould, have been critical ofg, seeing it as a statistical artifact, and that IQ tests instead measure a number of unrelated abilities.The 1995 American Psychological Association's report \"Intelligence: Knowns and Unknowns\" stated that IQ tests do correlate and that the view thatgis a statistical artifact was a minority one. A recent scientific understanding of collective intelligence, defined as a group's general ability to perform a wide range of tasks,expands the areas of human intelligence research applying similar methods and concepts to groups. Definition, operationalization and methods are similar to the psychometric approach of general individual intelligence where an individual's performance on a given set of cognitive tasks is used to measure intelligence indicated by thegeneral intelligence factorgextracted via factor analysis.In the same vein, collective intelligence research aims to discover acfactor' explaining between-group differences in performance as well as structural and group compositional causes for it. Several different theories of intelligence have historically been important forpsychometrics. Often they emphasized more factors than a single one like ing factor. Many of the broad, recent IQ tests have been greatly influenced by theCattell–Horn–Carroll theory. It is argued to reflect much of what is known about intelligence from research. A hierarchy of factors for human intelligence is used.gis at the top. Under it there are 10 broad abilities that in turn are subdivided into 70 narrow abilities. The broad abilities are: Modern tests do not necessarily measure of all of these broad abilities. For example, Gq and Grw may be seen as measures of school achievement and not IQ.Gt may be difficult to measure without special equipment. gwas earlier often subdivided into only Gf and Gc which were thought to correspond to the nonverbal or performance subtests and verbal subtests in earlier versions of the popular Wechsler IQ test. More recent research has shown the situation to be more complex. Reliability and validity are very different concepts. While reliability reflects reproducibility, validity refers to whether the test measures what it purports to measure.While IQ tests are generally considered to measure some forms of intelligence, they may fail to serve as an accurate measure of broader definitions of human intelligence inclusive of, for example,creativityandsocial intelligence. For this reason, psychologist Wayne Weiten argues that theirconstruct validitymust be carefully qualified, and not be overstated.According to Weiten, \"IQ tests are valid measures of the kind of intelligence necessary to do well in academic work. But if the purpose is to assess intelligence in a broader sense, the validity of IQ tests is questionable.\" Along these same lines, critics such asKeith Stanovichdo not dispute the capacity of IQ test scores to predict some kinds of achievement, but argue that basing a concept of intelligence on IQ test scores alone neglects other important aspects of mental ability.Robert Sternberg, another significant critic of IQ as the main measure of human cognitive abilities, argued that reducing the concept of intelligence to the measure ofgdoes not fully account for the different skills and knowledge types that produce success in human society. A study suggested that intelligence is composed of distinct cognitive systems, each of which having its own capacity and being (to some degree) independent of other components, with the cognitive profile being emergent fromanatomicallydistinct cognitive systems (such as brain regions or neural networks).For example, IQ and reading-/language-related traits/skillsappear to beinfluenced\"at least partly [by] distinct genetic factors\". Various types of potential measures related to some definitions of intelligence but not part of IQ measurement include: Psychologistshave shown that the definition of human intelligence is unique to the culture that one is studying.Robert Sternbergis among the researchers who have discussed how one's culture affects the person's interpretation of intelligence, and he further believes that to define intelligence in only one way without considering different meanings in cultural contexts may cast an investigative and unintentionally egocentric view on the world. To negate this, psychologists offer the following definitions of intelligence: Although typically identified by its western definition, multiple studies support the idea that human intelligence carries different meanings across cultures around the world. In many Eastern cultures, intelligence is mainly related with one's social roles and responsibilities. A Chinese conception of intelligence would define it as the ability to empathize with and understand others — although this is by no means the only way that intelligence is defined inChina.\nIn several African communities, intelligence is shown similarly through a social lens. However, rather than through social roles, as in many Eastern cultures, it is exemplified through social responsibilities. For example, in the language of Chi-Chewa, which is spoken by some ten million people across centralAfrica, the equivalent term for intelligence implies not only cleverness but also the ability to take on responsibility. Furthermore, within American culture there are a variety of interpretations of intelligence present as well. One of the most common views on intelligence within American societies defines it as a combination of problem-solving skills,deductive reasoningskills, andIntelligence quotient(IQ), while other American societies point out that intelligent people should have asocial conscience, accept others for who they are, and be able to give advice orwisdom. Motivational intelligence refers to an individual's capacity to comprehend and utilize various motivations, such as the need for achievement, affiliation, or power. It involves understanding tacit knowledge related to these motivations. This concept encompasses the ability to recognize and appreciate the diverse values, behaviors, and cultural differences of others, driven by intrinsic interest rather than solely to enhance interaction effectiveness. Research suggests a relationship between motivational intelligence, international experiences, and leadership. Individuals with higher levels of motivational intelligence tend to exhibit greater enthusiasm for learning about other cultures, thereby contributing to their effectiveness in cross-cultural settings. However, studies have also revealed variations in motivational intelligence across ethnicities, with Asian students demonstrating higher cognitive cultural intelligence but lower motivational intelligence compared to other groups. Investigations have explored the impact of motivational intelligence on job motivation. A study conducted on employees of Isfahan Gas Company indicated a positive and significant relationship between motivational intelligence and two of its indicators, namely adaptability and social relationship, with job motivation. These findings highlight the potential influence of motivational intelligence on individuals' motivation levels within work contexts. Motivational intelligence has been identified as a strong predictor, superseding knowledge intelligence,behavioral intelligence, and strategic intelligence. It holds a crucial role in promoting cooperation, which is considered the ideal and essential element of motivational intelligence.\nTherapeutic approaches grounded in motivational intelligence emphasize a collaborative partnership between the therapist and client. The therapist creates an environment conducive to change without imposing their views or attempting to force awareness or acceptance of reality onto the client. Motivational intelligence encompasses the understanding of motivations, such as achievement, affiliation, and power, as well as the appreciation of cultural differences and values. It has been found to impact areas such as international experiences, leadership, job motivation, and cooperative therapeutic interventions.", "metadata": {"url": "https://en.wikipedia.org/wiki/Human_intelligence", "title": "Human intelligence", "headings": ["Contents", "History", "Correlates", "Theories", "Relevance of IQ tests", "Theory of multiple intelligences", "Triarchic theory of intelligence", "PASS theory of intelligence", "Piaget's theory and Neo-Piagetian theories", "Parieto-frontal integration theory of intelligence", "Investment theory", "Intelligence compensation theory (ICT)", "Bandura's theory of self-efficacy and cognition", "Process, personality, intelligence and knowledge theory (PPIK)", "Latent inhibition", "Improving", "Genetic engineering", "Education", "Nutrition and chemicals", "Activities and adult neural development", "Digital tools", "Brain training", "Philosophy", "Measuring", "General intelligence factor org", "General collective intelligence factor orc", "Historical psychometric theories", "Cattell–Horn–Carroll theory", "Insufficiency of measurement via IQ", "Intelligence across cultures", "Motivational intelligence", "See also", "References", "Sources", "Further reading"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Human_intelligence", "https://en.wikipedia.org/wiki/Human_intelligence", "https://en.wikipedia.org/wiki/Human_intelligence", "https://en.wikipedia.org/wiki/Human_intelligence_(espionage)", "https://en.wikipedia.org/wiki/Psychology", "https://en.wikipedia.org/wiki/Outline_of_psychology", "https://en.wikipedia.org/wiki/History_of_psychology", "https://en.wikipedia.org/wiki/Subfields_of_psychology"]}},
{"id": "90ce149db23a", "content": " Acomputeris amachinethat can beprogrammedto automaticallycarry outsequences ofarithmeticorlogical operations(computation). Moderndigital electroniccomputers can perform generic sets of operations known asprograms, which enable computers to perform a wide range of tasks. The termcomputer systemmay refer to a nominally complete computer that includes thehardware,operating system,software, andperipheralequipment needed and used for full operation; or to a group of computers that are linked and function together, such as acomputer networkorcomputer cluster. A broad range ofindustrialandconsumer productsuse computers ascontrol systems, including simple special-purpose devices likemicrowave ovensandremote controls, and factory devices likeindustrial robots. Computers are at the core of general-purpose devices such aspersonal computersandmobile devicessuch assmartphones. Computers power theInternet, which links billions of computers and users. Early computers were meant to be used only forcalculations. Simple manual instruments like theabacushave aided people in doing calculations since ancient times. Early in theIndustrial Revolution, some mechanical devices were built to automate long, tedious tasks, such as guiding patterns forlooms. More sophisticated electrical machines did specializedanalogcalculations in the early 20th century. The firstdigitalelectronic calculating machines were developed duringWorld War II, bothelectromechanicaland usingthermionic valves. The firstsemiconductortransistorsin the late 1940s were followed by thesilicon-basedMOSFET(MOS transistor) andmonolithic integrated circuitchip technologies in the late 1950s, leading to themicroprocessorand themicrocomputer revolutionin the 1970s. The speed, power, and versatility of computers have been increasing dramatically ever since then, withtransistor countsincreasing at a rapid pace (Moore's lawnoted that counts doubled every two years), leading to theDigital Revolutionduring the late 20th and early 21st centuries. Conventionally, a modern computer consists of at least oneprocessing element, typically acentral processing unit(CPU) in the form of amicroprocessor, together with some type ofcomputer memory, typicallysemiconductor memorychips. The processing element carries out arithmetic and logical operations, and a sequencing and control unit can change the order of operations in response to storedinformation. Peripheral devices include input devices (keyboards,mice,joysticks, etc.), output devices (monitors,printers, etc.), andinput/output devicesthat perform both functions (e.g.touchscreens). Peripheral devices allow information to be retrieved from an external source, and they enable the results of operations to be saved and retrieved. It was not until the mid-20th century that the word acquired its modern definition; according to theOxford English Dictionary, the first known use of the wordcomputerwas in a different sense, in a 1613 book calledThe Yong Mans Gleaningsby the English writerRichard Brathwait: \"I haue  [sic] read the truest computer of Times, and the best Arithmetician that euer  [sic] breathed, and he reduceth thy dayes into a short number.\" This usage of the term referred to ahuman computer, a person who carried out calculations orcomputations. The word continued to have the same meaning until the middle of the 20th century. During the latter part of this period, women were often hired as computers because they could be paid less than their male counterparts.By 1943, most human computers were women. TheOnline Etymology Dictionarygives the first attested use ofcomputerin the 1640s, meaning 'one who calculates'; this is an \"agent noun from compute (v.)\". TheOnline Etymology Dictionarystates that the use of the term to mean\"'calculating machine' (of any type) is from 1897.\" TheOnline Etymology Dictionaryindicates that the \"modern use\" of the term, to mean 'programmable digital electronic computer' dates from \"1945 under this name; [in a] theoretical [sense] from 1937, asTuring machine\".The name has remained, although modern computers are capable of many higher-level functions. Devices have been used to aid computation for thousands of years, mostly usingone-to-one correspondencewithfingers. The earliest counting device was most likely a form oftally stick. Later record keeping aids throughout theFertile Crescentincluded calculi (clay spheres, cones, etc.) which represented counts of items, likely livestock or grains, sealed in hollow unbaked clay containers.The use ofcounting rodsis one example. Theabacuswas initially used for arithmetic tasks. TheRoman abacuswas developed from devices used inBabyloniaas early as 2400 BCE. Since then, many other forms of reckoning boards or tables have been invented. In a medieval Europeancounting house, a checkered cloth would be placed on a table, and markers moved around on it according to certain rules, as an aid to calculating sums of money. TheAntikythera mechanismis believed to be the earliest known mechanicalanalog computer, according toDerek J. de Solla Price.It was designed to calculate astronomical positions. It was discovered in 1901 in theAntikythera wreckoff the Greek island ofAntikythera, betweenKytheraandCrete, and has been dated to approximatelyc.100 BCE. Devices of comparable complexity to the Antikythera mechanism would not reappear until the fourteenth century. Many mechanical aids to calculation and measurement were constructed for astronomical and navigation use. Theplanispherewas astar chartinvented byAbū Rayhān al-Bīrūnīin the early 11th century.Theastrolabewas invented in theHellenistic worldin either the 1st or 2nd centuries BCE and is often attributed toHipparchus. A combination of theplanisphereanddioptra, the astrolabe was effectively an analog computer capable of working out several different kinds of problems inspherical astronomy. An astrolabe incorporating a mechanicalcalendarcomputerandgear-wheels was invented by Abi Bakr ofIsfahan,Persiain 1235.Abū Rayhān al-Bīrūnī invented the first mechanical gearedlunisolar calendarastrolabe,an early fixed-wiredknowledge processing machinewith agear trainand gear-wheels,c.1000 AD. Thesector, a calculating instrument used for solving problems in proportion,trigonometry, multiplication and division, and for various functions, such as squares and cube roots, was developed in the late 16th century and found application in gunnery, surveying and navigation. Theplanimeterwas a manual instrument to calculate the area of a closed figure by tracing over it with a mechanical linkage. Theslide rulewas invented around 1620–1630, by the English clergymanWilliam Oughtred, shortly after the publication of the concept of thelogarithm. It is a hand-operated analog computer for doing multiplication and division. As slide rule development progressed, added scales provided reciprocals, squares and square roots, cubes and cube roots, as well astranscendental functionssuch as logarithms and exponentials, circular andhyperbolictrigonometry and otherfunctions. Slide rules with special scales are still used for quick performance of routine calculations, such as theE6Bcircular slide rule used for time and distance calculations on light aircraft. In the 1770s,Pierre Jaquet-Droz, a Swisswatchmaker, built a mechanical doll (automaton) that could write holding a quill pen. By switching the number and order of its internal wheels different letters, and hence different messages, could be produced. In effect, it could be mechanically \"programmed\" to read instructions. Along with two other complex machines, the doll is at the Musée d'Art et d'Histoire ofNeuchâtel,Switzerland, and still operates. In 1831–1835, mathematician and engineerGiovanni Planadevised aPerpetual Calendar machine, which through a system of pulleys and cylinders could predict theperpetual calendarfor every year from 0 CE (that is, 1 BCE) to 4000 CE, keeping track of leap years and varying day length. Thetide-predicting machineinvented by the Scottish scientistSir William Thomsonin 1872 was of great utility to navigation in shallow waters. It used a system of pulleys and wires to automatically calculate predicted tide levels for a set period at a particular location. Thedifferential analyser, a mechanical analog computer designed to solvedifferential equationsbyintegration, used wheel-and-disc mechanisms to perform the integration. In 1876, Sir William Thomson had already discussed the possible construction of such calculators, but he had been stymied by the limited output torque of theball-and-disk integrators.In a differential analyzer, the output of one integrator drove the input of the next integrator, or a graphing output. Thetorque amplifierwas the advance that allowed these machines to work. Starting in the 1920s,Vannevar Bushand others developed mechanical differential analyzers. In the 1890s, the Spanish engineerLeonardo Torres Quevedobegan to develop a series of advancedanalog machinesthat could solve real and complex roots ofpolynomials,which were published in 1901 by theParis Academy of Sciences. Charles Babbage, an English mechanical engineer andpolymath, originated the concept of a programmable computer. Considered the \"father of the computer\",he conceptualized and invented the firstmechanical computerin the early 19th century. After working on hisdifference enginehe announced his invention in 1822, in a paper to theRoyal Astronomical Society, titled \"Note on the application of machinery to the computation of astronomical and mathematical tables\".He also designed to aid in navigational calculations, in 1833 he realized that a much more general design, ananalytical engine, was possible. The input of programs and data was to be provided to the machine viapunched cards, a method being used at the time to direct mechanicalloomssuch as theJacquard loom. For output, the machine would have aprinter, a curve plotter and a bell. The machine would also be able to punch numbers onto cards to be read in later. The engine would incorporate anarithmetic logic unit,control flowin the form ofconditional branchingandloops, and integratedmemory, making it the first design for a general-purpose computer that could be described in modern terms asTuring-complete. The machine was about a century ahead of its time. All the parts for his machine had to be made by hand – this was a major problem for a device with thousands of parts. Eventually, the project was dissolved with the decision of theBritish Governmentto cease funding. Babbage's failure to complete the analytical engine can be chiefly attributed to political and financial difficulties as well as his desire to develop an increasingly sophisticated computer and to move ahead faster than anyone else could follow. Nevertheless, his son,Henry Babbage, completed a simplified version of the analytical engine's computing unit (themill) in 1888. He gave a successful demonstration of its use in computing tables in 1906. In his workEssays on Automaticspublished in 1914,Leonardo Torres Quevedowrote a brief history of Babbage's efforts at constructing a mechanical Difference Engine and Analytical Engine. The paper contains a design of a machine capable to calculate formulas likeax(y−z)2{\\displaystyle a^{x}(y-z)^{2}}, for a sequence of sets of values. The whole machine was to be controlled by aread-onlyprogram, which was complete with provisions forconditional branching. He also introduced the idea offloating-point arithmetic.In 1920, to celebrate the 100th anniversary of the invention of thearithmometer, Torres presented in Paris the Electromechanical Arithmometer, which allowed a user to input arithmetic problems through akeyboard, and computed and printed the results,demonstrating the feasibility of an electromechanical analytical engine. During the first half of the 20th century, many scientificcomputingneeds were met by increasingly sophisticated analog computers, which used a direct mechanical or electrical model of the problem as a basis forcomputation. However, these were not programmable and generally lacked the versatility and accuracy of modern digital computers.The first modern analog computer was atide-predicting machine, invented bySir William Thomson(later to become Lord Kelvin) in 1872. Thedifferential analyser, a mechanical analog computer designed to solve differential equations by integration using wheel-and-disc mechanisms, was conceptualized in 1876 byJames Thomson, the elder brother of the more famous Sir William Thomson. The art of mechanical analog computing reached its zenith with thedifferential analyzer, completed in 1931 byVannevar BushatMIT.By the 1950s, the success of digital electronic computers had spelled the end for most analog computing machines, but analog computers remained in use during the 1950s in some specialized applications such as education (slide rule) and aircraft (control systems). Claude Shannon's 1937master's thesislaid the foundations of digital computing, with his insight of applying Boolean algebra to the analysis and synthesis of switching circuits being the basic concept which underlies all electronic digital computers. By 1938, theUnited States Navyhad developed theTorpedo Data Computer, an electromechanical analog computer forsubmarinesthat used trigonometry to solve the problem of firing a torpedo at a moving target. DuringWorld War II, similar devices were developed in other countries. Early digital computers wereelectromechanical; electric switches drove mechanical relays to perform the calculation. These devices had a low operating speed and were eventually superseded by much faster all-electric computers, originally usingvacuum tubes. TheZ2, created by German engineerKonrad Zusein 1939 inBerlin, was one of the earliest examples of an electromechanical relay computer. In 1941, Zuse followed his earlier machine up with theZ3, the world's first working electromechanicalprogrammable, fully automatic digital computer.The Z3 was built with 2000relays, implementing a 22bitword lengththat operated at aclock frequencyof about 5–10Hz.Program code was supplied on punchedfilmwhile data could be stored in 64 words of memory or supplied from the keyboard. It was quite similar to modern machines in some respects, pioneering numerous advances such asfloating-point numbers. Rather than the harder-to-implement decimal system (used inCharles Babbage's earlier design), using abinarysystem meant that Zuse's machines were easier to build and potentially more reliable, given the technologies available at that time.The Z3 was not itself a universal computer but could be extended to beTuring complete. Zuse's next computer, theZ4, became the world's first commercial computer; after initial delay due to the Second World War, it was completed in 1950 and delivered to theETH Zurich.The computer was manufactured by Zuse's own company,Zuse KG, which was founded in 1941 as the first company with the sole purpose of developing computers in Berlin.The Z4 served as the inspiration for the construction of theERMETH, the first Swiss computer and one of the first in Europe. Purelyelectronic circuitelements soon replaced their mechanical and electromechanical equivalents, at the same time that digital calculation replaced analog. The engineerTommy Flowers, working at thePost Office Research Stationin London in the 1930s, began to explore the possible use of electronics for thetelephone exchange. Experimental equipment that he built in 1934 went into operation five years later, converting a portion of thetelephone exchangenetwork into an electronic data processing system, using thousands ofvacuum tubes.In the US,John Vincent AtanasoffandClifford E. BerryofIowa State Universitydeveloped and tested theAtanasoff–Berry Computer(ABC) in 1942,the first \"automatic electronic digital computer\".This design was also all-electronic and used about 300 vacuum tubes, with capacitors fixed in a mechanically rotating drum for memory. During World War II, the British code-breakers atBletchley Parkachieved a number of successes at breaking encrypted German military communications. The German encryption machine,Enigma, was first attacked with the help of the electro-mechanicalbombeswhich were often run by women.To crack the more sophisticated GermanLorenz SZ 40/42machine, used for high-level Army communications,Max Newmanand his colleagues commissioned Flowers to build theColossus.He spent eleven months from early February 1943 designing and building the first Colossus.After a functional test in December 1943, Colossus was shipped to Bletchley Park, where it was delivered on 18 January 1944and attacked its first message on 5 February. Colossus was the world's firstelectronic digitalprogrammable computer.It used a large number of valves (vacuum tubes). It had paper-tape input and was capable of being configured to perform a variety ofboolean logicaloperations on its data, but it was not Turing-complete. Nine Mk II Colossi were built (The Mk I was converted to a Mk II making ten machines in total). Colossus Mark I contained 1,500 thermionic valves (tubes), but Mark II with 2,400 valves, was both five times faster and simpler to operate than Mark I, greatly speeding the decoding process. TheENIAC(Electronic Numerical Integrator and Computer) was the first electronicprogrammablecomputer built in the U.S. Although the ENIAC was similar to the Colossus, it was much faster, more flexible, and it was Turing-complete. Like the Colossus, a \"program\" on the ENIAC was defined by thestatesof its patch cables and switches, a far cry from thestored programelectronic machines that came later. Once a program was written, it had to be mechanically set into the machine with manual resetting of plugs and switches. The programmers of the ENIAC were six women, often known collectively as the \"ENIAC girls\". It combined the high speed of electronics with the ability to be programmed for many complex problems. It could add or subtract 5000 times a second, a thousand times faster than any other machine. It also had modules to multiply, divide, and square root. High speed memory was limited to 20 words (about 80 bytes). Built under the direction ofJohn MauchlyandJ. Presper Eckertat the University of Pennsylvania, ENIAC's development and construction lasted from 1943 to full operation at the end of 1945. The machine was huge, weighing 30 tons, using 200 kilowatts of electric power and contained over 18,000 vacuum tubes, 1,500 relays, and hundreds of thousands of resistors, capacitors, and inductors. The principle of the modern computer was proposed byAlan Turingin his seminal 1936 paper,On Computable Numbers. Turing proposed a simple device that he called \"Universal Computing machine\" and that is now known as auniversal Turing machine. He proved that such a machine is capable of computing anything that is computable by executing instructions (program) stored on tape, allowing the machine to be programmable. The fundamental concept of Turing's design is thestored program, where all the instructions for computing are stored in memory.Von Neumannacknowledged that the central concept of the modern computer was due to this paper.Turing machines are to this day a central object of study intheory of computation. Except for the limitations imposed by their finite memory stores, modern computers are said to beTuring-complete, which is to say, they havealgorithmexecution capability equivalent to a universal Turing machine. Early computing machines had fixed programs. Changing its function required the re-wiring and re-structuring of the machine.With the proposal of the stored-program computer this changed. A stored-program computer includes by design aninstruction setand can store in memory a set of instructions (aprogram) that details thecomputation. The theoretical basis for the stored-program computer was laid out byAlan Turingin his 1936 paper. In 1945, Turing joined theNational Physical Laboratoryand began work on developing an electronic stored-program digital computer. His 1945 report \"Proposed Electronic Calculator\" was the first specification for such a device. John von Neumann at theUniversity of Pennsylvaniaalso circulated hisFirst Draft of a Report on the EDVACin 1945. TheManchester Babywas the world's firststored-program computer. It was built at theUniversity of Manchesterin England byFrederic C. Williams,Tom KilburnandGeoff Tootill, and ran its first program on 21 June 1948.It was designed as atestbedfor theWilliams tube, the firstrandom-accessdigital storage device.Although the computer was described as \"small and primitive\" by a 1998 retrospective, it was the first working machine to contain all of the elements essential to a modern electronic computer.As soon as the Baby had demonstrated the feasibility of its design, a project began at the university to develop it into a practically useful computer, theManchester Mark 1. The Mark 1 in turn quickly became the prototype for theFerranti Mark 1, the world's first commercially available general-purpose computer.Built byFerranti, it was delivered to the University of Manchester in February 1951. At least seven of these later machines were delivered between 1953 and 1957, one of them toShelllabs inAmsterdam.In October 1947 the directors of British catering companyJ. Lyons & Companydecided to take an active role in promoting the commercial development of computers. Lyons'sLEO Icomputer, modelled closely on the CambridgeEDSACof 1949, became operational in April 1951and ran the world's first routine office computerjob. The concept of afield-effect transistorwas proposed byJulius Edgar Lilienfeldin 1925.John BardeenandWalter Brattain, while working underWilliam ShockleyatBell Labs, built the first workingtransistor, thepoint-contact transistor, in 1947, which was followed by Shockley'sbipolar junction transistorin 1948.From 1955 onwards, transistors replacedvacuum tubesin computer designs, giving rise to the \"second generation\" of computers. Compared to vacuum tubes, transistors have many advantages: they are smaller, and require less power than vacuum tubes, so give off less heat.Junction transistorswere much more reliable than vacuum tubes and had longer, indefinite, service life. Transistorized computers could contain tens of thousands of binary logic circuits in a relatively compact space. However, early junction transistors were relatively bulky devices that were difficult to manufacture on amass-productionbasis, which limited them to a number of specialized applications. At theUniversity of Manchester, a team under the leadership ofTom Kilburndesigned and built a machine using the newly developed transistors instead of valves.Their firsttransistorized computerand the first in the world, wasoperational by 1953, and a second version was completed there in April 1955. However, the machine did make use of valves to generate its 125 kHz clock waveforms and in the circuitry to read and write on its magneticdrum memory, so it was not the first completely transistorized computer. That distinction goes to theHarwell CADETof 1955,built by the electronics division of theAtomic Energy Research EstablishmentatHarwell. Themetal–oxide–silicon field-effect transistor(MOSFET), also known as the MOS transistor, was invented at Bell Labs between 1955 and 1960and was the first truly compact transistor that could be miniaturized and mass-produced for a wide range of uses.With itshigh scalability,and much lower power consumption and higher density than bipolar junction transistors,the MOSFET made it possible to buildhigh-density integrated circuits.In addition to data processing, it also enabled the practical use of MOS transistors asmemory cellstorage elements, leading to the development of MOSsemiconductor memory, which replaced earliermagnetic-core memoryin computers. The MOSFET led to themicrocomputer revolution,and became the driving force behind thecomputer revolution.The MOSFET is the most widely used transistor in computers,and is the fundamental building block ofdigital electronics. The next great advance in computing power came with the advent of theintegrated circuit(IC).\nThe idea of the integrated circuit was first conceived by a radar scientist working for theRoyal Radar Establishmentof theMinistry of Defence,Geoffrey W.A. Dummer. Dummer presented the first public description of an integrated circuit at the Symposium on Progress in Quality Electronic Components inWashington, D.C., on 7 May 1952. The first working ICs were invented byJack KilbyatTexas InstrumentsandRobert NoyceatFairchild Semiconductor.Kilby recorded his initial ideas concerning the integrated circuit in July 1958, successfully demonstrating the first working integrated example on 12 September 1958.In his patent application of 6 February 1959, Kilby described his new device as \"a body of semiconductor material ... wherein all the components of the electronic circuit are completely integrated\".However, Kilby's invention was ahybrid integrated circuit(hybrid IC), rather than amonolithic integrated circuit(IC) chip.Kilby's IC had external wire connections, which made it difficult to mass-produce. Noyce also came up with his own idea of an integrated circuit half a year later than Kilby.Noyce's invention was the first true monolithic IC chip.His chip solved many practical problems that Kilby's had not. Produced at Fairchild Semiconductor, it was made ofsilicon, whereas Kilby's chip was made ofgermanium. Noyce's monolithic IC wasfabricatedusing theplanar process, developed by his colleagueJean Hoerniin early 1959. In turn, the planar process was based onCarl Froschand Lincoln Derick work on semiconductor surface passivation by silicon dioxide. Modern monolithic ICs are predominantly MOS (metal–oxide–semiconductor) integrated circuits, built fromMOSFETs(MOS transistors).The earliest experimental MOS IC to be fabricated was a 16-transistor chip built by Fred Heiman and Steven Hofstein atRCAin 1962.General Microelectronicslater introduced the first commercial MOS IC in 1964,developed by Robert Norman.Following the development of theself-aligned gate(silicon-gate) MOS transistor by Robert Kerwin,Donald Kleinand John Sarace at Bell Labs in 1967, the firstsilicon-gateMOS IC withself-aligned gateswas developed byFederico Fagginat Fairchild Semiconductor in 1968.The MOSFET has since become the most critical device component in modern ICs. The development of the MOS integrated circuit led to the invention of themicroprocessor,and heralded an explosion in the commercial and personal use of computers. While the subject of exactly which device was the first microprocessor is contentious, partly due to lack of agreement on the exact definition of the term \"microprocessor\", it is largely undisputed that the first single-chip microprocessor was theIntel 4004,designed and realized by Federico Faggin with his silicon-gate MOS IC technology,along withTed Hoff,Masatoshi ShimaandStanley MazoratIntel.In the early 1970s, MOS IC technology enabled theintegrationof more than 10,000 transistors on a single chip. System on a Chip(SoCs) are complete computers on amicrochip(or chip) the size of a coin.They may or may not have integratedRAMandflash memory. If not integrated, the RAM is usually placed directly above (known asPackage on package) or below (on the opposite side of thecircuit board) the SoC, and the flash memory is usually placed right next to the SoC. This is done to improve data transfer speeds, as the data signals do not have to travel long distances. Since ENIAC in 1945, computers have advanced enormously, with modern SoCs (such as the Snapdragon 865) being the size of a coin while also being hundreds of thousands of times more powerful than ENIAC, integrating billions of transistors, and consuming only a few watts of power. The firstmobile computerswere heavy and ran from mains power. The 50 lb (23 kg)IBM 5100was an early example. Later portables such as theOsborne 1andCompaq Portablewere considerably lighter but still needed to be plugged in. The first laptops, such as theGrid Compass, removed this requirement by incorporating batteries – and with the continued miniaturization of computing resources and advancements in portable battery life, portable computers grew in popularity in the 2000s.The same developments allowed manufacturers to integrate computing resources into cellular mobile phones by the early 2000s. Thesesmartphonesandtabletsrun on a variety of operating systems and recently became the dominant computing device on the market.These are powered bySystem on a Chip(SoCs), which are complete computers on a microchip the size of a coin. Computers can be classified in a number of different ways, including: A computer does not need to beelectronic, nor even have aprocessor, norRAM, nor even ahard disk. While popular usage of the word \"computer\" is synonymous with a personal electronic computer,a typical modern definition of a computer is: \"A device that computes, especially a programmable [usually] electronic machine that performs high-speed mathematical or logical operations or that assembles, stores, correlates, or otherwise processes information.\"According to this definition, any device thatprocesses informationqualifies as a computer. The termhardwarecovers all of those parts of a computer that are tangible physical objects.Circuits, computer chips, graphic cards, sound cards, memory (RAM), motherboard, displays, power supplies, cables, keyboards, printers and \"mice\" input devices are all hardware. A general-purpose computer has four main components: thearithmetic logic unit(ALU), thecontrol unit, thememory, and theinput and output devices(collectively termed I/O). These parts are interconnected bybuses, often made of groups ofwires. Inside each of these parts are thousands to trillions of smallelectrical circuitswhich can be turned off or on by means of anelectronic switch. Each circuit represents abit(binary digit) of information so that when the circuit is on it represents a \"1\", and when off it represents a \"0\" (in positive logic representation). The circuits are arranged inlogic gatesso that one or more of the circuits may control the state of one or more of the other circuits. Input devicesare the means by which the operations of a computer are controlled and it is provided with data. Examples include: Output devicesare the means by which a computer provides the results of its calculations in a human-accessible form. Examples include: Thecontrol unit(often called a control system or central controller) manages the computer's various components; it reads and interprets (decodes) the program instructions, transforming them into control signals that activate other parts of the computer.Control systems in advanced computers may change the order of execution of some instructions to improve performance. A key component common to all CPUs is theprogram counter, a special memory cell (aregister) that keeps track of which location in memory the next instruction is to be read from. The control system's function is as follows— this is a simplified description, and some of these steps may be performed concurrently or in a different order depending on the type of CPU: Since the program counter is (conceptually) just another set of memory cells, it can be changed by calculations done in the ALU. Adding 100 to the program counter would cause the next instruction to be read from a place 100 locations further down the program. Instructions that modify the program counter are often known as \"jumps\" and allow for loops (instructions that are repeated by the computer) and often conditional instruction execution (both examples ofcontrol flow). The sequence of operations that the control unit goes through to process an instruction is in itself like a short computer program, and indeed, in some more complex CPU designs, there is another yet smaller computer called amicrosequencer, which runs amicrocodeprogram that causes all of these events to happen. The control unit, ALU, and registers are collectively known as acentral processing unit(CPU). Early CPUs were composed of many separate components. Since the 1970s, CPUs have typically been constructed on a singleMOS integrated circuitchip called amicroprocessor. The ALU is capable of performing two classes of operations: arithmetic and logic.The set of arithmetic operations that a particular ALU supports may be limited to addition and subtraction, or might include multiplication, division,trigonometryfunctions such as sine, cosine, etc., andsquare roots. Some can operate only on whole numbers (integers) while others usefloating pointto representreal numbers, albeit with limited precision. However, any computer that is capable of performing just the simplest operations can be programmed to break down the more complex operations into simple steps that it can perform. Therefore, any computer can be programmed to perform any arithmetic operation—although it will take more time to do so if its ALU does not directly support the operation. An ALU may also compare numbers and returnBoolean truth values(true or false) depending on whether one is equal to, greater than or less than the other (\"is 64 greater than 65?\"). Logic operations involveBoolean logic:AND,OR,XOR, andNOT. These can be useful for creating complicatedconditional statementsand processingBoolean logic. Superscalarcomputers may contain multiple ALUs, allowing them to process several instructions simultaneously.Graphics processorsand computers withSIMDandMIMDfeatures often contain ALUs that can perform arithmetic onvectorsandmatrices. A computer's memory can be viewed as a list of cells into which numbers can be placed or read. Each cell has a numbered \"address\" and can store a single number. The computer can be instructed to \"put the number 123 into the cell numbered 1357\" or to \"add the number that is in cell 1357 to the number that is in cell 2468 and put the answer into cell 1595.\" The information stored in memory may represent practically anything. Letters, numbers, even computer instructions can be placed into memory with equal ease. Since the CPU does not differentiate between different types of information, it is the software's responsibility to give significance to what the memory sees as nothing but a series of numbers. In almost all modern computers, eachmemory cellis set up to storebinary numbersin groups of eight bits (called abyte). Each byte is able to represent 256 different numbers (2= 256); either from 0 to 255 or −128 to +127. To store larger numbers, several consecutive bytes may be used (typically, two, four or eight). When negative numbers are required, they are usually stored intwo's complementnotation. Other arrangements are possible, but are usually not seen outside of specialized applications or historical contexts. A computer can store any kind of information in memory if it can be represented numerically. Modern computers have billions or even trillions of bytes of memory. The CPU contains a special set of memory cells calledregistersthat can be read and written to much more rapidly than the main memory area. There are typically between two and one hundred registers depending on the type of CPU. Registers are used for the most frequently needed data items to avoid having to access main memory every time data is needed. As data is constantly being worked on, reducing the need to access main memory (which is often slow compared to the ALU and control units) greatly increases the computer's speed. Computer main memory comes in two principal varieties: RAM can be read and written to anytime the CPU commands it, but ROM is preloaded with data and software that never changes, therefore the CPU can only read from it. ROM is typically used to store the computer's initial start-up instructions. In general, the contents of RAM are erased when the power to the computer is turned off, but ROM retains its data indefinitely. In a PC, the ROM contains a specialized program called theBIOSthat orchestrates loading the computer'soperating systemfrom the hard disk drive into RAM whenever the computer is turned on or reset. Inembedded computers, which frequently do not have disk drives, all of the required software may be stored in ROM. Software stored in ROM is often calledfirmware, because it is notionally more like hardware than software.Flash memoryblurs the distinction between ROM and RAM, as it retains its data when turned off but is also rewritable. It is typically much slower than conventional ROM and RAM however, so its use is restricted to applications where high speed is unnecessary. In more sophisticated computers there may be one or more RAMcache memories, which are slower than registers but faster than main memory. Generally computers with this sort of cache are designed to move frequently needed data into the cache automatically, often without the need for any intervention on the programmer's part. I/O is the means by which a computer exchanges information with the outside world.Devices that provide input or output to the computer are calledperipherals.On a typical personal computer, peripherals include input devices like the keyboard andmouse, and output devices such as thedisplayandprinter.Hard disk drives,floppy diskdrives andoptical disc drivesserve as both input and output devices.Computer networkingis another form of I/O.\nI/O devices are often complex computers in their own right, with their own CPU and memory. Agraphics processing unitmight contain fifty or more tiny computers that perform the calculations necessary to display3D graphics.Moderndesktop computerscontain many smaller computers that assist the main CPU in performing I/O. A 2016-era flat screen display contains its own computer circuitry. While a computer may be viewed as running one gigantic program stored in its main memory, in some systems it is necessary to give the appearance of running several programs simultaneously. This is achieved by multitasking, i.e. having the computer switch rapidly between running each program in turn.One means by which this is done is with a special signal called aninterrupt, which can periodically cause the computer to stop executing instructions where it was and do something else instead. By remembering where it was executing prior to the interrupt, the computer can return to that task later. If several programs are running \"at the same time\". Then the interrupt generator might be causing several hundred interrupts per second, causing a program switch each time. Since modern computers typically execute instructions several orders of magnitude faster than human perception, it may appear that many programs are running at the same time, even though only one is ever executing in any given instant. This method of multitasking is sometimes termed \"time-sharing\" since each program is allocated a \"slice\" of time in turn. Before the era of inexpensive computers, the principal use for multitasking was to allow many people to share the same computer. Seemingly, multitasking would cause a computer that is switching between several programs to run more slowly, in direct proportion to the number of programs it is running, but most programs spend much of their time waiting for slow input/output devices to complete their tasks. If a program is waiting for the user to click on the mouse or press a key on the keyboard, then it will not take a \"time slice\" until theeventit is waiting for has occurred. This frees up time for other programs to execute so that many programs may be run simultaneously without unacceptable speed loss. Some computers are designed to distribute their work across several CPUs in a multiprocessing configuration, a technique once employed in only large and powerful machines such assupercomputers,mainframe computersandservers. Multiprocessor andmulti-core(multiple CPUs on a single integrated circuit) personal and laptop computers are now widely available, and are being increasingly used in lower-end markets as a result. Supercomputers in particular often have highly unique architectures that differ significantly from the basic stored-program architecture and from general-purpose computers.They often feature thousands of CPUs, customized high-speed interconnects, and specialized computing hardware. Such designs tend to be useful for only specialized tasks due to the large scale of program organization required to use most of the available resources at once. Supercomputers usually see usage in large-scalesimulation,graphics rendering, andcryptographyapplications, as well as with other so-called \"embarrassingly parallel\" tasks. Softwareis the part of a computer system that consists of theencodedinformationthat determines the computer's operation, such asdataor instructions on how to process the data. In contrast to the physicalhardwarefrom which the system is built, software is immaterial. Software includescomputer programs,librariesand related non-executable data, such asonline documentationordigital media. It is often divided intosystem softwareandapplication software. Computer hardware and software require each other and neither is useful on its own. When software is stored in hardware that cannot easily be modified, such as withBIOSROMin anIBM PC compatiblecomputer, it is sometimes called \"firmware\". The defining feature of modern computers which distinguishes them from all other machines is that they can beprogrammed. That is to say that some type ofinstructions(theprogram) can be given to the computer, and it will process them. Modern computers based on thevon Neumann architectureoften have machine code in the form of animperative programming language. In practical terms, a computer program may be just a few instructions or extend to many millions of instructions, as do the programs forword processorsandweb browsersfor example. A typical modern computer can execute billions of instructions per second (gigaflops) and rarely makes a mistake over many years of operation. Large computer programs consisting of several million instructions may take teams ofprogrammersyears to write, and due to the complexity of the task almost certainly contain errors. This section applies to most commonRAM machine–based computers. In most cases, computer instructions are simple: add one number to another, move some data from one location to another, send a message to some external device, etc. These instructions are read from the computer'smemoryand are generally carried out (executed) in the order they were given. However, there are usually specialized instructions to tell the computer to jump ahead or backwards to some other place in the program and to carry on executing from there. These are called \"jump\" instructions (orbranches). Furthermore, jump instructions may be made to happenconditionallyso that different sequences of instructions may be used depending on the result of some previous calculation or some external event. Many computers directly supportsubroutinesby providing a type of jump that \"remembers\" the location it jumped from and another instruction to return to the instruction following that jump instruction. Program execution might be likened to reading a book. While a person will normally read each word and line in sequence, they may at times jump back to an earlier place in the text or skip sections that are not of interest. Similarly, a computer may sometimes go back and repeat the instructions in some section of the program over and over again until some internal condition is met. This is called theflow of controlwithin the program and it is what allows the computer to perform tasks repeatedly without human intervention. Comparatively, a person using a pocketcalculatorcan perform a basic arithmetic operation such as adding two numbers with just a few button presses. But to add together all of the numbers from 1 to 1,000 would take thousands of button presses and a lot of time, with a near certainty of making a mistake. On the other hand, a computer may be programmed to do this with just a few simple instructions. The following example is written in theMIPS assembly language: Once told to run this program, the computer will perform the repetitive addition task without further human intervention. It will almost never make a mistake and a modern PC can complete the task in a fraction of a second. In most computers, individual instructions are stored asmachine codewith each instruction being given a unique number (its operation code oropcodefor short). The command to add two numbers together would have one opcode; the command to multiply them would have a different opcode, and so on. The simplest computers are able to perform any of a handful of different instructions; the more complex computers have several hundred to choose from, each with a unique numerical code. Since the computer's memory is able to store numbers, it can also store the instruction codes. This leads to the important fact that entire programs (which are just lists of these instructions) can be represented as lists of numbers and can themselves be manipulated inside the computer in the same way as numeric data. The fundamental concept of storing programs in the computer's memory alongside the data they operate on is the crux of the von Neumann, or stored program, architecture.In some cases, a computer might store some or all of its program in memory that is kept separate from the data it operates on. This is called theHarvard architectureafter theHarvard Mark Icomputer. Modern von Neumann computers display some traits of the Harvard architecture in their designs, such as inCPU caches. While it is possible to write computer programs as long lists of numbers (machine language) and while this technique was used with many early computers,it is extremely tedious and potentially error-prone to do so in practice, especially for complicated programs. Instead, each basic instruction can be given a short name that is indicative of its function and easy to remember – amnemonicsuch as ADD, SUB, MULT or JUMP. These mnemonics are collectively known as a computer'sassembly language. Converting programs written in assembly language into something the computer can actually understand (machine language) is usually done by a computer program called an assembler. A programming language is anotation systemfor writing thesource codefrom which acomputer programis produced. Programming languages provide various ways of specifying programs for computers to run. Unlikenatural languages, programming languages are designed to permit no ambiguity and to be concise. They are purely written languages and are often difficult to read aloud. They are generally either translated intomachine codeby acompileror anassemblerbefore being run, or translated directly at run time by aninterpreter. Sometimes programs are executed by a hybrid method of the two techniques. There are thousands of programming languages—some intended for general purposeprogramming, others useful for only highly specialized applications. Machine languages and the assembly languages that represent them (collectively termedlow-level programming languages) are generally unique to the particular architecture of a computer's central processing unit (CPU). For instance, anARM architectureCPU (such as may be found in asmartphoneor ahand-held videogame) cannot understand the machine language of anx86CPU that might be in aPC.Historically a significant number of other CPU architectures were created and saw extensive use, notably including the MOS Technology 6502 and 6510 in addition to the Zilog Z80. Although considerably easier than in machine language, writing long programs in assembly language is often difficult and is also error prone. Therefore, most practical programs are written in more abstracthigh-level programming languagesthat are able to express the needs of theprogrammermore conveniently (and thereby help reduce programmer error). High level languages are usually \"compiled\" into machine language (or sometimes into assembly language and then into machine language) using another computer program called acompiler.High level languages are less related to the workings of the target computer than assembly language, and more related to the language and structure of the problem(s) to be solved by the final program. It is therefore often possible to use different compilers to translate the same high level language program into the machine language of many different types of computer. This is part of the means by which software like video games may be made available for different computer architectures such as personal computers and variousvideo game consoles. Program design of small programs is relatively simple and involves the analysis of the problem, collection of inputs, using the programming constructs within languages, devising or using established procedures and algorithms, providing data for output devices and solutions to the problem as applicable.As problems become larger and more complex, features such as subprograms, modules, formal documentation, and new paradigms such as object-oriented programming are encountered.Large programs involving thousands of line of code and more require formal software methodologies.The task of developing largesoftwaresystems presents a significant intellectual challenge.Producing software with an acceptably high reliability within a predictable schedule and budget has historically been difficult;the academic and professional discipline of software engineering concentrates specifically on this challenge. Errors in computer programs are called \"bugs\". They may be benign and not affect the usefulness of the program, or have only subtle effects. However, in some cases they may cause the program or the entire system to \"hang\", becoming unresponsive to input such asmouseclicks or keystrokes, to completely fail, or tocrash.Otherwise benign bugs may sometimes be harnessed for malicious intent by an unscrupulous user writing anexploit, code designed to take advantage of a bug and disrupt a computer's proper execution. Bugs are usually not the fault of the computer. Since computers merely execute the instructions they are given, bugs are nearly always the result of programmer error or an oversight made in the program's design.AdmiralGrace Hopper, an American computer scientist and developer of the firstcompiler, is credited for having first used the term \"bugs\" in computing after a dead moth was found shorting a relay in theHarvard Mark IIcomputer in September 1947. Computers have been used to coordinate information between multiple physical locations since the 1950s. The U.S. military'sSAGEsystem was the first large-scale example of such a system, which led to a number of special-purpose commercial systems such asSabre. In the 1970s, computer engineers at research institutions throughout the United States began to link their computers together using telecommunications technology. The effort was funded by ARPA (nowDARPA), and thecomputer networkthat resulted was called theARPANET.Logic gatesare a common abstraction which can apply to most of the abovedigitaloranalogparadigms. The ability to store and execute lists of instructions calledprogramsmakes computers extremely versatile, distinguishing them fromcalculators. TheChurch–Turing thesisis a mathematical statement of this versatility: any computer with aminimum capability (being Turing-complete)is, in principle, capable of performing the same tasks that any other computer can perform. Therefore, any type of computer (netbook,supercomputer,cellular automaton, etc.) is able to perform the same computational tasks, given enough time and storage capacity. In the 20th century,artificial intelligencesystems were predominantlysymbolic: they executed code that was explicitly programmed by software developers.Machine learningmodels, however, have a set parameters that are adjusted throughout training, so that the model learns to accomplish a task based on the provided data. The efficiency of machine learning (and in particular ofneural networks) has rapidly improved with progress in hardware forparallel computing, mainlygraphics processing units(GPUs).Somelarge language modelsare able to control computers or robots.AI progress may lead to the creation ofartificial general intelligence(AGI), a type of AI that could accomplish virtually any intellectual task at least as well as humans. As the use of computers has spread throughout society, there are an increasing number of careers involving computers. The need for computers to work well together and to be able to exchange information has spawned the need for many standards organizations, clubs and societies of both a formal and informal nature. ", "metadata": {"url": "https://en.wikipedia.org/wiki/Computer", "title": "Computer", "headings": ["Contents", "Etymology", "History", "Pre-20th century", "First computer", "Electromechanical calculating machine", "Analog computers", "Digital computers", "Modern computers", "Mobile computers", "Types", "By architecture", "By size, form-factor and purpose", "Unconventional computers", "Hardware", "History of computing hardware", "Other hardware topics", "Input devices", "Output devices", "Control unit", "Central processing unit (CPU)", "Arithmetic logic unit (ALU)", "Memory", "Input/output (I/O)", "Multitasking", "Multiprocessing", "Software", "Programs", "Networking and the Internet", "Artificial intelligence", "Professions and organizations", "See also", "Notes", "References", "Sources", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Computer", "https://en.wikipedia.org/wiki/Computer", "https://en.wikipedia.org/wiki/Computer", "https://en.wikipedia.org/wiki/Personal_computer", "https://en.wikipedia.org/wiki/Computer_(disambiguation)", "https://en.wikipedia.org/wiki/ENIAC", "https://en.wikipedia.org/wiki/Mainframe", "https://en.wikipedia.org/wiki/IBM_System/360"]}},
{"id": "441c02aab14e", "content": " Thisglossary of artificial intelligenceis a list of definitions of terms and concepts relevant to the study ofartificial intelligence(AI), its subdisciplines, and related fields. Related glossaries includeGlossary of computer science,Glossary of robotics,Glossary of machine vision, andGlossary of logic. Pronounced \"A-star\". Alsoabduction. Alsoadaptive network-based fuzzy inference system. Alsoartificial emotional intelligenceoremotion AI. Alsofuzzy string searching. Alsoargumentation system. Alsomachine intelligence. Also simplyAI planning. Alsoself-driving car,robot car, anddriverless car. Alsobackward reasoning. Alsostochastic Hopfield network with hidden units. Alsopropositional satisfiability problem; abbreviatedSATISFIABILITYorSAT. Alsobaggingorbootstrapping. Alsoself-learning know-how system. Alsoexhaustive searchorgenerate and test. Alsosmartbot,talkbot,chatterbot,bot,IM bot,interactive agent,conversational interface, orartificial conversational entity. Alsoclustering. Alsoartificial creativity,mechanical creativity,creative computing, orcreative computation. Alsotheoretical neuroscienceormathematical neuroscience. Alsoalgorithmic number theory. Alsostatistical computing. Alsoconlang. Alsorecombination. Alsodataset. Alsoenterprise data warehouse(EDW). Alsotheory of choice. Alsoepigenetic robotics. Alsoconversational agent(CA). Alsodimension reduction. Alsodecentralized artificial intelligence. Alsodilution. Alsointerface agent. Alsorepresentation learning. Alsofirst-order predicate calculusorpredicate logic. Alsoforward reasoning. Alsofriendly AIorFAI. Alsograph search. Alsocognitive augmentation,machine augmented intelligence, andenhanced intelligence. Alsovirtual assistantorpersonal digital assistant. Alsologic tree. AlsoClique Tree.  Alsomathematical programming. Alsocomputer audition(CA). Alsomechatronic engineering. Alsoself-organized system. Alsoentity identification,entity chunking, andentity extraction. Alsobrain–computer interface(BCI),neural-control interface(NCI),mind-machine interface(MMI),direct neural interface(DNI), orbrain–machine interface(BMI). Alsoneuromorphic computing. Alsonon-deterministic polynomial-timehardness. AlsoOckham's razororOcham's razor. Alsoontology extraction,ontology generation, orontology acquisition. Alsopathing. Alsofirst-order logic,predicate logic, andfirst-order predicate calculus. Alsorationality principle. Alsopropositional logic,statement logic,sentential calculus,sentential logic, andzeroth-order logic. Alsorandom decision forest. Alsoframe network. Alsoreasoning engine,rules engine, or simplyreasoner. Alsoweak supervision. Also simplySLD resolution. Alsosparse codingorSDL. Also simplythe singularity. AbbreviatedH+orh+. Alsotree search. Alsonarrow AI.", "metadata": {"url": "https://en.wikipedia.org/wiki/Glossary_of_artificial_intelligence", "title": "Glossary of artificial intelligence", "headings": ["A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L", "M", "N", "O", "P", "Q", "R", "S", "T", "U", "V", "W", "X", "References", "Works cited", "Notes"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Glossary_of_artificial_intelligence", "https://en.wikipedia.org/wiki/Glossary_of_artificial_intelligence", "https://en.wikipedia.org/wiki/Glossary_of_artificial_intelligence", "https://en.wikipedia.org/wiki/Artificial_intelligence", "https://en.wikipedia.org/wiki/Glossary_of_computer_science", "https://en.wikipedia.org/wiki/Glossary_of_robotics", "https://en.wikipedia.org/wiki/Glossary_of_machine_vision", "https://en.wikipedia.org/wiki/Glossary_of_logic"]}},
{"id": "b59f8a0e9856", "content": " In January 2022,15—the pseudonymousMassachusetts Institute of Technology(MIT) artificial intelligence researcher and creator of the non-commercialgenerative artificial intelligencevoice synthesisresearch project15.ai—discovered that theblockchain-based technology companyVoiceversehadplagiarizedfrom their platform. Voiceverse marketed itself as a service that offeredAI voice cloning technologythat could be purchased and traded asnon-fungible tokens(NFTs). Amid heightened controversy over NFTs in the gaming industry, voice actorTroy Baker(who has been described as one of the most famousvoice actors in video games) announced his partnership with Voiceverse on January 14, 2022, triggering immediate backlash over concerns about theenvironmental impact of NFTs,potential for fraud,predatory monetization in video games, and the potential ofAI displacing jobs for human voice actors. Later that same day, 15 revealed through server logs that Voiceverse had generated voice lines using 15's freetext-to-speechplatform, pitch-shifted the audio to make them unrecognizable, andfalsely marketedthe samples as their own technology before selling them as NFTs. Within an hour of being confronted with evidence, Voiceverse confessed and stated that their marketing team had used 15.ai without proper attribution while rushing to create atechnology demoto coincide with Baker's partnership announcement, further exacerbating the already negative reception to the original announcement. In response, 15 replied \"Go fuck yourself\"; the interaction wentviraland garnered a large amount of support for the developer. News publications universally characterized this incident as Voiceverse having \"stolen\" from 15.ai. The next day, Baker appeared on apodcastand stated that his motivation had been to help independent creators who were unable to afford professional voice actors. Following continued backlash and the plagiarism revelation, Baker ended his partnership with Voiceverse on January 31, 2022. Subsequently, the incident was documented in multipleAI ethicsdatabases, criticisms of predatory monetization in video games, andretrospectivesas an instance of plagiarism and theft stemming from artificial intelligence. Troy Bakeris a prominentvoice actorin thevideo game industrybest known for his performances asJoel MillerinThe Last of Usfranchise.Baker has been described as \"ubiquitous\" byPolygon,\"one of the most high-profile and prolific voice actors in video games\" byEurogamer,and \"arguably the most famous voice actor in the gaming industry\" byGameGuru.His other prominent roles include voicing Agent John \"Jonesy\" Jones inFortnite,Booker DeWittinBioShock Infinite, and bothBatmanandJokerin multiple Batman video games.As of October 2025, Baker holds the record for the most acting nominations at theBAFTA Games Awards, with five between 2013 and 2021. Voiceverse is ablockchain-based startup founded by theBored Ape Yacht Clubthat marketed itself as offering AI voice cloning technology in the form ofNFTs.Prior to the announcement of their partnership with Baker, Voiceverse had partnered with LOVO, Inc., an AI voice platform that, according to LOVO, could generate human-like voices.Voiceverse stated that any user who purchases a voice NFT would have unlimited and perpetual access to the voice model,which could be used to create content such asaudiobooks,YouTube videos,podcasts, e-learning materials, in-gamevoice chat, andZoom calls.Voiceverse promised that buyers would \"OWN[sic]all of theIP\" of content they created using these voices.Voiceverse's roadmap included plans to release 8,888 initial voice NFTs, a feature to add emotions to existing voices, and the ability for users to mint their own voices as NFTs. Prior to Baker's partnership, Voiceverse had also partnered with voice actorsCharlet Chung, who voicesD.VainOverwatch,andAndy MilonakisofThe Andy Milonakis Show. 15.aiis a free web application launched in 2020 that usesartificial intelligenceto generatetext-to-speechvoices of fictional characters frompopular media.Created by apseudonymousartificial intelligence researcher known as15, who began developing the technology as afreshmanduring their undergraduate research atMIT, it was an early example of an application ofgenerative artificial intelligenceduring the initial stages of theAI boom. The platform showed thatdeep neural networkscould generate emotionally expressive speech with only 15 seconds of speech; the name \"15.ai\" references the creator's statement that a voice can be convincingly cloned with just 15 seconds of audio, as opposed to the tens of hours of data previously required. 15.ai became anInternet phenomenonin early 2021 when content utilizing it went viral onsocial mediaand quickly gained widespread use among variousInternet fandoms. 15 has emphasized that it remain free and non-commercial; it only requires users to give proper credit when using the service for content creation. By early 2022, NFTs had become highly controversial within the gaming industry.Critics raised concerns about their environmental impact due to the significant energy consumption of blockchain technology.In addition, the prevalence of scams, fraud, and potentialmoney launderingassociated with NFT sales, as well as fears that NFTs were a new form ofpredatory monetizationfollowing the increasing frequency ofloot boxes, caused vocal pushback from the gaming community.Several major gaming companies had begun exploring NFT integration into their products, though fan backlash had already forced some projects to be cancelled.On December 16, 2021,the developers ofS.T.A.L.K.E.R. 2: Heart of Chernobylannounced that they would be including NFTs in the game, but cancelled within an hour of the announcement due to immediate universal backlash.Simultaneously, the rise of AI voice technology raised concerns among voice actors about potential job displacement and the devaluation of their work amidst the voice acting industry's ongoing struggles for better compensation and working conditions. I'm partnering with @VoiceverseNFT to explore ways where together we might bring new tools to new creators to make new things, and allow everyone a chance to own & invest in the IP's they create. We all have a story to tell.\nYou can hate.\nOr you can create. What'll it be?  January 14, 2022, 1:02 a.m. On January 14, 2022, 1:02a.m.EST, Baker announced onTwitterthat he was partnering with Voiceverse \"to explore ways where together we might bring new tools to new creators to make new things, and allow everyone a chance to own & invest in the IP's they create.\" The announcement concluded with the statement \"You can hate. Or you can create.\"Baker's specific role with Voiceverse remained unclear at the time of the announcement. Along with Baker's announcement, Voiceverse promoted their supposed voice AI technology on Twitter by posting animated videos that featured a cat character created by NFT firmChubbiverse.The videos concluded with text that read \"The Voice Powered By Voiceverse\"; Voiceverse stated on Twitter that the voices in the animations had been generated using their own AI voice synthesis technology and presented the videos as atechnology demonstrationof their voice NFT capabilities. The announcement provoked immediate and widespread backlash from the gaming community.Baker's tweet received thousands of replies andquote retweets(the vast majority of which were negative),far more than the number oflikes;Michael McWhertor ofPolygondescribed it as a \"textbook example of beingratioed\" and commented that reactions had been amplified by the final part of Baker's announcement.Michael Beckwith ofMetrocalled Baker's approach \"bizarrely aggressive\". Later that day, Baker responded to the backlash by apologizing for his choice of words.He said he appreciated people's thoughts and acknowledged that the \"hate/create part might have been a bit antagonistic,\" calling it a \"bad attempt to bring levity\".Despite the apology, Baker and his fellow voice actors did not distance themselves from Voiceverse at this point.At the same time, Voiceverse attempted to address the criticisms, stating that they were working to move to more environmentally friendly blockchain technology and that voice actors would receive royalties from NFT sales, with actors benefiting from any increase in NFT value. On December 13, 2021, amidst the increasingly negative reactions toward NFTs among the general public, the creator of15.ai(known pseudonymously as15) announced that they had \"no interest in incorporatingNFTsinto any aspect of [their] work.\" On January 14, 2022, 11:17a.m.EST(10 hours after Baker's initial announcement),15 commented on the Voiceverse venture, stating that it \"sounds like ascam\".Two hours later, at 1:20p.m., 15 explicitly accused Voiceverse of \"actively attempting to appropriate [15's] work for [Voiceverse's] own benefit.\"15 provided evidence through serverlog filesthat showed that the voices Voiceverse was claiming credit for had actually been generated by 15.ai.The log files, which showed the details of the serverrequest–responsesexactly matching up with those present in Voiceverse's video, proved that Voiceverse had used 15.ai to create the voice samples that they were marketing as their own technology.The Chubbiverse promotion videos featured distorted voices of charactersfrom the animated television seriesMy Little Pony: Friendship Is Magic.The voice lines had then been sold as NFTs,a violation of 15.ai'sterms of service, which explicitly prohibited commercial use and required proper attribution. Hey @fifteenai we are extremely sorry about this. The voice was indeed taken from your platform, which our marketing team used without giving proper credit. Chubbiverse team has no knowledge of this. We will make sure this never happens again. January 14, 2022, 2:09 p.m. Voiceverse initially responded sarcastically before deleting that response.At 2:09p.m. EST, Voiceverse wrote in an apology to 15: \"We are extremely sorry about this. The voice was indeed taken from your platform, which our marketing team used without giving proper credit. Chubbiverse team has no knowledge of this. We will make sure this never happens again.\"In theirDiscordserver, Voiceverse further stated that their marketing team had been in such a rush to create a partnershiptechnology demothat they resorted to using 15.ai without waiting for their own voice technology to be ready. In response, at 3:34p.m. EST, 15 tweeted \"Go fuck yourself\";the interaction wentviral, garnering widespread support for 15.In a subsequent statement, the creator expressed being \"extremely depressed\" by the incident and wrote: \"Not only because my work was stolen and used for profit, but also because of this scandal, the entire field ofvocal synthesisis now being misrepresented bycharlatanswho are only in it for the money.\"Voiceverse subsequently deleted the incriminating tweet, but Twitter users had already saved and reshared the video. News publications universally characterized the incident astheft. English-language news websites—includingEurogamer,NME,Kotaku Australia,The Mary Sue,The Journal,PlayStation Universe,Geek Culture,Tech Times,Stevivor,Checkpoint Gaming,Metro,Kakuchopurei,Wccftech,andMobidictum—reported that Voiceverse had stolen,taken,or used content without permission.Briana Lawrence ofThe Mary Suewrote that \"15's pinned tweet explicitly states that they have no interest in NFTs, so the theft in this case is a double dose of 'the audacity.'\"Ruby Innes ofKotaku Australiacalled the theft \"a case of absolute and unadulterated degenerate behaviour.\"Brandon Toh ofGeek Cultureremarked that Voiceverse's actions \"seem to run counter to their purported support for content creators as a whole.\"Russian gaming sitesGameGuru,iXBT Games,StopGame,DTF,VGTimes,andShazoo; Danish gaming magazineGamereactor;Czech newspaperiDNES;Spanish-language newspaperSportand gaming news websiteLevelUp;Portuguese entertainment siteOtakuPT;Greek gaming news websiteGameWorld;Indonesian gaming websiteGamebrott;Swedish gaming websiteFZ;and Finnish technology websiteMuropakettialso reported that Voiceverse had stolen,plagiarized,or used 15.ai's work without permission. According toEurogamer, reactions to Baker's initial partnership announcement were universally negative.Critics raised multiple concerns, including the potentialenvironmental impact of NFT salesdue toblockchain energy consumption,fears thatAI-driven voice technologywould automate and eliminate the need for actual human voice actors andjeopardize voice acting jobs,warnings that the technology could devalue voice actors' work and undercut prospective actors,and concerns aboutscams and art theft associated with NFTs.At the same time, fans also accused Baker of abandoning a 2017 musiccrowdfundingproject and never providing refunds to those who donated. The plagiarism revelation immediately exacerbated the already-negative reception. Less than an hour after 15's accusation,YouTubersSkillUp andYong Yeaboth reported that by plagiarizing 15.ai's work, Voiceverse had committed theft and fraud. On January 15, the day after the plagiarism revelation, Baker appeared on episode 90 of thePlay, Watch, Listenpodcast, which he co-hosts withAlanah Pearce,Mike Bithell, andAustin Wintory. In the episode, \"Talking to Troy Baker About His NFT Tweet,\" Baker stated that his primary motivation for the partnership was to help independent creators access resources they otherwise could not afford. He said: \"while I understood that an NFT was a component to this, that's not what I got involved with.\" Baker said he envisioned a scenario where \"if some independent game maker wants to have me in their game and they can't afford me and they can do that now, great.\" Responding to concerns that the technology could put voice actors out of work, Baker said: \"if the only reason why I don't do something to help somebody out is because it may hurt me, that's a fucked up reason to not do the right thing.\" He acknowledged that his announcement had been \"just a fucking bad look\" and apologized again; he also said that he had told Voiceverse he did not know what would happen with the partnership moving forward. On January 31, over two weeks after his initial announcement, Baker announced that he would no longer partner with Voiceverse and thanked fans for their \"feedback and patience\".He reiterated his apology from earlier in the month: \"Intentions aside, I've heard you and apologize for accusing anyone of 'hating' just by simply disagreeing with me.\"Voiceverse stated that the decision was reached as a \"mutual agreement\" between the two parties and stated that they would \"double-down our resources and efforts to execute on our roadmap, further our vision as the voice ofWeb3.0, and strengthen our community as well as the broader NFT ecosystem.\" On September 25, 2024, aclass action lawsuitwas filed againstLOVO, Inc., the parent company of Voiceverse, alleging that LOVO had illegally copied the voices of voice actors and used them without permission. Court documents cited LOVO/Voiceverse's prior plagiarism of 15.ai as part of the case.In April 2021, LOVO wrote that \"[15.ai] are LOVO's competition because we do all of that as well, but none of us are real threats to each other, yet.\" The incident was documented by various organizations indexingethics violations in artificial intelligenceandcryptocurrency. Both theAI Incident Database(AIID) and theAI, Algorithmic, and Automation Incidents and Controversies(AIAAIC)classified the incident as theft.Later, the AIAAIC also formally classified the incident as a case ofplagiarism.The MIT AI Risk Repository catalogued the incident as an example of \"economic and cultural devaluation of human effort\".In aretrospectiveof the incident in herWeb3 Is Going Just Greatwebsite, writer and crypto skepticMolly Whitewrote that \"things were further soured when it was revealed that Voiceverse had stolen work without crediting it from [...] 15.ai.\" White categorized the incident as theft, a \"bad idea\", and \"shady business\".In an article aboutvideo game monetizationon the Russian educational platformSkillbox,video game journalistPavel Khibchenko described the plagiarism incident as an example offraud in NFTs.In 2023,/Filmdescribed the incident as plagiarism and referred to Baker's partnership with Voiceverse as \"one of [his] less reputable roles\", writing that \"nobody's perfect.\"", "metadata": {"url": "https://en.wikipedia.org/wiki/Voiceverse_NFT_plagiarism_scandal", "title": "Voiceverse NFT plagiarism scandal", "headings": ["Contents", "Background", "Troy Baker", "Voiceverse", "15.ai", "NFTs in the video game industry", "Partnership announcement and backlash", "Plagiarism revelation", "Reactions", "Aftermath", "Legacy", "See also", "Notes", "References", "Tweets", "Videos"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Voiceverse_NFT_plagiarism_scandal", "https://en.wikipedia.org/wiki/Voiceverse_NFT_plagiarism_scandal", "https://en.wikipedia.org/wiki/Voiceverse_NFT_plagiarism_scandal", "https://en.wikipedia.org/wiki/15_(programmer)", "https://en.wikipedia.org/wiki/15.ai", "https://en.wikipedia.org/wiki/Troy_Baker", "https://en.wikipedia.org/wiki/NFT", "https://en.wikipedia.org/wiki/15_(programmer)"]}},
{"id": "4c347b41efd3", "content": "TheMachine Intelligence Research Institute(MIRI), formerly theSingularity Institute for Artificial Intelligence(SIAI), is anon-profitresearch institutefocused since 2005 on identifying and managing potentialexistential risks from artificial general intelligence. MIRI's work has focused on afriendly AIapproach to system design and on predicting the rate of technology development. In 2000,Eliezer Yudkowskyfounded the Singularity Institute for Artificial Intelligence with funding from Brian and Sabine Atkins, with the purpose of accelerating the development ofartificial intelligence(AI).However, Yudkowsky began to be concerned that AI systems developed in the future could becomesuperintelligentand pose risks to humanity,and in 2005 the institute moved to Silicon Valley and began to focus on ways to identify and manage those risks, which were at the time largely ignored by scientists in the field. Starting in 2006, the Institute organized theSingularity Summitto discuss the future of AI including its risks, initially in cooperation withStanford Universityand with funding fromPeter Thiel. TheSan Francisco Chronicledescribed the first conference as a \"Bay Area coming-out party for the tech-inspired philosophy calledtranshumanism\".In 2011, its offices were four apartments in downtown Berkeley.In December 2012, the institute sold its name, web domain, and the Singularity Summit toSingularity University,and in the following month took the name \"Machine Intelligence Research Institute\". In 2014 and 2015, public and scientific interest in the risks of AI grew, increasing donations to fund research at MIRI and similar organizations. In 2019,Open Philanthropyrecommended a general-support grant of approximately $2.1 million over two years to MIRI.In April 2020, Open Philanthropy supplemented this with a $7.7M grant over two years. In 2021,Vitalik Buterindonated several million dollars' worth ofEthereumto MIRI. MIRI's approach to identifying and managing the risks of AI, led by Yudkowsky, primarily addresses how to design friendly AI, covering both the initial design of AI systems and the creation of mechanisms to ensure that evolving AI systems remain friendly. MIRI researchers advocate early safety work as a precautionary measure.However, MIRI researchers have expressed skepticism about the views ofsingularity advocateslikeRay Kurzweilthatsuperintelligenceis \"just around the corner\".MIRI has funded forecasting work through an initiative called AI Impacts, which studies historical instances of discontinuous technological change, and has developed new measures of the relative computational power of humans and computer hardware. MIRI aligns itself with the principles and objectives of theeffective altruismmovement.", "metadata": {"url": "https://en.wikipedia.org/wiki/Machine_Intelligence_Research_Institute", "title": "Machine Intelligence Research Institute", "headings": ["Contents", "History", "Research and approach", "Works by MIRI staff", "See also", "References", "Further reading", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Machine_Intelligence_Research_Institute", "https://en.wikipedia.org/wiki/Machine_Intelligence_Research_Institute", "https://en.wikipedia.org/wiki/Machine_Intelligence_Research_Institute", "https://en.wikipedia.org/wiki/Singularity_University", "https://en.wikipedia.org/wiki/Nonprofit", "https://en.wikipedia.org/wiki/Research_institute", "https://en.wikipedia.org/wiki/Taxpayer_Identification_Number", "https://en.wikipedia.org/wiki/Friendly_artificial_intelligence"]}},
{"id": "e234109dffe3", "content": "Cluster analysis, orclustering, is a data analysis technique aimed at partitioning a set of objects into groups such that objects within the same group (called acluster) exhibit greatersimilarityto one another (in some specific sense defined by the analyst) than to those in other groups (clusters). It is a main task ofexploratory data analysis, and a common technique forstatisticaldata analysis, used in many fields, includingpattern recognition,image analysis,information retrieval,bioinformatics,data compression,computer graphicsandmachine learning. Cluster analysis refers to a family of algorithms and tasks rather than one specificalgorithm. It can be achieved by various algorithms that differ significantly in their understanding of what constitutes a cluster and how to efficiently find them. Popular notions of clusters include groups with smalldistancesbetween cluster members, dense areas of the data space, intervals or particularstatistical distributions. Clustering can therefore be formulated as amulti-objective optimizationproblem. The appropriate clustering algorithm and parameter settings (including parameters such as thedistance functionto use, a density threshold or the number of expected clusters) depend on the individualdata setand intended use of the results. Cluster analysis as such is not an automatic task, but an iterative process ofknowledge discoveryor interactive multi-objective optimization that involves trial and failure. It is often necessary to modifydata preprocessingand model parameters until the result achieves the desired properties. Besides the termclustering, there are a number of terms with similar meanings, includingautomaticclassification,numerical taxonomy,botryology(fromGreek:βότρυς'grape'),typological analysis, andcommunity detection. The subtle differences are often in the use of the results: while in data mining, the resulting groups are the matter of interest, in automatic classification the resulting discriminative power is of interest. Cluster analysis originated in anthropology by Driver and Kroeber in 1932and introduced to psychology byJoseph Zubinin 1938andRobert Tryonin 1939and famously used byCattellbeginning in 1943for trait theory classification inpersonality psychology. The notion of a \"cluster\" cannot be precisely defined, which is one of the reasons why there are so many clustering algorithms.There is a common denominator: a group of data objects. However, different researchers employ different cluster models, and for each of these cluster models again different algorithms can be given. The notion of a cluster, as found by different algorithms, varies significantly in its properties. Understanding these \"cluster models\" is key to understanding the differences between the various algorithms. Typical cluster models include: A \"clustering\" is essentially a set of such clusters, usually containing all objects in the data set. Additionally, it may specify the relationship of the clusters to each other, for example, a hierarchy of clusters embedded in each other. Clusterings can be roughly distinguished as: There are also finer distinctions possible, for example: As listed above, clustering algorithms can be categorized based on their cluster model. The following overview will only list the most prominent examples of clustering algorithms, as there are possibly over 100 published clustering algorithms. Not all provide models for their clusters and can thus not easily be categorized. An overview of algorithms explained in Wikipedia can be found in thelist of statistics algorithms. There is no objectively \"correct\" clustering algorithm, but as it was noted, \"clustering is in the eye of the beholder.\"In fact, an axiomatic approach to clustering demonstrates that it is impossible for any clustering method to meet three fundamental properties simultaneously:scale invariance(results remain unchanged under proportional scaling of distances),richness(all possible partitions of the data can be achieved), andconsistencybetween distances and the clustering structure.The most appropriate clustering algorithm for a particular problem often needs to be chosen experimentally, unless there is a mathematical reason to prefer one cluster model over another. An algorithm that is designed for one kind of model will generally fail on a data set that contains a radically different kind of model.For example, k-means cannot find non-convex clusters.Most traditional clustering methods assume the clusters exhibit a spherical, elliptical or convex shape. Connectivity-based clustering, also known ashierarchical clustering, is based on the core idea of objects being more related to nearby objects than to objects farther away. These algorithms connect \"objects\" to form \"clusters\" based on their distance. A cluster can be described largely by the maximum distance needed to connect parts of the cluster. At different distances, different clusters will form, which can be represented using adendrogram, which explains where the common name \"hierarchical clustering\" comes from: these algorithms do not provide a single partitioning of the data set, but instead provide an extensive hierarchy of clusters that merge with each other at certain distances. In a dendrogram, the y-axis marks the distance at which the clusters merge, while the objects are placed along the x-axis such that the clusters don't mix. Connectivity-based clustering is a whole family of methods that differ by the way distances are computed. Apart from the usual choice ofdistance functions, the user also needs to decide on the linkage criterion (since a cluster consists of multiple objects, there are multiple candidates to compute the distance) to use. Popular choices are known assingle-linkage clustering(the minimum of object distances),complete linkage clustering(the maximum of object distances), andUPGMAorWPGMA(\"Unweighted or Weighted Pair Group Method with Arithmetic Mean\", also known as average linkage clustering). Furthermore, hierarchical clustering can be agglomerative (starting with single elements and aggregating them into clusters) or divisive (starting with the complete data set and dividing it into partitions). These methods will not produce a unique partitioning of the data set, but a hierarchy from which the user still needs to choose appropriate clusters. They are not very robust towards outliers, which will either show up as additional clusters or even cause other clusters to merge (known as \"chaining phenomenon\", in particular withsingle-linkage clustering). In the general case, the complexity isO(n3){\\displaystyle {\\mathcal {O}}(n^{3})}for agglomerative clustering andO(2n−1){\\displaystyle {\\mathcal {O}}(2^{n-1})}fordivisive clustering,which makes them too slow for large data sets. For some special cases, optimal efficient methods (of complexityO(n2){\\displaystyle {\\mathcal {O}}(n^{2})}) are known: SLINKfor single-linkage and CLINKfor complete-linkage clustering. In centroid-based clustering, each cluster is represented by a central vector, which is not necessarily a member of the data set. When the number of clusters is fixed tok,k-means clusteringgives a formal definition as an optimization problem: find thekcluster centers and assign the objects to the nearest cluster center, such that the squared distances from the cluster are minimized. The optimization problem itself is known to beNP-hard, and thus the common approach is to search only for approximate solutions. A particularly well-known approximate method isLloyd's algorithm,often just referred to as \"k-means algorithm\" (althoughanother algorithm introduced this name). It does however only find alocal optimum, and is commonly run multiple times with different random initializations. Variations ofk-means often include such optimizations as choosing the best of multiple runs, but also restricting the centroids to members of the data set (k-medoids), choosingmedians(k-medians clustering), choosing the initial centers less randomly (k-means++) or allowing a fuzzy cluster assignment (fuzzy c-means). Mostk-means-type algorithms require thenumber of clusters–k– to be specified in advance, which is considered to be one of the biggest drawbacks of these algorithms. Furthermore, the algorithms prefer clusters of approximately similar size, as they will always assign an object to the nearest centroid; often yielding improperly cut borders of clusters. This happens primarily because the algorithm optimizes cluster centers, not cluster borders. Steps involved in the centroid-based clustering algorithm are: K-means has a number of interesting theoretical properties. First, it partitions the data space into a structure known as aVoronoi diagram. Second, it is conceptually close to nearest neighbor classification, and as such is popular inmachine learning. Third, it can be seen as a variation of model-based clustering, and Lloyd's algorithm as a variation of theExpectation-maximization algorithmfor this model discussed below. Centroid-based clustering problems such ask-means andk-medoids are special cases of the uncapacitated, metricfacility location problem, a canonical problem in the operations research and computational geometry communities. In a basic facility location problem (of which there are numerous variants that model more elaborate settings), the task is to find the best warehouse locations to optimally service a given set of consumers. One may view \"warehouses\" as cluster centroids and \"consumer locations\" as the data to be clustered. This makes it possible to apply the well-developed algorithmic solutions from the facility location literature to the presently considered centroid-based clustering problem. The clustering framework most closely related to statistics ismodel-based clustering, which is based ondistribution models. This approach models the data as arising from a mixture of probability distributions. It has the advantages of providing principled statistical answers to questions such as how many clusters there are, what clustering method or model to use, and how to detect and deal with outliers. While the theoretical foundation of these methods is excellent, they suffer fromoverfittingunless constraints are put on the model complexity. A more complex model will usually be able to explain the data better, which makes choosing the appropriate model complexity inherently difficult. Standardmodel-based clusteringmethods include more parsimonious models based on theeigenvalue decompositionof the covariance matrices, that provide a balance between overfitting and fidelity to the data. One prominent method is known as Gaussian mixture models (using theexpectation-maximization algorithm). Here, the data set is usually modeled with a fixed (to avoid overfitting) number ofGaussian distributionsthat are initialized randomly and whose parameters are iteratively optimized to better fit the data set. This will converge to alocal optimum, so multiple runs may produce different results. In order to obtain a hard clustering, objects are often then assigned to the Gaussian distribution they most likely belong to; for soft clusterings, this is not necessary. Distribution-based clustering produces complex models for clusters that can capturecorrelation and dependencebetween attributes. However, these algorithms put an extra burden on the user: for many real data sets, there may be no concisely defined mathematical model (e.g. assuming Gaussian distributions is a rather strong assumption on the data). In density-based clustering,clusters are defined as areas of higher density than the remainder of the data set. Objects in sparse areas – that are required to separate clusters – are usually considered to be noise and border points. The most populardensity-based clustering method isDBSCAN.In contrast to many newer methods, it features a well-defined cluster model called \"density-reachability\". Similar to linkage-based clustering, it is based on connecting points within certain distance thresholds. However, it only connects points that satisfy a density criterion, in the original variant defined as a minimum number of other objects within this radius. A cluster consists of all density-connected objects (which can form a cluster of an arbitrary shape, in contrast to many other methods) plus all objects that are within these objects' range. Another interesting property of DBSCAN is that its complexity is fairly low – it requires a linear number of range queries on the database – and that it will discover essentially the same results (it isdeterministicfor core and noise points, but not for border points) in each run, therefore there is no need to run it multiple times.OPTICSis a generalization of DBSCAN that removes the need to choose an appropriate value for the range parameterε{\\displaystyle \\varepsilon }, and produces a hierarchical result related to that oflinkage clustering. DeLi-Clu,Density-Link-Clustering combines ideas fromsingle-linkage clusteringand OPTICS, eliminating theε{\\displaystyle \\varepsilon }parameter entirely and offering performance improvements over OPTICS by using anR-treeindex. The key drawback of DBSCAN andOPTICSis that they expect some kind of density drop to detect cluster borders. On data sets with, for example, overlapping Gaussian distributions – a common use case in artificial data – the cluster borders produced by these algorithms will often look arbitrary, because the cluster density decreases continuously. On a data set consisting of mixtures of Gaussians, these algorithms are nearly always outperformed by methods such asEM clusteringthat are able to precisely model this kind of data. Mean-shiftis a clustering approach where each object is moved to the densest area in its vicinity, based onkernel density estimation. Eventually, objects converge to local maxima of density. Similar to k-means clustering, these \"density attractors\" can serve as representatives for the data set, but mean-shift can detect arbitrary-shaped clusters similar to DBSCAN. Due to the expensive iterative procedure and density estimation, mean-shift is usually slower than DBSCAN or k-Means. Besides that, the applicability of the mean-shift algorithm to multidimensional data is hindered by the unsmooth behaviour of the kernel density estimate, which results in over-fragmentation of cluster tails. The grid-based technique is used for amulti-dimensionaldata set.In this technique, we create a grid structure, and the comparison is performed on grids (also known as cells). The grid-based technique is fast and has low computational complexity. There are two types of grid-based clustering methods: STING and CLIQUE. Steps involved in the grid-based clusteringalgorithmare: In recent years, considerable effort has been put into improving the performance of existing algorithms.Among them areCLARANS,andBIRCH.With the recent need to process larger and larger data sets (also known asbig data), the willingness to trade semantic meaning of the generated clusters for performance has been increasing. This led to the development of pre-clustering methods such ascanopy clustering, which can process huge data sets efficiently, but the resulting \"clusters\" are merely a rough pre-partitioning of the data set to then analyze the partitions with existing slower methods such ask-means clustering. Forhigh-dimensional data, many of the existing methods fail due to thecurse of dimensionality, which renders particular distance functions problematic in high-dimensional spaces. This led to newclustering algorithms for high-dimensional datathat focus onsubspace clustering(where only some attributes are used, and cluster models include the relevant attributes for the cluster) andcorrelation clusteringthat also looks for arbitrary rotated (\"correlated\") subspace clusters that can be modeled by giving acorrelationof their attributes.Examples for such clustering algorithms are CLIQUEandSUBCLU. Ideas from density-based clustering methods (in particular the DBSCAN/OPTICS family of algorithms) have been adapted to subspace clustering (HiSC,hierarchical subspace clustering and DiSH) and correlation clustering (HiCO,hierarchical correlation clustering, 4Cusing \"correlation connectivity\" and ERiCexploring hierarchical density-based correlation clusters). Several different clustering systems based onmutual informationhave been proposed. One is Marina Meilă'svariation of informationmetric;another provides hierarchical clustering.Using genetic algorithms, a wide range of different fit-functions can be optimized, including mutual information.Alsobelief propagation, a recent development incomputer scienceandstatistical physics, has led to the creation of new types of clustering algorithms. Evaluation (or \"validation\") of clustering results is as difficult as the clustering itself.Popular approaches involve \"internal\" evaluation, where the clustering is summarized to a single quality score, \"external\" evaluation, where the clustering is compared to an existing \"ground truth\" classification, \"manual\" evaluation by a human expert, and \"indirect\" evaluation by evaluating the utility of the clustering in its intended application. Internal evaluation measures suffer from the problem that they represent functions that themselves can be seen as a clustering objective. For example, one could cluster the data set by the Silhouette coefficient; except that there is no known efficient algorithm for this. By using such an internal measure for evaluation, one rather compares the similarity of the optimization problems,and not necessarily how useful the clustering is. External evaluation has similar problems: if we have such \"ground truth\" labels, then we would not need to cluster; and in practical applications we usually do not have such labels. On the other hand, the labels only reflect one possible partitioning of the data set, which does not imply that there does not exist a different, and maybe even better, clustering. Neither of these approaches can therefore ultimately judge the actual quality of a clustering, but this needs human evaluation,which is highly subjective. Nevertheless, such statistics can be quite informative in identifying bad clusterings,but one should not dismiss subjective human evaluation. When a clustering result is evaluated based on the data that was clustered itself, this is called internal evaluation. These methods usually assign the best score to the algorithm that produces clusters with high similarity within a cluster and low similarity between clusters. One drawback of using internal criteria in cluster evaluation is that high scores on an internal measure do not necessarily result in effective information retrieval applications.Additionally, this evaluation is biased towards algorithms that use the same cluster model. For example, k-means clustering naturally optimizes object distances, and a distance-based internal criterion will likely overrate the resulting clustering. Therefore, the internal evaluation measures are best suited to get some insight into situations where one algorithm performs better than another, but this shall not imply that one algorithm produces more valid results than another.Validity as measured by such an index depends on the claim that this kind of structure exists in the data set. An algorithm designed for some kind of models has no chance if the data set contains a radically different set of models, or if the evaluation measures a radically different criterion.For example, k-means clustering can only find convex clusters, and many evaluation indexes assume convex clusters. On a data set with non-convex clusters neither the use ofk-means, nor of an evaluation criterion that assumes convexity, is sound. More than a dozen of internal evaluation measures exist, usually based on the intuition that items in the same cluster should be more similar than items in different clusters.For example, the following methods can be used to assess the quality of clustering algorithms based on internal criterion: TheDavies–Bouldin indexcan be calculated by the following formula:DB=1n∑i=1nmaxj≠i(σi+σjd(ci,cj)){\\displaystyle DB={\\frac {1}{n}}\\sum _{i=1}^{n}\\max _{j\\neq i}\\left({\\frac {\\sigma _{i}+\\sigma _{j}}{d(c_{i},c_{j})}}\\right)}wherenis the number of clusters,ci{\\displaystyle c_{i}}is thecentroidof clusteri{\\displaystyle i},σi{\\displaystyle \\sigma _{i}}is the average distance of all elements in clusteri{\\displaystyle i}to centroidci{\\displaystyle c_{i}}, andd(ci,cj){\\displaystyle d(c_{i},c_{j})}is the distance between centroidsci{\\displaystyle c_{i}}andcj{\\displaystyle c_{j}}. Since algorithms that produce clusters with low intra-cluster distances (high intra-cluster similarity) and high inter-cluster distances (low inter-cluster similarity) will have a low Davies–Bouldin index, the clustering algorithm that produces a collection of clusters with the smallestDavies–Bouldin indexis considered the best algorithm based on this criterion. The Dunn index aims to identify dense and well-separated clusters. It is defined as the ratio between the minimal inter-cluster distance to maximal intra-cluster distance. For each cluster partition, the Dunn index can be calculated by the following formula: whered(i,j) represents the distance between clustersiandj, andd'(k) measures the intra-cluster distance of clusterk. The inter-cluster distanced(i,j) between two clusters may be any number of distance measures, such as the distance between thecentroidsof the clusters. Similarly, the intra-cluster distanced'(k) may be measured in a variety of ways, such as the maximal distance between any pair of elements in clusterk. Since internal criterion seek clusters with high intra-cluster similarity and low inter-cluster similarity, algorithms that produce clusters with high Dunn index are more desirable. The silhouette coefficient contrasts the average distance to elements in the same cluster with the average distance to elements in other clusters. Objects with a high silhouette value are considered well clustered, objects with a low value may be outliers. This index works well withk-means clustering, and is also used to determine the optimal number of clusters. In external evaluation, clustering results are evaluated based on data that was not used for clustering, such as known class labels and external benchmarks. Such benchmarks consist of a set of pre-classified items, and these sets are often created by (expert) humans. Thus, the benchmark sets can be thought of as agold standardfor evaluation.These types of evaluation methods measure how close the clustering is to the predetermined benchmark classes. However, it has recently been discussed whether this is adequate for real data, or only on synthetic data sets with a factual ground truth, since classes can contain internal structure, the attributes present may not allow separation of clusters or the classes may containanomalies.Additionally, from aknowledge discoverypoint of view, the reproduction of known knowledge may not necessarily be the intended result.In the special scenario ofconstrained clustering, where meta information (such as class labels) is used already in the clustering process, the hold-out of information for evaluation purposes is non-trivial. A number of measures are adapted from variants used to evaluate classification tasks. In place of counting the number of times a class was correctly assigned to a single data point (known astrue positives), suchpair countingmetrics assess whether each pair of data points that is truly in the same cluster is predicted to be in the same cluster. As with internal evaluation, several external evaluation measures exist,for example: Purity is a measure of the extent to which clusters contain a single class.Its calculation can be thought of as follows: For each cluster, count the number of data points from the most common class in said cluster. Now take the sum over all clusters and divide by the total number of data points. Formally, given some set of clustersM{\\displaystyle M}and some set of classesD{\\displaystyle D}, both partitioningN{\\displaystyle N}data points, purity can be defined as: This measure doesn't penalize having many clusters, and more clusters will make it easier to produce a high purity. A purity score of 1 is always possible by putting each data point in its own cluster. Also, purity doesn't work well for imbalanced data, where even poorly performing clustering algorithms will give a high purity value. For example, if a size 1000 dataset consists of two classes, one containing 999 points and the other containing 1 point, then every possible partition will have a purity of at least 99.9%. The Rand indexcomputes how similar the clusters (returned by the clustering algorithm) are to the benchmark classifications. It can be computed using the following formula: whereTP{\\displaystyle TP}is the number of true positives,TN{\\displaystyle TN}is the number oftrue negatives,FP{\\displaystyle FP}is the number offalse positives, andFN{\\displaystyle FN}is the number offalse negatives. The instances being counted here are the number of correctpairwiseassignments. That is,TP{\\displaystyle TP}is the number of pairs of points that are clustered together in the predicted partition and in the ground truth partition,FP{\\displaystyle FP}is the number of pairs of points that are clustered together in the predicted partition but not in the ground truth partition etc. If the dataset is of size N, thenTP+TN+FP+FN=(N2){\\displaystyle TP+TN+FP+FN={\\binom {N}{2}}}. \nOne issue with theRand indexis thatfalse positivesandfalse negativesare equally weighted. This may be an undesirable characteristic for some clustering applications. The F-measure addresses this concern,as does the chance-correctedadjusted Rand index. The F-measure can be used to balance the contribution offalse negativesby weightingrecallthrough a parameterβ≥0{\\displaystyle \\beta \\geq 0}. Letprecisionandrecall(both external evaluation measures in themselves) be defined as follows:P=TPTP+FP{\\displaystyle P={\\frac {TP}{TP+FP}}}R=TPTP+FN{\\displaystyle R={\\frac {TP}{TP+FN}}}whereP{\\displaystyle P}is theprecisionrate andR{\\displaystyle R}is therecallrate. We can calculate the F-measure by using the following formula:Fβ=(β2+1)⋅P⋅Rβ2⋅P+R{\\displaystyle F_{\\beta }={\\frac {(\\beta ^{2}+1)\\cdot P\\cdot R}{\\beta ^{2}\\cdot P+R}}}Whenβ=0{\\displaystyle \\beta =0},F0=P{\\displaystyle F_{0}=P}. In other words,recallhas no impact on the F-measure whenβ=0{\\displaystyle \\beta =0}, and increasingβ{\\displaystyle \\beta }allocates an increasing amount of weight to recall in the final F-measure.\nAlsoTN{\\displaystyle TN}is not taken into account and can vary from 0 upward without bound. The Jaccard index is used to quantify the similarity between two datasets. TheJaccard indextakes on a value between 0 and 1. An index of 1 means that the two dataset are identical, and an index of 0 indicates that the datasets have no common elements. The Jaccard index is defined by the following formula:J(A,B)=|A∩B||A∪B|=TPTP+FP+FN{\\displaystyle J(A,B)={\\frac {|A\\cap B|}{|A\\cup B|}}={\\frac {TP}{TP+FP+FN}}}This is simply the number of unique elements common to both sets divided by the total number of unique elements in both sets.\nNote thatTN{\\displaystyle TN}is not taken into account. The Dice symmetric measure doubles the weight onTP{\\displaystyle TP}while still ignoringTN{\\displaystyle TN}:DSC=2TP2TP+FP+FN{\\displaystyle DSC={\\frac {2TP}{2TP+FP+FN}}} The Fowlkes–Mallows indexcomputes the similarity between the clusters returned by the clustering algorithm and the benchmark classifications. The higher the value of the Fowlkes–Mallows index the more similar the clusters and the benchmark classifications are. It can be computed using the following formula:FM=TPTP+FP⋅TPTP+FN{\\displaystyle FM={\\sqrt {{\\frac {TP}{TP+FP}}\\cdot {\\frac {TP}{TP+FN}}}}}whereTP{\\displaystyle TP}is the number oftrue positives,FP{\\displaystyle FP}is the number offalse positives, andFN{\\displaystyle FN}is the number offalse negatives. TheFM{\\displaystyle FM}index is the geometric mean of theprecisionandrecallP{\\displaystyle P}andR{\\displaystyle R}, and is thus also known as theG-measure, while the F-measure is their harmonic mean.Moreover,precisionandrecallare also known as Wallace's indicesBI{\\displaystyle B^{I}}andBII{\\displaystyle B^{II}}.Chance normalized versions of recall, precision and G-measure correspond toInformedness,MarkednessandMatthews Correlationand relate strongly toKappa. The Chi indexis an external validation index that measure the clustering results by applying thechi-squared statistic. This index scores positively the fact that the labels are as sparse as possible across the clusters, i.e., that each cluster has as few different labels as possible. The higher the value of the Chi Index the greater the relationship between the resulting clusters and the label used. The mutual information is aninformation theoreticmeasure of how much information is shared between a clustering and a ground-truth classification that can detect a non-linear similarity between two clustering.Normalized mutual informationis a family of corrected-for-chance variants of this that has a reduced bias for varying cluster numbers. A confusion matrix can be used to quickly visualize the results of a classification (or clustering) algorithm. It shows how different a cluster is from the gold standard cluster. The validity measure (short v-measure) is a combined metric for homogeneity and completeness of the clusters To measure cluster tendency is to measure to what degree clusters exist in the data to be clustered, and may be performed as an initial test, before attempting clustering. One way to do this is to compare the data against random data. On average, random data should not have clusters.   ", "metadata": {"url": "https://en.wikipedia.org/wiki/Cluster_analysis", "title": "Cluster analysis", "headings": ["Contents", "Definition", "Algorithms", "Connectivity-based clustering (hierarchical clustering)", "Centroid-based clustering", "Model-based clustering", "Density-based clustering", "Grid-based clustering", "Recent developments", "Evaluation and assessment", "Internal evaluation", "External evaluation", "Cluster tendency", "Applications", "Biology, computational biology and bioinformatics", "Medicine", "Business and marketing", "World Wide Web", "Computer science", "Social science", "Others", "See also", "Specialized types of cluster analysis", "Techniques used in cluster analysis", "Data projection and preprocessing", "Other", "References"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Cluster_analysis", "https://en.wikipedia.org/wiki/Cluster_analysis", "https://en.wikipedia.org/wiki/Cluster_analysis", "https://en.wikipedia.org/wiki/Machine_learning", "https://en.wikipedia.org/wiki/Data_mining", "https://en.wikipedia.org/wiki/Supervised_learning", "https://en.wikipedia.org/wiki/Unsupervised_learning", "https://en.wikipedia.org/wiki/Semi-supervised_learning"]}},
{"id": "7aafee556869", "content": "Thisglossary of virologyis a list of definitions of terms and concepts used invirology, the study ofviruses, particularly in the description of viruses and their actions. Related fields includemicrobiology,molecular biology, andgenetics. Often simply called anantiviral. Also simply called aphage. Alsocytopathogenic effect. Also called agag. Also sometimes called amycophage. Also calledantigenic imprintingand theHoskins effect. Also calledpassaging. Also calledviral burdenandviral titre. Also called aviral particle.", "metadata": {"url": "https://en.wikipedia.org/wiki/Glossary_of_virology", "title": "Glossary of virology", "headings": ["A", "B", "C", "D", "E", "G", "H", "I", "K", "L", "M", "N", "O", "P", "Q", "R", "S", "T", "U", "V", "Z", "See also", "References"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Glossary_of_virology", "https://en.wikipedia.org/wiki/Glossary_of_virology", "https://en.wikipedia.org/wiki/Glossary_of_virology", "https://en.wikipedia.org/wiki/Virology", "https://en.wikipedia.org/wiki/Virus", "https://en.wikipedia.org/wiki/Microbiology", "https://en.wikipedia.org/wiki/Molecular_biology", "https://en.wikipedia.org/wiki/Genetics"]}},
{"id": "b925b5d200aa", "content": " TheJulius Maximilian University of Würzburg(also referred to as theUniversity of Würzburg, in GermanJulius-Maximilians-Universität Würzburg) is a public research university inWürzburg, Germany.Founded in 1402, it is one of the oldest institutions of higher learning in Germany.The university initially had a brief run and was closed in 1415. It was reopened in 1582 on the initiative ofJulius Echter von Mespelbrunn. Today, the university is named for Julius Echter von Mespelbrunn andMaximilian Joseph. The University of Würzburg is part of theU15group of research-intensive German universities.The university is also a member of theCoimbra Group.In the winter semester 2022/2023, 26,787 students were enrolled, of which 16,351 were women and 3,250 were first semester university students.The University is associated with 14 Nobel laureates. Its official name isJulius-Maximilians-Universität Würzburg(or \"Julius-Maximilian University of Würzburg\") but it is commonly referred to as theUniversity of Würzburg.This name is taken fromJulius Echter von Mespelbrunn,Prince-Bishop of Würzburg, who reestablished the university in 1582,and Prince ElectorMaximilian Joseph, the prince under whom secularization occurred at the start of the 19th century. The university's central administration, foreign student office, and several research institutes are located within the area of the old town, while the newliberal artscampus, with its modern library, overlooks the city from the east. The university today enrolls approximately 29,000 students, out of which more than 1,000 come from other countries. The university was founded as the \"High School of Würzburg\" on an initiative started in 1401 by Prince Bishop Johannvon Egloffstein. He wanted to transform the \"Gymnasium herbipolense\" into a university with four faculties hoping that an influx of teaching staff and students in his territory would cover the need for qualified lawyers and clerics and thus lead to an upturn in the city's economy. He bought the buildings needed for teaching from members of his cathedral chapter. On 10 December 1402, he was granted the required privilege fromPope Boniface IX.This put Würzburg among the cities with the oldest universities in the then German-speaking area –Prague(1348),Vienna(1365),Heidelberg(1386),Cologne(1388) andErfurt(1392), and made Würzburg the oldest university in Bavaria. Among the teachers at the university were Winand von Steeg,Johannes Ambundi and Bartholomäus Fröwein. Already before 1430, however, teaching was suspended shortly after the death of Prince Bishop von Egloffstein. The reason for the decline was primarily the lack of funding, since it had not been possible to establish a foundation that had its own benefice. On 30 November 1413, the rector of the university, Johann Zantfurt, was murdered by his valet; the circumstances were never clarified. Later, Lorenz Fries bought the university building. In 1427, the \"Hohe Schule\" was mentioned for the last time in a document. By that time, it had not been dissolved yet, but had become insignificant.Friedrich von Wirsberg, who became prince-bishop in 1558, was the first to consider rebuilding the university. Due to problems with the clergy and administration, however, he was unable to realize his plans After classes had been resumed in some of the subjects in 1551 and the first doctorates had already been awarded in 1567, the Würzburg Prince-BishopJulius Echter von Mespelbrunn, during theCounter-Reformation, in 1575, first obtained the imperial and then, in 1576, the papal privileges to re-establish the university(see alsoErasmus Neustettercalled Stürmer). This time, financing was better ensured, and student regulations were stricter. On 2 January 1582,first the theological and philosophical faculties were reopened, and their deans appointed. The name of the university was \"Academia Iulia\" (Julius University).The university sealwas not created until the following year, and thus bears the year 1583. Statutes for the medical faculty were drawn up in 1587. Although the number of lecturers was not complete until 1593, the first medical student, Georg Leyerer from Ebersbrunn, was already enrolled on 2 October 1585. In 1591, the four-winged university building and the associated church (Neubaukirche) in one of its angles, both commissioned by Julius Echter, were completed. It seems certain that the architect of the building was Georg Robin. Theologians, lawyers and humanities scholars were accommodated in this complex which today is called \"Alte Universität\". The medical faculty found its home in Juliusspital. Initially, the university was only open to Catholic students. In 1734, Prince BishopFriedrich Karl von Schönbornissued new study regulations which opened it up to non-Catholics, too. First, theology in Würzburg was determined by Jesuits. But in 1773, the Würzburg Jesuit College was dissolved, andAdam Friedrich von Seinsheimhired followers of the Enlightenment for the theological faculty and thus laid the foundation for its future orientation. From then on, and especially under his successorFranz Ludwig von Erthal, Enlightenment theologians became increasingly active in Würzburg. Nevertheless, it was only in the early 19th century, after Würzburg had come under Bavarian rule, that the university gave up its ecclesiastical-Catholic character. The modern development of medical subjects began in the 18th century with the establishment of the medical clinic – in 1767, the \"internist\" and chemist Franz Heinrich Meinolf Wilhelm became the first head of the Juliusspital hospital. The surgical university clinic was established in 1769 underCarl Caspar von Siebold. In 1796, the physician and court medicus Anton Müller (1755–1827) began working at Juliusspital in Würzburg; although he never belonged to the university, he became the first psychiatrist in the hospital and the first to publish on his specialty. Franz Heinrich Meinolf Wilhelm, who as a professor held lectures in German for the first time from 1785, was the first to practice experimental chemistry at the University of Würzburg. Around 1800, the first student associations were founded in Würzburg. The Scientific dentistry in Würzburg began with the appointment of Carl Joseph Ringelmannas professor in 1807. In 1822, a faculty of political science was established at the university. During thecoalition wars, the university was renamed several times: First \"Churfürstliche Julius-Universität\" (1803), \"Julius Maximilians Universität\" (1803/04–1805/06), then \"Kurfürstliche Universität zu Würzburg\" (1806–1806/07), \"Großherzogliche Universität zu Würzburg\" (1807–1814), and finally \"Königliche Universität zu Würzburg\" (1815–1838). The names reflected the different affiliations of the university to theElectorate of Bavaria, which perished in 1806, to theGrand Duchy of Würzburg, which existed as a Rhineland state until 1814, and then to theKingdom of Bavaria. In the winter semester of 1838/39, the \"Königliche Universität zu Würzburg\" was renamed \"Königliche Julius-Maximilians-Universität\" and two years later \"Königlich Bayerische Julius-Maximilians-Universität\" which was to be its name for almost 80 years. After 1850, the university experienced a strong upswing. Numerous new buildings were created: for medicine in the vicinity ofJuliusspitaland Pleicherwall, for the natural sciences on today's Röntgenring and on Koellikerstraße, for dentistry at Pleichertor (demolished in 1879), and for the mental hospital on Schalksberg. Basic medical subjects were taught and researched in the \"Kollegienhaus\", which was completed in 1853 and was the first modern \"biocentre\"in Germany. The first full professor of ophthalmology, appointed in 1866 by the Bavarian king, was Robert Ritter von Welz, a student ofAlbrecht von Graefe. In 1857, the doctor, who had been teaching ophthalmology and dentistry in Würzburg since 1850, opened a private eye clinic in the former birthing house ofAdam Elias von Sieboldon Klinikstraße 6. On 4 January 1858, he acquired the building, which was donated by the Welzsche Marienstiftung for Poor People with Eye Diseases according to Welz' will in 1878 and became the first Würzburg university eye clinic. The former delivery house, which had been founded in 1805 as the first maternity clinic in Würzburg and a training center for midwives and obstetricians, in 1857, under Friedrich Wilhelm Scanzoni von Lichtenfels, moved to a new building on Klinikstraße 8. As an assistant to the surgeonCajetan von Textor,Robert von Welzwas also one of the pioneers of ether anesthesia in the German-speaking world. He developed an inhaler and, after testing it on himself and others in the winter of 1846/47, published the first work on it, and thus established modern anesthesiology in Würzburg. In the winter semester of 1876/77, the number of students at the University of Würzburg exceeded 1,000 for the first time. In 1888, the university, whose medical faculty was one of the most important after Vienna and Prague between 1850 and 1880, received its own pharmaceutical institute. On 28 October 1896, a new main building, called \"Neue Universität\", was inaugurated on Sanderring (its construction began in 1892); it is still the seat of the university management today. On 3 June 1896,Marcella O'Grady Boveriwas the first woman to be admitted to the Würzburg Medical Faculty. The first woman to habilitate at the University of Würzburg was the psychologist Maria Schorn in 1929. A new eye clinic was opened on Röntgenring 12 in 1901, with the portrait of Welz engraved over the portal. Welzhaus on Klinikstraße 6 was affiliated to the women's clinic on Klinikstraße 8, which existed there until 1934, and connected to it by a corridor on the first floor, which was destroyed in World War II and restored in 1974. Welzhaus which was also destroyed except for its outer façade on 16 March 1945, was rebuilt in 1953/1954. The Mathematical Institute was accommodated there until 1974, when the building was affiliated to the Medical Polyclinic. Between 1901 and 1911, five Würzburg researchers, whose appointment was mainly due to the mathematicianFriedrich Prym(dean and rector), were awarded Nobel Prizes.This strongly contributed to the international importance of the University of Würzburg, particularly of its philosophical faculty. After the November Revolution of 1918/19, which ended monarchy in Bavaria, the university also lost its title \"Königlich Bayerisch\" and was given its current name: \"Julius-Maximilians-Universität\". The medical faculty separated from Juliusspital and in 1921 moved to the new University Hospital of Würzburg on the outskirts of the city. It was called \"Luitpold Krankenhaus\". The State Luitpold Hospital was solemnly handed over on 2 November 1921, and within one year the various clinics moved into it. By the summer semester that year, the proportion of students enrolled in medicine had risen to 60 percent. In 1934, under its director Carl Joseph Gauss, the university women's clinic and the affiliated midwifery school moved from Welzhaus on Klinikstraße to the Grombühl district. An Institute for Genetics and Race Research was set up in Welzhaus on Klinikstraße 6 in November 1938 and inaugurated in May 1939. Between 1933 and 1945, the University of Würzburg deprived 184 scientists of their doctoral degrees. Above all, scientists of Jewish origin were thus degraded. After the critical processing of these events in 2010, the university posthumously rehabilitated these researchers in a public ceremony in May 2011. After theSecond World War, the faculty of theology was the first to start anew on 1 October 1945. The faculty of medicine (dean: Jürg Zutt) followed; it was officially reopened with the constitutive faculty meeting on 11 January 1947, and began its lectures in the winter semester of 1946 /47. On 12 March 1947, the university was solemnly reopened. According to a report by rector Josef Martin (philologist), the military government had dismissed 123 of the 150 professors who had worked before 1945 and only allowed 27 back to lecture at the university. In 1955,Julius Büdelsignificantly developed Africa Research in Würzburg. It was mainly due to the results of Büdel's and Horst Mensching's research trips, that Würzburg had become an important center for geographical research on Africa by the late 1970s. On 11 May 1965, the university laid the foundation stone for the new Hubland Campus on a hill in the east of Würzburg. The 111-hectare (270-acre) site had been acquired by theFree State of Bavariafrom the city of Würzburg in 1962 already, to make room for the more than 6,000 students enrolled at Alma Julia. In the years that followed, numerous new buildings were put up there, among them the chemistry center (from 1965 to 1972 the rooms for organic chemistry, pharmacy and food chemistry, inorganic chemistry and a central building were set up), the philosophy building, the university library, the biocentre (1992), sports facilities, buildings for physics, mathematics and computer science, a computer centre, a new canteen and student residences. In 2011, the central lecture hall and seminar building for all faculties (Z6) was inaugurated on Hubland campus, as well as a new internship building for the natural sciences. Starting from the existing Surgical Clinic (head: Ernst Kern), new subjects, departments and clinics developed in the seventies: in 1970, the Urological University Clinic (Hubert Frohmüller); in 1978, the Department for Special Thoracic Surgery (Associate Professor H. J. Viereck), the Department for Surgical X-ray Diagnostics (Extraordinarius G. Viehweger), and the Department for Transfusion Medicine and Immunohematology (Extraordinarius D. Wiebecke). Furthermore, on 16 June 1969, the first Bavarian chair for anesthesiology was established in the medical faculty, headed by his professor Karl-Heinz Weis (* 1927). Weis had already been in charge of the anesthesiology department since 1966 when Werner Wachsmuth was head of the surgical clinic. The former Chair for Genetic Science and Race Research, which Gebsattel had taken over, was renamed the Chair for Medical Psychology and Psychotherapy in 1965 and was filled by Dieter Wyss in 1968. In 1979, Holger Höhn was appointed to the Institute for Human Genetics, which had emerged from this chair. In 1978 the Institute for X-ray Diagnostics was established in the Medical Clinic under Extraordinarius H. Braun. In 1973, over 10,000 students were enrolled at the University of Würzburg, and the former conservatory became a university of music. In 1981, the University Library of Würzburg moved into its new building on Hubland. On 31 January 1983, a poisoned drink attack was carried out at the university. The drinks, which were mixed with thallium(I) sulfate, were put in front of a lecture hall together with a note declaring them as leftovers from a carnival party and donating them to the freshmen. The medical student Robert A. died as a result of the poisoning; eleven other students had to be treated in the hospital; the law student Peter S. sustained lasting damage. The perpetrator could never be identified. On 12 April 2011, the university opened its new Campus North, right next to Hubland campus: An additional site of 39 hectares is now available for the future development of the university. Campus North used to be a US military base (Leighton Barracks). After the Americans withdrew in January 2009, the university had the opportunity to use part of the former barracks for itself. This conversion from military to civilian area made rapid progress, and the campus canteen was inaugurated in 2014. The tower of Neubaukirche (university auditorium), with its height of 91 meters the city's tallest church tower, has one of the fourcarillonsin Bavaria. Between Easter and Christmas, public concerts of about 30 minutes are given on it every Wednesday at 5:30 p.m. In March 2016, JMU was the first university in Bavaria to be awarded the \"Bavaria barrier-free\" signet.The award was given for the removal of structural barriers, especially in new buildings, and for the establishment of the Information Center for People with Disabilities and Chronic Diseases (KIS), created in 2008. On 7 January 2019, the online portalWueStudyof the University of Würzburg was launched after a lengthy planning and processing phase. It replaces the former sb@home portal and uses the HISinOne software developed by the Hochschul-Informations-System. Today, around 28,000 students are enrolled at the university. In addition, there are more than 8,600 students at theUniversity of Applied Sciences Würzburg-Schweinfurt, founded on 1 August 1971, and around 750 students at the University of Music. Thus, every fourth citizen of Würzburg is a student. With a total of more than 10,000 employees, the university and its hospital are among the largest employers in the region. Due to the university's history, its institutes and hospitals are spread over the entire city. Facilities are found in the following places, among others: The University of Würzburg has been ranked globally and nationally in severaluniversity rankings. As of 2024, theQS World University Rankingsplaces the university at 440 globally and 23rd in Germany.According to theTimes Higher Education World University Rankingsfor 2024, it is positioned at 175th globally and 17th nationally.In the 2023ARWU World Rankings, the University of Würzburg is within the 201–300 range globally and within the 10–19 range nationally.", "metadata": {"url": "https://en.wikipedia.org/wiki/University_of_W%C3%BCrzburg", "title": "University of Würzburg", "headings": ["Contents", "Name", "History", "First founding in 1402", "From re-founding in 1582 to 1945", "Post War period", "Miscellaneous", "The University and the city", "Research institutions", "Campus", "Faculties", "Rankings", "Nobel laureates", "Worked at the university", "Temporarily worked at the university", "See also", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/University_of_W%C3%BCrzburg", "https://en.wikipedia.org/wiki/University_of_W%C3%BCrzburg", "https://en.wikipedia.org/wiki/University_of_W%C3%BCrzburg", "https://en.wikipedia.org/wiki/Geographic_coordinate_system", "https://en.wikipedia.org/wiki/Public_university", "https://en.wikipedia.org/wiki/Chancellor_(education)", "https://en.wikipedia.org/wiki/University_president", "https://en.wikipedia.org/wiki/W%C3%BCrzburg"]}},
{"id": "2137023d22bc", "content": "Andranik Semovich Tangian (Melik-Tangyan)(Russian: Андраник Семович Тангян (Мелик-Тангян)); born March 29, 1952) is a SovietArmenian-German mathematician, political economist and music theorist.He is professor of the Institute for Economics (ECON) of the Karlsruhe Institute of Technology. As a self-taught composer, he debuted with orchestral music to the playThe Last Trimesterat the MoscowCentral Children Theater[de]in 1977. Tangian spent the academic year 1990/91 at theUniversity of Hagenand published his first monograph on the mathematical theory of democracy in 1991.During the next two academic years, Tangian has been visiting professor/researcher at the computer music studio ACROE–LIFIA of theGrenoble Institute of Technology, where he wrote a monograph on artificial perception and music. From 1993 to 2002 Tangian ran a project on constructing objective functions for econometric decision models at theUniversity of Hagen. Combining thesocial choiceandpublic choiceapproaches, Tangian's theory mathematically studies the fundamental concept to modern democracies – that of political representation.For this purpose, several indices of representativeness are introduced and used for both theoretical analysis and applications. The method developed within the framework of the Mathematical theory of democracy assumes that instead of casting votes for candidates by name, electors give Yes/No-answers to political questions as raised in the candidates' manifestos.The balance of public opinion on these issues thus identified is then used to find the most representative candidates and form the most representative parliament. For decision models, Tangian has developed several methods for constructing objective functions (= composite indices that embody decision-makers' preferences).In particular, they are applied to optimize budgets for 16 Westphalian universitiesand the European subsidies to 271 German regions for equalizing unemployment rates. Tangian's ten empirical models offlexicurity— the European policy intended to compensate theflexibilization of employmentby social security measures — show that it fails to meet expectations.Alternatively, the job quality indicators developed within this researchare proposed for the workplace tax that, by analogy with the green tax, should charge employers for bad working conditions considered \"social pollution\". According to Tangian, the current rise in inequality is caused, among other things, by the increasing productivity, which enables to underpay workers in so-called \"labor equivalents\", maintaining nevertheless an impression of fair pay, and use the surplus profit to enrich the upper strata of the society. The approach implements Tangian'sprinciple of correlativity of perceptionfor structuring data without knowing the structures, which is based on memory-saving representations.This model is used for polyphonic voice separation/chord recognition and tempo tracking under variable tempo. Tangian has proposed to segment the musical text with respect to the segment functions and show the segments using tempo envelopes, dynamics and other execution techniques. All of these are displayed in a conditional \"orchestral score\".This idea is also applied to theatrical performance and its notation. In the 2000s, Tangian has developed algorithms for finding rhythmiccanonsandfugues, i.e. polyphonic structures generated by one or two rhythmic patterns that in their interaction produce a regular pulse train, however, with no coinciding time events from different voices.As harmony algorithms, 2D and 3D proximity maps for major and minor keys and chords have been developed.", "metadata": {"url": "https://en.wikipedia.org/wiki/Andranik_Tangian", "title": "Andranik Tangian", "headings": ["Contents", "Biography", "Works", "Mathematical theory of democracy", "Third Vote election method", "Decision theory", "Flexicurity", "Inequality", "Artificial perception and automatic notation of music", "Modeling interpretation", "Algorithmic composition", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Andranik_Tangian", "https://en.wikipedia.org/wiki/Andranik_Tangian", "https://en.wikipedia.org/wiki/Andranik_Tangian", "https://en.wikipedia.org/wiki/Moscow", "https://en.wikipedia.org/wiki/Moscow_State_University", "https://en.wikipedia.org/wiki/MSU_Faculty_of_Mechanics_and_Mathematics", "https://en.wikipedia.org/wiki/Applied_mathematics", "https://en.wikipedia.org/wiki/Political_economy"]}},
{"id": "e422701af4ba", "content": " Avirtual reality headset(VR headset) is ahead-mounted devicethat uses3D near-eye displaysandpositional trackingto provide avirtual realityenvironment for the user. VR headsets are widely used withVR video games, but they are also used in other applications, including simulators and trainers. VR headsets typically include astereoscopicdisplay (providing separate images for each eye),stereo sound, and sensors likeaccelerometersandgyroscopesfor tracking theposeof the user's head to match the orientation of the virtual camera with the user's eye positions in the real world.Mixed reality(MR) headsets are VR headsets that enable the user to see and interact with the outside world. Examples of MR headsets include theApple Vision ProandMeta Quest 3. VR headsets typically use at least oneMEMSIMU forthree degrees of freedom(3DOF) motion tracking, and optionally more tracking technology forsix degrees of freedom(6DOF) motion tracking. 6DOF devices typically use asensor fusionalgorithm to merge the data from the IMU and any other tracking sources, typically either one or more external sensors, or \"inside-out\" trackingusing outward facing cameras embedded in the headset. The sensor fusion algorithms that are used are often variants of aKalman filter. VR headsets can supportmotion controllers, which similarly combine inputs from accelerometers and gyroscopes with the headset's motion tracking system. Most headsetsare reliant on apersonal computerto operate. Some \"standalone\" headsets are based on amobile operating systemandsmartphone-like hardware, allowing VR apps to run directly on the device, while also allowing VR applications to be streamed from a PC over aUSBorWi-Ficonnection. Virtual reality headsets and viewers have also been designed for smartphones, where the device's screen is viewed through lenses acting as astereoscope, rather than using dedicated internal displays. VPL Researchwas a company that made early VR headsets in the 1980s. TheSega VRwas announced in 1991 and seen in early 1993 at the WinterCES. It was never released for consoles,but was utilized for theSegaVR-1 motion simulatorarcade attractionin 1994.Another early VR headset, theForte VFX1, was announced at CES in 1994. The VFX-1 has stereoscopic displays, 3-axis head-tracking, and stereo headphones. Sonyreleased theGlasstronin 1997, which has an optional positional sensor, allowing the wearer to view the surroundings, with the perspective moving as the user's head moves, giving a deep sense of immersion. These VR headsets gaveMechWarrior 2players a new visual perspective of seeing the battlefield from inside the cockpit of their craft. However, these early headsets failed commercially due to their limited technology,and they were described byJohn Carmackas like \"looking throughtoilet paper tubes\". In 2012, acrowdfundingcampaign began for a VR headset known asOculus Rift; the project was led by several prominentvideo game developers, includingJohn Carmackwho later became the company'sCTO.In March 2014, the project's parent companyOculus VRwas acquired byFacebookfor $2 billion.The final consumer-oriented release ofOculus Riftbegan shipping on 28 March 2016. In March 2014,Sonydemonstrated a prototype headset forPlayStation 4,which was later namedPlayStation VR.In 2014,Valvedemonstrated some headset prototypes,which led to a partnership withHTCto produce theVive, which focuses on\"room-scale\"VR environments that users can naturally navigate within and interact with. The headset uses Valve's \"SteamVR\" software platform.The Vive was released in April 2016and PlayStation VR in October 2016. Googlereleased a series of specifications and associatedDIYkits for virtual reality viewers known asGoogle Cardboard; these viewers are capable of being constructed using low-cost materials (and a smartphone with a gyroscope), such as cardboard (hence the naming).Samsung Electronicspartnered with Oculus VR to co-develop theSamsung Gear VR(which is only compatible with someSamsung Galaxydevices).LG Electronicsdeveloped a headset with dedicated displays for itsLG G5smartphone known as LG 360 VR.In March 2017, Microsoft launched a platform for VR andmixed realityheadsets running onWindows 10known asWindows Mixed Reality, with VR headsets from multiple partners including PC makersAcer,Dell,HP Inc., andLenovo. In 2018, Oculus released theOculus Go, a standalone headset running capable of running VRappson embedded mobile computing hardware, thus not needing a PC or an inserted smartphone to operate.In June 2019, Valve released their own in-house SteamVR headset, theValve Index.In an October 2019 report, Sony, Facebook (Oculus), and HTC were identified by Trend Force as the three largest manufacturers of VR hardware.2019 saw Facebook release the first-generationOculus Quest, a successor to the Oculus Go concept which supports motion controllers and positional tracking with 6DOF.Subsequent releases of the Quest line included theQuest 2(released September 2020) andQuest 3(October 2023). There are different optics and visual qualities that affect how an individual perceives the image quality and how they experience the virtual world. The image clarity depends on the display resolution, optic quality, refresh rate, and field of view. Because virtual reality headsets stretch a single display across a widefield of view(up to 110° for some devices according to manufacturers), the magnification factor makes flaws in display technology much more apparent. One issue is the so-calledscreen-door effect, where the gaps between rows and columns ofpixelsbecome visible, akin to looking through ascreen door.This was especially noticeable in earlier prototypes and development kits,which had lowerresolutionsthan the retail versions. Thelensesof the headset are responsible for mapping the up-close display to a wide field of view,while also providing a more comfortable distant point offocus. One challenge with this is providing consistency of focus: because eyes are free to turn within the headset, it is important to avoid having to refocus to preventeye strain. Fresnel lensesare commonly used in virtual reality headsets due to their compactness and lightweight structure.The lenses do not use multiple pieces of material in their lenses like other lenses, but the lens will be broken down into sections, allowing the individual to have a wider range of view. The issue seen with the lens consists of seeing the ridges of the lenses when the headset is not properly aligned on the head. The lenses introducedistortionandchromatic aberration, which are typically corrected insoftware.The lenses can also be adjusted dynamically to account for a user's eyeglass prescription so that the user can use the headset without corrective eyeglasses. Virtual reality headsets have significantly higher requirements forlatency—the time it takes from a change in input to have a visual effect—than ordinary video games.If the system is too sluggish to react to head movement, then it can cause the user to experiencevirtual reality sickness, a kind of motion sickness.According to a Valve engineer, the ideal latency would be 7–15milliseconds. Thegraphics processing unit(GPU) also needs to be powerful enough to render the required amount of frames. Oculus cited the limited processing power ofXbox OneandPlayStation 4as the reason why they targeted thePC gamingmarket with their first devices. Foveated renderingis a new technique to reduce the rendering workload. It useseye trackinghardware to determine at what point the user is looking and reduces rendering resolution farther from the user's gaze. This can be unnoticeable to the user because humanperipheral visionis far less sensitive than thefovea. Virtual reality headsets are being currently used as a means to train medical students forsurgery. It allows them to perform essential procedures in a virtual, controlled environment. Students perform surgeries on virtual patients, which allows them to acquire the skills needed to perform surgeries on real patients.It also allows the students to revisit the surgeries from the perspective of the leadsurgeon. Traditionally, students had to participate in surgeries and often they would miss essential parts. Now, with the use of VR headsets, students can watch surgical procedures from the perspective of the lead surgeon without missing essential parts. Students can also pause, rewind, and fast-forward surgeries. They also can perfect their techniques in a real headset, mounted in a risk-free environment. Besides training purposes, augmented reality headsets are also already being used forimage-guided surgery. VR headset mounted smartphones have been used to capture high-quality videos and images of the retina for documenting peripheral retinal lesions. Virtual reality headsets have been used by theUnited States Armed Forces. It is a particularly useful tool for training military personnel without putting them in harm's way. The virtual reality headset allows military personnel to interact with virtual reality people to make it feel real. They can talk to one another and do varying actions to make the virtual reality world feel like they are actually in the real world. There are also disadvantages and advantages when military personnel use the headset. The disadvantage is the headset is made for an indoor area, with a cool environment, and away from any heat, so when military personnel has just the headset on, no military equipment, it is not like their basic training. The advantages consist of repeating the situations multiple times and the cost of having the headset is less, due to no military equipment being needed. Virtual reality headsets are now being used to train employees in health and safety procedures. This allows trainees to experience hazardous situations in a safe, virtual environment. They can practise responding to fires, machinery failures, or chemical spills without real-world risk. Traditionally,safety trainingrelied on static materials or in-person drills. With VR, trainees can interact with scenarios, repeat sessions, and improve their reactions. This makes training more engaging and effective. Companies also benefit from reduced costs and improved compliance tracking. Media related toVirtual reality headsetsat Wikimedia Commons", "metadata": {"url": "https://en.wikipedia.org/wiki/Virtual_reality_headset", "title": "Virtual reality headset", "headings": ["Contents", "History", "Technology", "Resolution and display quality", "Optics", "Latency requirements", "Uses in various fields", "Medical training and diagnostics", "Military training", "Health and Safety Training", "See also", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Virtual_reality_headset", "https://en.wikipedia.org/wiki/Virtual_reality_headset", "https://en.wikipedia.org/wiki/Virtual_reality_headset", "https://en.wikipedia.org/wiki/Meta_Quest_3", "https://en.wikipedia.org/wiki/Head-mounted_display", "https://en.wikipedia.org/wiki/3D_near-eye_display", "https://en.wikipedia.org/wiki/Positional_tracking", "https://en.wikipedia.org/wiki/Virtual_reality"]}},
{"id": "e8dfffb6fe8c", "content": "Risk managementis the identification, evaluation, and prioritization ofrisks,followed by the minimization, monitoring, and control of the impact or probability of those risks occurring.Risks can come from various sources (i.e,threats) including uncertainty ininternational markets,political instability, dangers of project failures (at any phase in design, development, production, or sustaining of life-cycles),legal liabilities,credit risk,accidents,natural causes and disasters, deliberate attack from an adversary, or events of uncertain or unpredictableroot-cause.Retail traders also apply risk management by using fixed percentage position sizing and risk-to-reward frameworks to avoid large drawdowns and support consistent decision-making under pressure. Two types of events are analyzed in risk management: risks and opportunities. Negative events can be classified as risks while positive events are classified as opportunities. Risk managementstandardshave been developed by various institutions, including theProject Management Institute, theNational Institute of Standards and Technology,actuarialsocieties, andInternational Organization for Standardization.Methods, definitions and goals vary widely according to whether the risk management method is in the context ofproject management,security,engineering,industrial processes,financial portfolios,actuarial assessments, orpublic healthandsafety. Certain risk management standards have been criticized for having no measurable improvement on risk, whereas the confidence in estimates and decisions seems to increase. Strategies to manage threats (uncertainties with negative consequences) typically include avoiding the threat, reducing the negative effect or probability of the threat, transferring all or part of the threat to another party, and even retaining some or all of the potential or actual consequences of a particular threat. The opposite of these strategies can be used to respond to opportunities (uncertain future states with benefits). As aprofessional role, a risk managerwill \"oversee the organization's comprehensive insurance and risk management program, assessing and identifying risks that could impede the reputation, safety, security, or financial success of the organization\", and then develop plans to minimize and/or mitigate any negative (financial) outcomes. Risk analystssupport the technical side of the organization's risk management approach: once risk data has been compiled and evaluated, analysts share their findings with their managers, who use those insights to decide among possible solutions. \nSee alsoChief Risk Officer,internal audit, andFinancial risk management § Corporate finance. Risk is defined as the possibility that an event will occur that adversely affects the achievement of an objective.Uncertainty, therefore, is a key aspect of risk.Risk management appears in scientific and management literature since the 1920s.It became a formal science in the 1950s, when articles and books with \"risk management\" in the title also appear in library searches.Most of research was initially related to finance and insurance.One popular standard clarifying vocabulary used in risk management isISO Guide 31073:2022, \"Risk management — Vocabulary\". Ideally in risk management, a prioritization process is followed.Whereby the risks with the greatest loss (or impact) and the greatestprobabilityof occurring are handled first. Risks with lower probability of occurrence and lower loss are handled in descending order. In practice the process of assessing overall risk can be tricky, and organisation has to balance resources used to mitigate between risks with a higher probability but lower loss, versus a risk with higher loss but lower probability.Opportunity costrepresents a unique challenge for risk managers. It can be difficult to determine when to put resources toward risk management and when to use those resources elsewhere. Again, ideal risk management optimises resource usage (spending, manpower etc), and also minimizes the negative effects of risks. Opportunities first appear in academic research or management books in the 1990s. The first PMBoKProject Management Body of Knowledgedraft of 1987 doesn't mention opportunities at all. Modern project management school recognize the importance of opportunities. Opportunities have been included in project management literature since the 1990s, e.g. in PMBoK, and became a significant part of project risk management in the years 2000s,when articles titled \"opportunity management\" also begin to appear in library searches.Opportunity managementthus became an important part of risk management. Modern risk management theory deals with any type of external events, positive and negative. Positive risks are calledopportunities. Similarly to risks, opportunities have specific mitigation strategies: exploit, share, enhance, ignore. In practice, risks are considered \"usually negative\". Risk-related research and practice focus significantly more on threats than on opportunities. This can lead to negative phenomena such astarget fixation. For the most part, these methods consist of the following elements, performed, more or less, in the following order: The Risk managementknowledge area, as defined by theProject Management Body of KnowledgePMBoK, consists of the following processes: TheInternational Organization for Standardization(ISO) identifies the following principles for risk management: Benoit Mandelbrotdistinguished between \"mild\" and \"wild\" risk and argued that risk assessment and management must be fundamentally different for the two types of risk.Mild risk followsnormalor near-normalprobability distributions, is subject toregression to the meanand thelaw of large numbers, and is therefore relatively predictable. Wild risk followsfat-tailed distributions, e.g.,Paretoorpower-law distributions, is subject to regression to the tail (infinite mean or variance, rendering the law of large numbers invalid or ineffective), and is therefore difficult or impossible to predict. A common error in risk assessment and management is to underestimate the wildness of risk, assuming risk to be mild when in fact it is wild, which must be avoided if risk assessment and management are to be valid and reliable, according to Mandelbrot. According to the standardISO 31000, \"Risk management – Guidelines\", the process of risk management consists of several steps as follows: This involves: After establishing the context, the next step in the process of managing risk is to identify potential risks. Risks are about events that, when triggered, cause problems or benefits. Hence, risk identification can start with the source of problems and those of competitors (benefit), or with the problem's consequences. Some examples of risk sources are: stakeholders of a project, employees of a company or the weather over an airport. When either source or problem is known, the events that a source may trigger or the events that can lead to a problem can be investigated. For example: stakeholders withdrawing during a project may endanger funding of the project; confidential information may be stolen by employees even within a closed network; lightning striking an aircraft during takeoff may make all people on board immediate casualties. The chosen method of identifying risks may depend on culture, industry practice and compliance. The identification methods are formed by templates or the development of templates for identifying source, problem or event. Common risk identification methods are: Once risks have been identified, they must then be assessed as to their potential severity of impact (generally a negative impact, such as damage or loss) and to the probability of occurrence.These quantities can be either simple to measure, in the case of the value of a lost building, or impossible to know for sure in the case of an unlikely event, the probability of occurrence of which is unknown. Therefore, in the assessment process it is critical to make the best educated decisions in order to properly prioritize the implementation of therisk management plan. Even a short-term positive improvement can have long-term negative impacts.  Take the \"turnpike\" example. A highway is widened to allow more traffic. More traffic capacity leads to greater development in the areas surrounding the improved traffic capacity. Over time, traffic thereby increases to fill available capacity. Turnpikes thereby need to be expanded in a seemingly endless cycles. There are many other engineering examples where expanded capacity (to do any function) is soon filled by increased demand. Since expansion comes at a cost, the resulting growth could become unsustainable without forecasting and management. The fundamental difficulty in risk assessment is determining the rate of occurrence since statistical information is not available on all kinds of past incidents and is particularly scanty in the case of catastrophic events, simply because of their infrequency. Furthermore, evaluating the severity of the consequences (impact) is often quite difficult for intangible assets. Asset valuation is another question that needs to be addressed. Thus, best educated opinions and available statistics are the primary sources of information. Nevertheless, risk assessment should produce such information for senior executives of the organization that the primary risks are easy to understand and that the risk management decisions may be prioritized within overall company goals. Thus, there have been several theories and attempts to quantify risks. Numerous different risk formulae exist, but perhaps the most widely accepted formula for risk quantification is: \"Rate (or probability) of occurrence multiplied by the impact of the event equals risk magnitude.\" Risk mitigation measures are usually formulated according to one or more of the following major risk options, which are: Later research has shown that the financial benefits of risk management are less dependent on the formula used but are more dependent on the frequency and how risk assessment is performed. In business it is imperative to be able to present the findings of risk assessments in financial, market, or schedule terms. Robert Courtney Jr. (IBM, 1970) proposed a formula for presenting risks in financial terms. The Courtney formula was accepted as the official risk analysis method for the US governmental agencies. The formula proposes calculation of ALE (annualized loss expectancy) and compares the expected loss value to the security control implementation costs (cost–benefit analysis). Planning for risk management uses four essential techniques. Under the acceptance technique, the business intentionally assumes risks without financial protections in the hopes that possible gains will exceed prospective losses. The transfer approach shields the business from losses by shifting risks to a third party, frequently in exchange for a fee, while the third-party benefits from the project. By choosing not to participate in high-risk ventures, the avoidance strategy avoids losses but also loses out on possibilities. Last but not least, the reduction approach lowers risks by implementing strategies like insurance, which provides protection for a variety of asset classes and guarantees reimbursement in the event of losses. Once risks have been identified and assessed, all techniques to manage the risk fall into one or more of these four major categories: Ideal use of theserisk control strategiesmay not be possible.  Some of them may involve trade-offs that are not acceptable to the organization or person making the risk management decisions. Another source, from the US Department of Defense (see link),Defense Acquisition University, calls these categories ACAT, for Avoid, Control, Accept, or Transfer.  This use of the ACAT acronym is reminiscent of another ACAT (for Acquisition Category) used in US Defense industry procurements, in which Risk Management figures prominently in decision making and planning. Similarly to risks, opportunities have specific mitigation strategies: exploit, share, enhance, ignore. This includes not performing an activity that could present risk. Refusing to purchase apropertyor business to avoidlegal liabilityis one such example. Avoidingairplaneflights for fear ofhijacking.  Avoidance may seem like the answer to all risks, but avoiding risks also means losing out on the potential gain that accepting (retaining) the risk may have allowed. Not entering a business to avoid the risk of loss also avoids the possibility of earning profits. Increasing risk regulation in hospitals has led to avoidance of treating higher risk conditions, in favor of patients presenting with lower risk. Risk reduction or \"optimization\" involves reducing the severity of the loss or the likelihood of the loss from occurring. For example,sprinklersare designed to put out afireto reduce the risk of loss by fire.  This method may cause a greater loss by water damage and therefore may not be suitable.Halonfire suppression systems may mitigate that risk, but the cost may be prohibitive as astrategy. Acknowledging that risks can be positive or negative, optimizing risks means finding a balance between negative risk and the benefit of the operation or activity; and between risk reduction and effort applied. By effectively applyingHealth, Safety and Environment(HSE) management standards, organizations can achieve tolerable levels ofresidual risk. Modern software development methodologies reduce risk by developing and delivering software incrementally. Early methodologies suffered from the fact that they only delivered software in the final phase of development; any problems encountered in earlier phases meant costly rework and often jeopardized the whole project. By developing in iterations, software projects can limit effort wasted to a single iteration. Outsourcingcould be an example of risk sharing strategy if the outsourcer can demonstrate higher capability at managing or reducing risks.For example, a company may outsource only its software development, the manufacturing of hard goods, or customer support needs to another company, while handling the business management itself. This way, the company can concentrate more on business development without having to worry as much about the manufacturing process, managing the development team, or finding a physical location for a center. Also, implanting controls can also be an option in reducing risk. Controls that either detect causes of unwanted events prior to the consequences occurring during use of the product, or detection of the root causes of unwanted failures that the team can then avoid. Controls may focus on management or decision-making processes. All these may help to make better decisions concerning risk. Briefly defined as \"sharing with another party the burden of loss or the benefit of gain, from a risk, and the measures to reduce a risk.\" The term 'risk transfer' is often used in place of risk-sharing in the mistaken belief that you can transfer a risk to a third party through insurance or outsourcing. In practice, if the insurance company or contractor go bankrupt or end up in court, the original risk is likely to still revert to the first party. As such, in the terminology of practitioners and scholars alike, the purchase of an insurance contract is often described as a \"transfer of risk.\" However, technically speaking, the buyer of the contract generally retains legal responsibility for the losses \"transferred\", meaning that insurance may be described more accurately as a post-event compensatory mechanism. For example, a personal injuries insurance policy does not transfer the risk of a car accident to the insurance company. The risk still lies with the policyholder namely the person who has been in the accident. The insurance policy simply provides that if an accident (the event) occurs involving the policyholder then some compensation may be payable to the policyholder that is commensurate with the suffering/damage. Methods of managing risk fall into multiple categories. Risk-retention pools are technically retaining the risk for the group, but spreading it over the whole group involves transfer among individual members of the group. This is different from traditional insurance, in that no premium is exchanged between members of the group upfront, but instead, losses are assessed to all members of the group. Risk retention involves accepting the loss, or benefit of gain, from a risk when the incident occurs.  Trueself-insurancefalls in this category. Risk retention is a viable strategy for small risks where the cost of insuring against the risk would be greater over time than the total losses sustained. All risks that are not avoided or transferred are retained by default. This includes risks that are so large or catastrophic that either they cannot be insured against or the premiums would be infeasible.Waris an example since most property and risks are not insured against war, so the loss attributed to war is retained by the insured. Also any amounts of potential loss (risk) over the amount insured is retained risk.  This may also be acceptable if the chance of a very large loss is small or if the cost to insure for greater coverage amounts is so great that it would hinder the goals of the organization too much. Select appropriate controls or countermeasures to mitigate each risk. Risk mitigation needs to be approved by the appropriate level of management. For instance, a risk concerning the image of the organization should have top management decision behind it whereas IT management would have the authority to decide on computer virus risks. The risk management plan should propose applicable and effective security controls for managing the risks. For example, an observed high risk of computer viruses could be mitigated by acquiring and implementing antivirus software. A good risk management plan should contain a schedule for control implementation and responsible persons for those actions. There are four basic steps of risk management plan, which are threat assessment, vulnerability assessment, impact assessment and risk mitigation strategy development. According toISO/IEC 27001, the stage immediately after completion of therisk assessmentphase consists of preparing a Risk Treatment Plan, which should document the decisions about how each of the identified risks should be handled. Mitigation of risks often means selection ofsecurity controls, which should be documented in a Statement of Applicability, which identifies which particular control objectives and controls from the \nstandard have been selected, and why. Implementation follows all of the planned methods for mitigating the effect of the risks. Purchase insurance policies for the risks that it has been decided to transferred to an insurer, avoid all risks that can be avoided without sacrificing the entity's goals, reduce others, and retain the rest. Initial risk management plans will never be perfect. Practice, experience, and actual loss results will necessitate changes in the plan and contribute information to allow possible different decisions to be made in dealing with the risks being faced. Risk analysisresults and management plans should be updated periodically. There are two primary reasons for this: Enterprise risk management (ERM) defines risk as those possible events or circumstances that can have negative influences on theenterprisein question,  \nwhere the impact can be on the very existence, the resources (human and capital), the products and services, or the customers of the enterprise, as well as external impacts on society, markets, or the environment. \nThere arevarious defined frameworkshere, where every probable risk can have a pre-formulated plan to deal with its possible consequences (to ensurecontingencyif the risk becomes aliability).\nManagers thus analyze and monitor both the internal and external environment facing the enterprise, addressingbusiness riskgenerally, and any impact on the enterprise achieving itsstrategic goals.\nERM thus overlaps various other disciplines -operational risk management,financial risk managementetc. - but is differentiated by its strategic and long-term focus.ERM systems usually focus on safeguarding reputation, acknowledging its significant role in comprehensive risk management strategies. As applied tofinance, risk management concerns the techniques and practices for measuring, monitoring and controlling themarket-andcredit risk(andoperational risk) on a firm'sbalance sheet, due to a bank's credit and trading exposure, or re afund manager's portfolio value; for an overview seeFinance § Risk management. The concept of \"contractual risk management\" emphasises the use of risk management techniques in contract deployment, i.e. managing the risks which are accepted through entry into a contract. Norwegian academic Petri Keskitalo defines \"contractual risk management\" as \"a practical, proactive and systematical contracting method that uses contract planning and governance to manage risks connected to business activities\".In an article by Samuel Greengard published in 2010, two US legal cases are mentioned which emphasise the importance of having a strategy for dealing with risk: Greengard recommends using industry-standard contract language as much as possible to reduce risk as much as possible and rely on clauses which have been in use and subject to established court interpretation over a number of years. Customs risk management is concerned with the risks which arise within the context ofinternational tradeand have a bearing on safety and security, including the risk thatillicit drugsandcounterfeit goodscan pass across borders and the risk that shipments and their contents are incorrectly declared.TheEuropean Unionhas adopted a Customs Risk Management Framework (CRMF) applicable across the union and throughout itsmember states, whose aims include establishing a common level of customs control protection and a balance between the objectives of safe customs control and the facilitation of legitimate trade.Two events which prompted theEuropean Commissionto review customs risk management policy in 2012-13 were theSeptember 11 attacksof 2001 and the2010 transatlantic aircraft bomb plotinvolving packages being sent fromYemento theUnited States, referred to by the Commission as \"the October 2010 (Yemen) incident\". ESRM is a security program management approach that links security activities to an enterprise's mission and business goals through risk management methods. The security leader's role in ESRM is to manage risks of harm to enterprise assets in partnership with the business leaders whose assets are exposed to those risks. ESRM involves educating business leaders on the realistic impacts of identified risks, presenting potential strategies to mitigate those impacts, then enacting the option chosen by the business in line with accepted levels of business risk tolerance Formedical devices, risk management is a process for identifying, evaluating and mitigating risks associated with harm to people and damage to property or the environment. Risk management is an integral part of medical device design and development, production processes and evaluation of field experience, and is applicable to all types of medical devices. The evidence of its application is required by most regulatory bodies such as theUS FDA. The management of risks for medical devices is described by the International Organization for Standardization (ISO) inISO 14971:2019, Medical Devices—The application of risk management to medical devices, a product safety standard. The standard provides a process framework and associated requirements for management responsibilities, risk analysis and evaluation, risk controls and lifecycle risk management. Guidance on the application of the standard is available via ISO/TR 24971:2020. The European version of the risk management standard was updated in 2009 and again in 2012 to refer to the Medical Devices Directive (MDD) and Active Implantable Medical Device Directive (AIMDD) revision in 2007, as well as the In Vitro Medical Device Directive (IVDD). The requirements of EN 14971:2012 are nearly identical to ISO 14971:2007. The differences include three \"(informative)\" Z Annexes that refer to the new MDD, AIMDD, and IVDD. These annexes indicate content deviations that include the requirement for risks to be reducedas far as possible, and the requirement that risks be mitigated by design and not by labeling on the medical device (i.e., labeling can no longer be used to mitigate risk). Typical risk analysis and evaluation techniques adopted by the medical device industry includehazard analysis,fault tree analysis(FTA),failure mode and effects analysis(FMEA), hazard and operability study (HAZOP), and risk traceability analysis for ensuring risk controls are implemented and effective (i.e. tracking risks identified to product requirements, design specifications, verification and validation results etc.). FTA analysis requires diagramming software. FMEA analysis can be done using aspreadsheetprogram. There are also integrated medical device risk management solutions. Through adraft guidance, the FDA has introduced another method named \"Safety Assurance Case\" for medical device safety assurance analysis. The safety assurance case is structured argument reasoning about systems appropriate for scientists and engineers, supported by a body of evidence, that provides a compelling, comprehensible and valid case that a system is safe for a given application in a given environment. With the guidance, a safety assurance case is expected for safety critical devices (e.g. infusion devices) as part of the pre-market clearance submission, e.g. 510(k). In 2013, the FDA introduced another draft guidance expecting medical device manufacturers to submit cybersecurity risk analysis information. Project risk management must be considered at the different phases of acquisition. At the beginning of a project, the advancement of technical developments, or threats presented by a competitor's projects, may cause a risk or threat assessment and subsequent evaluation of alternatives (seeAnalysis of Alternatives). Once a decision is made, and the project begun, more familiar project management applications can be used: Megaprojects(sometimes also called \"major programs\") are large-scale investment projects, typically costing more than $1 billion per project. Megaprojects include major bridges, tunnels, highways, railways, airports, seaports, power plants, dams, wastewater projects, coastal flood protection schemes, oil and natural gas extraction projects, public buildings, information technology systems, aerospace projects, and defense systems. Megaprojects have been shown to be particularly risky in terms of finance, safety, and social and environmental impacts. Risk management is therefore particularly pertinent for megaprojects and special methods and special education have been developed for such risk management. It is important to assess risk in regard to natural disasters likefloods,earthquakes, and so on. Outcomes of natural disaster risk assessment are valuable when considering future repair costs, business interruption losses and other downtime, effects on the environment, insurance costs, and the proposed costs of reducing the risk.TheSendai Framework for Disaster Risk Reductionis a 2015 international accord that has set goals and targets fordisaster risk reductionin response to natural disasters.There are regularInternational Disaster and Risk ConferencesinDavosto deal with integral risk management. Several tools can be used to assess risk and risk management of natural disasters and other climate events, including geospatial modeling, a key component ofland change science. This modeling requires an understanding of geographic distributions of people as well as an ability to calculate the likelihood of a natural disaster occurring. The management of risks to persons and property inwildernessand remote natural areas has developed with increases in outdoor recreation participation and decreased social tolerance for loss.  Organizations providing commercial wilderness experiences can now align with national and international consensus standards for training and equipment such asANSI/NASBLA 101-2017 (boating),UIAA152 (ice climbing tools),andEuropean Norm13089:2015 + A1:2015 (mountaineering equipment).TheAssociation for Experiential Educationoffers accreditation for wilderness adventure programs.TheWilderness Risk Management Conferenceprovides access to best practices, and specialist organizations provide wilderness risk management consulting and training. The text Outdoor Safety – Risk Management for Outdoor Leaders,published by the New Zealand Mountain Safety Council, provides a view of wilderness risk management from the New Zealand perspective, recognizing the value of national outdoor safety legislation and devoting considerable attention to the roles of judgment and decision-making processes in wilderness risk management. One popular models for risk assessment is the Risk Assessment and Safety Management (RASM) Model developed by Rick Curtis, author of The Backpacker's Field Manual.The formula for the RASM Model is: Risk = Probability of Accident × Severity of Consequences. The RASM Model weighs negative risk—the potential for loss, against positive risk—the potential for growth. IT riskis a risk related to information technology. This is a relatively new term due to an increasing awareness thatinformation securityis simply one facet of a multitude of risks that are relevant to IT and the real world processes it supports. \"Cybersecurity is tied closely to the advancement of technology. It lags only long enough for incentives like black markets to evolve and new exploits to be discovered. There is no end in sight for the advancement of technology, so we can expect the same from cybersecurity.\" ISACA'sRisk ITframework ties IT risk to enterprise risk management. Duty of Care Risk Analysis (DoCRA) evaluates risks and their safeguards and considers the interests of all parties potentially affected by those risks.TheVerizon Data Breach Investigations Report (DBIR)features how organizations can leverage the Veris Community Database (VCDB) to estimate risk. Using HALOCKmethodologywithin CIS RAM and data from VCDB, professionals can determine threat likelihood for their industries. IT risk management includes \"incident handling\", an action plan for dealing with intrusions, cyber-theft, denial of service, fire, floods, and other security-related events. According to theSANS Institute, it is a six step process: Preparation, Identification, Containment, Eradication, Recovery, and Lessons Learned. Operational risk management (ORM) is the oversight ofoperational risk, including the risk of loss resulting from: inadequate or failed internal processes and systems; human factors; or external events. Given thenature of operations, ORM is typically a \"continual\" process, and will include ongoing risk assessment, risk decision making, and the implementation of risk controls. For the offshore oil and gas industry, operational risk management is regulated by thesafety caseregime in many countries. Hazard identification and risk assessment tools and techniques are described in the international standard ISO 17776:2000, and organisations such as the IADC (International Association of Drilling Contractors) publish guidelines forHealth, Safety and Environment(HSE) Case development which are based on the ISO standard. Further, diagrammatic representations of hazardous events are often expected by governmental regulators as part of risk management in safety case submissions; these are known asbow-tie diagrams(seeNetwork theory in risk assessment). The technique is also used by organisations and regulators in mining, aviation, health, defence, industrial and finance. The principles and tools for quality risk management are increasingly being applied to different aspects of pharmaceutical quality systems. These aspects include development, manufacturing, distribution, inspection, and submission/review processes throughout the lifecycle of drug substances, drug products, biological and biotechnological products (including the use of raw materials, solvents, excipients, packaging and labeling materials in drug products, biological and biotechnological products). Risk management is also applied to the assessment of microbiological contamination in relation to pharmaceutical products and cleanroom manufacturing environments. Supply chain risk management (SCRM) aims at maintainingsupply chaincontinuity in the event of scenarios or incidents which could interrupt normal business and hence profitability. Risks to the supply chain range from everyday to exceptional, including unpredictable natural events (such astsunamisandpandemics) to counterfeit products, and reach across quality, security, to resiliency and product integrity. Mitigation of these risks can involve various elements of the business includinglogisticsand cybersecurity, as well as the areas of finance and operations. Travel risk management is concerned with how organisations assess the risks to theirstaff when travelling, especially when travelling overseas. In the field ofinternational standards, ISO 31030:2021 addresses good practice in travel risk management. The Global Business Travel Association's education and research arm, the GBTA Foundation. found in 2015 that most businesses covered by their research employed travel risk management protocols aimed at ensuring the safety and well-being of their business travelers.Six key principles of travel risk awareness put forward by the association are preparation, awareness of surroundings and people, keeping a low profile, adopting an unpredictable routine, communications and layers of protection.Traveler tracking using mobile tracking and messaging technologies had by 2015 become a widely used aspect of travel risk management. Risk communicationis a complex cross-disciplinary academic field that is part of risk management and related to fields likecrisis communication. The goal is to make sure that targeted audiences understand how risks affect them or their communities by appealing to their values. Risk communication is particularly important indisaster preparedness,public health,and preparation for majorglobal catastrophic risk.For example, theimpacts of climate changeandclimate riskeffect every part of society, so communicating that risk is an importantclimate communicationpractice, in order for societies to plan forclimate adaptation.Similarly, inpandemic prevention,understanding of riskhelps communities stop the spread of disease and improve responses. Risk communication deals with possible risks and aims to raise awareness of those risks to encourage or persuade changes in behavior to relieve threats in the long term. On the other hand, crisis communication is aimed at raising awareness of a specific type of threat, the magnitude, outcomes, and specific behaviors to adopt to reduce the threat. Risk communication infood safetyis part of therisk analysis framework. Together with risk assessment and risk management, risk communication aims to reducefoodborne illnesses. Food safety risk communication is an obligatory activity for food safety authoritiesin countries, which adopted theAgreement on the Application of Sanitary and Phytosanitary Measures.", "metadata": {"url": "https://en.wikipedia.org/wiki/Risk_management", "title": "Risk management", "headings": ["Contents", "Introduction", "Risks vs. opportunities", "Method", "Principles", "Mild versus wild risk", "Process", "Establishing the context", "Identification", "Assessment", "Risk options", "Potential risk treatments", "Risk management plan", "Implementation", "Review and evaluation of the plan", "Areas", "Enterprise", "Finance", "Contractual risk management", "Customs", "Memory institutions(museums, libraries and archives)", "Enterprise security", "Medical devices", "Project management", "Megaprojects (infrastructure)", "Natural disasters", "Wilderness", "Information technology", "Operations", "Petroleum and natural gas", "Pharmaceutical sector", "Supply chain", "Travel", "Risk communication", "See also", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Risk_management", "https://en.wikipedia.org/wiki/Risk_management", "https://en.wikipedia.org/wiki/Risk_management", "https://en.wikipedia.org/wiki/Risk_(disambiguation)", "https://en.wikipedia.org/wiki/Risk_analysis_(business)", "https://en.wikipedia.org/wiki/Risk_Management_(magazine)", "https://en.wikipedia.org/wiki/Risk_Analysis_(journal)", "https://en.wikipedia.org/wiki/NASA"]}},
{"id": "f6eafec51967", "content": " Project managementis the process of supervising the work of ateamto achieve all project goals within the given constraints.This information is usually described inproject documentation, created at the beginning of the development process. The primary constraints arescope, time andbudget.The secondary challenge is tooptimizetheallocationof necessary inputs and apply them to meet predefined objectives. The objective of project management is to produce a complete project which complies with the client's objectives. In many cases, the objective of project management is also to shape or reform the client's brief to feasibly address the client's objectives. Once the client's objectives are established, they should influence all decisions made by other people involved in the project– for example, project managers, designers, contractors and subcontractors. Ill-defined or too tightly prescribed project management objectives are detrimental to the decisionmaking process. Aprojectis a temporary and unique endeavor designed to produce a product, service or result with a defined beginning and end (usually time-constrained, often constrained by funding or staffing) undertaken to meet unique goals and objectives, typically to bring about beneficial change or added value.The temporary nature of projects stands in contrast with business as usual (or operations),which are repetitive, permanent or semi-permanent functional activities to produce products or services. In practice, themanagementof such distinct production approaches requires the development of distinct technical skills and management strategies. Prior to the year 1900,civil engineeringprojects were generally managed by creative architects, engineers, andmaster buildersthemselves, for example,Vitruvius(first century BC),Christopher Wren(1632–1723),Thomas Telford(1757–1834), andIsambard Kingdom Brunel(1806–1859).In the 1950s, organizations started to apply project-management tools and techniques more systematically to complex engineering projects. As a discipline, project management developed from several fields of application including civil construction, engineering, and heavydefenseactivity.Two forefathers of project management areHenry Gantt, called the father of planning and control techniques,who is famous for his use of theGantt chartas a project management tool (alternativelyHarmonogramfirst proposed byKarol Adamiecki);andHenri Fayolfor his creation of the five management functions that form the foundation of the body of knowledge associated with project and program management.Both Gantt and Fayol were students ofFrederick Winslow Taylor's theories ofscientific management. His work is the forerunner to modern project management tools includingwork breakdown structure(WBS) andresource allocation. The 1950s marked the beginning of the modern project management era, where coreengineeringfields came together to work as one. Project management became recognized as a distinct discipline arising from the management discipline with the engineering model.In the United States, prior to the 1950s, projects were managed on an ad-hoc basis, using mostlyGantt chartsand informal techniques and tools. At that time, two mathematicalproject-schedulingmodels were developed. Thecritical path method(CPM) was developed as a joint venture betweenDuPont CorporationandRemington Rand Corporationfor managing plant maintenance projects. Theprogram evaluation and review technique(PERT), was developed by theU.S. Navy Special Projects Officein conjunction with theLockheed CorporationandBooz Allen Hamiltonas part of thePolaris missilesubmarine program. PERTand CPM are very similar in their approach but still present some differences. CPM is used for projects that assume deterministic activity times; the times at which each activity will be carried out are known. PERT, on the other hand, allows for stochastic activity times; the times at which each activity will be carried out are uncertain or varied. Because of this core difference, CPM andPERTare used in different contexts. These mathematical techniques quickly spread into many private enterprises. At the same time, as project-scheduling models were being developed, technology for project costestimating, cost management and engineering economics was evolving, with pioneering work by Hans Lang and others. In 1956, the American Association of Cost Engineers (nowAACE International; the Association for the Advancement ofCost Engineering) was formed by early practitioners of project management and the associated specialties of planning andscheduling, cost estimating, and project control. AACE continued its pioneering work and in 2006, released the first integrated process for portfolio, program, and project management (total cost managementframework). In 1969, theProject Management Institute(PMI) was formed in the USA.PMI publishes the original version ofA Guide to the Project Management Body of Knowledge(PMBOK Guide) in 1996 with William Duncan as its primary author, which describes project management practices that are common to \"most projects, most of the time.\" In August 2021,theProject Management Institute(PMI) released the seventh edition ofA Guide to the Project Management Body of Knowledge (PMBOK® Guide), marking a significant evolution in project management standards. Unlike previous editions, which emphasized a process-based framework, the seventh edition adopts a holistic, principle-based approach, aligning with the dynamic needs of modern project management. This shift integrates agile, hybrid, and predictive methodologies, reflecting the growing diversity of project delivery methods across industries. A key feature of the seventh edition is the introduction of eight performance domains: Stakeholder, Team, Development Approach and Life Cycle, Planning, Project Work, Delivery, Measurement, and Uncertainty. These domains provide a comprehensive framework for effective project management, focusing on outcomes and adaptability rather than rigid processes. By emphasizing principles over prescriptive steps, the guide encourages practitioners to tailor practices to specific project contexts, enhancing flexibility and innovation. This transformative update, accompanied byThe Standard for Project Management, underscores PMI’s commitment to addressing contemporary challenges and fostering value-driven project outcomes. This shift in focus brings project management practitioners into the 21st century, opening up the door to a more holistic and people-centric approach. Project management methods can be applied to any project. It is often tailored to a specific type of project based on project size, nature, industry or sector. For example, the construction industry, which focuses on the delivery of things like buildings, roads, and bridges, has developed its own specialized form of project management that it refers to asconstruction project managementand in which project managers can become trained and certified.Theinformation technologyindustry has also evolved to develop its own form of project management that is referred to asIT project managementand which specializes in the delivery of technical assets and services that are required to pass through various lifecycle phases such as planning, design, development, testing, and deployment.Biotechnologyproject managementfocuses on the intricacies of biotechnology research and development.Localization project managementincludes application of many standard project management practices to translation works even though many consider this type of management to be a very different discipline. For example, project managers have a key role in improving the translation even when they do not speak the language of the translation, because they know the study objectives well to make informed decisions.Similarly,research study managementcan also apply a project manage approach.There is public project management that covers all public works by the government, which can be carried out by the government agencies or contracted out to contractors. Another classification of project management is based on the hard (physical) or soft (non-physical) type. Common among all the project management types is that they focus on three important goals: time, quality, and cost. Successful projects are completed on schedule, within budget, and according to previously agreed quality standards i.e. meeting the Iron Triangle or Triple Constraint in order for projects to be considered a success or failure. For each type of project management, project managers develop and utilize repeatable templates that are specific to the industry they're dealing with.  This allows project plans to become very thorough and highly repeatable, with the specific intent to increase quality, lower delivery costs, and lower time to deliver project results. A 2017 study suggested that the success of any project depends on how well four key aspects are aligned with the contextual dynamics affecting the project, these are referred to as thefour P's: There are a number of approaches to organizing and completing project activities, including phased, lean, iterative, and incremental. There are also several extensions to project planning, for example, based on outcomes (product-based) or activities (process-based). Regardless of themethodologyemployed, careful consideration must be given to the overall project objectives, timeline, and cost, as well as the roles and responsibilities of all participants andstakeholders. Benefits realization management (BRM) enhances normal project management techniques through a focus on outcomes (benefits) of a project rather than products or outputs and then measuring the degree to which that is happening to keep a project on track. This can help to reduce the risk of a completed project being a failure by delivering agreed upon requirements (outputs) i.e. project success but failing to deliver the benefits (outcomes) of those requirements i.e. product success. Note that good requirements management will ensure these benefits are captured as requirements of the project and their achievement monitored throughout the project. In addition, BRM practices aim to ensure the strategic alignment between project outcomes and business strategies. The effectiveness of these practices is supported by recent research evidencing BRM practices influencing project success from a strategic perspective across different countries and industries. These wider effects are called the strategic impact. An example of delivering a project to requirements might be agreeing to deliver a computer system that will process staff data and manage payroll, holiday, and staff personnel records in shorter times with reduced errors. Under BRM, the agreement might be to achieve a specified reduction in staff hours and errors required to process and maintain staff data after the system installation when compared without the system. Critical path method (CPM) is an algorithm for determining the schedule for project activities. It is the traditional process used for predictive-based project planning. The CPM method evaluates the sequence of activities, the work effort required, the inter-dependencies, and the resulting float time per line sequence to determine the required project duration. Thus, by definition, the critical path is the pathway of tasks on the network diagram that has no extra time available (or very little extra time).\" Critical chain project management (CCPM) is an application of thetheory of constraints(TOC) to planning and managing projects and is designed to deal with the uncertainties inherent in managing projects, while taking into consideration the limited availability ofresources(physical, human skills, as well as management & support capacity) needed to execute projects. The goal is to increase the flow of projects in an organization (throughput). Applying the first three of thefive focusing stepsof TOC, the system constraint for all projects, as well as the resources, are identified. To exploit the constraint, tasks on the critical chain are given priority over all other activities. Earned value management (EVM) extends project management with techniques to improve project monitoring.It illustrates project progress towards completion in terms of work and value (cost).Earned Scheduleis an extension to the theory and practice of EVM. In critical studies of project management, it has been noted that phased approaches are not well suited for projects which are large-scale and multi-company,with undefined, ambiguous, or fast-changing requirements,or those with high degrees of risk, dependency, and fast-changing technologies. Thecone of uncertaintyexplains some of this as the planning made on the initial phase of the project suffers from a high degree of uncertainty. This becomes especially true as software development is often the realization of a new or novel product. These complexities are better handled with a more exploratory or iterative and incremental approach.Several models of iterative and incremental project management have evolved, includingagile project management,dynamic systems development method, andextreme project management. Lean project management uses the principles fromlean manufacturingto focus on delivering value with less waste and reduced time. There are five phases to a project lifecycle; known as process groups.  Each process group represents a series of inter-related processes to manage the work through a series of distinct steps to be completed. This type of project approach is often referred to as \"traditional\"or \"waterfall\".The five process groups are: Some industries may use variations of these project stages and rename them to better suit the organization. For example, when working on abrick-and-mortardesign and construction, projects will typically progress through stages like pre-planning, conceptual design, schematic design, design development, construction drawings (or contract documents), and construction administration. While the phased approach works well for small, well-defined projects, it often results in challenge or failure on larger projects, or those that are more complex or have more ambiguities, issues, and risks- see the parodying 'six phases of a big project'. The incorporation of process-based management has been driven by the use of maturity models such as theOPM3and theCMMI(capability maturity model integration; seeImage:Capability Maturity Model.jpg Project production management is the application of operations management to the delivery of capital projects. The Project production management framework is based on a project as a production system view, in which a project transforms inputs (raw materials, information, labor, plant & machinery) into outputs (goods and services). Product-based planning is a structured approach to project management, based on identifying all of the products (projectdeliverables) that contribute to achieving the project objectives. As such, it defines a successful project as output-oriented rather than activity- or task-oriented.The most common implementation of this approach isPRINCE2. Traditionally (depending on what project management methodology is being used), project management includes a number of elements: four to five project management process groups, and a control system. Regardless of the methodology or terminology used, the same basic project management processes or stages of development will be used. Major process groups generally include: In project environments with a significant exploratory element (e.g.,research and development), these stages may be supplemented with decision points (go/no go decisions) at which the project's continuation is debated and decided. An example is thePhase–gate model. Project management relies on a wide variety of meetings to coordinate actions. For instance, there is the kick-off meeting, which broadly involves stakeholders at the project's initiation. Project meetings or project committees enable the project team to define and monitor action plans. Steering committees are used to transition between phases and resolve issues. Project portfolio and program reviews are conducted in organizations running parallel projects. Lessons learned meetings are held to consolidate learnings. All these meetings employ techniques found inmeeting science, particularly to define the objective, participant list, and facilitation methods. The initiating processes determine the nature and scope of the project.If this stage is not performed well, it is unlikely that the project will be successful in meeting the business' needs. The key project controls needed here are an understanding of the business environment and making sure that all necessary controls are incorporated into the project. Any deficiencies should be reported and a recommendation should be made to fix them. The initiating stage should include a plan that encompasses the following areas. These areas can be recorded in a series of documents called Project Initiation documents.\nProject Initiation documents are a series of planned documents used to create an order for the duration of the project. \nThese tend to include: After the initiation stage, the project is planned to an appropriate level of detail (see anexample of a flowchart).The main purpose is to plan time, cost, and resources adequately to estimate the work needed and to effectively manage risk during project execution. As with the Initiation process group, a failure to adequately plan greatly reduces the project's chances of successfully accomplishing its goals. Project planninggenerally consists of Additional processes, such as planning for communications and for scope management, identifying roles and responsibilities, determining what to purchase for the project, and holding a kick-off meeting are also generally advisable. Fornew product developmentprojects, conceptual design of the operation of the final product may be performed concurrent with the project planning activities and may help to inform the planning team when identifying deliverables and planning activities. While executing we must know what are the planned terms that need to be executed.\nThe execution/implementation phase ensures that the project management plan's deliverables are executed accordingly. This phase involves proper allocation, coordination, and management of human resources and any other resources such as materials and budgets. The output of this phase is the project deliverables. Documenting everything within a project is key to being successful. To maintain budget, scope, effectiveness and pace a project must have physical documents pertaining to each specific task. With correct documentation, it is easy to see whether or not a project's requirement has been met. To go along with that, documentation provides information regarding what has already been completed for that project. Documentation throughout a project provides a paper trail for anyone who needs to go back and reference the work in the past. \nIn most cases, documentation is the most successful way to monitor and control the specific phases of a project.  With the correct documentation, a project's success can be tracked and observed as the project goes on. If performed correctly, documentation can be the backbone of a project's success Monitoring and controlling consist of those processes performed to observe project execution so that potential problems can be identified in a timely manner and corrective action can be taken, when necessary, to control the execution of the project. The key benefit is that project performance is observed and measured regularly to identify variances from the project management plan. Monitoring and controlling include: Two main mechanisms support monitoring and controlling in projects. On the one hand,contractsoffer a set of rules and incentives often supported by potential penalties and sanctions.On the other hand, scholars in business and management have paid attention to the role of integrators (also called project barons) to achieve a project's objectives.In turn, recent research in project management has questioned the type of interplay between contracts and integrators. Some have argued that these two monitoring mechanisms operate as substitutesas one type of organization would decrease the advantages of using the other one. In multi-phase projects, the monitoring and control process also provides feedback between project phases, to implement corrective or preventive actions to bring the project into compliance with the project management plan. Project maintenance is an ongoing process, and it includes: In this stage,auditorsshould pay attention to how effectively and quickly user problems are resolved. Over the course of any construction project, the work scope may change. Change is a normal and expected part of the construction process. Changes can be the result of necessary design modifications, differing site conditions, material availability, contractor-requested changes, value engineering, and impacts from third parties, to name a few. Beyond executing the change in the field, the change normally needs to be documented to show what was actually constructed. This is referred to as change management. Hence, the owner usually requires a final record to show all changes or, more specifically, any change that modifies the tangible portions of the finished work. The record is made on the contract documents – usually, but not necessarily limited to, the design drawings. The end product of this effort is what the industry terms as-built drawings, or more simply, \"as built.\" The requirement for providing them is a norm in construction contracts. Construction document management is a highly important task undertaken with the aid of an online or desktop software system or maintained through physical documentation. The increasing legality pertaining to the construction industry's maintenance of correct documentation has caused an increase in the need for document management systems. When changes are introduced to the project, the viability of the project has to be re-assessed. It is important not to lose sight of the initial goals and targets of the projects. When the changes accumulate, the forecasted result may not justify the original proposed investment in the project. Successful project management identifies these components, and tracks and monitors progress, so as to stay within time and budget frames already outlined at the commencement of the project. Exact methods were suggested to identify the most informative monitoring points along the project life-cycle regarding its progress and expected duration. Closing includes the formal acceptance of the project and the ending thereof. Administrative activities include the archiving of the files and documenting lessons learned. This phase consists of: Also included in this phase is the post implementation review. This is a vital phase of the project for the project team to learn from experiences and apply to future projects. Normally a post implementation review consists of looking at things that went well and analyzing things that went badly on the project to come up with lessons learned. Project control (also known asCost Engineering)\nshould be established as an independent function in project management. It implements verification and controlling functions during the processing of a project to reinforce the defined performance and formal goals.The tasks of project control are also: Fulfillment and implementation of these tasks can be achieved by applying specific methods and instruments of project control. The following methods of project control can be applied: Project control is that element of a project that keeps it on track, on time, and within budget.Project control begins early in the project with planning and ends late in the project with post-implementation review, having a thorough involvement of each step in the process. Projects may be audited or reviewed while the project is in progress. Formal audits are generally risk or compliance-based and management will direct the objectives of the audit. An examination may include a comparison of approved project management processes with how the project is actually being managed.Each project should be assessed for the appropriate level of control needed: too much control is too time-consuming, too little control is very risky. If project control is not implemented correctly, the cost to the business should be clarified in terms of errors and fixes. Control systems are needed for cost,risk, quality, communication, time, change, procurement, and human resources. In addition, auditors should consider how important the projects are to thefinancial statements, how reliant the stakeholders are on controls, and how many controls exist.  Auditors should review the development process and procedures for how they are implemented. The process of development and the quality of the final product may also be assessed if needed or requested. A business may want the auditing firm to be involved throughout the process to catch problems earlier on so that they can be fixed more easily. An auditor can serve as a controls consultant as part of the development team or as an independent auditor as part of an audit. Businesses sometimes use formal systems development processes. This help assure systems are developed successfully. A formal process is more effective in creating strong controls, and auditors should review this process to confirm that it is well designed and is followed in practice. A good formal systems development plan outlines: There are five important characteristics of a project: (i) It should always have specific start and end dates. (ii) They are performed and completed by a group of people. (iii) The output is the delivery of a unique product or service. (iv) They are temporary in nature. (v) It is progressively elaborated. Examples are: designing a new car or writing a book. Complexity and its nature play an important role in the area of project management. Despite having a number of debates on this subject matter, studies suggest a lack of definition and reasonable understanding of complexity in relation to the management of complex projects. Project complexity is the property of a project which makes it difficult to understand, foresee, and keep under control its overall behavior, even when given reasonably complete information about the project system. The identification of complex projects is specifically important to multi-project engineering environments. As it is considered that project complexity and project performance are closely related, it is important to define and measure the complexity of the project for project management to be effective. Complexity can be: Based on theCynefin framework,complex projects can be classified as: By applying the discovery in measuring work complexity described inRequisite Organizationand Stratified Systems Theory,Elliott Jaquesclassifies projects and project work (stages, tasks) into seven basic levels of project complexity based on such criteria as time-span of discretion and complexity of a project's output: Benefits from measuring Project Complexity are to improve project people feasibility by matching the level of a project's complexity with an effective targeted completion time, with the respective capability level of the project manager and of the project members. Similarly with theLaw of requisite varietyandThe law of requisite complexity, project complexity is sometimes required in order for the project to reach its objectives, and sometimes it has beneficial outcomes. Based on the effects of complexity, Stefan Morcov proposed its classification as Positive, Appropriate, or Negative. Aproject manageris a professional in the field of project management. Project managers are in charge of the people in a project. People are the key to any successful project. Without the correct people in the right place and at the right time a project cannot be successful. Project managers can have the responsibility of the planning, execution, controlling, and closing of any project typically relating to theconstruction industry, engineering, architecture,computing, and telecommunications. Many other fields of production engineering, design engineering, and heavy industrial have project managers. A project manager needs to understand the order of execution of a project to schedule the project correctly as well as the time necessary to accomplish each individual task within the project. A project manager is the person accountable for accomplishing the stated project objectives on behalf of the client. Project Managers tend to have multiple years' experience in their field. A project manager is required to know the project in and out while supervising the workers along with the project. Typically in most construction, engineering, architecture, and industrial projects, a project manager has another manager working alongside of them who is typically responsible for the execution of task on a daily basis. This position in some cases is known as a superintendent. A superintendent and project manager work hand in hand in completing daily project tasks. Key project management responsibilities include creating clear and attainable project objectives, building the project requirements, and managing thetriple constraint(now including more constraints and calling it competing constraints) for projects, which is cost, time, quality and scope for the first three but about three additional ones in current project management. A typical project is composed of a team of workers who work under the project manager to complete the assignment within the time and budget targets. A project manager normally reports directly to someone of higher stature on the completion and success of the project. A project manager is often a client representative and has to determine and implement the exact needs of the client, based on knowledge of the firm they are representing. The ability to adapt to the various internal procedures of the contracting party, and to form close links with the nominated representatives, is essential in ensuring that the key issues of cost, time, quality and above all, client satisfaction, can be realized. A complete project manager, a term first coined by Robert J. Graham in his simulation, has been expanded upon by Randall L. Englund and Alfonso Bucero. They describe a complete project manager as a person who embraces multiple disciplines, such asleadership, influence, negotiations, politics, change and conflict management, and humor. These are all \"soft\" people skills that enableproject leadersto be more effective and achieve optimized, consistent results. There is a tendency to confuse the project success with project management success. They are two different things. \"Project success\" has 2 perspectives: Project management success criteria are different from project success criteria. The project management is said to be successful if the given project is completed within the agreed upon time, met the agreed upon scope and within the agreed upon budget. Subsequent to the triple constraints, multiple constraints have been considered to ensure project success. However, the triple or multiple constraints indicate only the efficiency measures of the project, which are indeed the project management success criteria during the project lifecycle. The priori criteria leave out the more important after-completion results of the project which comprise four levels i.e. the output (product) success, outcome (benefits) success and impact (strategic) success during the product lifecycle. These posterior success criteria indicate the effectiveness measures of the project product, service or result, after the project completion and handover. This overarching multilevel success framework of projects, programs and portfolios has been developed by Paul Bannerman in 2008.In other words, a project is said to be successful, when it succeeds in achieving the expected business case which needs to be clearly identified and defined during the project inception and selection before starting the development phase. This multilevel success framework conforms to the theory of project as a transformation depicted as the input-process / activity-output-outcome-impact in order to generate whatever value intended. Emanuel Camilleri in 2011 classifies all the critical success and failure factors into groups and matches each of them with the multilevel success criteria in order to deliver business value. An example of a performance indicator used in relation to project management is the \"backlog of commissioned projects\" or \"project backlog\". The United StatesDepartment of Defensestates that \"Cost, Schedule, Performance, and Risk\" are the four elements through which Department of Defenseacquisitionprofessionals make trade-offs and track program status.There are alsointernational standards. Risk management applies proactive identification (seetools) of future problems and understanding of their consequences allowingpredictivedecisions about projects. ERM system plays a role in overall risk management. Thework breakdown structure(WBS) is atree structurethat shows a subdivision of the activities required to achieve an objective – for example a portfolio, program, project, and contract. The WBS may be hardware-, product-, service-, orprocess-oriented (see an example in aNASA reporting structure (2001)).Beside WBS for project scope management, there areorganizational breakdown structure (chart), cost breakdown structure andrisk breakdown structure. A WBS can be developed by starting with the end objective and successively subdividing it into manageable components in terms of size, duration, and responsibility (e.g., systems, subsystems, components, tasks, sub-tasks, and work packages), which include all steps necessary to achieve the objective. The work breakdown structure provides a common framework for the natural development of the overall planning and control of a contract and is the basis for dividing work into definable increments from which the statement of work can be developed and technical, schedule, cost, and labor hour reporting can be established.The work breakdown structure can be displayed in two forms, as a table with subdivision of tasks or as an organizational chart whose lowest nodes are referred to as \"work packages\". It is an essential element in assessing the quality of a plan, and an initial element used during the planning of the project. For example, a WBS is used when the project is scheduled, so that the use of work packages can be recorded and tracked. Similarly to work breakdown structure (WBS), other decomposition techniques and tools are: organization breakdown structure (OBS), product breakdown structure (PBS), cost breakdown structure (CBS), risk breakdown structure (RBS), and resource breakdown structure (ResBS). There are several project management standards, including: Some projects, either identical or different, can be managed as program management.  \nPrograms are collections of projects that support a common objective and set of goals. While individual projects have clearly defined and specific scope and timeline, a program's objectives and duration are defined with a lower level of granularity. Besides programs and portfolios, additional structures that combine their different characteristics are: project networks, mega-projects, or mega-programs. A project network is a temporary project formed of several different distinct evolving phases, crossing organizational lines. \nMega-projects and mega-programs are defined as exceptional in terms of size, cost, public and political attention, and competencies required. An increasing number of organizations are using what is referred to asproject portfolio management(PPM) as a means of selecting the right projects and then using project management techniquesas the means for delivering the outcomes in the form of benefits to the performing public, private or not-for-profit organization. Portfolios are collections of similar projects. Portfolio management supports efficiencies of scale, increasing success rates, and reducing project risks, by applying similar standardized techniques to all projects in the portfolio, by a group of project management professionals sharing common tools and knowledge. \nOrganizations often create project management offices as an organizational structure to support project portfolio management in a structured way.Thus, PPM is usually performed by a dedicated team of managers organized within an enterprise project management office (PMO), usually based within the organization, and headed by a PMO director or chief project officer. In cases where strategic initiatives of an organization form the bulk of the PPM, the head of the PPM is sometimes titled as the chief initiative officer. Project management softwareis software used to help plan, organize, and manage resource pools, develop resource estimates and implement plans. Depending on the sophistication of the software, functionality may includeestimationand planning,scheduling,cost controlandbudget management,resource allocation,collaboration software,communication,decision-making,workflow,risk, quality,documentation, and/or administration systems.. Acomparison of project management softwareshows different features included in different software. Virtual program management (VPM) is management of a project done by avirtual team, though it rarely may refer to a project implementing a virtual environmentIt is noted that managing a virtual project is fundamentally different from managing traditional projects,combining concerns ofremote workand global collaboration (culture, time zones, language).", "metadata": {"url": "https://en.wikipedia.org/wiki/Project_management", "title": "Project management", "headings": ["Contents", "History", "Project management types", "Approaches of project management", "Benefits realization management", "Critical path method", "Critical chain project management", "Earned value management", "Iterative and incremental project management", "Lean project management", "Project lifecycle", "Process-based management", "Project production management", "Product-based planning", "Process groups", "Initiating", "Planning", "Executing", "Project documentation", "Monitoring and controlling", "Closing", "Project control and project control systems", "Characteristics of projects", "Project complexity", "Positive, appropriate (requisite), and negative complexity", "Project managers", "Multilevel success framework and criteria - project success vs. project performance", "Risk management", "Work breakdown structure and other breakdown structures", "International standards", "Program management and project networks", "Project portfolio management", "Project management software", "Virtual project management", "See also", "Related fields", "Related subjects", "Lists", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Project_management", "https://en.wikipedia.org/wiki/Project_management", "https://en.wikipedia.org/wiki/Project_management", "https://en.wikipedia.org/wiki/Product_management", "https://en.wikipedia.org/wiki/Business_administration", "https://en.wikipedia.org/wiki/Accounting", "https://en.wikipedia.org/wiki/Management_accounting", "https://en.wikipedia.org/wiki/Financial_accounting"]}},
{"id": "5d15a267abf1", "content": "Office managementis a profession involving the design, implementation, evaluation, and maintenance of the process ofworkwithin anofficeor other organization, in order to sustain and improveefficiencyandproductivity. Office management is thus a part of the overall administration of business and since the elements of management are forecasting and planning, organizing, command, control and coordination, the office is a part of the total management function. Office management can be defined as “a distinct process of planning, organizing, staffing, directing, coordinating and controlling office in order to facilitate achievement of objectives of any business enterprise’ the definition shows managerial functions of an administrative manager. Following diagram indicates various elements or functions in the process of office management. The following point enlightens the importance of office management: Targets or goals are results in quantitative terms which are to be achieved in a given time. Management makes people realize the goals and directs their efforts towards the achievement of these goals. Management helps in utilization of resources effectively. Scarce resources are put to use optimistically by managers. Managers bring about coordination and integration of various resources. It is management which guides the personnel in office in the use of resources. Office costs can be reduced under the guidance and control of efficient management. Office Management is concerned with doing the office activities in a best and cheapest way. Cost reduction is one of the object of management which can be achieved through work simplification and mechanization. Through better planning, sound organization and effective control, management enables a concern to reduce costs and prepare an enterprise to face cut throat competition. Uninterrupted flow of work is only possible if there is proper planning and control. Management ensures efficient and smooth flow of work. Management helps in maintaining efficiency in an office. A manager not only performs and produces results, but may do it in the most efficient manner so as to contribute towards profit generation. Management has to play an important role in keeping the organization alive. Change in technology and methods must be anticipated and adapted for survival and growth. It is only management which can do so and molds the enterprise in such a changing environment. Innovation is finding new, different and better method of doing existing work. To plan and manage innovation, management has to play an important role. Suggestions from customers, information from salesmen, close watch on competitor's activities provide source of innovation. Efficient management helps in retaining talented and hard working employees by providing them comfortable work environment. Manager must motivate his employees by recognizing and appreciating their talents. Management provides leadership by influencing and guiding office personnel. Managers influence his subordinates to work willingly for achieving organizational goals. Importance of office management is that it helps in planning the change and introducing it at the right time and in the right manner. Due to change in technology methods, work procedures etc. have to be changed for efficiency and economy. People resist change due to lack of understanding the reasons for change and lack of training in new methods. Management helps in minimizing resistance of people and acts as a change-agent. Office management helps in improving public relations and increasing goodwill of an enterprise by dealing with grievances of consumers and general public. Management is beneficial not only to the business enterprises but to the various segments of society also. It provides and maintains link with various types of suppliers, banks, insurance companies, government departments, and general public. It benefits society as a whole by providing its services. An office manager is responsible for monitoring and reviewing systems, usually focusing on specific outcomes such as improved timescales, turnover, output, sales, etc. They may supervise or manage a team of administrators, allocating roles, recruiting and training, and issuing assignments and projects. As such the role is varied, often including responsibilities across a diverse range of functions such as: Personal competencies useful in the role are: problem solving skills, good decision-making abilities, integrity, resourcefulness, creativity, assertiveness, flexibility, time management skills and the ability to cope with pressure.", "metadata": {"url": "https://en.wikipedia.org/wiki/Office_management", "title": "Office management", "headings": ["Contents", "Importance of Office Management", "(i) Helps in Achievement of Targets", "(ii) Optimum Use of Resources", "(iii) Minimization of Costs", "(iv) Smooth Flow of Work", "(v) Helps in Maintaining Office Efficiency", "(vi) Managing Survival and Growth", "(vii) Provides Innovation", "(viii) Helps in Retaining Talent and Inculcating Sense of Loyalty in Office Staff", "(ix) Provides Leadership", "(x) Managing Change", "(xi) Maintaining Public Relations", "(xii) Social Benefits", "Functions", "See also", "References", "Further reading"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Office_management", "https://en.wikipedia.org/wiki/Office_management", "https://en.wikipedia.org/wiki/Office_management", "https://en.wikipedia.org/wiki/Business_administration", "https://en.wikipedia.org/wiki/Accounting", "https://en.wikipedia.org/wiki/Management_accounting", "https://en.wikipedia.org/wiki/Financial_accounting", "https://en.wikipedia.org/wiki/Audit"]}},
{"id": "82e3d09e5da3", "content": " James Vincent Pryor(born 1968) is an American philosopher and Professor of Philosophy at theUniversity of North Carolina at Chapel Hill(UNC). He is known for his expertise onepistemologyandphilosophy of language.Before teaching at UNC, Pryor was a faculty member in thephilosophy departmentofNew York University.He has also taught atHarvard UniversityandPrinceton University.  This biography of an American philosopher is astub. You can help Wikipedia byexpanding it.", "metadata": {"url": "https://en.wikipedia.org/wiki/James_Pryor", "title": "James Pryor", "headings": ["Contents", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/James_Pryor", "https://en.wikipedia.org/wiki/James_Pryor", "https://en.wikipedia.org/wiki/James_Pryor", "https://en.wikipedia.org/wiki/Princeton_University", "https://en.wikipedia.org/wiki/Cornell_University", "https://en.wikipedia.org/wiki/Thesis", "https://en.wikipedia.org/wiki/Doctoral_advisor", "https://en.wikipedia.org/wiki/Mark_Johnston_(philosopher)"]}},
{"id": "436df4a38106", "content": "TheUniversity of the Antilles(French:Université des Antilles), also known in English as theUniversity of the French Antilles, is a French public university, located in theFrench West Indies. It was previously part of a larger institution in combination with campuses inFrench Guianaknown as the University of the French West Indies and Guiana. As a result of funding disputes, that university was separated into two distinct institutions based on its constituent parts in French Guiana and theLesser Antillesrespectively. The separation process was completed by 1 January 2015. The university has three campuses: 4°56′24″N52°19′19″W﻿ / ﻿4.9400°N 52.3220°W﻿ /4.9400; -52.3220  This article about a French university, college, or other educational institution is astub. You can help Wikipedia byexpanding it. ThisGuadeloupe-related article is astub. You can help Wikipedia byexpanding it. ThisMartinique-related article is astub. You can help Wikipedia byexpanding it.", "metadata": {"url": "https://en.wikipedia.org/wiki/Education_in_French_Guiana", "title": "University of the French Antilles", "headings": ["Contents", "History", "Location", "Notable people", "Faculty", "Alumni", "See also", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/University_of_the_French_Antilles", "https://en.wikipedia.org/wiki/University_of_the_French_Antilles", "https://en.wikipedia.org/wiki/University_of_the_French_Antilles", "https://en.wikipedia.org/wiki/Geographic_coordinate_system", "https://en.wikipedia.org/wiki/University", "https://en.wikipedia.org/wiki/French-speaking", "https://en.wikipedia.org/wiki/Caribbean", "https://en.wikipedia.org/wiki/University_of_the_West_Indies"]}},
{"id": "e3bfcbb45a35", "content": " TheTheory of FormsorTheory of Ideas,also known asPlatonic idealismorPlatonic realism, is aphilosophical theorycredited to theClassical GreekphilosopherPlato. A major concept inmetaphysics, the theory suggests that the physical world is not as real or true as Forms. According to this theory, Forms—conventionally capitalized and also commonly translated as Ideas—are the timeless, absolute, non-physical, and unchangeableessencesof all things, which objects and matter in the physical world merely participate in, imitate, or resemble.In other words, Forms are various abstract ideals that exist even outside of human minds and that constitute the basis of reality. Thus, Plato's Theory of Forms is a type ofphilosophical realism, asserting that certain ideas are literally real, and a type ofidealism, asserting that reality is fundamentally composed of ideas, orabstract objects. Plato describes these entities only through the characters (primarilySocrates) in hisdialogueswho sometimes suggest that these Forms are the only objects of study that can provideknowledge.The theory itself is contested by characters within the dialogues, and it remains a general point of controversy in philosophy. Nonetheless, the theory is considered to be aclassicalsolution to theproblem of universals. Referring to Forms, Plato used a number ofAncient Greekterms that mainly relate tovision, sight, andappearance, includingἰδέα(idéā; from a root meaningto see), a word that precedes attested philosophical usage. Plato uses these aspects of sight and appearance in his dialogues to explain his Forms, including the supreme one: theForm of the Good. Other terms includeεἶδος(eîdos) meaning \"visible form\", and the related termsμορφή(morphḗ) meaning \"shape\",andφαινόμενα(phainómena) meaning \"appearances\", fromφαίνω(phaínō) meaning \"shine\", ultimately fromIndo-European*bʰeh₂-or*bhā-.The original meanings of these terms remained stable over the centuries before the beginning ofWestern philosophy, at which time they became equivocal, acquiring additional specialized philosophic meanings. Plato used the termseidosandideainterchangeably. Thepre-Socratic philosophers, ancient Greek thinkers born before Plato, noted that appearances change, and they began to ask what the thing that changes \"really\" is. If something changes, what component or essence of it remains \"real\"? The answer wassubstance, which stands under the changes and is the actually existing thing being seen. The status of appearances now came into question, including how the appearance is related to the substance. For instance, the earliest known pre-Socratic philosopher,Thales, argued that the fundamental substance all things are made of is water. Scriptures written byPythagoras, another pre-Socratic philosopher, suggest that he developed an earlier theory similar toPlato's Forms. For Pythagoras, like Plato, the substance or essence of all things was not something physical (like water) but rather somethingabstract. However, Pythagoras's theory was much narrower than Plato's, proposing that the non-physical and timeless essences that compose the physical world are specificallynumbers, whereas Plato conceived of his Forms as a vast array of intangible ideals. The Forms are expounded upon in Plato's dialogues and general speech, in that every object or quality in reality—dogs, human beings, mountains, colors, courage, love, and goodness—has a Form. Form answers the question, \"What is that?\" Plato was going a step further and asking what Form itself is. He supposed that the object was essentially or \"really\" the Form and that the phenomena were mere shadows mimicking the Form; that is, momentary portrayals of the Form under different circumstances.The problem of universals– how can one thing in general be many things in particular – was solved by presuming that Form was a distinct singular thing but caused plural representations of itself in particular objects. For example, in the dialogueParmenides, Socrates states: \"Nor, again, if a person were to show that all is one by partaking of one, and at the same time many by partaking of many, would that be very astonishing. But if he were to show me that the absolute one was many, or the absolute many one, I should be truly amazed.\"Matter is considered particular in itself. For Plato, Forms, such as beauty, are more real than any objects that imitate them. Though the Forms are timeless and unchanging, physical things are in a constant change of existence. Where Forms are unqualified perfection, physical things are qualified and conditioned. These Forms are the essences of various objects: they are that without which a thing would not be the kind of thing it is. For example, there are countless tables in the world but the Form of tableness is at the core; it is the essence of all of them.Plato's Socrates held that the world of Forms is transcendent to our own world (the world of substances) and also is the essential basis of reality. Super-ordinate to matter, Forms are the most pure of all things. Furthermore, he believed that true knowledge/intelligence is the ability to grasp the world of Forms with one's mind. A Form isaspatial(transcendent to space) andatemporal(transcendent to time).In the world of Plato, atemporal means that it does not exist within any time period, rather it provides the formal basis for time.It therefore formally grounds beginning, persisting and ending. It is neither eternal in the sense of existing forever, nor mortal, of limited duration. It exists transcendent to time altogether.Forms are aspatial in that they have no spatial dimensions, and thus no orientation in space, nor do they even (like the point) have a location.They are non-physical, but they are not in the mind. Forms are extra-mental (i.e. real in the strictest sense of the word). A Form is an objective \"blueprint\" of perfection.The Forms are perfect and unchanging representations of objects and qualities. For example, the Form of beauty or the Form of a triangle. For the form of a triangle say there is a triangle drawn on a blackboard. A triangle is a polygon with 3 sides. The triangle as it is on the blackboard is far from perfect. However, it is only the intelligibility of the Form \"triangle\" that allows us to know the drawing on the chalkboard is a triangle, and the Form \"triangle\" is perfect and unchanging. It is exactly the same whenever anyone chooses to consider it; however, time only affects the observer and not the triangle. It follows that the same attributes would exist for the Form of beauty and for all Forms. Plato explains how we are always many steps away from the idea or Form. The idea of a perfect circle can have us defining, speaking, writing, and drawing about particular circles that are always steps away from the actual being. The perfect circle, partly represented by a curved line, and a precise definition, cannot be drawn. The idea of the perfect circle is discovered, not invented. Plato often invokes, particularly in his dialoguesPhaedo,RepublicandPhaedrus, poetic language to illustrate the mode in which the Forms are said to exist. Near the end of thePhaedo, for example, Plato describes the world of Forms as a pristine region of the physical universe located above the surface of the Earth (Phd.109a–111c). In thePhaedrusthe Forms are in a \"place beyond heaven\" (hyperouranios topos) (Phdr.247c ff); and in theRepublicthe sensible world is contrasted with the intelligible realm (noēton topon) in the famousAllegory of the Cave. It would be a mistake to take Plato's imagery as positing the intelligible world as a literal physical space apart from this one.Plato emphasizes that the Forms are not beings that extend in space (or time), but subsist apart from any physical space whatsoever.Thus we read in theSymposiumof the Form of Beauty: \"It is not anywhere in another thing, as in an animal, or in earth, or in heaven, or in anything else, but itself by itself with itself,\" (211b). And in theTimaeusPlato writes: \"Since these things are so, we must agree that which keeps its own form unchangingly, which has not been brought into being and is not destroyed, which neither receives into itself anything else from anywhere else,nor itself enters into anything anywhere, is one thing,\" (52a, emphasis added). Plato's conception of Forms actually differs from dialogue to dialogue, and in certain respects it is never fully explained, so many aspects of the theory are open to interpretation. Forms are first introduced in thePhaedo, but in that dialogue the concept is simply referred to as something the participants are already familiar with, and the theory itself is not developed. Similarly, in theRepublic, Plato relies on the concept of Forms as the basis of many of his arguments but feels no need to argue for the validity of the theory itself or to explain precisely what Forms are. Commentators have been left with the task of explaining what Forms are and how visible objects participate in them, and there has been no shortage of disagreement. Some scholars advance the view that Forms are paradigms, perfect examples on which the imperfect world is modeled. Others interpret Forms as universals, so that the Form of Beauty, for example, is that quality that all beautiful things share. Yet others interpret Forms as \"stuffs\", the conglomeration of all instances of a quality in the visible world. Under this interpretation, we could say there is a little beauty in one person, a little beauty in another – all the beauty in the world put together is the Form of Beauty. Plato himself was aware of the ambiguities and inconsistencies in his Theory of Forms, as is evident from the incisive criticism he makes of his own theory in theParmenides. InCratylus, Plato writes: But if the very nature of knowledge changes, at the time when the change occurs there will be no knowledge, and, according to this view, there will be no one to know and nothing to be known: but if that which knows and that which is known exist ever, and the beautiful and the good and every other thing also exist, then I do not think that they can resemble a process of flux, as we were just now supposing. Plato believed that long before our bodies ever existed, our souls existed and inhabited heaven, where they became directly acquainted with the forms themselves. Real knowledge, to him, was knowledge of the forms. But knowledge of the forms cannot be gained through sensory experience because the forms are not in the physical world. Therefore, our real knowledge of the forms must be the memory of our initial acquaintance with the forms in heaven. Therefore, what we seem to learn is in fact just remembering. No one has ever seen aperfectcircle, nor a perfectly straight line, yet everyone knows what a circle and a straight line are. Plato uses the tool-maker's blueprint as evidence that Forms are real: ... when a man has discovered the instrument which is naturally adapted to each work, he must express this natural form, and not others which he fancies, in the material .... Perceived circles or lines are not exactly circular or straight, and true circles and lines could never be detected since by definition they are sets of infinitely small points. But if the perfect ones were not real, how could they direct the manufacturer? One difficulty lies in the conceptualization of the \"participation\" of an object in a form (or Form). The young Socrates conceives of his solution to the problem of the universals in another metaphor: Nay, but the idea may be like the day which is one and the same in many places at once, and yet continuous with itself; in this way each idea may be one and the same in all at the same time. But exactly how is a Form like the day in being everywhere at once? The solution calls for a distinct form, in which the particular instances, which are not identical to the form, participate; i.e., the form is shared out somehow like the day to many places. The concept of \"participate\", represented in Greek by more than one word, is as obscure in Greek as it is in English. Plato hypothesized that distinctness meant existence as an independent being, thus opening himself to the famousthird man argumentof Parmenides,which proves that forms cannot independently exist and be participated. If universal and particulars – say man or greatness – all exist and are the same then the Form is not one but is multiple. If they are only like each other then they contain a form that is the same and others that are different. Thus if we presume that the Form and a particular are alike then there must be another, or third Form, man or greatness by possession of which they are alike. Aninfinite regressionwould then result; that is, an endless series of third men. The ultimate participant, greatness, rendering the entire series great, is missing. Moreover, any Form is not unitary but is composed of infinite parts, none of which is the proper Form. The young Socrates did not give up the Theory of Forms over the Third Man but took another tack, that the particulars do not exist as such. Whatever they are, they \"mime\" the Forms, appearing to be particulars. This is a clear dip intorepresentationalism, that we cannot observe the objects as they are in themselves but only their representations. That view has the weakness that if only the mimes can be observed then the real Forms cannot be known at all and the observer can have no idea of what the representations are supposed to represent or that they are representations. Socrates' later answer would be that men already know the Forms because they were in the world of Forms before birth. The mimes only recall these Forms to memory. The topic of Aristotle's criticism of Plato's Theory of Forms is a large one and continues to expand. Rather than quote Plato, Aristotle often summarized. Classical commentaries thus recommended Aristotle as an introduction to Plato, even when in disagreement; the PlatonistSyrianusused Aristotelian critiques to further refine the Platonic position on forms in use in his school, a position handed down to his studentProclus.As a historian of prior thought, Aristotle was invaluable, however this was secondary to his own dialectic and in some cases he treats purported implications as if Plato had actually mentioned them, or even defended them. In examining Aristotle's criticism of The Forms, it is helpful to understand Aristotle's ownhylomorphic forms, by which he intends to salvage much of Plato's theory. Plato distinguished between real and non-real \"existing things\", where the latter term is used of substance. The figures that the artificer places in the gold are not substance, but gold is. Aristotle stated that, for Plato, all things studied by the sciences have Form and asserted that Plato considered only substance to have Form. Uncharitably, this leads him to something like a contradiction: Forms existing as the objects of science, but not-existing as substance. Scottish philosopherW.D. Rossobjects to this as a mischaracterization of Plato. Plato did not claim to know where the line between Form and non-Form is to be drawn. As Cornford points out,those things about which the young Socrates (and Plato) asserted \"I have often been puzzled about these things\"(in reference to Man, Fire and Water), appear as Forms in later works. However, others do not, such as Hair, Mud, Dirt. Of these, Socrates is made to assert, \"it would be too absurd to suppose that they have a Form.\" Rossalso objects to Aristotle's criticism that Form Otherness accounts for the differences between Forms and purportedly leads to contradictory forms: the Not-tall, the Not-beautiful, etc. That particulars participate in a Form is for Aristotle much too vague to permit analysis. By one way in which he unpacks the concept, the Forms would cease to be of one essence due to any multiple participation. As Ross indicates, Plato didn't make that leap from \"A is not B\" to \"A is Not-B.\" Otherness would only apply to its own particulars and not to those of other Forms. For example, there is no Form Not-Greek, onlyparticularsof Form Otherness that somehowsuppressForm Greek. Regardless of whether Socrates meant the particulars of Otherness yield Not-Greek, Not-tall, Not-beautiful, etc., the particulars would operate specifically rather than generally, each somehow yielding only one exclusion. Plato had postulated that we know Forms through a remembrance of the soul'spast livesand Aristotle's arguments against this treatment ofepistemologyare compelling. For Plato, particulars somehow do not exist, and, on the face of it, \"that which is non-existent cannot be known\".SeeMetaphysicsIII 3–4. Nominalism(from Latinnomen, \"name\") says that ideal universals are mere names, human creations; the blueness shared by sky and blue jeans is a shared concept, communicated by our word \"blueness\". Blueness is held not to have any existence beyond that which it has in instances of blue things.This concept arose in the Middle Ages,as part ofScholasticism. Scholasticism was a highly multinational, polyglottal school of philosophy, and the nominalist argument may be more obvious if an example is given in more than one language. For instance,colour termsare strongly variable by language; some languages consider blue and green the same colour, others have monolexemic terms for several shades of blue, which are considered different; other languages, like the Mandarinqingdenote both blue and black. The German word \"Stift\" means a pen or a pencil, and also anything of the same shape. The English \"pencil\" originally meant \"small paintbrush\"; the term later included the silver rod used forsilverpoint. The German \"Bleistift\" and \"Silberstift\" can both be called \"Stift\", but this term also includes felt-tip pens, which are clearly not pencils. The shifting and overlapping nature of these concepts makes it easy to imagine them as mere names, with meanings not rigidly defined, but specific enough to be useful for communication. Given a group of objects, how is one to decide if it contains only instances of a single Form, or several mutually exclusive Forms? Dialogues that discuss FormsThe theory is presented in the following dialogues:", "metadata": {"url": "https://en.wikipedia.org/wiki/Platonic_realism", "title": "Theory of forms", "headings": ["Contents", "Etymology", "Pre-Socratic philosophy", "Plato's Forms", "Intelligible realm and separation of the Forms", "Ambiguities of the theory", "Evidence of Forms", "Human perception", "Perfection", "Criticisms of Platonic Forms", "Self-criticism", "Aristotelian criticism", "Scholastic criticism", "See also", "Notes", "Primary sources", "Bibliography", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Theory_of_forms", "https://en.wikipedia.org/wiki/Theory_of_forms", "https://en.wikipedia.org/wiki/Theory_of_forms", "https://en.wikipedia.org/wiki/The_Forms_(band)", "https://en.wikipedia.org/wiki/Platonism", "https://en.wikipedia.org/wiki/Life_of_Plato", "https://en.wikipedia.org/wiki/Intelligible_form", "https://en.wikipedia.org/wiki/Hyperuranion"]}},
{"id": "629c226947dd", "content": "Psychological Science, the flagship journal of theAssociation for Psychological Science, is a monthly,peer-reviewedscientific journalpublished bySAGE Publications. The journal publishes research articles, short reports, and research reports covering all aspects ofpsychology.Itseditor-in-chiefisSimine Vazire(University of Melbourne). The following persons have been editors-in-chief:  This article about anacademic journalonpsychologyis astub. You can help Wikipedia byexpanding it. See tips for writing articles about academic journals. Further suggestions might be found on the article'stalk page.", "metadata": {"url": "https://en.wikipedia.org/wiki/Psychological_Science_(journal)", "title": "Psychological Science", "headings": ["Contents", "Past editors", "References"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Psychological_Science", "https://en.wikipedia.org/wiki/Psychological_Science", "https://en.wikipedia.org/wiki/Psychological_Science", "https://en.wikipedia.org/wiki/Psychology", "https://en.wikipedia.org/wiki/Outline_of_academic_disciplines", "https://en.wikipedia.org/wiki/Psychology", "https://en.wikipedia.org/wiki/Editor-in-chief", "https://en.wikipedia.org/wiki/Patricia_Bauer"]}},
{"id": "6feef83f6a3d", "content": "Reasonis the capacity ofconsciouslyapplyinglogicbydrawing valid conclusionsfrom new or existinginformation, with the aim of seekingtruth.It is associated with such characteristicallyhumanactivities asphilosophy,religion,science,language, andmathematics, and is normally considered to be a distinguishing ability possessed by humans.Reason is sometimes referred to asrationality,although the latter is more about its application. Reasoninginvolves using more-or-less rational processes ofthinkingandcognitionto extrapolate from one's existing knowledge to generate new knowledge, and involves the use of one'sintellect. The field oflogicstudies the ways in which humans can useformal reasoningto producelogically validargumentsand true conclusions.Reasoning may be subdivided intoformsoflogical reasoning, such asdeductive reasoning,inductive reasoning, andabductive reasoning. Aristotledrew a distinction between logicaldiscursive reasoning(reason proper), andintuitive reasoning,in which the reasoning process through intuition—however valid—may tend toward the personal and the subjectively opaque. In some social and political settings logical and intuitive modes of reasoning may clash, while in other contexts intuition and formal reason are seen as complementary rather than adversarial. For example, inmathematics, intuition is often necessary for the creative processes involved with arriving at aformal proof, arguably the most difficult of formal reasoning tasks. Reasoning, likehabitorintuition, is one of the ways by which thinking moves from one idea to a related idea. For example, reasoning is the means by which rational individuals understand the significance of sensory information from their environments, or conceptualize abstract dichotomies such ascause and effect,truthandfalsehood, orgood and evil. Reasoning, as a part ofexecutive decision making, is also closely identified with the ability to self-consciously change, in terms ofgoals,beliefs,attitudes,traditions, andinstitutions, and therefore with the capacity forfreedomandself-determination. Psychologistsandcognitive scientistshave attempted to study and explainhow people reason, e.g. which cognitive and neural processes are engaged, and how cultural factors affect the inferences that people draw. The field ofautomated reasoningstudies how reasoning may or may not be modeled computationally.Animal psychologyconsiders the question of whether animals other than humans can reason. In theEnglish languageand other modernEuropean languages, \"reason\", and related words, represent words which have always been used to translate Latin and classical Greek terms in their philosophical sense. The earliest major philosophers to publish in English, such asFrancis Bacon,Thomas Hobbes, andJohn Lockealso routinely wrote in Latin and French, and compared their terms to Greek, treating the words \"logos\", \"ratio\", \"raison\" and \"reason\" as interchangeable. The meaning of the word \"reason\" in senses such as \"human reason\" also overlaps to a large extent with \"rationality\" and the adjective of \"reason\" in philosophical contexts is normally \"rational\", rather than \"reasoned\" or \"reasonable\".Some philosophers, Hobbes for example, also used the wordratiocinationas a synonym for \"reasoning\". In contrast to the use of \"reason\" as anabstract noun,areasonis a consideration that either explains or justifies events, phenomena, orbehavior.Reasons justify decisions, reasons support explanations of natural phenomena, and reasons can be given to explain the actions (conduct) of individuals. The words are connected in this way: using reason, or reasoning, means providing good reasons. For example, when evaluating a moral decision, \"morality is, at the very least, the effort to guide one's conduct byreason—that is, doing what there are the best reasons for doing—while giving equal [and impartial] weight to the interests of all those affected by what one does.\" The proposal that reason gives humanity a special position in nature has been arguedto be a defining characteristic ofwesternphilosophyand later westernscience, starting with classical Greece. Philosophy can be described as a way of life based upon reason, while reason has been among the major subjects of philosophical discussion since ancient times. Reason is often said to bereflexive, or \"self-correcting\", and the critique of reason has been a persistent theme in philosophy. For many classicalphilosophers, nature was understoodteleologically, meaning that every type of thing had a definitive purpose that fit within a natural order that was itself understood to have aims. Perhaps starting withPythagorasorHeraclitus, thecosmoswas even said to have reason.Reason, by this account, is not just a characteristic that people happen to have. Reason was considered of higher stature than other characteristics of human nature, because it is something people share with nature itself, linking an apparently immortal part of the human mind with the divine order of the cosmos. Within the humanmindorsoul(psyche), reason was described byPlatoas being the natural monarch which should rule over the other parts, such as spiritedness (thumos) and the passions.Aristotle, Plato's student, defined human beings asrational animals, emphasizing reason as a characteristic ofhuman nature. He described the highest human happiness or well being (eudaimonia) as a life which is lived consistently, excellently, and completely in accordance with reason. The conclusions to be drawn from the discussions of Aristotle and Plato on this matter are amongst the most debated in the history of philosophy.But teleological accounts such as Aristotle's were highly influential for those who attempt to explain reason in a way that is consistent withmonotheismand the immortality and divinity of the human soul. For example, in theneoplatonistaccount ofPlotinus, thecosmoshas one soul, which is the seat of all reason, and the souls of all people are part of this soul. Reason is for Plotinus both the provider of form to material things, and the light which brings people's souls back into line with their source. The classical view of reason was adopted by the early Church.The greatest among the earlyChurch FathersandDoctors of the Churchsuch asAugustine of Hippo,Basil of Caesarea, andGregory of Nyssawere as much Neoplatonic philosophers as they were Christian theologians, and they adopted the Neoplatonic view of human reason and its implications for our relationship to creation, to ourselves, and to God. The Neoplatonic conception of the rational aspect of the human soul was widely adopted by medieval Islamic philosophers and continues to hold significance inIranian philosophy.As European intellectual life reemerged from theDark Ages, the ChristianPatristictradition and the influence of esteemed Islamic scholars likeAverroesandAvicennacontributed to the development of theScholasticview of reason, which laid the foundation for our modern understanding of this concept. Among the Scholastics who relied on the classical concept of reason for the development of their doctrines, none were more influential thanSaint Thomas Aquinas, who put this concept at the heart of hisNatural Law. In this doctrine, Thomas concludes that because humans have reason and because reason is a spark of the divine, every single human life is invaluable, all humans are equal, and every human is born with an intrinsic and permanent set of basic rights.On this foundation, the idea of human rights would later be constructed by Spanish theologians at theSchool of Salamanca. Other Scholastics, such asRoger BaconandAlbertus Magnus, following the example of Islamic scholars such asAlhazen, emphasised reason an intrinsic human ability to decode the created order and the structures that underlie our experienced physical reality. This interpretation of reason was instrumental to the development of the scientific method in the early Universities of the high Middle Ages. Theearly modern erawas marked by a number of significant changes in the understanding of reason, starting inEurope. One of the most important of these changes involved a change in themetaphysicalunderstanding of human beings. Scientists and philosophers began to question theteleologicalunderstanding of the world.Nature was no longer assumed to be human-like, with its own aims or reason, and human nature was no longer assumed to work according to anything other than the same \"laws of nature\" which affect inanimate things. This new understanding eventually displaced the previousworld viewthat derived from a spiritual understanding of the universe. Accordingly, in the 17th century,René Descartesexplicitly rejected the traditional notion of humans as \"rational animals\", suggesting instead that they are nothing more than \"thinking things\" along the lines of other \"things\" in nature. Any grounds of knowledge outside that understanding was, therefore, subject to doubt. In his search for a foundation of all possible knowledge, Descartes brought into doubtallknowledge—exceptthat of the mind itself in the process of thinking: At this time I admit nothing that is not necessarily true. I am therefore precisely nothing but a thinking thing; that is a mind, or intellect, or understanding, or reason—words of whose meanings I was previously ignorant. This eventually became known asepistemologicalor \"subject-centred\" reason, because it is based on theknowing subject, who perceives the rest of the world and itself as a set of objects to be studied, and successfully mastered, by applying the knowledge accumulated through such study. Breaking with tradition and with many thinkers after him, Descartes explicitly did not divide the incorporeal soul into parts, such as reason and intellect, describing them instead as one indivisible incorporeal entity. A contemporary of Descartes,Thomas Hobbesdescribed reason as a broader version of \"addition and subtraction\" which is not limited to numbers.This understanding of reason is sometimes termed \"calculative\" reason. Similar to Descartes, Hobbes asserted that \"No discourse whatsoever, can end in absolute knowledge of fact, past, or to come\" but that \"sense and memory\" is absolute knowledge. In the late 17th century through the 18th century,John LockeandDavid Humedeveloped Descartes's line of thought still further. Hume took it in an especiallyskepticaldirection, proposing that there could be no possibility ofdeducingrelationships of cause and effect, and therefore no knowledge is based on reasoning alone, even if it seems otherwise. Hume famously remarked that, \"We speak not strictly and philosophically when we talk of the combat of passion and of reason. Reason is, and ought only to be the slave of the passions, and can never pretend to any other office than to serve and obey them.\"Hume also took his definition of reason to unorthodox extremes by arguing, unlike his predecessors, that human reason is not qualitatively different from either simply conceiving individual ideas, or from judgments associating two ideas,and that \"reason is nothing but a wonderful and unintelligible instinct in our souls, which carries us along a certain train of ideas, and endows them with particular qualities, according to their particular situations and relations.\"It followed from this that animals have reason, only much less complex than human reason. In the 18th century,Immanuel Kantattempted to show that Hume was wrong by demonstrating that a \"transcendental\" self, or \"I\", was a necessary condition of all experience. Therefore, suggested Kant, on the basis of such a self, it is in fact possible to reason both about the conditions and limits of human knowledge. And so long as these limits are respected, reason can be the vehicle of morality, justice, aesthetics, theories of knowledge (epistemology), and understanding. In the formulation of Kant, who wrote some of the most influential modern treatises on the subject, the great achievement of reason (German:Vernunft) is that it is able to exercise a kind of universal law-making. Kant was able therefore to reformulate the basis of moral-practical, theoretical, and aesthetic reasoning on \"universal\" laws. Here,practical reasoningis the self-legislating or self-governing formulation of universalnorms, andtheoreticalreasoning is the way humans posit universallaws of nature. Under practical reason, the moralautonomyor freedom of people depends on their ability, by the proper exercise of that reason, to behave according to laws that are given to them. This contrasted with earlier forms of morality, which depended onreligious understandingand interpretation, or onnature, for their substance. According to Kant, in a free society each individual must be able to pursue their goals however they see fit, as long as their actions conform to principles given by reason. He formulated such a principle, called the \"categorical imperative\", which would justify an action only if it could be universalized: Act only according to that maxim whereby you can, at the same time, will that it should become a universal law. In contrast to Hume, Kant insisted that reason itself (GermanVernunft) could be used to find solutions to metaphysical problems, especially the discovery of the foundations of morality. Kant claimed that these solutions could be found with his \"transcendental logic\", which unlike normal logic is not just an instrument that can be used indifferently, as it was for Aristotle, but a theoretical science in its own right and the basis of all the others. According toJürgen Habermas, the \"substantive unity\" of reason has dissolved in modern times, such that it can no longer answer the question \"How should I live?\" Instead, the unity of reason has to be strictly formal, or \"procedural\". He thus described reason as a group of three autonomous spheres (on the model of Kant's three critiques): For Habermas, these three spheres are the domain of experts, and therefore need to be mediated with the \"lifeworld\" by philosophers. In drawing such a picture of reason, Habermas hoped to demonstrate that the substantive unity of reason, which in pre-modern societies had been able to answer questions about the good life, could be made up for by the unity of reason's formalizable procedures. Hamann,Herder,Kant,Hegel,Kierkegaard,Nietzsche,Heidegger,Foucault,Rorty, and many other philosophers have contributed to a debate about what reason means, or ought to mean. Some, like Kierkegaard, Nietzsche, and Rorty, are skeptical about subject-centred, universal, or instrumental reason, and even skeptical toward reason as a whole. Others, including Hegel, believe that it has obscured the importance ofintersubjectivity, or \"spirit\" in human life, and they attempt to reconstruct a model of what reason should be. Some thinkers, e.g. Foucault, believe there are otherformsof reason, neglected but essential to modern life, and to our understanding of what it means to live a life according to reason.Others suggest that there is not just one reason or rationality, but multiple possible systems of reason or rationality which may conflict (in which case there is no super-rational system one can appeal to in order to resolve the conflict). In the last several decades, a number of proposals have been made to \"re-orient\" this critique of reason, or to recognize the \"other voices\" or \"new departments\" of reason: For example, in opposition to subject-centred reason, Habermas has proposed a model ofcommunicative reasonthat sees it as an essentially cooperative activity, based on the fact of linguisticintersubjectivity. Nikolas Kompridisproposed a widely encompassing view of reason as \"that ensemble of practices that contributes to the opening and preserving of openness\" in human affairs, and a focus on reason's possibilities for social change. The philosopherCharles Taylor, influenced by the 20th century German philosopherMartin Heidegger, proposed that reason ought to include the faculty ofdisclosure, which is tied to the way we make sense of things in everyday life, as a new \"department\" of reason. In the essay \"What is Enlightenment?\", Michel Foucault proposed a critique based on Kant's distinction between \"private\" and \"public\" uses of reason: The termslogicorlogicalare sometimes used as if they were identical withreasonorrational, or sometimes logic is seen as the most pure or the defining form of reason: \"Logic is about reasoning—about going from premises to a conclusion. ... When you do logic, you try to clarify reasoning and separate good from bad reasoning.\"In moderneconomics,rational choiceis assumed to equate to logicallyconsistentchoice. However, reason and logic can be thought of as distinct—although logic is one important aspect of reason. AuthorDouglas Hofstadter, inGödel, Escher, Bach, characterizes the distinction in this way: Logic is done inside a system while reason is done outside the system by such methods as skipping steps, working backward, drawing diagrams, looking at examples, or seeing what happens if you change the rules of the system.Psychologists Mark H. Bickard and Robert L. Campbell argue that \"rationality cannot be simply assimilated to logicality\"; they note that \"human knowledge of logic andlogical systemshas developed\" over time through reasoning, and logical systems \"can't construct new logical systems more powerful than themselves\", so reasoning and rationality must involve more than a system of logic.Psychologist David Moshman, citing Bickhard and Campbell, argues for a \"metacognitiveconception of rationality\" in which a person's development of reason \"involves increasing consciousness and control of logical and other inferences\". Reason is a type ofthought, andlogicinvolves the attempt to describe a system of formal rules or norms of appropriate reasoning.The oldest surviving Western writings to explicitly consider and systematically codify the rules by which reason operates, are the works of theGreekphilosopherAristotle, especiallyPrior AnalyticsandPosterior Analytics.Although the Ancient Greeks had no separate word for logic as distinct from language and reason, Aristotle'snewly coined word\"syllogism\" (syllogismos) identified logic clearly for the first time as a distinct field of study.When Aristotle referred to \"the logical\" (hē logikē), he was referring more broadly to rational thought. As pointed out by philosophers such as Hobbes, Locke, and Hume, some animals are also clearly capable of a type of \"associative thinking\", even to the extent of associating causes and effects. A dog once kicked, can learn how to recognize the warning signs and avoid being kicked in the future, but this does not mean the dog has reason in any strict sense of the word. It also does not mean that humans acting on the basis of experience or habit are using their reason. Human reason requires more than being able to associate two ideas—even if those two ideas might be described by a reasoning human as a cause and an effect—perceptions of smoke, for example, and memories of fire. For reason to be involved, the association of smoke and the fire would have to be thought through in a way that can be explained, for example as cause and effect. In the explanation ofLocke, for example, reason requires the mental use of a third idea in order to make this comparison by use ofsyllogism. More generally, according toCharles Sanders Peirce, reason in the strict sense requires the ability to create and manipulate a system ofsymbols, as well asindices and icons, the symbols having only a nominal, though habitual, connection to either (for example) smoke or fire.One example of such a system of symbols and signs islanguage. The connection of reason to symbolic thinking has been expressed in different ways by philosophers.Thomas Hobbesdescribed the creation of \"Markes, or Notes of remembrance\" asspeech.He used the wordspeechas an English version of the Greek wordlogosso that speech did not need to be communicated.When communicated, such speech becomes language, and the marks or notes or remembrance are called \"Signes\" by Hobbes. Going further back, although Aristotle is a source of the idea that only humans have reason (logos), he does mention that animals with imagination, for whom sense perceptions can persist, come closest to having something like reasoning andnous, and even uses the word \"logos\" in one place to describe the distinctions which animals can perceive in such cases. Reason andimaginationrely on similarmental processes.Imagination is not only found in humans. Aristotle asserted thatphantasia(imagination: that which can hold images orphantasmata) andphronein(a type of thinking that can judge and understand in some sense) also exist in some animals.According to him, both are related to the primary perceptive ability of animals, which gathers the perceptions of different senses and defines the order of the things that are perceived without distinguishing universals, and without deliberation orlogos. But this is not yet reason, because human imagination is different. Terrence DeaconandMerlin Donald, writing about theorigin of language, connect reason not only tolanguage, but alsomimesis.They describe the ability to create language as part of an internal modeling ofreality, and specific to humankind. Other results areconsciousness, andimaginationorfantasy. Modern proponents of a genetic predisposition to language itself includeNoam ChomskyandSteven Pinker. If reason is symbolic thinking, and peculiarly human, then this implies that humans have a special ability to maintain a clear consciousness of the distinctness of \"icons\" or images and the real things they represent. Merlin Donald writes: A dog might perceive the \"meaning\" of a fight that was realistically play-acted by humans, but it could not reconstruct the message or distinguish the representation from its referent (a real fight).... Trained apes are able to make this distinction; young children make this distinction early—hence, their effortless distinction between play-acting an event and the event itself In classical descriptions, an equivalent description of this mental faculty iseikasia, in the philosophy of Plato.This is the ability to perceive whether a perception is an image of something else, related somehow but not the same, and therefore allows humans to perceive that a dream or memory or a reflection in a mirror is not reality as such. What Klein refers to asdianoetic eikasiais theeikasiaconcerned specifically with thinking and mental images, such as those mental symbols, icons,signes, and marks discussed above as definitive of reason. Explaining reason from this direction: human thinking is special in that we often understand visible things as if they were themselves images of our intelligible \"objects of thought\" as \"foundations\" (hypothēsesin Ancient Greek). This thinking (dianoia) is \"...an activity which consists in making the vast and diffuse jungle of the visible world depend on a plurality of more 'precise'noēta\". Both Merlin Donald and the Socratic authors such as Plato and Aristotle emphasize the importance ofmimēsis, often translated asimitationorrepresentation. Donald writes: Imitation is found especially in monkeys and apes [...but...] Mimesis is fundamentally different from imitation and mimicry in that it involves the invention of intentional representations.... Mimesis is not absolutely tied to external communication. Mimēsisis a concept, now popular again in academic discussion, that was particularly prevalent in Plato's works. In Aristotle, it is discussed mainly in thePoetics. In Michael Davis's account of the theory of man in that work: It is the distinctive feature of human action, that whenever we choose what we do, we imagine an action for ourselves as though we were inspecting it from the outside. Intentions are nothing more than imagined actions, internalizings of the external. All action is therefore imitation of action; it is poetic... Donald, like Plato (and Aristotle, especially inOn Memory and Recollection), emphasizes the peculiarity in humans of voluntary initiation of a search through one's mental world. The ancient Greekanamnēsis, normally translated as \"recollection\" was opposed tomnemeor \"memory\". Memory, shared with some animals,requires a consciousness not only of what happened in the past, but alsothatsomething happened in the past, which is in other words a kind ofeikasia\"...but nothing except man is able to recollect.\"Recollection is a deliberate effort to search for and recapture something once known. Klein writes that, \"To become aware of our having forgotten something means to begin recollecting.\"Donald calls the same thingautocueing, which he explains as follows:\"Mimetic acts are reproducible on the basis of internal, self-generated cues. This permits voluntary recall of mimetic representations, without the aid of external cues—probably the earliest form of representationalthinking.\" In a celebrated paper, the fantasy author and philologistJ.R.R. Tolkienwrote in his essay \"On Fairy Stories\" that the terms \"fantasy\" and \"enchantment\" are connected to not only \"the satisfaction of certain primordial human desires\" but also \"the origin of language and of the mind\". A subdivision ofphilosophyand a variety of reasoning islogic. The traditional main division made in philosophy is betweendeductive reasoningandinductive reasoning.Formal logichas been described asthe science of deduction.The study of inductive reasoning is generally carried out within the field known asinformal logicorcritical thinking. Deduction is a form of reasoning in which a conclusion follows necessarily from the stated premises. A deduction is also the name for the conclusion reached by a deductive reasoning process. A classic example of deductive reasoning is evident insyllogismslike the following: The reasoning in this argument is deductivelyvalidbecause there is no way in which both premises could be true and the conclusion be false. Induction is a form of inference that producesproperties or relationsabout unobserved objects ortypesbased onprevious observations or experiences, or that formulates general statements orlawsbased on limited observations of recurringphenomenalpatterns. Inductive reasoning contrasts with deductive reasoning in that, even in the strongest cases of inductive reasoning, the truth of the premises does not guarantee the truth of the conclusion. Instead, the conclusion of an inductive argument follows with some degree ofprobability. For this reason also, the conclusion of an inductive argument contains more information than is already contained in the premises. Thus, this method of reasoning is ampliative. A classic example of inductive reasoning comes from theempiricistDavid Hume: Analogical reasoning is a form of inductive reasoning from a particular to a particular. It is often used incase-based reasoning, especially legal reasoning.An example follows: Analogical reasoning is a weaker form of inductive reasoning from a single example, because inductive reasoning typically uses a large number of examples to reason from the particular to the general.Analogical reasoning often leads to wrong conclusions. For example: Abductive reasoning, or argument to the best explanation, is a form of reasoning that does not fit in either the deductive or inductive categories, since it starts with incomplete set of observations and proceeds with likely possible explanations. The conclusion in an abductive argument does not follow with certainty from its premises and concerns something unobserved. What distinguishes abduction from the other forms of reasoning is an attempt to favour one conclusion above others, by subjective judgement or by attempting to falsify alternative explanations or by demonstrating the likelihood of the favoured conclusion, given a set of more or less disputable assumptions. For example, when a patient displays certain symptoms, there might be various possible causes, but one of these is preferred above others as being more probable. Flawed reasoning in arguments is known asfallacious reasoning. Bad reasoning within arguments can result from either aformal fallacyor aninformal fallacy. Formal fallacies occur when there is a problem with the form, or structure, of the argument. The word \"formal\" refers to this link to theformof the argument. An argument that contains a formal fallacy will always be invalid. An informal fallacy is an error in reasoning that occurs due to a problem with thecontent, rather than the form or structure, of the argument. In law relating to the actions of an employer or apublic body, a decision or action which falls outside the range of actions or decision available when acting in good faith can be described as \"unreasonable\". Use of the term is considered in theEnglish lawcases ofShort v Poole Corporation(1926),Associated Provincial Picture Houses Ltd v Wednesbury Corporation(1947) andBraganza v BP Shipping Limited(2015). Philosophy is often characterized as a pursuit of rational understanding, entailing a more rigorous and dedicated application of human reasoning than commonly employed. Philosophers have long debated two fundamental questions regarding reason, essentially examining reasoning itself as a human endeavor, or philosophizing about philosophizing. The first question delves into whether we can place our trust in reason's ability to attainknowledgeandtruthmore effectively than alternative methods. The second question explores whether a life guided by reason, a life that aims to be guided by reason, can be expected to lead to greaterhappinesscompared to other approaches to life. Sinceclassical antiquitya question has remained constant in philosophical debate (sometimes seen as a conflict betweenPlatonismandAristotelianism) concerning the role of reason in confirmingtruth. People use logic,deduction, andinductionto reach conclusions they think are true. Conclusions reached in this way are considered, according to Aristotle, more certain than sense perceptions on their own.On the other hand, if such reasoned conclusions are only built originally upon a foundation of sense perceptions, then our most logical conclusions can never be said to be certain because they are built upon the very same fallible perceptions they seek to better. This leads to the question of what types offirst principles, or starting points of reasoning, are available for someone seeking to come to true conclusions. In Greek, \"first principles\" arearchai, \"starting points\",and the faculty used to perceive them is sometimes referred to in Aristotleand Platoasnouswhich was close in meaning toawarenessorconsciousness. Empiricism(sometimes associated with Aristotlebut more correctly associated withBritishphilosophers such asJohn LockeandDavid Hume, as well as their ancient equivalents such asDemocritus) asserts that sensory impressions are the only available starting points for reasoning and attempting to attain truth. This approach always leads to the controversial conclusion thatabsolute knowledgeis not attainable.Idealism, (associated with Plato and his school), claims that there is a \"higher\" reality, within which certain people can directly discover truth without needing to rely only upon the senses, and that this higher reality is therefore the primary source of truth. Philosophers such asPlato,Aristotle,Al-Farabi,Avicenna,Averroes,Maimonides,Aquinas, andHegelargued that reason must be fixed and discoverable—perhaps by dialectic, analysis, or study. Religious philosophers such asThomas AquinasandÉtienne Gilsonattempted to show that reason andrevelationare compatible. According to Hegel, \"...the only thought which Philosophy brings with it to the contemplation ofHistory, is the simple conception of reason; that reason is the Sovereign of the World; that the history of the world, therefore, presents us with a rational process.\" Since the 17th centuryrationalists, reason has often been taken to be asubjective faculty, or rather the unaided ability (pure reason) to form concepts. ForDescartes,Spinoza, andLeibniz, this was associated withmathematics.Kantattempted to show that pure reason could form concepts (timeandspace) that are the conditions of experience. Kant made his argument in opposition to Hume, who denied that reason had any role to play in experience. After Plato and Aristotle,western literatureoften treated reason as being the faculty that trained the passions and appetites.Stoic philosophy, by contrast, claimed most emotions were merely false judgements.According to the Stoics the only good is virtue, and the only evil is vice, therefore emotions that judged things other than vice to be bad (such as fear or distress), or things other than virtue to be good (such as greed) were simply false judgements and should be discarded (though positive emotions based on true judgements, such as kindness, were acceptable).After the critiques of reason in the early Enlightenment the appetites were rarely discussed or were conflated with the passions.Some Enlightenment camps took after the Stoics to say reason should oppose passion rather than order it, while others like the Romantics believed that passion displaces reason, as in the maxim \"follow your heart\". Reason has been seen as cold, an \"enemy of mystery and ambiguity\",a slave, or judge, of the passions, notably in the work ofDavid Hume. More recently,Freudwrote, “It seems as though the activity of the other agencies of the mind is able only to modify the pleasure principle but not to nullify it; and it remains a question of the greatest theoretical importance, and one that has not yet been answered, when and how it is ever possible for the pleasure principle to be overcome.” Reasoning that claims the object of a desire is demanded by logic alone is calledrationalization. Rousseaufirst proposed, in his secondDiscourse, that reason and political life is not natural and is possibly harmful to mankind.He asked what really can be said about what is natural to mankind. What, other than reason and civil society, \"best suits his constitution\"? Rousseau saw \"two principles prior to reason\" in human nature. First we hold an intense interest in our own well-being. Secondly we object to the suffering or death of any sentient being, especially one like ourselves.These two passions lead us to desire more than we could achieve. We become dependent upon each other, and on relationships of authority and obedience. This effectively puts the human race into slavery. Rousseau says that he almost dares to assert that nature does not destine men to be healthy. According toRichard Velkley, \"Rousseau outlines certain programs of rational self-correction, most notably the political legislation of theContrat Socialand the moral education inÉmile. All the same, Rousseau understands such corrections to be only ameliorations of an essentially unsatisfactory condition, that of socially and intellectually corrupted humanity.\" This quandary presented by Rousseau led toKant's new way of justifying reason as freedom to create good and evil. These therefore are not to be blamed on nature or God. In various ways,German Idealismafter Kant, and major later figures suchNietzsche,Bergson,Husserl,Scheler, andHeidegger, remain preoccupied with problems coming from the metaphysical demands or urges of reason.Rousseau and these later writers also exerted a large influence on art and politics. Many writers (such asNikos Kazantzakis) extol passion and disparage reason. In politics modernnationalismcomes from Rousseau's argument that rationalistcosmopolitanismbrings man ever further from his natural state. InDescartes' Error,Antonio Damasiopresents the \"Somatic Marker Hypothesis\" which states that emotions guide behavior and decision-making. Damasio argues that these somatic markers (known collectively as \"gut feelings\") are \"intuitive signals\" that direct our decision making processes in a certain way that cannot be solved with rationality alone. Damasio further argues that rationality requires emotional input in order to function. There are many religious traditions, some of which are explicitlyfideistand others of which claim varying degrees ofrationalism. Secular critics sometimes accuse all religious adherents of irrationality; they claim such adherents are guilty of ignoring, suppressing, or forbidding some kinds of reasoning concerning some subjects (such as religious dogmas, moral taboos, etc.).Thoughtheologiesandreligionssuch asclassical monotheismtypically do not admit to beingirrational, there is often a perceived conflict or tension betweenfaithandtraditionon the one hand, and reason on the other, as potentially competing sources ofwisdom,law, andtruth. Religious adherents sometimes respond by arguing that faith and reason can be reconciled, or have different non-overlapping domains, or that critics engage in a similar kind of irrationalism: Some commentators have claimed thatWestern civilizationcan be almost defined by its serious testing of the limits of tension between \"unaided\" reason andfaithin \"revealed\" truths—figuratively summarized asAthensandJerusalem, respectively.Leo Straussspoke of a \"GreaterWest\" that included all areas under the influence of the tension between Greek rationalism andAbrahamicrevelation, including theMuslimlands. He was particularly influenced by theMuslim philosopherAl-Farabi. To consider to what extentEastern philosophymight have partaken of these important tensions, Strauss thought it best to consider whetherdharmaortaomay be equivalent toNature(physisin Greek). According to Strauss the beginning of philosophy involved the \"discovery or invention of nature\" and the \"pre-philosophical equivalent of nature\" was supplied by \"such notions as 'custom' or 'ways'\", which appear to be really universal in all times and places. The philosophical concept of nature or natures as a way of understandingarchai(first principles of knowledge) brought about a peculiar tension between reasoning on the one hand, and tradition or faith on the other. Scientific research into reasoning is carried out within the fields ofpsychologyandcognitive science. Psychologists attempt to determine whether or not people are capable of rational thought in a number of different circumstances. Assessing how well someone engages in reasoning is the project of determining the extent to which the person isrationalor acts rationally. It is a key research question in thepsychology of reasoningand cognitive science of reasoning.Rationalityis often divided into its respectivetheoretical and practical counterparts. Experimental cognitive psychologists research reasoning behaviour. Such research may focus, for example, on how people perform on tests of reasoning such asintelligenceorIQtests, or on how well people's reasoning matches ideals set by logic (see, for example, theWason test).Experiments examine how people make inferences from conditionals likeif A then Band how they make inferences about alternatives likeA or else B.They test whether people can make valid deductions about spatial and temporal relations likeA is to the left of BorA happens after B, and about quantified assertions likeall the A are B.Experiments investigate how people make inferences about factual situations, hypothetical possibilities, probabilities, andcounterfactualsituations. Developmental psychologists investigate the development of reasoning from birth to adulthood. Piaget'stheory of cognitive developmentwas the first complete theory of reasoning development. Subsequently, several alternative theories were proposed, including theneo-Piagetian theories of cognitive development. The biological functioning of the brain is studied byneurophysiologists,cognitive neuroscientists, andneuropsychologists. This includes research into the structure and function of normally functioning brains, as well as of damaged or otherwise unusual brains. In addition to carrying out research into reasoning, some psychologists—for exampleclinical psychologistsandpsychotherapists—work to alter people's reasoning habits when those habits are unhelpful. Inartificial intelligenceandcomputer science, scientists study and useautomated reasoningfor diverse applications includingautomated theorem provingtheformal semantics of programming languages, andformal specificationinsoftware engineering. Meta-reasoningis reasoning about reasoning. In computer science, a system performs meta-reasoning when reasoning about its operation.This requires a programming language capable ofreflection, the ability to observe and modify its own structure and behaviour. A species could benefit greatly from better abilities to reason about, predict, and understand the world. French social and cognitive scientistsDan Sperberand Hugo Mercier argue that, aside from these benefits, other forces could have been driving the evolution of reason. They point out that reasoning is very difficult for humans to do effectively, and that it is hard for individuals to doubt their own beliefs (confirmation bias). Reasoning is most effective when done as a collective—as demonstrated by the success of projects likescience. They suggest that there are pressures not just individual, butgroup selectionat play. Any group that managed to find ways of reasoning effectively would reap benefits for all its members, increasing theirfitness. This could also help explain why humans, according to Sperber, are not optimized to reason effectively alone. Sperber's & Mercier's argumentative theory of reasoning claims that reason may have more to do with winning arguments than searching for the truth. Aristotlefamously described reason (with language) as a part ofhuman nature, because of which it is best for humans to live \"politically\" meaning in communities of about the size and type of a smallcity state(polisin Greek). For example: It is clear, then, that a human being is more of a political [politikon= of thepolis] animal [zōion] than is any bee or than any of those animals that live in herds. For nature, as we say, makes nothing in vain, and humans are the only animals who possess reasoned speech [logos]. Voice, of course, serves to indicate what is painful and pleasant; that is why it is also found in other animals, because their nature has reached the point where they can perceive what is painful and pleasant and express these to each other. But speech [logos] serves to make plain what is advantageous and harmful and so also what is just and unjust. For it is a peculiarity of humans, in contrast to the other animals, to have perception of good and bad, just and unjust, and the like; and the community in these things makes a household or city [polis].... By nature, then, the drive for such a community exists in everyone, but the first to set one up is responsible for things of very great goodness. For as humans are the best of all animals when perfected, so they are the worst when divorced from law and right. The reason is that injustice is most difficult to deal with when furnished with weapons, and the weapons a human being has are meant by nature to go along with prudence and virtue, but it is only too possible to turn them to contrary uses. Consequently, if a human being lacks virtue, he is the most unholy and savage thing, and when it comes to sex and food, the worst. But justice is something political [to do with thepolis], for right is the arrangement of the political community, and right is discrimination of what is just. If human nature is fixed in this way, we can define what type of community is always best for people. This argument has remained a central argument in all political, ethical, and moral thinking since then, and has become especially controversial since firstlyRousseau's Second Discourse, and secondly, theTheory of Evolution. Already in Aristotle there was an awareness that thepolishad not always existed and had to be invented or developed by humans themselves. The household came first, and the first villages and cities were just extensions of that, with the first cities being run as if they were still families with Kings acting like fathers. Friendshipseems to prevail in man and woman according tonature[kata phusin]; for people are by nature [tēi phusei] pairing more than political [politikon], in as much as the household [oikos] is prior and more necessary than thepolisand making children is more common [koinoteron] with the animals. In the other animals, community [koinōnia] goes no further than this, but people live together [sumoikousin] not only for the sake of making children, but also for the things for life; for from the start the functions [erga] are divided, and are different for man and woman. Thus they supply each other, putting their own into the common [eis to koinon]. It is for these reasons that both utility and pleasure seem to be found in this kind of friendship. Rousseauin his Second Discourse finally took the shocking step of claiming that this traditional account has things in reverse: with reason, language, and rationally organized communities all having developed over a long period of time merely as a result of the fact that some habits of cooperation were found to solve certain types of problems, and that once such cooperation became more important, it forced people to develop increasingly complex cooperation—often only to defend themselves from each other. In other words, according to Rousseau, reason, language, and rational community did not arise because of any conscious decision or plan by humans or gods, nor because of any pre-existing human nature. As a result, he claimed, living together in rationally organized communities like modern humans is a development with many negative aspects compared to the original state of man as an ape. If anything is specifically human in this theory, it is the flexibility and adaptability of humans. This view of the animal origins of distinctive human characteristics later received support fromCharles Darwin'sTheory of Evolution. The two competing theories concerning the origins of reason are relevant to political and ethical thought because, according to the Aristotelian theory, a best way of living together exists independently of historical circumstances. According to Rousseau, we should even doubt that reason, language, and politics are a good thing, as opposed to being simply the best option given the particular course of events that led to today. Rousseau's theory, that human nature is malleable rather than fixed, is often taken to imply (for example byKarl Marx) a wider range of possible ways of living together than traditionally known. However, while Rousseau's initial impact encouraged bloody revolutions against traditional politics, including both theFrench Revolutionand theRussian Revolution, his own conclusions about the best forms of community seem to have been remarkably classical, in favor of city-states such asGeneva, andrural living.", "metadata": {"url": "https://en.wikipedia.org/wiki/Insight_learning", "title": "Reason", "headings": ["Contents", "Etymology and related words", "Philosophical history", "Classical philosophy", "Christian and Islamic philosophy", "Subject-centred reason in early modern philosophy", "Substantive and formal reason", "The critique of reason", "Reason compared to related concepts", "Reason compared to logic", "Reason compared to cause-and-effect thinking, and symbolic thinking", "Reason, imagination, mimesis, and memory", "Logical reasoning methods and argumentation", "Unreasonable decisions and actions", "Traditional problems raised concerning reason", "Reason versus truth, and \"first principles\"", "Reason versus emotion or passion", "Reason versus faith or tradition", "Reason in particular fields of study", "Psychology and cognitive science", "Computer science", "Evolution of reason", "Reason in political philosophy and ethics", "See also", "References", "Further reading"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Reason", "https://en.wikipedia.org/wiki/Reason", "https://en.wikipedia.org/wiki/Reason", "https://en.wikipedia.org/wiki/Reason_(disambiguation)", "https://en.wikipedia.org/wiki/Epistemology", "https://en.wikipedia.org/wiki/Outline_of_epistemology", "https://en.wikipedia.org/wiki/Coherentism", "https://en.wikipedia.org/wiki/Contextualism"]}},
{"id": "653ed0a112fd", "content": "Insoftware engineering,profiling(program profiling,software profiling) is a form ofdynamic program analysisthat measures, for example, the space (memory) or timecomplexity of a program, theusage of particular instructions, or the frequency and duration of function calls.  Most commonly, profiling information serves to aidprogram optimization, and more specifically,performance engineering. Profiling is achieved byinstrumentingeither the programsource codeor its binary executable form using a tool called aprofiler(orcode profiler). Profilers may use a number of different techniques, such as event-based, statistical, instrumented, and simulation methods. Profilers use a wide variety of techniques to collect data, includinghardware interrupts,code instrumentation,instruction set simulation, operating systemhooks, andperformance counters. Program analysis tools are extremely important for understanding program behavior. Computer architects need such tools to evaluate how well programs will perform on newarchitectures. Software writers need tools to analyze their programs and identify critical sections of code.Compilerwriters often use such tools to find out how well theirinstruction schedulingorbranch predictionalgorithm is performing... — ATOM,PLDI The output of a profiler may be: A profiler can be applied to an individual method or at the scale of a module or program, to identify performance bottlenecks by making long-running code obvious.A profiler can be used to understand code from a timing point of view, with the objective of optimizing it to handle various runtime conditionsor various loads.Profiling results can be ingested by a compiler that providesprofile-guided optimization.Profiling results can be used to guide the design and optimization of an individual algorithm; theKrauss matching wildcards algorithmis an example.Profilers are built into someapplication performance managementsystems that aggregate profiling data to provide insight intotransactionworkloads indistributedapplications. Performance-analysis tools existed onIBM/360andIBM/370platforms from the early 1970s, usually based on timer interrupts which recorded theprogram status word(PSW) at set timer-intervals to detect \"hot spots\" in executing code.This was an early example ofsampling(see below). In early 1974instruction-set simulatorspermitted full trace and other performance-monitoring features. Profiler-driven program analysis on Unix dates back to 1973,when Unix systems included a basic tool,prof, which listed each function and how much of program execution time it used. In 1982gprofextended the concept to a completecall graphanalysis. In 1994, Amitabh Srivastava andAlan EustaceofDigital Equipment Corporationpublished a paper describing ATOM(Analysis Tools with OM). The ATOM platform converts a program into its own profiler: atcompile time, it inserts code into the program to be analyzed. That inserted code outputs analysis data. This technique - modifying a program to analyze itself - is known as \"instrumentation\". In 2004 both thegprofand ATOM papers appeared on the list of the 50 most influentialPLDIpapers for the 20-year period ending in 1999. Flat profilers compute the average call times, from the calls, and do not break down the call times based on the callee or the context. Call graphprofilersshow the call times, and frequencies of the functions, and also the call-chains involved based on the callee. In some tools full context is not preserved. Input-sensitive profilersadd a further dimension to flat or call-graph profilers by relating performance measures to features of the input workloads, such as input size or input values. They generate charts that characterize how an application's performance scales as a function of its input. Profilers, which are also programs themselves, analyze target programs by collecting information on the target program's execution. Based on their data granularity, which depends upon how profilers collect information, they are classified asevent-basedorstatisticalprofilers. Profilers interrupt program execution to collect information.  Those interrupts can limit time measurement resolution, which implies that timing results should be taken with a grain of salt.Basic blockprofilers report a number of machineclock cyclesdevoted to executing each line of code, or timing based on adding those together; the timings reported per basic block may not reflect a difference betweencachehits and misses. Event-based profilers are available for the following programming languages: These profilers operate bysampling. A sampling profiler probes the target program'scall stackat regular intervals usingoperating systeminterrupts. Sampling profiles are typically less numerically accurate and specific, providing only a statistical approximation, but allow the target program to run at near full speed. \"The actual amount of error is usually more than one sampling period. In fact, if a value is n times the sampling period, the expected error in it is the square-root of n sampling periods.\" In practice, sampling profilers can often provide a more accurate picture of the target program's execution than other approaches, as they are not as intrusive to the target program and thus don't have as many side effects (such as on memory caches or instruction decoding pipelines). Also since they don't affect the execution speed as much, they can detect issues that would otherwise be hidden. They are also relatively immune to over-evaluating the cost of small, frequently called routines or 'tight' loops. They can show the relative amount of time spent in user mode versus interruptible kernel mode such assystem callprocessing. Unfortunately, running kernel code to handle the interrupts incurs a minor loss of CPU cycles from the target program, diverts cache usage, and cannot distinguish the various tasks occurring in uninterruptible kernel code (microsecond-range activity) from user code. Dedicated hardware can do better: ARM Cortex-M3 and some recent MIPS processors' JTAG interfaces have a PCSAMPLE register, which samples theprogram counterin a truly undetectable manner, allowing non-intrusive collection of a flat profile. Some commonly usedstatistical profilers for Java/managed code areSmartBear Software'sAQtimeandMicrosoft'sCLR Profiler.Those profilers also support native code profiling, along withApple Inc.'sShark(OSX),OProfile(Linux),IntelVTuneand Parallel Amplifier (part ofIntel Parallel Studio), andOraclePerformance Analyzer,among others. This technique effectively adds instructions to the target program to collect the required information. Note thatinstrumentinga program can cause performance changes, and may in some cases lead to inaccurate results and/orheisenbugs.  The effect will depend on what information is being collected, on the level of timing details reported, and on whether basic block profiling is used in conjunction with instrumentation.For example, adding code to count every procedure/routine call will probably have less effect than counting how many times each statement is obeyed.  A few computers have special hardware to collect information; in this case the impact on the program is minimal. Instrumentation is key to determining the level of control and amount of time resolution available to the profilers.", "metadata": {"url": "https://en.wikipedia.org/wiki/Software_performance_analysis", "title": "Profiling (computer programming)", "headings": ["Contents", "Gathering program events", "Use of profilers", "History", "Profiler types based on output", "Flat profiler", "Call-graph profiler", "Input-sensitive profiler", "Data granularity in profiler types", "Event-based profilers", "Statistical profilers", "Instrumentation", "Interpreter instrumentation", "Hypervisor/simulator", "See also", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Profiling_(computer_programming)", "https://en.wikipedia.org/wiki/Profiling_(computer_programming)", "https://en.wikipedia.org/wiki/Profiling_(computer_programming)", "https://en.wikipedia.org/wiki/Software_development", "https://en.wikipedia.org/wiki/Data_modeling", "https://en.wikipedia.org/wiki/Software_development_process", "https://en.wikipedia.org/wiki/Requirements_analysis", "https://en.wikipedia.org/wiki/Software_design"]}},
{"id": "41e4a7eb4b0c", "content": " Since the origin ofvideo gamesin the early 1970s, thevideo game industry, theplayers, andsurrounding culturehave spawned a wide range of technical and slang terms. Alsoisometric graphics. Alsotriple A. Alsobadge,trophy,medal,cheevo. Alsoaim down sights. Alsocontrol stickandthumbstick. A term used in manyrole-playingandstrategygames to describe attacks or other effects that affect multiple targets within a specified area. For example, in the role-playing game,Dungeons & Dragons, a fireballspellwill deal damage to anyone within a certain radius of where it strikes. In most tactical strategy gamesartilleryweapons have an area of effect that will damage anyone within a radius of the strike zone. Often the effect is stronger on the target than on anything else hit. See also:Splash damage Area of effect can also refer to spells and abilities that are non-damaging. For example, a powerful healing spell may affect anyone within a certain range of the caster (often only if they are a member of the caster'sparty). Some games also have what are referred to as \"aura\" abilities that will affect anyone in the area around the person with the ability. For example, many strategy games have hero or officer units that can improve the morale and combat performance of friendly units around them. The inclusion of AoE elements in game mechanics can increase the role of strategy, especially inturn-based games. The player has to place units wisely to mitigate the possibly devastating effects of a hostile area of effect attack; however, placing units in a dense formation could result in gains that outweigh the increased AoE damage received. Alsodisplay modeandshow mode. A pre-recorded demonstration of a video game that is displayed when the game is not being played. Originally built intoarcade games, the main purpose of the attract mode is to entice passers-by to play the game.It usually displays the game'stitle screen, the game's story (if it has one), itshigh scorelist,sweepstakes(on some games) and the message \"Game Over\" or \"Insert Coin\" over or in addition to a computer-controlled demonstration ofgameplay. In theAtari 8-bit computersof the late 1970s and 1980s, the termattract modewas sometimes used to denote a simplescreensaverthat slowly cycled the display colors to preventphosphor burn-inwhen no input had been received for several minutes.Attract modes demonstrating gameplay are common in current home video games. Alsoaim-assist. Alsobunny hopping. Alsobackfilling. Alsoachievement. Alsobanhammer. Alsobeta testing. Alsobuild-order. Alsostory modeandcampaign. Alsocharacter select. Alsoguild Alsoclutching the gameandcoming in clutch. The option to keep playing the game after all of the player'sliveshave been lost, rather than ending the game and restarting from the very beginning. There may or may not be a penalty for doing this, such as losing a certain number of points or being unable to access bonus stages. Inarcade games, when a player loses or fails an objective, they will generally be shown a \"continue countdown\" screen, in which the player has a limited amount of time (usually 10, 15, or 20 seconds) to insert additional coins in order to continue the game from the point where it had ended; deciding not to continue will result in the displaying of agame overscreen. The continue feature was added to arcade games in the early 1980s as a way to earn more money from players.The first arcade game to have a continue feature wasFantasy,and the first home console cartridge to have this feature was the Atari 2600 version ofVanguard.As a result of the continue feature, games started to have stories and definite endings; however, those games were designed so that it would be nearly impossible to get to the end of the game without continuing.Salen and Zimmerman argue that the continue feature in games such asGauntletwas an outlet forconspicuous consumption. Alsocrit. Alsocinematic. Alsocontrol padanddirectional pad. Alsoday zero. Alsoday one. Alsofree-for-all Alsoconversation tree. Alsodowned Alsostick drift. See alsolevel Alsosoftware testingandSoftware release life cycle. Alsoinfinite runner. Alsoelectronic sports,e-sports,eSports,competitive gaming,cybersportsandprofessional gaming. Alsofield of vision. Alsoinvincibility frames,invulnerability period,mercy invincibility. Alsofull perfect combo (FPC). Alsogameplay mechanics. Alsogameplay mode. AlsoBuy-to-play. AlsoLive Service Games. Alsogoated. Also:infinite health,infinite life,invincibility,invulnerability Alsohit points(HP). Alsohi-score. Alsodamage ring. Alsoi-frames. Alsoindependent video game. Alsoheads-up display(HUD). Alsomagic points. Alsomulti-user domain,multi-user dungeon. Alsocross-platform. AlsoCPU. AlsoP2WorPTW. Alsohardcore mode. Alsoplatformer. Alsoragdolling. Alsogamer rage. Alsorerolling Alsoold-school gaming Alsogrenade jumping. Alsogame save,savegame, orsavefile. Alsoside-scroller. Alsosweaty,sweatlord. Alsomeat shield. Alsotunneling. Alsotech tree. The initial screen of acomputer,video, orarcade gameafter the credits and logos of thegame developerandpublisherare displayed. Early title screens often included all thegame optionsavailable (single player, multiplayer, configuration of controls, etc.) while modern games have opted for the title screen to serve as asplash screen. This can be attributed to the use of the title screen as aloading screen, in which to cache all the graphical elements of the main menu. Older computer and video games had relatively simple menu screens that often featuredpre-renderedartwork. Alsowall banging. AlsoStreamer bait Alsozerg rush AlsoCPU vs. CPU", "metadata": {"url": "https://en.wikipedia.org/wiki/Glossary_of_video_game_terms", "title": "Glossary of video game terms", "headings": ["0–9", "A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L", "M", "N", "O", "P", "Q", "R", "S", "T", "U", "V", "W", "X", "Y", "Z", "See also", "References"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Glossary_of_video_game_terms", "https://en.wikipedia.org/wiki/Glossary_of_video_game_terms", "https://en.wikipedia.org/wiki/Glossary_of_video_game_terms", "https://en.wikipedia.org/wiki/Video_game", "https://en.wikipedia.org/wiki/Video_game_industry", "https://en.wikipedia.org/wiki/Gamer", "https://en.wikipedia.org/wiki/Video_game_culture", "https://en.wikipedia.org/wiki/Arcade_video_game"]}},
{"id": "6e2bfef7406f", "content": "Glossary ofUnified Modeling Language(UML)termsprovides a compilation ofterminologyused in all versions ofUML, along with theirdefinitions.  Any notable distinctions that may exist between versions are noted with the individual entry it applies to.           ", "metadata": {"url": "https://en.wikipedia.org/wiki/Glossary_of_Unified_Modeling_Language_terms", "title": "Glossary of Unified Modeling Language terms", "headings": ["A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "L", "M", "N", "O", "P", "Q", "R", "S", "T", "U", "V", "W", "X", "See also", "Sources"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Glossary_of_Unified_Modeling_Language_terms", "https://en.wikipedia.org/wiki/Glossary_of_Unified_Modeling_Language_terms", "https://en.wikipedia.org/wiki/Glossary_of_Unified_Modeling_Language_terms", "https://en.wikipedia.org/wiki/Unified_Modeling_Language", "https://en.wikipedia.org/wiki/Classifier_(UML)", "https://en.wikipedia.org/wiki/Actor_(UML)", "https://en.wikipedia.org/wiki/Class_(computer_science)", "https://en.wikipedia.org/wiki/Use_case"]}},
{"id": "86d4cb4dc10f", "content": " Beijing Zhipu Huazhang Technology Co., Ltd.,branded asZ.ai,  is a Chinese technology company specializing inartificial intelligence(AI). The company was formerly known asZhipu AIuntil its rebranding in 2025. As of 2024, it is one of China's \"AI Tiger\" companies by investors and considered to be the third largestLLMmarket player inChina's AI industryaccording to theInternational Data Corporation.In January 2025, theUnited States Commerce Departmentblacklisted the company in itsEntity Listdue to national security concerns. The startup company began fromTsinghua Universityand was later spun out as an independent company. In 2023, it raised 2.5 billion yuan (approx. 350 million in USD) with the help ofAlibaba GroupandTencent.Other investors of the company includeAnt Group,Meituan,Xiaomi, andHongShan. In May 2024, Prosperity7 Ventures, LLC, a Saudi Arabian finance firm, participated in a 400 million USD financing round for Zhipu AI with a valuation of approximately 3 billion USD. In March 2024, Zhipu AI said that they were developing aSora-like technology to achieveartificial general intelligence(AGI).In July 2024, they debuted their \"Ying\" text-to-video model. AfterOpenAIannounced an API block for their services in some areas beginning in July 2024, Zhipu AI have announced a \"Special Migration Program\" for OpenAI API users. In October 2024, Zhipu AI released GLM-4.0, an open-sourceend-to-end speech large language model. The model can replicate human-like interactions and has the capability to adjust its tone, emotion, or dialect based from user's preference. In July 2025, Zhipu AI released GLM-4.5 and GLM-4.5 Air, their next generation language models which topped several popular benchmarks.Along with the release of their model, the company also rebranded itself as Z.ai.In August 2025, Z.ai announced that their GLM models are compatible withHuawei’s Ascendprocessors.On August 11, 2025, Z.ai released a new vision-language model (VLM) with a total of 106B parameters, GLM-4.5V, achieving SOTA against other open-source VLMs such asAlibaba'sQwen2.5-VLand StepFun's Step-3.In late September 2025, the company released GLM 4.6 using China's domestic chips such as those fromCambricon Technologies. GLM (General Language Model, formerly known as ChatGLM) is a series of pre-trained dialogue models initially developed by Zhipu AI and Tsinghua KEG in 2023. According toNVIDIA, their open-source ChatGLM3-6B in the ChatGLM 3.0 series described it as having \"smooth dialogue and easy deployment\" compared to the first two generations. GLM 4.5, released in July 2025 by Z.ai, is priced at 13% ofDeepSeek's cost and can run at only eightNVIDIA H20chips.The release of GLM 4.6 in late September 2025 marked the first integration of FP8 and Int4 quantization onCambriconchips. It also supports native FP8 onMoore ThreadsGPUs. Debuted in July 2024, Ying is a text-to-video model that can generate image and text prompts into a six-second video clip for around 30 seconds. The service is available at their official website and mobile applications integrated with their ChatGLM chatbot. Released in October 2024, AutoGLM is an AI agent application that uses voice commands to complete tasks within a smartphone. The app can analyze complex tasks such as ordering an item from a nearby store and repeating an order based from the user's shopping history. The app was made as a rival toApple's on-device AI system,Apple Intelligence. The AI tool runs on a series of AI models and chatbots, such as their ChatGLM chatbot, to process the required actions. The company has offices in theMiddle East,United Kingdom,Singapore, andMalaysia. It is also engaged in joint \"innovation center\" projects across Southeast Asia. In January 2025, theUnited States Commerce Departmentadded the company to itsEntity List, citing national security concerns.", "metadata": {"url": "https://en.wikipedia.org/wiki/Z.ai", "title": "Z.ai", "headings": ["Contents", "History", "Products and services", "GLM", "Ying", "AutoGLM", "International presence", "See also", "References", "Notes", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Z.ai", "https://en.wikipedia.org/wiki/Z.ai", "https://en.wikipedia.org/wiki/Z.ai", "https://en.wikipedia.org/wiki/Trade_name", "https://en.wikipedia.org/wiki/Privately_held_company", "https://en.wikipedia.org/wiki/Artificial_intelligence", "https://en.wikipedia.org/wiki/Beijing", "https://en.wikipedia.org/wiki/China"]}},
{"id": "fafd215b462a", "content": "Instatistics, originally ingeostatistics,krigingorKriging(/ˈkriːɡɪŋ/), also known asGaussian process regression, is a method ofinterpolationbased onGaussian processgoverned by priorcovariances. Under suitable assumptions of the prior, kriging gives thebest linear unbiased prediction(BLUP) at unsampled locations.Interpolating methods based on other criteria such assmoothness(e.g.,smoothing spline) may not yield the BLUP. The method is widely used in the domain ofspatial analysisandcomputer experiments. The technique is also known asWiener–Kolmogorov prediction, afterNorbert WienerandAndrey Kolmogorov. The theoretical basis for the method was developed by the French mathematicianGeorges Matheronin 1960, based on the master's thesis ofDanie G. Krige, the pioneering plotter of distance-weighted average gold grades at theWitwatersrandreef complex inSouth Africa. Krige sought to estimate the most likely distribution of gold based on samples from a few boreholes.  The English verb isto krige, and the most common noun iskriging. The word is sometimes capitalized asKrigingin the literature. Though computationally intensive in its basic formulation, kriging can be scaled to larger problems using variousapproximation methods. Kriging predicts the value of a function at a given point by computing a weighted average of the known values of the function in the neighborhood of the point. The method is closely related toregression analysis. Both theories derive abest linear unbiased estimatorbased on assumptions oncovariances, make use ofGauss–Markov theoremto prove independence of the estimate and error, and use very similar formulae. Even so, they are useful in different frameworks: kriging is made for estimation of a single realization of a random field, while regression models are based on multiple observations of a multivariate data set. The kriging estimation may also be seen as asplinein areproducing kernel Hilbert space, with the reproducing kernel given by the covariance function.The difference with the classical kriging approach is provided by the interpretation: while the spline is motivated by a minimum-norm interpolation based on a Hilbert-space structure, kriging is motivated by an expected squared prediction error based on a stochastic model. Kriging withpolynomial trend surfacesis mathematically identical togeneralized least squarespolynomialcurve fitting. Kriging can also be understood as a form ofBayesian optimization.Kriging starts with apriordistributionoverfunctions. This prior takes the form of a Gaussian process:N{\\displaystyle N}samples from a function will benormally distributed, where thecovariancebetween any two samples is the covariance function (orkernel) of the Gaussian process evaluated at the spatial location of two points. Asetof values is then observed, each value associated with a spatial location. Now, a new value can be predicted at any new spatial location by combining the Gaussian prior with a Gaussianlikelihood functionfor each of the observed values. The resultingposteriordistribution is also Gaussian, with a mean and covariance that can be simply computed from the observed values, their variance, and the kernel matrix derived from the prior. In geostatistical models, sampled data are interpreted as the result of a random process. The fact that these models incorporate uncertainty in their conceptualization does not mean that the phenomenon – the forest, the aquifer, the mineral deposit – has resulted  from a random process, but rather it allows one to build a methodological basis for the spatial inference of quantities in unobserved locations and to quantify the uncertainty associated with the estimator. Astochastic processis, in the context of this model, simply a way to approach the set of data collected from the samples. The first step in geostatistical modulation is to create a random process that best describes the set of observed data. A value from locationx1{\\displaystyle x_{1}}(generic denomination of a set ofgeographic coordinates) is interpreted as a realizationz(x1){\\displaystyle z(x_{1})}of therandom variableZ(x1){\\displaystyle Z(x_{1})}. In the spaceA{\\displaystyle A}, where the set of samples is dispersed, there areN{\\displaystyle N}realizations of the random variablesZ(x1),Z(x2),…,Z(xN){\\displaystyle Z(x_{1}),Z(x_{2}),\\ldots ,Z(x_{N})}, correlated between themselves. The set of random variables constitutes a random function, of which only one realization is known – the setz(xi){\\displaystyle z(x_{i})}of observed data. With only one realization of each random variable, it's theoretically impossible to determine anystatistical parameterof the individual variables or the function. The proposed solution in the geostatistical formalism consists inassumingvarious degrees ofstationarityin the random function, in order to make the inference of some statistic values possible. For instance, if one assumes, based on the homogeneity of samples in areaA{\\displaystyle A}where the variable is distributed, the hypothesis that thefirst momentis stationary (i.e. all random variables have the same mean), then one is assuming that the mean can be estimated by the arithmetic mean of sampled values. The hypothesis of stationarity related to thesecond momentis defined in the following way: the correlation between two random variables solely depends on the spatial distance between them and is independent of their location.  Thus ifh=x2−x1{\\displaystyle \\mathbf {h} =x_{2}-x_{1}}andh=|h|{\\displaystyle h=|\\mathbf {h} |}, then: For simplicity, we defineC(xi,xj)=C(Z(xi),Z(xj)){\\displaystyle C(x_{i},x_{j})=C{\\big (}Z(x_{i}),Z(x_{j}){\\big )}}andγ(xi,xj)=γ(Z(xi),Z(xj)){\\displaystyle \\gamma (x_{i},x_{j})=\\gamma {\\big (}Z(x_{i}),Z(x_{j}){\\big )}}. This hypothesis allows one to infer those two measures – thevariogramand thecovariogram: where: In this set,(i,j){\\displaystyle (i,\\;j)}and(j,i){\\displaystyle (j,\\;i)}denote the same element. Generally an \"approximate distance\"h{\\displaystyle h}is used, implemented using a certain tolerance. Spatial inference, or estimation, of a quantityZ:Rn→R{\\displaystyle Z\\colon \\mathbb {R} ^{n}\\to \\mathbb {R} }, at an unobserved locationx0{\\displaystyle x_{0}}, is calculated from a linear combination of the observed valueszi=Z(xi){\\displaystyle z_{i}=Z(x_{i})}and weightswi(x0),i=1,…,N{\\displaystyle w_{i}(x_{0}),\\;i=1,\\ldots ,N}: The weightswi{\\displaystyle w_{i}}are intended to summarize two extremely important procedures in a spatial inference process: When calculating the weightswi{\\displaystyle w_{i}}, there are two objectives in the geostatistical formalism:unbiasandminimal variance of estimation. If the cloud of real valuesZ(x0){\\displaystyle Z(x_{0})}is plotted against the estimated valuesZ^(x0){\\displaystyle {\\hat {Z}}(x_{0})}, the criterion for global unbias,intrinsic stationarityorwide sense stationarityof the field, implies that the mean of the estimations must be equal to mean of the real values. The second criterion says that the mean of the squared deviations(Z^(x)−Z(x)){\\displaystyle {\\big (}{\\hat {Z}}(x)-Z(x){\\big )}}must be minimal, which means that when the cloud of estimated valuesversusthe cloud real values is more disperse, the estimator is more imprecise. Depending on the stochastic properties of the random field and the various degrees of stationarity assumed, different methods for calculating the weights can be deduced, i.e. different types of kriging apply. Classical methods are: The unknown valueZ(x0){\\displaystyle Z(x_{0})}is interpreted as a random variable located inx0{\\displaystyle x_{0}}, as well as the values of neighbors samplesZ(xi),i=1,…,N{\\displaystyle Z(x_{i}),\\ i=1,\\ldots ,N}. The estimatorZ^(x0){\\displaystyle {\\hat {Z}}(x_{0})}is also interpreted as a random variable located inx0{\\displaystyle x_{0}}, a result of the linear combination of variables. Kriging seeks to minimize the mean square value of the following error in estimatingZ(x0){\\displaystyle Z(x_{0})}, subject to lack of bias: The two quality criteria referred to previously can now be expressed in terms of the mean and variance of the new random variableϵ(x0){\\displaystyle \\epsilon (x_{0})}: Since the random function is stationary,E[Z(xi)]=E[Z(x0)]=m{\\displaystyle E[Z(x_{i})]=E[Z(x_{0})]=m}, the weights must sum to 1 in order to ensure that the model is unbiased.  This can be seen as follows: Two estimators can haveE[ϵ(x0)]=0{\\displaystyle E[\\epsilon (x_{0})]=0}, but the dispersion around their mean determines the difference between the quality of estimators. To find an estimator with minimum variance, we need to minimizeE[ϵ(x0)2]{\\displaystyle E[\\epsilon (x_{0})^{2}]}. Seecovariance matrixfor a detailed explanation. where the literals{Varxi,Varx0,Covxix0}{\\displaystyle \\left\\{\\operatorname {Var} _{x_{i}},\\operatorname {Var} _{x_{0}},\\operatorname {Cov} _{x_{i}x_{0}}\\right\\}}stand for Once defined the covariance model orvariogram,C(h){\\displaystyle C(\\mathbf {h} )}orγ(h){\\displaystyle \\gamma (\\mathbf {h} )}, valid in all field of analysis ofZ(x){\\displaystyle Z(x)}, then we can write an expression for the estimation variance of any estimator in function of the covariance between the samples and the covariances between the samples and the point to estimate: Some conclusions can be asserted from this expression. The variance of estimation: Solving this optimization problem (seeLagrange multipliers) results in thekriging system: The additional parameterμ{\\displaystyle \\mu }is aLagrange multiplierused in the minimization of the kriging errorσk2(x){\\displaystyle \\sigma _{k}^{2}(x)}to honor the unbiasedness condition. Simple kriging is mathematically the simplest, but the least general.It assumes theexpectationof therandom fieldis known and relies on acovariance function. However, in most applications neither the expectation nor the covariance are known beforehand. The practical assumptions for the application ofsimple krigingare: The covariance function is a crucial design choice, since it stipulates the properties of the Gaussian process and thereby the behaviour of the model. The covariance function encodes information about, for instance, smoothness and periodicity, which is reflected in the estimate produced. A very common covariance function is the squared exponential, which heavily favours smooth function estimates.For this reason, it can produce poor estimates in many real-world applications, especially when the true underlying function contains discontinuities and rapid changes. Thekriging weightsofsimple kriginghave no unbiasedness condition and are given by thesimple kriging equation system: This is analogous to a linear regression ofZ(x0){\\displaystyle Z(x_{0})}on the otherz1,…,zn{\\displaystyle z_{1},\\ldots ,z_{n}}. The interpolation by simple kriging is given by The kriging error is given by which leads to the generalised least-squares version of theGauss–Markov theorem(Chiles & Delfiner 1999, p. 159): See alsoBayesian Polynomial Chaos Although kriging was developed originally for applications in geostatistics, it is a general method of statistical interpolation and can be applied within any discipline to sampled data from random fields that satisfy the appropriate mathematical assumptions. It can be used where spatially related data has been collected (in 2-D or 3-D) and estimates of \"fill-in\" data are desired in the locations (spatial gaps) between the actual measurements. To date kriging has been used in a variety of disciplines, including the following: Another very important and rapidly growing field of application, inengineering, is the interpolation of data coming out as response variables of deterministic computer simulations,e.g.finite element method(FEM) simulations. In this case, kriging is used as ametamodelingtool, i.e. a black-box model built over a designed set ofcomputer experiments. In many practical engineering problems, such as the design of ametal formingprocess, a single FEM simulation might be several hours or even a few days long. It is therefore more efficient to design and run a limited number of computer simulations, and then use a kriging interpolator to rapidly predict the response in any other design point. Kriging is therefore used very often as a so-calledsurrogate model, implemented insideoptimizationroutines.Kriging-based surrogate models may also be used in the case of mixed integer inputs.", "metadata": {"url": "https://en.wikipedia.org/wiki/Kriging", "title": "Kriging", "headings": ["Contents", "Main principles", "Related terms and techniques", "Geostatistical estimator", "Linear estimation", "Methods", "Ordinary kriging", "Simple kriging", "Bayesian kriging", "Properties", "Applications", "Design and analysis of computer experiments", "See also", "References", "Further reading", "Historical references", "Books"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Kriging", "https://en.wikipedia.org/wiki/Kriging", "https://en.wikipedia.org/wiki/Kriging", "https://en.wikipedia.org/wiki/Credible_interval", "https://en.wikipedia.org/wiki/Statistics", "https://en.wikipedia.org/wiki/Geostatistics", "https://en.wikipedia.org/wiki/Interpolation", "https://en.wikipedia.org/wiki/Gaussian_process"]}},
{"id": "08cd1c386139", "content": " This is an index oflists of virus taxa.", "metadata": {"url": "https://en.wikipedia.org/wiki/List_of_viruses", "title": "Lists of virus taxa", "headings": ["Contents", "By taxonomic rank"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Lists_of_virus_taxa", "https://en.wikipedia.org/wiki/Lists_of_virus_taxa", "https://en.wikipedia.org/wiki/Lists_of_virus_taxa", "https://en.wikipedia.org/wiki/List_of_higher_virus_taxa", "https://en.wikipedia.org/wiki/List_of_virus_families_and_subfamilies", "https://en.wikipedia.org/wiki/List_of_virus_genera"]}},
{"id": "6bb46629a767", "content": " TheBauhaus-Universität Weimaris a university located inWeimar, Germany, and specializes in the artistic and technical fields. Established in 1860 as the Great Ducal Saxon Art School, it gained collegiate status on 3 June 1910. In 1919 the school was renamed Bauhaus by its new directorWalter Gropiusand it received its present name in 1996. There are more than 4000 students enrolled, with the percentage of international students above the national average at around 27%.In 2010 the Bauhaus-Universität Weimar commemorated its 150th anniversary as an art school and college in Weimar. In 2019 the university celebrated the centenary of the founding of the Bauhaus, together with partners all over the world. Weimar boasts a long tradition of art education and instruction in the areas of fine art,handicrafts, music and architecture.\nIn 1776 theWeimar Princely Free Zeichenschulewas established, but gradually lost significance after theGrand Ducal Saxon Art Schoolwas founded in 1860. The Free Zeichenschule was discontinued in 1930.\nIn 1829 the architectClemens Wenzeslaus Coudrayestablished theFree School of Trades(which later became the Grand Ducal Saxon Architectural Trade School, or State School of Architecture), which operated in the evenings and Sundays and supplemented the courses at the Free Zeichenschule. In 1926, the school was incorporated into the Gotha School of Architecture. The Orchestra School, which opened in 1872, eventually became theCollege of Music Franz Lisztin Weimar. The history of the Bauhaus-Universität Weimar goes back to 1860 when Grand DukeCarl Alexander (Saxe-Weimar-Eisenach)founded theGrand Ducal Saxon Art School. Although it became a public institution in 1902, its ties with the ducal house remained strong for years. Students were instructed in a variety of artistic subjects, including landscape, historical, portrait and animal painting, and sculpting. In 1905 the Art School merged with theWeimar Sculpture School, which, although integrated into the educational system in a \"cooperative relationship between high and applied art\",was independently managed. The school was raised to college status in 1910 and was renamed theGrand Ducal Saxon College of Fine Arts. The development of the Bauhaus-Universität Weimar was also strongly influenced by theGrand Ducal Saxon School of Arts and Craftswhich trained artisans in the handicrafts between 1907 and 1915. Both schools issued certificates of participation and conferred diplomas. The names of renowned artists, instructors and students can be found in the historical documents and records of both schools. In 1919 Walter Gropius merged the College of Fine Arts and the School of Arts and Crafts into theStaatliches Bauhausin Weimar. It was the making of a new type of art school, a pioneer of modernity, the legacy of which continues to influence the Bauhaus-University Weimar today. In 1923 Gropius summarized his vision with the radical formula \"Art and Technology – A New Unity.\"His \"concept of collaboration with the industry\"was strongly opposed, not least of all because he was \"determined from the very start to beat down any resistance toward this new kind of architecturally related art.\" The increasing equalization of professors and workshop instructors and unbridgeable differences made it impossible \"for art to develop freely, without purpose and with no connection to architecture at the Bauhaus.\"As a result, the State College of Fine Arts was founded in 1921, an institution at which academically traditional masters could work and teach, such as Richard Engelmann,Max Thedy,Walther Klemm,Alexander OlbrichtandHugo Gugg[de](Hedwig Holtz-Sommer's[de]instructor). The Bauhaus only remained in Weimar until spring 1925 when it was forced to relocate to Dessau for political reasons. There the Bauhaus began a new, important chapter as a college of art and design. UNESCO designated the jointWorld Heritage Sitetitled theBauhaus and its Sites in Weimar, Dessau and Bernauin December 1996. The Bauhaus sites in Weimar that are part of the World Heritage Site are the main building (formerly theGrand Ducal Saxon School of Fine Art) and the Van de Velde building (formerly theGrand Ducal Saxon School of Arts and Crafts) on the Bauhaus University campus, and theHaus am Horn. TheState College of Trades and Architecture, or College of Architecture for short, succeeded theBauhausin 1926, which, since theState School of Architecturehad moved to Gotha, offered its own regular postgraduate courses in Architecture in the form both Van de Velde and Gropius had long envisioned. Although the College of Architecture continued to adhere to the idea of the Bauhaus, it offered a much more practical orientation. This corresponded to the \"concept of a construction-based, productive working community,\" which represented one of the founding principles of this successor institution. The experimental and innovative focus of the Bauhaus fell somewhat to the wayside. In 1929 there were 88 students enrolled at the College of Architecture.After completing their education, graduates received a diploma in the Construction department and the title \"Journeyman\" or \"Master\" in their area of handicraft. Paul Schultze-Naumburg rejected all phenomena of industrial, urban society. He strived to establish a new architectural style that exuded\"Gemütlichkeit\", or coziness. In his opinion, it was necessary to preserve the German styles typical of the region, so that people could find identification and orientation in times of rapid social and cultural upheaval.Graduates of the Architecture course received the title \"Diplom-Architekt\" (certified architect), while artists received a simple certificate and craftspeople received the title \"Journeyman\" or \"Master\". The well-known artists and instructors of this period include:Hermann Giesler, Hans Seytter (e.g.,Stiftskirche, Stuttgart),Walther Klemm, Alexander Olbricht andHugo Gugg[de]. The institution officially attained college-level status in 1942. By this time, theSchool of Tradeshad been removedfrom the college, which now called itself theCollege of Architecture and Fine Arts. After World War II, theSoviet Military Administration of Thuringiaoversaw the restructuring of the college to reflect antifascist-democratic principles. Under the aegis of the architect Hermann Henselmann, appointed director in 1946, the college focused its efforts to rebuild the country and pick up where the Bauhaus left off. Some even suggested changing the name of the college to \"The Bauhaus – College of Architecture and Handicraft and Engineering Design.\" After theGDRwas established and the East German university system was restructured, the college itself underwent major changes in 1951. The \"Fine Arts\" department, which had previously been chaired by the sculptorSiegfried Tschierschky, was dissolved. The newCollege of Architecturewas placed under the control of the \"Ministry of Reconstruction\" with the objective to develop academic and research programs for a new technical college of civil engineering. In 1954 the college received a rectorial constitution with two new faculties: \"Civil Engineering\" and \"Building Materials Science and Technology\". Otto Englberger, an architect, professor of \"Residential and Community Building,\" and provisional director of the college since 1951, was appointed the first vice-chancellor of the newCollege of Architecture and Civil Engineering Weimar(HAB). In the following decades, the college became one of the leading academic institutions in the field of civil engineering, respected throughout East and West Germany alike. Because the college was so integrated in the political system of the GDR, the direction of its instruction and research activities was largely dictated by the government for the purpose of carrying out the latest civil engineering tasks. The third higher education reform of 1968/69 modernized and reorganized the structure of the college based on business administration principles. The faculties were replaced by \"sections\", and the college was expanded to include the section of \"Computer Technology and Data Processing.\" In 1976 research and reception of the Bauhaus was revived at the HAB Weimar. It represented the first step of an ongoing positive re-evaluation of the legacy of the college. Thanks to these research efforts, the college established relations with other institutions, including several in West Germany. Ever since 1951, students in all disciplines were required by East German law to pass a basic study program in Marxist–Leninist philosophy. Later, academic staff, lecturers and professors were also required to complete training on a regular basis. TheInstitute for Marxism–Leninism, which offered these courses at the HAB, was closed in 1990. The well-known artists and instructors of this period include:Walther Klemmand Anita Bach (born 1927, first female professor of architecture in the GDR). The politicalupheavalof 1989 initiated a radical process of restructuring at the college. The goal was to quickly adapt the college to the basic principles of freedom and democracy and integrate it into the international community of higher education institutions. Several changes were made to its overall structure; redundant departments were merged or dissolved. A new chapter began in 1993 with the establishment of the \"Faculty of Art and Design\" which reincorporated the artistic disciplines into the academic profile of the college. The establishment of the \"Faculty of Media\" in 1996 emphasized the college's dedication to progressive thinking. After changing its name to the\"Bauhaus-Universität Weimar\"in 1996, the university demonstrated its dedication to the spirit of the Bauhaus. The well-known artists and instructors of this period include:Lucius Burckhardt,Werner HolzwarthandWolfgang Ernst. The university possesses a unique structure with four main faculties. It has fostered a diverse profile of instruction and research based on engineering and architectural disciplines. Today the university offers students a selection of approximately 40 degree programs. The term \"Bauhaus\" in its name stands for eagerness to experiment, openness, creativity, proximity to industrial practice and internationality. The Faculty of Architecture and Urban Studies sees itself as a universal space for thought and experimentation. The close connection between architecture and urban planning creates the special and contemporary profile. The faculty stands for university-based research and experimental teaching, which imparts interface competencies of artistic and scientific methods in design and planning. It currently has 80 partner universities and is considered one of the most influential architecture faculties in Germany. Student enrolment at the Faculty of Architecture and Urbanism: 1,155 (winter semester 2021/22) Degree programs: Programs for young scientists: The Faculty of Architecture and Urban Studies has its headquarters in the main building, which was designed by Van de Velde and is a UNESCO World Heritage Site. Seminar and studio spaces for students of the faculty are located here. Reflection on heritage shapes the teaching and research of the three institutes at the faculty – even beyond the 100th anniversary of the Bauhaus in 2019: By researching space, city and architecture under changing social boundary conditions, the faculty contributes to the sustainable design of architecture, city and landscape. In exhibitions and symposia, it enters into an exchange with the public. Founded in 1954, the Faculty of Civil Engineering today combines the disciplines of natural sciences and computer science, mechanics, construction, materials, environment and management under one roof. In addition to traditional and modern engineering methods, the faculty also draws from neighboring scientific fields such as law, economics and social sciences. This enables it to assume responsibility throughout the life cycle of the built environment and to participate in its further development. In the area of research, the faculty focuses primarily on future-oriented new technologies such as BIM. The focus of teaching is on project studies. The research profile is largely determined by six institutes: Student enrolment at the Faculty of Civil Engineering (incl. the Digital Engineering program): 998 (winter semester 2021/2022). Furthermore, 285 persons deepen their knowledge in offers of the central continuing education. Degree programs: International Degree Programs: Part-time Master's programs: The Faculty of Art and Design was founded in 1993. It is the university training center for designers and artists in theFree State of Thuringia. With its teaching concept, the \"Weimar Model\", it places the project at the center of studies and thus differs from the classical art academies and studies in fixed class systems. The content of teaching and research at the faculty is the project and design of human living spaces. The focus is on the recognition and promotion of creative forces and the search for possibilities of their practical implementation. Student enrolment at the Faculty of Art and Design: 955 (winter semester 2021/22) Degree programs: International Degree Programs: PhD: The Faculty of Art and Design has been using the studios and classrooms in the former School of Arts and Crafts (Van de Velde Building) since 1996. Following a renovation phase lasting two years, the Faculty of Art and Design returned to the Van de Velde Building in April 2010. In November 2013, the faculty celebrated its 20th anniversary with the festival week.For 23 yearsJay Rutherford, a Canadiangraphic designer, was the professor of Visual Communications. The Faculty of Media is the youngest of the four faculties at Bauhaus-Universität Weimar and is dedicated to researching media challenges of the digital present and future as well as the innovative shaping of media development. In teaching as well as in research, the faculty places humanities-literary culture with scientific-technical culture in a constructive, creative and critical dialogue. It promotes professional and human exchange across the disciplinary boundaries of technology, science and art. Research, research-oriented, project-based teaching and interdisciplinary cooperation characterize the faculty's self-image. It is significantly involved in the two university-wide research focuses Digital Engineering and Cultural Studies Media Research. The Faculty of Media comprises three departments: Media Studies, Media Informatics and Media Management. The study program has a strong international orientation. Several degree programs are offered in English. In addition, the faculty has a German-French study program. Graduates are employed in the cultural and educational sectors, in IT, in media companies and in science and research. Student enrolment at the Faculty of Media (incl. the Digital Engineering program): 758 (winter semester 2021/2022) Degree programs: Department of Media Informatics: International Degree Programs: Department of Media Studies: Department of Media Management: Study Programs: International Degree Programs: Following German reunification, a vacated industrial facility in the vicinity of the historic center of Weimar near the Frauenplan andGoethe's housewas chosen as the site of a new library and lecture hall for the Bauhaus-Universität Weimar. Following an urban planning competition in 1991, the architects' officemeck architekten(Munich) were commissioned to design the building. After a four-year construction phase costing 12 million euros, the new university library and an integrated main auditorium were officially opened in 2005, and in 2006, the building was awarded theThuringian State Prize for Architecture and Urban Planning.", "metadata": {"url": "https://en.wikipedia.org/wiki/Bauhaus_University,_Weimar", "title": "Bauhaus University, Weimar", "headings": ["Contents", "Academic tradition in Weimar", "History of the university", "Art School and School of Arts and Crafts", "Directors of the Art School", "Directors of the Sculpture School", "Directors of the School of Arts and Crafts", "Staatliches Bauhaus", "College of Trades and Architecture", "College of Architecture and Fine Arts", "College of Architecture and Civil Engineering", "Bauhaus-Universität Weimar", "Faculties", "Architecture and Urbanism", "Civil Engineering", "Art and Design", "Media", "University library", "Notable alumni", "References", "Further reading", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Bauhaus_University,_Weimar", "https://en.wikipedia.org/wiki/Bauhaus_University,_Weimar", "https://en.wikipedia.org/wiki/Bauhaus_University,_Weimar", "https://en.wikipedia.org/wiki/Geographic_coordinate_system", "https://en.wikipedia.org/wiki/Bauhaus_(disambiguation)", "https://en.wikipedia.org/wiki/Staatliches_Bauhaus", "https://en.wikipedia.org/wiki/University_president", "https://en.wikipedia.org/wiki/Weimar"]}},
{"id": "dbda25328475", "content": " TheTechnische Universität Ilmenau(Ilmenau University of Technology,TU Ilmenau) is a Germanpublicresearch universitylocated inIlmenau, Thuringia, central Germany. Founded in 1894, it has five academic departments (faculties) with about 4,900 students.Teaching and research are focused on the fields of technology (including computer science), mathematics and natural sciences, business and media. Research and education at the Technische Universität Ilmenau is focused on engineering with strong links to economics andnatural sciences. It is the only university in the federal state ofThüringenwith the title \"Technische Universität\". The university began its life in 1894 as the \"Thüringisches Technikum\", a private training college. This took on the status of \"Hochschule für Elektrotechnik\" (HfE) before becoming a \"Technische Hochschule\" (TH) and in 1992 being accorded the title of \"Technische Universität\" (TU). TU Ilmenau offers degrees in technology, science, economics and media. These all also form part of the interdisciplinary media subjects which are a more recent development and combine technology, economics, law and social studies. The 4,900 students (2021/22) include about 1,700 who come from around 100 nations outside Germany.The courses they take lead to bachelor's and/or master's degrees in which the subjects tend to be drawn from a number of disciplines within the overall groups of engineering, mathematics with science, and economics with social studies. Among the distinguishing features of the TU Ilmenau are personal care for students from professors, tutors and student mentors; a campus with modern buildings only short distances apart; a variety of social activities and social support; many student associations as well as diverse cultural and sports activities. TheFraunhofer Instituteof Digital Media Technology (IDMT) is located near the TU Ilmenau campus. It is well known for their audio processing technology, media compression, and video processing teams. The Department ofElectrical Engineering and Information Technologyhas its roots in the Faculties of Heavy Current Technology and Light Current Technology of the erstwhile engineering college, the \"Hochschule für Elektrotechnik\" (HfE). It comprises four institutes as well as the Inter-Faculty Institute for Materials Technology and is in charge of the following graduate courses of study: Electrical Engineering and Information Technology, Media Technology, Communications and Signal Processing, as well as the further education course of Telecommunications Manager. The inventor of theMP3music encoding formatKarlheinz Brandenburgis one of the professors at this Faculty. The Department ofComputer Science and Automationhas its roots in the Institutes of Control Engineering and Electromedical and Radiological of the HfE as well as in the scientific fields of Engineering Informatics and Computer Engineering of the former TH Ilmenau. This faculty has five institutes including 20 departments and the junior professorship \"Automation Technology\" and is in charge of the course of study of \"Biomedical Engineering\", \"Computer Science\", \"Computer Engineering\" and \"Technical Cybernetics and Systems Theory\". The Department ofMechanical Engineeringwas founded as Faculty of Precision Mechanics and Optics at the HfE. It comprises 19 departments as well as the junior professorship \"Design of mechatronics drives\" and is in charge of the graduate courses of study of Mechanical Engineering, Mechatronics, Automotive Engineering, Optronics, Teacher Training for Vocational School and Materials Science taught at the Inter-Faculty Institute for Materials Technology. Complementary further-education courses offered include Applications of Light and Innovative Engineering Design for Industrial Machinery and Equipment (shared course with theFriedrich-Schiller-Universität Jena). The Department ofMathematics and Natural Sciencehas emerged from the Faculty of Mathematics, Natural Science and Technical Basic Sciences of the HfE. At present, it comprises the Institutes of Mathematics, Physics, Chemistry and Biotechnique as well as Media and Communications. It is in charge of the graduate courses of study of Mathematics, Technical Physics and Applied Media Science. Furthermore, it is responsible for the basic training of the students required for other courses of study in mathematics, physics and chemistry. The Department ofEconomic Sciences and Mediaopened in 1990/91 is the youngest of all faculties at the university. The course of study of Business Informatics has been offered since 1988, and in 1990, the course of study of Industrial Engineering and Management was added. This faculty has four institutes including 15 departments and is in charge of the graduate courses of study of Commercial Information Technology, Industrial Engineering and Management and Media Economics. In the field of further education, it is responsible for the postgraduate course of Economic and Technical Information. Research in Ilmenau is carried out at all stages: theory, application of the theory, prototype testing and transfer to industrial application. Because the TU relies upon interdisciplinary work across faculty boundaries, and brings together many skills thereby, the following highly competitive research activities have been established: The university has a major centre contributing greatly to its research performance, the ZMN, Centre for Micro- and Nanotechnology.\nSo that results achieved in applied research can be transferred rapidly to industrial use, and so that spin-off companies are founded by the university and new partners found for collaborative projects, the university has set up public-private partnerships on new models, with the university taking a seat on the management boards of industrial companies. This concept is underlain by the entities known as \"TU Ilmenau Service GmbH\" and the \"Technologiegesellschaft Thüringen mbH & Co. KG\". The university is actively participating in the restructuring and development of the region (\"Technologieregion Ilmenau-Arnstadt\"). It also contributes to regional planning with its thinking on the encouragement of a high-tech periphery to the campus itself. There is a large number of innovative technological companies which have taken root in the immediate area of the university. With the \"Energietechnisches Zentrum Thüringen\" (Energy Engineering Centre for Thuringia), the TU Ilmenau is also steering its research strategy into energy engineering. Here the intention is to unite the academic strength of the university in energy engineering and management with the interest of other Thuringian enterprises and institutes. In theTimes Higher Education World University Rankingsof 2024, the university is placed at 1001-1200 globally and 49th within the country. The Technische Universität Ilmenau is an active partner in the scientific-technological and economic promotion of the Ilmenau Technological Development Area. In addition to this, it seeks to gain a wider reputation on both a national and international scale. Considering educational export as one its main tasks, the university supports the international exchange of its students and collaborators on the basis of programmes set up for this purpose.The Technische Universität Ilmenau strives to increase the number of foreign students and therefore promotes the cultural education as an important aspect of an ever increasing international competence requested.Every two years the Initiative Solidarische Welt Ilmenau e.V. hosts ISWI (International Student Week Ilmenau) at the TU Ilmenau. It is an international conference for students from all around the world. It aims to foster tolerance, understanding among nations and an international attitude. The TU Ilmenau runs we4you, which is an organization to help and welcome international students in Ilmenau. The university is the most important employer in Ilmenau. It is one of the four universities inThuringia, the others being theUniversity of Erfurt, theBauhaus University of Weimar, and theFriedrich Schiller University of Jena. It is now the most important centre of science in Thuringia, and intensive cooperations with the TU Ilmenau occur.", "metadata": {"url": "https://en.wikipedia.org/wiki/Technische_Universit%C3%A4t_Ilmenau", "title": "Technische Universität Ilmenau", "headings": ["Contents", "Introduction", "Background", "Academics", "Departments", "Department of Electrical Engineering and Information Technology", "Department of Computer Science and Automation", "Department of Mechanical Engineering", "Department of Mathematics and Natural Science", "Department of Economic Sciences and Media", "Research", "Rankings", "National and international networking", "TU Ilmenau in Thuringian scientific and technological culture", "People", "Faculty", "See also", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Technische_Universit%C3%A4t_Ilmenau", "https://en.wikipedia.org/wiki/Technische_Universit%C3%A4t_Ilmenau", "https://en.wikipedia.org/wiki/Technische_Universit%C3%A4t_Ilmenau", "https://en.wikipedia.org/wiki/Geographic_coordinate_system", "https://en.wikipedia.org/wiki/Public_university", "https://en.wikipedia.org/wiki/Ilmenau", "https://en.wikipedia.org/wiki/Thuringia", "https://en.wikipedia.org/wiki/School_colors"]}},
{"id": "2ea12930764b", "content": "Anactive shutter 3D system(a.k.a.alternate frame sequencing,alternate image,AI,alternating field,field sequentialoreclipse method) is a technique for displayingstereoscopic3D images. It works by only presenting the image intended for the left eye while blocking the right eye's view, then presenting the right-eye image while blocking the left eye, and repeating this so rapidly that the interruptions do not interfere with the perceived fusion of the two images into a single 3D image. Modern active shutter 3D systems generally use liquid crystal shutter glasses (also called \"LC shutter glasses\"or \"active shutter glasses\"). Each eye's glass contains aliquid crystallayer which has the property of becoming opaque whenvoltageis applied, being otherwisetransparent. The glasses are controlled by a timing signal that allows the glasses to alternately block one eye, and then the other, in synchronization with therefresh rateof the screen. The timing synchronization to the video equipment may be achieved via a wired signal, or wirelessly by either aninfraredorradio frequency(e.g.Bluetooth, DLP link) transmitter. Historic systems also used spinning discs, for example theTeleviewsystem. Active shutter 3D systems are used to present3D filmsin some theaters, and they can be used to present 3D images onCRT,plasma,LCD, projectors and other types of video displays. Although virtually all ordinary unmodified video and computer systems can be used to display 3D by adding a plug-in interface and active shutter glasses, disturbing levels of flicker or ghosting may be apparent with systems or displays not designed for such use. The rate of alternation required to eliminate noticeable flicker depends on image brightness and other factors, but is typically well over 30 image pair cycles per second, the maximum possible with a 60 Hz display. A 120 Hz display, allowing 60 images per second per eye, is widely accepted as flicker-free. Crosstalk is the leakage of frames between left eye and right eye.LCDs have exhibited this problem more often than plasma and DLP displays, due to slowerpixel response time.  LCDs that utilize a strobe backlight,such as nVidia's LightBoost,reduce crosstalk.  This is done by turning off the backlight between refreshes, while waiting for the shutter glasses to switch eyes, and also for the LCD panel to finish pixel transitions. TheM-3DI Standardwas a cross-manufacturer standardization initiative to increase compatibility ofLC (Active) Shutter Glassesled byPanasonicin collaboration with XpanD 3D and announced in March 2011.It aimed to increase acceptance of 3D products by consumers by extending the agreement to various manufacturers of 3D TV, computers, notebooks, home projectors, and cinema hardware.As of April 2011, the agreement was joined byHitachi,Changhong,Funai,Hisense,Mitsubishi Electric,Epson,ViewSonic, and SIM2 Multimedia S.p.A. In August of the same year, M-3DI was superseded by another agreement, named \"Full HD 3D Glasses Initiative\", formed between Panasonic,Samsung,Sony,Sharp Corporation,TCL Technology,ToshibaandPhilips.The standardization agreement comprised consumer products including televisions, computers and projectors, also based on XpanD 3D's technology. The press release in the announcement said, \"Universal glasses with the new IR/RF protocols will be made available in 2012, and are targeted to be backward compatible with 2011 3D active TVs.\" Field Sequential has been used in video games, VHS and VHD movies and is often referred to as HQFS for DVDs, these systems use wired or wireless LCS glasses. The Sensio format was used with DVDs using wireless LCS glasses. Each different active 3D shutter glasses implementation can operate in their own manufacturer-setfrequencyto match the refresh rate of the display or projector. Therefore, to achieve compatibility across different brands, certain glasses have been developed to be able to adjust to a broad range of frequencies. The principle made its public debut remarkably early. In 1922, theTeleview3-D system was installed in a single theater in New York City. Several short films and one feature-length film were shown by running left-eye and right-eye prints in a pair of interlocked projectors with their shutters operating out of phase. Each seat in the auditorium was equipped with a viewing device containing a rapidly rotating mechanical shutter synchronized with the projector shutters. The system worked, but the expense of the installation and the unwieldiness of the viewers, which had to be supported on adjustable stands, confined its use to this one engagement. In recent decades, the availability of lightweight optoelectronic shutters has led to an updated revival of this display method. Liquid crystal shutter glasses were first invented by Stephen McAllister ofEvans and Sutherland Computer Corporationin the mid-1970s. The prototype had the LCDs mounted to a small cardboard box using duct tape. The glasses were never commercialized due toghosting, but E&S was a very early adopter of third-party glasses such as theStereoGraphicsCrystalEyesin the mid-1980s. Matsushita Electric(now Panasonic) developed a3D televisionthat employed active-shutter technology in the late 1970s. They unveiled the television in 1981, while at the same time adapting the technology for use with the firststereoscopic video game,Sega's arcade gameSubRoc-3D(1982). In 1985, 3DVHDplayers became available in Japan from manufacturers such as Victor (JVC),National(Panasonic), andSharp. Other units were available for field sequential VHS tapes including the Realeyes 3D. A few kits were made available to watch field sequential DVDs. Sensio released their own format which was higher quality than the High Quality Field Sequential (HQFS) DVDs. The method of alternating frames can be used to render modern 3D games intotrue 3D, although a similar method involving alternate fields has been used to give a 3D illusion on consoles as old as theMaster SystemandFamily Computer. Special software or hardware is used to generate two channels of images, offset from each other to create the stereoscopic effect. High frame rates (typically ~100fps) are required to produce seamless graphics, as the perceived frame rate will be half the actual rate (each eye sees only half the total number of frames). Again, LCD shutter glasses synchronized with the graphics chip complete the effect. In 1982,Sega'sarcadevideo gameSubRoc-3Dcame with a special 3D eyepiece,which was a viewer with spinning discs to alternate left and right images to the player's eye from a single monitor.The game's active shutter 3D system was jointly developed by Sega withMatsushita(now Panasonic). In 1984,Milton Bradleyreleased the 3D Imager, a primitive form of active shutter glasses that used a motorized rotating disc with transparencies as physical shutters, for theVectrex. Although bulky and crude, they used the same basic principle of rapidly alternating imagery that modern active shutter glasses still use. Nintendoreleased theFamicom 3D Systemfor theFamicomin October 1987 in Japan, which was an LCD shutter headset, the first home video game electronic device to use LCD Active Shutter glasses. Sega released theSegaScope 3-Dfor theMaster SystemWorldwide in November 1987. Only eight 3D compatible games were ever released. In 1993Pioneerreleased theLaserActivesystem which had a bay for various \"PAC's\" such as the Mega LD PAC and LD-ROM² PAC. The unit was 3D capable with the addition of the LaserActive 3D goggles (GOL-1) and the adapter (ADP-1). While the 3D hardware for these earlier video game systems is almost entirely in the hands of collectors it is still possible to play the games in 3D using emulators, for example using a Sega Dreamcast with a Sega Master System emulator in conjunction with a CRT television and a 3D system like the one found in The Ultimate 3-D Collection. In 1999–2000, a number of companies created stereoscopic LC shutter glasses kits for theWindows PCswhich worked with application and games written forDirect3DandOpenGL3D graphicsAPIs. These kits only worked with CRT computer displays and employed eitherVGA pass-through,VESA Stereoor proprietary interface for left–right synchronization. The most prominent example was the ELSA Revelator glasses, which worked exclusively in Nvidia cards through a proprietary interface based on VESA Stereo. Nvidia later bought the technology and used it in itsstereo driverfor Windows. The glasses kits came with driver software which intercepted API calls and effectively rendering the two views in sequence; this technique required twice the performance from thegraphic card, so a high-end device was needed. Visual glitches were common, as many 3Dgame enginesrelied on 2D effects which were rendered at the incorrect depth, causing disorientation for the viewer. Very few CRT displays were able to support a 120 Hzrefresh rateat common gaming resolutions of the time, so high-end CRT display was required for a flicker-free image; and even with a capable CRT monitor, many users reported flickering and headaches. These CRT kits were entirely incompatible with common LCD monitors which had low 60 Hz or 75 Hz refresh rates, unlike CRT displays that had a higher refresh rate at lower resolutions. Moreover, the display market swiftly shifted to LCD monitors and most display makers ceased production of CRT monitors in early 2000s, which meant that PC glasses kits shortly fell into disuse and were reduced to a very niche market, requiring a purchase of a used high-end, big diagonal CRT monitor. SplitFish EyeFX 3D was a stereo 3D shutter glasses kit for the SonyPlayStation 2released in 2005; it only supported standard-definition CRT TVs. The accessory included a pass-through cable for the PS2 gamepad; when activated, the attached accessory would issue a sequence of rapidly alternating left–right movement commands to the console, producing a kind of \"wiggle stereoscopy\" effect additionally aided by the wired LC shutter glasses which worked in sync with these movements.The kit arrived too late in the product cycle of the console when it was effectively replaced by thePlayStation 3, and only a few games were supported, so it was largely ignored by gamers. The USB-basedNvidia 3D Visionkit released in 2008 supports CRT monitors capable of 100, 110, or 120 Hz refresh rates, as well as 120 Hz LCD monitors. There are many sources of low-cost 3D glasses. IO glasses are the most common glasses in this category.XpanD 3Dis a manufacturer of shutter glasses, with over 1000 cinemas currently using XpanD glasses.With the release of this technology to the home-viewer market as of 2009, many other manufacturers are now developing their own LC shutter glasses, such as Unipolar International Limited, Accupix Co., Ltd,Panasonic,Samsung, andSony. TheM-3DI Standard, announced byPanasonic Corporationtogether withXPAND 3Din March 2011, aims to provide industry-wide compatibility and standardization ofLC (Active) Shutter Glasses. Samsunghas developed active 3D glasses that are 2 ounces (57 g) and utilize lens and frame technology pioneered bySilhouette, who creates glasses forNASA. Nvidiamakes a3D Visionkit for the PC; it comes with 3D shutter glasses, a transmitter, and special graphics driver software. While regular LCD monitors run at 60 Hz, a 120 Hz monitor is required to use 3D Vision. Other well-known providers of active 3D glasses include EStar America and Optoma. Both companies produce 3D Glasses compatible with a variety of technologies, including RF, DLP Link and Bluetooth. In 2007, Texas Instruments introduced stereo 3D capableDLPsolutions to its OEMs,Samsung and Mitsubishi then introduced the first 3D ready DLP televisions, and DLP 3D projectors came later. These solutions utilize the inherent speed advantage of the Digital Micro-mirror Device (DMD) to sequentially generate a high refresh rate for the left and right views required for stereoscopic imaging. DLP 3D technology uses the SmoothPicturewobulationalgorithm and relies on the properties of modern 1080p60 DMD imagers. It effectively compacts two L/R views into a single frame by using acheckerboardpattern, only requiring a standard 1080p60 resolution for stereoscopic transmission to the TV. The claimed advantage of this solution is increased spatial resolution, unlike other methods which cut vertical or horizontal resolution in half. The micromirrors are organized in a so-called \"offset-diamond pixel layout\" of 960×1080 micromirrors, rotated 45 degrees, with their center points placed in the center of \"black\" squares on the checkerboard. The DMD employs full-pixelwobulationto display the complete 1080p image as two half-resolution images in a fast sequence. The DMD operates at twice the refresh rate, i.e. 120 Hz, and the complete 1080p picture is displayed in two steps. On the first cadence, only half of the original 1080p60 image is displayed – the pixels that correspond to the \"black\" squares of the checkerboard pattern. On the second cadence, the DMD array is mechanically shifted (\"wobulated\") by one pixel, so the micromirrors are now in a position previously occupied by the gaps, and another half of the image is displayed – this time, the pixels that correspond to the \"white\" squares. A synchronization signal is then generated to synchronize the screen's refresh with LC shutter glasses worn by the viewer, using Texas Instruments' proprietary mechanism called DLP Link.\nDLP Link keeps sync by embedding briefly-flashed white frames during the display'sblanking interval, which are picked up by the LC shutter glasses. Plasma display panelsare inherently high-speed devices as well, since they usepulse-width modulationto maintain the brightness of individual pixels, making them compatible with sequential method involving shutter glasses. Modern panels feature pixel driving frequency of up to 600 Hz and allow 10-bit to 12-bit color precision with 1024 to 4096 gradations of brightness for each subpixel. Samsung Electronics launched 3D ready PDP TVs in 2008, a \"PAVV Cannes 450\" in Korea and PNAx450 in the UK and the US. The sets utilize the same checkerboard pattern compression scheme as their DLP TVs, though only at the native resolution of 1360×768 pixels and not at HDTV standard 720p, making them only usable with a PC. Matsushita Electric (Panasonic) prototyped the \"3D Full-HD Plasma Theater System\" on CES 2008. The system is a combination of a 103-inchPDP TV, a Blu-ray Disc player andshutter glasses. The new system transmits 1080i60 interlaced images for both right and left eyes, and the video is stored on 50-gigabyte Blu-ray using the MPEG-4 AVC/H.264 compressionMultiview Video Codingextension. Formerly, LCDs were not very suitable for stereoscopic 3D due to slowpixel response time. Liquid crystal displays have traditionally been slow to change from one polarization state to another. Users of early 1990s laptops are familiar with the smearing and blurring that occurs when something moves too fast for the LCD to keep up. LCD technology is not usually rated by frames per second but rather the time it takes to transition from one pixel color value to another pixel color value.  Normally, a 120 Hz refresh is displayed for a full 1/120 second (8.33 milliseconds) due tosample-and-hold, regardless of how quickly an LCD can complete pixel transitions.  Recently, it became possible to hide pixel transitions from being seen, using strobe backlight technology, by turning off the backlight between refreshes,to reduce crosstalk.  Newer LCD televisions, including high-end Sony and Samsung 3D TVs, now utilize astrobed backlightorscanning backlightto reduce 3Dcrosstalkduring shutter glasses operation. Invision therapyofamblyopiaand of intermittent centralsuppression, liquid crystal devices have been used for purposes of enhanced occlusion therapy. In this scenario, the amblyopic patient wears electronically programmable liquid crystal glasses or goggles continuously for several hours during regular everyday activities. Wearing the device encourages or forces the patient to use both eyes alternatingly, similar toeye patching, but rapidly alternating in time. The aim is to circumvent the patient's tendency to suppress the field of view of the weaker eye and to train the patient's capacity forbinocular vision. The goggles mostly feature a much slower flicker rate than the more well-known active shutter 3D glasses.", "metadata": {"url": "https://en.wikipedia.org/wiki/Active_shutter_3D_system", "title": "Active shutter 3D system", "headings": ["Contents", "Advantages and disadvantages", "Advantages", "Disadvantages", "Crosstalk", "Standards", "Timeline", "Games", "Hardware", "Active shutter 3D system providers", "DLP 3D", "Plasma TV", "LCD", "Therapeutic alternating occlusion", "See also", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Active_shutter_3D_system", "https://en.wikipedia.org/wiki/Active_shutter_3D_system", "https://en.wikipedia.org/wiki/Active_shutter_3D_system", "https://en.wikipedia.org/wiki/Stereoscopic", "https://en.wikipedia.org/wiki/Liquid_crystal", "https://en.wikipedia.org/wiki/Voltage", "https://en.wikipedia.org/wiki/Transparency_(optics)", "https://en.wikipedia.org/wiki/Refresh_rate"]}},
{"id": "0714090b046a", "content": "IEEE 1471is a supersededIEEE standardfor describing the architecture of a \"software-intensive system\", also known assoftware architecture. In 2011 it was superseded byISO/IEC/IEEE 42010,Systems and software engineering — Architecture description. IEEE 1471 is the short name for a standard formally known as ANSI/IEEE 1471-2000,Recommended Practice for Architecture Description of Software-Intensive Systems.WithinInstitute of Electrical and Electronics Engineers(IEEE) parlance, this is a \"recommended practice\", the least normative of its standards. In 2007 this standard was adopted byISO/IECJTC1/SC7 asISO/IEC 42010:2007,Systems and Software Engineering -- Recommended practice for architectural description of software-intensive systems. It has long been recognizedthat \"architecture\" has a strong influence over the life cycle of a system. However, until relatively recently,hardware issues have tended to dominate architectural thinking, and software aspects, when considered at all, were often the first to be compromised under the pressures of development.IEEE 1471 was created to provide a basis for thinking about the architecture of software-intensive systems. IEEE 1471's contributions can be summarised as follows  (in this list, items initalicsare terms defined by and used in the standard): IEEE 1471 provides informative annexes that relate its concepts to architecture concepts in other standards, includingRM-ODPandIEEE 12207. In August 1995, the IEEE Software Engineering Standards Committee (SESC) chartered an IEEE Architecture Planning Group (APG)  to set direction for incorporating architectural thinking into IEEE standards. In April 1996, the Architecture Working Group (AWG) was created to implement the recommendations made by APG to the SESC. The AWG was chaired by Basil Sherlund, vice-chairs Ronald Wade, David Emery, the specification was edited by Rich Hilliard. The AWG had 25 members. Drafts of the specification were balloted and commented on by 130 international reviewers. In September 2000, the IEEE-SA Standards Board approved the specification as IEEE Std 1471-2000. In 2006, ISO/IEC Joint Technical Committee 1 (JTC1), Information technology/Subcommittee SC 7, Software and systems engineering, adopted the specification as ISO/IEC 42010, under a special \"fast-track procedure\", in parallel with its approval by national bodies of ISO and IEC. A coordinated revision of this standard by ISO/IEC JTC1/SC7/WG42 and IEEE CS commenced in 2006, following the successful ISO/IEC fast-track ballot and in line with the IEEE standard 5-year review of the standard. In November 2011,IEEE 1471-2000 and ISO/IEC 42010:2007 was superseded byISO/IEC/IEEE 42010:2011,Systems and software engineering — Architecture description. According to IEEE 1471anarchitecture descriptioncan be used for the following: According to IEEE Standard Glossary of Software Engineering Terminologythe following definitions are used: IEEE 1471 uses the following conceptual framework. IEEE 1471defines a set of normative requirements for conforming architecture descriptions, including the following:", "metadata": {"url": "https://en.wikipedia.org/wiki/IEEE_1471", "title": "IEEE 1471", "headings": ["Contents", "Overview", "History", "Purpose", "Terminology", "Conceptual framework", "Conformance", "See also", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/IEEE_1471", "https://en.wikipedia.org/wiki/IEEE_1471", "https://en.wikipedia.org/wiki/IEEE_1471", "https://en.wikipedia.org/wiki/IEEE_Standard", "https://en.wikipedia.org/wiki/Software_architecture", "https://en.wikipedia.org/wiki/ISO/IEC_42010", "https://en.wikipedia.org/wiki/Institute_of_Electrical_and_Electronics_Engineers", "https://en.wikipedia.org/wiki/ISO/IEC"]}},
{"id": "b3b786263513", "content": "ISO/IEC 80000,Quantities and units, is aninternational standarddescribing theInternational System of Quantities(ISQ). It was developed and promulgated jointly by theInternational Organization for Standardization(ISO) and theInternational Electrotechnical Commission(IEC). It serves as a style guide for usingphysical quantitiesandunits of measurement, formulas involving them, and their corresponding units, in scientific and educational documents for worldwide use. The ISO/IEC 80000 family of standards was completed with the publication of the first edition of Part 1 in November 2009. By 2021, ISO/IEC 80000 comprised 13 parts, two of which (parts 6 and 13) were developed by IEC and the remaining 11 were developed by ISO, with a further three parts (15, 16 and, 17) under development. Part 14 was withdrawn. By 2021 the 80000 standard had 13 published parts. A description of each part is available online, with the complete parts for sale. ISO 80000-1:2022 revised ISO 80000-1:2009, which replaced ISO 31-0:1992 and ISO 1000:1992.This document gives general information and definitions concerning quantities, systems of quantities, units, quantity and unit symbols, and coherent unit systems, especially the International System of Quantities (ISQ).The descriptive text of this part is available online. According to the standard, symbols for quantities are \"generally single letters from the Latin or Greek alphabet\" and are \"written in italic (sloping) type\". Examples include ISO 80000-2:2019 revised ISO 80000-2:2009,which supersededISO 31-11.It specifies mathematical symbols, explains their meanings, and gives verbal equivalents and applications. The descriptive text of this part is available online. ISO 80000-3:2019 revised ISO 80000-3:2006,which supersedesISO 31-1andISO 31-2.It gives names, symbols, definitions and units for quantities of space and time. The descriptive text of this part is available online. A definition of thedecibel, included in the original 2006 publication, was omitted in the 2019 revision, leaving ISO/IEC 80000 without a definition of this unit; a new part of the standard, IEC 80000-15 (Logarithmic and related quantities), is under development. ISO 80000-4:2019 revised ISO 80000-4:2006,which supersededISO 31-3.It gives names, symbols, definitions and units for quantities of mechanics. The descriptive text of this part is available online. ISO 80000-5:2019 revised ISO 80000-5:2007,which supersededISO 31-4.It gives names, symbols, definitions and units for quantities ofthermodynamics. The descriptive text of this part is available online. IEC 80000-6:2022 revised IEC 80000-6:2008,which supersededISO 31-5as well as IEC 60027-1. It gives names, symbols, and definitions for quantities and units ofelectromagnetism. The descriptive text of this part is available online. ISO 80000-7:2019 revised ISO 80000-7:2008,which supersededISO 31-6.It gives names, symbols, definitions and units for quantities used forlightandoptical radiationin thewavelengthrange of approximately 1 nm to 1 mm. The descriptive text of this part is available online. ISO 80000-8:2020 revised ISO 80000-8:2007,which revised ISO 31-7:1992.It gives names, symbols, definitions, and units for quantities ofacoustics. The descriptive text of this part is available online. It has a foreword, scope introduction, scope, normative references (of which there are none), as well as terms, and definitions. It includes definitions ofsound pressure,sound power, andsound exposure, and their correspondinglevels:sound pressure level,sound power level, andsound exposure level. It includes definitions of the following quantities: IEC 80000-13:2025 revised IEC 80000-13:2008, which replaced subclauses 3.8 and 3.9 of IEC 60027-2:2005 andIEC 60027-3.It defines quantities and units used ininformation scienceandinformation technology, and specifies names and symbols for these quantities and units. It has a scope; normative references; names, definitions, and symbols; and prefixes forbinarymultiples. Quantities defined in this standard are: The standard also includes definitions for units relating to information technology, such as theerlang(E),bit(bit),octet(o),byte(B),baud(Bd),shannon(Sh),hartley(Hart), and thenatural unit of information(nat). Clause 4 of the standard defines standardbinary prefixesused to denote powers of 1024 as 1024(kibi-), 1024(mebi-), 1024(gibi-), 1024(tebi-), 1024(pebi-), 1024(exbi-), 1024(zebi-), 1024(yobi-), 1024(robi-), and 1024(quebi-). Part 1 of ISO 80000 introduces the International System of Quantities and describes its relationship with theInternational System of Units(SI). Specifically, its introduction states \"The system of quantities, including the relations among the quantities used as the basis of the units of the SI, is named theInternational System of Quantities, denoted 'ISQ', in all languages.\" It further clarifies that \"ISQ is simply a convenient notation to assign to the essentially infinite and continually evolving and expanding system of quantities and equations on which all of modern science and technology rests. ISQ is a shorthand notation for the 'system of quantities on which the SI is based'.\" The standard includes all SI units but is not limited to only SI units. Units that form part of the standard but not the SI include the units of information storage (bitandbyte), units ofentropy(shannon,natural unit of informationandhartley), and theerlang(a unit of traffic intensity).", "metadata": {"url": "https://en.wikipedia.org/wiki/ISO/IEC_80000", "title": "ISO/IEC 80000", "headings": ["Contents", "Overview", "Subject areas", "Part 1: General", "Part 2: Mathematics", "Part 3: Space and time", "Part 4: Mechanics", "Part 5: Thermodynamics", "Part 6: Electromagnetism", "Part 7: Light and radiation", "Part 8: Acoustics", "Part 13: Information science and technology", "International System of Quantities", "Units of the ISO and IEC 80000 series", "See also", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/ISO/IEC_80000", "https://en.wikipedia.org/wiki/ISO/IEC_80000", "https://en.wikipedia.org/wiki/ISO/IEC_80000", "https://en.wikipedia.org/wiki/International_standard", "https://en.wikipedia.org/wiki/International_System_of_Quantities", "https://en.wikipedia.org/wiki/International_Organization_for_Standardization", "https://en.wikipedia.org/wiki/International_Electrotechnical_Commission", "https://en.wikipedia.org/wiki/Physical_quantities"]}},
{"id": "b99c4661d451", "content": "Lee Galloway(November 29, 1871 – January 31, 1962)was an Americaneducator,publisher, andorganizational theorist.He was Professor in the School of Finance and Commerce at theNew York University, and co-founders ofThe National Association of Corporation Schools,predecessor of theAmerican Management Association. Charles Lee Galloway was born inDurand, Wisconsinin 1871, son of William D. Galloway and Ellen (Laskey) Galloway, natives respectively of Canada and England. He obtained his BSc at theUniversity of Minnesotain 1896, his MA fromColumbia Universityin 1900, and his PhD from theNew York Universityin 1907. For his graduate work Galloway had spent some time in European Universities, and was visiting scholar with the British economic historianSir William Ashleyat the University of Birmingham, and with the German economistJohannes Conradat the University of Halle. After his graduation at the University of Minnesota in 1896, Galloway had started his working life as school teacher in Minnesota. From 1901 to 1905 he was assistant principal at a high school in Minneapolis and served as superintendent of city schools atSouth St. PaulandTwo Harbors. After his graduation at the New York University in 1907, Galloway joined their faculty.By 1911 he was Assistant Professor of Commerce and Industry in the New York University School of Commerce, nowNew York University Stern School of Business.In 1918 he was appointed Professor of Commerce and Industry, and in 1919 head of its department of business management. In 1920 he founded and became director of the school of retailing financed by the leading department stores of New York City. In 1912 Galloway had entered the publishing business. He became chairman of the board of The Ronald Press Company, and editor-in-chief. He was consulting editor for a seriesDepartment Store Merchandise Manualsat Ronald Press in 1917, editor of theAdministration Magazineand member of the Advisory Council of theJournal of Business. In 1912-13 Galloway andFrederick C. Henderschotthad played a pioneering role in the establishing ofThe National Association of Corporation Schools, where both continued to participate in executive roles. Galloway married June 8, 1900 to Hetty G. Buehler, daughter of William G. Buehler of Minneapolis.She had graduated from the University of Minnesota in 1899. TheNew York Universityin 1914 introduced its first course inindustrial managementin a new industrial engineering program. It introduced lesson inFactory Organizationand inSystem  and Organization in Commercial Business,about the implications ofscientific managementfor office and service activities. Nelson (1992) summarized. that in 1916 the New York University: Galloway in 1921 published his standard workOffice Management, Its Principles and Practice,which would become a well-known book inoffice management.", "metadata": {"url": "https://en.wikipedia.org/wiki/Lee_Galloway", "title": "Lee Galloway", "headings": ["Contents", "Biography", "Youth, education and early career", "Further career in education and publishing", "Personal", "Work", "Management Department at New York University", "Selected publications", "References"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Lee_Galloway", "https://en.wikipedia.org/wiki/Lee_Galloway", "https://en.wikipedia.org/wiki/Lee_Galloway", "https://en.wikipedia.org/wiki/Educator", "https://en.wikipedia.org/wiki/Publisher", "https://en.wikipedia.org/wiki/Organizational_theorist", "https://en.wikipedia.org/wiki/New_York_University", "https://en.wikipedia.org/wiki/The_National_Association_of_Corporation_Schools"]}},
{"id": "9d0b0cbf1e76", "content": " Google Scholaris a freely accessibleweb search enginethat indexes the full text ormetadataofscholarly literatureacross an array of publishing formats and disciplines. Released inbetain November 2004, the Google Scholar index includespeer-reviewedonlineacademic journalsand books, conference papers,thesesanddissertations,preprints,abstracts,technical reports, and other scholarly literature, includingcourt opinionsandpatents. Google Scholar uses a web crawler, or web robot, to identify files for inclusion in the search results.For content to be indexed in Google Scholar, it must meet certain specified criteria.An earlier statistical estimate published inPLOS Oneusing amark and recapturemethod estimated approximately 79–90% coverage of all articles published in English with an estimate of 100 million.This estimate also determined how many online documents were available. Google Scholar has been criticized for not vetting journals and for includingpredatory journalsin its index. The University of Michigan Library and other libraries whose collections Google scanned forGoogle Booksand Google Scholar retained copies of the scans and have used them to create theHathiTrust Digital Library. Google Scholar arose out of a discussion between Alex Verstak andAnurag Acharya,both of whom were then working on building Google's main web index.Their goal was to \"make the world's problem solvers 10% more efficient\"by allowing easier and more accurate access to scientific knowledge. This goal is reflected in the Google Scholar's advertising slogan \"Stand on the shoulders of giants\", which was taken from an idea attributed toBernard of Chartres,quoted by Isaac Newton, and is a nod to the scholars who have contributed to their fields over the centuries, providing the foundation for new intellectual achievements.One of the sources for the texts in Google Scholar is the University of Michigan's print collection. Scholars have gained a range of features over time. In 2006, a citation importing feature was implemented supportingbibliography managers, such asRefWorks,RefMan,EndNote, andBibTeX. In 2007, Acharya announced that Google Scholar had started a program to digitize and host journal articles in agreement with their publishers, an effort separate fromGoogle Books, whose scans of older journals do not include the metadata required for identifying specific articles in specific issues.In 2011,Googleremoved Scholar from the toolbars on its search pages,making it both less easily accessible and less discoverable for users not already aware of its existence. Around this period, sites with similar features such asCiteSeer,Scirus, and MicrosoftWindows Live Academicsearch were developed. Some of these are now defunct; in 2016, Microsoft launched a new competitor,Microsoft Academic. A major enhancement was rolled out in 2012, with the possibility for individual scholars to create personal \"Scholar Citations profiles\".A feature introduced in November 2013 allows logged-in users to save search results into the \"Google Scholar library\", a personal collection which the user can search separately and organize by tags.Via the \"metrics\" button, it reveals the top journals in a field of interest, and the articles generating these journal's impact can also be accessed. A metrics feature now supports viewing the impact of whole fields of science and academic journals.Google also included profiles for some posthumous academics, includingAlbert EinsteinandRichard Feynman.For several years, the profile forIsaac Newtonindicated he was as a \"professor atMIT\", with a \"verified email at mit.edu\". Google Scholar allows users to search for digital or physical copies of articles, whether online or in libraries.It indexes \"full-text journal articles, technical reports, preprints,theses, books, and other documents, including selected Web pages that are deemed to be 'scholarly.'\"Because many of Google Scholar's search results link to commercial journal articles, most people will be able to access only an abstract and the citation details of an article, and have to pay a fee to access the entire article.The most relevant results for the searched keywords will be listed first, in order of the author's ranking, the number of references that are linked to it and their relevance to other scholarly literature, and the ranking of the publication that the article appears in. Using its \"group of\" feature, it shows the available links to journal articles. In the 2005 version, this feature provided a link to both subscription-access versions of an article and to free full-text versions of articles; for most of 2006, it provided links to only the publishers' versions. Since December 2006, it has provided links to both published versions and major open accessrepositories, including all those posted on individual faculty web pages and other unstructured sources identified by similarity. On the other hand, Google Scholar does not allow to filter explicitly betweentoll accessandopen accessresources, a feature offeredUnpaywalland the tools which embed its data, such asWeb of Science,ScopusandUnpaywall Journals, used by libraries to calculate the real costs and value of their collections. Through its \"cited by\" feature, Google Scholar provides access to abstracts of articles that have cited the article being viewed.It is this feature in particular that provides thecitation indexingpreviously only found inCiteSeer,Scopus, andWeb of Science. Google Scholar also provides links so that citations can be either copied in various formats or imported into user-chosenreference managerssuch asZotero. \"Scholar Citations profiles\" are public author profiles that are editable by authors themselves.Individuals, logging on through a Google account with a bona fide address usually linked to an academic institution, can now create their own page giving their fields of interest and citations. Google Scholar automatically calculates and displays the individual's total citation count,h-index, andi10-index. According to Google, \"three-quarters of Scholar search results pages ... show links to the authors' public profiles\" as of August 2014. Through its \"Related articles\" feature, Google Scholar presents a list of closely related articles, ranked primarily by how similar these articles are to the original result, but also taking into account the relevance of each paper. Google Scholar's legal database of US cases is extensive. Users can search and read published opinions of US state appellate and supreme court cases since 1950, US federal district, appellate, tax, and bankruptcy courts since 1923 and US Supreme Court cases since 1791.Google Scholar embeds clickable citation links within the case and the How Cited tab allows lawyers to research prior case law and the subsequent citations to the court decision. While mostacademic databases and search enginesallow users to select one factor (e.g. relevance, citation counts, or publication date) to rank results, Google Scholar ranks results with a combined ranking algorithm in a \"way researchers do, weighing the full text of each article, the author, the publication in which the article appears, and how often the piece has been cited in other scholarly literature\".Research has shown that Google Scholar puts high weight especially oncitation counts,as well as words included in a document's title.In searches by author or year, the first search results are often highly cited articles, as the number of citations is highly determinant, whereas in keyword searches the number of citations is probably the factor with the most weight, but other factors also participate. Some searchers found Google Scholar to be of comparable quality and utility to subscription-based databases when looking at citations of articles in some specific journals.The reviews recognize that its \"cited by\" feature in particular poses serious competition toScopusandWeb of Science. A study looking at the biomedical field found citation information in Google Scholar to be \"sometimes inadequate, and less often updated\".The coverage of Google Scholar may vary by discipline compared to other general databases.Google Scholar strives to include as many journals as possible, includingpredatory journals, which may lack academic rigor. Specialists on predatory journals say that these kinds of journals \"have polluted the global scientific record with pseudo-science\" and \"that Google Scholar dutifully and perhaps blindly includes in its central index.\" Google Scholar does not publish a list of journals crawled or publishers included, and the frequency of its updates is uncertain.Bibliometricevidence suggests Google Scholar's coverage of the sciences and social sciences is competitive with other academic databases; as of 2017, Scholar's coverage of the arts and humanities has not been investigated empirically and Scholar's utility for disciplines in these fields remains ambiguous.Especially early on, some publishers did not allow Scholar to crawl their journals.Elsevierjournals have been included since mid-2007, when Elsevier began to make most of itsScienceDirectcontent available to Google Scholar and Google's web search.However, a 2014 studyestimates that Google Scholar can find almost 90% (approximately 100 million) of all scholarly documents on the Web written in English. Large-scale longitudinal studies have found between 40 and 60 percent of scientific articles are available in full text via Google Scholar links. Google Scholar puts high weight on citation counts in its ranking algorithm and therefore is being criticized for strengthening theMatthew effect;as highly cited papers appear in top positions they gain more citations while new papers hardly appear in top positions and therefore get less attention by the users of Google Scholar and hence fewer citations. Google Scholar effect is a phenomenon when some researchers pick and cite works appearing in the top results on Google Scholar regardless of their contribution to the citing publication because they automatically assume these works' credibility and believe that editors, reviewers, and readers expect to see these citations.Google Scholar has problems identifying publications on thearXivpreprint server correctly. Interpunctuation characters in titles produce wrong search results, and authors are assigned to wrong papers, which leads to erroneous additional search results. Some search results are even given without any comprehensible reason. Google Scholar is vulnerable tospam.Researchers from theUniversity of California, BerkeleyandOtto-von-Guericke University Magdeburgdemonstrated that citation counts on Google Scholar can be manipulated and complete non-sense articles created withSCIgenwere indexed within Google Scholar.These researchers concluded that citation counts from Google Scholar should be used with care, especially when used to calculate performance metrics such as theh-indexorimpact factor, which is in itself a poor predictor of article quality.Google Scholar started computing an h-index in 2012 with the advent of individual Scholar pages. Several downstream packages likeHarzing's Publish or Perishalso use its data.The practicality of manipulating h-index calculators byspoofingGoogle Scholar was demonstrated in 2010 by Cyril Labbe fromJoseph Fourier University, who managed to rank \"Ike Antkare\" ahead ofAlbert Einsteinby means of a large set ofSCIgen-produced documents citing each other (effectively an academiclink farm).As of 2010, Google Scholar was not able toshepardizecase law, asLexiscould.Unlike other indexes of academic work such asScopusandWeb of Science, Google Scholar does not maintain anApplication Programming Interfacethat may be used to automate data retrieval. Use of web scrapers to obtain the contents of search results is also severely restricted by the implementation of CAPTCHAs. Google Scholar does not display or exportDigital Object Identifiers(DOIs),ade factostandard implemented by all major academic publishers to uniquely identify and refer to individual pieces of academic work.In 2024, researchers found that Google Scholar was manipulatable through citation-purchasing services. Search engine optimization(SEO) for traditional web search engines such asGooglehas been popular for many years. For several years, SEO has also been applied to academic search engines such as Google Scholar.SEO foracademic articlesis also called \"academic search engine optimization\" (ASEO) and defined as \"the creation, publication, and modification of scholarly literature in a way that makes it easier for academic search engines to both crawl it and index it\".ASEO has been adopted by several organizations, among themElsevier,OpenScience,Mendeley,andSAGE Publishing,to optimize their articles' rankings in Google Scholar. ASEO has been criticised for allowing journals to artificially inflate their metrics and introducing spam into academic search engines.", "metadata": {"url": "https://en.wikipedia.org/wiki/Google_Scholar", "title": "Google Scholar", "headings": ["Contents", "History", "Features and specifications", "Groups and access to literature", "Citation analysis and tools", "Related articles", "US legal case database", "Ranking algorithm", "Limitations and criticism", "Search engine optimization for Google Scholar", "See also", "References", "Further reading", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Google_Scholar", "https://en.wikipedia.org/wiki/Google_Scholar", "https://en.wikipedia.org/wiki/Google_Scholar", "https://en.wikipedia.org/wiki/Bibliographic_database", "https://en.wikipedia.org/wiki/Google", "https://en.wikipedia.org/wiki/Web_search_engine", "https://en.wikipedia.org/wiki/Metadata", "https://en.wikipedia.org/wiki/Academic_publishing"]}},
{"id": "2f9351969e58", "content": "Historically in Maldives the children aged three and up in theMaldiveswere educated in traditional schools known as \"Kiyavaage\" or \"Edhurge\",generally using a single large room or the shelter of tree. The children learned simple arithmetic,Dhivehiand some Arabic, and practised reciting theQur'an.These private schools no longer exist, as western style schools replaced them in the 1980s–1990s. The first western-style school in the Maldives isMajeediyya School, a secondary established in 1927.The school was originally co-educational, but it was felt necessary to create a second school for girls (Aminiya School) in 1944. Based on a study by educational advisors fromUNESCO, the Government of Maldives began implementation of the Educational Development Project on 6 October 1976. This Project constituted a comprehensive programme of educational development comprising Expansion of Primary Education, Teacher Training, Curriculum Development, Educational Radio, Community Education Programme for Adult Education and Textbook Development and Printing. The first school under this project was opened inBaa AtollEydhafushiin March 1978 followed by another two inN.ManadhooandHDh.Kulhudhuffushiin March 1979. School construction was continued in all atolls and was later complemented by Primary Schools construction project by Japan. Curriculum Development began in 1976, while Teacher Training began in 1977. Simultaneously, other programmes were introduced and continued through the 1970s and until the mid-1980s from where on the First Ten Year Master Plan for Educational (1986–1995) began implementation. Second Master Plan was implemented 1996–2005. These were the bases of educational development in the Maldives begun by the government ofPresident Nasircontinued byPresident Gayoom. As of 2002, the President's Office claimed that universal primary education has almost been achieved and the literacy rate had improved from 70 per cent in 1978 to 98.82 per cent. In 2005, there were 106,220 students in schools, or 40% of the total population. A National University Act was passed in January 2011 to establish the first university in the Maldives.Institutions offering higher education in the Maldives are:", "metadata": {"url": "https://en.wikipedia.org/wiki/Education_in_Maldives", "title": "Education in the Maldives", "headings": ["Contents", "Higher education", "See also", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Education_in_the_Maldives", "https://en.wikipedia.org/wiki/Education_in_the_Maldives", "https://en.wikipedia.org/wiki/Education_in_the_Maldives", "https://en.wikipedia.org/wiki/Maldives", "https://en.wikipedia.org/wiki/Dhivehi_language", "https://en.wikipedia.org/wiki/Qur%27an", "https://en.wikipedia.org/wiki/Majeediyya_School", "https://en.wikipedia.org/wiki/Aminiya_School"]}},
{"id": "372ab4b48791", "content": "Poitier Meets Platois an album recorded by Warner Bros. Records and published by Jackie Barnett. The actorSidney Poitierrecites excerpts fromPlato's works over music composed and conducted byFred Katz. The passages were arranged and selected by Henry L. Drake. (Side 1) 1. \"The Philosopher-King Must Rule\" 2. \"This I Know-That I Know Nothing\" 3. \"Contribution of Music and Gymnastics\" 4. \"Immortality of the Soul\" 5. \"The Greeks Had a Word for it\" (Side 2) 6. \"Our World a Cave\" 7. \"Woman's Place in Society\" 8. \"Discovery of the Good Life\" 9. \"Only the Wise are Brave\" 10. \"The Penalty is Death\"", "metadata": {"url": "https://en.wikipedia.org/wiki/Poitier_Meets_Plato", "title": "Poitier Meets Plato", "headings": ["Contents", "Track listing", "References"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Poitier_Meets_Plato", "https://en.wikipedia.org/wiki/Poitier_Meets_Plato", "https://en.wikipedia.org/wiki/Poitier_Meets_Plato", "https://en.wikipedia.org/wiki/Album", "https://en.wikipedia.org/wiki/Sidney_Poitier", "https://en.wikipedia.org/wiki/Music_genre", "https://en.wikipedia.org/wiki/Jazz", "https://en.wikipedia.org/wiki/Spoken_Word"]}},
{"id": "e90c3d3bac6d", "content": "\"Plato's Dream\" (original French title \"Songe de Platon\") is a 1756short storywritten in the 18th century by the FrenchphilosopherandsatiristVoltaire. Along with his 1752 novellaMicromégas, \"Plato's Dream\" is among the first modern works in thegenreofscience fiction. \"Plato's Dream\" is a pointed philosophical criticism of religious doctrine, told as adreamcontained within the framework of a famous (and religiously tolerated) personality ofantiquity,Plato. Voltaire's story recounts a dream attributed to the renowned Greek philosopher, whereinDemiurgos, agod-like entity referred to as the \"eternal geometer\", appoints to a number of \"lesser superbeings\" the task of creating their own worlds.Demogorgonassumes responsibility for the creation ofEarth, and is at first quite pleased with his creation, believing that he had \"silenced Envy herself\".That is to say, Demogorgon was so convinced of the perfection of his creation, critics and naysayers would be rendered speechless. Much to his dismay, Demogorgon found his eminently imperfect handiwork to be the subject of ridicule by the other beings. Specifically, their onslaught of criticisms targeted the disproportionate ratio of good to evil, arguing that if his planet truly is as good as he claimed, its inhabitants would not be plagued by so much suffering. The story draws to a close amidst a quarrel among the superbeings, who mock each other's haphazard attempts at creating their own planet. Demiurgos hushes the quarrel, ironically proclaiming: \"It belongs to me alone to create things perfect and immortal\". To which Demogorgon replies, \"Us, for example?\" This exchange satirizes the idea of the perfect, harmonious universe put forth by many religious doctrines. Some of the most notable ancient Greek philosophers (Socrates,Plato, andAristotle) significantly shaped the later ideas and writings propounded by French Enlightenment thinkers. The Enlightenment, which aimed to depart from various aspects of religious doctrine such as \"superstition, enthusiasm, fanaticism, and supernaturalism\", was driven by thephilosophes.Thephilosophes,one of whom was Voltaire, aimed to further intellectual spheres by promoting reason, science, and rationalism as the foundations of knowledge. Socrates, who is widely regarded as the very embodiment of these ideals, was venerated by French Enlightenment philosophers. In fact, Voltaire's contemporaries often likened him to the Socrates of their time, with many others tempted to adopt the same label.Such a desire may be observed in the writings ofDenis Diderot, who penned in a manuscript: \"'As he faced death, Socrates was regarded in Athens as we are today in Paris ... My dear friends, may we in every way be like Socrates, just as his reputation resembled ours at the hour of his death.'\" Voltaire, however, was not nearly as outspoken. Voltaire's attitude towards Socrates may only be inferred from his writings, where Socrates was frequently a subject of discussion.Russel Goulbourne attempts to dissect this ambiguity in his bookSocrates from Antiquity to Enlightenment. He is particularly drawn to an excerpt from a letter written by Voltaire in 1737 who, the year prior, was gifted a gold bust of Socrates by the crown prince of Prussia: \"This present has prompted me to reread everything Plato says about Socrates,\"Moreover, Socrates was the subject of a comedy written by Voltaire, aptly namedSocrate. At surface value, this might suggest that, like Diderot, Voltaire revered Socrates; however, many historians would suggest that he was actually quite ambivalent about him. According to Goulbourne, Voltaire's rereading of Plato—specifically the Platonic dialogues—informed his perspectives on religion.However, that is not to suggest that Voltaire was particularly fond of Plato's work; quite the contrary, he, among many otherphilosophes, considered Plato asophist.Platonism at this time was widely regarded as \"a religion that men professed from its establishment, without interruption, until lately\" (trans.)That is to say, Plato's philosophy reaffirmed the hierarchical structures established by religion by suggesting that philosophical inquiry should be reserved to those capable of understanding it.This stance ran contrary to Enlightenment ideals and was therefore shunned by many. Voltaire was among those who disapproved of Platonism, criticizing Plato's \"inintelligibility\" and 'galimathias' as significant pitfalls.He rejected the obscurity and \"inintelligibility\" contained within some of Plato's most notable works, particularlyTimaeus(which inspired \"Plato's Dream\") and theRepublic, for their complicated metaphysical teachings. He viewed the foundations of Platonism as \"hubristic\" and convoluted. \"Plato's Dream\" is a critical philosophical exploration of religion and its core teachings. While not explicitly stated, Voltaire himself was highly critical ofChristianity(more specifically, authority figures within the church),a stance evident in his seminal work,Candide, published in 1759. He directly addressed his distaste for the clergy in thePhilosophical Letters, most notably in the fifth letter. In it, he portrayed the clergy as a fundamentally corrupt institution, and furthermore depicted religion as a mechanism of reinforcing a social \"hierarchy\".In this view, the clergy, and religion more broadly, reaffirms ignorance of social realities by passing off religious teachings as objective truths. However, in \"Plato's Dream,\" Voltaire chose to focus more so on the philosophical foundations of religious beliefs, rather than religion as a social institution. He inquired into the existence ofGodby examining all the imperfection and suffering inherent in the world: \"You certainly were not willing that there should remain any great number of these animals on Earth at once; for, over the course of a given year, smallpox will regularly carry off a tenth of the species, and sister maladies will taint the springs of life in the remainder\".He further detailed the capriciousness of mankind, maintaining that humans themselves contribute to their own suffering: \"...those who survive are occupied in lawsuits, or cutting each other's throats\". That being said, the human condition and one's innate desire for connection--and, ironically, for particularity or \"distinctness\" from others--play a central role in shaping the narrative's critique of Religion. For Voltaire, religion as both a philosophical and social enterprise not only perpetuates ignorance but also directly contradicts its purported aim of spreading the benevolent teachings of God--as demonstrated by the self-interested behavior of the humans occupying Demogorgon's Earth. Voltaire opened the narrative by stating that \"In ancient times, dreams were much revered, and Plato was one of the greatest dreamers.\"This assertion, though it appears to be clothed in a layer of sarcasm, enhances the intricacy of the narrative, as most ancient Greeks interpreted dreams as prophetic messages from the gods.However, this idea did not originate with the ancient Greeks-- the belief in the divine origin of dreams is traceable to AncientMesopotamian mythology.Such an idea is most prominent in the widely recognized ancient Mesopotamian myth, theEpic of Gilgamesh.In tablet VII, Enkidu--Gilgamesh's companion--dreams of a discussion between the Gods, who are deciding his punishment for his involvement in the slaughter of the Bull of Heaven and Humbaba.Shortly thereafter, Enkidu falls ill and subsequently dies.Moreover, in the Mesopotamiandeluge myth, the Epic ofAtra-Hasis, the story's hero, Atrahasis is warned by Enki of the impending flood through the medium of a dream. In terms of the Ancient Greek tradition,Platohimself contributed little to the philosophy of dreams or dreaming. He did, however, endorse the idea that dreams stemmed from a divine source, a perspective observable in one of his most notable dialogues,Crito.On a more controversial note, inThe Republic, Plato dons a perspective that closely resembles aFreudianinterpretation of dreams, despite writing centuries before him: \"…in all of us, even the most highly respectable, there is a lawless wild beast nature, which peers out in sleep\". Ancient Greeks' veneration for dreams and their divine sources is vital to Voltaire's narrative, as it not only adds a layer of depth to his overarching critique of religious practitioners, but also very subtly (and almost imperceptibly) critiques society's inclination to seek out religious, as opposed to rational, explanations of social or natural phenomenon. At the end of the story, Voltaire alludes to Plato'sallegory of the cave: \"Demiurgos scowled, and with that Plato awoke. Or did he?\" Much like Voltaire's use of a dream as figurative and metaphorical device, Plato employed imagery of a cave to represent ignorance.Those who partake in a \"cavic existence\"only know what life is like inside the cave. They accept the illusions within the cave's walls as truth, rarely ever stopping to question what life might be like beyond their own echo-chamber.Really, it is a demonstration of two vastly different \"states of consciousness,\" where one man becomes aware of the life beyond his familiar existence, while the other remains trapped by his own ignorance. This idea is inextricably linked to Voltaire's brief yet highly significant mention ofancient Greekperspectives on dreams, as Voltaire too views willful ignorance as an affront to reason.", "metadata": {"url": "https://en.wikipedia.org/wiki/Plato%27s_Dream", "title": "Plato's Dream", "headings": ["Contents", "Plot summary", "Voltaire in the context of Ancient Greek philosophy", "Themes", "Religion", "Dreams", "Ignorance versus enlightenment", "See also", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Plato%27s_Dream", "https://en.wikipedia.org/wiki/Plato%27s_Dream", "https://en.wikipedia.org/wiki/Plato%27s_Dream", "https://en.wikipedia.org/wiki/Short_story", "https://en.wikipedia.org/wiki/Philosopher", "https://en.wikipedia.org/wiki/Satirist", "https://en.wikipedia.org/wiki/Voltaire", "https://en.wikipedia.org/wiki/Microm%C3%A9gas"]}},
{"id": "546608c0e656", "content": "William Kaye Estes(June 17, 1919 – August 17, 2011) was an American psychologist. AReview of General Psychologysurvey, published in 2002, ranked Estes as the 77th most cited psychologist of the 20th century.In order to develop a statistical explanation for the learning phenomena, William Kaye Estes developed the Stimulus Sampling Theory in 1950 which suggested that a stimulus-response association is learned on a single trial; however, the learning process is continuous and consists of the accumulation of distinct stimulus-response pairings. As an undergraduate, Estes was a student ofRichard M. Elliottat theUniversity of Minnesota.  As a graduate student he stayed at theUniversity of Minnesota, and worked underB. F. Skinner, with whom he developed the conditioned suppression paradigm (Estes & Skinner, 1941). After receiving his doctorate, Estes joined Skinner on the faculty ofIndiana University. After Estes got out of theU. S. Armyat the end ofWorld War II, he established his reputation as one of the originators of mathematical learning theory. Estes went from Indiana University toStanford University, toRockefeller UniversityinNew York, and finally toHarvard University. While teaching at Harvard University, Estes contributed as an instituting first editor of thePsychological Sciencefor theAssociation for Psychological Science. He was also editor ofPsychological Reviewfrom 1977 to 1982 After retiring from Harvard, Estes returned toBloomington, Indiana, where he remained active in academics to becomeprofessor emeritusat his original academic home department. One of Estes' most famous contributions to learning theory was stimulus-sampling theory, which conceives of learning as establishing associations to hypothetical stimulus elements that are randomly drawn from a pool of elements that characterize a particular learning situation.  This theory predictedprobability matching, which has been found in a wide range of tasks for many different organisms. Estes has had a major influence on theories of learning and memory, both in his own and in the theories of his many students and collaborators. In honor of his impact within the field of psychology, Estes received theNational Medal of Scienceon December 16, 1997, from PresidentBill Clinton. Estes proposed a model of learning that he called Stimulus Sampling Theory (SST). SST is a probabilistic model that provides a statistical explanation of how we learn a stimulus-response association in a single trial, but require more stimulus-response repetitions to build an evident unit of learning.Stimulus-sampling models aid at least two functions. One is to make experimental predictions for situations in which the stimulus elements are controlled, in part at least, by the experimenter. The stimulus-sampling theory also aids as a heuristic device for discovering effective truisms about changes in response probabilities.The general theory of stimulus-sampling assumes the existence of a population of discrete stimulus elements and hypothesizes that an entity draws a sample from this population on each trial of a learning experiment. All stimulus-response theories have stimuli that are \"connected\" or \"conditioned\" to possible responses of the entity.A natural extension of SST theory provides explanations of discrimination, generalization, temporal processes, and even motivational phenomena. The \"folding-in\" technique used in classrooms today is derived from the stimulus sampling theory. An example of the folding-in procedure is a student reviewing ten flash cards (seven known, three unknown) and working through them till the student learns the ten cards 100%. After learning the ten cards, the student then replaces the three originally unknown cards with three more unknown cards.This drill is used to promote acquisition and fluency, and studies have shown that drill is extremely effective in teaching a wide range of responses. Mathematical psychology", "metadata": {"url": "https://en.wikipedia.org/wiki/William_Kaye_Estes", "title": "William Kaye Estes", "headings": ["Contents", "Background and education", "Estes on education", "Career highlights", "Notable affiliations", "Awards and honors", "Selected bibliography", "See also", "References"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/William_Kaye_Estes", "https://en.wikipedia.org/wiki/William_Kaye_Estes", "https://en.wikipedia.org/wiki/William_Kaye_Estes", "https://en.wikipedia.org/wiki/Minneapolis", "https://en.wikipedia.org/wiki/Minnesota", "https://en.wikipedia.org/wiki/University_of_Minnesota", "https://en.wikipedia.org/wiki/Psychology", "https://en.wikipedia.org/wiki/Mathematical_Psychology"]}},
{"id": "4ac155373bc9", "content": " Speedrunningis the act of playing avideo game, or section of a video game, with the goal of completing it as fast as possible. Speedrunning often involves following planned routes, which may incorporatesequence breakingand exploitglitchesthat allow sections to be skipped or completed more quickly than intended.Tool-assisted speedrunning(TAS) is a subcategory of speedrunning that usesemulation softwareor additional tools to create a precisely controlled sequence of inputs. Manyonline communitiesrevolve around speedrunning specific games; community leaderboard rankings for individual games form the primary competitive metric for speedrunning. Racing between two or more speedrunners is also a popular form of competition. Videos andlivestreamsof speedruns are shared via the internet on media sites such asYouTubeandTwitch. Speedruns are sometimes showcased at marathon events, which aregaming conventionsthat feature multiple people performing speedruns in a variety of games. Speedrunning has been a part of video games since the early days of the medium, similar to the chasing of high scores, though it did not achieve broad interest until 1993. Some groundwork for what would become modern speedrunning was established byid Softwareduring the development forWolfenstein 3D(1992), although prior  games such asMetroid(1986) andPrince of Persia(1989) encouraged speedrunning by noting a player's time upon meeting certain metrics, including completion of the game.Wolfenstein 3Drecorded a \"par time\" statistic which was based onJohn Romero's personal records for each level. Romero's best level times were also printed in the official hint book, which was available via the same mail-order system used to distribute the game at the time. His intention was that players would attempt to beat his times. The development of a strong speedrunning community is considered to have originated with the 1993 computer gameDoom.The game retained the \"par time\" mechanic fromWolfensteinand included a feature that allowed players to record and play back gameplay using files calleddemos(also known as game replays). Demos were lightweight files that could be shared more easily than video files onInternetbulletin board systemsat the time.Internally,in January 1994,University of Waterloostudent Christina Norman created aFile Transfer Protocolserver dedicated to compiling demos, named the LMP Hall of Fame (after the .lmpfile extensionused byDoomdemos). The LMP Hall of Fame inspired the creation of the Doom Honorific Titles by Frank Stajano, a catalogue of titles that a player could obtain by beating certain challenges in the game.TheDoomspeedrunning community emerged in November 1994, when Simon Widlake created COMPET-N, a website hosting leaderboards dedicated to ranking completion times ofDoom's single-player levels. In 1996,id SoftwarereleasedQuakeas a successor to theDoomseries. Like its predecessor,Quakehad a demo-recording feature and drew attention from speedrunners.In April 1997, Nolan \"Radix\" Pflug created Nightmare Speed Demos (NSD), a website for trackingQuakespeedruns.In June 1997, Pflug released a full-game speedrun demo ofQuakecalledQuake Done Quick, which introduced speedrunning to a broader audience.Quakespeedruns were notable for their breadth of movement techniques, including \"bunny hopping,\" a method of gaining speed also present in future shooting games likeCounter-StrikeandTeam Fortress.In April 1998, NSD merged with another demo-hosting website to createSpeed Demos Archive. For five years, Speed Demos Archive hosted exclusivelyQuakespeedruns, but in 2003 it published a 100% speedrun ofMetroid Primedone by Pflug. Six months later, SDA began accepting runs from all games. Unlike its predecessor websites, SDA did not compile leaderboards for their games; they displayed only the fastest speedrun of each game.Until SDA's expansion into games other thanQuakein 2004, speedrun video submissions were primarily sent to early video game record-keeperTwin Galaxies.The videos were often never publicly released, creating verifiability concerns that SDA aimed to address. It was often impossible to determine what strategies had gone into setting these records, hindering the development of speedrunning techniques.Sites dedicated to speedrunning, including game-specific sites, began to establish thesubculturearound speedrunning. These sites were not only used for sharing runs but also to collaborate and share tips to improve times, leading to collaborative efforts to continuously improve speedrunning records on certain games. In 2003, a video demonstrating a TAS ofSuper Mario Bros. 3garnered widespread attention on the internet; many speedrunners cite this as their first introduction to the hobby. It was performed and published by a Japanese user named Morimoto. The video was lacking context to indicate that it was a TAS, so many people believed it to be an actual human performance. It drew criticism from viewers who felt \"cheated\" when Morimoto later explained the process by which he created the video and apologized for the confusion.In December 2003, after seeing Morimoto’s TAS, a user named Bisqwit created TASVideos (initially named NESVideos), a site dedicated to displaying tool-assisted speedruns. The creation of video-sharing and streaming websites in the late 2000s and early 2010s contributed to an increase in the accessibility and popularity of speedrunning. In 2005, the creation of YouTube enabled speedrunners to upload and share videos of speedruns and discuss strategies on the SDAforums.Twitch, a livestreaming website centered around video gaming, was launched in 2011. The advent of livestreaming made for easier verification and preservation of speedruns, and some speedrunners believe it is responsible for a shift towards collaboration among members of the community.In 2014,Speedrun.comwas created, which had less stringent submission guidelines than SDA and was intended to centralize speedrun leaderboards for many different games. Speedrunners' move towards usingSpeedrun.comand social media platforms likeSkypeandDiscordcontributed to SDA's relevance waning in the 2010s. Routing is a fundamental process in speedrunning.Routing is the act of developing an optimal sequence of actions and stages in a video game. A route may involve skipping one or more important items or sections. Skipping a part of a video game that is normally required for progression is referred to assequence breaking,a term first used in reference to the 2002 action-adventure gameMetroid Prime.Video gameglitchesmay be used to achieve sequence breaks,or may be used for other purposes such as skippingcutscenesand increasing the player's speed or damage output.Some people, calledglitch-hunters, choose to focus on finding glitches that will be useful to speedrunners.In some games,arbitrary code executionexploits may be possible, allowing players to write their own code into the game's memory. Several speedruns use a \"credits warp\", a category of glitch that causes the game'scredits sequenceto play, which may require arbitrary code execution.The use of glitches and sequence breaks in speedruns was historically not allowed, per the rules of Twin Galaxies' early leaderboards. When speedrunning moved away from Twin Galaxies towards independent online leaderboards, their use became increasingly common.  A tool-assisted speedrun (TAS) is a speedrun that usesemulation softwareand tools to create a \"theoretically perfect playthrough\".According to TASVideos, common examples of tools include advancing the game frame by frame to play the game more precisely, retrying parts of the run using savestates, andhex editing.These tools are designed to remove restrictions imposed by human reflexes and allow for optimal gameplay.The run is recorded as a series of controller inputs intended to be fed back to the game in sequence.Although generally recorded on an emulator, TASes can be played back on original console hardware by sending inputs into the console's controller ports, a process known as console verification (as some exploits are possible on emulation but not console).To differentiate them from tool-assisted speedruns, unassisted speedruns are sometimes referred to asreal-time attack(RTA) speedruns. Due to the lack of a human playing the game in real time, TASes are not considered to be in competition with RTA speedruns. Speedruns are divided into various categories that impose additional limitations on a runner. It is common for category restrictions to require a certain amount of content to be completed in the game.Each video game may have its own speedrun categories, but some categories are popular irrespective of game.The most common are: Speedrunners compete in these categories by ranking times on online leaderboards.According toWired, the definitive website for speedrun leaderboards isSpeedrun.com. As of July 2021,the site hosts leaderboards for over 20,000 video games.Runners usually record footage of their speedruns for accurate timing and verification, and may include a timer in their videos. They often use timers that keep track of splits—the time between the start of the run and the completion of some section or objective.Verification is usually done by leaderboard moderators who review submissions and determine the validity of individual speedruns. According to many speedrunners, community is an important aspect of the hobby. Matt Merkle, director of operations atGames Done Quick, says that speedrunners \"value the cooperation the community encourages,\"and many speedrunners have said that their mental health has improved because of their involvement in the community.Erica Lenti, writing forWired,said a sense of community is vital to speedrunning because it motivates players and aids in the development of routes and tricks used in speedruns,and Milan Jacevic highlighted \"years of research\" and collective community efforts that contribute to world records. Speedrunners use media-sharing sites likeYouTubeandTwitchto share videos and livestreams of speedruns.The speedrunning community is divided into many sub-communities focused on speedrunning specific games. These sub-communities can form their own independent leaderboards and communicate about their games usingDiscord.Many communities have used the centralized leaderboard hosting siteSpeedrun.comsince its founding in 2014. Speedrunning marathons, a form ofgaming convention,feature a series of speedruns by multiple speedrunners. While many marathons are held worldwide,the largest event isGames Done Quick, a semiannual marathon held in the United States.As of January 2022,it has raised over $37 million for charity organizations since its inception in 2010.The largest marathon in Europe is theEuropean Speedrunner Assembly, held in Sweden. Both events broadcast the speedruns onTwitchand raise money for various charity organizations.Speedruns at marathons are done in one attempt and often have accompanying commentary.Many people consider marathons to be important to runners and spectators in the speedrunning community. Peter Marsh, writing for theAustralian Broadcasting Corporation, says that the Games Done Quick events provide an inclusive space for women and theLGBTQ communityin contrast to the related cultures of gaming and Twitch streaming.Alex Miller ofWiredsays the events have played an important role in connecting people and supporting international humanitarian organizationMédecins Sans Frontièresduring theCOVID-19 pandemic. Races between two or more speedrunners are a common competition format. They require players to be skilled at recovering from setbacks during a speedrun because they cannot start over.Occasionally, races are featured at marathons; a 4-personSuper Metroidrace is a popular recurring event at Games Done Quick marathons.The Global Speedrun Association (GSA) have organized head-to-head tournaments for multiple games, includingCeleste,Super Mario 64, andSuper Mario Odyssey. In 2019, GSA organized an in-person speedrun race event called PACE. Their efforts have drawn criticism from some speedrunners who believe that they \"undermine the community spirit\", citing cash prizes as incentives to avoid collaboration with other speedrunners and ignore games without prize money.Video game randomizers—ROM hacksthat randomly shuffle item locations and other in-game content—are popular for speedrun races as well. Tournaments and other events have been organized for randomizer races, and they have been featured at speedrun marathons. Splicing is by far the most popular cheating method in speedrunning.Here, a speedrun is not recorded continuously, as is usually the case, but instead composed of various video snippets recorded at different times, sometimes with gameplay stolen from TAS composers or legitimate players. AtSGDQ2019, speedrunner \"ConnorAce\" used a spliced run to illegitimately claim the world record onClustertruckfor the \"NoAbility%\" category, depriving the legitimate record holder from being invited to the event. The run was treated with suspicion due to it not being submitted officially toSpeedrun.com, with the video being unlisted on YouTube prior to ConnorAce's acceptance into SGDQ. In October 2019, ConnorAce's run was exposed by the YouTube documentarian Apollo Legend. In a typical case, splicing allows difficult segments to be repeated to perfection and edited together afterwards into one seemingly continuous effort, which can sometimes dramatically reduce the amount of time needed to grind out a comparable score.However, a spliced run is not considered cheating if it is announced to be a multi-segment run upon submission; for example, this community-mademulti-segment compilationforSuper Mario Bros. When 'TASbotting', the player records their controller inputs as a tool-assisted run in an external device in order to then have this device reproduce the inputs on a real console.As with splicing, the inputs of individual segments can be combined and, as is usual for tool-assisted runs, inputs can be made frame by frame. As long as these inputs are authentic and seem realistic for a human being, such manipulations are much more difficult to detect in the resulting video product than splicing.If, on the other hand, a TAS is not outputted on the original hardware but, as usual, on emulators, it can sometimes be alleged from the resulting video that such auxiliary programs were used; additionally, some emulators never perfectly imitate the desired hardware, which can cause synchronization issues when replayed on a console. Modifying game timers, especially on computer games, is another common method to improve one's recorded times. However, this is a very noticeable manipulation, especially in highly competitive areas, since the speedruns in the upper area of leaderboards are repeatedly analyzed by other players in order to check their legitimacy and playback reproducibility, including a temporal check known as \"retiming\". This often reveals discrepancies between one's recording time and a speedrun in the leaderboards. Another method, a variation of splicing, includes speeding up cutscenes or compressing transitional black space. Again, such methods are likely to be detected by a speedrun moderator, although some games, especially where PC speed can have an effect, may actually vary depending on hardware. Finally, another common cheating method is to play the game using frame-by-frame advancement or in slow motion, which is similar to normal tool-assisted speedrunning but without the ability to redo inputs. Playing in slow motion is often effective for games that require very precise movements. While it is often possible to use traditional cheats such as aGameSharkto increase character speed, strength, health, etc., such cheats are generally quite easy for an experienced moderator to detect, even when applied subtly. However, the modification of internal files to improveRNGcan often be much more difficult to detect. One of the most infamous examples of file modification was several cheated runs by the speedrunnerDreamin 2020, whose luck was considered so extreme in a series ofMinecraftspeedrunsthat they were considered exceedingly unlikely to have been done without cheating (with an approximately 1 in 20sextillionchance of occurring, as estimated byMatt ParkerfromNumberphile) by both the moderators atSpeedrun.comand various YouTubers, such asKarl Jobstand Matt Parker, whose videos on Dream gained a combined 5.7 million and 6.5 million views, respectively, as of January 2024.Dream later admitted to the runs being cheated about five months after his runs were rejected, although he claimed he did not know he was using a modified version of the game.Nearly two years later, the player who helped uncover Dream's cheated runs, MinecrAvenger, was also found to be using similar luck manipulation in late 2022. While all of the aforementioned methods are deceptive in nature, the simplest way of cheating is merely to lie about a time. One of the most infamous cases of this was done byTodd Rogers. Several of his records have come under scrutiny for being seemingly impossible or lacking sufficient proof. In 2002, Robert Mruczek, then chief referee at Twin Galaxies, officially rescinded Todd's record time inBarnstormingafter other players pointed out that his time of 32.04 seconds did not appear to be possible, even when the game was hacked to remove all obstacles. Upon further investigation, Twin Galaxies referees were unable to find independent verification for this time, having instead been relying on erroneous information from Activision. As listed on the Twin Galaxies leaderboard until January 2018, Rogers's record in the 1980 Activision gameDragsterwas a time of 5.51 seconds from 1982.At the time, Activision verified high scores byPolaroid.According to Rogers, after he submitted a photo of this time, he was called by Activision, who asked him to verify how he achieved such a score, because they had programmed a 'perfect run' of the game and were unable to achieve better than a 5.54.The game's programmerDavid Cranewould later confirm that he had a vague recollection of programming test runs, but did not remember the results.In 2012, Todd received aGuinness World Recordfor the longest-standing video game score record, for his 1982Dragsterrecord.In 2017, a speedrunner named Eric \"Omnigamer\" Koziel disassembled the game's code and concluded that the fastest possible time was 5.57 seconds. With atick rateof 0.03 seconds, the record claim is two ticks faster than Omnigamer's data and one tick faster than the reported Activision 'perfect run'. In order to prevent most of these methods, some games require a video of the hands on the controller or keyboard (\"handcam\"), in addition to the screen recording, so that game-specific moderators in charge of authenticating a submission can ensure that the inputs are really done in the specified combination and by a human.Other methods includeforensic audio analysis, which is a common method for detecting telltale signs of video splicing; this is why runs without high-quality audio streams are often rejected on speedrun boards. Additional detection methods are the use of mathematics (as in the aforementioned Dream case) or human moderation of suspicious inputs (in games which record them such asDoomandTrackMania). Cheat detection software created forTrackManiawas used to analyze over 400,000 replays and isolate a handful of cheaters, leading to hundreds of world records being determined to have been cheated using slowdown tools. This included those of Burim \"riolu\" Fejza, who was signed to theeSportsteam Nordavind (now known as 00 Nation) before being dropped following the scandal.", "metadata": {"url": "https://en.wikipedia.org/wiki/Speedrunning", "title": "Speedrunning", "headings": ["Contents", "History", "Early examples", "DoomandQuakedemos, early Internet communities", "Speed Demos Archive and video sharing", "Methodology", "Gameplay strategies", "Tool-assisted speedruns", "Categorization and ranking", "Community", "Marathons", "Speedrun races", "Cheating", "Methods", "Cheat detection", "See also", "Notes", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Speedrunning", "https://en.wikipedia.org/wiki/Speedrunning", "https://en.wikipedia.org/wiki/Speedrunning", "https://en.wikipedia.org/wiki/Speedrun_(disambiguation)", "https://en.wikipedia.org/wiki/SuperTux", "https://en.wikipedia.org/wiki/Video_game", "https://en.wikipedia.org/wiki/Sequence_breaking", "https://en.wikipedia.org/wiki/Glitch"]}},
{"id": "6b6d806d57b6", "content": " TheUniversity of California, Berkeley(UC Berkeley,Berkeley,Cal, orCalifornia)is apublicland-grantresearch universityinBerkeley, California, United States. Founded in 1868 and named after theAnglo-IrishphilosopherGeorge Berkeley, it is the state's firstland-grant universityand the founding campus of theUniversity of Californiasystem. Berkeley has an enrollment of more than 45,000 students. The university is organized around fifteen schools of study on the same campus, including theCollege of Chemistry, theCollege of Engineering,College of Letters and Science, and theHaas School of Business. It isclassifiedamong \"R1: Doctoral Universities – Very high research activity\".Lawrence Berkeley National Laboratorywas originally founded as part of the university. Berkeley was a founding member of theAssociation of American Universitiesand was one of the original eight \"Public Ivy\" schools. In 2021, the federal funding for campus research and development exceeded $1 billion.Thirty-two libraries also compose theBerkeley library systemwhich is thesixth largest research library by number of volumes heldin the United States. Berkeley students compete in thirtyvarsityathletic sports, and the university is one of eighteen full-member institutions in theAtlantic Coast Conference(ACC). Berkeley's athletic teams, theCalifornia Golden Bears, have also won 107 national championships, 196 individual national titles, and223 Olympic medals(including 121 gold).Berkeley'salumni,faculty, and researchersinclude 59Nobel laureatesand 19Academy Awardwinners,and the university is also a producer ofRhodes Scholars,Marshall Scholars,andFulbright Scholars. Made possible byPresident Lincoln's signing of theMorrill Actin 1862, the University of California was founded in 1868 as the state's first land-grant university, inheriting the land and facilities of the privateCollege of Californiaand the federal-funding eligibility of a public agricultural, mining, and mechanical arts college.The Organic Act states that the \"University shall have for its design, to provide instruction and thorough and complete education in all departments of science, literature and art, industrial and professional pursuits, and general education, and also special courses of instruction in preparation for the professions.\" Ten faculty members and forty male students made up the fledgling university when it opened in Oakland in 1869.Frederick Billings, a trustee of the College of California, suggested that a new campus site north of Oakland be named in honor ofAnglo-IrishphilosopherGeorge Berkeley.The university began admitting women the following year.In 1870,Henry Durant, founder of the College of California, became its first president. With the completion of North andSouth Hallsin 1873, the university relocated to its Berkeley location with 167 male and 22 female students.The first female student to graduate was in 1874, admitted in the first class to include women in 1870. Beginning in 1891,Phoebe Apperson Hearstfunded several programs and new buildings and, in 1898, sponsored an international competition inAntwerp, where French architectÉmile Bénardsubmitted the winning design for a campus master plan. In 1905, the University Farm was established nearSacramento, ultimately becoming theUniversity of California, Davis.In 1919, the Los Angeles branch of theCalifornia State Normal Schoolbecame the southern branch of the university, which ultimately became theUniversity of California, Los Angeles.By the 1920s, the number of campus buildings in Berkeley had grown substantially and included twenty structures designed by architectJohn Galen Howard.In 1917, one of the nation's firstROTCprograms was established at Berkeleyand its School of Military Aeronautics began training pilots, includingJimmy Doolittle. In 1926, futureFleet AdmiralChester W. Nimitzestablished the firstNaval ROTCunit at Berkeley.Berkeley ROTC alumni include former Secretary of DefenseRobert McNamara, Army Chief of StaffFrederick C. Weyand, sixteen othergeneral officers, ten Navyflag officers, and AFROTC alumna CaptainTheresa Claiborne.In the 1930s,Ernest Orlando Lawrencehelped establish the Radiation Laboratory (nowLawrence Berkeley National Laboratory) and invented thecyclotron, which won him the Nobel physics prize in 1939.Using the cyclotron, Berkeley professors and Berkeley Lab researchers went on to discover sixteenchemical elements—more than any other university in the world.In particular, during World War II and followingGlenn Seaborg's then-secret discovery of plutonium, Lawrence's Radiation Laboratory began to contract with the U.S. Army to develop the atomic bomb. Physics professorJ. Robert Oppenheimerwas named scientific head of the Manhattan Project in 1942.Along with the Lawrence Berkeley National Laboratory, Berkeley founded and was then a partner in managing two other labs,Los Alamos National Laboratory(1943) andLawrence Livermore National Laboratory(1952). In 1952, theUniversity of Californiareorganized itself into a system of semi-autonomous campuses, with each campus given a chancellor, andClark Kerrbecame Berkeley's first chancellor, whileRobert Sproulremained in place as the president of the University of California.Berkeley gained a worldwide reputation forpolitical activismin the 1960s. In 1964, theFree Speech Movementorganized student resistance to the university's restrictions on political activities on campus—most conspicuously, student activities related to theCivil Rights Movement. The arrest in Sproul Plaza ofJack Weinberg, a recent Berkeley alumnus and chair of CampusCORE, prompted a series of student-led acts of formal remonstrance and civil disobedience that ultimately gave rise to the Free Speech Movement, which movement would prevail and serve as a precedent for studentoppositionto America's involvement in the Vietnam War.In 1982, theMathematical Sciences Research Institute(MSRI) was established on campus with support from theNational Science Foundationand at the request of three Berkeley mathematicians—Shiing-Shen Chern,Calvin Moore, andIsadore M. Singer. The institute is now widely regarded as a leading center for collaborative mathematical research, drawing thousands of visiting researchers from around the world each year. In the current century, Berkeley has become less politically active, although more liberal.Democrats outnumber Republicans on the faculty by a ratio of nine to one, which is a ratio similar to that of American academia generally.The school has become more focused onSTEMdisciplines and fundraising.In 2007, theEnergy Biosciences Institutewas established with funding fromBPand Stanley Hall, a research facility and headquarters for theCalifornia Institute for Quantitative Biosciences, opened. Supported by a grant from alumnusJim Simons, theSimons Institute for the Theory of Computingwas established in 2012. In 2015, Berkeley and its sister campus,UCSF, established theInnovative Genomics Instituteto developCRISPR gene editing, and, in 2020, an anonymous donor pledged $252 million to help fund a new center for computing and data science. For the 2020 fiscal year, Berkeley set a fundraising record, receiving over $1 billion in gifts and pledges, and two years later, it broke that record, raising over $1.2 billion.In 2024,protestsat Berkeley regarding theGaza warresulted in police action. Officially named the \"University of California, Berkeley\" it is often shortened to \"Berkeley\" in general reference or in an academic context (Berkeley Law,Berkeley Engineering,Berkeley Haas,Berkeley Public Health) and to \"California\" or \"Cal\" particularly when referring to its athletic teams (California Golden Bears). The University of California is governed by a twenty-six memberBoard of Regents, eighteen of whom are appointed by theGovernor of Californiato 12-year terms. The board also has sevenex officiomembers, a student regent, and a non-voting student regent-designate.Prior to 1952, Berkeley was the University of California, so the university president was also Berkeley's chief executive. In 1952, the university reorganized itself into a system of semi-autonomous campuses, with each campus having its own chief executive, a chancellor, who would, in turn, report to the president of the university system. Twelve vice-chancellors report directly to Berkeley's chancellor, and the deans of the fifteen colleges and schools report to the executive vice chancellor and provost, Berkeley's chief academic officer.Twenty-three presidents and chancellors have led Berkeley since its founding. Presidents Chancellors With the exception of government contracts, public support is apportioned to Berkeley and the other campuses of the University of California system through the UC Office of the President and accounts for 12 percent of Berkeley's total revenues.Berkeley has benefited from private philanthropy and alumni and their foundations have given to the university for operations and capital expenditures with the more prominent beingJ. Paul Getty,Ann Getty,Sanford Diller,Donald Fisher,Flora Lamson Hewlett, David Schwartz (Bio-Rad) and members of the Haas (Walter A. Haas,Rhoda Haas Goldman,Walter A. Haas Jr.,Peter E. Haas,Bob Haas) family. Berkeley has also benefited from benefactors beyond its alumni ranks, notable among which areMark ZuckerbergandPriscilla Chan;Vitalik Buterin,Patrick Collison,John Collison, theRon Conwayfamily,Daniel Gross,Dustin MoskovitzandCari Tuna, along withJane Streetprincipals;BP; the Bill and Melinda Gates Foundation, billionaireSir Li Ka-Shing, Israeli-Russian billionaireYuri Milner,Thomas and Stacey Siebel,Sanford and Joan Weill, and professorGordon Rausser($50 million gift in 2020).Hundreds of millions of dollars have been given anonymously.The 2008–13 \"Campaign for Berkeley\" raised $3.13 billion from 281,855 donors, and the \"Light the Way\" campaign, which concluded at the end of 2023, has raised over $6.2 billion. Berkeley is a large, primarily residential research university with a majority of its enrolment in undergraduate programs but also offering a comprehensive doctoral program.The university has beenaccreditedby theWestern Association of Schools and CollegesSenior College and University Commission since 1949.The university operates on asemester calendarand awarded 8,725 bachelor's, 3,286 master's or professional and 1,272 doctoral degrees in 2018–2019. There are 1,789 full-time and 886 part-time faculty members among the university's academic enterprise which is organized into fifteen colleges and schools that comprise 180 departments and 80 interdisciplinary units offering over 350 degree programs. Colleges serve both undergraduate and graduate students, while schools are generally graduate only, though some offer undergraduate majors or minors: The four-year, full-time undergraduate program offers 107 bachelor's degrees across the Haas School of Business (1), College of Chemistry (5), College of Engineering (20), College of Environmental Design (4), College of Letters and Science (67), Rausser College of Natural Resources (10), and individual majors (2).The most popular majors areelectrical engineering and computer sciences,political science,molecularandcell biology,environmental science, andeconomics. Requirements for undergraduate degrees include an entry-level writing requirement before enrollment (typically fulfilled by minimum scores on standardized admissions exams such as the SAT or ACT), completing coursework on \"American History and Institutions\" before or after enrollment by taking an introductory class, passing an \"American Cultures Breadth\" class at Berkeley, as well as requirements for reading and composition and specific requirements declared by the department and school. Berkeley has a \"comprehensive\" graduate program, with high coexistence with the programs offered to undergraduates, and offers interdisciplinary graduate programs with the medical schools at theUniversity of California, San FranciscoandStanford University. The university offersMaster of Arts,Master of Science,Master of Fine Arts, andPhDdegrees in addition to professional degrees such as theJuris Doctor,Master of Business Administration,Master of Public Health, andMaster of Design.The university awarded 963 doctoral degrees and 3,531 master's degrees in 2017.Admission to graduate programs is decentralized; applicants apply directly to the department or degree program. Most graduate students are supported by fellowships, teaching assistantships, or research assistantships. Doe Libraryserves as theBerkeley library system's reference, periodical, and administrative center, while most of the main collections reside in the subterranean Gardner Main Stacks and Moffitt Undergraduate Library. TheBancroft Library, which has over 400,000 printed volumes and 70 million manuscripts, pictures, and maps, maintains special collections that document the history of the western part of North America, with an emphasis on California, Mexico and Central America. The Bancroft Library also houses the Mark Twain Papers,the Oral History Center,the Center for the Tebtunis Papyri,and the University Archives. In his memoirs,Clark Kerrrecords Berkeley's rise in the rankings (according to theNational Academies) during the 20th century. The school's first ranking in 1906 placed it among the top six schools (\"Big Six\") in the nation. In 1934, it ranked second, tied withColumbiaand theUniversity of Chicago, behind onlyHarvard; in 1957, it was ranked as the only school second to Harvard. In 1964, Berkeley was named the \"best balanced distinguished university\", meaning the school had not only the most top departments but also the highest percentage of top ranking departments in its school. The school in 1993 was the only remaining member of the original 1906 \"Big Six\", along with Harvard; in that year Berkeley ranked first. TheAmerican Council on Education, a private non-profit association, ranked Berkeley tenth in 1934. However, by 1942, private funding had helped Berkeley rise to second place, behind only Harvard, based on the number of distinguished departments.In 1985,Yale Universityadmissions officer Richard Moll publishedPublic Ivies: A Guide to America's Best Public Undergraduate Colleges and Universitieswhich named Berkeley a \"Public Ivy\". The 2010United States National Research Council Rankingsidentified Berkeley as having the highest number of top-ranked doctoral programs in the nation. Berkeley doctoral programs that received a #1 ranking included English, German, Political Science, Geography, Agricultural and Resource Economics, Mathematics, Physics, Chemistry, Biochemistry, Molecular Biology, Genetics, Genomics, Epidemiology, Plant Biology, Computer Science, Electrical Engineering, Mechanical Engineering, and Civil and Environmental Engineering. For Fall 2022, Berkeley's total enrollment was 45,745: 32,831 undergraduate and 12,914 graduate students, with women accounting for 56% of undergraduates and 49% of graduate and professional students. It had 128,226 freshman applicants and accepted 14,614 (11.4%). Among enrolled freshman, the average unweighted GPA was 3.90. Berkeley's enrollment ofNational Merit Scholarswas third in the nation until 2002, when participation in the National Merit program was discontinued.For 2019, Berkeley ranked fourth in enrollment of recipients of theNational Merit $2,500 Scholarship(132 scholars).27% of admitted students receive federalPell grants. Berkeley students are eligible for a variety of public and private financial aid. Inquiries are processed through the Financial Aid and Scholarships Office, although schools such as the Haas School of BusinessandBerkeley Law,have their own financial aid offices. Much of the Berkeley campus is in the city limits ofBerkeleywith portion of the property extending intoOakland.It encompasses approximately 1,232-acres, though the \"central campus\" occupies only the low-lying western 178-acres of this area. Of the remaining acres, approximately 200-acres are occupied by the Lawrence Berkeley National Laboratory; other facilities above the main campus include theLawrence Hall of Scienceand several research units, notably theSpace Sciences Laboratory, theMathematical Sciences Research Institute, an 800-acre (320-hectare) ecological preserve, theUniversity of California Botanical Gardenand a recreation center in Strawberry Canyon. Portions of the mostly undeveloped, eastern area of the campus are actually within theCity of Oakland; these portions extend from theClaremont Resortnorth through thePanoramic Hillneighborhood toTilden Park. To the west of the central campus is thedowntown business district of Berkeley; to the northwest is the neighborhood of North Berkeley, including the so-calledGourmet Ghetto, a commercial district known for high quality dining due to the presence of such world-renowned restaurants asChez Panisse. Immediately to the north is a quiet residential neighborhood known asNorthsidewith a large graduate student population;situated north of that are the upscale residential neighborhoods of theBerkeley Hills. Immediately southeast of campus lies fraternity row and beyond that theClark Kerr Campusand an upscale residential area namedClaremont. Thearea south of the universityincludes student housing andTelegraph Avenue, one of Berkeley's main shopping districts with stores, street vendors and restaurants catering to college students and tourists. In addition, the university also owns land to the northwest of the main campus, a married student housing complex in the nearby town of Albany (\"Albany Village\" and the \"Gill Tract\"), and afield research stationseveral miles to the north inRichmond, California. The campus is home to several museums including theUniversity of California Museum of Paleontology, theBerkeley Art Museum and Pacific Film Archive, and theLawrence Hall of Science. The Museum of Paleontology, found in the lobby of the Valley Life Sciences Building, showcases a variety of dinosaur fossils including a complete cast of a Tyrannosaurus Rex. The campus also offers resources for innovation and entrepreneurship, such as the Big Ideas Competition, the Sutardja Center for Entrepreneurship and Technology, and the Berkeley Haas Innovation Lab.The campus is also home to theUniversity of California Botanical Garden, with more than 12,000 individual species. What is considered the historic campus today was the result of the 1898 \"International Competition for thePhoebe HearstArchitectural Plan for the University of California,\" funded byWilliam Randolph Hearst's mother and initially held in the Belgian city ofAntwerp; eleven finalists were judged again in San Francisco in 1899.The winner was FrenchmanÉmile Bénard, who refused to personally supervise the implementation of his plan and the task was subsequently given to architecture professorJohn Galen Howard. Howard designed over twenty buildings, which set the tone for the campus up until its expansion in the 1950s and 1960s. The structures forming the \"classical core\" of the campus were built in theBeaux-ArtsClassical style, and includeHearst Greek Theatre,Hearst Memorial Mining Building,Doe Memorial Library, California Hall,Wheeler Hall, Le Conte Hall, Gilman Hall, Haviland Hall, Wellman Hall,Sather Gate, and theSather Tower(nicknamed \"the Campanile\" after its architectural inspiration,St Mark's Campanilein Venice), the tallest university clock tower in the United States.Buildings he regarded as temporary and non-academic were designed in shingle orCollegiate Gothicstyles; examples of these are North Gate Hall, Dwinelle Annex, and Stephens Hall. Many of Howard's designs are recognizedCalifornia Historical Landmarksand are listed on theNational Register of Historic Places. Built in 1873 in aVictorianSecond-Empire-style, South Hall, designed by David Farquharson, is the oldest university building in California. It, and theFrederick Law Olmsted-designedPiedmont Avenueeast of the main campus, are two of the only surviving examples of the nineteenth-century campus. Other notable architects and firms whose work can be found in the campus and surrounding area areBernard Maybeck(Faculty Club);Julia Morgan(Hearst Women's Gymnasium andJulia Morgan Hall);William Wurster(Stern Hall); Moore Ruble Yudell (Haas School of Business);Tod Williams Billie Tsien Architects(C.V. Starr East Asian Library), andDiller Scofidio + Renfro(Berkeley Art Museum and Pacific Film Archive). Flowing into the main campus are two branches ofStrawberry Creek. The south fork enters a culvert upstream of the recreational complex at the mouth of Strawberry Canyon and passes beneathCalifornia Memorial Stadiumbefore appearing again in Faculty Glade. It then runs through the center of the campus before disappearing underground at the west end of campus. The north fork appears just east ofUniversity Houseand runs through the glade north of the Valley Life Sciences Building, the original site of the Campus Arboretum. Trees in the area date from the founding of the university. The campus features numerous wooded areas, including:Founders' Rock, Faculty Glade, Grinnell Natural Area, and theEucalyptusGrove, which is both the tallest stand of such trees in the world and the tallest stand of hardwood trees in North America.The campus sits on theHayward Fault, which runs directly through California Memorial Stadium. The official university mascot isOski the Bear, who debuted in 1941. Previously, live bear cubs were used as mascots at Memorial Stadium until it was decided in 1940 that a costumed mascot would be a better alternative. Named after theOski-wow-wowyell, he is cared for by the Oski Committee, whose members have exclusive knowledge of the identity of the costume-wearer.TheUniversity of California Marching Band, which has served the university since 1891, performs at every home football game and at select road games as well. A smaller subset of the Cal Band, the Straw Hat Band, performs at basketball games, volleyball games, and other campus and community events. The UC Rally Committee, formed in 1901, is the official guardian of California's Spirit and Traditions. Wearing their traditional blue and gold rugbies, Rally Committee members can be seen at all major sporting and spirit events. Committee members are charged with the maintenance of the six Cal flags, the large California banner overhanging the Memorial Stadium Student Section andHaas Pavilion, the California Victory Cannon, Card Stunts andThe Big \"C\"among other duties. The Rally Committee is also responsible for safekeeping of theStanford Axewhen it is in Cal's possession. Overlooking the main Berkeley campus from the foothills in the east, The Big \"C\" is an important symbol of California school spirit. The Big \"C\" has its roots in an early 20th-century campus event called \"Rush\", which pitted the freshman and sophomore classes against each other in a race up Charter Hill that often developed into a wrestling match. It was eventually decided to discontinue Rush and, in 1905, the freshman and sophomore classes banded together in a show of unity to build \"the Big C.\" Students invented the college football tradition ofcard stunts. Then known as Bleacher Stunts, they were first performed during the 1910Big Gameand consisted of two stunts: a picture of the Stanford Axe and a large blue \"C\" on a white background. The tradition is continued today by the Rally Committee in the Calstudent sectionand incorporates complicated motions, for example tracing the Cal script logo on a blue background with an imaginary yellow pen. The California Victory Cannon, placed onTightwad Hilloverlooking the stadium, is fired before every football home game, after every score, and after every Cal victory. First used in the 1963 Big Game, it was originally placed on the sidelines before moving to Tightwad Hill in 1971. The only time the cannon ran out of ammunition was during a game againstPacificin 1991, when Cal scored 12 touchdowns.The Cal Mic Men, a standard at home football games, has recently expanded to involve basketball and volleyball. The traditional role comes from students holding megaphones and yelling, but now includes microphones, a dedicated platform during games, and the direction of the entire student section. Berkeley students are offered a variety of housing options, including university-owned or affiliated residences, private residences, fraternities and sororities, and cooperative housing (co-ops). Berkeley students, and those of other local schools, have the option of living in one of the twenty cooperative houses participating in the Berkeley Student Cooperative (BSC), anonprofithousing cooperativenetwork consisting of 20 residences and 1250 member-owners. About three percent of undergraduate men and nine percent of undergraduate women—or 3,400 of total undergraduates—are active in Berkeley's Greek system.University-sanctioned fraternities and sororities comprise over 60 houses affiliated with four Greek councils. TheAssociated Students of the University of California(ASUC) is the officialstudent associationthat controls funding for student groups and organizes on-campus student events. The two main political parties are \"Student Action\"and \"CalSERVE\".The organization was founded in 1887 and has an annual operating budget of $1.7 million (excluding the budget of the Graduate Assembly of the ASUC), in addition to various investment assets. Its alumni include multiple State Senators, Assemblymembers, and White House Administration officials. Berkeley's student-run online television station,CalTV, was formed in 2005 and broadcasts online. It is run by students with a variety of backgrounds and majors. Since the mid-2010s, it has been a program of theASUC.Berkeley's independent student-run newspaper isThe Daily Californian. Founded in 1871,The Daily Calbecame independent in 1971 after the campus administration fired three senior editors for encouraging readers to take backPeople's Park. The Daily Californian has both a print and online edition. Berkeley's FMstudent radio station,KALX, broadcasts on 90.7 MHz. It is run largely by volunteers, including both students and community members. Berkeley also features an assortment of student-run publications: There are ninety-four political student groups on campus, including MEChXA de UC Berkeley, BerkeleyACLU, Berkeley Students for Life, Campus Greens, The Sustainability Team (STEAM), theBerkeley Student Food Collective, Students for Sensible Drug Policy, Cal Berkeley Democrats, and the Berkeley College Republicans.The Residence Hall Assembly (RHA) is the student-led umbrella organization that oversees event planning, legislation, sponsorships and other activities for over 7,200 on-campus undergraduate residents. Berkeley students also run a number of consulting groups, including the Berkeley Group, founded in 2003 and affiliated with the Haas School.Students from various concentrations are recruited and trained to work on pro-bono consulting engagements with actual nonprofit clients. Berkeley Consulting, founded in 1996, has served over 140 companies across the high-tech, retail, banking, and non-profit sectors. ImagiCal has been the college chapter of theAmerican Advertising Federationat Berkeley since the late 1980s.The team competes annually in the National Student Advertising Competition, with students from disparate majors working together on a marketing case underwritten by a corporate sponsor. TheBerkeley Forumis a nonpartisan student organization that hosts panels, debates, and speeches across a variety of fields.Past speakers includeSenatorRand Paul, entrepreneur and venture capitalistPeter Thiel, andKhan AcademyfounderSalman Khan. Democratic Education at Cal, or DeCal, is a program that promotes the creation of professor-sponsored, student-facilitated classes.DeCal arose out of the 1960sFree Speech movementand was officially established in 1981. The program offers around 150 courses on a vast range of subjects that appeal to the student community, including classes on theRubik's Cube,blockchain,web design, metamodernism,cooking, Jewish art,3D animation, andbioprinting. The campus is home to severala cappellagroups, including Drawn to Scale, Artists in Resonance, Berkeley Dil Se, theUC Men's Octet, theCalifornia Golden Overtones, DeCadence, and Noteworthy. TheUniversity of California Men's Octetwas founded in 1948. Since 1967, students and staff jazz musicians have had an opportunity to perform and study with theUniversity of California Jazz Ensembles. For several decades it hosted the Pacific Coast Collegiate Jazz Festival, part of the American Collegiate Jazz Festival, a competitive forum for student musicians. PCCJF brought jazz artists includingHubert Laws,Sonny Rollins,Freddie Hubbard, andEd Shaughnessyto the Berkeley campus as performers. Berkeley also hosts other performing arts groups in comedy, dance, acting and instrumental music. Given Berkeley'sSTEMeducation, there are a variety of student-run engineering teams that focus on winning design and engineering competitions.\nBerkeley has two prominentamateur rocketryteams: Space Enterprise at Berkeley (SEB)and Space Technologies and Rocketry (STAR).Both have launched solid-fuelsounding rocketsand are currently developingliquid propellant rockets. The university also has twoFormula SAEteams: Berkeley Formula Racingand Formula Electric Berkeley.Both of these teams participate in Formula SAE–run competitions, with the former focusing on internal combustion engines and the latter on electric motors. Berkeley has a number of other vehicle teams, including CalSol,CalSMV,and Human Powered Vehicle. The university's athletic teams are known as theCalifornia Golden Bears, often shortened to \"Cal Bears\" or just \"Cal,\" and were historically members of the NCAA Division IPac-12 Conference(Pac-12). Cal is also a member of theMountain Pacific Sports Federationin several sports not sponsored by the Pac-12 and theAmerica East Conferencein women'sfield hockey. In 2024, Cal joined theAtlantic Coast Conference(ACC).The first school colors, established in 1873 by a committee of students, wereYale Blueand gold.Yale Blue was originally chosen because many of the university's inaugural faculty were Yale graduates, including Henry Durant, its first president. Blue and gold were specified and made the official colors of the university and the state colors of California in 1955.In 2014, the athletic department specified a darker blue. TheCalifornia Golden Bearshave won national championships in baseball (2), men's basketball (2), men's crew (15), women's crew (3), football (5), men's golf (1), men's gymnastics (4), men's lacrosse (1), men's rugby (26), softball (1), men's swimming & diving (4), women's swimming & diving (3), men's tennis (1), men's track & field (1), and men's water polo (13). Students and alumni have also won207 Olympic medals. California finished in first place in the 2007–08 Fall U.S. Sports Academy Directors' Cup standings (now theNACDA Directors' Cup), a competition measuring the best overall collegiate athletic programs in the country, with points awarded for national finishes in NCAA sports.It finished the 2007–08 competition in seventh place with 1119 points.Most recently, California finished in third place in the 2010–11 NACDA Directors' Cup with 1219.50 points, finishing behind Stanford and Ohio State. This is California's highest ever finish in the Director's Cup.The Golden Bears' traditional arch-rival is theStanford Cardinal, and the most anticipated sporting event between the two universities is the annual football match dubbed theBig Game, celebrated with spirit events on both campuses. Since 1933, the winner of the Big Game has been awarded custody ofthe Stanford Axe. Other sporting games between these rivals have related names such as the Big Splash (water polo) or the Big Kick (soccer). Alumni have included 260American Academy of Arts and SciencesFellows,34Pulitzer Prizewinners, 25living billionaire alumni,22cabinetmembers, 68 recipients of theNational Medal of Science, 190 recipients of theMacArthur Fellowship,144 members of theNational Academy of Sciences,139Guggenheim Fellows, and 125Sloan Fellows, and 75 members of theNational Academy of Engineering. Berkeley alumni have served in a range of prominent government offices, both domestic and foreign, includingChief Justice of the United States Supreme Court(Earl Warren, BA, JD);United States Attorney General(Edwin MeeseIII, JD);United States Secretary of State(Dean Rusk, LLB);United States Secretary of the Treasury(W. Michael Blumenthal, BA, andG. William Miller, JD);United States Secretary of Defense(Robert McNamara, BS);United States Secretary of the Interior(Franklin Knight Lane, 1887);United States Secretary of TransportationandUnited States Secretary of Commerce(Norman Mineta, BS);United States Secretary of Agriculture(Ann Veneman, MPP);National Security Advisor(Robert C. O'Brien, JD); scores of federal judges and members of theUnited States Congress(10 currently serving) andUnited States Foreign Service; governors of California (George C. Pardee;Hiram W. Johnson;Earl Warren, BA and LLB;Jerry Brown, BA; andPete Wilson, JD), Michigan (Jennifer Granholm, BA), and the United States Virgin Islands (Walter A. Gordon, BA); Lieutenant General of the United States Army (Jimmy Doolittle, BA); Major General of the United States Marine Corps (Oliver Prince Smith); Brigadier General of the United States Marine Corps (Bertram A. Bone, BS);Director of the Central Intelligence Agencyand Chairman of the Atomic Energy Commission (John A. McCone, BS); chair and members of theCouncil of Economic Advisers(Michael Boskin, BA, PhD.; Sandra Black, BA; Jesse Rothstein, PhD; Robert Seamans, PhD; Jay Shambaugh, PhD; James Stock, MA, PhD); Governor of the Federal Reserve System (H. Robert Heller, PhD) and President and CEO of the Federal Reserve Bank of New York (William C. Dudley, PhD); Commissioners of theSEC(Troy A. Paredes, BA) and theFCC(Rachelle Chong, BA); andUnited States Surgeon General(Kenneth P. Moritsugu, MPH).\nForeign alumni include thePresident of Colombia1922–1926, (Pedro Nel Ospina Vázquez, BA); thePresident of Mexico(Francisco I. Madero, attended 1892–93); the President and Prime Minister of Pakistan; the Premier of the Republic of China (Sun Fo, BA); the President of Costa Rica (Miguel Angel Rodriguez, MA, PhD); and members of parliament of the United Kingdom (House of Lords,Lydia Dunn, Baroness Dunn, BS), India (Rajya Sabha, the upper house,Prithviraj Chavan, MS); Iran (Mohammad Javad Larijani, PhD); Nigerian Minister of Science and Technology and first Executive Governor of Abia State (Ogbonnaya Onu, PhD); Barbados' Ambassador to Brazil (Tonika Sealy-Thompson, PhD). Alumni have also served in many supranational posts, notable among which are President of theWorld Bank(Robert McNamara, BS); Deputy Prime Minister of Spain and managing director of theInternational Monetary Fund(Rodrigo Rato, MBA); executive director ofUNICEF(Ann Veneman, MPP); member of theEuropean Parliament(Bruno Megret, MS); and judge of theWorld Court(Joan Donoghue, JD). NobellaureateWilliam F. Giauque(BS 1920, PhD 1922) investigatedchemical thermodynamics, Nobel laureateWillard Libby(BS 1931, PhD 1933) pioneeredradiocarbon dating, Nobel laureateWillis Lamb(BS 1934, PhD 1938) examined thehydrogenspectrum, Nobel laureateHamilton O. Smith(BA 1952) appliedrestriction enzymestomolecular genetics, Nobel laureateRobert Laughlin(BA 1972) explored thefractional quantum Hall effect, and Nobel laureateAndrew Fire(BA 1978) helped to discoverRNA interference-gene silencingby double-strandedRNA. Nobel laureateGlenn T. Seaborg(PhD 1937) collaborated withAlbert Ghiorso(BS 1913) to discover twelve chemical elements, such asamericium,berkelium, andcalifornium.David Bohm(PhD 1943) discoveredBohm diffusion. Nobel laureateYuan T. Lee(PhD 1965) developed thecrossed molecular beamtechnique for studying chemical reactions.Carol Greider(PhD 1987) was awarded the 2009Nobel Prize in medicinefor discovering a key mechanism in the genetic operations of cells.Harvey Itano(BS 1942) conducted breakthrough work onsickle cell anemiathat marked the first time a disease was linked to a molecular origin. Narendra Karmarkar(PhD 1983) is known for the interior point method, a polynomial algorithm for linear programming known asKarmarkar's algorithm.National Medal of SciencelaureateChien-Shiung Wu(PhD 1940), often known as the \"Chinese Madame Curie\", disproved the Law of Conservation ofParityfor which she was awarded the inauguralWolf Prize in Physics.Kary Mullis(PhD 1973) was awarded the 1993Nobel Prize in Chemistryfor his role in developing thepolymerase chain reaction,a method for amplifyingDNAsequences.Olga Hartman(MA 1933, PhD 1936) was a zoologist who described hundreds of species ofpolychaete worms.Edward P. Tryon(PhD 1967) is the physicist who first said our universe originated from a quantum fluctuation of the vacuum.John N. Bahcall(BS 1956) worked on theStandard Solar Modeland theHubble Space Telescope,resulting in aNational Medal of Science.Peter Smith(BS 1969) was theprincipal investigatorand project leader for theNASArobotic explorerPhoenix,which physically confirmed the presence of water on the planetMarsfor the first time.AstronautsJames van Hoften(BS 1966),Margaret Rhea Seddon(BA 1970),Leroy Chiao(BS 1983), andRex Walheim(BS 1984) have orbited the Earth in NASA's fleet ofSpace Shuttles. Berkeley alumni have developed a number of key technologies associated with thepersonal computerand the Internet.Unixwas created by alumnusKen Thompson(BS 1965, MS 1966) along with colleagueDennis Ritchie. Alumni such asL. Peter Deutsch(PhD 1973),Butler Lampson(PhD 1967), andCharles P. Thacker(BS 1967)worked with Ken Thompson onProject Genieand then formed the ill-fatedUS Department of Defense-funded Berkeley Computer Corporation (BCC), which was scattered throughout the Berkeley campus in non-descript offices to avoid anti-war protestors.After BCC failed, Deutsch, Lampson, and Thacker joinedXerox PARC, where they developed a number of pioneering computer technologies, culminating in theXerox Altothat inspired theApple Macintosh. In particular, the Alto used acomputer mouse, which had been invented byDoug Engelbart(BEng 1952, PhD 1955). Thompson, Lampson, Engelbart, and Thackerall later received a Turing Award. Also at Xerox PARC was Ronald Schmidt (BS 1966, MS 1968, PhD 1971), who became known as \"the man who broughtEthernetto the masses.\" Another Xerox PARC researcher,Charles Simonyi(BS 1972), pioneered the firstWYSIWIGword processorprogram and was recruited personally byBill Gatesto join the fledgling company known asMicrosoftto createMicrosoft Word. Simonyi later became the first repeatspace tourist, blasting off on RussianSoyuzrockets to work at theInternational Space Stationorbiting the Earth. In 1977, a graduate student in the computer science department named Bill Joy (MS 1982) assembledthe originalBerkeley Software Distribution, commonly known asBSD Unix. Joy, who went on to co-found Sun Microsystems, also developed the original version of theterminalconsole editorvi, whileKen Arnold(BA 1985) createdCurses, a terminal controllibraryforUnix-likesystems that enables the construction oftext user interface (TUI)applications. Working alongside Joy at Berkeley were undergraduatesWilliam Jolitz(BS 1997) and his future wifeLynne Jolitz(BA 1989), who together created386BSD, a version of BSD Unix that runs on Intel CPUs and evolved into theBSD family of free operating systemsand theDarwin operating systemunderlying AppleMac OS X.Eric Allman(BS 1977, MS 1980) createdSendMail, a Unixmail transfer agentthat delivers about twelve percent of theemailin the world. TheXCF, an undergraduate research group located inSoda Hall, has been responsible for a number of notable software projects, includingGTK+(Peter Mattis, BS 1997),The GIMP(Spencer Kimball, BS 1996), and the initial diagnosis of theMorris worm.In 1992,Pei-Yuan Wei(BS 1990)an undergraduate at the XCF, createdViolaWWW, one of the first graphical web browsers. ViolaWWW was the first browser to have embedded scriptable objects, stylesheets, and tables. He donated the code to Sun Microsystems, inspiringJavaapplets. ViolaWWW also inspired researchers at theNational Center for Supercomputing Applicationsto create theMosaic web browser,a pioneeringweb browserthat became MicrosoftInternet Explorer. Billionaire alumniincludeGordon Moore(Intel founder),James Harris Simons(Renaissance Technologies),Masayoshi Son(SoftBank),Jon Stryker (Stryker Medical Equipment),Eric Schmidt(former Google Chairman) andWendy Schmidt,Michael Milken, Bassam Alghanim, Kutayba Alghanim,Charles Simonyi(Microsoft),Cher Wang(HTC),Robert Haas(Levi Strauss & Co.),Carlos Rodríguez-Pastor(Interbank, Peru),Fayez Sarofim,Daniel S. Loeb,Paul Merage,David Hindawi,Orion Hindawi,Bill Joy(Sun Microsystems founder),Victor Koo,Tony Xu(DoorDash),Lowell Milken,Nathaniel Simonsand Laura Baxter-Simons, Liong Tek Kwee and Liong Seen Kwee,Elizabeth Simons and Mark Heising,Oleg Tinkov, andAlice Schwartz. Pulitzer Prize–winning journalistMarguerite Higgins(BA 1941) was a pioneering female war correspondentwho covered World War II, theKorean War, and theVietnam War.NovelistRobert Penn Warren(MA 1927) won three Pulitzer Prizes,including one for his novelAll the King's Men, which was later made into an Academy Award-winningmovie. Pulitzer Prize–winning cartoonistRube Goldberg(BS 1904) invented the comically complex—yet ultimately trivial—contraptions known asRube Goldberg machines. Journalist Alexandra Berzon (MA 2006) won a Pulitzer Prize in 2009,and journalistMatt Richtel(BA 1989), who also coauthors the comic stripRudy Parkunder the pen name of \"Theron Heir\",won the 2010Pulitzer Prize for National Reporting.Pulitzer Prize–winning historianLeon Litwack(BA1951, PhD 1958) taught as a professor at UC Berkeley for 43 years;three otherUC Berkeley professors have also received the Pulitzer Prize. Alumna and professorSusan Rasky(BA 1974) won thePolk Awardfor journalism in 1991. USC Professor and Berkeley alumnusViet Thanh Nguyen's (PhD 1997) first novelThe Sympathizerwon the 2016Pulitzer Prize for Fiction. Irving Stone(BA 1923) wrote the novelLust for Life, which was later made into an Academy Award-winningfilm of the same namestarringKirk DouglasasVincent van Gogh. Stone also wroteThe Agony and the Ecstasy, which was later made into afilm of the same namestarring Oscar winnerCharlton HestonasMichelangelo.Mona Simpson(BA 1979) wrote the novelAnywhere But Here, which was later made into a film of the same name starring Oscar-winning actressSusan Sarandon.Terry McMillan(BA 1986) wroteHow Stella Got Her Groove Back, which was later made into a film of the same name starring Oscar-nominated actressAngela Bassett.Randi Mayem Singer(BA 1979) wrote the screenplay forMrs. Doubtfire, which starred Oscar-winning actorRobin Williamsand Oscar-winning actressSally Field.Audrey Wells(BA 1981) wrote the screenplayThe Truth About Cats & Dogs, which starred Oscar-nominated actressUma Thurman.James Schamus(BA 1982, MA 1987, PhD 2003) collaborated on screenplays with Oscar-winning directorAng Leeon the Academy Award-winning moviesCrouching Tiger, Hidden DragonandBrokeback Mountain. Berkeley alumni have won 20Academy Awardsand 25Emmy Awards.Gregory Peck(BA 1939), nominated for four Oscars during his career, won an Oscar for acting inTo Kill a Mockingbird.Chris Innis(BA 1991) won the 2010 Oscar for film editing for her work on best picture winner,The Hurt Locker.Walter Plunkett(BA 1923) won an Oscar for costume design (forAn American in Paris).Freida Lee Mock(BA 1961) andCharles H. Ferguson(BA 1978) have eachwon an Oscar for documentary filmmaking. Mark Berger (BA 1964) has won four Oscars for sound mixing and is an adjunct professor at UC Berkeley.Edith Head(BA 1918), who was nominated for 34 Oscars during her career, won eight Oscars for costume design.Joe Letteri(BA 1981) has won four Oscars for Best Visual Effects in theJames CameronfilmAvatarand thePeter JacksonfilmsKing Kong,The Two Towers, andThe Return of the King.Emmy Awardwinners include Jon Else (BA 1968) for cinematography;Andrew Schneider(BA 1973) for screenwriting; Linda Schacht (BA 1966, MA 1981), two for broadcast journalism;Christine Chen (dual-BA's 1990), two for broadcast journalism;Kathy Baker(BA 1977), three for acting; Ken Milnes (BS 1977), four for broadcasting technology; andLeroy Sievers(BA 1977),twelve for production.Elisabeth Leamy(BA 1989) is the recipient of thirteenEmmy awards. Former undergraduates have participated in the contemporary music industry, such asGrateful Deadbass guitaristPhil Lesh,the PolicedrummerStewart Copeland,Rolling Stone MagazinefounderJann Wenner,the Bangleslead singerSusanna Hoffs(BA 1980),Counting Crowslead singerAdam Duritz, electronic music producerGiraffage,MTVcorrespondentSuchin Pak(BA 1997),AFImusiciansDavey HavokandJade Puget(BA 1996), and solo artistMarié Digby(\"Say It Again\").People MagazineincludedThird Eye Blindlead singer and songwriterStephan Jenkins(BA 1987) in the magazine's list of50 Most Beautiful People.Alumni have also acted in classic television series such asKaren Grassle(BA 1965) who playedCaroline IngallsinLittle House on the Prairie,Jerry Mathers(BA 1974) who starred inLeave it to Beaver, andRoxann Dawson(BA 1980) who portrayedB'Elanna TorresonStar Trek: Voyager. Sport alumni include tennis athleteHelen Wills Moody(BA 1925) won 31Grand Slamtitles, including eight singles titles atWimbledon.Tarik Glenn(BA 1999) is aSuper Bowl XLIchampion.Michele Tafoya(BA 1988) is a sports television reporter forABC SportsandESPN.Sports agentLeigh Steinberg(BA 1970, JD 1973) has represented professional athletes such asSteve Young,Troy Aikman, andOscar De La Hoya; Steinberg has been called the real-life inspirationfor the title character in the Oscar-winningfilmJerry Maguire(portrayed byTom Cruise).Matt Biondi(BA 1988) won eight Olympic gold medals during his swimming career, in which he participated in three different Olympics. At theBeijing Olympicsin 2008,Natalie Coughlin(BA 2005) became the first American female athlete in modern Olympic history to win six medals in one Olympics.", "metadata": {"url": "https://en.wikipedia.org/wiki/University_of_California,_Berkeley", "title": "University of California, Berkeley", "headings": ["Contents", "History", "Founding", "20th century", "21st century", "Controversies", "Organization and administration", "Name", "Governance", "Funding", "Academics", "Faculty and departments", "Undergraduate programs", "Graduate and professional programs", "Library system", "Reputation and rankings", "Admissions and enrollment", "Discoveries and innovation", "Natural sciences", "Computer and applied sciences", "Companies and entrepreneurship", "Campus", "Architecture", "Natural features", "Student life and traditions", "Student housing", "Student-run organizations", "Athletics", "Notable alumni, faculty, and staff", "Faculty and staff", "Alumni", "See also", "Notes", "References", "Further reading", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/University_of_California,_Berkeley", "https://en.wikipedia.org/wiki/University_of_California,_Berkeley", "https://en.wikipedia.org/wiki/University_of_California,_Berkeley", "https://en.wikipedia.org/wiki/Geographic_coordinate_system", "https://en.wikipedia.org/wiki/Berkeley_College_(disambiguation)", "https://en.wikipedia.org/wiki/Let_there_be_light", "https://en.wikipedia.org/wiki/Latin", "https://en.wikipedia.org/wiki/Public_university"]}},
{"id": "45c4fe3327b6", "content": "UML colorstandards are a set of four colors associated withUnified Modeling Language(UML) diagrams. The coloring system indicates which of severalarchetypesapply to the UML object. UML typically identifies astereotypewith a bracketed comment for each object identifying whether it is a class, interface, etc. These colors were first suggested byPeter Coad,Eric Lefebvre, andJeff De Lucain a series of articles inThe Coad Letter,and later published in their bookJava Modeling In Color With UML. Over hundreds of domain models, it became clear that four major \"types\" of classes appeared again and again, though they had different names in different domains. After much discussion, these were termedarchetypes, which is meant to convey that the classes of a given archetype follow more or less the same form. That is,attributes,methods,associations, andinterfacesare fairly similar among classes of a given archetype. When attempting to classify a given domain class, one typically asks about the color standards in this order: Although the actual colors vary, most systems tend to use lighter color palettes so that black text can also be easily read on a colored background. Coad, et al., used the 4-color pastelPost-it notes,and later had UML modeling tools support the color scheme by associating a color to one or more class stereotypes. Many people feel colored objects appeal to the pattern recognition section of the brain.  Others advocate that you can begin a modeling process with a stack of four-color note cards or colored sticky notes. The value of color modeling was especially obvious when standing back from a model drawn or projected on a wall. That extra dimension allowed modelers to see important aspects of the models (the pink classes, for instance), and to spot areas that may need reviewing (unusual combinations of color classes linked together). The technique also made it easy to help determine aspects of the domain model – especially for newcomers to modeling. For example, by simply looking first for \"pinks\" in the domain, it was easy to begin to get some important classes identified for a given domain. It was also easy to review the standard types of attributes, methods, and so on, for applicability to the current domain effort.", "metadata": {"url": "https://en.wikipedia.org/wiki/Object_Modeling_in_Color", "title": "Object Modeling in Color", "headings": ["Contents", "See also", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Object_Modeling_in_Color", "https://en.wikipedia.org/wiki/Object_Modeling_in_Color", "https://en.wikipedia.org/wiki/Object_Modeling_in_Color", "https://en.wikipedia.org/wiki/Unified_Modeling_Language", "https://en.wikipedia.org/wiki/Stereotype_(UML)", "https://en.wikipedia.org/wiki/Peter_Coad", "https://en.wikipedia.org/wiki/Eric_Lefebvre", "https://en.wikipedia.org/wiki/Jeff_De_Luca"]}},
{"id": "b8cea52682aa", "content": " Simplified Chinese charactersare one of two standardizedcharacter setswidely used to write theChinese language, with the other beingtraditional characters. Their mass standardization during the 20th century was part of an initiative by thePeople's Republic of China(PRC) to promote literacy, and their use in ordinary circumstances on the mainland has been encouraged by the Chinese government since the 1950s.They are the standard forms used inmainland China,Malaysia, andSingapore, while traditional characters are officially used inHong Kong,Macau, andTaiwan. Simplification of a component—either a character or a sub-component called aradical—usually involves either a reduction in its total number ofstrokes, or an apparent streamlining of which strokes are chosen in what places—for example, the⼓'WRAP'radical used in the traditional character沒is simplified to⼏'TABLE'to form the simplified character没.By systematically simplifying radicals, large swaths of the character set are altered. Some simplifications were based on popularcursiveforms that embody graphic or phonetic simplifications of the traditional forms. In addition, variant characters with identical pronunciation and meaning were reduced to a single standardized character, usually the simplest among all variants in form. Finally, many characters were left untouched by simplification and are thus identical between the traditional and simplified Chinese orthographies. The Chinese government has never officially announced the completion of the simplification process after the bulk of characters were introduced by the 1960s. In the wake of theCultural Revolution, asecond round of simplified characterswas promulgated in 1977—largely composed of entirely new variants intended to artificially lower the stroke count, in contrast to the first round—but was massively unpopular and never saw consistent use. The second round of simplifications was ultimately retracted officially in 1986, well after they had largely ceased to be used due to their unpopularity and the confusion they caused. In August 2009, China began collecting public comments for a revised list of simplified characters;the resultingList of Commonly Used Standard Chinese Characterslists 8,105 characters, including a few revised forms, and was implemented for official use by China'sState Councilon 5 June 2013. In Chinese, simplified characters are referred to by their official name简化字;jiǎnhuàzì, or colloquially as简体字;jiǎntǐzì. The latter term refers broadly to all character variants featuring simplifications of character form or structure,a practice which has always been present as a part of the Chinese writing system. The official name tends to refer to the specific, systematic set published by the Chinese government, which includes not only simplifications of individual characters, but also a substantial reduction in the total number of characters through the merger of formerly distinct forms. According to Chinese palaeographerQiu Xigui, the broadest trend in the evolution of Chinese characters over their history has been simplification, both in graphicalshape(字形;zìxíng), the \"external appearances of individual graphs\", and in graphicalform(字体;字體;zìtǐ), \"overall changes in the distinguishing features of graphic[al] shape and calligraphic style, [...] in most cases refer[ring] to rather obvious and rather substantial changes\".The initiatives following the founding of theQin dynasty(221–206 BC) to universalize the use of theirsmall seal scriptacross the recently conquered parts of the empire is generally seen as being the first real attempt at script reform in Chinese history. Before the 20th century, variation in character shape on the part of scribes, which would continue with the later invention ofwoodblock printing, was ubiquitous. For example, prior to theQin dynasty(221–206 BC) the character meaning 'bright' was written as either明or朙—with either日'Sun'or囧'window'on the left, with the月'Moon'componenton the right.Li Si(d.208 BC), theChancellorof Qin, attempted to universalize the Qinsmall seal scriptacross China followingthe warsthat had politically unified the country for the first time. Li prescribed the朙form of the character for 'bright', but some scribes ignored this and continued to write the character as明. However, the increased usage of朙was followed by proliferation of a third variant:眀, with目'eye'on the left—likely derived as a contraction of朙. Ultimately,明became the character's standard form. TheBook of Han(111 AD) describes an earlier attempt made byKing Xuan of Zhou(d.782 BC) to unify character forms across thestates of ancient China, with his chief chronicler having \"[written] fifteen chapters describing\" what is referred to as the \"big seal script\". The traditional narrative, as also attested in theShuowen Jiezidictionary (c.100 AD), is that the Qinsmall seal scriptthat would later be imposed across China was originally derived from the Zhou big seal script with few modifications. However, the body of epigraphic evidence comparing the character forms used by scribes gives no indication of any real consolidation in character forms prior to the founding of the Qin.TheHan dynasty(202 BC – 220 AD) that inherited the Qin administration coincided with the perfection ofclerical scriptthrough the process oflibian. Though most closely associated with the People's Republic, the idea of a mass simplification of character forms first gained traction in China during the early 20th century. In 1909, the educator and linguistLufei Kuiformally proposed the use of simplified characters in education for the first time. Over the following years—marked by the 1911Xinhai Revolutionthat toppled theQing dynasty, followed by growing social and political discontent that further erupted into the 1919May Fourth Movement—many anti-imperialist intellectuals throughout China began to see the country's writing system as a serious impediment to its modernization. In 1916, a multi-part English-language article entitled \"The Problem of the Chinese Language\" co-authored by the Chinese linguistYuen Ren Chao(1892–1982) and poetHu Shih(1891–1962) has been identified as a turning point in the history of the Chinese script—as it was one of the first clear calls for China to move away from the use of characters entirely.Instead, Chao proposed that the language be written with an alphabet, which he saw as more logical and efficient. The alphabetization and simplification campaigns would exist alongside one another among the Republican intelligentsia for the next several decades. Recent commentators have echoed some contemporary claims that Chinese characters were blamed for the economic problems in China during that time.Lu Xun, one of the most prominent Chinese authors of the 20th century, stated that \"if Chinese characters are not destroyed, then China will die\" (漢字不滅，中國必亡). During the 1930s and 1940s, discussions regarding simplification took place within the rulingKuomintang(KMT) party. Many members of the Chinese intelligentsia maintained that simplification would increase literacy rates throughout the country. In 1935, theRepublic of ChinaMinistry of Education published the first official list of simplified forms, consisting of 324 characters collated byPeking UniversityprofessorQian Xuantong. However, fierce opposition within the KMT resulted in the list being rescinded in 1936. Work throughout the 1950s resulted in the 1956 promulgation of theChinese Character Simplification Scheme, a draft of 515 simplified characters and 54 simplified components, whose simplifications would be present in most compound characters. Over the following decade, the Script Reform Committee deliberated on characters in the 1956 scheme, collecting public input regarding the recognizability of variants, and often approving forms in small batches. Parallel to simplification, there were also initiatives aimed at eliminating the use of characters entirely and replacing them withpinyinas an official Chinese alphabet, but this possibility was abandoned, confirmed by a speech given byZhou Enlaiin 1958.In 1965, the PRC published theList of Commonly Used Characters for Printing[zh](hereafterCharacters for Printing), which included standard printed forms for 6196 characters, including all of the forms from the 1956 scheme. Asecond round of simplified characterswas promulgated in 1977, but was poorly received by the public and quickly fell out of official use. It was ultimately formally rescinded in 1986.The second-round simplifications were unpopular in large part because most of the forms were completely new, in contrast to the familiar variants comprising the majority of the first round.With the rescission of the second round, work toward further character simplification largely came to an end. In 1986, authorities retracted the second round completely, though they had been largely fallen out of use within a year of their initial introduction. That year, the authorities also promulgated a final version of theGeneral List of Simplified Chinese Characters. It was identical to the 1964 list save for 6 changes—including the restoration of 3 characters that had been simplified in the first round:叠,覆,像; the form疊is used instead of叠in regions using traditional characters. The Chinese government stated that it wished to keep Chinese orthography stable. TheChart of Generally Utilized Characters of Modern Chinesewas published in 1988 and included7000simplified and unsimplified characters. Of these, half were also included in the revisedList of Commonly Used Characters in Modern Chinese, which specified2500common characters and1000less common characters.In 2009, the Chinese government published a major revision to the list which included a total of8300characters. No new simplifications were introduced. In addition, slight modifications to the orthography of 44 characters to fit traditional calligraphic rules were initially proposed, but were not implemented due to negative public response.Also, the practice of unrestricted simplification of rare and archaic characters by analogy using simplified radicals or components is now discouraged. A State Language Commission official cited \"oversimplification\" as the reason for restoring some characters. The language authority declared an open comment period until 31 August 2009, for feedback from the public. In 2013, theList of Commonly Used Standard Chinese Characterswas published as a revision of the 1988 lists; it included a total of8105characters.It included 45 newly recognized standard characters that were previously considered variant forms, as well as official approval of 226 characters that had been simplified by analogy and had seen wide use but were not explicitly given in previous lists or documents. Singaporeunderwentthree successive rounds of character simplification, eventually arriving at the same set of simplified characters as mainland China.The first round was promulgated by theMinistry of Educationin 1969, consisting of 498 simplified characters derived from 502 traditional characters. A second round of 2287 simplified characters was promulgated in 1974. The second set contained 49 differences from the mainland China system; these were removed in the final round in 1976. In 1993, Singapore adopted the 1986 mainland China revisions. Unlike in mainland China, Singapore parents have the option of registering their children's names in traditional characters. Malaysia also promulgated a set of simplified characters in 1981, though completely identical to the mainland Chinese set. They are used in Chinese-language schools. All characters simplified this way are enumerated in Charts 1 and 2 of the 1986General List of Simplified Chinese Characters, hereafter theGeneral List. All characters simplified this way are enumerated in Chart 1 and Chart 2 in the 1986Complete List. Characters in both charts are structurally simplified based on similar set of principles. They are separated into two charts to clearly mark those in Chart 2 as 'usable as simplified character components', based on which Chart 3 is derived. Merging homophonous characters: Adapting cursive shapes(草書楷化): Replacing a component with a simple arbitrary symbol(such as又and乂): Omitting entire components: Omitting components, then applying further alterations: Structural changes that preserve the basic shape Replacing the phonetic component ofphono-semantic compounds: Replacing an uncommon phonetic component: Replacing entirely with a newly coined phono-semantic compound: Removing radicals Only retaining single radicals Replacing with ancient forms or variants: Adopting ancient vulgar variants: Readopting abandoned phonetic-loan characters: Copying and modifying another traditional character: Based on 132 characters and 14 components listed in Chart 2 of theComplete List, the 1,753 derived characters found in Chart 3 can be created by systematically simplifying components using Chart 2 as a conversion table. While exercising such derivation, the following rules should be observed: Sample derivations: The Series One List of Variant Characters reduces the number of total standard characters. First, amongst each set of variant characters sharing identical pronunciation and meaning, one character (usually the simplest in form) is elevated to the standard character set, and the rest are made obsolete. Then amongst the chosen variants, those that appear in the \"Complete List of Simplified Characters\" are also simplified in character structure accordingly. Some examples follow: Sample reduction of equivalent variants: Ancient variants with simple structure are preferred: Simpler vulgar forms are also chosen: The chosen variant was already simplified in Chart 1: In some instances, the chosen variant is actually more complex than eliminated ones. An example is the character搾which is eliminated in favor of the variant form榨. The扌'HAND'with three strokes on the left of the eliminated搾is now seen as more complex, appearing as the⽊'TREE'radical木, with four strokes, in the chosen variant榨. Not all characters standardised in the simplified set consist of fewer strokes. For instance, the traditional character強, with 11 strokes is standardised as强, with 12 strokes, which is a variant character. Such characters do not constitute simplified characters. The new standardized character forms shown in theCharacters for Publishingand revised through theCommon Modern Characterslist tend to adopt vulgar variant character forms. Since the new forms take vulgar variants, many characters now appear slightly simpler compared to old forms, and as such are often mistaken as structurally simplified characters. Some examples follow: The traditional component釆becomes米: The traditional component囚becomes日: The traditional \"Break\" stroke becomes the \"Dot\" stroke: The traditional components⺥and爫become⺈: The traditional component奐becomes奂: A commonly cited example of the irregularity of simplification involves characters that share the \"hand\" component又, which is used in many simplified characters. While there is an observable pattern involving the replacement of 𦰩 with 又 as seen in漢→汉,難→难,癱→瘫,嘆→叹,灘→滩, when observing that歎→叹,歡→欢,勸→劝,灌(not simplified) and罐(not simplified), an inconsistency arises. This is due to the fact that in the Complete List of Simplified Characters,漢→汉appears in Chart 1 while難→难is listed in Chart 2 and癱→瘫as a derived character in the non-exhaustive list in Chart 3. Therefore,难is defined as a 'simplified character component' according to the standard, while又is not. Based on难,癱is simplified to瘫, and灘to滩. Since both歡→欢and勸→劝appear in Chart 1, they are not defined as derived characters. There are therefore no characters or components found in Chart 2 usable for derivation of灌and罐. Further investigation reveals that these two characters do not appear in Chart 1 nor in \"Series One Organization List of Variant Characters\". Thus they remain unchanged from traditional forms in theCommon Modern Characterslist. The People's Republic of China and Singapore generally use simplified characters. They appear very sparingly in texts originating in Hong Kong, Macau, Taiwan, and overseas Chinese communities, although they are becoming more prevalent as mainland China becomes more integrated globally. The Law of the People's Republic of China on the National Common Language and Characters implies that simplified Chinese characters are the country's standard script, with traditional Chinese being used for purposes such as ceremonies, cultural purposes such as calligraphy, for decoration, in publications and books on ancient literature and poetry, and for research purposes. Traditional characters remain ubiquitous on buildings that predate the promotion of simplified characters, such as former government buildings, religious buildings, educational institutions, and historical monuments. Traditional characters are also often used for commercial purposes, such as in shopfront displays and advertisements. As part of theone country, two systemsmodel, the PRC has not attempted to force Hong Kong or Macau into using simplified characters. The PRC tends to print material intended for people in Hong Kong, Macau and Taiwan, and overseas Chinese in traditional characters. For example, versions of thePeople's Dailyare printed in traditional characters, and bothPeople's DailyandXinhuahave traditional character versions of their website available, usingBig5encoding. Mainland companies selling products in Hong Kong, Macau and Taiwan use traditional characters in order to communicate with consumers; the reverse is also true. Dictionaries published in mainland China generally show both simplified and their traditional counterparts. In digital media, many cultural phenomena imported from Hong Kong and Taiwan into mainland China, such as music videos, karaoke videos, subtitled movies, and subtitled dramas, use traditional Chinese characters. Textbooks, official statements, and newspapers show no signs of moving to simplified Chinese characters, including state-funded media. However, for example, Hong Konger students sometimes opt to write with simplified characters when taking notes or while taking exams, in order to write faster. It is common for Hong Kongers to learn traditional Chinese characters in school, as well as some simplified characters incidentally, usually by consuming media produced on the mainland. For use on computers, however, people tend to type Chinese characters using an IME with a traditional character set, such as Big5. In Hong Kong, as well as elsewhere, it is common for people to use both sets, due to the ease of conversion between the two sets. Simplified characters are not used in any official capacity in Taiwan, including in government and civil publications in Taiwan. However, they are sometimes used in calligraphy and informal handwriting.It is also legal to import and distribute publications printed in simplified characters. Specific simplified forms predating the 20th century are in common use, such as台, the first character in the name \"Taiwan\", rivalling the orthodox form臺even in publications and academic contexts. In Singapore, where Mandarin Chinese is one of the official languages, simplified characters are the official standard and are generally used in most of official publications as well as the government-controlled press. While simplified characters are taught exclusively in schools and are generally used in most of official publications, the government does not officially discourage the use of traditional characters and still allow parents to choose whether to have their child's Chinese name registered in simplified or traditional characters. Traditional characters are widely used by older Singaporeans, and are widespread on billboards, stall menus, and decorations, as well as in newspapers and on television. There is no restriction on the use of traditional characters in mass media, and television programs, books, magazines and music imported from Hong Kong and Taiwan are widely available, almost always using traditional characters. Many shop signs and menus inhawker centresand coffee shops continue to be written with traditional characters. Chinese is not an official language in Malaysia, but over 90% of ethnic-Chinese students in the country are educated in Chinese schools, which have been teaching in simplified characters since 1981.Traditional characters are also widely used by older people and are likewise widespread on billboards, to a greater extent than in Singapore.Most of Malaysia's Chinese-language newspapers compromise by retaining traditional characters in article headlines, but opting to use simplified characters for the bodies of articles. In Indonesia, Chinese is not an official language. However, the country is also home to a sizable ethnic-Chinese community, and similarly to Malaysia, ethnic-Chinese students typically receive their education in Chinese-language schools that almost exclusively use simplified characters. Traditional characters are seldom used, typically only for stylistic purposes. In general, schools in mainland China, Malaysia and Singapore use simplified characters exclusively, while schools in Hong Kong, Macau, and Taiwan use traditional characters exclusively. Today, simplified Chinese characters predominate among college and university programs teaching Chinese as a foreign language outside of China,such as those in the United States. In December 2004, Ministry of Education authorities rejected a proposal from a BeijingChinese People's Political Consultative Conference(CPPCC) political conference member that called for elementary schools to teach traditional Chinese characters in addition to the simplified ones. The conference member pointed out that many, especially young people, have difficulties with traditional Chinese characters; this is especially important in dealing with non-mainland communities such as Taiwan and Hong Kong. The educational authorities did not approve the recommendation, saying that it did not fit in with the \"requirements as set out by the law\" and it could potentially complicate the curricula.A similar proposal was delivered to the first plenary session of the 11th CPPCC in March 2008. Most, if not all, Chinese-language textbooks in Hong Kong are written in traditional characters. Before 1997, the use of simplified characters was generally discouraged by educators.After 1997, while students are still expected to be proficient and utilize traditional characters in formal settings, they may sometimes adopt a hybrid written form in informal settings to speed up writing. Chinese textbooks in Singapore, Malaysia and Indonesia are written exclusively in simplified characters, and only simplified characters are taught in school. Traditional characters are usually only taught to those taking up calligraphy as aco-curricular activityor Cantonese as an elective course at school. The majority of textbooks teaching Chinese are now based on simplified characters and Hanyu Pinyin – although there are textbooks originating in China which have a traditional version. For practical reasons, universities and schools prepare students who will be able to communicate with mainland China, so their obvious choice is to use simplified characters. In places where a particular set is not locally entrenched, such as Europe and the United States, instruction is now mostly simplified, as the economic importance of mainland China increases, and also because of the availability of textbooks printed in mainland China. Teachers of international students often recommend learning both systems. In the United Kingdom, universities mainly teach Mandarin Chinese at the undergraduate level using the simplified characters coupled with pinyin. However, they will require the students to learn or be able to recognise the traditional forms if they are studying in Taiwan or Hong Kong (such as taking Cantonese courses). In Australia and New Zealand, schools, universities andTAFEsuse predominantly simplified characters. Russia and most East European nations are traditionally oriented on the education of the PRC's system for teaching Chinese, which uses simplified characters but exposes the learners to both systems. InSouth Korea, universities have used predominantly simplified characters since the 1990s. In high school, Chinese is one of the selective subjects. By the regulation of the national curricula standards,bopomofoand traditional characters had been originally used before (since the 1940s), but by the change of regulation, pinyin and simplified characters have been used to pupils who enter the school in 1996 or later. Therefore, bopomofo and traditional characters disappeared after 1998 in South Korean high school Chinese curriculum. In Japan there are two types of schools. Simplified Chinese is taught instead of traditional Chinese in pro-mainland China schools. They also teach Pinyin, a romanization system for standard Chinese, while the Taiwan-oriented schools teach bopomofo, which uses phonetic symbols. However, the Taiwan-oriented schools are starting to teach simplified Chinese and pinyin to offer a more well-rounded education. In thePhilippines, the use of simplified characters has become increasingly popular. Before the 1970s, Chinese schools in the Philippines were under the supervision of the Ministry of Education of the Republic of China. Hence, most books were using traditional characters. Traditional characters remained prevalent until the early 2000s. Institutions like theConfucius Institute, being the cultural arm of the People's Republic of China, are strong proponents of the use of simplified characters. Also, many schools are now importing their Mandarin textbooks from Singapore instead of Taiwan. Public universities such as the Linguistics and Asian Languages Department of theUniversity of the Philippinesuse simplified characters in their teaching materials. On the other hand, private schools such asChiang Kai Shek CollegeandSaint Jude Catholic Schoolremain major proponents of the usage of traditional characters. Some private universities, such as theAteneo de Manila University, also use simplified characters. In computer text applications, theGB encoding schememost often renders simplified Chinese characters, while Big5 most often renders traditional characters. Although neither encoding has an explicit connection with a specific character set, the lack of a one-to-one mapping between the simplified and traditional sets established a de facto linkage. Since simplified Chinese conflated many characters into one and since the initial version of the GB encoding scheme, known asGB 2312-80, contained only one code point for each character, it is impossible to use GB 2312 to map to the bigger set of traditional characters. It is theoretically possible to use Big5 code to map to the smaller set of simplified character glyphs, although there is little market for such a product. Newer and alternative forms of GB have support for traditional characters. In particular, mainland authorities have now establishedGB 18030as the official encoding standard for use in all mainland software publications. The encoding contains all East Asian characters included inUnicode3.0. As such, GB 18030 encoding contains both simplified and traditional characters found in Big-5 and GB, as well as all characters found inJapaneseandKoreanencodings. Unicode deals with the issue of simplified and traditional characters as part of the project ofHan unificationby including code points for each. This was rendered necessary by the fact that the linkage between simplified characters and traditional characters is not one-to-one. While this means that a Unicode system can display both simplified and traditional characters, it also means that differentlocalisationfiles are needed for each type. In font filenames and descriptions, the acronym SC is used to signify the use of simplified Chinese characters to differentiate fonts that use TC for traditional characters. TheWorld Wide Web Consortium(W3C)'s Internationalization working group recommends the use of thelanguage tagzh-Hansas a language attribute value and Content-Language value to specify web-page content in simplified Chinese characters. AuthorLiu Shahewas an outspoken critic of the simplification of Chinese characters. He wrote a dedicated column entitled \"Simplified Characters are Unreasonable\" in the Chinese edition of theFinancial Times. Some critics pejoratively refer to Simplified Chinese as 殘體字 meaning \"crippled characters.\"", "metadata": {"url": "https://en.wikipedia.org/wiki/Simplified_Chinese_characters", "title": "Simplified Chinese characters", "headings": ["Contents", "Nomenclature", "History", "Background", "Late Qing literature and Republican-era reform (1850–1949)", "First round of simplification (1949–1977)", "Second round of simplification (1977–1986)", "Since 1986", "Outside mainland China", "Methodology", "Structural simplification", "Derivation based on simplified components", "Elimination of variants", "Novel forms", "Structural simplification", "Simplifying components", "Elimination of allographs", "Novel forms", "Inconsistencies", "Distribution", "Mainland China", "Hong Kong", "Taiwan", "Southeast Asia", "In education", "Mainland China", "Hong Kong", "Singapore, Malaysia and Indonesia", "Chinese as a foreign language", "Use with computers", "Internet usage", "Criticism", "See also", "Notes", "References", "Citations", "Works cited", "Further reading", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Simplified_Chinese_characters", "https://en.wikipedia.org/wiki/Simplified_Chinese_characters", "https://en.wikipedia.org/wiki/Simplified_Chinese_characters", "https://en.wikipedia.org/wiki/Logographic", "https://en.wikipedia.org/wiki/Chinese_Character_Simplification_Scheme", "https://en.wikipedia.org/wiki/General_List_of_Simplified_Chinese_Characters", "https://en.wikipedia.org/wiki/Second_round_of_simplified_Chinese_characters", "https://en.wikipedia.org/wiki/List_of_Commonly_Used_Characters_in_Modern_Chinese"]}},
{"id": "ce6fa862eca5", "content": " Glorious India Award in 2017Society for Technical Communication(STC) Award of Merit in 2017PROSE Awardfor best textbook in Physical Sciences & Mathematics in 2016Toulouse Scholars Award fromUNTin 2016–17IEEE Distinguished Lecturer since 2017 Saraju Mohantyis an Indian-American professor of the Department of Computer Science and Engineering, and the director of the Smart Electronic Systems Laboratory, at theUniversity of North Texasin Denton, Texas.Mohanty received a Glorious India Award – Rich and Famous NRIs of America in 2017 for his contributions to the discipline.Mohanty is a researcher in the areas of \"smart electronics for smart cities/villages\", \"smart healthcare\", \"application-Specific things for efficient edge computing\", and \"methodologies for digital and mixed-signal hardware\".He has made significant research contributions to security by design (SbD) for electronic systems, hardware-assisted security (HAS) and protection,high-level synthesisof digital signal processing (DSP) hardware, andmixed-signal integrated circuitcomputer-aided designandelectronic design automation. Mohanty has been the editor-in-chief (EiC) of theIEEE Consumer Electronics Magazineduring 2016-2021.He has held the Chair of theIEEE Computer Society'sTechnical Committee on Very Large Scale Integrationduring 2014-2018.He holds 4 US patents in the areas of his research, and has published 500 research articles and 5 books.He is ranked among top 2% faculty around the world in Computer Science and Engineering discipline as per the standardized citation metric adopted by the Public Library of Science Biology journal. Saraju Mohanty started his schooling at Lodhachua, Nayagarh, Odisha. After graduating fromBadagada Government High School, Bhubaneswarin 1988, Mohanty completed a 10+2 Science degree fromRajdhani College, Bhubaneswarin 1990. He received his bachelor's degree inelectrical engineeringfrom theCollege of Engineering and Technology, Bhubaneswar,Orissa University of Agriculture and Technology, in 1995. In 1999 Mohanty completed a master's degree in engineering in Systems Science and Automation from theIndian Institute of Sciencein Bangalore, India.His thesis mentors at IISc were Professor K. R. Ramakrishnan and ProfessorMohan Kankanhalli(IEEEFellow)with whom he co-authored his first peer-reviewed paper. Mohanty earned a PhD incomputer engineeringfrom theUniversity of South Floridain 2003. His PhD mentor was ProfessorNagarajan Ranganathan(IEEEFellow andAAASFellow). Mohanty has worked on the Secure Digital Camera (SDC) for real-time security and IP protection at the source end of the information. In the Internet of Things (IoT) framework the SDC can be a sensor node (aka thing) for real-time trustworthy sensing. The SDC can have applications where still image or video digital cameras are needed, such as secure digital video broadcasting, secure video surveillance, electronic passport, and identity card processing. The secure digital camera (SDC) has been adopted by various researchers worldwide. Mohanty has worked tohigh-level synthesis(HLS) or architecture-level synthesis of digital signal processing (DSP) hardware.His methods address energy consumption and power fluctuation in DSP hardware which are heart of consumer electronic systems such that battery life and battery efficiency increases.His nanoelectronic-basedHigh-level synthesistechniques addresses the issue of process variations, the primary issue of nanoelectronic technology, during the high-level synthesis itself before the digital design moves to the detailed and lower levels of design abstractions, such as logic-level or transistor-level. Mohanty has worked on design space exploration and optimization of analog/mixed-signal system on a chip (AMS-SoC) which is essentially the technology representation of a consumer electronics such as a smart mobile phone.The key feature of these design flows is the need for only two manual layout (or physical design) iterations which saves significant design effort. These fast design flows rely on accuratemetamodelsof the analog and mixed-signal circuit components. This research advances the state-of-the art in Design for Excellence (DfX) orDesign for X, such as Design for Variability (DfV) and Design for Cost (DfC).", "metadata": {"url": "https://en.wikipedia.org/wiki/Saraju_Mohanty", "title": "Saraju Mohanty", "headings": ["Contents", "Education", "Scientific contributions", "Contributions to security and IP protection of consumer electronic systems", "Contributions tohigh-level synthesisof digital signal processing (DSP) hardware", "Contributions to analog electronics and mixed-signal circuits", "Selected editor and conference chair positions", "Awards", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Saraju_Mohanty", "https://en.wikipedia.org/wiki/Saraju_Mohanty", "https://en.wikipedia.org/wiki/Saraju_Mohanty", "https://en.wikipedia.org/wiki/Odisha", "https://en.wikipedia.org/wiki/University_of_South_Florida", "https://en.wikipedia.org/wiki/Indian_Institute_of_Science", "https://en.wikipedia.org/wiki/Orissa_University_of_Agriculture_and_Technology", "https://en.wikipedia.org/wiki/Computer_engineering"]}},
{"id": "fc303889e2f5", "content": " This is an alphabetical list of genera of biological viruses.  It includes allgeneraand subgenera of viruses listed by theInternational Committee on Taxonomy of Viruses(ICTV) 2022 release.", "metadata": {"url": "https://en.wikipedia.org/wiki/List_of_virus_genera", "title": "List of virus genera", "headings": ["Contents", "A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L", "M", "N", "O", "P", "Q", "R", "S", "T", "U", "V", "W", "X", "Y", "Z", "Subgenera", "See also", "References"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/List_of_virus_genera", "https://en.wikipedia.org/wiki/List_of_virus_genera", "https://en.wikipedia.org/wiki/List_of_virus_genera", "https://en.wikipedia.org/wiki/Genus", "https://en.wikipedia.org/wiki/International_Committee_on_Taxonomy_of_Viruses", "https://en.wikipedia.org/wiki/List_of_virus_families_and_subfamilies", "https://en.wikipedia.org/wiki/List_of_higher_virus_taxa", "https://en.wikipedia.org/wiki/Albetovirus"]}},
{"id": "478c1bde0521", "content": " Der Tagesspiegel(lit.'The Day Mirror') is aGermandailynewspaper. It has regional correspondent offices inWashington, D.C., andPotsdam.Der Tagesspiegelis aliberalnewspaperthat is classified ascentristmedia in the context of German politics. Founded on 27 September 1945 by Erik Reger, Walther Karsch and Edwin Redslob,Der Tagesspiegel'smain office is based in Berlinat Askanischer Platz in the locality ofKreuzberg, about 600 metres (2,000 ft) fromPotsdamer Platzand the former location of theBerlin Wall. For more than 45 years,Der Tagesspiegelwas owned by an independenttrust. In 1993, in response to an increasingly competitive publishing environment, and to attract investments required for technical modernisation, such as commission of a new printing plant, and improved distribution, it was bought by theGeorg von Holtzbrinck Publishing Group. Its current publisher is Dieter von Holtzbrinck witheditors in chiefStephan-Andreas Casdorff andLorenz Maroldt[de]. Pierre Gerckens, Giovanni di Lorenzo and Hermann Rudolph are editors of the newspaper. Some of the notable writers includeBas KastandHarald Martenstein. The paper's main readership is in the western half of the city, due to the 1948 blockade having stopped its circulation inEast BerlinandBrandenburg. The paper has recentlybeen redesigned, introducing more colour and a clearertypeface. In 2005 it was awarded theWorld's Best-Designed NewspapersAward by theSociety for News Designin New York. It is owned by Verlag Der TagesspiegelGmbH, a member of theGeorg von Holtzbrinck Publishing Group, and associated with theWall Street Journal. In 2009,Dieter von HoltzbrinckboughtDer TagesspiegelandHandelsblattfrom Holtzbrinck. From 2005 to 2008, American journalist Michael Scaturro edited the English-language version ofDer Tagesspiegel, which was known asThe Berlin Paper. In 2007 and 2008Der Tagesspiegel'sWashington, D.C., correspondent,Christoph von Marschall, was noted in both Germany and the United States for his coverage ofBarack Obama's presidential campaign. He wrote a book entitledBarack Obama – Der schwarze Kennedy. The literal translation of its German title is \"Barack Obama – the BlackKennedy\".His book was a bestseller in Germany, where other commentators had also compared the two Americans.", "metadata": {"url": "https://en.wikipedia.org/wiki/Der_Tagesspiegel", "title": "Der Tagesspiegel", "headings": ["Contents", "History and profile", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Der_Tagesspiegel", "https://en.wikipedia.org/wiki/Der_Tagesspiegel", "https://en.wikipedia.org/wiki/Der_Tagesspiegel", "https://en.wikipedia.org/wiki/Daily_newspaper", "https://en.wikipedia.org/wiki/Broadsheet", "https://en.wikipedia.org/wiki/Dieter_von_Holtzbrinck", "https://en.wikipedia.org/wiki/Berlin", "https://en.wikipedia.org/wiki/ISSN_(identifier)"]}},
{"id": "dbeabc228763", "content": "ThePolytechnic University of Valencia(Valencian:Universitat Politècnica de València;IPA:[univeɾsiˈtatpoliˈtɛɡnikaðevaˈlensi.a],Spanish:Universidad Politécnica de Valencia), shortened toUPV, is a Spanish university located inValencia, with a focus on science, technology, and arts. It was founded in 1968 as the Higher Polytechnic School of Valencia and became a university in 1971, but some of its schools are more than 100 years old. The Polytechnic University of Valencia consists of three campuses: (Valencia,GandiaandAlcoy) and 13 schools and faculties: School ofCivil Engineering(1972), School ofArchitecture(1972), School ofIndustrial Engineering(1972), School of Agricultural Engineering and theEnvironment(1972), School of Building Engineering (1972), School ofDesignEngineering (1972), Higher Polytechnic School of Alcoi (1972), Faculty ofFine Arts(1978), School ofInformatics(1982), School ofTelecommunicationEngineering (1989), Higher Polytechnic School of Gandia (1993), School of Engineering inGeodesy, Cartography and Surveying (1994), and Faculty ofBusiness AdministrationandManagement(1999). The university offers 53 bachelor's and master's degrees and 32 doctoral programs. ", "metadata": {"url": "https://en.wikipedia.org/wiki/Polytechnic_University_of_Valencia", "title": "Technical University of Valencia", "headings": ["Contents", "Characteristics", "Publications", "Notable alumni", "See also", "Notes and references", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Technical_University_of_Valencia", "https://en.wikipedia.org/wiki/Technical_University_of_Valencia", "https://en.wikipedia.org/wiki/Technical_University_of_Valencia", "https://en.wikipedia.org/wiki/Geographic_coordinate_system", "https://en.wikipedia.org/wiki/Public_university", "https://en.wikipedia.org/wiki/Xarxa_Vives_d%27Universitats", "https://en.wikipedia.org/wiki/Top_International_Managers_in_Engineering", "https://en.wikipedia.org/wiki/CESAER"]}},
{"id": "46a836921e17", "content": "Stereoscopic Displays and Applications(SD&A) is an academic technical conference in the field ofstereoscopic 3D imaging.The conference started in 1990 and is held annually.  The conference is held as part of the annual Electronic Imaging: Science and Technology Symposiumorganised by theSociety for Imaging Science and Technology(IS&T). SD&A is an academic technical conference dedicated to stereoscopic imaging topics, specializing in all forms of stereoscopic imaging, including stereoscopic 3D display hardware, stereoscopic 3D image capture, stereoscopic 3D image storage and processing, and also applications of these technologies.  As well as including coverage of two-view 3D displays, the conference includes significant coverage of multi-view autostereoscopic displays andvolumetric 3D displays- any system that stimulates stereoscopic vision in an observer. The backbone of the annual SD&A conference is the technical presentations, which are all accompanied by a technical paper published in the conference proceedings. Alongside the technical sessions, the conference has its own keynote presentation, a popular demonstration session (where a range of stereoscopic 3D technologies can be seen in one place at one time), the 3D theater (where the latest stereoscopic content is shown), and a discussion forum. SD&A was founded in 1990 byJohn O. MerrittandScott Fisher, and has been held annually since.HolographypioneerStephen Bentonwas also an SD&A conference chair from 2000 until his death in 2003. From 1990 to 1993, papers from the SD&A conference were published in its own proceedings volume. From 1994, the papers from the SD&A conference were co-published with papers fromThe Engineering Reality of Virtual Realityconference (which was co-located with SD&A) in a volume series titledStereoscopic Displays and Virtual Reality Systems. From 2008, SD&A went back to the publication of papers in its own proceedings volume. Over the period 1990 to 2015, SD&A and the Electronic Imaging Symposium were jointly organized by IS&T andSPIE.  From 2016 onwards, SD&A and EI are organized by IS&T. A detailed listing of the conference program for every year since 1996 is available on the official SD&A website.  The Introduction/Preface of every year's conference proceedings also contains a descriptive summary of each conference.  The proceedings Introduction is also available on the official SD&A website. A technical proceedings is published annually containing manuscripts presented at the conference.  Over 1100 technical papers have been published over the history of the SD&A conference. The full list of conference proceedings, including a compilation DVD-ROM (1990–2009), is listed at the official SD&A website. The DVD-ROM compilation \"Stereoscopic Displays and Applications 1990-2009: A Complete 20-Year Retrospective - and The Engineering Reality of Virtual Reality 1994-2009 (CDP51)\"released in 2010 represents a technical knowledge base across stereoscopic 3D and VR topics containing the complete technical record of the Stereoscopic Displays and Applications conference (1990-2009), The Engineering Reality of Virtual Reality conference (1994-2009), and papers from a selection of ten other 3D related SPIE conferences (1977-1989) predating SD&A. The disc contains 1260 individual technical papers – 816 from the Stereoscopic Displays and Applications conference, 223 from The Engineering Reality of Virtual Reality conference, and 221 papers from the SPIE 3D conferences prior to SD&A. Some of the presentations at the SD&A conference have been, or go onto be, published in theJournal of Electronic Imaging.  From 1990 to 2015, the SD&A proceedings were published as part of theProceedings of SPIEseries.  From 2016 the SD&A proceedings are published byIS&Tand will be available open-access. Papers presented at SD&A are cited extensively.  The conference tracks its citations via custom Google Scholar page.  As of September 2019, the total citation count is 22k - which is almost double the citation count from January 2014 (12,371).As of January 2014, the top ten most-cited papers across first 25 years of SD&A are: Various media outlets have reported on research presented at SD&A and on the conference itself.  \nOutlets include: See also Citation Statistics above.", "metadata": {"url": "https://en.wikipedia.org/wiki/Stereoscopic_Displays_and_Applications", "title": "Stereoscopic Displays and Applications", "headings": ["Contents", "Scope", "Overview", "History", "Proceedings", "Citation statistics", "Reporting", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Stereoscopic_Displays_and_Applications", "https://en.wikipedia.org/wiki/Stereoscopic_Displays_and_Applications", "https://en.wikipedia.org/wiki/Stereoscopic_Displays_and_Applications", "https://en.wikipedia.org/wiki/List_of_academic_disciplines_and_sub-disciplines", "https://en.wikipedia.org/wiki/Stereoscopic", "https://en.wikipedia.org/wiki/Society_for_Imaging_Science_and_Technology", "https://en.wikipedia.org/wiki/Volumetric_display", "https://en.wikipedia.org/wiki/John_O._Merritt"]}},
{"id": "b687623de816", "content": "Anenterprise architecture framework(EA framework) defines how to create and use anenterprise architecture. Anarchitecture frameworkprovides principles and practices for creating and using the architecture description of a system. It structures architects' thinking by dividing the architecture description into domains, layers, or views, and offers models – typically matrices and diagrams – for documenting each view.  This allows for making systemic design decisions on all the components of the system and making long-term decisions around new design requirements, sustainability, and support. Enterprise architecture regards the enterprise as a large and complex system orsystem of systems.To manage the scale and complexity of this system, an architectural framework provides tools and approaches that help architects abstract from the level of detail at which builders work, to bring enterprise design tasks into focus and produce valuable architecture description documentation. The components of an architecture framework provide structured guidance that is divided into three main areas: The earliest rudiments of the step-wise planning methodology currently advocated byThe Open Group Architecture Framework(TOGAF) and other EA frameworks can be traced back to the article of Marshall K. Evans and Lou R. Hague titled \"Master Plan for Information Systems\"published in 1962 in Harvard Business Review. Since the 1970s people working in IS/IT have looked for ways to engage business people – to enable business roles and processes - and to influence investment in business information systems and technologies – with a view to the wide and long term benefits of the enterprise. Many of the aims, principles, concepts and methods now employed in EA frameworks were established in the 1980s, and can be found in IS and IT architecture frameworks published in that decade and the next. By 1980, IBM'sBusiness Systems Planning(BSP) was promoted as a method for analyzing and designing an organization's information architecture, with the following goals: In 1982, when working for IBM and with BSP, John Zachman outlined his framework for enterprise-level \"Information Systems Architecture\". Then and in later papers, Zachman used the word enterprise as a synonym for business. \"Although many popular information systems planning methodologies, design approaches, and various tools and techniques do not preclude or are not inconsistent with enterprise-level analysis, few of them explicitly address or attempt to define enterprise architectures.\"However, in this article the term \"Enterprise Architecture\" was mentioned only once without any specific definition and all subsequent works of Zachman used the term \"Information Systems Architecture\". In 1986, thePRISM architecture frameworkwas developed as a result of the research project sponsored by a group of companies, including IBM, which was seemingly the first published EA framework. In 1987, John Zachman, who was a marketing specialist at IBM, published the paper,A Framework for Information Systems Architecture.The paper provided a classification scheme forartifactsthat describe (at several levels of abstraction) the what, how, where, who, when and why of information systems. Given IBM already employed BSP, Zachman had no need to provide planning process. The paper did not mention enterprise architecture. In 1989, the National Institute of Standards and Technology (NIST) published theNIST Enterprise Architecture Model.This was a five-layer reference model that illustrates the interrelationship of business, information system, and technology domains. It was promoted within the U.S. federal government. It was not an EA framework as we see it now, but it helped to establish the notion of dividing EA into architecture domains or layers. The NIST Enterprise Architecture Model seemingly was the first publication that consistently used the term \"Enterprise Architecture\". In 1990, the term \"Enterprise Architecture\" was formally defined for the first time as an architecture that \"defines and interrelates data, hardware, software, and communications resources, as well as the supporting organization required to maintain the overall physical structure required by the architecture\". In 1992, a paper by Zachman and Sowastarted thus \"John Zachman introduced a framework for information systems architecture (ISA) that has been widely adopted by systems analysts and database designers.\" The term enterprise architecture did not appear. The paper was about using the ISA framework to describe, “...the overall information system and how it relates to the enterprise and its surrounding environment.” The word enterprise was used as a synonym for business. In 1993, Stephen Spewak's bookEnterprise Architecture Planning(EAP) defined a process for defining architectures for the use of information in support of the business and the plan for implementing those architectures. The business mission is the primary driver. Then the data required to satisfy the mission. Then the applications built to store and provide that data. Finally the technology to implement the applications. Enterprise Architecture Planning is a data-centric approach to architecture planning. An aim is to improve data quality, access to data, adaptability to changing requirements, data interoperability and sharing, and cost containment. EAP has its roots in IBM'sBusiness Systems Planning(BSP). In 1994, the Open Group selectedTAFIMfrom the US DoD as a basis for development of TOGAF, where architecture meant IT architecture. TOGAF started out taking a strategic and enterprise-wide, but technology-oriented, view. It emerged from the desire to rationalize a messy IT estate. Right up to version 7, TOGAF was still focused on defining and using a Technical Reference Model (or foundation architecture) to define the platform services required from the technologies that an entire enterprise uses to support business applications. In 1996, the USIT Management Reform Act, more commonly known as theClinger-Cohen Act, repeatedly directed that a US federal government agency's investment in IT must be mapped to identifiable business benefits. In addition, it made the agency CIO responsible for, “...developing, maintaining and facilitating the implementation of a sound and integrated IT architecture for the executive agency.” By 1997, Zachman had renamed and refocused his ISA framework as an EA framework; it remained a classification scheme for descriptive artifacts, not a process for planning systems or changes to systems. In 1998, The Federal CIO Council began developing the Federal Enterprise Architecture Framework (FEAF) in accordance with the priorities enunciated in Clinger-Cohen and issued it in 1999. FEAF was a process much like TOGAF's ADM, in which “The architecture team generates a sequencing plan for the transition of systems, applications, and associated business practices predicated upon a detailed gap analysis [between baseline and target architectures].” In 2001, the US Chief CIO council publishedA practical guide to Federal Enterprise Architecture, which starts, “An enterprise architecture (EA) establishes the Agency-wide roadmap to achieve an Agency's mission through optimal performance of its core business processes within an efficient information technology (IT) environment.\"\nAt that point, the processes in TOGAF, FEAF, EAP and BSP were clearly related. In 2002/3, in itsEnterprise Edition, TOGAF 8 shifted focus from the technology architecture layer to the higher business, data and application layers. It introduced structured analysis, afterinformation technology engineering, which features, for example, mappings of organization units to business functions and data entities to business functions. Today, business functions are often called business capabilities. And many enterprise architects regard their business function/capability hierarchy/map as the fundamental Enterprise Architecture artifact. They relate data entities, use cases, applications and technologies to the functions/capabilities. In 2006, the popular bookEnterprise Architecture As Strategyreported the results of work by MIT's Center for Information System Research. This book emphasises the need for enterprise architects to focus on core business processes (\"Companies excel because they've [decided] which processes they must execute well, and have implemented the IT systems to digitise those processes.\") and to engage business managers with the benefits that strategic cross-organisational process integration and/or standardisation could provide. A 2008 research project for the development of professional certificates in enterprise and solution architecture by theBritish Computer Society(BCS) showed that enterprise architecture has always been inseparable from information system architecture, which is natural, since business people need information to make decisions and carry out business processes. In 2011, the TOGAF 9.1. specification says: \"Business planning at the strategy level provides the initial direction to enterprise architecture.\"Normally, the business principles, business goals, and strategic drivers of the organization are defined elsewhere.In other words, Enterprise Architecture is not a business strategy, planning or management methodology. Enterprise Architecture strives to align business information systems technology with given business strategy, goals and drivers. The TOGAF 9.1 specification clarified, that, \"A complete enterprise architecture description should contain all four architecture domains (business, data, application, technology), but the realities of resource and time constraints often mean there is not enough time, funding, or resources to build a top-down, all-inclusive architecture description encompassing all four architecture domains, even if the enterprise scope is [...] less than the full extent of the overall enterprise.\" In 2013,TOGAFis the most popular Architecture framework (judged by published certification numbers) that some assume it defines EA.However, some still use the term Enterprise Architecture as a synonym for Business Architecture, rather than covering all four architecture domains - business, data, applications and technology. Since Stephen Spewak'sEnterprise Architecture Planning(EAP) in 1993 – and perhaps before then – it has been normal to divide enterprises architecture into fourarchitecture domains. Note that the applications architecture is about the choice of and relationships between applications in the enterprise's application portfolio, not about the internal architecture of a single application (which is often called application architecture). Many EA frameworks combine data and application domains into a single (digitized) information system layer, sitting below the business (usually a human activity system) and above the technology (the platformIT infrastructure). For many years, it has been common to regard the architecture domains as layers, with the idea that each layer contains components that execute processes and offer services to the layer above. This way of looking at the architecture domains was evident in TOGAF v1 (1996), which encapsulated the technology component layer behind the platform services defined in the \"Technical Reference Model\" - very much according to the philosophy of TAFIM and POSIX. The view of architecture domains as layers can be presented thus: Each layerdelegateswork to the layer below. In each layer, the components, the processes and the services can be defined at a coarse-grained level and decomposed into finer-grained components, processes and services. The graphic shows a variation on this theme. In addition to three major framework components discussed above. An ideal EA framework should feature: Most modern EA frameworks (e.g. TOGAF, ASSIMPLER, EAF) include most of the above. Zachman has always focused on architecture description advice. The application and technology domains (not to be confused with business domains) are characterized by domain capabilities and domain services. The capabilities are supported by the services. The application services are also referred to inservice-oriented architecture(SOA). The technical services are typically supported by software products. The data view starts with the data classes which can be decomposed into data subjects which can be further decomposed into data entities. The basic data model type which is most commonly used is called merda (master entity relationship diagrams assessment, seeentity-relationship model). The Class, subject and entity forms a hierarchical view of data. Enterprises may have millions of instances of data entities. The Enterprise Architecture Reference Traditional Model offers a clear distinction between the architecture domains (business, information/data, application/integration and technical/infrastructure). These domains can be further divided into Sub domain disciplines. An example of the EA domain and subdomains is in the image on the right. Many enterprise architecture teams consist of Individuals with Skills aligned with the Enterprise Architecture Domains and sub-domain disciplines. Here are some examples: enterprise business architect, enterprise documentational architect, enterprise application architect, enterprise infrastructure architect, enterprise information architect, etc. An example of the list of reference architecture patterns in the application and information architecture domains are available atArchitectural pattern (computer science). Aview modelis a framework that defines the set of views or approaches used insystems analysis,systems design, or the construction of anenterprise architecture. Since the early 1990s, there have been a number of efforts to define standard approaches for describing and analyzing system architectures. Many of the recent Enterprise Architecture frameworks have some kind of set of views defined, but these sets are not always calledview models. Perhaps the best-known standard in the field ofsoftware architectureandsystem architecturestarted life asIEEE 1471, anIEEE Standardfor describing thearchitecture of a software-intensive systemapproved in 2000. In its latest version, the standard is published asISO/IEC/IEEE 42010:2011. The standard defines an architecture framework asconventions, principles and practices for the description of architectures established within a specific domain of application and/or community of stakeholders, and proposes an architecture framework is specified by: Architecture frameworks conforming to the standard can include additional methods, tools, definitions, and practices beyond those specified. Nowadays there are now countless EA frameworks, many more than in the following listing. Enterprise architecture frameworks that are released asopen source:", "metadata": {"url": "https://en.wikipedia.org/wiki/Enterprise_Architecture_Framework", "title": "Enterprise architecture framework", "headings": ["Contents", "Overview", "History", "EA framework topics", "Architecture domain", "Layers of the enterprise architecture", "Components of enterprise architecture framework", "Enterprise architecture domains and subdomains", "View model", "Standardization", "Types of enterprise architecture framework", "Consortia-developed frameworks", "Defense industry frameworks", "Government frameworks", "Open-source frameworks", "Proprietary frameworks", "See also", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Enterprise_architecture_framework", "https://en.wikipedia.org/wiki/Enterprise_architecture_framework", "https://en.wikipedia.org/wiki/Enterprise_architecture_framework", "https://en.wikipedia.org/wiki/NIST_Enterprise_Architecture_Model", "https://en.wikipedia.org/wiki/Enterprise_architecture", "https://en.wikipedia.org/wiki/Enterprise_architecture", "https://en.wikipedia.org/wiki/Architecture_framework", "https://en.wikipedia.org/wiki/System_of_systems"]}},
{"id": "54389d01469a", "content": " International StandardIEC/ISO 81346 series \"Industrial systems, installations and equipment and industrial products – structuring principles and reference designations\"defines the rules for reference designation systems (RDS). It is published as a double logo standard prepared by IEC technical committee 3: Information structures and elements, identification and marking principles, documentation and graphical symbols,in cooperation with ISO technical committee 10: Technical product documentation. The 81346 series replaces the deprecated IEC 61346:1996. Future developments of the standards on reference designations will be made in cooperation between the IEC and theISOand published as IEC 81346. (Standards developed in cooperation between IEC and ISO are assigned numbers in the 80000 series) The standard consists of two parts and two supplements: The supplementary sheets for application guidelines (IEC/TR 61346-3:2001) and considerations of terms and their relationships (IEC 61346-4:1998) for DIN EN 61346 were withdrawn in May 2010 without replacement. They are translations of the International Standard IEC 81346 published by the IEC. In 1997 the IEC changed the numbering of the IEC publications and added 60000 to the standard numbers used up to 1997. For example, IEC 61346 from 1996 was published under the number IEC 1346 but was listed under IEC 61346. From 2010, the standards for reference marking will be published as a joint IEC/ ISO standard in the 80000 number range and then published under the number 81346. Preceding standard IEC 61346:1996 has been withdrawn and is replaced by IEC/ISO 81346. 81346-12 is also known as RDS-CW (Reference Designation System for Construction Works).It is maintained by ISO Working Group ISO/TC10/SC10/WG10responsible for Reference Designation within ISO Process Plant Documentation sub committee SC10. RDS-CW has been designed as an international classification system that can be used byBIMallowing for the prospect of integrating classification systems for construction works with classification systems for the Power sector. 81346-10 also known as RDS-PS (Reference Designation System for Power Supply Systems).is maintained by ISO/IEC Joint Working Group ISO/TC10/SC10/JWG10.The latest version 81346-10:2022 is published as a full International Standard, and replaces the previous Technical Specification ISO/TS 81346-10:2015. Upgrading form TS to IS implies greater maturity and more scrutiny in the development of the standard. Supporting 81346-10:2022 is a planned supplementary document. 81346-101 \"Modelling concepts and guidelines for power supply systems\" is a proposed TS (Technical Specification) currently in committee stage of development. 81346-14 known as RDS-MS (Reference Designation System for Manufacturing Systems) is an approved proposal in early development currently at the Committee Draft stage (CD-stage) within ISO/TC 10/SC 10/JWG 10.  Its full title will be \"ISO 81346-14 Industrial systems, installations and equipment and industrial products —Structuring principles and reference designations — Part 14: Manufacturing systems\". ", "metadata": {"url": "https://en.wikipedia.org/wiki/IEC_81346", "title": "IEC 81346", "headings": ["Contents", "Contents", "Double Logo Standards", "Outline", "Preceding Standard", "RDS-CW", "RDS-PS", "RDS-MS", "Proposed Additions", "See also", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/IEC_81346", "https://en.wikipedia.org/wiki/IEC_81346", "https://en.wikipedia.org/wiki/IEC_81346", "https://en.wikipedia.org/wiki/International_Electrotechnical_Commission", "https://en.wikipedia.org/wiki/International_Organization_for_Standardization", "https://en.wikipedia.org/wiki/Building_information_modeling", "https://en.wikipedia.org/wiki/Reference_designator", "https://en.wikipedia.org/wiki/Functional_specification"]}},
{"id": "a476f756ace4", "content": "ISO/IEC 33001Information technology - Process assessment - Concepts and terminologyis a set oftechnical standardsdocuments for the computersoftware developmentprocess and related business management functions. ISO/IEC 33001:2015 is a revision ofISO/IEC 15504, also termedSoftware Process Improvement and Capability Determination(SPICE). The ISO/IEC 330xx family superseded the ISO/IEC 155xx family.  Thissoftware-engineering-related article is astub. You can help Wikipedia byexpanding it.", "metadata": {"url": "https://en.wikipedia.org/wiki/ISO/IEC_33001", "title": "ISO/IEC 33001", "headings": ["Contents", "Further reading", "References"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/ISO/IEC_33001", "https://en.wikipedia.org/wiki/ISO/IEC_33001", "https://en.wikipedia.org/wiki/ISO/IEC_33001", "https://en.wikipedia.org/wiki/Technical_standard", "https://en.wikipedia.org/wiki/Software_development", "https://en.wikipedia.org/wiki/ISO/IEC_15504", "https://en.wikipedia.org/wiki/Software_engineering", "https://en.wikipedia.org/wiki/Computer_programming"]}},
{"id": "882ab7816999", "content": " Macauis a city oftourismwith amulticulturalblend which provides a broad sense and international perspective for itscollege students. The free academic atmosphere and its profound and unique foundation inculturehave also created favorable conditions forhigher education. Most of thecurricula,teachersand the general quality ofteachinghave reached an internationally accepted level. MainlyEnglishorChinese(or both) are the languages of instruction in universities; some courses or programs are conducted inPortuguese. The following is a list of universities, polytechnics and other advanced level (higher) education and research institutions in Macau.", "metadata": {"url": "https://en.wikipedia.org/wiki/List_of_universities_in_Macau", "title": "List of universities and colleges in Macau", "headings": ["Contents", "See also", "References"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/List_of_universities_and_colleges_in_Macau", "https://en.wikipedia.org/wiki/List_of_universities_and_colleges_in_Macau", "https://en.wikipedia.org/wiki/List_of_universities_and_colleges_in_Macau", "https://en.wikipedia.org/wiki/Macau", "https://en.wikipedia.org/wiki/Tourism", "https://en.wikipedia.org/wiki/Multicultural", "https://en.wikipedia.org/wiki/College_student", "https://en.wikipedia.org/wiki/Culture"]}},
{"id": "b2ce214d6b7c", "content": "Auniversity pressis an academicpublishinghouse affiliated with an institution of higher learning that specializes in the publication ofmonographsandscholarly journals. This article outlines notable presses of this type, arranged by country; where appropriate, the page also specifies the academic institution that each press is affiliated with. It also notes whether a press belongs to theAssociation of University Presses (AUP), theAssociation of European University Presses (AEUP),Association of Canadian University Presses (ACUP), or theAssociation Française des Presses d'Universités Diffusion (AFPU-D)[fr].", "metadata": {"url": "https://en.wikipedia.org/wiki/List_of_university_presses", "title": "List of university presses", "headings": ["Contents", "Argentina", "Armenia", "Australia", "Austria", "Bangladesh", "Belgium", "Brazil", "Bulgaria", "Canada", "Chile", "China", "Colombia", "Czech Republic", "Denmark", "Egypt", "Estonia", "Ethiopia", "Finland", "France", "Germany", "Greece", "Hong Kong", "Hungary", "India", "Indonesia", "Iran", "Ireland", "Israel", "Italy", "Jamaica", "Japan", "Jordan", "Kazakhstan", "Kenya", "Latvia", "Lebanon", "Lithuania", "Malaysia", "Mexico", "Namibia", "Netherlands", "New Zealand", "Nigeria", "Norway", "Panama", "Peru", "Philippines", "Poland", "Portugal", "Qatar", "Romania", "Russia", "Saudi Arabia", "Senegal", "Singapore", "South Africa", "South Korea", "Spain", "Sweden", "Taiwan", "Thailand", "Tunisia", "Turkey", "Uganda", "Ukraine", "United Arab Emirates", "United Kingdom", "United States", "Uzbekistan", "Vietnam", "Yemen", "Zambia", "See also", "Notes", "References"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/List_of_university_presses", "https://en.wikipedia.org/wiki/List_of_university_presses", "https://en.wikipedia.org/wiki/List_of_university_presses", "https://en.wikipedia.org/wiki/University_press", "https://en.wikipedia.org/wiki/Publishing", "https://en.wikipedia.org/wiki/Monograph", "https://en.wikipedia.org/wiki/Academic_journal", "https://en.wikipedia.org/wiki/Association_of_University_Presses"]}},
{"id": "30a70763c99c", "content": " Under Hong Kong law, there are 22 accredited degree-awarding higher education institutions in Hong Kong.The following is a list. Only the first three categories of higher education are eligible to award bachelor's degrees or above in Hong Kong. 1911 - The University of Hong Kong (college merged in) 1972 - The Hong Kong Polytechnic 1997 - The Open University of Hong Kong 2021 - Hong Kong Metropolitan University 1903 - Canton Christian College\n1927 - Lingnan University\n1967 - Lingnan College, re-established in Hong Kong\n1978 - registered as an Approved Post Secondary College 香港樹仁大學 1976 - registered as an Approved Post Secondary College\n2006 - Hong Kong Shue Yan University 2018 - Hang Seng University of Hong Kong 2001 - registered as an Approved Post Secondary College2011 - The new Chinese name \"明愛徐誠斌學院\" was adopted. Then, the college changed its name to the \"Caritas Institute of Higher Education\" (明愛專上學院) the same year. The following notation is used: 1949 - Chu Hai College, re-established in Hong Kong\n2004 - Chu Hai College of Higher Education\n2004 - registered as an Approved Post Secondary College 2014 - Hong Kong Nang Yan College of Higher Education\n2014 - registered as an Approved Post Secondary College 2011 - Tung Wah College2011 - registered as an Approved Post Secondary College 香港伍倫貢學院 2019 - UOW College Hong Kong Note 1: The Open University of Hong Kong was established and financed by the Hong Kong Government from 1989 to 1993. Since then, it has been self-financed but still receives some irregular subsidies and loans from the government. Note 2: In January 2007, the Hong Kong government offered a one-off grant of HK$200 million to establish a general development fund to support the academic development and improve the campus facilities of Hong Kong Shue Yan University. Note 3: In August 2017, the Hong Kong government announced 6 self-funded institutions,Caritas Institute of Higher Education,Chu Hai College of Higher Education,Hang Seng Management College,The Open University of Hong Kong,Tung Wah CollegeandTechnological and Higher Education Institute of Hong Kongwill be included in the Study Subsidy Scheme for Designated Professions/Sectors (SSSDP) from 2018. Note 4: In July 2017, the Hong Kong government announced that the Non-means-tested Subsidy Scheme for Self-financing Undergraduate Studies in Hong Kong will include full-time self-financing degree programmes from 15 (non-UGC funded) institutions for the cohort to be admitted in the 2017/18 academic year. These institutions are government-supported, but do not fall under the UGC. These institutions offer higher education programmes, but are not authorised to confer degrees. 香港城市大學專業進修學院", "metadata": {"url": "https://en.wikipedia.org/wiki/List_of_universities_in_Hong_Kong", "title": "List of higher education institutions in Hong Kong", "headings": ["Contents", "Universities", "Post-secondary Institutions", "Public institutions", "Sub-degree institutions", "Other institutions", "See also", "Notes", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/List_of_higher_education_institutions_in_Hong_Kong", "https://en.wikipedia.org/wiki/List_of_higher_education_institutions_in_Hong_Kong", "https://en.wikipedia.org/wiki/List_of_higher_education_institutions_in_Hong_Kong", "https://en.wikipedia.org/wiki/Higher_education_in_Hong_Kong", "https://en.wikipedia.org/wiki/Areas_of_Hong_Kong", "https://en.wikipedia.org/wiki/University_of_Hong_Kong", "https://en.wikipedia.org/wiki/Hong_Kong_Island", "https://en.wikipedia.org/wiki/Hong_Kong_College_of_Medicine_for_Chinese"]}},
{"id": "92486a8c58d5", "content": " Passionate Minds: The Great Enlightenment Love Affairis a 2006 book by authorDavid Bodanis. Written in the form of a novel, the book deals with the life and love ofVoltaireand his mistress, scientistÉmilie du Châtelet. It also discusses the theories they propounded about life,theologyand the nature of theuniverse. The story was written with the aid of historic letters of correspondence between Émilie and Voltaire, as well as between several other prominent figures of theEnlightenment. The full bibliographic citation of the book in question is: The novel is set in the period of development inWestern Europeknown as theAge of Enlightenment. At the time new scientific discoveries were being made, and people began to question society and theruling classes. The story is set against a backdrop of social and political turmoil. The book takes place over a period of 43 years, from 1706 to 1749. The book utilizes severalthemesto convey its story to the reader.Predominate themes includethe rights of women.Though not actively campaigning forwomen's rights, this book highlights the way in which woman were treated during the pre-Enlightenment period.This is emphasized by the manner in which du Châtelet's scientific breakthroughs and discoveries are passed off as unimportant, simply because of her gender. The book starts with a \"flash forward\" in which Émilie du Châtelet is briefly introduced. It is June in the year 1749, and Émilie is in the final stages of her pregnancy. She is struggling to complete a book of her theories and calculations, and fears that she will not have enough time to finish the thesis. The book then jumps back in time to the year 1706, and to a younger\nÉmilie. She has not yet met Voltaire, and is but ten years old. She lives with her parents, and is considered an unusual child because of her love of books and reading.", "metadata": {"url": "https://en.wikipedia.org/wiki/Passionate_Minds", "title": "Passionate Minds", "headings": ["Contents", "Citation", "Background", "Themes", "Plot", "References", "Further reading"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Passionate_Minds", "https://en.wikipedia.org/wiki/Passionate_Minds", "https://en.wikipedia.org/wiki/Passionate_Minds", "https://en.wikipedia.org/wiki/David_Bodanis", "https://en.wikipedia.org/wiki/Little,_Brown", "https://en.wikipedia.org/wiki/ISBN_(identifier)", "https://en.wikipedia.org/wiki/OCLC_(identifier)", "https://en.wikipedia.org/wiki/David_Bodanis"]}},
{"id": "e74d212e3b9d", "content": " Voltaireis a 1933 Americanpre-Codebiographical filmdirected byJohn G. Adolfiand starringGeorge ArlissasVoltaire, an 18th-century French writer and philosopher. It is the last of Arliss' films produced by Warner Bros and the last of his seven collaborations with Adolfi. In pre-Revolutionary France, Voltaire champions the oppressed commoners and tries to warn KingLouis XV(Reginald Owen) about the growing unrest among his subjects. The writer has a powerful ally inMadame Pompadour(Doris Kenyon), Louis' mistress, but the Count de Sarnac (Alan Mowbray) opposes him for his own ends. When Voltaire pleads for the life of Calas, unjustly accused of treason, Louis is inclined to pardon the man, but Sarnac persuades him that it would be a sign of weakness, and Calas is swiftly executed. As a reward, Sarnac gains the wealthy man's estates.  Voltaire invites Calas' daughter and rightful heiress, Nanette (Margaret Lindsay), to shelter in his home. Meanwhile, Sarnac tries to persuade the King that Voltaire is a traitor, citing his well-known friendship withFrederick the Greatand claiming that it is he who is betraying French secrets to the Prussian ruler. Louis is not entirely convinced, but does banish Voltaire from his royal court atVersailles. As a result, Madame Pompadour becomes reluctant to aid Voltaire further, until he arranges it so that she can overhear from Sarnac's own lips his ambition to replace her as Louis' paramount adviser. Then, she persuades the King to allow Voltaire to stage a new play at Versailles. The production is a thinly disguised portrayal of Calas' execution and the aftermath transposed to an exotic setting. Voltaire hopes to open the King's eyes to his danger. Voltaire recruits Nanette to portray the part of herself. The King is sympathetic to the theatrical Nanette's plight, not recognizing himself as her despised oppressor until Sarnac points it out. Then Louis orders the play stopped before the explanatory final scene and orders that Voltaire be sent to theBastille. However, hearing of a rich present given to Sarnac by Frederick, Voltaire unmasks the count as the real traitor. Sarnac is arrested, and Nanette's estates are restored to her. The film ends by showing peasants revolting, with the words \"Justice\", \"Tolerance\", and \"Liberty\" on the screen, then showing Voltaire with an overlay of a flag blowing in the wind. According to Warner Bros the film earned $393,000 domestically and $372,000 foreign. ", "metadata": {"url": "https://en.wikipedia.org/wiki/Voltaire_(film)", "title": "Voltaire(film)", "headings": ["Contents", "Plot", "Cast", "Box office", "Preservation status", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Voltaire_(film)", "https://en.wikipedia.org/wiki/Voltaire_(film)", "https://en.wikipedia.org/wiki/Voltaire_(film)", "https://en.wikipedia.org/wiki/John_G._Adolfi", "https://en.wikipedia.org/wiki/Paul_Green_(playwright)", "https://en.wikipedia.org/wiki/Maude_T._Howell", "https://en.wikipedia.org/wiki/Raymond_Griffith", "https://en.wikipedia.org/wiki/George_Arliss"]}},
{"id": "65d958b02785", "content": " People's ParkinBerkeley, Californiais a parcel of land owned by theUniversity of California, Berkeley. Located east ofTelegraph Avenueand bound by Haste and Bowditch Streets and Dwight Way, People's Park was a symbol during the radical politicalactivism of the late 1960s.Formerly a park, the site is now under construction for new university student housing and homeless supportive housing. While the land is owned by the University of California, People's Park was de facto established as apublic parkon April 20, 1969, by local activists.On May 13, University ChancellorRoger W. Heynsannounced plans to construct a soccer field on the site, leading to a confrontation two days later between protesters and police on May 15.On a day known as\"Bloody Thursday\", police used tear gas and fired shotguns at the protesters to quell the riot, resulting notably in the death of James Rector.In 1984, the city of Berkeley declared it a historical and cultural landmark. In 2018, the university published a plan to build 1,100 new units of student housing and 125 units of supportive housing for homeless people on the site, but a small contingent of activists delayed those plans through opposition including protests,lawsuits,sabotage of construction equipment,and trespassing on the site.The housing plans were backed by theBerkeley City Council, MayorJesse Arreguin, Berkeley's California Assembly representativeBuffy Wicksand California GovernorGavin Newsom, and a majority of UC Berkeley students. Pending a judgment in a legal challenge to the university's housing plan, the park was closed off in early January 2024, when construction workers and police surrounded the park with a 17-foot high wall of shipping containers to prevent trespassing.On June 6, the California Supreme Court unanimously ruled in the university's favor, allowing construction to proceed.Consequently, construction officially started on July 22. In 1956, theRegents of the University of Californiaallocated a 2.8 acres (11,000 m) plot of land containing residences for future development into student housing, parking, and offices as part of the university's long range development plan. At the time, public funds were lacking to buy the land, and the plan was shelved until June 1967, when the university acquired $1.3 million to buy the land througheminent domain.The short-term goal was to create athletic fields with student housing being a longer-range goal. Bulldozers arrived in February 1968 and began demolition of the residences. However, the university ran out of development funds, leaving the lot only partially cleared of demolition debris and rubble for 14 months. On April 15, 1969, local boilermaker and activist Michael Delacour held a meeting with fellow political activists to discuss transforming the vacant lot into a community park. The idea quickly gained traction, and in the following days, theBerkeley Barb, a local underground newspaper, published a call to action for the creation of the park. On Sunday, April 20, more than 100 people arrived at the site to begin building the park. Local landscape architect Jon Read and many others contributed trees, flowers, shrubs, and sod. Eventually, about 1,000 people became directly involved, with many more donating money and materials. On May 13, ChancellorRoger W. Heynsnotified the media via a press release that the university would build a fence around the property and begin construction. In the early morning of Thursday, May 15, 1969, local police cleared the lot and arrested three people who refused to leave.University work crews arrived later and erected an 8-foot (2.4-metre) tall fence around the site.Beginning at noon,about 3,000 people appeared in Sproul Plaza at nearby UC Berkeley for a rally in favor of the park.The crowd later moved down Telegraph Avenue toward People's Park.Arriving in the early afternoon, protesters were met by the remaining 159 Berkeley and university police officers assigned to guard the fenced-off park site. A major confrontation ensued between police and the crowd, which grew to 4,000. James Rector was watching from the roof of Granma Books when he was shot by police;he died on May 19.A carpenter, Alan Blanchard, was permanently blinded by a load of birdshot directly to his face.At least 128 Berkeley residents were admitted to local hospitals for head trauma, shotgun wounds, and other serious injuries inflicted by police. That evening, GovernorRonald Reagandeclared a state of emergency in Berkeley and sent in 2,700National Guardtroops.Demonstrations continued in Berkeley for several days after Bloody Thursday,and National Guard troops remained stationed there for two weeks. After the march in support of People's Park on May 30, 1969, the university decided to keep the 8-foot-tall perimeter chain-link wire fence and maintain a 24-hour guard over the site. On June 20, the University of California Regents voted to turn the People's Park site into a soccer field and parking lot, pending construction of apartments within a year. These plans never materialized.Efforts by the university to put in a soccer field in 1971 were met with resistance,  with 44 people arrested during the protests.In 1979, protesters tore up a parking lot after the university paved over a part of the park for student parking. In the immediate aftermath of the May 1969 demonstrations, and consistent with their goal of \"letting a thousand parks bloom,\" on May 25,People's Park activists began gardening a two-block strip of land called the \"Hearst Corridor,\" located adjacent to Hearst Avenue just northwest of the university campus. The Hearst Corridor was a strip of land along the north side of Hearst Avenue that had been left largely untended after the houses had been torn down to facilitate the completion of an underground subway line by theBay Area Rapid Transit(BART) District. Initially slated for apartments, community outreach by a citizen's committee in 1974 revealed overwhelming support for the establishment of a public park, and the park was officially dedicated on June 7, 1979. In the spring of 1991, the university released plans to redevelop People's Park. They proposed removing the Free Speech Stage and installing several large volleyball courts throughout the park. Bulldozers were ushered in, accompanied by riot police, to install the sand volleyball courts, spurring a new wave of protests. Protests grew each day, and police escalated to shooting wood pellets and rubber bullets at demonstrators. More than 104 people were arrested.TheSan Francisco Examinerlater reported the cost to the university of installing one sand volleyball court to be $150,000, not including costs for security to defend the courts against protesters.The volleyball courts remained until 1997, however, when the university finally removed them from the park. On August 25, 1992,Rosebud Denovo, who had been arrested or questioned more than a dozen times since 1991,broke into the basement of the residence of UC Berkeley ChancellorChang-Lin Tien. Officers from theUniversity of California Police Department(UCPD) responded to a silent alarm that had been triggered.Oakland Police Department(OPD) were called to assist. Refusing to surrender when called upon to do so by the responding officers, Denovo fled into the house.OPD police officers, with dogs, entered the house; after a brief encounter, an OPD officer shot and killed Denovo.Denovo was carrying a note demanding an end to the construction in People's Park; it read, in part: \"We are willing to die for this piece of land. Are you?\"Several protests over Denovo's death were made in the week following the shooting.Although the Office of the Alameda County District Attorney determined the police had acted appropriately in a report released in October,park activists and street people doubted the use of deadly force was justified. In 2011, People's Park saw a new wave of protests, known as the \"tree-sit\", consisting of a series of individual \"tree-sitters\" who occupied a wooden platform in one of the trees in People's Park. These protests lasted throughout most of the fall of 2011, only ending when a protester fell out of a tree. In late 2011, UC Berkeley bulldozed the west end of People's Park, in an effort to provide students and the broader community with safer, more sanitary conditions. People's Park has been the subject of long-running contention between those who see it as a haven for criminals that is unfriendly to visitors and families, and those who see it as an essential green space south of campus and a memorial to theFree Speech Movement. While the site had public bathrooms, gardens, and a playground area, many residents do not see it as a welcoming place, citing drug use and a high crime rate.ASan Francisco Chroniclearticle on January 13, 2008, referred to People's Park as \"a forlorn and somewhat menacing hub for drug users and the homeless.\" The same article quoted denizens and supporters of the park saying it was \"perfectly safe, clean and accessible.\"In May 2018, UC Berkeley reported that campus police had been called 1,585 times to People's Park in the previous year.The university also said there had been 10,102 criminal incidents in the park between 2012 and 2017.A 2015 investigation by theDaily Californianfound that most crimes reported at People's Park were related to \"quality-of-life\" such as drug and alcohol violations, and disorderly conduct, but that there were also multiple reports of assault, battery, aggravated theft, and robbery at the park. In 2018, UC Berkeley unveiled a plan for People's Park that would include the construction of housing for as many as 1,000 students, supportive housing for the homeless or military veterans, and a memorial honoring the park's history and legacy.In November 2018, Rigel Robinson was elected to the Berkeley City Council for District 7, which includes People's Park, campaigning on his support for developing housing at People's Park. On August 29, 2019,Chancellor Carol T. Christconfirmed plans to create student housing for 600–1000 students, and supportive housing for 100–125 people. San Francisco-based LMS architects were selected to build the housing, and Christ stated that the university was moving to a time of \"extensive public comment\" on the plans for construction. In February 2020, Berkeley City Councilmembers Rigel Robinson and Lori Droste and Berkeley MayorJesse Arreguinpublished their support for developing permanent supportive housing and student housing on the site in anSF Chronicle opinion. That month, on February 10, the university held its first public comment forum. Advocates of the park held a rally to protest the proposal, with students citing the historical, cultural, and social relevance of the park. On April 17, 2020, UC Berkeley published its plans for the People's Park Housing Project during its third virtual open house. Because of theCOVID-19 pandemic, and the following shelter-in-place ordinances, the university moving forward with the plan was faced with significant backlash. The mayor of Berkeley,Jesse Arreguín, wrote \"I think we should launch this process at a time and in a way that allows full transparency and participation. I therefore reiterate my request that the campus delay the public comment period until after the Shelter in Place order is lifted.\" On April 29, 2020, the Associated Students of the University of California (ASUC), planned to vote on re-establishing the nonpartisan housing commission. In January 2021, UC Berkeley erected fences around portions of People's Park to take core samples of the soil composition in preparation for construction.Homeless people who had set up tents in the park during the COVID-19 pandemic were removed from the site by UC police.In response, a rally was organized on January 29. Michael Delacour, one of the founders of the park, gave a speech expressing frustration. Spurred on by his words, hundreds of people broke down construction equipment, tore down the fences, and carried them down Telegraph Avenue. Some were deposited on the front steps of Sproul Hall, the UC Berkeley administration building. Protesters, including some UC Berkeley students, occupied the park in February 2021 to call for an immediate halt of development plans and evictions of current residents of the park, citing police mistreatment of the homeless' belongings. A university spokesman said that he was unaware of any reports of police throwing away those belongings. In a statement issued shortly after the occupation began, UC Berkeley Chancellor Carol Christ described building on the park as a \"a unique opportunity for a win-win-win-win.\" People's Park was officially listed on theNational Register of Historic Placeson May 24, 2022. Just after midnight on August 3, 2022, theUC Berkeley Police Departmentand contractors began fencing off People's Park. Protesters gathered after multiple \"bulldozer\" alerts were shared when workers began unloading heavy machinery and construction equipment into the park. At about 3 a.m., activists tried to block the movement of machinery into the park by lying on the road, and arrests were made.By noon, 47 trees in People's Park were cut down by a local company. These events were accompanied by a protest atSproul Plazaon theUC Berkeleycampus. Demonstrators marched down Telegraph Avenue and Haste Street, coalescing at the park.By noon, the university decided to withdraw construction crews from the site, citing \"destruction of construction materials, unlawful protest activities and violence on the part of some.\" Hours later, the university announced that construction work at People's Park would be temporarily paused. On August 4, a special City Council meeting was canceled by MayorJesse Arreguín. The meeting was scheduled a day after confrontations with law enforcement occurred, in order to discuss lifting Berkeley's ban on the use of tear gas and pepper spray by police. The June 2020 ban was put in place by a unanimous vote, with Arreguín saying at the time that tear gas \"is banned in warfare and should not be used on our streets or in protests.\" The mayor said he initially called for the August 4 meeting following the protests at People's Park, but later said that he \"came to the conclusion that it was the wrong approach and that the ban on tear gas should remain.\" The mayor stated that he supports the university's housing project, but said that \"it’s understandable that people are very concerned and upset about the construction at the park\" and that there is a need to \"make sure that people can protest peacefully, and make sure we are protecting the safety of the broader community at the same time.\" On August 5, theCalifornia First District Court of Appealupheld a stay on construction, demolition and tree-cutting, temporarily pausing further development work at People's Park until the legal issue was resolved. The university, however, retained and enforced its legal right to fence the perimeter of the park. On January 4, 2024, shortly after midnight, UC Berkeley fenced off the park's perimeter with double-stackedintermodal containersin an action that involved at least 100 police officers from UCPD, Cal State campus police, California Highway Patrol, and the Alameda County Sheriff's Office.About 60 protesters occupied the park during the overnight operation until forced to leave by police, which led to seven arrests.The university was not allowed to start construction on its proposed development due to the ongoing court case, but took measures to fully secure the perimeter of the lot, as several large trees were also chopped down. On the previous night, park advocates had held an overnight vigil to defend against rumored fencing, expressing concern that UC Berkeley's winter break meant that many students were not around.In a press release, UC Berkeley stated that the park was being closed to \"minimize disruption for the city of Berkeley and campus communities\". Within a week after setting up the containers, UC Berkeley addedrazor wirealong their tops to prevent protesters from climbing onto or over them. On June 6, 2024, the California Supreme Court unanimously sided with the university in an appeal to begin construction on the site.UC Berkeley announced after the ruling that it would be preparing a plan to start construction of student housing at the site, and subsequently began on July 22.", "metadata": {"url": "https://en.wikipedia.org/wiki/People%27s_Park_(Berkeley)", "title": "People's Park (Berkeley)", "headings": ["Contents", "History", "Early history", "1969 protests and \"Bloody Thursday\"", "Later history", "Relation to Ohlone Park", "1991 volleyball court controversy", "2000s to 2010s", "Redevelopment and controversy (since 2018)", "2021 occupation", "National historical recognition", "2022 demolition effort", "2024 fencing", "2024 California Supreme Court decision", "See also", "References", "Further reading", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/People%27s_Park_(Berkeley)", "https://en.wikipedia.org/wiki/People%27s_Park_(Berkeley)", "https://en.wikipedia.org/wiki/People%27s_Park_(Berkeley)", "https://en.wikipedia.org/wiki/Geographic_coordinate_system", "https://en.wikipedia.org/wiki/Geographic_coordinate_system", "https://en.wikipedia.org/wiki/University_of_California,_Berkeley", "https://en.wikipedia.org/wiki/National_Register_of_Historic_Places", "https://en.wikipedia.org/wiki/List_of_Berkeley_Landmarks"]}},
{"id": "f32836006362", "content": "Memorex Corp.began as acomputer tapeproducer and expanded to become both a consumer media supplier and a major IBMplug compatibleperipheral supplier.  It was broken up and ceased to exist after 1996 other than as aconsumer electronicsbrand specializing in diskrecordable mediaforCDandDVDdrives,flash memory,computeraccessories and otherelectronics. Established in 1961 inSilicon Valley, Memorex started by selling computer tapes, and then other media such as disk packs. The company later expanded intodisk drivesand other peripheral equipment forIBMmainframes. During the 1970s and into the early 1980s, Memorex was worldwide one of the largest independent suppliers ofdisk drivesandcommunications controllersto users of IBM-compatible mainframes, as well as media for computer uses and consumers. The company's name is aportmanteauof \"memory excellence\". Memorex entered the consumer media business in 1971 and started the ad campaign, first with its \"shattering glass\" advertisements and then with a series of legendarytelevision commercialsfeaturingElla Fitzgerald. In the commercials, she would sing a note that shattered a glass while being recorded to a Memorexaudio cassette. The tape was played back and the recording also broke the glass, asking \"Is it live, or is it Memorex?\" This would become the company slogan which was used in a series of advertisements released through 1970s and 1980s. In 1982, Memorex was bought byBurroughsfor its enterprise businesses; the company's consumer business, a small segment of the company's revenue at that time was sold to Tandy.Over the next six years, Burroughs and its successorUnisysshut down, sold off or spun out the various remaining parts of Memorex. The computer media, communications and IBM end user sales and service organization were spun out as Memorex International. In 1988, Memorex International acquired theTelex CorporationbecomingMemorex TelexNV, a corporation based in theNetherlands, which survived as an entity until the middle 1990s.The company evolved into a provider of information technology solutions including the distribution and integration of data network and storage products and the provision of related services in 18 countries worldwide. As late as 2006, several pieces existed as subsidiaries of other companies, see e.g., Memorex Telex Japan Ltda subsidiary of Kanematsuor Memorex Telex (UK) Ltd. a subsidiary of EDS Global Field Services. Over time the Memorex consumer brand has been owned by Tandy, Hanny Holdings and Imation. As of 2016, the Memorex brand is owned by Digital Products International (DPI).", "metadata": {"url": "https://en.wikipedia.org/wiki/Memorex", "title": "Memorex", "headings": ["Contents", "History and evolution", "Timeline", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Memorex", "https://en.wikipedia.org/wiki/Memorex", "https://en.wikipedia.org/wiki/Memorex", "https://en.wikipedia.org/wiki/Public_company", "https://en.wikipedia.org/wiki/Laurence_Spitters", "https://en.wikipedia.org/wiki/Magnetic_tape", "https://en.wikipedia.org/wiki/Plug_compatible", "https://en.wikipedia.org/wiki/Consumer_electronics"]}},
{"id": "25b08cd23d77", "content": " Edward Rolf Tufte(/ˈtʌfti/;born March 14, 1942),sometimes known as \"ET\",is an Americanstatisticianandprofessor emeritusofpolitical science,statistics, andcomputer scienceatYale University.He is noted for his writings oninformation designand as a pioneer in the field ofdata visualization. Edward Rolf Tufte was born in 1942 inKansas City, Missouri, toVirginia Tufte(1918–2020) and Edward E. Tufte (1912–1999). He grew up inBeverly Hills, California, where his father was a longtime city official. He graduated from the publicBeverly Hills High School. Tufte received a BS and a MS in statistics fromStanford University, and a Doctor of Philosophy in political science fromYale University.His dissertation was completed in 1968 and titledThe Civil Rights Movement and Its Opposition. Tufte was hired in 1967 by theWoodrow Wilson SchoolofPrinceton Universityas a lecturer in politics and public affairs, where he steadily moved up to the rank of full Professor in 1972.He taught courses there inpolitical economyanddata analysiswhile publishing three quantitatively inclined political science books. In 1975, while at Princeton, Tufte was asked to teach a statistics course to a group of journalists who were visiting the school to study economics. He developed a set of readings and lectures onstatistical graphics, which he further developed in joint seminars he taught with renowned statisticianJohn Tukey, a pioneer in the field of information design. These course materials became the foundation for Tufte's first book on information design,The Visual Display of Quantitative Information. In 1977, Tufte left Princeton University for Yale University, where he accepted an appointment as Professor ofPolitical Science,Statistics, andComputer Science, as well as a Senior Critic at theYale School of Art. After negotiations with major publishers failed, Tufte decided to self-publish the bookThe Visual Display of Quantitative Informationin 1982, working closely with graphic designer Howard Gralla. Tufte financed the work by taking out asecond mortgageon his home. The book quickly became a commercial success and secured Tufte's transition from political scientist to information expert. In 1999, after 22 years of service at Yale University, his professorship at Yale was madeEmeritus. On March 5, 2010, PresidentBarack Obamaappointed Tufte to theAmerican Recovery and Reinvestment Act'sRecovery Independent Advisory Panel \"to provide transparency in the use of Recovery-related funds\". Tufte is an expert in the presentation ofinfographicssuch aschartsanddiagrams, and is a fellow of theAmerican Statistical Association. He has held fellowships from theGuggenheim Foundationand theCenter for Advanced Study in the Behavioral Sciences. Tufte's writing is important in such fields asinformation designandvisual literacy, which deal with the visual communication of information.  He coined the wordchartjunkto refer to useless, non-informative, or information-obscuring elements of quantitative information displays.  Tufte's other key concepts include what he calls thelie factor, thedata-ink ratio, and thedata densityof a graphic. Tufte uses the term \"data-ink ratio\" to argue against using excessive decoration in visual displays of quantitative information.InVisual Display, Tufte explains, \"Sometimes decoration can help editorialize about the substance of the graphic. But it is wrong to distort the data measures—the ink locating values of numbers—in order to make an editorial comment or fit a decorative scheme.\" Tufte encourages the use of data-richillustrationsthat present all available data. When such illustrations are examined closely, everydata pointhas a value, but when they are looked at more generally, only trends and patterns can be observed. Tufte suggests these macro/micro readings be presented in the space of an eye-span, in the high resolution format of the printed page, and at the unhurried pace of the viewer's leisure. Tufte uses several historical examples to make his case. These includeJohn Snow'scholera outbreak map,Charles Joseph Minard'sCarte Figurative, earlyspace debrisplots,Galileo Galilei'sSidereus Nuncius, andMaya Lin'sVietnam Veterans Memorial. For instance, the listing of the names of deceased soldiers on the black granite of Lin's sculptural memorial is shown to be more powerful as a chronological list rather than as an alphabetical one. The sacrifice each fallen individual has made is thus highlighted within the overall time scope of the war.InSidereus Nuncius, Galileo presents the nightly observations of the moons of Jupiter in relation to the body itself, interwoven with the two-month narrative record. Tufte has criticized the wayMicrosoft PowerPointis typically used. In his essay \"The Cognitive Style of PowerPoint\", Tufte criticizes many aspects of the software: Tufte cites the way PowerPoint was used byNASAengineers in the events leading to theSpace Shuttle Columbia disasteras an example of PowerPoint's many problems. The software style is designed topersuaderather than to inform people of technical details.  Tufte's analysis of a NASA PowerPoint slide is included in theColumbia Accident Investigation Board’s report -- including an engineering detail buried in small type on a crowded slide with six bullet points, that if presented in a regular engineeringwhite paper, might have been noticed and the disaster prevented. Instead, Tufte argues that the most effective way of presenting information in a technical setting, such as an academic seminar or a meeting of industry experts, is by distributing a brief written report that can be read by all participants in the first 5 to 10 minutes of the meeting.  Tufte believes that this is the most efficient method of transferring knowledge from the presenter to the audience and then the rest of the meeting is devoted to discussion and debate. One method Tufte encourages to allow quick visual comparison of multiple series is thesmall multiple, a chart with many series shown on a single pair of axes that can often be easier to read when displayed as several separate pairs of axes placed next to each other. He suggests this is particularly helpful when the series are measured on quite different vertical (y-axis) scales, but over the same range on the horizontalx-axis (usually time). Sparklinesare a condensed way to present trends and variation, associated with a measurement such as averagetemperatureorstock marketactivity, often embedded directly in the text; for example: The Dow Jones index for February 7, 2006.These are often used as elements of asmall multiplewith several lines used together. Tufte explains the sparkline as a kind of \"word\" that conveys rich information without breaking the flow of a sentence or paragraph made of other \"words\" both visual and conventional. To date, the earliest known implementation of sparklines was conceived by interaction designer Peter Zelchenko and implemented by programmer Mike Medved in early 1998. Beyond his academic endeavors over the years, Tufte has created sculptures, often large outdoor ones made of metal or stone,that were first primarily exhibited on his own ruralConnecticutproperty. In 2009–10, some of these artworks were exhibited at theAldrich Contemporary Art MuseuminRidgefield, Connecticut, in the one-man showEdward Tufte: Seeing Around. Hogpen Hill Farms, the 234-acre(95-hectare) Tuftesculpture gardenin Woodbury, Connecticut, is open to the public on summer weekends. In 2010, Edward Tufte opened a gallery, ET Modern, inNew York City'sChelsea Art Districtat 11th Avenue and 20th Street.The gallery closed in 2013.  ", "metadata": {"url": "https://en.wikipedia.org/wiki/Edward_Tufte", "title": "Edward Tufte", "headings": ["Contents", "Early life and education", "Career", "Infographic work", "Information design", "Criticism of PowerPoint", "Small multiple", "Sparkline", "Sculpture", "Hogpen Hill Farms", "ET Modern", "Bibliography", "Works on political economy", "Works of analytic design", "Exhibitions", "References"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Edward_Tufte", "https://en.wikipedia.org/wiki/Edward_Tufte", "https://en.wikipedia.org/wiki/Edward_Tufte", "https://en.wikipedia.org/wiki/Kansas_City,_Missouri", "https://en.wikipedia.org/wiki/Stanford_University", "https://en.wikipedia.org/wiki/Bachelor_of_Science", "https://en.wikipedia.org/wiki/Master_of_Science", "https://en.wikipedia.org/wiki/Yale_University"]}},
{"id": "045c0c9b0e02", "content": " The following is a list ofSinitic languagesand their dialects. For a traditional dialectological overview, see alsovarieties of Chinese. \"Chinese\" is a blanket term covering many different varieties spoken across China.Mandarin Chineseis the most popular dialect, and is used as alingua francaacross China. Linguists classify these varieties as theSiniticbranch of theSino-Tibetanlanguage family. Within this broad classification, there are between seven and fourteen dialect groups, depending on the classification. The conventionally accepted set of seven dialect groups first appeared in the second edition of the dialectology handbook edited byYuan Jiahua(1961).\nIn order of decreasing number of speakers, they are: The revised classification ofLi Rong, used in theLanguage Atlas of China(1987) added three further groups split from these: The number of speakers derived from statistics or estimates (2019) and were rounded: In addition to the varieties listed below, it is customary to speak informally of dialects of each province (such asSichuan dialectandHainan dialect). These designations do not generally correspond to classifications used by linguists, but each nevertheless has characteristics of its own. The number of speakers derived from statistics or estimates (2019) and were rounded: Sometimes subcategory of Wu. Sometimes a subcategory of Mandarin. The non-Min dialects of Hainan were once considered Yue, but are now left unclassified: In addition to the varieties within the Sinitic branch of Sino-Tibetan, a number ofmixed languagesalso exist that comprise elements of one or more Chinese varieties with other languages. The extensive 1987Language Atlas of Chinagroups Chinese local varieties into the following units: In the list below,local dialects are not listed.  Groups are in bold, subgroups are numbered, and clusters are bulleted.", "metadata": {"url": "https://en.wikipedia.org/wiki/List_of_varieties_of_Chinese", "title": "List of varieties of Chinese", "headings": ["Contents", "Classification", "Summary", "List of languages and dialects", "Gan", "Mandarin", "Hui", "Jin", "Hakka", "Min", "Wu", "Xiang", "Yue", "Pinghua", "Ba-Shu", "Other", "Mixed languages", "List in theAtlas", "See also", "Notes", "References"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/List_of_varieties_of_Chinese", "https://en.wikipedia.org/wiki/List_of_varieties_of_Chinese", "https://en.wikipedia.org/wiki/List_of_varieties_of_Chinese", "https://en.wikipedia.org/wiki/Lists_of_ISO_639_codes", "https://en.wikipedia.org/wiki/Greater_China_Region", "https://en.wikipedia.org/wiki/Standard_Mandarin", "https://en.wikipedia.org/wiki/Sichuanese_dialects", "https://en.wikipedia.org/wiki/Northeastern_Mandarin"]}},
{"id": "c1845e76caaa", "content": "TheAssociation of American Publishers(AAP) is the national trade association of the Americanbook publishingindustry. AAP lobbies for book, journal and education publishers in theUnited States. AAP members include most of the major commercial publishers in the United States, as well as smaller and nonprofit publishers, university presses, and scholarly societies. Patricia Schroeder, a formerUnited States representative, served as the association'sCEOfrom 1997 until 2009, taking over the role fromNicholas A. Veliotes. On May 1, 2009, another former United States representative,Tom Allen, took over as president and CEO. In January 2017,Maria Pallante, a former United StatesRegister of Copyrights, became the president and CEO of the organization. The association's core programs deal primarily with advocacy related to:intellectual property; new technology and digital issues of concern to publishers; the freedom to read,censorshipandlibel; the freedom to publish; funding foreducationandlibraries; postal rates and regulations; tax and trade policy; and internationalcopyrightenforcement. AAP tracks publisher revenue on a monthly and annual basis with its StatShot programs.The association has also awarded books, journals, and electronic content through its annualPROSE Awardssince 1976. In August 2019, AAP suedAudiblefor its Captions feature, through which machine-generated text could be displayed alongside audio narration.The lawsuit was settled in February 2020, with Audible agreeing not to implement the Captions feature without obtaining express permission. The AAP initially supported the arrest ofDmitry Sklyarov. AAP was criticized after it contractedEric Dezenhall'scrisis managementfirm to promote its position regarding theopen accessmovement.Schroeder toldThe Washington Post“the association hired Dezenhall when members realized they needed help. ‘We thought we were angels for a long time and we didn't need PR firms.’” In 2020, AAP released press statements to support four of its members in the case ofHachette v. Internet Archive(IA). President Maria Pallante said of the case, \"As the complaint outlines, by illegally copying and distributing online a stunning number of literary works each day, IA displays an abandon shared only by the world’s most egregious pirate sites.\"This action was opposed by theElectronic Frontier Foundation,Public Knowledge,and theAssociation of Research Libraries.", "metadata": {"url": "https://en.wikipedia.org/wiki/Association_of_American_Publishers", "title": "Association of American Publishers", "headings": ["Contents", "Activities", "Controversies", "See also", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Association_of_American_Publishers", "https://en.wikipedia.org/wiki/Association_of_American_Publishers", "https://en.wikipedia.org/wiki/Association_of_American_Publishers", "https://en.wikipedia.org/wiki/Book_publishing", "https://en.wikipedia.org/wiki/United_States", "https://en.wikipedia.org/wiki/Patricia_Schroeder", "https://en.wikipedia.org/wiki/United_States_House_of_Representatives", "https://en.wikipedia.org/wiki/CEO"]}},
{"id": "ec955236325d", "content": " Caulimoviridaeis a family ofvirusesinfecting plants.The family contains 11 genera.Viruses belonging to the familyCaulimoviridaeare termed double-stranded DNA (dsDNA) reverse-transcribing viruses (orpararetroviruses) i.e. viruses that contain areverse transcriptionstage in their replication cycle. This family contains allplant viruseswith a dsDNA genome that have a reverse transcribing phase in their lifecycle. The following genera are recognized: All viruses of this family are non-enveloped. Virus particles are either bacilliform or isometric. The type of nucleocapsid incorporated into the virus structure determines the size of the viral particles. Bacilliform particles are approximately 35–50 nm in diameter and up to 900 nm in length. Isometric particles are on average 45–50 nm in diameter and show icosahedral symmetry. The genomes of viruses from this family contain monopartite, non-covalently closed circular dsDNA of 7.2–9.3 kbp with discontinuities in both genome strands at specific places. These genomes contain oneopen reading frame(ORF), as observed inpetuviruses, to eight ORFs such as in thesoymoviruses. Proteins encoded by the viral genomes always includereverse transcriptase(RT), a ribonuclease H (RnaseH),aspartic proteases(AP), capsids (CP),30K movement proteins(MP) and viral associated proteins (VAP). Some ORF code for proteins of unknown function. The AP, RT and RnaseH are coded in the same ORF and produce a polyprotein. The RT protein unify the five family in the orderOrtervirales:Belpaoviridae,Caulimoviridae,Metaviridae,PseudoviridaeandRetroviridae.However, unlike the other four families, theCaulimoviridaegenomes do not encode an integrase protein. Thus their integration is not mandatory in their replication life cycle. The virionenter in the host celland will reach the nucleus. The capsid protein are disassembled and the circular dsDNA enter the nucleus via the nuclear pore. The viral DNA forms supercoiled mini-chromosome structures upon entering the host nucleus, where it is transcribed by the host polymerase II into polyadenylatedRNAwhich is terminally redundant (due to transcription occurring twice for some parts of the DNA). Newly transcribed RNA are exported into the cytoplasm where it is either translated into viral proteins, or retrotranscribed into new copies of the dsDNA viral genome by the viralreverse transcriptase. New dsDNA genomes are encapsidated in the cytoplasm and released. The presence of endogenous viral elements (EVEs) in plant genomes is widespread.and most known plant EVEs originate from viruses with DNA genomes in the familyCaulimoviridae. Integration is thought to occur through non-homologous end-joining (illegitimate recombination) during DNA repair mechanisms. Most plant EVEs are non infectious. However, infectiousCaulimoviridaeEVEs have been reported in the genome of petunia(Petunia vein clearing virus), banana(Banana streak OL virus,Banana streak GF virus,Banana streak IM virus) andNicotiana edwardsonii(Tobacco vein clearing virus).", "metadata": {"url": "https://en.wikipedia.org/wiki/Caulimoviridae", "title": "Caulimoviridae", "headings": ["Contents", "Taxonomy", "Virus particle structure", "Genome structure and replication", "Structure", "Replication", "Integration", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Caulimoviridae", "https://en.wikipedia.org/wiki/Caulimoviridae", "https://en.wikipedia.org/wiki/Caulimoviridae", "https://en.wikipedia.org/wiki/Virus_classification", "https://en.wikipedia.org/wiki/Virus", "https://en.wikipedia.org/wiki/Riboviria", "https://en.wikipedia.org/wiki/Revtraviricetes", "https://en.wikipedia.org/wiki/Revtraviricetes"]}},
{"id": "decf74075476", "content": " TheAutonomous University of Madrid(Spanish:Universidad Autónoma de Madrid;UAM), commonly known asla Autónoma,is a Spanishpublic universitylocated inMadrid, Spain. The university was founded in 1968 byroyal decree. UAM is widely respected as one of the most prestigious universities in Europe. According to theQS World University Rankings2022, UAM is ranked as the top university in Spain and has consistently ranked as #1 in Spain in theEl PaísUniversity rankings, published annually. Among its notable alumni, which include every president that theSupreme Court of SpainandConstitutional Court of Spainhas had, is the current King of Spain,Felipe VI, who studied the Licenciatura en Derecho (Law) and is the president of UAM’s alumni society. The campus of the university spans a rural tract of 650 acres (260 ha), mostly aroundmetropolitan Madrid. Founded in 1968, its main campus, Cantoblanco, is located near the cities ofAlcobendas,San Sebastián de los ReyesandTres Cantos. UAM's Cantoblanco Campus holds most of the university's facilities. It is located 15 km (9.3 mi) north of Madrid and has an extension of over 2,200,000 m(24,000,000 sq ft). Of these, nearly 770,000 m(8,300,000 sq ft) are urbanised and about a third of them are garden areas. UAM offers 94 doctorate programs across the university. It also offers 88 master's degrees. According to a study carried out by the newspaperEl Mundo, in 2021, UAM was the best university in the country to study biology, nursing, medicine, physics and law, within the 50 careers with the highest demand. TheStabilization Plan of 1959and the development plans of the 1960s boosted the Spanish economy after years of austerity and the self-sufficiency-based economy.The end of diplomatic and economic isolation led to an economic boom in Spain that resulted in the consolidation of a middle class similar to that of otherWestern Europeannations. The demand for higher education increased, and the Spanish university system grew increasingly congested. The Autonomous University of Madrid was established by the 5-1968 Decree approved by the SpanishCouncil of Ministersduring theFrancoist dictatorshipalong with theAutonomous University of Barcelonaand theUniversity of Bilbao. This decree was sponsored by the then-Minister of Science and Education, José Luis Villar Palasí, in order to restructure the Spanish university system. The nameUniversidad Autónoma de Madridfirst appeared in an executive order by the Ministry which was published on 13 August 1968. On 8 June 2018 the Autonomous University of Madrid celebrated its 50th anniversary with a series of commemorative events. UAM's Cantoblanco Campus is home to most of the university's facilities. It is located 15 km north of Madrid and has an extension of over 2,200,000 m. Of these are nearly 770,000 are urbanised and about a third of them are garden areas. The campus was designed as auniversity townthat was to be self-sufficient, but also would be situated away from Madrid in order to keep student activity against theFrancoistdictatorship away from the capital. Initially, the campus held the faculties ofphilosophyandliberal arts,law,economics,business management, andscience, as well as the rectorate, several other service buildings and sports facilities. The university's other facilities, the faculty ofmedicineand theteacher trainingSanta Maria school are in downtown Madrid. There are two other teacher training schools inSegoviaand inCuenca. Over the years, the faculty ofpsychology, thebiologybuilding of the faculty of sciences, the new faculty of law (that allowed the transfer of the teacher training school to the main campus, and that was later transformed in faculty of education and teacher training) along with itspolitical scienceannex building, thepolytechnicschool (initially superior technical school of computing engineers), the libraries ofhumanitiesand sciences, as well as theErasmus of Rotterdamdormitory have been built on the main campus. The original faculties were housed in interconnected buildings with several patios in between them. Characteristic to each building is a large number of stairs in its corridors, initially designed to prevent students from running in case of police raids. Currently, this fact has been considered by many university officials as a setback in the integration of handicapped students. The newest facilities were built in a contemporary style, being more accessible and allowing more free movement to students. Sporting facilities include two swimming pools (an indoor one and an outdoor one), two multiple-use pavilions, and outdoor tennis, football, basketball, paddle tennis, rugby, and futsal and beach volleyball courts. Other services on campus include 16 cafeterias and other eating facilities, medical services, a pharmacy with optic care, a foreign languages pavilion, and a bookstore. The campus also houses several research facilities partnered with the Spanish Scientific Research Council (CSIC). Cantoblanco Campus is accessible by train belonging toRenfeCercaniasCommuter service (station Cantoblanco-Universidad), or by the Madrid Region Commuter Bus service. The campus is located in the B1 area of theMadrid Transports Consortium. UAM's faculty of medicine is located north of Madrid nearLa Paz teaching hospital(that acts as one of the faculty's teaching hospitals, as Puerta de Hierro Majadahonda Hospital,La Princesa Hospital, Niño Jesús Hospital and Fundación Jiménez Díaz do). It was inaugurated in 1969. Juan Luis Vives Residence Hall was UAM's first residential facility. It is located in the Plaza Castilla area in northern Madrid. It has 130 residents and holds several cultural activities for the university. La Cristalera residence is located inMiraflores de la Sierra, a village north of Madrid that was acquired by the university in 1989. It is used for conferences and meetings and is the main centre of UAM's summer courses. The UAM is divided into eight faculties and superior schools that support and coordinate most of the university's academic and administrative activity. Each faculty is divided into departments that coordinate the teaching and research of the different subjects. Researchers can organise into research institutes in order to coordinate their activities in a specific research field. The university totals up to 59 departments and eight research institutes. In addition to these, the UAM has seven associate schools, which are not completely part of UAM's administrative structure, but issue UAM-recognised titles and are under UAM's academic regulations. Faculties and superior schools: Associate schools are: UAM administration is established according to the 2023 Organic Law of the University System (LOSU). The Senior Academic and Administrative Officer of the Autonomous University of Madrid is the rector, who must be, by law, a chair professor serving in the university, elected every four years with a two-term limit by universal graded suffrage. The currentrectoris Amaya Mendikoetxea, chair of EnglishLiguistics, who was elected in 2021, becoming the second woman Rector of the University. The rector appoints an indefinite number of vice-rectors to lead different administrative departments of the university (such as Student affairs or Graduate academic affairs), and a secretary general coordinating the rector's team and overseeing the legal procedures of the university, as well as university protocol. Per the university's social board, the rector also designates the manager as part of his team, which oversees the university's economic and administrative activity. The grades assigned to each sector for rectoral elections in UAM according to its charter are: UAM's collective government bodies are the University Assembly, The Board of Governors, and The Social Board. The University Assembly is made up of 153 full professors, 84 students, 27 hired, associate, or emeritus professors, 27 members of the non-teaching personnel, 9 research or teaching trainees, the rector, the secretary-general, and the manager. It is the highest representative body of the university. It elaborates the university's general guidelines, changes or passes a new university charter, elects twenty members of the Board of Governors, and elects the universityOmbudsman. The Board of Governors is the ordinary governmental body of the university. It controls and passes regulations on most of the university's academic, personnel, and administrative issues. It is composed of the rector, the secretary-general, the manager, 20 members elected by the assembly according to its composition, all the deans and the head of the polytechnic school, 7 heads of department, a head of a research institute, 15 members designated by the rector and three members of the Social Board. The Social Board is the body responsible for the relations between the university and society. Its members are designated by trade unions, the municipality of Madrid, employers unions, companies related to the university, the Madrid Assembly and the Board of Governors of the university. It also oversees the universities financial activities and passes the university budget. Its current chairman isManuel Pizarro. Faculties are headed by a dean, whilst the responsible of the polytechnic school is called head. They are elected in the same way as the rector and have also a limit of two four-year terms. They are aided by vice deans or deputy heads. They are overseen by a faculty or school board. Departments are led by the head of the department and overseen by the department council. UAM offers Spanish undergraduates fully recognized degrees. There are theDiplomaturaandIngenierías Técnicas(technical engineering), which are three-year studies equivalent to an associate degree.LicenciaturasandIngenierías Superioresare four to five years studies equivalent to a bachelor's degree. Along with that, UAM offers second levellicenciaturas, which allow people who have a diplomatura to obtain alicenciaturaby taking courses. In other case, they must have at least the first two or three years of alicenciaturaand combined degree, which are very popular among Spanish students. They also offer courses in languages other than Spanish. In addition to the Faculties where the degrees on the different fields of knowledge and science are studied —Faculty of Science, F. of Business and Economic Science, F. of Law, F. of Philosophy and the Arts, F. of Teacher Training and Education, F. of Psychology, F. of Medicine and School of Engineering— there are external centers that teach specific studies and their associated degree: \"La Salle\" Centre of Higher Education, The Red Cross School of Nursing, The Jimenez Diaz Foundation University School of Nursing, The ONCE University School of Physioterapy. UAM offers 94PhDprograms in all of the universities programs. It also offers 72 master's degrees, and with the implementation of theBologna Process16 recognised master's degrees for theacademic yearof 2006–07. In addition, the alliance of the four leading Spanish public Universities, two in Madrid (Autónoma University of Madrid and Universidad Carlos III) and two in Barcelona (Universitat Autònoma de Barcelona,Universitat Pompeu Fabra) allows close collaboration between projects and researchers. Throughout its history, the UAM has been one of Spain's most prominenthigher educationinstitutions,being ranked first amongst Spanish universities by theEl MundoUniversity Supplement (known as \"Las 50 Carreras\").It has also consistently ranked as the #1 law school in Spain for the past 100 years. For the subject \"Mathematics\" the university was ranked within top 51-75 universities in the world (within top 12 in Europe).It was the Spanish university with the most researchers among the most cited according to theThomson Reutersranking citation in 2011. The Autonomous University of Madrid has an active student body, having organised one of Spain's most important events against the dictatorship in 1976 called the Iberian Peoples Festival. It had an attendance of over 70,000. UAM has over a hundred student societies covering activities ranging fromstudent unionismto theatre and music. The oldest active association in UAM is the Law Students Association (AED in Spanish), a left-leaning student union established in 1981. Furthermore, there are new prominent societies in the field of social sciences, such a Debate Society (Sociedad de Debates UAM) and a Model UN society (UAM-I-MUN), both founded and run mainly by law students. UAM does not have a formal student government body, as it has been rejected by students in several occasions, and instead students elect different student unions (usually with difference on political issues) to the different university government bodies. In recent years, UAM students have organised massively to protest against terrorism, after the assassination of Francisco Tomas y Valiente byETAin 1995, against the Organic Law of Universities in 2001, to clean Spain's northern coast after thePrestige oil spillin 2002, against theWar in Iraqin 2003, to assist to the IIEuropean Social Forumalso in 2003, and in solidarity with the victims of the11 March 2004 Madrid train bombings. UAM is also a festive campus, holding several festivals during spring. The most important one was the Spring festival held until 1993, but halted due to overcrowding. Since then minor festivals have been held by student associations. These festivals usually consist of rock concerts by amateur rock bands (many of which have members that are UAM) from midday until dusk. According to university regulations, festival profits have to be destined tocharitiesor to the organisation of cultural events. In 2005, due to overcrowding of the festivals that led to several problems, university officials suspended further festivals until a more convenient place for their celebration would be found. Thus, no festivals were held in 2006. 40°32′43″N3°41′46″W﻿ / ﻿40.5453°N 3.69611°W﻿ /40.5453; -3.69611", "metadata": {"url": "https://en.wikipedia.org/wiki/Autonomous_University_of_Madrid", "title": "Autonomous University of Madrid", "headings": ["Contents", "History", "Campuses", "Main campus", "Medicine campus", "La Cristalera", "Academic organization", "Administrative organisation", "Studies", "Undergraduate", "Graduate", "Research", "Reputation", "Student life", "Societies and compromise", "Festivals and parties", "Notable alumni", "Royalty", "Politics", "Media", "Literature", "Business", "Science", "Noted faculty and researchers", "List of rectors", "Gallery", "See also", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Autonomous_University_of_Madrid", "https://en.wikipedia.org/wiki/Autonomous_University_of_Madrid", "https://en.wikipedia.org/wiki/Autonomous_University_of_Madrid", "https://en.wikipedia.org/wiki/Geographic_coordinate_system", "https://en.wikipedia.org/wiki/University_of_Madrid_(disambiguation)", "https://en.wikipedia.org/wiki/Seal_(emblem)", "https://en.wikipedia.org/wiki/Latin_language", "https://en.wikipedia.org/wiki/Public_university"]}},
{"id": "5c11f29eded7", "content": " John Fitzgerald Kennedy(May 29, 1917 – November 22, 1963), also known asJFK, was the 35thpresident of the United States, serving from 1961 untilhis assassinationin 1963. He was theyoungestpersonelectedpresident at 43 years.Kennedy served at the height of theCold War, and the majority of his foreign policy concerned relations with theSoviet UnionandCuba. A member of theDemocratic Party, Kennedy representedMassachusettsin both houses of theUnited States Congressbefore his presidency. Born into the prominentKennedy familyinBrookline, Massachusetts, Kennedy graduated fromHarvard Universityin 1940, joining theU.S. Naval Reservethe following year. DuringWorld War II, he commandedPT boatsin thePacific theater. Kennedy's survival following the sinking ofPT-109and his rescue of his fellow sailors made him a war hero and earned theNavy and Marine Corps Medal, but left him with serious injuries. After a brief stint in journalism, Kennedy representeda working-class Boston districtin theU.S. House of Representativesfrom 1947 to 1953. He was subsequently elected to theU.S. Senate, serving as the juniorsenator for Massachusettsfrom 1953 to 1960. While in the Senate, Kennedy published his bookProfiles in Courage, which won aPulitzer Prize. Kennedy ran in the1960 presidential election. His campaign gained momentum afterthe first televised presidential debatesin American history, and he was elected president, narrowly defeatingRepublicanopponentRichard Nixon, the incumbent vice president. Kennedy's presidency saw high tensions with communist states in the Cold War. He increased the number ofAmerican military advisersinSouth Vietnam, and theStrategic Hamlet Programbegan during his presidency. In 1961, he authorized attempts to overthrow the Cuban government ofFidel Castroin the failedBay of Pigs InvasionandOperation Mongoose. In October 1962, U.S. spy planes discovered Soviet missile bases had been deployed in Cuba. The resulting period of tensions, termed theCuban Missile Crisis, nearly resulted innuclear war. In August 1961, afterEast Germantroops erected theBerlin Wall, Kennedy sent an army convoy to reassure West Berliners of U.S. support, and deliveredone of his most famous speechesin West Berlin in June 1963. In 1963, Kennedy signed the firstnuclear weapons treaty. He presided over the establishment of thePeace Corps,Alliance for Progresswith Latin America, and the continuation of theApollo programwith the goal oflanding a man on the Moonbefore 1970. He supported thecivil rights movementbut was only somewhat successful in passing hisNew Frontierdomestic policies. On November 22, 1963, Kennedy was assassinated inDallas. His vice president,Lyndon B. Johnson,assumed the presidency.Lee Harvey Oswaldwas arrested for the assassination, but he was shot and killed byJack Rubytwo days later. TheFederal Bureau of Investigation(FBI) and theWarren Commissionboth concluded Oswald had acted alone, butconspiracy theories about the assassinationpersist. After Kennedy's death, Congress enacted many of his proposals, including theCivil Rights Act of 1964and theRevenue Act of 1964. Kennedy ranks highly inpolls of U.S. presidentswith historians and the general public. His personal life has been the focus of considerable sustained interest following public revelations in the 1970s of his chronic health ailments andextramarital affairs. Kennedy is the most recentU.S. president to have died in office. John Fitzgerald Kennedy was born outsideBostoninBrookline, Massachusetts, on May 29, 1917,toJoseph P. Kennedy Sr., a businessman and politician, andRose Kennedy(néeFitzgerald), a philanthropist and socialite.His paternal grandfather,P. J. Kennedy, was an East Bostonward bossandMassachusetts state legislator.Kennedy's maternal grandfather and namesake,John F. Fitzgerald, was a U.S. congressman and two-termmayor of Boston.All four of his grandparents were children of Irish immigrants.Kennedy had an older brother,Joseph Jr., and seven younger siblings:Rosemary,Kathleen,Eunice,Patricia,Robert,Jean, andTed. Kennedy's father amassed a private fortune and establishedtrust fundsfor his nine children, guaranteeing them lifelong financial independence.His business kept him away from home for long stretches, but Joe Sr. was a formidable presence in his children's lives. He encouraged them to be ambitious, emphasized political discussions at the dinner table, and demanded a high level of academic achievement. John's first exposure to politics came in1922, when he touredBoston wardswith his grandfather Fitzgerald during his unsuccessful gubernatorial campaign.In September 1927, due to an outbreak ofpolioinMassachusettsand Joe Sr.'s business interests inWall StreetandHollywood, the family relocated from Boston to theRiverdaleneighborhood of New York City.Several years later, his brother Robert toldLookmagazine that his father left Boston because of job signs that read: \"No Irish Need Apply.\"The Kennedys spent summers and early autumns attheir homeinHyannis Port, Massachusetts, a village onCape Cod,where they engaged in various outdoor activities.Christmas and Easter holidays were spent at theirwinter retreatinPalm Beach, Florida.In September 1930, Kennedy, 13 years old, was sent to theCanterbury SchoolinNew Milford, Connecticut, for 8th grade. In April 1931, he had anappendectomy, after which he withdrew from Canterbury and recuperated at home. In September 1931, Kennedy began attendingChoate, a preparatory boarding school inWallingford, Connecticut.Rose had wanted John and Joe Jr. to attend aCatholic school, but Joe Sr. believed that if they were to compete in the political world, they needed to be among boys from prominentProtestantfamilies.John spent his first years at Choate in his older brother's shadow and compensated with rebellious behavior that attracted a clique. Their most notorious stunt was exploding a toilet seat with a firecracker. In the next chapel assembly, the headmaster, George St. John, brandished the toilet seat and spoke of \"muckers\" who would \"spit in our sea,\" leading Kennedy to name his group \"The Muckers Club.\" It included his roommate and lifelong friendLem Billings.Kennedy graduated from Choate in June 1935, finishing 64th of 112 students.He had been the business manager of the school yearbook and was voted the \"most likely to succeed.\" Kennedy intended to study underHarold Laskiat theLondon School of Economics, as his older brother had done. However, ill health forced his return to the United States in October 1935, when he enrolled late atPrinceton University, but had to withdraw after two months due to gastrointestinal illness. In September 1936, Kennedy enrolled atHarvard College.He wrote occasionally forThe Harvard Crimson, the campus newspaper, but had little involvement with campus politics, preferring to concentrate on athletics and his social life. Kennedy playedfootballand was on the junior varsity squad during his sophomore year, but an injury forced him off the team, and left him with back problems that plagued him for the rest of his life. He earned membership in theHasty Pudding Cluband theSpee Club, one of Harvard's elite \"final clubs\". In July 1938, Kennedy sailed overseas with his older brother to work at theAmerican embassy in London, where their father was serving as PresidentFranklin D. Roosevelt's ambassador to theCourt of St. James's.The following year, Kennedy traveled throughout Europe, theSoviet Union, theBalkans, and the Middle East in preparation for his Harvard senior honors thesis.He then went to Berlin, where a U.S. diplomatic representative gave him a secret message about war breaking out soon to pass on to his father, and toCzechoslovakiabefore returning to London on September 1, 1939—the day thatGermany invaded Poland; the start ofWorld War II.Two days later, the family was in theHouse of Commonsfor speeches endorsing the United Kingdom's declaration of war on Germany. Kennedy was sent as his father's representative to assist with arrangements for American survivors of the torpedoing ofSSAtheniabefore flying back to the United States on his first transatlantic flight. While an upperclassman at Harvard, Kennedy began to take his studies more seriously and developed an interest inpolitical philosophy. He made thedean's listin his junior year.In 1940, Kennedy completed his thesis, \"Appeasement in Munich\", about British negotiations during theMunich Agreement. The thesis was released on July 24, under the titleWhy England Slept.The book was one of the first to offer information about the war and its origins, and quickly became a bestseller.In addition to addressing Britain's unwillingness to strengthen its military in the lead-up to the war, the book called for anAnglo-American allianceagainst the rising totalitarian powers. Kennedy became increasingly supportive of U.S. intervention in World War II, and his father's isolationist beliefs resulted in the latter's dismissal as ambassador. In 1940, Kennedy graduatedcum laudefrom Harvard with a Bachelor of Arts in government, concentrating oninternational affairs.That fall, he enrolled at theStanford Graduate School of Businessand audited classes,but he left after a semester to help his father complete his memoirs as an American ambassador. In early 1941, Kennedy toured South America. Kennedy planned to attendYale Law School, but canceled those plans when American entry into World War II seemed imminent.In 1940, Kennedy attempted to enter the Army'sOfficer Candidate School. Despite months of training, he was medically disqualified due to chronic back problems. On September 24, 1941, with the help ofAlan Goodrich Kirk—the director of theOffice of Naval Intelligence(ONI) and former navalattachéto Joe Sr.—Kennedy joined theUnited States Naval Reserve. He was commissioned as anensignon October 26, 1941,and joined the ONI staff in Washington, D.C. In January 1942, Kennedy was assigned to the ONI field office at Headquarters,Sixth Naval District, inCharleston, South Carolina.He hoped to command aPT (patrol torpedo) boat, but his health problems seemed almost certain to prevent active duty. Kennedy's father intervened by providing misleading medical records and convincing PT officers that his presence would bring publicity to the fleet.Kennedy completed six months of training at theNaval Reserve Officer Training Schoolin Chicago and at theMotor Torpedo Boat Squadrons Training CenterinMelville, Rhode Island.His first command wasPT-101from December 7, 1942, until February 23, 1943.Unhappy with his assignment to thePanama Canal, far from the fighting, Kennedy appealed to SenatorDavid Walshof Massachusetts, who arranged for him to be reassigned to theSouth Pacific. In April 1943, Kennedy was assigned to Motor Torpedo Squadron TWO,and on April 24 he took command ofPT-109,then based onTulagiIsland in theSolomons.On the night of August 1–2, in support of theNew Georgia campaign,PT-109and fourteen other PTs were ordered to block or repel four Japanese destroyers and floatplanes carrying food, supplies, and 900 Japanese soldiers to the Vila Plantation garrison on the southern tip of the Solomon'sKolombangaraIsland. Intelligence had been sent to Kennedy's commander, Thomas G. Warfield, who, as a result, was expecting the arrival of the large Japanese naval force that would pass on the evening of August 1. Of the 24 torpedoes fired that night by eight of the American PTs, not one hit the Japanese convoy.On that moonless night, Kennedy spotted a Japanese destroyer heading north on its return from the base of Kolombangara around 2:00 a.m., and attempted to turn to attack, whenPT-109was suddenly rammed at an angle and cut in half by thedestroyerAmagiri, killing twoPT-109crew members.Avoiding surrender, the remaining crew swam towardPlum Pudding Island, 3.5 miles (5.6 km) southwest of the remains ofPT-109, on August 2.Despite re-injuring his back in the collision, Kennedy towed a badly burned crewman named Patrick McMahonto the island with a life jacket strap clenched between his teeth.From there, Kennedy and his subordinate, Ensign George Ross, made forays through the coral islands, searching for help.When they encountered an English-speaking native with a canoe, Kennedy carved his location on acoconutshell and requested a boat rescue. Seven days after the collision, with the coconut message delivered, thePT-109crew was rescued. Almost immediately, thePT-109rescue became a highly publicized event. The story was chronicled by John Hersey inThe New Yorkerin 1944; decades later, it was the basis of a successfulfilm.It followed Kennedy into politics and provided a strong foundation for his appeal as a leader.Hersey portrayed Kennedy as a modest, self-deprecating hero.For his courage and leadership, Kennedy was awarded theNavy and Marine Corps Medal, and the injuries he suffered during the incident qualified him for aPurple Heart. After a month's recovery, Kennedy returned to duty, commandingPT-59. On November 2, Kennedy'sPT-59, along with two other PT boats, took part in the rescue of 40 to 50 Marines. The59acted as a shield from shore fire as they escaped on two rescue landing craft at the base of the Warrior River onChoiseul Island, taking ten Marines aboard and delivering them to safety.Under doctor's orders, Kennedy was relieved of his command on November 18, and sent to the hospital on Tulagi.By December 1943, with his health deteriorating, Kennedy left the Pacific front and arrived in San Francisco in early January 1944.After receiving treatment for his back injury at theChelsea Naval Hospitalin Massachusetts from May to December 1944, he was released from active duty.Beginning in January 1945, Kennedy spent three months recovering from his back injury atCastle Hot Springs, a resort and temporary military hospital in Arizona.On March 1, 1945, Kennedy retired from the Navy Reserve on physical disability and was honorably discharged with the full rank of lieutenant.When later asked how he became a war hero, Kennedy joked: \"It was easy. They cut my PT boat in half.\" On August 12, 1944, Kennedy's older brother,Joe Jr., a Navy pilot, was killed during an air mission. His body was never recovered.News of his death reached the family's home in Hyannis Port, Massachusetts, a day later. Kennedy felt that Joe Jr.'s reckless flight was partly an effort to outdo him.To console himself, Kennedy set out to assemble a privately published book of remembrances of his brother,As We Remember Joe. In April 1945, Kennedy's father, who was a friend ofWilliam Randolph Hearst, arranged a position for his son as a special correspondent forHearst Newspapers; the assignment kept Kennedy's name in the public eye and \"expose[d] him to journalism as a possible career\".He covered theUnited Nations Conference on International OrganizationinSan Francisco, theBritish elections, and thePotsdam Conferencein Germany. Kennedy's elder brother, Joe Jr., had been thefamily's political standard-bearerand was tapped by their father to seek the presidency. After Joe's death, the assignment fell to John as the second eldest.Boston mayorMaurice J. Tobindiscussed the possibility of John becoming his running mate in1946as a candidate forMassachusetts lieutenant governor, but Joe Sr. preferred a congressional campaign that could send John to Washington, where he could have national visibility. At the urging of Joe Sr., U.S. RepresentativeJames Michael Curleyvacated his seat in the solidly Democratic11th congressional district of Massachusettsto become mayor of Boston in 1946. Kennedy established legal residency at 122 Bowdoin Street across from theMassachusetts State House.He won the Democratic primary with 42 percent of the vote, defeating nine other candidates.According to Fredrik Logevall, Joe Sr. spent hours on the phone with reporters and editors, seeking information, trading confidences, and cajoling them into publishing puff pieces on John, ones that invariably played up his war record in the Pacific. He oversaw a professional advertising campaign that ensured ads went up in just the right places. The campaign had a virtual monopoly on[Boston] subwayspace, and on window stickers (\"Kennedy for Congress\") for cars and homes, and was the force behind the mass mailing of Hersey'sPT-109article. Though Republicans took control of the House in the1946 elections, Kennedy defeated his Republican opponent in the general election, taking 73 percent of the vote. As a congressman, Kennedy had a reputation for taking little interest in the management of his office or his constituents' concerns, with one of the highest absenteeism rates in the House, although much was explained by illness.George Smathers, one of his few political friends at the time, claimed that he was more interested in being a writer than a politician, and at that time, he suffered from extreme shyness.Kennedy found \"most of his fellow congressmen boring, preoccupied as they all seemed to be with their narrow political concerns\". The arcane House rules and customs, which slowed legislation, exasperated him. Kennedy served in the House for six years, joining the influentialEducation and Labor Committeeand theVeterans' Affairs Committee.He concentrated his attention on international affairs, supporting theTruman Doctrineas an appropriate response to the emergingCold War.He also supportedpublic housingand opposed theLabor Management Relations Act of 1947, which restricted the power of labor unions.Though not as vocally anti-communist asJoseph McCarthy, Kennedy supported theInternal Security Act of 1950, which required communists to register with the government, and he deplored the \"loss of China\".Kennedy denounced Truman and the State Department during a speech inSalem, Massachusettson January 30, 1949, for contributing to the \"tragic story of China whose freedom we once fought to preserve. What our young men had saved [in World War II], our diplomats and our President have frittered away.\"Having served as aBoy Scoutduring his childhood, Kennedy was active in theBoston Councilfrom 1946 to 1955 as district vice chairman, member of the executive board, vice-president, and National Council Representative. To appeal to the largeItalian-Americanvoting bloc in Massachusetts, Kennedy delivered a speech in November 1947 supporting a $227 million aid package to Italy. He maintained that Italy was in danger from an \"onslaught of the communist minority\" and that the country was the \"initial battleground in the communist drive to capture Western Europe.\"To counter Soviet efforts to take control in Middle Eastern and Asian countries likeIndochina, Kennedy wanted the United States to develop nonmilitary techniques of resistance that would not create suspicions ofneoimperialismor add to the country's financial burden. The problem, as he saw it, was not simply to be anti-communist but to stand for something that these emerging nations would find appealing. Almost every weekend that Congress was in session, Kennedy would fly back to Massachusetts to give speeches to veteran, fraternal, and civic groups, while maintaining an index card file on individuals who might be helpful in a future statewide campaign.Contemplating whether to run forMassachusetts governoror theU.S. Senate, Kennedy abandoned interest in the former, believing that the governor \"sat in an office, handing out sewer contracts\". As early as 1949, Kennedy began preparing to run for the Senate in1952against Republican three-term incumbentHenry Cabot Lodge Jr.with the campaign slogan \"KENNEDY WILL DOMOREFOR MASSACHUSETTS\".Joe Sr. again financed his son's candidacy—persuading theBoston Postto switch its support to Kennedy by promising the publisher a $500,000 loan—while John's younger brotherRobertemerged as campaign manager.Kennedy's mother and sisters were also highly effective canvassers, hosting a series of \"teas\" at hotels and parlors across Massachusetts to reach out to women voters.In the presidential election, RepublicanDwight D. Eisenhowercarried Massachusetts by 208,000 votes, but Kennedy narrowly defeated Lodge by 70,000 votes for the Senate seat.The following year, he marriedJacqueline Bouvier. Kennedy underwent several spinal operations over the next two years. Often absent from the Senate, he was at times critically ill and received Catholiclast rites. During his convalescence in 1956, he publishedProfiles in Courage, a book about U.S. senators who risked their careers for their personal beliefs, for which he won thePulitzer Prize for Biographyin 1957.Rumors that this work wasghostwrittenby his close adviser andspeechwriter,Ted Sorensen, were confirmed in Sorensen's 2008 autobiography. At the start of his first term, Kennedy focused on fulfilling the promise of his campaign to do \"more for Massachusetts\" than his predecessor. Although Kennedy's and Lodge's legislative records were similarly liberal, Lodge voted for theTaft-Hartley Act of 1947and Kennedy voted against it. OnNBC'sMeet the Press, Kennedy excoriated Lodge for not doing enough to prevent the increasing migration of manufacturing jobs from Massachusetts to the South, and blamed theright-to-workprovision for giving the South an unfair advantage over Massachusetts in labor costs.In May 1953, Kennedy introduced \"The Economic Problems of New England\",a 36-point programto help Massachusetts industries such asfishing,textile manufacturing,watchmaking, andshipbuilding, as well as the Boston seaport.Kennedy's policy agenda includedprotective tariffs, preventing excessivespeculationin rawwool, stronger efforts to research and marketAmerican fish products, an increase in theFish and Wildlife Servicebudget (including funds forUS FWSAlbatross III), funds to rehabilitate theSouth Boston Army Base, shipbuilding contracts at theFore River ShipyardinQuincy, Massachusetts, and the development ofhydroelectricandnuclear powerin New England—such as theYankee Rowe Nuclear Power StationinRowe, Massachusetts, which began construction in 1958.Kennedy's suggestions for stimulating the region's economy appealed to both parties by offering benefits to business and labor, and promising to serve national defense. Congress would eventually enact most of the program.AMassachusetts Audubon Societysupporter, Kennedy wanted to make sure that the shorelines ofCape Codremained unsullied by industrialization. On September 3, 1959, Kennedy co-sponsored theCape Cod National Seashorebill with his Republican colleague SenatorLeverett Saltonstall. As a senator, Kennedy quickly won a reputation for responsiveness to requests from constituents (i.e., co-sponsoring legislation to provide federal loans to help rebuild communities damaged by the1953 Worcester tornado), except on certain occasions when the national interest was at stake.In 1954, Kennedy voted in favor of theSaint Lawrence Seawaywhich would connect the Great Lakes to the Atlantic Ocean, despite opposition from Massachusetts politicians who argued that the project would hurt thePort of Bostoneconomically. In 1954, when the Senate voted to condemnJoseph McCarthyfor breaking Senate rules and abusing an Army general, Kennedy was the only Democrat not to cast a vote against him.Kennedy drafted a speech supporting the censure. However, it was not delivered because Kennedy was hospitalized for back surgery in Boston.Although Kennedy never indicated how he would have voted, the episode damaged his support among members of theliberalcommunity in the 1956 and 1960 elections. In 1956, Kennedy gained control of theMassachusetts Democratic Party,and delivered the state delegation to the party's presidential nominee,Adlai Stevenson II, at theDemocratic National Conventionin August.Stevenson let the conventionselect the vice presidential nominee. Kennedy finished second in the balloting, losing to SenatorEstes Kefauverof Tennessee, but receiving national exposure. In 1957, Kennedy joined the Senate'sSelect Committee on Labor Rackets(also known as the McClellan Committee) with his brother Robert, who was chief counsel, to investigateracketeeringin labor-management relations.The hearings attracted extensive radio and television coverage where the Kennedy brothers engaged in dramatic arguments with controversial labor leaders, includingJimmy Hoffaof theTeamsters Union. The following year, Kennedy introduced a bill to prevent the expenditure ofunion duesfor improper purposes or private gain; to forbid loans from union funds for illicit transactions; and to compelauditsof unions, which would ensure against falsefinancial reports.It was the first major labor relations bill to pass either house since the Taft–Hartley Act of 1947 and dealt largely with the control of union abuses exposed by the McClellan Committee, but did not incorporate tough Taft–Hartley amendments requested by President Eisenhower. It survived Senate floor attempts to include Taft-Hartley amendments and passed but was rejected by the House.\"Honest union members and the general public can only regard it as a tragedy that politics has prevented the recommendations of the McClellan committee from being carried out this year,\" Kennedy announced. That same year, Kennedy joined the Senate'sForeign Relations Committee.There he supportedAlgeria's effort to gain independencefrom France and sponsored an amendment to theMutual Defense Assistance Actthat would provide aid toSoviet satellite nations. Kennedy in 1959 introduced a controversial bill to eliminate from theNational Defense Education Actof 1958 a provision requiring loyalty oaths and affidavits from aid recipients. Kennedy cast a procedural vote against President Eisenhower's bill for theCivil Rights Act of 1957, and this was considered by some to be an appeasement of Southern Democratic opponents of the bill.Kennedy did vote for Title III of the act, which would have given the Attorney General powers to enjoin, but Majority LeaderLyndon B. Johnsonagreed to let the provision die as a compromise measure.Kennedy also voted for the \"Jury Trial Amendment.\" Many civil rights advocates criticized the vote as one that would weaken the Act.A final compromise bill, which Kennedy supported, was passed in September 1957.As a senator from Massachusetts, which lacked a sizable Black population, Kennedy was not particularly sensitive to the problems of African Americans. Robert Kennedy later reflected, \"We weren't thinking of the Negroes of Mississippi or Alabama—what should be done for them. We were thinking of what needed to be done in Massachusetts.\" Most historians and political scientists who have written about Kennedy refer to his U.S. Senate years as an interlude.According to historianRobert Dallek, Kennedy called being a senator \"the most corrupting job in the world.\" He complained that they were all too quick to cut deals and please campaign contributors to ensure their political futures. Kennedy, with the luxury of a rich father who could finance his campaigns, could remain independent of any special interest, except for those in his home state of Massachusetts that could align against his reelection.According to authorRobert Caro, Majority Leader Lyndon Johnson viewed Kennedy as a \"playboy\", describing his performance in the Senate and the House as \"pathetic\" on another occasion, saying that he was \"smart enough, but he doesn't like the grunt work\".Author John T. Shaw acknowledges that while his Senate career is not associated with acts of \"historic statesmanship\" or \"novel political thought,\" Kennedy made modest contributions as a legislator, drafting more than 300 bills to benefit Massachusetts and the New England region, some of which became law. In1958, Kennedy was re-elected to the Senate, defeating his Republican opponent, Boston lawyer Vincent J. Celeste, with 73.6 percent of the vote, the largest winning margin in the history of Massachusetts politics.In the aftermath of his re-election, Kennedy began preparing to run for president by traveling throughout the U.S. to build his candidacy for 1960. On January 2, 1960, Kennedy announced his candidacy for theDemocratic presidential nomination.Though some questioned Kennedy's age and experience, his charisma and eloquence earned him numerous supporters. Kennedy faced several potential challengers, including Senate Majority Leader Lyndon Johnson,Adlai Stevenson II, and SenatorHubert Humphrey. Kennedy traveled extensively to build his support. His campaign strategy was to win several primaries to demonstrate his electability to theparty bosses, who controlled most of the delegates, and to prove to his detractors that a Catholic could win popular support.Victories over Senator Humphrey in the Wisconsin and West Virginia primaries gave Kennedy momentum as he moved on to the1960 Democratic National Conventionin Los Angeles. When Kennedy entered the convention, he had the most delegates, but not enough to ensure that he would win the nomination.Stevenson—the 1952 and 1956 presidential nominee—remained very popular, while Johnson also hoped to win the nomination with support from party leaders. Kennedy's candidacy also faced opposition from former PresidentHarry S. Truman, who was concerned about Kennedy's lack of experience. Kennedy knew that a second ballot could give the nomination to Johnson or someone else, and his well-organized campaign was able to earn the support of just enough delegates to win the presidential nomination on the first ballot. Kennedy ignored the opposition of his brother Robert, who wanted him to choose labor leaderWalter Reuther,and other liberal supporters when hechose Johnsonas his vice-presidential nominee. He believed that the Texas senator could help him win support from theSouth.In accepting the presidential nomination, Kennedy gave his well-known \"New Frontier\" speech: For the problems are not all solved and the battles are not all won—and we stand today on the edge of a New Frontier. ... But the New Frontier of which I speak is not a set of promises—it is a set of challenges. It sums up not what I intend to offer the American people, but what I intend to ask of them. At the start of the fall general election campaign, the Republican nominee and incumbent Vice President Richard Nixon held a six-point lead in the polls.Major issues included how to get the economy moving again, Kennedy's Catholicism, theCuban Revolution, and whether the space and missile programs of the Soviet Union hadsurpassedthose of the U.S. To address fears that his Catholic faith would impact his decision-making, he told the Greater Houston Ministerial Association on September 12: \"I am not the Catholic candidate for president. I am the Democratic Party candidate for president who also happens to be a Catholic. I do not speak for my Church on public matters—and the Church does not speak for me.\"He promised to respect theseparation of church and state, and not to allow Catholic officials to dictate public policy. The Kennedy and Nixon campaigns agreed to a series oftelevised debates.An estimated 70 million Americans, about two-thirds of the electorate, watched the first debate on September 26.Kennedy had met the day before with the producer to discuss the set design and camera placement. Nixon, recently released from the hospital after a painful knee injury, did not take advantage of this opportunity and, during the debate, looked at the reporters asking questions and not at the camera. Kennedy wore a blue suit and shirt to reduce glare and appeared sharply focused against the gray studio background. Nixon wore a light-colored suit that blended into the gray background; in combination with the harsh studio lighting that left Nixon perspiring, he offered a less-than-commanding presence. By contrast, Kennedy appeared relaxed, tanned, and telegenic, looking into the camera while answering questions.It is often claimed that television viewers overwhelmingly believed Kennedy, appearing to be the more attractive of the two, had won, while radio listeners (a smaller audience) thought Nixon had defeated him.However, only one poll split TV and radio voters like this and the methodology was poor.PollsterElmo Roperconcluded that the debates raised interest, boosted turnout, and gave Kennedy an estimated two million additional votes, largely due to the first debate.The debates are now considered a milestone in American political history—the point at which the medium of television began to play a dominant role. Kennedy's campaign gained momentum after the first debate, and he pulled slightly ahead of Nixon in most polls. On Election Day, Kennedy defeated Nixon in one of the closest presidential elections of the 20th century. In the national popular vote,by most accounts, Kennedy led Nixon by just two-tenths of one percent (49.7% to 49.5%), while in theElectoral College, he won 303 votes to Nixon's 219 (269 were needed to win).Fourteen electors from Mississippi and Alabama refused to support Kennedy because he supported thecivil rights movement; they voted for SenatorHarry F. Byrdof Virginia, as did an elector from Oklahoma.Forty-three years old, Kennedy was theyoungest personever elected to the presidency (thoughTheodore Rooseveltwas a year younger when he succeeded to the presidency after theassassination of William McKinleyin 1901). Kennedy was sworn in as the 35th president at noon on January 20, 1961. Inhis inaugural address, he spoke of the need for all Americans to be active citizens: \"Ask not what your country can do for you—ask what you can do for your country.\" He asked the nations of the world to join to fight what he called the \"common enemies of man: tyranny, poverty, disease, and war itself.\"He added: \"All this will not be finished in the first one hundred days. Nor will it be finished in the first one thousand days, nor in the life of this Administration, nor even perhaps in our lifetime on this planet. But let us begin.\" In closing, he expanded on his desire for greater internationalism: \"Finally, whether you are citizens of America or citizens of the world, ask of us here the same high standards of strength and sacrifice which we ask of you.\" The address reflected Kennedy's confidence that his administration would chart a historically significant course in both domestic policy and foreign affairs. The contrast between this optimistic vision and the pressures of managing daily political realities would be one of the main tensions of the early years of his administration. Kennedy scrapped the decision-making structure of Eisenhower,favoring an organizational model resembling a wheel, with all spokes leading to the president. He was willing to make the increased number of rapid decisions required in such an environment.Though the cabinet remained important, Kennedy generally relied more on his staffers within theExecutive Office.Despite concerns overnepotism, Kennedy's father insisted that Robert Kennedy becomeU.S. Attorney General, and the younger Kennedy became the \"assistant president\" who advised on all major issues. Kennedy's foreign policy was dominated by American confrontations with the Soviet Union, manifested by proxy contests in the global state of tension known as theCold War. Like his predecessors, Kennedy adopted the policy ofcontainmentto stop the spread of communism.Fearful of the possibility ofnuclear war, Kennedy implemented a defense strategy known asflexible response. This strategy relied on multiple options for responding to the Soviet Union, discouragedmassive retaliation, and encouragedmutual deterrence.In contrast to Eisenhower's warning about the perils of themilitary-industrial complex, Kennedy focused on rearmament. From 1961 to 1964 the number ofnuclear weaponsincreased by 50 percent, as did the number ofB-52bombers to deliver them. In January 1961,Soviet PremierNikita Khrushchevdeclared his support forwars of national liberation. Kennedy interpreted this step as a direct threat to the \"free world.\" Between 1960 and 1963,twenty-four countriesgained independence as the process ofdecolonizationcontinued. Kennedy set out to woo the leaders and people of the \"Third World,\" expanding economic aid and appointing knowledgeable ambassadors.His administration established theFood for Peaceprogram and thePeace Corpsto provide aid todeveloping countries. The Food for Peace program became a central element in American foreign policy, and eventually helped many countries to develop their economies and become commercial import customers. During the election campaign, Kennedy attacked the Eisenhower administration for losing ground on the African continent,and stressed that the U.S. should be on the side of anti-colonialism and self-determination.Kennedy considered theCongo Crisisto be among the most important foreign policy issues facing his presidency, and he supported aUN operationthat prevented the secession ofKatanga.Moïse Tshombe, leader of Katanga, declared its independence from the Congo, and the Soviet Union responded by sending weapons and technicians to underwrite their struggle.On October 2, 1962, Kennedy signed the United Nations bond issue bill to ensure U.S. assistance in financing UN peacekeeping operations in the Congo and elsewhere. In one of his first presidential acts, Kennedy signedExecutive Order10924 that officially started thePeace Corps. He named his brother-in-law,Sargent Shriver, as its first director.Through this program, Americans volunteered to help developing countries in fields like education, farming, health care, and construction.Kennedy believed that countries that received Peace Corps volunteers were less likely to succumb to a communist revolution.Tanganyika(present-dayTanzania) andGhanawere the first countries to participate.The organization grew to 5,000 members by March 1963 and 10,000 the year after.Since 1961, over 200,000 Americans have joined the Peace Corps, representing 139 countries. Kennedy anxiously anticipated a summit with Nikita Khrushchev. The proceedings for the summit got off to a problematic start when Kennedy reacted aggressively to a routine Khrushchev speech on Cold War confrontation in early 1961. The speech was intended for domestic audiences in the Soviet Union, but Kennedy interpreted it as a personal challenge. His mistake helped raise tensions going into theVienna summit.The summit would cover several topics, but both leaders knew that the most contentious issue would beBerlin, which had been divided in two with the start of the Cold War. The enclave ofWest Berlinlay within Soviet-alliedEast Germany, but was supported by the U.S. and other Western powers. The Soviets wanted to reunify Berlin under the control of East Germany, partly due to the large number of East Germans who had fled to West Berlin. On June 4, 1961, Kennedy met with Khrushchev in Vienna and left the meeting angry and disappointed that he had allowed the premier to bully him, despite the warnings he had received. Khrushchev, for his part, was impressed with the president's intelligence but thought him weak. Kennedy did succeed in conveying the bottom line to Khrushchev on the most sensitive issue before them, a proposed treaty between Moscow andEast Berlin. He made it clear that any treaty interfering with U.S. access rights in West Berlin would be regarded as an act of war.Shortly after Kennedy returned home, the Soviet Union announced its plan to sign a treaty with East Berlin, abrogating any third-party occupation rights in either sector of the city. Kennedy assumed that his only option was to prepare the country for nuclear war, which he thought had a one-in-five chance of occurring. In the weeks immediately following the summit, more than 20,000 peoplefled from East Berlinto the western sector, reacting to statements from the Soviet Union. Kennedy began intensive meetings on the Berlin issue, whereDean Achesontook the lead in recommending a military buildup alongside NATO allies.In a July 1961 speech, Kennedy announced his decision to add $3.25 billion (equivalent to $34.2 billion in 2024) to the defense budget, along with over 200,000 additional troops, stating that an attack on West Berlin would be taken as an attack on the U.S. The speech received an 85% approval rating. A month later, both the Soviet Union and East Berlin began blocking any further passage of East Germans into West Berlin and erectedbarbed-wirefences, which were quickly upgraded to theBerlin Wall. Kennedy acquiesced to the wall, though he sent Vice President Johnson to West Berlin to reaffirm U.S. commitment to the enclave's defense. In the following months, in a sign of rising Cold War tensions, both the U.S. and the Soviet Union ended a moratorium on nuclear weapon testing.A brief stand-off between U.S. and Soviet tanks occurred atCheckpoint Charliein October following a dispute over free movement of Allied personnel. Thecrisiswas defused largely through a backchannel communication the Kennedy administration had set up with Soviet spyGeorgi Bolshakov.In remarks to his aides on the Berlin Wall, Kennedy noted that \"it's not a very nice solution, but a wall is a hell of a lot better than a war.\" The Eisenhower administration had created a plan to overthrowFidel Castro's regime though an invasion of Cuba by a counter-revolutionary insurgency composed of U.S.-trained, anti-CastroCuban exilesled byCIAparamilitary officers.Kennedy had campaigned on a hardline stance against Castro, and when presented with the plan that had been developed under the Eisenhower administration, he enthusiastically adopted it regardless of the risk of inflaming tensions with the Soviet Union.Kennedy approved the final invasion plan on April 4, 1961. On April 15, 1961, eight CIA-suppliedB-26bombers left Nicaragua to bomb Cuban airfields. The bombers missed many of their targets, leaving most of Castro's air force intact.On April 17, the 1,500 U.S.-trained Cuban exile invasion force, known asBrigade 2506, landed at beaches along theBay of Pigsand immediately came under heavy fire.The goal was to spark a widespread popular uprising against Castro, but no such uprising occurred.No U.S. air support was provided.The invading force was defeated within two days by theCuban Revolutionary Armed Forces;114 were killed and Kennedy was forced to negotiate for the release of the 1,189 survivors.After twenty months, Cuba released the captured exiles in exchange for a ransom of $53 million worth of food and medicine.The incident made Castro wary of the U.S. and led him to believe that another invasion would take place. BiographerRichard Reevessaid that Kennedy focused primarily on the political repercussions of the plan rather than military considerations. When it proved unsuccessful, he was convinced that the plan was a setup to make him look bad.He took responsibility for the failure, saying, \"We got a big kick in the leg and we deserved it. But maybe we'll learn something from it.\"Kennedy's approval ratings climbed afterwards, helped in part by the vocal support given to him by Nixon and Eisenhower.He appointed Robert Kennedy to help lead a committee to examine the causes of the failure.The Kennedy administrationbanned all Cuban importsand convinced theOrganization of American States(OAS) to expel Cuba. In late 1961, the White House formed the Special Group (Augmented), headed by Robert Kennedy and includingEdward Lansdale, SecretaryRobert McNamara, and others. The group's objective—to overthrow Castro via espionage, sabotage, and other covert tactics—was never pursued.In November 1961, he authorizedOperation Mongoose.In March 1962, Kennedy rejectedOperation Northwoods, proposals forfalse flagattacks against American military and civilian targets,and blaming them on the Cuban government to gain approval for a war against Cuba. However, the administration continued to plan for an invasion of Cuba in the summer of 1962. In the aftermath of the Bay of Pigs invasion, Khrushchev increased economic and military assistance to Cuba.The Soviet Union planned to allocate in Cuba 49medium-range ballistic missiles, 32intermediate-range ballistic missiles, 49 lightIl-28bombers and about 100tactical nuclear weapons.The Kennedy administration viewed the growingCuba-Soviet alliancewith alarm, fearing that it could eventually pose a threat to the U.S.On October 14, 1962, CIAU-2spy planestook photographsof the Soviets' construction of intermediate-range ballistic missile sites in Cuba. The photos were shown to Kennedy on October 16; a consensus was reached that the missiles were offensive in nature and posed an immediate nuclear threat. Kennedy faced a dilemma: if the U.S. attacked the sites, it might lead to nuclear war with the Soviet Union, but if the U.S. did nothing, it would be faced with the increased threat from close-range nuclear weapons (positioned approximately 90 mi (140 km) away from the Florida coast).The U.S. would also appear to the world as less committed to the defense of the Western Hemisphere. On a personal level, Kennedy needed to show resolve in reaction to Khrushchev, especially after the Vienna summit.To deal with the crisis, he formed an ad-hoc body of key advisers, later known asEXCOMM, that met secretly between October 16 and 28. More than a third ofU.S. National Security Council(NSC) members favored an unannounced air assault on the missile sites, but some saw this as \"Pearl Harborin reverse.\"There was some concern from the international community (asked in confidence) that the assault plan was an overreaction, given that Eisenhower had placedPGM-19 Jupitermissiles in Italy and Turkey in 1958. It also could not be assured that the assault would be 100% effective.In concurrence with a majority vote of the NSC, Kennedy decided on anaval blockade(or \"quarantine\"). On October 22, after privately informing the cabinet and leading members of Congress about the situation, Kennedy announced the naval blockade on national television and warned that U.S. forces would seize \"offensive weapons and associated materiel\" that Soviet vessels might attempt to deliver to Cuba. The U.S. Navy would stop and inspect all Soviet ships arriving off Cuba, beginning October 24. Several Soviet ships approached the blockade line, but they stopped or reversed course.The OAS gave unanimous support to the removal of the missiles. Kennedy exchanged two sets of letters with Khrushchev, to no avail.UN Secretary GeneralU Thantrequested both parties to reverse their decisions and enter a cooling-off period. Khrushchev agreed, but Kennedy did not.Kennedy managed to preserve restraint when a Soviet missile unauthorizedly downed a U.S. Lockheed U-2 reconnaissance aircraft over Cuba, killing pilotRudolf Anderson. At the president's direction, Robert Kennedy privately informed Soviet AmbassadorAnatoly Dobryninthat the U.S. would remove the Jupiter missiles from Turkey \"within a short time after this crisis was over.\"On October 28, Khrushchev agreed to dismantle the missile sites, subject to UN inspections.The U.S. publicly promised never to invade Cuba and privately agreed to remove its Jupiter missiles from Italy and Turkey, which were by then obsolete and had been supplanted by submarines equipped withUGM-27 Polarismissiles. In the aftermath, aMoscow–Washington hotlinewas established to ensure clear communications between the leaders of the two countries.This crisis brought the world closer to nuclear war than at any point before or after, but \"the humanity\" of Khrushchev and Kennedy prevailed.The crisis improved the image of American willpower and the president's credibility. Kennedy's approval rating increased from 66% to 77% immediately thereafter. Believing that \"those who make peaceful revolution impossible, will make violent revolution inevitable,\"Kennedy sought to contain the perceived threat of communism in Latin America by establishing theAlliance for Progress, which sent aid to some countries and sought greaterhuman rightsstandards in the region.In response to Kennedy's plea, Congress voted for an initial grant of $500 million in May 1961.The Alliance for Progress supported the construction of housing, schools, airports, hospitals, clinics and water-purification projects as well as the distribution of free textbooks to students.However, the program did not meet many of its goals. Massive land reform was not achieved; populations more than kept pace with gains in health and welfare; and according to one study, only 2 percent of economic growth in 1960s Latin America directly benefited the poor.U.S. presidents after Kennedy were less supportive of the program and by 1973, the permanent committee established to implement the Alliance was disbanded by the OAS. The Eisenhower administration, through the CIA, had begun formulating plans to assassinate Castro in Cuba andRafael Trujilloin theDominican Republic. When Kennedy took office, he privately instructed the CIA that any plan must includeplausible deniabilityby the U.S. His public position was in opposition.In June 1961, the Dominican Republic's leader was assassinated; in the days following, Undersecretary of StateChester Bowlesled a cautious reaction by the nation. Robert Kennedy, who saw an opportunity for the U.S., called Bowles \"a gutless bastard\" to his face. After the election, Eisenhower emphasized to Kennedy that the communist threat in Southeast Asia required priority; Eisenhower consideredLaosto be \"the cork in the bottle\" in regards to the regional threat.In March 1961, Kennedy voiced a change in policy from supporting a \"free\" Laos to a \"neutral\" Laos, indicating privately thatVietnamshould be deemed America's tripwire for communism's spread in the area.Though he was unwilling to commit U.S. forces to a major military intervention in Laos, Kennedy did approveCIA activitiesdesigned to defeat Communist insurgents through bombing raids and the recruitment of theHmong people. During his presidency, Kennedy continued policies that provided political, economic, and military support to theSouth Vietnamesegovernment.Vietnam had been divided into a communist North Vietnam and a non-communist South Vietnam after the1954 Geneva Conference, but Kennedy escalated American involvement in Vietnam in 1961 by financing theSouth Vietnam army, increasing the number of U.S.military advisorsabove the levels of the Eisenhower administration, and authorizing U.S. helicopter units to provide support to South Vietnamese forces.On January 18, 1962, Kennedy formally authorized escalated involvement when he signed the National Security Action Memorandum (NSAM) – \"Subversive Insurgency (War of Liberation).\"Operation Ranch Hand, a large-scale aerial defoliation effort using the herbicideAgent Orange, began on the roadsides of South Vietnam to combatguerrilla defendants. Though Kennedy provided support for South Vietnam throughout his tenure, Vietnam remained a secondary issue for the Kennedy administration until 1963.On September 2, Kennedy declared in an interview withWalter CronkiteofCBS: In the final analysis, it is their war. They are the ones who have to win it or lose it. We can help them, we can give them equipment, we can send our men out there as advisers, but they have to win it, the people of Vietnam, against the Communists... But I don't agree with those who say we should withdraw. That would be a great mistake... [The United States] made this effort to defend Europe. Now Europe is quite secure. We also have to participate—we may not like it—in the defense of Asia. Kennedy increasingly soured on the president of South Vietnam,Ngo Dinh Diem, whose violentcrackdown on Buddhist practicesgalvanized opposition to his leadership. In August 1963,Henry Cabot Lodge Jr.replacedFrederick Noltingas the U.S. ambassador to South Vietnam. Days after his arrival in South Vietnam, Lodge reported that several South Vietnamese generals sought the assent of the U.S. government to their plan of removing Diem from power. The Kennedy administration was split regarding not just the removal of Diem, but also their assessment of the military situation and the proper U.S. role in the country. After the State Department sent adiplomatic cableto Lodge that ordered him to pressure Diem to remove military authority from his brother,Ngô Đình Nhu, or face potential withdrawal of U.S. support and removal from power,Kennedy instructed Lodge to offer covert assistance to a coup d'état, excluding assassination.On November 1, 1963, a junta of senior military officers executed thecoupwhich led to thearrest and assassinations of Diem and Nhuon November 2. By November 1963, there were 16,000 American military personnel in South Vietnam, up from Eisenhower's 900 advisors;more than one hundred Americans had been killed in action and no final policy decision was made.In the aftermath of the aborted coup in September 1963, the Kennedy administration reevaluated its policies in South Vietnam. Kennedy rejected the full-scale deployment of ground soldiers but also the total withdrawal of U.S. forces.Historians disagree on whether the U.S. military presence in Vietnam would have escalated had Kennedy survived and been re-elected in 1964.Fueling the debate are statements made by Secretary of Defense McNamara in the 2003 documentary filmThe Fog of Warthat Kennedy was strongly considering pulling out of Vietnam after the 1964 election,and comments made by Kennedy administrationWhite House Counseland speechwriterTed Sorensenin a 2008 memoir suggesting that Kennedy was undecided about what policy direction to take. On October 11, 1963, Kennedy signedNSAM 263ordering the withdrawal of 1,000 military personnel by the end of the year following the third recommendation of theMcNamara–Taylor missionreport, which concluded that the training program for the South Vietnamese military had sufficiently progressed to justify the withdrawal.However, NSAM 263 also approved the first recommendation of the report to continue providing support to South Vietnam to prevent the spread of communism and until theViet Congwas suppressed, while the third recommendation suggested that even if the majority of the U.S. military objective was completed by the end of 1965 that continued presence of U.S. training personnel in more limited numbers could be necessary if the insurgency was not suppressed. In 1963, Germany was enduring a time of particular vulnerability due to Soviet aggression to the east as well as the impending retirement of West German ChancellorAdenauer.At the same time, French President Charles de Gaulle was trying to build a Franco-West German counterweight to the American and Soviet spheres of influence.To Kennedy's eyes, this Franco-German cooperation seemed directed againstNATO's influence in Europe. To reinforce the U.S. alliance with West Germany, Kennedy travelled to West Germany and West Berlin in June 1963. On June 26, Kennedy toured West Berlin, culminating in a public speech at the city hall in front of hundreds of thousands of enthusiastic Berliners.He reiterated the American commitment to Germany and criticized communism, and was met with an ecstatic response from the massive audience.Kennedy used the construction of the Berlin Wall as an example of the failures of communism: \"Freedom has many difficulties, and democracy is not perfect. But we have never had to put a wall up to keep our people in, to prevent them from leaving us.\" The speech is known for its famous phrase\"Ich bin ein Berliner\"(\"I am a Berliner\"). Kennedy ended the arms embargo that the Truman and Eisenhower administrations had enforced onIsraelin favor of increased security ties, becoming the founder of theU.S.-Israeli military alliance. Describing the protection of Israel as a moral and national commitment, he was the first to introduce the concept of a 'special relationship' between the U.S. and Israel.In 1962, the Kennedy administration sold Israel a major weapon system, theHawk antiaircraft missile. Historians differ as to whether Kennedy pursued security ties with Israel primarily to shore up support with Jewish-American voters or because he admired the Jewish state. In December 1961,Abd al-Karim Qasim's Iraqi government passed Public Law 80, which restricted the partially American-controlledIraq Petroleum Company(IPC)'sconcessionary holdingto those areas in which oil was actually being produced (namely, the fields atAz ZubairandKirkuk), effectively expropriating 99.5% of the IPC concession. British and U.S. officials demanded that the Kennedy administration place pressure on the Qasim regime.In April 1962, the State Department issued new guidelines on Iraq that were intended to increase American influence. Meanwhile, Kennedy instructed the CIA—under the direction ofArchibald Bulloch Roosevelt Jr.—to begin making preparations for a military coup against Qasim. The anti-imperialist and anti-communistIraqi Ba'ath Partyoverthrew and executed Qasim ina violent coupon February 8, 1963. Despite persistent rumors that the CIA orchestrated the coup, declassified documents and the testimony of former CIA officers indicate that there was no direct American involvement.The Kennedy administration was pleased with the outcome and ultimately approved a $55-million arms deal for Iraq. During his four-day visit to his ancestral home of Ireland beginning on June 26, 1963,Kennedy accepted a grant ofarmorial bearingsfrom theChief Herald of Ireland, received honorary degrees from theNational University of IrelandandTrinity College Dublin, attended a State Dinner in Dublin, and was conferred with the freedom of the towns and cities of Wexford, Cork, Dublin, Galway, and Limerick.He visited the cottage at Dunganstown, nearNew Ross, County Wexford, where his ancestors had lived before emigrating to America. Kennedy was the first foreign leader to address theHouses of the Oireachtas, the Irish parliament.Kennedy later told aides that the trip was the best four days of his life. On June 10, 1963, Kennedy, at the high point of his rhetorical powers,delivered thecommencement address at American University. Also known as \"A Strategy of Peace\", not only did Kennedy outline a plan to curb nuclear arms, but he also \"laid out a hopeful, yet realistic route for world peace at a time when the U.S. and Soviet Union faced the potential for an escalatingnuclear arms race.\"Kennedy also announced that the Soviets had expressed a desire to negotiate a nuclear test ban treaty, and that the U.S. had postponed planned atmospheric tests. Troubled by the long-term dangers ofradioactive contaminationandnuclear proliferation, Kennedy and Khrushchev agreed to negotiate a nuclear test ban treaty, originally conceived in Adlai Stevenson's 1956 presidential campaign.In their Vienna summit meeting in June 1961, Khrushchev and Kennedy reached an informal understanding against nuclear testing, but the Soviet Union began testing nuclear weapons that September. In response, the United States conducted tests five days later.Shortly afterwards, new U.S. satellites began delivering images that made it clear that the Soviets were substantially behind the U.S. in the arms race.Nevertheless, the greater nuclear strength of the U.S. was of little value as long as the Soviet Union perceived itself to be at parity. In July 1963, Kennedy sentW. Averell Harrimanto Moscow to negotiate a treaty with the Soviets.The introductory sessions included Khrushchev, who later delegated Soviet representation toAndrei Gromyko. It quickly became clear that a comprehensive test ban would not be implemented, due largely to the reluctance of the Soviets to allow inspections to verify compliance. Ultimately, the United States, the United Kingdom, and the Soviet Union were the initial signatories to a limited treaty, which prohibited atomic testing on the ground, in the atmosphere, or underwater, but not underground. The U.S. Senate approved the treaty on September 23, 1963, and Kennedy signed it on October 7, 1963.France was quick to declare that it was free to continue developing and testing its nuclear defenses. Kennedy called his domestic proposals the \"New Frontier\".However, Kennedy's small margin of victory in the 1960 election, his lack of deep connections to influential members of Congress, and his administration's focus on foreign policy hindered the passage of New Frontier policies. In 1961, Kennedy prioritized passing five bills: federal assistance for education, medical insurance for the elderly, housing legislation, federal aid to struggling areas, and an increase in the federal minimum wage.Kennedy's bill to increase thefederal minimum wageto $1.25 an hour passed in early 1961, but an amendment inserted by conservative leader from Georgia,Carl Vinson, exempted laundry workers from the law.Kennedy also won passage of theArea Redevelopment Actand the Housing Act of 1961. The Area Redevelopment Act, a $394 million program, provided federal funding to economically struggling regions (primarily inAppalachia), while the Housing Act of 1961 provided funds forurban renewalandpublic housingand authorized federalmortgage loansto those who did not qualify for public housing.Kennedy proposed a bill providing for $2.3 billion in federal educational aid to the states, with more money going to states with lowerper capita income. Though the Senate passed the education bill, it was defeated in the House by a coalition of Republicans, Southern Democrats, and Catholics.Kennedy's health insurance bill, which would have paid for hospitalization and nursing costs for the elderly, failed to pass either house of Congress.A bill that would have established theDepartment of Urban Affairs and Housingwas also defeated. In 1962, Kennedy won approval of theManpower Development and Training Act, a three-year program aimed at retraining workers displaced by new technology. Its impact onstructural unemployment, however, was minimal.At the urging of his sisterEunice, Kennedy madeintellectual disabilitiesa priority for his administration. In 1963, Congress passed theCommunity Mental Health Act, which provided funding to local mental health community centers and research facilities. Trade policy included both domestic and foreign policy. The 1962Trade Expansion Actwas passed by Congress with wide majorities. It authorized the president to negotiate tariff reductions on a reciprocal basis of up to 50 percent with theEuropean Common Market.The legislation paved the way for theKennedy RoundofGeneral Agreement on Tariffs and Tradenegotiations, concluding on June 30, 1967, the last day before expiration of the Act. Walter Heller, who served as the chairman of the CEA, advocated for aKeynesian-style tax cut designed to help spur economic growth, and Kennedy adopted this policy.The idea was that a tax cut would stimulate consumer demand, which in turn would lead to higher economic growth, lower unemployment, and increased federal revenues.To the disappointment of liberals likeJohn Kenneth Galbraith, Kennedy's embrace of the tax cut shifted his administration's focus away from the proposed old-age health insurance program and other domestic expenditures.In January 1963, Kennedy proposed a tax cut that would reduce the top marginal tax rate from 91 to 65 percent, and lower the corporate tax rate from 52 to 47 percent. The predictions according to the Keynesian model indicated the cuts would decrease income taxes by about $10 billion and corporate taxes by about $3.5 billion. The plan included reforms designed to reduce the impact ofitemized deductions, as well as provisions to help the elderly and handicapped. Republicans and many Southern Democrats opposed the bill, calling for simultaneous reductions in expenditures, but debate continued throughout 1963.Three months after Kennedy died, Johnson pushed the plan through Congress. TheRevenue Act of 1964lowered the top individual rate to 70 percent, and the top corporate rate to 48 percent. Kennedy ended a period of tight fiscal policies, loosening monetary policy to keepinterest ratesdown and to encourage growth of the economy.He presided over the first government budget to top the $100 billion mark, in 1962, and his first budget in 1961 resulted in the nation's first non-war, non-recessiondeficit.The economy, which had been through two recessions in three years and was in one when Kennedy took office, accelerated notably throughout his administration. Despite lowinflationand interest rates, theGDPhad grown by an average of only 2.2% per annum during the Eisenhower administration (scarcely more than population growth at the time), and it had declined by 1% during Eisenhower's last twelve months in office. The economy turned around and prospered during Kennedy's presidency. The GDP expanded by an average of 5.5% from early 1961 to late 1963,while inflation remained steady at around 1% and unemployment eased.Industrial production rose by 15% and motor vehicle sales increased by 40%.This sustained rate of growth in GDP and industry continued until around 1969. Kennedy was proud that his Labor Department helped keep wages steady in the steel industry, but was outraged in April 1962 whenRoger Blough, the president ofU.S. Steel, quietly informed Kennedy that his company would raise prices.In response, Attorney General Robert Kennedy began aprice-fixinginvestigation against U.S. Steel, and President Kennedy convinced other steel companies to rescind their price increases until finally even U.S. Steel, isolated and in danger of being undersold, agreed to rescind its own price increase.An editorial inThe New York Timespraised Kennedy's actions and stated that the steel industry's price increase \"imperil[ed] the economic welfare of the country by inviting a tidal wave of inflation.\"Nevertheless, the administration's Bureau of Budget reported the price increase would have caused a net gain for the GDP as well as a net budget surplus.The stock market, which had steadily declined since Kennedy's election in 1960, dropped 10% shortly after the administration's action on the steel industry took place. Kennedy verbally supportedcivil rightsduring his 1960 presidential campaign; he telephonedCoretta Scott King, wife ofMartin Luther King Jr., who had been jailed while trying to integrate a department store lunch counter. Robert Kennedy called Georgia GovernorErnest Vandiverand obtained King's release from prison, which drew additional Black support to his brother's candidacy.Recognizing that conservative Southern Democrats could block legislation, Kennedy did not introduce civil rights legislation on taking office.He needed their support to pass his economic and foreign policy agendas, and to support his reelection in 1964.Kennedy did appoint many Blacks to office, including civil rights attorneyThurgood Marshallto theU.S. Court of Appeals.Abraham Bolden, the first blackSecret Serviceagent, was appointed by Kennedy. Kennedy believed the grassroots movement for civil rights would anger many Southern Whites and make it more difficult to pass civil rights laws in Congress, and he distanced himself from it.As articulated by Robert Kennedy, the administration's early priority was to \"keep the president out of this civil rights mess.\"Civil rights movement participants, mainly those on the front line in the South, viewed Kennedy as lukewarm,especially concerning theFreedom Riders. In May 1961, theCongress of Racial Equality, led byJames Farmer, organized integrated Freedom Rides to test a Supreme Court case ruling that declared segregation on interstate transportation illegal.The Riders were repeatedly met with mob violence, including by federal and state law enforcement officers.Kennedy assignedfederal marshalsto protect the Riders rather than using federal troops or uncooperative FBI agents.Kennedy feared sending federal troops would stir up \"hated memories ofReconstruction\" among conservative Southern whites.The Justice Department then petitioned theInterstate Commerce Commission(ICC) to adhere to federal law. By September 1961, the ICC ruled in favor of the petition. On March 6, 1961, Kennedy signedExecutive Order 10925, which required government contractors to \"take affirmative action to ensure that applicants are employed and that employees are treated during employment without regard to their race, creed, color, or national origin.\"It established thePresident's Committee on Equal Employment Opportunity. In September 1962,James Meredithenrolled at the all-WhiteUniversity of Mississippibut was prevented from entering. In response, Attorney General Robert Kennedy sent 400 federal marshals.TheOle Miss riot of 1962left two dead and dozens injured, prompting Kennedy to send in 3,000 troops to quell the riot.Meredith did finally enroll in class. Kennedy regretted not sending in troops earlier and he began to doubt whether the \"evils of Reconstruction\" he had been taught or believed were true.On November 20, 1962, Kennedy signedExecutive Order 11063, which prohibited racial discrimination in federally supported housing. On June 11, 1963, Kennedy intervened when Alabama GovernorGeorge Wallaceblocked thedoorwayto theUniversity of Alabamato stop two Black students,Vivian MaloneandJames Hood, from attending. Wallace moved aside only after being confronted by Deputy Attorney GeneralNicholas Katzenbachand theAlabama National Guard, which had just been federalized by order of the president. That evening Kennedy gave his famousReport to the American People on Civil Rightsspeech on national television and radio, launching his initiative for civil rights legislation—to provide equal access to public schools and other facilities, and greater protection of voting rights. His proposals became part of theCivil Rights Act of 1964. The day ended with the murder of an NAACP leader,Medgar Evers, in Mississippi.As Kennedy had predicted, the day after his TV speech, and in reaction to it, House Majority leaderCarl Albertcalled to advise him that his two-year signature effort in Congress to combat poverty in Appalachia had been defeated, primarily by the votes of Southern Democrats and Republicans.When Arthur Schlesinger Jr. complimented Kennedy on his remarks, Kennedy bitterly replied, \"Yes, and look at what happened to area development the very next day in the House.\" He then added, \"But of course, I had to give that speech, and I'm glad that I did.\"On June 16,The New York Timespublished an editorial which argued that while Kennedy had initially \"moved too slowly and with little evidence of deep moral commitment\" in regards to civil rights he \"now demonstrate[d] a genuine sense of urgency about eradicating racial discrimination from our national life.\" A crowd of over 250,000, predominantly African Americans, gathered in Washington for the civil rightsMarch on Washington for Jobs and Freedomon August 28, 1963. Kennedy initially opposed the march, fearing it would have a negative effect on the prospects for the civil rights bills pending in Congress. These fears were heightened just prior to the march when FBI DirectorJ. Edgar Hooverpresented Kennedy with reports that some of King's close advisers, specificallyJack O'DellandStanley Levison, were communists.When King ignored the administration's warning, Robert Kennedy authorized the FBI towiretapKing and other leaders of theSouthern Christian Leadership Conference.Although Kennedy only gave written approval for limited wiretapping of King's phones \"on a trial basis, for a month or so,\"Hoover extended the clearance so his men were \"unshackled\" to look for evidence in any areas of King's life they deemed worthy. The Department of Justice was assigned to coordinate the federal government's involvement in the March on Washington on August 28; several hundred thousand dollars were channeled to the six sponsors of the March.To ensure a peaceful demonstration, the organizers and the president personally edited speeches that were inflammatory and collaborated on all aspects related to times and venues. Thousands of troops were placed on standby. Kennedy watched King's speech on TV and was very impressed. The March was considered a \"triumph of managed protest,\" and not one arrest relating to the demonstration occurred. Afterwards, the March leaders accepted an invitation to the White House to meet with Kennedy, and photos were taken. Kennedy felt that the March was a victory for him as well and bolstered the chances for his civil rights bill. Three weeks later, on Sunday, September 15,a bomb explodedat the 16th Street Baptist Church in Birmingham; by the end of the day, four Black children had died in the explosion, and two others were shot to death in the aftermath.Due to this resurgent violence, the civil rights legislation underwent some drastic amendments that critically endangered any prospects for passage of the bill, to the outrage of Kennedy. He called the congressional leaders to the White House, and by the following day, the original bill, without the additions, had enough votes to get it out of the House committee.Gaining Republican support, SenatorEverett Dirksenpromised the legislation would be brought to a vote preventing aSenate filibuster.On July 2, 1964, the guarantees Kennedy proposed in his June 1963 speech became federal law, when President Johnson signed the Civil Rights Act. During the 1960 presidential campaign, Kennedy endorsed the concept ofequal pay for equal work.In December 1961, Kennedy signed an executive order creating thePresidential Commission on the Status of Womento advise him on issues concerning the status of women.Former First Lady Eleanor Roosevelt led the commission. The commission's final report was issued in October 1963; it documented the legal and cultural discrimination women in America faced and made several policy recommendations to bring about change.On June 10, 1963, Kennedy signed theEqual Pay Act of 1963, which amended theFair Labor Standards Actand abolished wage disparity based on sex. Under the leadership of the attorney general, the Kennedy administration shifted the focus of the Justice Department, the FBI, and the IRS toorganized crime. Kennedy won congressional approval for five bills (i.e.,Federal Wire Actof 1961) designed to crack down on interstateracketeering, gambling, and the transportation of firearms. On March 22, 1962, Kennedy signed into law a bill abolishing the mandatory death penalty forfirst degree murderin the District of Columbia, the only remaining jurisdiction in the United States with such a penalty.The death penalty has not been applied in D.C. since 1957 and has now been abolished. Kennedy had relatively little interest in agricultural issues, but he sought to remedy the issue of overproduction, boost the income of farmers, and lower federal expenditures on agriculture. Under the direction of Secretary of AgricultureOrville Freeman, the administration sought to limit the production of farmers, but these proposals were generally defeated in Congress. To increase demand for domestic agricultural products and help the impoverished, Kennedy launched a pilotFood Stamp programand expanded thefederal school lunch program. Construction of theKinzua Damflooded 10,000 acres (4,000 hectares) ofSeneca nationland that they had occupied under theTreaty of 1794, and forced 600 Seneca to relocate toSalamanca, New York. Kennedy was asked by theAmerican Civil Liberties Unionto halt the project, but he declined, citing a critical need for flood control. He expressed concern about the plight of the Seneca and directed government agencies to assist in obtaining more land, damages, and assistance to mitigate their displacement. In the aftermath of the Soviet launch ofSputnik 1, the first artificial Earth satellite,NASAproposed a crewedlunar landingby the early 1970s.Funding for the program, known as theApollo program, was far from certain as Eisenhower held an ambivalent attitude.Early in his presidency, Kennedy was poised to dismantle the crewed space program, but he postponed any decision out of deference to Vice President Johnson, who had been a strong supporter of the program in the Senate.WithJerome Wiesner, Johnson was given a major role in overseeing the administration's space policy, and at Johnson's recommendation, Kennedy appointedJames E. Webbto head NASA. In Kennedy'sState of the Unionaddress in 1961, he suggested international cooperation in space. Khrushchev declined, as the Soviets did not wish to reveal the status of their rocketry and space capabilities.In April 1961, Soviet cosmonautYuri Gagarinbecame the first person to fly in space, reinforcing American fears about being left behind by the Soviet Union.Less than a month later,Alan Shepardbecame the first American to travel into space, strengthening Kennedy's confidence in NASA.The following year,John Glenn, aboard theMercurycraftFriendship 7, became the first American to orbit the Earth. In the aftermath of Gagarin's flight, as well as the failed Bay of Pigs invasion, Kennedy felt pressured to respond to the perceived erosion of American prestige. He asked Johnson to explore the feasibility of beating the Soviets to theMoon. Though he was concerned about the program's costs, Kennedy agreed to Johnson's recommendation that the U.S. commit to a crewed lunar landing as the major objective of the space program. In a May 25 speech to Congress, Kennedy declared, ... I believe that this nation should commit itself to achieving the goal, before this decade is out, of landing a man on the Moon and returning him safely to the Earth. No single space project in this period will be more impressive to mankind, or more important for the long-range exploration of space; and none will be so difficult or expensive to accomplish.Full text Though Gallup polling showed that many in the public were skeptical of the necessity of the Apollo program,members of Congress were strongly supportive in 1961 and approved a major increase in NASA's funding. Webb began reorganizing NASA, increasing its staffing level, and building two new centers: aLaunch Operations Centerfor thelarge Moon rocketnorthwest ofCape Canaveral Air Force Station, and aManned Spacecraft Centerin Houston. Kennedy took the latter occasion as an opportunity to deliver anotherspeechpromoting the space effort on September 12, 1962, in which he said: No nation which expects to be the leader of other nations can expect to stay behind in this race for space. ... We choose to go to the Moon in this decade and do the other things, not because they are easy, but because they are hard.Full text On November 21, 1962, in a cabinet meeting with Webb and other officials, Kennedy explained that the Moon shot was important for reasons of international prestige, and that the expense was justified.On July 20, 1969, almost six years after Kennedy's death,Apollo 11landed the first crewed spacecraft on the Moon. In 1962, Kennedy appointed justicesByron WhiteandArthur Goldbergto theSupreme Court.Additionally, Kennedy appointed 21 judges to theUnited States Courts of Appeals, and 102 judges to theUnited States district courts. Kennedy was assassinated inDallasat 12:30 p.m.Central Standard Timeon November 22, 1963.He was in Texas on a political trip to smooth over frictions in the Democratic Party between liberalsRalph YarboroughandDon Yarborough(no relation) and conservativeJohn Connally.While traveling in a presidentialmotorcadethroughDealey Plaza, he was shot once in the back, the bullet exiting via his throat, and once in the head. Kennedy was taken toParkland Hospital, where he was pronounced dead 30 minutes later, at 1:00 p.m.He was 46 years old.Lee Harvey Oswaldwas arrested for the murder of police officerJ. D. Tippitand was subsequently charged with Kennedy's assassination.Oswald denied shooting anyone, claiming he was apatsy.On November 24, before he could be prosecuted, he was shot and killed byJack Ruby.Ruby was arrested and convicted for the murder of Oswald. Ruby successfully appealed his conviction but died of cancer on January 3, 1967, while the date for his new trial was being set. President Johnson quickly issued anexecutive orderto create theWarren Commission—chaired by Chief JusticeEarl Warren—to investigate the assassination. The commission concluded that Oswald acted alone in killing Kennedy and that Oswald was not part of any conspiracy.These conclusions are disputed by many.AGallup Pollin November 2013 showed 61% believed in a conspiracy, and only 30% thought that Oswald did it alone.In 1979, theU.S. House Select Committee on Assassinationsconcluded, with one third of the committee dissenting, \"that Kennedy was probably assassinated as a result of aconspiracy.\" The committee was unable to identify the other gunmen or the extent of the conspiracy. This conclusion was based largely on audio recordings of the shooting.Subsequently, investigative reports from theFBIand a specially appointedNational Academy of SciencesCommittee determined that \"reliable acoustic data do not support a conclusion that there was a second gunman.\"TheJustice Departmentlater concluded \"that no persuasive evidence can be identified to support the theory of a conspiracy\". Kennedy's body was brought back to Washington. On November 23, six military pallbearers carried the flag-draped coffin into theEast Room of the White House, where he lay in repose for 24 hours.The coffin was then transported on a horse-drawncaissonto the Capitol to lie in state. Throughout the day and night, hundreds of thousands of people lined up to view the guarded casket,with a quarter million passing through therotundaduring the 18 hours of lying in state. Kennedy's funeral service was held on November 25, atCathedral of St. Matthew the ApostleinWashington, D.C.TheRequiem Masswas led byCardinalRichard Cushing, then theArchbishop of Boston.It was attended by approximately 1,200 guests, including representatives from over 90 countries.After the service, Kennedy was buried atArlington National CemeteryinArlington County, Virginia. The Kennedy family is one of the most establishedpolitical familiesin the United States, having produced a president, three senators, three ambassadors, and numerous other representatives and public officials. While a congressman, Kennedy embarked on a seven-week trip to India, Japan, Vietnam, and Israel in 1951, at which point he became close with his then 25-year-old brother Robert, as well as his 27-year-old sister Patricia. Because they were several years apart in age, the brothers had previously seen little of each other. This 25,000-mile (40,000 km) journey was the first extended time they had spent together and resulted in their becoming best friends.Robert would eventually serve as his brother'sattorney generaland closest presidential advisor;he would later run for president in1968before hisassassination, while another Kennedy brother, Ted, ran for president in1980. Kennedy met his wife,Jacqueline Lee \"Jackie\" Bouvier, when he was a congressman.Charles L. Bartlett, a journalist, introduced the pair at a dinner party.They were married on September 12, 1953, atSt. Mary's ChurchinNewport, Rhode Island.The newlyweds honeymooned in Mexico before settling in their new home,Hickory Hill, inMcLean, Virginia.In 1956, they sold their Hickory Hill estate to Kennedy's brother Robert, and bought a townhouse inGeorgetown.The Kennedys also resided at an apartment inBoston, their legal residence during John's congressional career,and a summer home inCape Cod, Massachusetts. After a miscarriage in 1955 and a stillbirth in 1956 (their daughter Arabella), their daughterCarolinewas born in 1957.John Jr., nicknamed \"John-John\" by the press as a child, was born in late November 1960, 17 days after his father was elected. John Jr. died in 1999 when thesmall plane he was piloting crashed.In August 1963, Jackie gave birth to a son,Patrick; however, he died after two days due to complications from birth. Kennedy and his wife were younger than the presidents and first ladies who preceded them, and both were popular in themedia culturein ways more common to pop singers and movie stars than politicians, influencing fashion trends and becoming the subjects of photo spreads in popular magazines. Although Eisenhower had allowed presidential press conferences to be filmed for television, Kennedy was the first president to ask for them to be broadcastliveand made good use of the medium.In 1961, theRadio-Television News Directors Associationpresented Kennedy with its highest honor, thePaul White Award, in recognition of his open relationship with the media. The Kennedys invited a range of artists, writers, and intellectuals to White House dinners, raising the profile of the arts in America. On the White House lawn, they established a swimming pool and tree house, while Caroline attended a preschool with 10 other children inside the home. Vaughn Meader'sFirst Familycomedy album, which parodied the president, the first lady, their family, and the administration, sold about four million copies. Kennedy was plagued by childhood diseases, includingwhooping cough,chickenpox,measles, and ear infections. These ailments compelled him to spend a considerable amount of timeconvalescing. Three months prior to his third birthday, in 1920, Kennedy came down withscarlet fever, a highly contagious and life-threatening disease, and was admitted toBoston City Hospital. During his years at Choate, Kennedy was beset by health problems that culminated with his emergency hospitalization in 1934 atYale New Haven Hospital, where doctors suspected leukemia.While ill, he became a passionate reader and also afatalist.In June 1934, he was admitted to theMayo Clinicin Minnesota; the ultimate diagnosis wascolitis.After withdrawing from Princeton University, Kennedy was hospitalized for observation atPeter Bent Brigham Hospitalin Boston. He then spent the spring of 1936 working as a ranch hand outsideBenson, ArizonaunderJack Speiden. Years after Kennedy's death, it was revealed that in September 1947—at age 30 and during his first term in Congress—he was diagnosed by Sir Daniel Davis atThe London ClinicwithAddison's disease. Davis estimated that Kennedy would not live for another year, while Kennedy hoped he could live for ten.In 1966, White House physicianJanet Travelldisclosed that Kennedy also hadhypothyroidism. The presence of twoendocrine diseasesraises the possibility that Kennedy hadautoimmune polyendocrine syndrome type 2. Kennedy suffered from chronic severe back pain, for which he underwent surgery. His condition may have had diplomatic repercussions, as he was reportedly taking a combination of medications to manage the pain during the 1961Vienna Summit. The combination included hormones, animal organ cells, steroids, vitamins, enzymes, and amphetamines, and possible side effects included hyperactivity,hypertension, impaired judgment, nervousness, and mood swings.Kennedy at one time was regularly seen by three doctors, one of whom,Max Jacobson, at first was unknown to the other two, as his mode of treatment was controversialand used for the most severe bouts of back pain. Into late 1961, disagreements existed among Kennedy's doctors concerning the balance of medication and exercise. Kennedy preferred the former because he was short on time and desired immediate relief.The president's primary White House physician,George G. Burkley, set up gym equipment in the White House basement, where Kennedy performed stretching exercises three times a week.Details of these and other medical issues were not publicly disclosed during Kennedy's lifetime.Burkley realized that treatments by Jacobson and Travell, including excessive use of steroids and amphetamines, were medically inappropriate, and took action to remove Kennedy from their care. In 2002,Robert Dallekwrote an extensive history of Kennedy's health based on a collection of Kennedy–associated papers from 1955 to 1963, including X-rays and prescription records from Travell. According to Travell's records, during his presidency, Kennedy suffered from high fevers; stomach, colon, and prostate issues; abscesses; high cholesterol; and adrenal problems. Travell kept a \"Medicine Administration Record\", cataloging Kennedy's medications: injected and ingestedcorticosteroidsfor his adrenal insufficiency; procaine shots and ultrasound treatments and hot packs for his back;Lomotil,Metamucil,paregoric,phenobarbital,testosterone, and trasentine to control his diarrhea, abdominal discomfort, and weight loss; penicillin and other antibiotics for hisurinary-tract infectionsand anabscess; andTuinalto help him sleep. Kennedy was single in the 1940s and had relationships with Danish journalistInga Arvadand actressGene Tierney.During his time as a senator, he had an affair withGunilla von Postwho later wrote that the future president tried to end his marriage to be with her before he and his wife had any children.Kennedy was also reported to have had affairs withMarilyn Monroe,Judith Campbell,Mary Pinchot Meyer,Marlene Dietrich,White House internMimi Alford,and his wife'spress secretary,Pamela Turnure.Several conspiracy theories have surroundedMonroe's death, alleging that Kennedy may have been involved. The full extent of Kennedy's relationship with Monroe—who in 1962 famously sang \"Happy Birthday, Mr. President\" at Kennedy's birthday celebration atMadison Square Garden—is not known, though it has been reported that they spent a weekend together in March 1962 while he was staying atBing Crosby's house.Furthermore, people at the White House switchboard noted that Monroe had called Kennedy during 1962.J. Edgar Hoover, the FBI director, received reports about Kennedy's indiscretions.These included an alleged tryst with a suspectedEast Germanspy,Ellen Rometsch. According to historianMichael Beschloss, in July 1963, Hoover reportedly informed Robert Kennedy about the affair with a woman \"suspected as a Soviet intelligence agent, someone linked to East German intelligence.\" Robert reportedly took the matter seriously enough to raise it with leading Democratic and Republican figures in Congress.However, the FBI never turned up \"any solid evidence\" that Rometsch was a spy or that she had a relationship with President Kennedy.Former Secret Service agent Larry Newman recalled \"morale problems\" that the president's indiscretions engendered within the Secret Service. Kennedy inspired affection and loyalty from the members of his team and his supporters.According to Reeves, this included \"the logistics of Kennedy's liaisons ... [which] required secrecy and devotion rare in the annals of the energetic service demanded by successful politicians.\"Kennedy believed that his friendly relationship with members of the press would help protect him from public revelations about his sex life. Kennedy was a fan ofMajor League Baseball'sBoston Red Soxand theNational Basketball Association'sBoston Celtics.Growing up on Cape Cod, Kennedy and his siblings developed a lifelong passion forsailing.He also took upgolf; playing regularly at theHyannisport Clubin Massachusetts and the Palm Beach Country Club in Florida. Kennedy was the firstCatholicelected to the presidency.During his childhood, he attendedSt. Aidan's Churchin Brookline, Massachusetts, where he wasbaptizedon June 19, 1917.From 1946 until he died in 1963, he served on the advisory board of the Roman CatholicEmmanuel College. Historians and political scientists tend torankKennedy as an above-average president, and he is usually the highest-ranking president who served less than one full term.A 2010 survey by theGallup Organization, when Americans were asked their opinions of modern presidents, Kennedy was found to be the most-popular, with an 85 percent retrospective approval rating.A 2014 survey fromThe Washington Postof 162 members of theAmerican Political Science Association's Presidents and Executive Politics section ranked Kennedy 14th highest overall among the 43 persons who have been president, including then-presidentBarack Obama. The survey found Kennedy to be the most overrated U.S. president.A 2017C-SPANsurvey has Kennedy ranked among the top ten presidents.A 2023 Gallup survey showed Kennedy with a retrospective approval rating of 90 percent, the highest of all U.S. presidents in recent history.Assessments of his policies are mixed.Many of Kennedy's legislative proposals were passed after his death, during theJohnson administration, and Kennedy's death gave those proposals a powerful moral component. Kennedy came in third (behind Martin Luther King Jr. andMother Teresa) inGallup's List of Widely Admired Peopleof the 20th century.In 1961, he was awarded theLaetare Medalby theUniversity of Notre Dame, considered the most prestigious award forAmerican Catholics.He was posthumously awarded thePacem in TerrisAward(Latin: Peace on Earth) and thePresidential Medal of Freedom. The term \"Camelot\" is often used to describe his presidency, reflecting both the mythic grandeur accorded Kennedy in death and powerful nostalgia for that era of American history.According to Richard Dean Burns and Joseph M. Siracusa, the most popular theme surrounding Kennedy's legacy is its replay of the legend ofKing ArthurandCamelotfromArthurian Literature.In an interview following Kennedy's death, his widow Jacqueline mentioned his affection for the Broadway musicalCamelotand quoted its closing lines: \"Don't let it be forgot, that once there was a spot, for one brief, shining moment that was known as Camelot.\"Critics, especially historians, have dismissed the Camelot myth as a distortion of Kennedy's actions, beliefs, and policies. However, in the public memory, the years of Kennedy's presidency are still seen as a brief, brilliant, and shining moment. Examples of the extensive list include: The 1963 LIFE article represented the first use of the term \"Camelot\" in print and is attributed with having played a major role in establishing and fixing this image of the Kennedy Administration and period in the popular mind.", "metadata": {"url": "https://en.wikipedia.org/wiki/John_F._Kennedy", "title": "John F. Kennedy", "headings": ["Contents", "Early life and education", "U.S. Naval Reserve (1941–1945)", "CommandingPT-109andPT-59", "Journalism (1945)", "U.S. House of Representatives (1947–1953)", "U.S. Senate (1953–1960)", "1960 presidential election", "Presidency (1961–1963)", "Foreign policy", "Domestic policy", "Judicial appointments", "Assassination", "Funeral", "Personal life, family, and reputation", "Wife and children", "Popular image", "Health", "Affairs and friendships", "Sports", "Religion", "Historical evaluations and legacy", "Presidency", "Memorials and eponyms", "Works", "Books", "Select speeches", "See also", "Notes", "References", "Citations", "Works cited", "Further reading", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/John_F._Kennedy", "https://en.wikipedia.org/wiki/John_F._Kennedy", "https://en.wikipedia.org/wiki/John_F._Kennedy", "https://en.wikipedia.org/wiki/John_Kennedy_(disambiguation)", "https://en.wikipedia.org/wiki/Jack_Kennedy_(disambiguation)", "https://en.wikipedia.org/wiki/JFK_(disambiguation)", "https://en.wikipedia.org/wiki/John_F._Kennedy_(disambiguation)", "https://en.wikipedia.org/wiki/Oval_Office"]}},
{"id": "82ae5cbe1e59", "content": " TheGerman National Library of Science and Technology(German:Technische Informationsbibliothek), abbreviatedTIB, is thenational libraryof theFederal Republic of Germanyfor all fields of engineering, technology, and thenatural sciences. It is jointly funded by theFederal Ministry of Education and Research(BMBF) and the 16German states. Founded in 1959, the library operates in conjunction with theLeibniz Universität Hannover.In addition to acquiring scientific literature, it conductsapplied researchin such areas as the archiving of non-textual materials,data visualizationand thefuture Internet. The library is also involved in a number ofopen accessinitiatives. With a collection of about 8.9 million items in 2012,the TIB is the largest technology and natural science library in the world. The TIB acquires literature in all engineering fields as well as architecture, information technology, chemistry, mathematics, physics and otherbasic sciences. It is a particular specialist in the acquisition of \"gray literature\";that is, literature difficult to obtain and not available via the standard book or journal trade.It also holds a large number of standards, norms, patents, source data, scientific conference proceedings, government research papers and dissertations. Special collections include the \"Albrecht Haupt Collection\" of digitally rendered architectural drawings, and a regional focus on technical literature from East Asia and Eastern Europe.The film and audiovisual material held previously by IWF Knowledge and Media (IWF Wissen und Medien) is now held by TIB. The TIB's holdings total 10 million media units (as of December 31, 2022): In 2010, the physical collection occupied 125 kilometres (78 mi) of shelving. To counteract the flood of publications in the sciences, TIB is developing the Open Research Knowledge Graph,with which the scientific contributions from scientific publications can be organized in a flexible database (the Knowledge Graph). In 2024, the TIB published the ORKG ASK service,which enables AI-supported scientific questions to be answered on the basis of a corpus of 80 million scientific publications. In 2005 the TIB became the world's firstDigital Object Identifier(DOI) registration agency for research data sets in the fields of technology, natural sciences and medicine.It offers registration for the results of any publicly funded research conducted in Europe. The TIB is alegal depositlibrary for research projects sponsored by various agencies of the German Federal Government, in particular: The TIB is a member of theLeibniz Association,a consortium of 87 non-university research institutes in Germany. In support of the Association'sopen accessgoals, the TIB operates the Leibniz Open Access Repository in cooperation with Leibniz Institute for Information Infrastructure (formerlyFachinformationszentrum Karlsruhe). The TIB advises the Leibniz Association's various member organizations, scientists and staff on depositing publications in the repository according toopen accessguidelines. The amount, usage and importance of non-textual materials such as3D models,AV mediaand research data is continually increasing and only a small proportion can be searched at the present time.The goal of theTIB Competence Centre for Non-Textual Materials(Kompetenzzentrum für nicht-textuelle Materialien, abbreviated to KNM) is to fundamentally improve access to, and the use of, such non-textual materials. The TIB also develops new multimedia analysis methods such as morphology, speech or structure recognition to create indexing and metadata to help researchers and educators make better use of these complex materials. In addition, the competence center is dedicated to the preservation of multimedia objects, the assignment of DOI, and knowledge transfer. TIB operates the GetInfo portal for science and technology with interdisciplinary search capabilities for the other German National Libraries as well as access to more than 150 million data sets from other specialized databases, publishers and library catalogs.The TIB also makes scientific videos of lectures, conferences, computer animations, simulations and experiments available via GetInfo. These video items can be searched free-of-charge and can be downloaded viaFlash Player. The TIB partners with a variety of national and international libraries, institutions and associations. The TIB is one of three partners in the Leibniz Library Network for Research Information consortiumGoportis, the others being theGerman National Library of Economics(ZBW) andGerman National Library of Medicine(ZB MED). This initiative develops and operates online search services, online full-text delivery services, licensing agreements, non-textual materials, document preservation efforts, data storage, and open access. The TIB is also the scientific information provider for researchers in the newly independent states of the formerSoviet Union, includingAzerbaijan, Georgia,Kazakhstan,Kyrgyzstan,TajikistanandUkraine. It also collaborates with numerous organizations in China, Japan and Eastern Europe. Notable institutional partnerships include: As part of the German national research infrastructure, the TIB conducts its ownapplied research, particularly in the field ofinformation science. In cooperation with a variety of other institutions, these projects focus on the areas of visual searching, data visualization, theSemantic Web, and theFuture Internet. PROBADO is a project to develop tools for the automatic indexing, storage and delivery of non-textual documents such as 3D models. Its goal is to enable academic libraries to deal with multimedia objects just as easily as with textual information. Tools include searching by intuitive drawing in 2D and 3D and delivery of results while drawing. For this initiative the TIB partnered with the Technical University of Darmstadt, the University of Bonn and the Technical University of Graz. This project, funded by theLeibniz Association, is a joint effort of the TIB, the GRIS Darmstadt (Interactive Graphics Systems at theTechnical University of Darmstadt) and the IGD (Fraunhofer Institute for Computer Graphics). It deals with developing approaches to the interactive, graphical access to research data in order to make it easily represented and searchable. The project is tasked with developing methods for data analysis, visual search systems, metadata-based searching and prototype implementation. SCOAP(Sponsoring Consortium for Open Access Publishing in Particle Physics) is a global consortium of organizations in high energy physics, physics research centers and leading international libraries. Its goal is to convert essential journals in particle physics that are presently financed by subscriptions intoopen access journalswith the support of the publishers.SCOAP-DH is funded by theGerman Research Foundation, working in cooperation with theGerman Electron Synchrotron(DESY) and theMax Planck Society(MPS). Additional TIB research projects include:", "metadata": {"url": "https://en.wikipedia.org/wiki/German_National_Library_of_Science_and_Technology", "title": "German National Library of Science and Technology", "headings": ["Contents", "Collection", "Services", "Open Research Knowledge Graph", "DOI Registration Agency", "Depository library", "Leibniz Open Access Repository", "Competence Center for Non-Textual Material", "GetInfo online service", "Partnerships", "Goportis library network", "Institutional partners", "Other partners", "Research projects", "PROBADO 3D", "Visual access to research data", "SCOAP-DH", "Other research projects", "See also", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/German_National_Library_of_Science_and_Technology", "https://en.wikipedia.org/wiki/German_National_Library_of_Science_and_Technology", "https://en.wikipedia.org/wiki/German_National_Library_of_Science_and_Technology", "https://en.wikipedia.org/wiki/Geographic_coordinate_system", "https://en.wikipedia.org/wiki/Hanover", "https://en.wikipedia.org/wiki/National_library", "https://en.wikipedia.org/wiki/Research_library", "https://en.wikipedia.org/wiki/Chemistry"]}},
{"id": "4d7fa1f62b9f", "content": " CNET(short for \"Computer Network\")is an American media website that publishes reviews, news, articles, blogs, podcasts, and videos on technology andconsumer electronicsglobally. CNET originally produced content for radio and television in addition to its website before applyingnew mediadistribution methods through itsinternet televisionnetwork,CNET Video, and its podcast and blog networks. Founded in 1992 byHalsey Minorand Shelby Bonnie, it was the flagship brand of CNET Networks and became a brand ofCBS Interactivethrough that unit's acquisition of CNET Networks in 2008.Following acquisition byRed Ventureson October 30, 2020,the website faced criticism for the decline in quality of its editorial content and its factual unreliability due to the use ofgenerative AIin the creation of its articles,as well as concerns over itsjournalistic integrityafter it began increased publication of biased reviews andsponsored contentto benefit itsadvertisingpartners.On October 1, 2024, CNET was acquired byZiff Davis. After leavingPepsiCo, Halsey Minor and Shelby Bonnie launched c/net, a 24-hour cable network about computers and technology in 1992.With help fromFox Networkco-founder Kevin Wendleand former Disney creative associate Dan Baker,CNET produced four pilot television programs about computers, technology, and the Internet.CNET TVwas composed ofCNET Central,The Web, andThe New Edge.CNET Centralwas created first and aired insyndicationin theUnited Stateson theUSA Network. Later, it began airing on USA's sister networkSci-Fi Channelalong withThe WebandThe New Edge.These were later followed byTV.comin 1996. Media personalityRyan Seacrestfirst came to national prominence at CNET, as the host ofThe New Edgeand doing various voice-over work for CNET. CNET online launched in June 1995.CNET, Inc., the site's owner, had itsinitial public offering(IPO) in July 1996, trading on theNASDAQNational Market as \"CNWK\".In 1998, CNET, Inc. was sued by Snap Technologies, operators of the education service CollegeEdge, fortrademark infringementrelating to CNET, Inc.'s ownership of the domain name Snap.com, due to Snap Technologiesalready owning a trademark on its name. CNET produced another television technology news program calledNews.comthat aired onCNBCbeginning in 1999.From 2001 to 2003, it operated CNET Radio on theClear Channel-ownedKNEW(910) in theSan Francisco Bay Area,WBPS(890) inBoston, andXM Satellite Radio. CNET Radio offered technology-themed programming. After failing to attract a sufficient audience, CNET Radio ceased operating in January 2003 due to financial losses. In July 1999, CNET, Inc. acquired theSwiss-based company GDT, later renamed to CNET Channel.In 1998, CNET, Inc. granted the right to Asiacontent.com to set up CNET Asia and the operation was brought back in December 2000.In January 2000, the same time CNET, Inc. became CNET Networks,it acquired comparison shopping site mySimon for $736 million.In October 2000, CNET Networks acquiredZDNETfor approximately $1.6 billion.In January 2001,Ziff Davisreached an agreement with CNET Networks to regain the URLs lost in the 2000 sale of Ziff Davis toSoftBank, a publicly traded Japanese media and technology company. In April 2001, CNET acquiredTechRepublic, which provides content for IT professionals fromGartner, for $23 million in cash and stock.In May 2002, CNET Networks acquired Smartshop, an automated product catalog and feature comparison technology company, for an undisclosed amount. On July 14, 2004, CNET Networks announced that it would acquire photography websiteWebshotsfor $70 million ($60 million in cash, $10 million in deferred consideration),completing the acquisition that same month.In October 2007, it sold Webshots toAmerican Greetingsfor $45 million.In August 2005, CNET Networks acquiredMetacritic, areview aggregation website, for an undisclosed amount. In 2005, Google representatives refused to be interviewed by all CNET reporters for a year after CNET published Google's CEOEric Schmidt's salary and named the neighborhood where he lives, as well as some of his hobbies and political donations.All the information had been gleaned from Google searches. In September 2006, CNET acquiredChowhound, an online food community. On October 10, 2006, Shelby Bonnie resigned as chairman andCEO, in addition to two other executives, as a result of astock options backdatingscandal that occurred between 1996 and 2003.This would also cause the firm to restate its financial earnings over 1996 to 2003 for over $105 million in resulting expenses.TheSecurities and Exchange Commissionlater dropped an investigation into the practice. Neil Ashe was named as the new CEO. In December 2006,James Kim, an editor at CNET, died in the Oregon wilderness. CNET hosted a memorial show and podcasts dedicated to him. On March 1, 2007, CNET announced the public launch ofBNET, a website targeted towards business managers. BNET had been running under beta status since 2005.In 2008 programmerChris Wanstrath, who worked on GameSpot and Chowhound, left CNET to startGitHub. On May 15, 2008, it was announced thatCBS Corporationwould buy CNET Networks forUS$1.8 billion.On June 30, 2008, the acquisition was completed.Former CNET Networks properties were managed underCBS Interactiveat the time. CBS Interactive acquired manydomainnames originally created by CNET Networks, includingdownload.com, downloads.com, upload.com, news.com, search.com,TV.com,mp3.com, chat.com, computers.com, shopper.com, com.com, and cnet.com. It also heldradio.comuntilCBS Radiowas sold toEntercomin 2017. In 2011, CNET and CBS Interactive were sued by a coalition of artists (led by FilmOn founder Alki David) forcopyright infringementby promoting the download ofLimeWire, a popularpeer to peerdownloading software.Although the original suit was voluntarily dropped by Alki David, he vowed to sue at a later date to bring \"expanded\"action against CBS Interactive. In November 2011, another lawsuit against CBS Interactive was introduced, claiming that CNET and CBS Interactive knowingly distributed LimeWire. On September 19, 2013, CBS Interactive launched aSpanish languagesister site under the name CNET en Español.It focuses on topics of relevance primarily to Spanish-speaking technology enthusiasts. The site offered a \"new perspective\" on technology and is under the leadership of managing editor Gabriel Sama.The site not only offered news and tutorials, but also had a robust reviews section that it was led by Juan Garzon. After Red Ventures' acquisition, the company announced the closing of CNET en Español on November 11, 2020, leaving the largest tech site in Spanish in the US out of the market. In March 2014, CNET refreshed its site by merging with CNET UK and vowing to merge all editions of the agency into a unified agency. This merge brought many changes, foremost of which would be a new user interface and the renaming of CNET TV as CNET Video. Red Venturesannounced in September 2020 that it would acquire CNET fromViacomCBSfor $500 million.The transaction was completed on October 30, 2020. In November 2022, CNET began publishing articles written withartificial intelligenceand edited by humans.CNET was criticized for failing to disclose that it was using a machine to write articles,and for using human bylines on some AI-generated content until caught by independent investigators.CNET reviewed those articles in January 2023 after many were found to contain serious errors and plagiarized material.CNET reporters said Red Ventures pushed them to give more favourable coverage to advertisers and work on sponsored content.Subsequently, 10% of CNET staff were laid off.Employees unionized in response to the scandal and layoffs, saying AI-generated content posed a danger to their professional reputations.A former staffer demanded that her byline be removed from the site, in order to protect her reputation if her articles were revised by AI. In August 2023, CNET had deleted thousands of old articles from their website in an effort to raise thesearch engine optimizationrankings onGoogle Search.Before an article is deleted on its website, CNET creates an internal copy and another toWayback Machine. The writer, if still employed by CNET, is also alerted 10 days in advance.Googlesaid deleting articles to optimize for search engine rankings is not a good practice. In January 2024,Axiosreported that Red Ventures was exploring a sale of the website, with a goal of attaining at least $250 million for it. The site was profitable at the time.The approximate halving of CNET's value under Red Ventures' ownership is attributed to interest rates, a slower ad market, and the reputational damage to CNET caused by the AI scandals. On August 6, 2024, theNew York Timesreported that Red Ventures had reached an agreement to sell CNET toZiff Davisfor $100 million, subject to regulatory approval.The acquisition was completed in the third quarter of 2024. France websites: Japan websites: CNET launched a website to covervideo games,CNET Gamecenter, in the middle of 1996.According to theSan Francisco Chronicle, it was \"one of the first Web sites devoted to computer gaming news\".It became a leading game-focused website;in 1999,PC Magazinenamed it one of the hundred-best websites in any field, alongside competitorsIGNandGameSpot.According toGamecenterhead Michael Brown, the site received between 50,000 and 75,000 daily visitors by late 2000.In May 2000, CNET founded the Gamecenter Alliance network to bringGamecenterand four partner websites, includingInside Mac Games, under one banner.Nielsen//NetRatings ranked Gamecenter the sixth-most-popular gaming website in the United States by mid-2000. On July 19, 2000, CNET, Inc. made public its plan to buyZiff-Davisand itsZDNetInternet business for $1.6 billion.Because ZDNet had partnered with SpotMedia—parent company ofGameSpot—in late 1996,the acquisition brought bothGameSpotandGamecenterunder CNET, Inc.'s ownership.Later that year,The New York Timesdescribed the two publications as the \"TimeandNewsweekof gaming sites\". The paper reported thatGamecenter\"seem[ed] to be thriving\" amid thedot-com crash, with its revenue distributed acrossonline advertisingand anaffiliate sales programwith CNET'sGame Shopperwebsite,launched in late 1999. Following an almost $400 million loss at CNET as a result of the dot-com crash, the company ended the Gamecenter Alliance network in January 2001.On February 7,Gamecenteritself was closed in a redundancy reduction effort, asGameSpotwas the more successful of the two sites.Around 190 jobs were cut from CNET during this period,including \"at least 20\" atGamecenter, according to theSan Francisco Chronicle.Discussing the situation, Tom Bramwell ofEurogamerreported, \"It is thought [...] that very few if any of the website's staff will move sideways into jobs atGameSpot, now the company's other gaming asset.\"The Washington Postlater noted thatGamecenterwas among the \"popular video-game news sites\" to close in 2001, alongsideDaily Radar. In January 2013, CNET namedDish Network's \"Hopper withSling\"digital video recorderas a nominee for theCES\"Best in Show\" award (which is decided by CNET on behalf of its organizers), and named it the winner in a vote by the site's staff. However, CBS abruptly disqualified the Hopper, and vetoed the results because the company was inactive litigationwith Dish Network. CNET also announced that it could no longer review any product or service provided by companies that CBS are in litigation with (which also includesAereo). The new vote subsequently gave the Best in Show award to theRazer Edgetablet instead. Dish Network's CEO Joe Clayton said that the company was \"saddened that CNET's staff is being denied its editorial independence because of CBS' heavy-handed tactics.\"On January 14, 2013, editor-in-chief Lindsey Turrentine addressed the situation, stating that CNET's staff were in an \"impossible\" situation due to theconflict of interestposed by the situation, and promised that she would do everything within her power to prevent a similar incident from occurring again. The conflict also prompted one CNET senior writer, Greg Sandoval, to resign. The decision also drew the ire of staff from theConsumer Electronics Association, the organizers of CES; CEOGary J. Shapirocriticized the decision in aUSA Todayop-edcolumn and a statement by the CEA, stating that \"making television easier to watch is not against the law. It is simply pro-innovation and pro-consumer.\" Shapiro felt that the decision also hurt the confidence of CNET's readers and staff, \"destroying its reputation for editorial integrity in an attempt to eliminate a new market competitor.\" As a result of the controversy and fearing damage to the show's brand, the CEA announced on January 31, 2013, that CNET will no longer decide the CES Best in Show award winner due to the interference of CBS (the position has been offered to other technology publications), and the \"Best in Show\" award was jointly awarded to both the Hopper with Sling and Razer Edge. With a catalog of more than 400,000 titles, the Downloads section of the website allows users to download popular software. CNET's download.com providesWindows,Macintosh, and mobile software for download. CNET claims that this software is free ofspyware, but independent sources have confirmed that this is not the case. WhileDownload.comis overall a safe place to download programs, precautions should be taken before downloading from the site, as some downloads do contain malware. In January 2023,Wikipedia editorsbegan the process of downgrading CNET's reliability rating as a source following the revelation that CNET was publishing content generated byartificial intelligence. In response to the decision, CNET claimed it maintained high editorial standards, stating, \"It is important to clarify that CNET is not actively using AI to create new content. While we have no specific plans to restart, any future initiatives would follow our public AI policy.\"", "metadata": {"url": "https://en.wikipedia.org/wiki/CNET", "title": "CNET", "headings": ["Contents", "History", "Origins", "Acquisitions and expansions", "CBS Corporation ownership", "Red Ventures ownership", "Websites", "CNET Networks", "Gamecenter", "Criticism", "Hopper controversy", "Malware in downloads", "AI-generated content (2023)", "See also", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/CNET", "https://en.wikipedia.org/wiki/CNET", "https://en.wikipedia.org/wiki/CNET", "https://en.wikipedia.org/wiki/News.com.au", "https://en.wikipedia.org/wiki/Subsidiary", "https://en.wikipedia.org/wiki/Halsey_Minor", "https://en.wikipedia.org/wiki/Holding_company", "https://en.wikipedia.org/wiki/CBS_Interactive"]}},
{"id": "0e43128c2340", "content": " Areference designator(RefDes) unambiguously identifies the location of acomponentwithin anelectrical schematicor on aprinted circuit board. The reference designator usually consists of one or two letters followed by a number, e.g. C3, D1, R4, U15. The number is sometimes followed by a letter, indicating that components are grouped or matched with each other, e.g. R17A, R17B. TheIEEE315 standard contains a list of Class Designation Letters to use for electrical and electronic assemblies. For example, the letter R is a reference prefix for the resistors of an assembly, C for capacitors, K for relays. Industrial electrical installations often use reference designators according toIEC 81346. IEEE 200-1975 or \"Standard Reference Designations for Electrical and Electronics Parts and Equipments\" is a standard that was used to define referencing naming systems for collections of electronic equipment. IEEE 200 was ratified in 1975. The IEEE renewed the standard in the 1990s, but withdrew it from active support shortly thereafter. This document also has an ANSI document number, ANSI Y32.16-1975. This standard codified information from, among other sources, a United States military standard MIL-STD-16 which dates back to at least the 1950s in American industry. To replace IEEE 200-1975,ASME, a standards body for mechanical engineers, initiated the new standard ASME Y14.44-2008. This standard, along with IEEE 315-1975, provide the electrical designer with guidance on how to properly reference and annotate everything from a single circuit board to a collection of complete enclosures. ASME Y14.44-2008and IEEE 315-1975define how to reference and annotate components of electronic devices. It breaks down a system into units, and then any number of sub-assemblies.  The unit is the highest level of demarcation in a system and is always a numeral.  Subsequent demarcation are called assemblies and always have the Class Letter \"A\" as a prefix following by a sequential number starting with 1.  Any number of sub-assemblies may be defined until finally reaching the component. Note that IEEE 315-1975defines separate class designation letters forseparableassemblies (class designation 'A') andinseparableassemblies (class designation 'U'). Inseparable assemblies—i.e., \"items which are ordinarily replaced as a single item of supply\"—are typically treated as components in this referencing scheme. Examples: Especially valuable is the method of referencing and annotating cables plus their connectors within and outside assemblies.\nExamples: A cable connecting these two might be: Connectors on this cable would be designated: ASME Y14.44-2008 continues the convention ofPlugP andJackJ when assigning references forelectrical connectorsin assemblies where a J (orjack) is the more fixed and P (or plug) is the less fixed of a connector pair, without regard to thegenderof the connector contacts. The construction of reference designators is covered by IEEE 200-1975/ANSI Y32.16-1975(replaced by ASME Y14.44-2008) and IEEE 315-1975. The table below lists designators commonly used, and does not necessarily comply with standards. For modern use, designators are often simplified towards shorter designators, because it requires less space on silkscreens.", "metadata": {"url": "https://en.wikipedia.org/wiki/Reference_designator", "title": "Reference designator", "headings": ["Contents", "History", "Definition", "Designators", "Other designators", "See also", "References", "Further reading"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Reference_designator", "https://en.wikipedia.org/wiki/Reference_designator", "https://en.wikipedia.org/wiki/Reference_designator", "https://en.wikipedia.org/wiki/Joule_thief", "https://en.wikipedia.org/wiki/Schematic", "https://en.wikipedia.org/wiki/Electronic_component", "https://en.wikipedia.org/wiki/Circuit_diagram", "https://en.wikipedia.org/wiki/Printed_circuit_board"]}},
{"id": "3bf2022eed78", "content": " Building information modeling(BIM) is an approach involving the generation and management of digital representations of the physical and functional characteristics of buildings or other physical assets and facilities. BIM is supported by various tools, processes, technologies and contracts. Building information models (BIMs) arecomputer files(often but not always in proprietary formats and containing proprietary data) which can be extracted, exchanged or networked to support decision-making regarding a built asset. BIM software is used by individuals, businesses and government agencies who plan,design,construct, operate and maintain buildings and diversephysical infrastructures, such as water, refuse, electricity, gas, communication utilities, roads, railways, bridges, ports and tunnels. CAD tools often serve as foundational elements in BIM workflows, enabling the transition from 2D drafting to integrated 3D modeling for better asset representation. The concept of BIM has been in development since the 1970s, but it only became an agreed term in the early 2000s. The development of standards and the adoption of BIM has progressed at different speeds in different countries. Developed bybuildingSMART,Industry Foundation Classes(IFCs) – data structures for representing information – became an international standard, ISO 16739, in 2013, and BIM process standards developed in theUnited Kingdomfrom 2007 onwards formed the basis of an international standard, ISO 19650, launched in December 2018. The concept of BIM has existed since the 1970s. The software tools developed for modeling buildings emerged in the late 1970s and early 1980s, and included workstation products such asChuck Eastman's Building Description Systemand GLIDE,RUCAPS,Sonata,ReflexandGable 4D Series.The early applications, and the hardware needed to run them, were expensive, which limited widespread adoption. The pioneering role of applications such as RUCAPS, Sonata and Reflex has been recognized by Laiserinas well as the UK'sRoyal Academy of Engineering;formerGMWemployeeJonathan Ingramworked on all three products.What became known as BIM products differed from architectural drafting tools such asAutoCADby allowing the addition of further information (time, cost, manufacturers' details, sustainability, and maintenance information, etc.) to the building model. As Graphisoft had been developing such solutions for longer than its competitors, Laiserin regarded itsArchiCADapplication as then \"one of the most mature BIM solutions on the market.\"Following its launch in 1987, ArchiCAD became regarded by some as the first implementation ofBIM,as it was the firstCADproduct on a personal computer able to create both 2D and 3D geometry, as well as the first commercial BIM product for personal computers.However, Graphisoft founderGábor Bojárhas acknowledged to Jonathan Ingram in an open letter, that Sonata \"was more advanced in 1986 than ArchiCAD at that time\", adding that it \"surpassed already the matured definition of 'BIM' specified only about one and a half decade later\". The term 'building model' (in the sense of BIM as used today) was first used in papers in the mid-1980s: in a 1985 paper by Simon Ruffle eventually published in 1986,and later in a 1986 paper by Robert Aish– then at GMW Computers Ltd, developer of RUCAPS software – referring to the software's use at London'sHeathrow Airport.The term 'Building Information Model' first appeared in a 1992 paper by G.A. van Nederveen and F. P. Tolman. However, the terms 'Building Information Model' and 'Building Information Modeling' (including the acronym \"BIM\") did not become popularly used until some 10 years later. Facilitating exchange and interoperability of information in digital format was variously with differing terminology: byGraphisoftas \"Virtual Building\" or \"Single Building Model\",Bentley Systemsas \"Integrated Project Models\", and byAutodeskorVectorworksas \"Building Information Modeling\".In 2002, Autodesk released awhite paperentitled \"Building Information Modeling,\"and other software vendors also started to assert their involvement in the field.By hosting contributions from Autodesk, Bentley Systems and Graphisoft, plus other industry observers, in 2003,Jerry Laiserin helped popularize and standardize the term as a common name for the digital representation of the building process.Early adoption by architectural and engineering firms in the 2000s helped drive BIM’s global acceptance, paving the way for standardized processes and data exchange formats. As some BIM software developers have created proprietary data structures in their software, data and files created by one vendor's applications may not work in other vendor solutions. To achieveinteroperabilitybetween applications, neutral, non-proprietary or open standards for sharing BIM data among different software applications have been developed. Poor software interoperability has long been regarded as an obstacle to industry efficiency in general and to BIM adoption in particular. In August 2004 a US National Institute of Standards and Technology (NIST) report conservatively estimated that $15.8 billion was lost annually by the U.S. capital facilities industry due to inadequate interoperability arising from \"the highly fragmented nature of the industry, the industry’s continued paper-based business practices, a lack of standardization, and inconsistent technology adoption among stakeholders\". An early BIM standard was the CIMSteel Integration Standard, CIS/2, a product model and data exchange file format for structural steel project information (CIMsteel: Computer Integrated Manufacturing of Constructional Steelwork). CIS/2 enables seamless and integrated information exchange during the design and construction of steel framed structures. It was developed by theUniversity of Leedsand the UK's Steel Construction Institute in the late 1990s, with inputs fromGeorgia Tech, and was approved by theAmerican Institute of Steel Constructionas its data exchange format for structural steel in 2000. BIM is often associated withIndustry Foundation Classes(IFCs) andaecXML– data structures for representing information – developed bybuildingSMART. IFC is recognised by theISOand has been an international standard, ISO 16739, since 2013.OpenBIM is an initiative by buildingSMART that promotes open standards and interoperability. Based on the IFC standard, it allows vendor-neutral BIM data exchange. OpenBIM standards also includeBIM Collaboration Format(BCF) for issue tracking andInformation Delivery Specification(IDS) for defining model requirements. Construction Operations Building information exchange (COBie) is also associated with BIM. COBie was devised by Bill East of theUnited States Army Corps of Engineersin 2007,and helps capture and record  equipment lists, product data sheets, warranties, spare parts lists, and preventive maintenance schedules. This information is used to support operations, maintenance and asset management once a built asset is in service.In December 2011, it was approved by the US-basedNational Institute of Building Sciencesas part of its National Building Information Model (NBIMS-US) standard.COBie has been incorporated into software, and may take several forms including spreadsheet, IFC, and ifcXML. In early 2013BuildingSMARTwas working on a lightweight XML format, COBieLite, which became available for review in April 2013.In September 2014, a code of practice regarding COBie was issued as a British Standard: BS 1192-4. In January 2019, ISO published the first two parts of ISO 19650, providing a framework for building information modelling, based on process standards developed in the United Kingdom. UK BS and PAS 1192 specifications form the basis of further parts of the ISO 19650 series, with parts on asset management (Part 3) and security management (Part 5) published in 2020. TheIEC/ISO 81346series for reference designation has published 81346-12:2018,also known as RDS-CW (Reference Designation System for Construction Works). The use of RDS-CW offers the prospect of integrating BIM with complementary international standards based classification systems being developed for the Power Plant sector. ISO 19650-1:2018 defines BIM as: The US National Building Information Model Standard Project Committee has the following definition: Traditional building design was largely reliant upon two-dimensionaltechnical drawings(plans, elevations, sections, etc.). Building information modeling extends the three primary spatial dimensions (width, height and depth), incorporating information about time (so-called 4D BIM),cost (5D BIM),asset management, sustainability, etc. BIM therefore covers more than just geometry. It also covers spatial relationships, geospatial information, quantities and properties of building components (for example, manufacturers' details), and enables a wide range of collaborative processes relating to the built asset from initial planning through to construction and then throughout its operational life. BIM authoring tools present a design as combinations of \"objects\" – vague and undefined, generic or product-specific, solid shapes or void-space oriented (like the shape of a room), that carry their geometry, relations, and attributes. BIM applications allow extraction of different views from a building model for drawing production and other uses. These different views are automatically consistent, being based on a single definition of each object instance.BIM software also defines objects parametrically; that is, the objects are defined as parameters and relations to other objects so that if a related object is amended, dependent ones will automatically also change.Each model element can carry attributes for selecting and ordering them automatically, providing cost estimates as well as material tracking and ordering. For the professionals involved in a project, BIM enables a virtual information model to be shared by the design team (architects,landscape architects,surveyors,civil,structuralandbuilding servicesengineers, etc.), themain contractorandsubcontractors, and the owner/operator. Each professional adds discipline-specific data to the shared model – commonly, a 'federated' model which combines several different disciplines' models into one.Combining models enables visualisation of all models in a single environment, better coordination and development of designs, enhanced clash avoidance and detection, and improved time and cost decision-making. \"BIM wash\" or \"BIM washing\" is a term sometimes used to describe inflated, and/or deceptive, claims of using or delivering BIM services or products. Use of BIM goes beyond the planning and design phase of a project, extending throughout the life cycle of the asset. The supporting processes ofbuilding lifecycle managementincludecost management,construction management,project management,facility operationandapplication ingreen building. A 'Common Data Environment' (CDE) is defined in ISO 19650 as an: A CDE workflow describes the processes to be used while a CDE solution can provide the underlying technologies. A CDE is used to share data across a project or asset lifecycle, supporting collaboration across a whole project team. The concept of a CDE overlaps withenterprise content management, ECM, but with a greater focus on BIM issues. Building information models span the whole concept-to-occupation time-span. To ensure efficient management of information processes throughout this span, a BIM manager might be appointed. The BIM manager is retained by a design build team on the client's behalf from the pre-design phase onwards to develop and to track the object-oriented BIM against predicted and measured performance objectives, supporting multi-disciplinary building information models that drive analysis, schedules, take-off and logistics.Companies are also now considering developing BIMs in various levels of detail, since depending on the application of BIM, more or less detail is needed, and there is varying modeling effort associated with generating building information models at different levels of detail. Participants in the building process are constantly challenged to deliver successful projects despite tight budgets, limited staffing, accelerated schedules, and limited or conflicting information. The significant disciplines such asarchitectural,structuralandMEPdesigns should be well-coordinated, as two things can't take place at the same place and time. BIM additionally is able to aid in collision detection, identifying the exact location of discrepancies. The BIM concept envisages virtual construction of a facility prior to its actual physical construction, in order to reduce uncertainty, improve safety, work out problems, and simulate and analyze potential impacts.Sub-contractors from every trade can input critical information into the model before beginning construction, with opportunities to pre-fabricate or pre-assemble some systems off-site. Waste can be minimised on-site and products delivered on a just-in-time basis rather than being stock-piled on-site.BIM improves project coordination by enabling real-time collaboration, allowing teams to identify and resolve issues before construction begins. Quantities and shared properties of materials can be extracted easily. Scopes of work can be isolated and defined. Systems, assemblies and sequences can be shown in a relative scale with the entire facility or group of facilities. BIM also prevents errors by enabling conflict or 'clash detection' whereby the computer model visually highlights to the team where parts of the building (e.g.:structural frame and building services pipes or ducts) may wrongly intersect. BIM can bridge the information loss associated with handing a project from design team, to construction team and to building owner/operator, by allowing each group to add to and reference back to all information they acquire during their period of contribution to the BIM model. Enabling an effective handover of information from design and construction (including via IFC or COBie) can thus yield benefits to the facility owner or operator.BIM-related processes relating to longer-term asset management are also covered in ISO-19650 Part 3. For example, a building owner may find evidence of a water leak in a building. Rather than exploring the physical building, the owner may turn to the model and see that a watervalveis located in the suspect location. The owner could also have in the model the specific valve size, manufacturer, part number, and any other information ever researched in the past, pending adequate computing power. Such problems were initially addressed by Leite and Akinci when developing a vulnerability representation of facility contents and threats for supporting the identification of vulnerabilities in building emergencies. Dynamic information about the building, such as sensor measurements and control signals from the building systems, can also be incorporated within software to support analysis of building operation and maintenance.As such, BIM in facility operation can be related tointernet of thingsapproaches;rapid access to data may also be aided by use of mobile devices (smartphones, tablets) and machine-readableRFIDtags orbarcodes;while integration and interoperability with other business systems -CAFM,ERP,BMS, IWMS, etc - can aid operational reuse of data. There have been attempts at creating information models for older, pre-existing facilities. Approaches include referencing key metrics such as theFacility Condition Index(FCI), or using3D laser-scanningsurveys andphotogrammetrytechniques (separately or in combination) or digitizing traditional building surveying methodologies by using mobile technology to capture accurate measurements and operation-related information about the asset that can be used as the basis for a model. Trying to retrospectively model a building constructed in, say 1927, requires numerous assumptions about design standards, building codes, construction methods, materials, etc, and is, therefore, more complex than building a model during design. One of the challenges to the proper maintenance and management of existing facilities is understanding how BIM can be utilized to support a holistic understanding and implementation ofbuilding managementpractices and \"cost of ownership\" principles that support the fullproduct lifecycleof a building.  AnAmerican National StandardentitledAPPA 1000 – Total Cost of Ownership for Facilities Asset Managementincorporates BIM to factor in a variety of critical requirements and costs over thelife-cycleof the building, including but not limited to: replacement of energy, utility, and safety systems; continual maintenance of the building exterior and interior and replacement of materials; updates to design and functionality; and recapitalization costs. BIM ingreen building, or \"green BIM\", is a process that can help architecture, engineering and construction firms to improve sustainability in the built environment. It can allow architects and engineers to integrate and analyze environmental issues in their design over thelife cycleof the asset.In the ERANet projects EPC4SESand FinSESCo projects worked on the digital representation of the energy demand of the building. The nucleus is theXMLfrom issuingEnergy Performance Certificates, amended by roof data to be able to retrieve the position and size ofPVorPV/T. China began its exploration on informatisation in 2001. The Ministry of Construction announced BIM was as the key application technology of informatisation in\"Ten new technologies of construction industry\"(by 2010).The Ministry of Science and Technology (MOST) clearly announced BIM technology as a national key research and application project in\"12th Five-Year\" Science and Technology Development Planning.Therefore, the year 2011 was described as\"The First Year of China's BIM\". In 2006 theHong Kong Housing Authorityintroduced BIM,and then set a target of full BIM implementation in 2014/2015. BuildingSmart Hong Kong was inaugurated in Hong Kong SAR in late April 2012.TheGovernment of Hong Kongmandates the use of BIM for all government projects over HK$30M since 1 January 2018. India Building Information Modelling Association (IBIMA) is a national-level society that represents the entire Indian BIM community.In India BIM is also known as VDC:VirtualDesign andConstruction. Due to its population and economic growth, India has an expanding construction market. In spite of this, BIM usage was reported by only 22% of respondents in a 2014 survey.In 2019, government officials said BIM could help save up to 20% by shortening construction time, and urged wider adoption by infrastructure ministries. The Iran Building Information Modeling Association (IBIMA) was founded in 2012 by professional engineers from five universities in Iran, including the Civil and Environmental Engineering Department atAmirkabir University of Technology.While it is not currently active, IBIMA aims to share knowledge resources to support construction engineering management decision-making. BIM implementation is targeted towards BIM Stage 2 by the year 2020 led by the Construction Industry Development Board (CIDB Malaysia). Under the Construction Industry Transformation Plan (CITP 2016–2020),it is hoped more emphasis on technology adoption across the project life-cycle will induce higher productivity. The Building and Construction Authority (BCA) has announced that BIM would be introduced for architectural submission (by 2013), structural and M&E submissions (by 2014) and eventually for plan submissions of all projects with gross floor area of more than 5,000 square meters by 2015. The BCA Academy is training students in BIM. The Ministry of Land, Infrastructure and Transport (MLIT) has announced \"Start of BIM pilot project in government building and repairs\" (by 2010).Japan Institute of Architects (JIA) released the BIM guidelines (by 2012), which showed the agenda and expected effect of BIM to architects.MLIT announced \" BIM will be mandated for all of its public works from the fiscal year of 2023, except those having particular reasons\". The works subject to WTO Government Procurement Agreement shall comply with the published ISO standards related to BIM such as ISO19650 series as determined by the Article 10 (Technical Specification) of the Agreement. Small BIM-related seminars and independent BIM effort existed in South Korea even in the 1990s. However, it was not until the late 2000s that the Korean industry paid attention to BIM. The first industry-level BIM conference was held in April 2008, after which, BIM has been spread very rapidly. Since 2010, the Korean government has been gradually increasing the scope of BIM-mandated projects. McGraw Hill published a detailed report in 2012 on the status of BIM adoption and implementation in South Korea. Dubai Municipalityissued a circular (196) in 2014 mandating BIM use for buildings of a certain size, height or type. The one page circular initiated strong interest in BIM and the market responded in preparation for more guidelines and direction. In 2015 the Municipality issued another circular (207) titled 'Regarding the expansion of applying the (BIM) on buildings and facilities in the emirate of Dubai' which made BIM mandatory on more projects by reducing the minimum size and height requirement for projects requiring BIM. This second circular drove BIM adoption further with several projects and organizations adopting UK BIM standards as best practice. In 2016, the UAE's Quality andConformityCommission set up a BIM steering group to investigate statewide adoption of BIM. Austrian standards for digital modeling are summarized in the ÖNORM A 6241, published on 15 March 2015. The ÖNORM A 6241-1 (BIM Level 2), which replaced the ÖNORM A 6240-4, has been extended in the detailed and executive design stages, and corrected in the lack of definitions. The ÖNORM A 6241-2 (BIM Level 3) includes all the requirements for the BIM Level 3 (iBIM). The Czech BIM Council, established in May 2011, aims to implement BIM methodologies into the Czech building and designing processes, education, standards and legislation. In Estonia digital construction cluster (Digitaalehituse Klaster) was formed in 2015 to develop BIM solutions for the whole life-cycle of construction.The strategic objective of the cluster is to develop an innovative digital construction environment as well as VDCnew product development, Grid and e-construction portal to increase the international competitiveness and sales of Estonian businesses in the construction field. The cluster is equally co-funded by European Structural and Investment Funds through Enterprise Estonia and by the members of the cluster with a total budget of 600 000 euros for the period 2016–2018. The French arm ofbuildingSMART, called Mediaconstruct (existing since 1989), is supporting digital transformation in France. A building transition digital plan – French acronym PTNB – was created in 2013 (mandated since 2015 to 2017 and under several ministries). A 2013 survey of European BIM practice showed France in last place, but, with government support, in 2017 it had risen to third place with more than 30% of real estate projects carried out using BIM.PTNB was superseded in 2018 by Plan BIM 2022,administered by an industry body, the Association for the Development of Digital in Construction (AND Construction), founded in 2017, and supported by a digital platform, KROQI,developed and launched in 2017 by CSTB (France'sScientific and Technical Centre for Building). In December 2015, the German minister for transportAlexander Dobrindtannounced a timetable for the introduction of mandatory BIM for German road and rail projects from the end of 2020.Speaking in April 2016, he said digital design and construction must become standard for construction projects in Germany, with Germany two to three years behind The Netherlands and the UK in aspects of implementing BIM.BIM was piloted in many areas of German infrastructure delivery and in July 2022Volker Wissing,Federal Minister for Digital and Transport, announced that, from 2025, BIM will be used as standard in the construction of federal trunk roads in addition to the rail sector. In November 2017, Ireland's Department for Public Expenditure and Reform launched a strategy to increase use of digital technology in delivery of key public works projects, requiring the use of BIM to be phased in over the next four years. Through the new D.l. 50, in April 2016 Italy has included into its own legislation several European directives including 2014/24/EU on Public Procurement. The decree states among the main goals of public procurement the \"rationalization of designing activities and of all connected verification processes, through the progressive adoption of digital methods and electronic instruments such as Building and Infrastructure Information Modelling\".A norm in 8 parts is also being written to support the transition: UNI 11337-1, UNI 11337-4 and UNI 11337-5 were published in January 2017, with five further chapters to follow within a year. In early 2018 the Italian Ministry of Infrastructure and Transport issued a decree (DM 01/12/17) creating a governmental BIM Mandate compelling public client organisations to adopt a digital approach by 2025, with an incremental obligation which will start on 1 January 2019. Lithuania is moving towards adoption of BIM infrastructure by founding a public body \"Skaitmeninė statyba\" (Digital Construction), which is managed by 13 associations. Also, there is a BIM work group established by Lietuvos Architektų Sąjunga (a Lithuanian architects body). The initiative intends Lithuania to adopt BIM, Industry Foundation Classes (IFC) and National Construction Classification as standard. An international conference \"Skaitmeninė statyba Lietuvoje\" (Digital Construction in Lithuania) has been held annually since 2012. On 1 November 2011, the Rijksgebouwendienst, the agency within theDutch Ministry of Housing, Spatial Planning and the Environmentthat manages government buildings, introduced the Rgd BIM Standard,which it updated on 1 July 2012. In Norway BIM has been used increasingly since 2008. Several large public clients require use of BIM in open formats (IFC) in most or all of their projects. The Government Building Authority bases its processes on BIM in open formats to increase process speed and quality, and all large and several small and medium-sized contractors use BIM. National BIM development is centred around the local organisation, buildingSMART Norway which represents 25% of the Norwegian construction industry. BIMKlaster (BIM Cluster) is a non-governmental, non-profit organisation established in 2012 with the aim of promoting BIM development in Poland.In September 2016, the Ministry of Infrastructure and Construction began a series of expert meetings concerning the application of BIM methodologies in the construction industry. Created in 2015 to promote the adoption of BIM in Portugal and its normalisation, the Technical Committee for BIM Standardisation, CT197-BIM, has created the first strategic document for construction 4.0 in Portugal, aiming to align the country's industry around a common vision, integrated and more ambitious than a simple technology change. The Russian government has approved a list of the regulations that provide the creation of a legal framework for the use of information modeling of buildings in construction and encourages the use of BIM in government projects. The BIM Association of Slovakia, \"BIMaS\", was established in January 2013 as the first Slovak professional organisation focused on BIM. Although there are neither standards nor legislative requirements to deliver projects in BIM, many architects, structural engineers and contractors, plus a few investors are already applying BIM. A Slovak implementation strategy created by BIMaS and supported by the Chamber of Civil Engineers and Chamber of Architects has yet to be approved by Slovak authorities due to their low interest in such innovation. A July 2015 meeting at Spain's Ministry of Infrastructure [Ministerio de Fomento] launched the country's national BIM strategy, making BIM a mandatory requirement on public sector projects with a possible starting date of 2018.Following a February 2015 BIM summit in Barcelona, professionals in Spain established a BIM commission (ITeC) to drive the adoption of BIM in Catalonia. Since 2009 through the initiative of buildingSmart Switzerland, then 2013, BIM awareness among a broader community of engineers and architects was raised due to the open competition forBasel's Felix Platter Hospitalwhere a BIM coordinator was sought. BIM has also been a subject of events by the Swiss Society for Engineers and Architects, SIA. In May 2011 UK GovernmentChief Construction AdviserPaul Morrellcalled for BIM adoption on UK government construction projects.Morrell also told construction professionals to adopt BIM or be \"Betamaxed out\".In June 2011 the UK government published its BIM strategy,announcing its intention to require collaborative 3D BIM (with all project and asset information, documentation and data being electronic) on its projects by 2016. Initially, compliance would require building data to be delivered in a vendor-neutral 'COBie' format, thus overcoming the limited interoperability of BIM software suites available on the market. The UK GovernmentBIM Task Groupled the government's BIM programme and requirements,including a free-to-use set of UK standards and tools that defined 'level 2 BIM'.In April 2016, the UK Government published a new central web portal as a point of reference for the industry for 'level 2 BIM'.The work of the BIM Task Group then continued under the stewardship of theCambridge-basedCentre for Digital Built Britain(CDBB),announced in December 2017 and formally launched in early 2018. Outside of government, industry adoption of BIM since 2016 has been led by the UK BIM Alliance,an independent, not-for-profit, collaboratively-based organisation formed to champion and enable the implementation of BIM, and to connect and represent organisations, groups and individuals working towards digital transformation of the UK's built environment industry. In November 2017, the UK BIM Alliance merged with the UK and Ireland chapter of BuildingSMART.In October 2019, CDBB, the UK BIM Allianceand theBSI Grouplaunched the UK BIM Framework. Superseding the BIM levels approach, the framework describes an overarching approach to implementing BIM in the UK, giving free guidance on integrating the internationalISO 19650series of standards into UK processes and practice. National Building Specification(NBS) has published research into BIM adoption in the UK since 2011, and in 2020 published its 10th annual BIM report.In 2011, 43% of respondents had not heard of BIM; in 2020 73% said they were using BIM. BIM is not mandatory in Canada.Several organizations support BIM adoption and implementation in Canada: the Canada BIM Council (CANBIM, founded in 2008),the Institute for BIM in Canada,and buildingSMART Canada (the Canadian chapter ofbuildingSMARTInternational).Public Services and Procurement Canada(formerly Public Works and Government Services Canada) is committed to using non-proprietary or \"OpenBIM\" BIM standards and avoids specifying any specific proprietary BIM format. Designers are required to use the international standards of interoperability for BIM (IFC). TheAssociated General Contractors of Americaand US contracting firms have developed various working definitions of BIM that describe it generally as: Although the concept of BIM and relevant processes are being explored by contractors, architects anddevelopersalike, the term itself has been questioned and debatedwith alternatives including Virtual Building Environment (VBE) also considered. Unlike some countries such as the UK, the US has not adopted a set of national BIM guidelines, allowing different systems to remain in competition.In 2021, theNational Institute of Building Sciences(NIBS) looked at applying UK BIM experiences to developing shared US BIM standards and processes. The US National BIM Standard had largely been developed through volunteer efforts; NIBS aimed to create a national BIM programme to drive effective adoption at a national scale. BIM is seen to be closely related toIntegrated Project Delivery(IPD) where the primary motive is to bring the teams together early on in the project.A full implementation of BIM also requires the project teams to collaborate from the inception stage and formulate model sharing and ownership contract documents. TheAmerican Institute of Architectshas defined BIM as \"a model-based technology linked with a database of project information\",and this reflects the general reliance on database technology as the foundation. In the future, structured text documents such asspecificationsmay be able to be searched and linked to regional, national, and international standards. BIM has the potential to play a vital role in the Nigerian AEC sector. In addition to its potential clarity and transparency, it may help promote standardization across the industry. For instance, Utiomesuggests that, in conceptualizing a BIM-based knowledge transfer framework from industrialized economies to urban construction projects in developing nations, generic BIM objects can benefit from rich building information within specification parameters in product libraries, and used for efficient, streamlined design and construction. Similarly, an assessment of the current 'state of the art' by Korifound that medium and large firms were leading the adoption of BIM in the industry. Smaller firms were less advanced with respect to process and policy adherence. There has been little adoption of BIM in the built environment due to construction industry resistance to changes or new ways of doing things. The industry is still working with conventional 2D CAD systems in services and structural designs, although production could be in 3D systems. There is virtually no utilisation of 4D and 5D systems. BIM Africa Initiative, primarily based in Nigeria, is a non-profit institute advocating the adoption of BIM across Africa.Since 2018, it has been engaging with professionals and the government towards the digital transformation of the built industry.Produced annually by its research and development committee, the African BIM Report gives an overview of BIM adoption across the African continent. The South African BIM Institute, established in May 2015, aims to enable technical experts to discuss digital construction solutions that can be adopted by professionals working within the construction sector. Its initial task was to promote the SA BIM Protocol. There are no mandated or national best practice BIM standards or protocols in South Africa. Organisations implement company-specific BIM standards and protocols at best (there are isolated examples of cross-industry alliances). In February 2016, Infrastructure Australia recommended: \"Governments should make the use of Building Information Modelling (BIM) mandatory for the design of large-scale complex infrastructure projects. In support of a mandatory rollout, the Australian Government should commission the Australasian Procurement and Construction Council, working with industry, to develop appropriate guidance around the adoption and use of BIM; and common standards and protocols to be applied when using BIM\". In 2015, many projects in the rebuilding ofChristchurchwere being assembled in detail on a computer using BIM well before workers set foot on the site. The New Zealand government started a BIM acceleration committee, as part of a productivity partnership with the goal of 20 per cent more efficiency in the construction industry by 2020.Today, BIM use is still not mandated in the country while several challenges have been identified for its implementation in the country.However, members of the AEC industry and academia have developed a national BIM handbook providing definitions, case studies and templates. Some purposes or uses of BIM may be described as 'dimensions'. However, there is little consensus on definitions beyond 5D. Some organisations dismiss the term; for example, the UKInstitution of Structural Engineersdoes not recommend using nD modelling terms beyond 4D, adding \"cost (5D) is not really a 'dimension'.\" 3D BIM, an acronym forthree-dimensionalbuilding information modeling, refers to the graphical representation of an asset's geometric design, augmented by information describing attributes of individual components. 3D BIM work may be undertaken by professional disciplines such as architectural, structural, andMEP,and the use of 3D models enhances coordination and collaboration between disciplines. A 3D virtual model can also be created by creating apoint cloudof the building or facility usinglaser scanningtechnology. 4D BIM, an acronym for 4-dimensional building information modeling, refers to the intelligent linking of individual3D CADcomponents or assemblies with time- or scheduling-related information.The term 4D refers to thefourth dimension:time, i.e. 3D plus time. 4D modelling enables project participants (architects, designers, contractors, clients) to plan, sequence the physical activities, visualise the critical path of a series of events, mitigate the risks, report and monitor progress of activities through the lifetime of the project.4D BIM enables a sequence of events to be depicted visually on a time line that has been populated by a 3D model, augmenting traditionalGantt chartsandcritical path (CPM)schedules often used in project management.Construction sequences can be reviewed as a series of problems using 4D BIM, enabling users to explore options, manage solutions and optimize results. As an advanced construction management technique, it has been used by project delivery teams working on larger projects.4D BIM has traditionally been used for higher end projects due to the associated costs, but technologies are now emerging that allow the process to be used by laymen or to drive processes such as manufacture. 5D BIM, an acronym for5-dimensionalbuilding information modeling refers to the intelligent linking of individual 3D components or assemblies with time schedule (4D BIM) constraintsand then with cost-related information.5D models enable participants to visualise construction progress and related costs over time.This BIM-centric project management technique has potential to improve management and delivery of projects of any size or complexity. In June 2016,McKinsey & Companyidentified 5D BIM technology as one of five big ideas poised to disrupt construction. It defined 5D BIM as \"a five-dimensional representation of the physical and functional characteristics of any project. It considers a project’s time schedule and cost in addition to the standard spatial design parameters in 3-D.\" 6D BIM, an acronym for6-dimensionalbuilding information modeling, is sometimes used to refer to the intelligent linking of individual 3D components or assemblies with all aspects of project life-cycle management information.However, there is less consensus about the definition of 6D BIM; it is also sometimes used to cover use of BIM for sustainability purposes. In the project life cycle context, a 6D model is usually delivered to the owner when a construction project is finished. The \"As-Built\" BIM model is populated with relevant building component information such as product data and details, maintenance/operation manuals, cut sheet specifications, photos, warranty data, web links to product online sources, manufacturer information and contacts, etc. This database is made accessible to the users/owners through a customized proprietary web-based environment. This is intended to aid facilities managers in the operation and maintenance of the facility. The term is less commonly used in the UK and has been replaced with reference to the Asset Information Requirements (AIR) and an Asset Information Model (AIM) as specified in BS EN ISO 19650-3:2020.", "metadata": {"url": "https://en.wikipedia.org/wiki/Building_information_modeling", "title": "Building information modeling", "headings": ["Contents", "History", "Interoperability and BIM standards", "Definition", "BIM wash", "Usage throughout the asset life cycle", "Common Data Environment", "Management of building information models", "BIM in construction management", "BIM in facility operation and asset management", "BIM in green building", "International developments", "Asia", "Europe", "North America", "Africa", "Oceania", "Purposes or dimensionality", "3D", "4D", "5D", "6D", "See also", "Notes", "References", "Further reading"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Building_information_modeling", "https://en.wikipedia.org/wiki/Building_information_modeling", "https://en.wikipedia.org/wiki/Building_information_modeling", "https://en.wikipedia.org/wiki/Bim_(disambiguation)", "https://en.wikipedia.org/wiki/Mechanical_room", "https://en.wikipedia.org/wiki/Lidar", "https://en.wikipedia.org/wiki/Chief_Architect_Software", "https://en.wikipedia.org/wiki/Cutaway_drawing"]}},
{"id": "c0310ac233b4", "content": " University College Dublin(Irish:Coláiste na hOllscoile, Baile Átha Cliath), commonly referred to asUCD, is a publicresearch universityinDublin, Ireland, and amember institutionof theNational University of Ireland. With more than 38,000 students, it is Ireland's largest university. UCD originates in a body founded in 1854, which opened as theCatholic University of Irelandon the feast ofSt. MalachywithJohn Henry Newmanas its first rector; it re-formed in 1880 and chartered in its own right in 1908. The Universities Act, 1997 renamed the constituent university as the \"National University of Ireland, Dublin\", and a ministerial order of 1998 renamed the institution as \"University College Dublin – National University of Ireland, Dublin\". Originally located atSt Stephen's GreenandEarlsfort terracein Dublin's city centre, all faculties later relocated to a 133-hectare (330-acre)campus atBelfield, six kilometres to the south of the city centre. In 1991, it purchased a second site in Blackrock,which currently houses theMichael Smurfit Graduate Business School. A report published in May 2015 asserted that the economic output generated by UCD and its students in Ireland amounted to €1.3 billion annually. UCD can trace its history to the institution founded in 1854 as theCatholic University of Ireland.Renamed University College in 1883 and put under the control of theJesuitsin 1883,it became University College Dublin in 1908, a constituent college of theNational University of Irelandunder the Universities Act. After theCatholic Emancipationperiod of Irish history,Archbishop of Armaghattempted to provide, for the first time in Ireland, higher-level education for followers of theCatholic Churchand taught by such people. The Catholic hierarchy demanded a Catholic alternative to the University of Dublin'sTrinity College, whoseAnglicanorigins the hierarchy refused to overlook. Since the 1780s, the University of Dublin had admitted Catholics to study; a religious test, however, hindered the efforts of Catholics in their desire to obtain membership in the university's governing bodies. Thus, in 1850 at theSynodofThurles, it was decided to open a university in Dublin for Catholics. As a result of these efforts, a new \"Catholic University of Ireland\" opened in 1854 onSt Stephen's Green, withJohn Henry Newmanappointed as its first rector.The Catholic University opened its doors on the feast of St Malachy, 3 November 1854.In 1855, the Catholic University Medical School was opened on Cecilia Street. As a private university, Catholic University was never given a royal charter, and so was unable to award recognised degrees and suffered from chronic financial difficulties. Newman left the university in 1857. In 1861, Bartholomew Woodlock was appointed Rector and served until he becameBishop of Ardagh and Clonmacnoisein 1879.Henry Nevillewas appointed Rector to replace Woodlock. In 1880, theRoyal University of Irelandwas established and allowed students from any college to take examinations for a degree. In 1882, Catholic University reorganised, and the St Stephen's Green institution (the former Arts school of the Catholic University) run by the Irish Jesuits,was renamed University College,and it began participating in the Royal University system. In 1883, FrWilliam DelanySJ was appointed the first president of University College. The college attracted academics from around Ireland, includingFr.Gerard Manley HopkinsandJames Joyce. Some notable staff and students at the school during this period includedFrancis Sheehy-Skeffington,Patrick Pearse,Hugh Kennedy, Hannah O'Leary,Eoin MacNeill,Kevin O'Higgins,Tom Kettle,James Ryan,Douglas HydeandJohn A. Costello. In 1908, theNational University of Irelandwas founded and the following year the Royal University was dissolved.This new university was brought into existence with three constituent University Colleges – Dublin,GalwayandCork.Following the establishment of the NUI, D. J. Coffey, Professor of Physiology, Catholic University Medical School, became the first president of UCD. The Medical School in Cecilia Street became the UCD Medical Faculty and the Faculty of Commerce was established. Under the Universities Act, 1997, University College Dublin was established as a constituent university within the National University of Ireland framework. In 1911, land donated byLord Iveaghhelped the university expand inEarlsfort Terrace/Hatch Street/ St Stephen's Green.Iveagh Gardenswas part of this donation. UCD is a major holder of archives of national and international significance relating to theIrish War of Independence. In 1913, in response to the formation of theUlster Volunteers,Eóin MacNeill, professor of early Irish history, called for the formation of an Irish nationalist force to counteract it.TheIrish Volunteerswere formed later that year and MacNeill was elected its Chief-of-staff.At the outbreak ofWorld War I, in view of theHome Rule Act 1914and the political perception that it might not be implemented, the leader of the Home Rule Party,John Redmond, urged the Irish Volunteers to support the British war effort as a way of supporting Irish Home Rule.This effort on behalf of Home Rule included many UCD staff and students. Many of those who opposed this move later participated in theEaster Rising. Several UCD staff and students participated in the rising, includingPádraig Pearse,Thomas MacDonagh,Michael HayesandJames Ryan, and a smaller number, includingTom KettleandWillie Redmond, fought for the British inWorld War I. Many UCD staff, students and alumni fought in theIrish War of Independence. Following the signing of theAnglo-Irish Treaty, four UCD graduates joined thegovernment of the Irish Free State. UCD graduates have since participated in Irish political life – three of the ninePresidents of Irelandand six of the fourteenTaoisighhave been either former staff or graduates. In 1926, the University Education (Agriculture and Dairy Science) Act transferred theRoyal College of ScienceinMerrion Streetand Albert Agricultural College in Glasnevin to UCD.In 1933, Belfield House was purchased for sporting purposes. In 1940, Arthur Conway was appointed president.By the early 1940s, the college had become the largest third-level institution in the state and the college attempted to expand the existing city centre campus. It was later decided that the best solution would be to move the college to a larger greenfield site outside of the city centre and create a moderncampus university. This move started in the early 1960s when the faculty of science moved to the new 1.4 square kilometres (350 acres) park campus atBelfieldin a suburb on the south side of Dublin.The Belfield campus developed into a complex of modern buildings and inherited Georgian townhouses, accommodating the colleges of the university as well as its student residences and many leisure and sporting facilities. One of UCD's previous locations, theRoyal College of Scienceon Merrion Street, is now the location of the renovatedIrish GovernmentBuilding, where the Department of theTaoiseach(Irish prime minister) is situated.University College Dublin also had a site inGlasnevinfor much of the last century, theAlbert Agricultural College, the southern part of which is now occupied byDublin City University, the northern part is where parts of the suburb ofBallymunare located. The new campus was largely designed byA&D Wejchert & Partners Architectsand includes several notable structures, including the UCD Water Tower which was built in 1972 by John Paul Construction. The Tower won the 1979 Irish Concrete Society Award.It stands 60 metres high with a dodecahedron tank atop a pentagonal pillar.The Tower is part of the UCD Environmental Research Station.O'Reilly Hall, opened in 1994, was designed by the Irish architecture firmScott Tallon Walker. In 1964, Jeremiah Hogan was appointed president andThomas E. Nevinled the science faculty to move to a new campus atBelfield. Also that year, UCD became the first university in Europe to launch anMBAprogramme. In 1967,Donogh O'Malleyproposed a plan to merge UCD and Trinity.Between 1969 and 1970, the Faculties of Commerce, Arts and Law moved to Belfield.In 1972, Thomas Murphy was appointed president.In 1973, the library opened.In 1980, the college purchased Richview and 17.4 acres and the architecture faculty moved there. In 1981, the Sports Complex opened. In 1986, Patrick Masterson was appointed president. From the 1980s until his death in January 2021, a solitary, non-verbal homeless man affectionately known asOld Man Belfieldbecame a fixture of campus life at Belfield, becoming well known to students and staff alike.The man, whose real name was Michael Byrne, slept rough on campus for the last 30, if not 40 years, of his life.Despite not speaking, he came to be \"loved and respected by generations of students and staff\"and accepted as \"part of the UCD community\". During the 1990s, some of the students of Women's Studies, led by Niamh Nolan, petitioned to rename their Gender Studies building afterHanna Sheehy-Skeffingtonto honour her contribution to women's rights and equal access to third-level education. Her husbandFrancis Sheehy-Skeffingtonwas himself an alumnus of the university and Hanna of the Royal University, a sister university of UCD. Their campaign was successful and the building was renamed the Hanna Sheehy-Skeffington Building. In 1990, UCD purchased Carysfort College, Blackrock, and became the location of theSmurfit Graduate school of business.The first student village, Belgrove, opened that year as well. In 1992, the second student village, Merville, opened and the Centre for Film studies was established. In 1993, Art Cosgrove was appointed president.In 1994, O'Reilly Hall was opened. InMalaysia, UCD andRoyal College of Surgeons in Ireland(RCSI) owns a private medical universityRCSI & UCD Malaysia Campus(RUMC) withinGeorge Town, Penang. Established in 1996, RUMC, as a branch campus of UCD, offers a twinning programme in medicine where students spend the first half of their course in either RCSI or UCD, before completing their clinical years at RUMC. In 2003, NovaUCD, a Euro Innovation and Technology Transfer Centre, opened.In 2004,Hugh Bradywas appointed president.In 2006, UCD Horizons begins. In 2009, Trinity and UCD announce the Innovation Alliance. In 2010,NCADand UCD form an academic alliance. In 2012 the expanded Student and Sports Centre opened. In 2012, the college closed the athletics track and field facilities and students demanded an apology.In 2013, the UCD O'Brien Centre for Science opened and the UCD Sutherland School of Law opened.It is now the largestCommon Lawlaw school in the European Union. In 2015, UCD opened a global centre in the US.In 2019, UCD became the first Irish university to launch aBlack Studiesmodule, coordinated by DrEbun Josephand ProfKathleen Lynch.In March 2022 Prof Andrew Deeks resigned to take up the role of vice-Chancellor at Murdoch University, in Perth, Western Australia.Prof Mark Rogers was appointed acting president. UCD consists of six colleges, their associated schools (37 in total)and multiple research institutes and centres.Each college also has its ownGraduate School, for postgraduates. List of colleges and their respective schools following restructuring in September 2015. The UCD College of Business is made up of the Quinn School of Business, theMichael Smurfit Graduate Business School, and UCD Business International Campus.The former constituent school, the UCD Quinn School of Business (commonly The Quinn School), is the building in which the UCD College of Business's undergraduate programme is based. It is located in a three-story building on the Belfield campus and is named afterLochlann Quinn, one of the main financial contributors to the school. Other donors includedBank of Ireland,AIB,Irish Life & Permanent,Accenture,KPMG,PwC,Dunnes StoresandErnst & Young.When first opened in 2002, it claimed to be the only business school in Europe with a specific focus on technology ande-learning. At the beginning of the 2005/2006 academic year, UCD introduced theHorizonscurriculum,which completely semesterised and modularised all undergraduate courses.  Under the new curriculum, students choose ten core modules from their specific subject area and two other modules, which can be chosen from any other programme at the university. UCD is also home to UCD Professional Academy, which offers career development through a range of professional diplomas.Subject areas include Business, IT, Management, Marketing and Design. Undergraduate fees are funded in part by the Irish State (for EU citizens) and by students themselves under the \"Free Fees Initiative\".Postgraduate fees vary depending on the student nationality, course and degree type, ranging from 7,000€ to 22,000€ per year. The initial patrons and benefactors of UCD were the Catholic Church. Amongst the most recent patrons include actorGregory Peck, who was a founding patron of the School of Film.Other benefactors includeLochlann Quinn(UCD Quinn School of Business),Michael Smurfit(Michael Smurfit Graduate Business School),Peter Sutherland(Sutherland School of Law),Tony O'Reilly(O'Reilly Hall)andDenis O'Brien(O'Brien Science Centre). In the 2025QS World University Rankings, UCD was ranked as 126th in the world.The 2022QS World University Rankingsfor employability and reputation rate UCD as first in Ireland and 87th in the world. The 2023Times Higher Education World University Rankingsplaced UCD in the range of 201–250.It also ranked it 101–200th in the 2022 Impact Rankings. TheQSSubject Ranking: Veterinary Science, 2018 ranked UCD 24th globally and first in Ireland. The 2024U.S. News & World Reportranked UCD as the second best university in Ireland and 253rd globally. UCD's Michael Smurfit Graduate Business School is ranked 22nd in the Financial Times' ranking of leading European Business Schools in 2022 and 1st in Ireland. UCD was The Sunday Times University of the Year 2006 and 2020. UCD had a research income of €155.7 million during 2021/22. The School of Physics hosts research groups in Astrophysics, space science and relativity theory (members of theVERITASandINTEGRALexperiments) and Experimental particle physics (participating in theLarge Hadron ColliderexperimentsLHCbandCMS). Amongst the research institutes of the university are:  Wide partnerships in which UCD is involved include: The most prominent UCD-related company is theIE Domain Registry; many UCD academics continue to sit on the board of directors. UCD originally gained control of the.iedomain in the late 1980s. The NovaUCD initiative is UCD's innovation and technology transfer centre, funded through a public-private partnership.In 2004,Duologrelocated its Dublin headquarters to NovaUCD. TheEducational Irish Research Satellite 1, or EIRSAT-1, was aCubeSatdeveloped at UCDwith the support of the Education Officeof theEuropean Space Agency. It was Ireland's first satellite , launched on 1 December 2023. Thestudents' unionin the college has been an active part of campaigns run by the National Union,USI, and has played a role in the life of the college since its foundation in 1974. The Union has also taken stances on issues of human rights that have attracted attention in Ireland and around the world; in particular, it implemented a ban ofCoca-Colaproducts in Student Union controlled shops on the basis of alleged human and trade union rights abuses inColombia. This ban was overturned in 2010. UCD has over 60 sports clubs based on campus with 28 sports scholarships awarded annually. UCD competes in the most popular Irish field sports ofGaelic games,hurling, soccer andrugby union. UCD is the only Irish university to compete in both the major Irish leagues for rugby and soccer,withUniversity College Dublin A.F.C.andUniversity College Dublin R.F.C.competing in the top leagues of their respective competitions.UCD GAAhave won the mostSigerson Cup(Gaelic football) titles, whilst they have the second mostFitzgibbon Cup(hurling) wins, both the major university competitions in the sports in Ireland. UCD sport annually compete in theColours MatchwithTrinity College Dublinin a range of sports, including in rugby. The rugby side has won 35 of the 57 contests. UCD RFC has produced 13British and Irish Lionsas well 70Irish Rugby Internationaland 5 for other nations. In 1985,UCDdrew withEverton F.C.in the first round of theUEFA Cup Winners' Cup, which Everton went on to win. Other team sports in the college basketball side,UCD Marian, victors in the 2012 Irish Basketball Superleague. The Belfield campus is home to a number of sports facilities. These include the National Hockey stadium (which has previously hosted theWomen's Hockey World Cup Finalsand the Men's Hockey European Championship Finals) andUCD Bowla 3,000 capacity stadium used for rugby and soccer. UCD has one of the largest fitness centres in the country,squash courts, tennis courts, an indoor rifle range, over twenty sports pitches (for rugby, soccer and Gaelic games), an indoor climbing wall and two large sports halls. The Sportscenter was added to in 2012 with the competition of anOlympic-size swimming pool, atepidariumand an updated fitness center as part of the re-development of the UCD Student Centre. UCD hosted theIFIUSWorld Interuniversity Gamesin October 2006. UCD Boat Club represents the college inrowing. Crews train on theRiver LiffeyatIslandbridgeand onPoulaphouca ReservoirinBlessington, in addition to land-based training on campus. The UCD men's eight were victorious at the Henley Royal Regatta in 1974. In later years, the club has had successes in both ladies' and men's rowing. UCD ladies have won many National Senior Championships, most recently in 2015.As of 2023, UCD were the champions in the men's Senior 8 oar event, having won this event for four consecutive years. UCD have also held national titles also in men's Senior 4 oar and Novice 8 oar championships. Several members of the club have represented Ireland at the World Championships and Olympic Games. The club competes annually in the Gannon Cup – the colours race against Trinity College on the Liffey. The event was first contested in 1947. As of 2025, the record in the competition is 37 victories apiece, with one dead heat. UCD Ladies compete for the Corcoran cup for the colours with UCD having won 27 times to 17 by Trinity. Leinster Rugby's headquarters and training facility are located on campus, housing the academy, senior squad and administrative arms of the rugby club. Their facilities include an office block and a high performance facility, located next to the Institute of Sport and Health (ISH). It was completed in 2012 at a cost of 2.5 million euro.They also use UCD's pitches. As of 2022, UCD had more than seventy student societies,including large-scale party societies such as Ag Soc, Arts Soc, Commerce and Economics Society, ISS (and its subgroup AfricaSoc), INDSoc (Indian Society) and MSoc (Malaysian Society) who have the largest student communities of Indian and Malaysian students in Ireland.There are also religiously interested groups such as the Christian Union, the Islamic Society, the Atheist and Secular Society, a television station Campus Television Network, academic-oriented societies like the Economic Society,UCD Philosophy Society, Mathsoc, Classical Society, and An Cumann Gaelach, anIrish-language societyand such charities as St. Vincent de Paul, UCDSVP. There are two main societies for international students, ESN UCD (part of theErasmus Student Network) and the International Student's Society. The UCD Dramsoc is the university's drama society. The oldest societies include theLiterary and Historical Society(known as the L&H and which dates itself to 1855), the Commerce & Economics Society (in its 110th session as of 2022),and theLaw Society(founded in 1911).At the start of the 2012/13 Academic Year, the L&H had a membership of 5,143 becoming the largest student society in UCD and in Europe. The Commerce & Economics Society, which describes itself as \"Ireland's largest and oldest business orientated university society\", was originally a debating society.By 1999 it was, according to an article in theIrish Times, the \"largest college society in UCD, Ireland and the British Isles\".The society runs a number of events, including the formal black-tie 'Comm Ball', as well as mock interviews and networking events.Its notable former auditors and members include ex-TaoisighCharles HaugheyandGarret FitzGerald. Incompetitive debating, the L&H and Law Society have represented the college several times, with the L&H securing 11 team wins and 12 individual wins in theIrish Times Debateand the Law Society achieving 2 team wins and 2 individual wins. The two societies have also been successful at the UK and IrelandJohn Smith Memorial Mace(formerly The Observer Mace) with the L&H winning 5 titles and Law Society 2 titles. UCD has hosted theWorld University Debating Championshipstwice, including the 2006 event. A number of UCD societies engage in voluntary work on-campus and across Dublin. For example, the UCD Student Legal Service is a student-run society that provides free legal information clinics to the students of UCD. Irish political parties are also represented on campus, with chapters of ÓgraFianna Fáil, YoungFine Gael, Ógra Shinn Féin, the Young Greens, People Before Profit and Labour Youth.UCD's \"flagship instrumental ensemble\", the University College Dublin Symphony Orchestra, was celebrating its 20th anniversary season as of 2022/2023. UCD has two student newspapers currently published on campus, the broadsheetUniversity Observerand the tabloidCollege Tribune The University Observerhas won several awards, including five \"newspaper of the year\" awards at Ireland'sNational Student Media Awards.Founded in 1994, its first editors were Pat Leahy and comedianDara Ó Briain.Several figures in Irish journalism have held the position of editor includingThe Irish Timespolitical editor Pat Leahy,RTÉNews reporterSamantha Libreri, andVirgin Media Newspolitical correspondent Gavan Reilly.In 2001, in addition to several Irish National Student Media Awards, theUniversity Observertook the runner up prize for \"Best Publication\" at theGuardianStudent Media Awards in London. The main sections within the paper are campus, national and international news, comment, opinion and sport. Each issue is also accompanied by an arts and culture supplement calledO-Two, with music interviews, travel, fashion and colour pieces. TheCollege Tribunewas founded in 1989, with the assistance of political commentatorVincent Browne. Then an evening student at UCD, Browne noted the lack of an independent media outlet for students and staff and set about establishing astudent newspaper. The paper was initially established with links to theSunday Tribune, though over time these links faded and ultimately, theTribunewould outlast its national counterpart. The paper supports itself financially through commercial advertising in its print edition, and maintains editorial independence from both university authorities and the Students' Union.TheTribunehas been recognised on a number of occasions at theNational Student Media Awards, and won Student Newspaper of the Year at the 1996USI&Irish IndependentMedia Awards. College Tribunesections include news, sport, features, arts, film and entertainment, music, fashion, business, and politics & innovation. It also has an arts culture supplement,The Trib, and a satirical 'paper within a paper',The Evil Gerald. UCD also has a student radio station,Belfield FM, broadcasting throughout the academic year online on the station's website. The station is independently run by the UCD Broadcasting Society and has produced well known Irish radio presenters such asRyan TubridyandRick O'Shea(ofRTÉfame) and Barry Dunne of98FM.\nBelfield FM is the successor to UCD FM, which was operated within the entertainment office of thestudents' unionas a service for students. Initially launched in 1992, the station rebranded in 2000 and has operated since then under the current name. As a result of the implementation of the students' union's new constitution at the beginning of the 2012 / 2013 academic year, the station now operates as a student society. In later years,students have been given a scarf of St Patrick's blue, navy and saffron at the President's Welcome Ceremony when they are officially welcomed. These colours have replaced \"Faculty\" colours and are now worn at graduation also. Notablealumniand faculty of UCD include fiveNobel laureates,fourTaoisighof Ireland, threeIrish Presidents, and one President of India.The university has produced 32Chief Justicesof the Supreme Court of Ireland,29RhodesScholars, 3Pulitzer Prizewinners, and 3Pritzker Prizerecipients.Additionally, UCD is associated with writers such asJames Joyce,William Butler Yeats,andGerard Manley Hopkins; physicistDennis Jennings;Golden Globe AwardrecipientsCarroll O'ConnorandGabriel Byrne;Academy AwardwinnerNeil Jordan; one of the co-developers of theOxford–AstraZeneca COVID-19 vaccineTeresa Lambe; and manyCEOs, including those ofUnilever,Aer Lingus,Mediahuis Ireland,Chevron Corporation, andBP.  In International affairs UCD's alumni include: Seven of Ireland's former European Commissioners are alumni. Irish revolutionariesPádraig PearseandThomas MacDonagh, two of the leaders of theEaster Risingand signatories of theProclamation of the Irish Republicwere, respectively, a student and member of faculty at the university. As well as former president Douglas Hyde and Pádraig Pearse, UCD ProfessorEóin MacNeillhad a key role in theGaelic revivalin Ireland. Since the foundation of the Irish state in 1922, UCD has produced the largest number of Justices of theSupreme Court of Ireland, the largest number of Chief Justices and the largest number ofAttorneys General of Irelandof any Irish institution of higher education. AlumnaSíofra O'Learyis Judge at the European Court of Human Rights and three of the six current justices of the Supreme Court are UCD alumni. In 2008,Tony Holohanwas appointedChief Medical Officer for Ireland. In 2010,UCD School of Medicinegraduate and cardiothoracic surgeonEilis McGovernwas elected 168th President of theRoyal College of Surgeons in Irelandand thereby became the first female President of anysurgical Royal Collegein the world. Notable writers includeJames Joyce,Kate O'Brien,Austin Clarke,Benedict Kiely,Pearse Hutchinson,Thomas Kinsella,John Jordan,John McGahern,Paul LynchandHugh McFadden.Dee Forbes, Director GeneralRTÉandMiriam O'Callaghan, presenter of RTÉ's leading current affairs show, Prime Time, are alumni, as are comediansDermot Morgan(1952–1998) andDara Ó Briainwho were major figures in the university's debating scene for many years, andFoil Arms and Hogwho met at the Drama Society (Dramsoc). UCD has produced a number of notable athletes, including in field sports such asGaelic gamesandrugby union. Many played within the university's club sides such asBrian O'Driscollwho played forUniversity College Dublin R.F.C.The club has produced numerousBritish and Irish Lionsincluding O'Driscoll, with several others attending as students. Notable GAA athletes includeRena Buckley, one of the most decorated players in GAA history, having won a total of 17 All-Ireland senior medals;Seán Murphy, a medical school graduate and member of theGaelic Football Team of the Millennium; andNicky Rackard, included in theHurling Team of the Century.Kevin Moran, formerly a Gaelic football but also a soccer player forManchester United, graduated with a Bachelor of Commerce in 1976. Alumni include Ireland's fastest manIsrael Olatunde. Alumni involved in business include: A number of catholic religious figures studied or played significant roles at UCD, including CardinalsTomás Ó FiaichandDesmond Connell, as well as the founding rector Cardinal Newman. Clerical students fromClonliffe College,All Hallows College, St. Joseph's, Blackrock (Vincentians), the Holy Ghost Fathers (Spiritans) inBlackrock CollegeandKimmage Manor,St. Mary's Priory(Dominicans) and the JesuitMilltown Park(and Rathfarnham Castle) would have studied for degrees at UCD while studying theology in their seminaries, as theology prohibited by the Royal University and National University of Ireland until 1996. Amongst the number of humanitarians to attend areJohn O'Sheafounder of GOAL andTom Arnoldthe CEO ofConcern Worldwide. Former faculty includeDennis Jenningsof the School of Computing, considered to be anInternet pioneerfor his leadership ofNSFNET, the network that became theInternet backbone. Other notable faculty includePatrick Lynch, logician and philosopherJan Łukasiewicz, Professor of Science and SocietyJames Heckmanwho won theNobel Memorial Prize in Economic Sciencesin 2000, andgeotechnical engineerÉamon Hanrahan. James Joyce's novelA Portrait of the Artist as a Young Manis partially set in UCD (when it was sited onEarlsfort Terrace) whereStephen Dedalus(now the name of the IT building) is enrolled as a student. Joyce's posthumously published autobiographical novelStephen Herocontains stories of his time in UCD.Flann O'Brien's novelAt Swim-Two-Birdsfeatures a UCD student who writes a meta-novel wherein the author is put on trial by the characters of his novel.Maeve Binchy's novel,Circle of Friends, deals with three female friends starting college in UCD in the 1950s. However, shots of Trinity College were used in the1995 film. The secondRoss O'Carroll-Kellynovel,The Teenage Dirtbag Years, follows the titular character as he enters UCD. Christy Moorewrote a tongue in cheek song about UCD'sLiterary and Historical Societycalled \"The Auditor of the L and H\". Conor McPherson's third filmSaltwaterwas filmed in Belfield, UCD.InBoston Legal, Season 2, Episode 21 \"Word Salad Day\", there is a reference to a fictional study from University College Dublin that \"found that the effects of divorce on children are far more damaging than the death of a parent\". 53°18′30″N6°13′20″W﻿ / ﻿53.30833°N 6.22222°W﻿ /53.30833; -6.22222", "metadata": {"url": "https://en.wikipedia.org/wiki/University_College_Dublin_Press", "title": "University College Dublin", "headings": ["Contents", "History", "Catholic University of Ireland", "Foundation of University College Dublin", "UCD and the Irish War of Independence", "Expansion", "Move to Belfield", "1950–2000", "2000s", "Academic", "Colleges and schools", "UCD College of Business", "UCD Horizons", "UCD Professional Academy", "Fees", "Reputation", "Patrons and benefactors", "Rankings", "Research and innovation", "Research institutes", "External collaborations", "Current and former campus companies", "Satellite development", "Student life", "Students' Union", "Sport", "Leinster Rugby", "Societies", "Student publications and media", "UCD scarf colours", "Notable people", "Presidents", "Alumni", "In popular culture", "In literature", "In music and film", "See also", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/University_College_Dublin", "https://en.wikipedia.org/wiki/University_College_Dublin", "https://en.wikipedia.org/wiki/University_College_Dublin", "https://en.wikipedia.org/wiki/Geographic_coordinate_system", "https://en.wikipedia.org/wiki/University_of_Dublin", "https://en.wikipedia.org/wiki/Dublin_City_University", "https://en.wikipedia.org/wiki/Technological_University_Dublin", "https://en.wikipedia.org/wiki/Irish_language"]}},
{"id": "a45ca758f2ec", "content": "The Scranton Times-Tribuneis a morning newspaper serving theScranton, Pennsylvania, area. Until August 2023, it was the flagship title ofTimes-Shamrock Communicationsand run by three generations of the Lynett-Haggerty family. It is now owned byMediaNews Group, a subsidiary ofAlden Global Capital. On Sundays, the paper is published asThe Sunday Times. In the 12 months preceding September 2022, the paper had a daily average circulation of 24,434. The current paper is the result of a 2005 merger between the afternoonScranton Timesand morningScranton Tribune. TheTimeswas founded in 1870. It struggled under six owners before E. J. Lynett bought the paper in 1895. Within 20 years, theTimeswas the dominant newspaper in northeastern Pennsylvania, and the third-largest in the state (behind only thePhiladelphia Inquirerand thePittsburgh Press). In January 1923, Lynett founded one of Scranton's first radio stations, WQAN.The Lynett family still owns the station today under the callsWEJL. Lynett died in 1943. His three children took control of the paper with William R. Lynett, the oldest, as publisher and editor. He died in 1946; siblings Edward J. and Elizabeth R. Lynett took over as co-publishers, with Edward J. as editor. Edward J. Lynett died in 1966, and his four children took over. Shortly after they took over, theTimesexpanded to a full week with the appearance ofThe Sunday Times. In 1990, theTimesbought the remains of its principal rival, the morningScrantonian-Tribune. This paper had been founded in 1891 as theScranton Tribune. In 1910, it merged with Scranton's first newspaper,The Morning Republican, and changed its name to theScranton Republican. AfterLouis A. WatresandLaurence Hawley Watressold theRepublicanin 1934, it became theScranton Tribuneonce again in 1936.In 1938, Richard Little, owner of Scranton's Sunday paper,The Scrantonian(founded 1897), teamed up with Morris L. Goodman to buy theTribuneas well. The Goodman-Little family partnership continued for almost half a century, until Richard Little III sold his interest to the Goodmans in 1986. Only a year later, Media One Corporation (no relation to thecable company) bought out the Goodmans and merged the two papers into one seven-day morning paper,The Scrantonian-Tribune. However, Media One was unable to turn the paper around. In 1990, it shuttered the paper.The Lynetts bought theScrantonian-Tribunenameplate and some other assets, and relaunched the paper as theScranton Tribune, with much of the same content as theTimes(except for timely editing). By 2004, it was obvious that Scranton could no longer support a morning and afternoon paper, and the Lynetts announced that their two papers would merge into one morning paper,The Times-Tribune. The new paper first rolled off the presses on July 27, 2005. However, its legal name for some years afterward was stillThe Scranton Times; until the Lynetts sold the papter, the licensee for sister radio station WEJL and its satellites was \"The Scranton Times L. P.\" In April 2023, the newspaper ceased offering a print edition on Mondays. Instead, a digital version would be offered that day.That August, Times-Shamrock Communications sold theTimes-Tribuneand three other daily newspapers toMediaNews Group, earning a handsome return on E. J. Lynett's purchase of 128 years earlier. TheTimesendorsedGeorge W. Bushin 2000 but did not endorse anyone in 2004.The Times-TribuneendorsedBarack Obamain 2008 and 2012. The paper endorsedHillary Clintonin 2016, then native ScrantonianJoe Bidenin 2020. The Scranton Timeswon thePulitzer Prizefor Public Service in 1946, while theScranton TribuneandScrantonian(then separately owned) won the prize for Local Reporting in 1959. ", "metadata": {"url": "https://en.wikipedia.org/wiki/Scranton_Times_Tribune", "title": "The Scranton Times-Tribune", "headings": ["Contents", "History", "Endorsements", "Awards", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/The_Scranton_Times-Tribune", "https://en.wikipedia.org/wiki/The_Scranton_Times-Tribune", "https://en.wikipedia.org/wiki/The_Scranton_Times-Tribune", "https://en.wikipedia.org/wiki/Daily_newspaper", "https://en.wikipedia.org/wiki/Broadsheet", "https://en.wikipedia.org/wiki/MediaNews_Group", "https://en.wikipedia.org/wiki/MediaNews_Group", "https://en.wikipedia.org/wiki/English_language"]}},
{"id": "afa36efd1a16", "content": " TheEarly Admissions Scheme(EAS) was a subsystem of theJoint University Programmes Admissions System(JUPAS) developed by theUniversity Grants Committee of Hong Kong. The scheme had been adopted between the academic year of 2002/03 to 2010/11.It enabled students who skipped theHKALEto enter theUniversity of Hong Kong, theChinese University of Hong Kongor theHong Kong University of Science and Technology. Candidates who received 6 or more \"A\"s, attained level 4 or above in English Language and Chinese Language, or obtained \"C\" or above in French or Putonghua in theHKCEE, were eligible to take part in the scheme, which might grant them admission to the aforementioned institutions without requiring them to sit for the HKALE. Only 400-500 candidateswere eligible to join the scheme annually throughout the implementation of the scheme. Most of themwould be admitted to university after they graduated from Form 6. Others, who were studying Form 7 and going to take the HKALE, were usually those who either failed to enrol on their preferred programme  via the scheme, or planned tostudy abroadas some overseas universitiesmay not acceptadmissionapplications with HKCEE result only. Some studentswho were eligible to participate in the scheme, were once given an offer soon after the announcement of HKCEE results, thus allowing them to enter the university immediately rather than after completing Form 6. They were not classified as applicants of the scheme even though they were granted \"Early Admissions\", like other EAS applicants. Unlike the latter, those students were usually provided an extra year of bridging courses after they entered the university. After the last HKCEE, which was held in 2010, the scheme was officially abolished. By the number ofactualintakes, the EAS is the biggest subsystem ofJUPAS(roughly about 3-5% of total JUPAS intakes). It aims at providing flexibility to outstanding Secondary 6 students to be admitted to the three institutions participating in the scheme. Applicants must achieve the requirements in one sitting of the HKCEE or other qualifying examinations. Applicants will be invited to information sessions held by the three participating universities on specific dates in order to help them in choosing the universities and programmes. On submission, applicants may select up to three programmes per university, making it a total maximum of nine programmes. Applicants will then be invited to attend an interview by respective institutions. Usually only the first programme in the priority order of each institution will provide a subject-based interview but there are various exceptional cases. After the interviews applicants will receive feedbacks from the universities before they make their final choices. A few weeks after the interviews, applicants will be required to draw up a final list of iteration. The list should consist of a maximum of 5 programmes. The programmes in the list are divided into two bands, with the programmes in the first two priority order being Band A and the other three being Band B. Successful applicants will only receive one offer which is the highest priority on their programme list. Theoretically, to prevent domination in some popular \"elite\" programmes, hence causing unfairness to mainstream entrants, no programme should admit more the 1/3 EAS students to its total JUPAS intakes. An existence of such system made a few students may end up not being offered to their desired programme, though in most cases they will accept the less-desired offer. There are more and more critics on the Scheme who believe imposes an unfairness to Form 7 students (especially to those who have obtained remarkable HKCEE results but could not achieve Level 4 or above in either one or both language subject(s), those who are unable show their talent to the maximum extent in the HKCEE or who do not excel academically but in other areas which are ignored by the scheme) who are required to sit for the HKALE which is much more difficult than the HKCEE. Non-EAS students are likely to face huge pressure as the EAS students are often labelled as 'superior' whereas non-EAS students are categorised as 'inferior' or 'less able'. Non-EAS students have to face the HKALE, which is generally believed to be more tedious. Moreover, EAS entries are counted as entry by JUPAS but not direct admissions, which means, the mainstream applicant will have less chance entering certain programmes, especially programmes which are popular in EAS applicants, like Medicine. Nevertheless, not all eligible students participated in the scheme. Students who left their original secondary schools and went studying inHang Seng School of Commercehad to give up participating in this programme. On the contrary, students who went toPLK Vicwood KT Chong Sixth Form Collegewere not required to make such sacrifice for quality education. The general public and many education expertscriticise that HKCEE is not an appropriate examination for being a selection criteria of universities' admission procedure. Apart from this, the keen competition for places in the universities would extend to the HKCEE, and Form 5 students (HKCEE candidates) may encounter a high psychological pressure. It is also doubtfulwhether EAS-benefited students are mature enough to choose suitable university programmes which would probably determine their whole life. Adverse effect on EAS-benefited student (who have already seized places in the universities) learning in Form 6 would also be inevitable.", "metadata": {"url": "https://en.wikipedia.org/wiki/Early_Admissions_Scheme_(Hong_Kong)", "title": "Early Admissions Scheme (Hong Kong)", "headings": ["Contents", "The scheme", "Views of Non-EAS students", "Unfairness", "Form 6 Study", "Doubts in suitability for EAS students", "See also", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Early_Admissions_Scheme_(Hong_Kong)", "https://en.wikipedia.org/wiki/Early_Admissions_Scheme_(Hong_Kong)", "https://en.wikipedia.org/wiki/Early_Admissions_Scheme_(Hong_Kong)", "https://en.wikipedia.org/wiki/Higher_education", "https://en.wikipedia.org/wiki/Hong_Kong", "https://en.wikipedia.org/wiki/Joint_University_Programmes_Admissions_System", "https://en.wikipedia.org/wiki/Traditional_Chinese_characters", "https://en.wikipedia.org/wiki/Cantonese"]}},
{"id": "285fe128c4fd", "content": " The Washington Post(locally known asThePostand, informally,WaPoorWP) is an Americandaily newspaperpublished inWashington, D.C., the national capital. It is the most widely circulated newspaper in theWashington metropolitan areaand has a national audience. In 2023, thePosthad 130,000 print subscribers and 2.5 million digital subscribers, both of which were thethird-largestamong American newspapers afterThe New York TimesandThe Wall Street Journal. In 2025, the number of print subscribers had declined to below 100,000 for the first time in 55 years. ThePostwas founded in 1877. In its early years, it went through several owners and struggled both financially and editorially. In 1933, financierEugene Meyerpurchased it out of bankruptcy and revived its health and reputation; this work was continued by his successorsKatharineandPhil Graham, Meyer's daughter and son-in-law, respectively, who bought out several rival publications. ThePost's1971 printing of thePentagon Papershelped spuropposition to the Vietnam War. ReportersBob WoodwardandCarl Bernsteinled the investigation into the break-in at theDemocratic National Committee, which developed into theWatergate scandaland the1974 resignationof PresidentRichard Nixon. In October 2013, the Graham family sold the newspaper toNash Holdings, a holding company owned byJeff Bezos, forUS$250million. The newspaper has won thePulitzer Prize76 times for its work,the second-most of any publication afterThe New York Times.It is considered anewspaper of recordin the U.S.Postjournalists have received 18Nieman Fellowshipsand 368 White House News Photographers Association awards.The paper is well known for itspolitical reportingand is one of the few remaining American newspapers to operateforeign bureaus,with internationalbreaking newshubs inLondonandSeoul. The Washington Postis regarded as one of the leading daily American newspapers along withThe New York Times, theLos Angeles Times, andThe Wall Street Journal.ThePosthas distinguished itself through its political reporting on the workings of the White House, Congress, and other aspects of the U.S. government. It is considered a newspaper of record in the U.S. The Washington Postdoes not print an edition for distribution away from theEast Coast. In 2009, the newspaper ceased publication of itsNational Weekly Editiondue to shrinking circulation.The majority of its newsprint readership is in Washington, D.C., and its suburbs in Maryland and Northern Virginia. The newspaper's 21 foreign bureaus are inBaghdad,Beijing,Beirut,Berlin,Brussels,Cairo,Dakar,Hong Kong,Islamabad,Istanbul,Jerusalem,London,Mexico City,Moscow,Nairobi,New Delhi,Rio de Janeiro,Rome,Seoul,Tokyo, andToronto.In November 2009, the newspaper announced the closure of three U.S. regional bureaus inChicago,Los AngelesandNew York City, as part of an increased focus onWashington, D.C.–based political stories and local news.The newspaper has local bureaus in Maryland (Annapolis, Montgomery County, Prince George's County, and Southern Maryland) and Virginia (Alexandria, Fairfax, Loudoun County, Richmond, and Prince William County). As of March 2023, thePost's average printed weekday circulation is 139,232, making it the third largest newspaper in the country by circulation. For many decades, thePosthad its main office at 1150 15th Street NW. This real estate remained with Graham Holdings when the newspaper was sold to Jeff Bezos' Nash Holdings in 2013. Graham Holdings sold 1150 15th Street, along with 1515 L Street, 1523 L Street, and land beneath 1100 15th Street, for $159 million in November 2013.The Postcontinued to lease space at 1150 L Street NW.In May 2014,The Postleased the west tower ofOne Franklin Square, a high-rise building at 1301 K Street NW in Washington, D.C. Mary Jordanwas the founding editor, head of content, and moderator forWashington Post Live,The Post's editorial events business, which organizes political debates, conferences and news events for the media company, including \"The 40th Anniversary of Watergate\" in June 2012 that featured key Watergate figures including former White House counselJohn Dean,Washington PosteditorBen Bradlee, and reportersBob WoodwardandCarl Bernstein, which was held at the Watergate hotel. Regular hosts includeFrances Stead Sellers.Lois Romanowas formerly the editor ofWashington Post Live. ThePosthas its own exclusiveZIP Code, 20071. The newspaper was founded in 1877 byStilson Hutchins(1838–1912); in 1880, it added a Sunday edition, becoming the city's first newspaper to publish seven days a week. In April 1878, about four months into publication,The Washington PostpurchasedThe Washington Union, a competing newspaper which was founded byJohn Lynchin late 1877. TheUnionhad only been in operation about six months at the time of the acquisition. The combined newspaper was published from the Globe Building asThe Washington Post and Unionbeginning on April 15, 1878, with a circulation of 13,000.ThePost and Unionname was used about two weeks until April 29, 1878, returning to the original masthead the following day. In 1889, Hutchins sold the newspaper toFrank Hatton, a former Postmaster General, andBeriah Wilkins, a former Democratic congressman from Ohio. To promote the newspaper, the new owners requested the leader of theUnited States Marine Band,John Philip Sousa, to compose a march for the newspaper's essay contest awards ceremony. Sousa composed \"The Washington Post\".It became the standard music to accompany the two-step, a late 19th-century dance craze,and remains one of Sousa's best-known works. In 1893, the newspaper moved to a building at 14th and E streets NW, where it would remain until 1950. This building combined all functions of the newspaper into one headquarters – newsroom, advertising, typesetting, and printing – that ran 24 hours per day. In 1898, during theSpanish–American War, thePostprintedClifford K. Berryman's classic illustrationRemember the Maine, which became the battle-cry for American sailors during the War. In 1902, Berryman published another famous cartoon in thePost–Drawing the Line in Mississippi. This cartoon depicts PresidentTheodore Rooseveltshowing compassion for a small bear cub and inspired New York store ownerMorris Michtomto create the teddy bear.Wilkins acquired Hatton's share of the newspaper in 1894 at Hatton's death. After Wilkins' death in 1903, his sons John and Robert ran thePostfor two years before selling it in 1905 toJohn Roll McLean, owner of theCincinnati Enquirer. During the Wilson presidency, thePostwas credited with the \"most famous newspapertypo\" in D.C. history according toReasonmagazine; thePostintended to report that President Wilson had been \"entertaining\" his future-wife Mrs. Galt, but instead wrote that he had been \"entering\" Mrs. Galt. When McLean died in 1916, he put the newspaper in a trust, having little faith that his playboy sonEdward \"Ned\" McLeancould manage it as part of his inheritance. Ned went to court and broke the trust, but, under his management, the newspaper slumped toward ruin. He bled the paper for his lavish lifestyle and used it to promote political agendas. During theRed Summer of 1919the Post supported the white mobs and even ran a front-page story which advertised the location at which white servicemen were planning to meet to carry out attacks on black Washingtonians. In 1929, financierEugene Meyer, who had run theWar Finance Corp.sinceWorld War I,secretly made an offer of $5 million for thePost,but he was rebuffed by Ned McLean.On June 1, 1933, Meyer bought the paper at a bankruptcy auction for $825,000 three weeks after stepping down asChairman of the Federal Reserve. He had bid anonymously, and was prepared to go up to $2 million, far higher than the other bidders.These includedWilliam Randolph Hearst, who had long hoped to shut down the ailingPostto benefit his own Washington newspaper presence. ThePost'shealth and reputation were restored under Meyer's ownership. In 1946, he was succeeded as publisher by his son-in-law,Philip Graham.Meyer eventually gained the last laugh over Hearst, who had owned the oldWashington Timesand theHeraldbefore their 1939 merger that formed theTimes-Herald.This was in turn bought by and merged into thePostin 1954.The combined paper was officially namedThe Washington Post and Times-Heralduntil 1973, although theTimes-Heraldportion of thenameplatebecame less and less prominent over time. The merger left thePostwith two remaining local competitors, theWashington Star(Evening Star) andThe Washington Daily News. In 1972, the two competitors merged, forming theWashington Star-News. Following Graham's death in 1963, control of The Washington Post Company passed to his wife,Katharine Graham(1917–2001), who was also Eugene Meyer's daughter.Few women had run prominent national newspapers in the United States, and Katharine Graham described herself as particularly anxious about assuming this role.She served as publisher from 1969 to 1979. Graham took The Washington Post Company public on June 15, 1971, in the midst of thePentagon Paperscontroversy. A total of 1,294,000 shares were offered to the public at $26 per share.By the end of Graham's tenure as CEO in 1991, the stock was worth $888 per share, not counting the effect of an intermediate 4:1 stock split. Graham also oversaw the Post company's diversification purchase of the for-profit education and training companyKaplan, Inc.for $40 million in 1984.Twenty years later, Kaplan had surpassed thePostnewspaper as the company's leading contributor to income, and by 2010 Kaplan accounted for more than 60% of the entire company revenue stream. Executive editor Ben Bradlee put the newspaper's reputation and resources behind reporters Bob Woodward and Carl Bernstein, who, in a long series of articles, chipped away at the story behind the 1972 burglary ofDemocratic National Committeeoffices in theWatergate complexin Washington. ThePost'sdogged coverage of the story, the outcome of which ultimately played a major role in the resignation of PresidentRichard Nixon, won the newspaper aPulitzer Prizein 1973. In 1972, the \"Book World\" section was introduced with Pulitzer Prize-winning criticWilliam McPhersonas its first editor.It featured Pulitzer Prize-winning critics such asJonathan YardleyandMichael Dirda, the latter of whom established his career as a critic at thePost. In 2009, after 37 years, with great reader outcries and protest,The Washington Post Book Worldas a standalone insert was discontinued, the last issue being Sunday, February 15, 2009,along with a general reorganization of the paper, such as placing the Sunday editorials on the back page of the main front section rather than the \"Outlook\" section and distributing some other locally oriented \"op-ed\" letters and commentaries in other sections.However, book reviews are still published in the Outlook section on Sundays and in the Style section the rest of the week, as well as online. Donald E. Graham, Katharine's son, succeeded her as a publisher in 1979. In 1995, the domain name washingtonpost.com was purchased. That same year, a failed effort to create an online news repository called Digital Ink launched. The following year it was shut down and the first website was launched in June 1996. In August 2013,Jeff BezospurchasedThe Washington Postand other local publications, websites, and real estateforUS$250million,transferring ownership to Nash Holdings LLC, Bezos's private investment company.The paper's former parent company, which retained some other assets such as Kaplan and a group of TV stations, was renamedGraham Holdingsshortly after the sale. Nash Holdings, which includes thePost, is operated separately from technology companyAmazon, which Bezos founded and where he is as of 2022executive chairman and the largest single shareholder, with 12.7% of voting rights. Bezos said he has a vision that recreates \"the 'daily ritual' of reading thePostas a bundle, not merely a series of individual stories...\"He has been described as a \"hands-off owner\", holding teleconference calls with executive editorMartin Baronevery two weeks.Bezos appointedFred Ryan(founder and CEO ofPolitico) to serve as publisher and chief executive officer. This signaled Bezos' intent to shift thePostto a more digital focus with a national and global readership. In 2015, thePostmoved from the building it owned at 1150 15th Street to a leased space three blocks away at One Franklin Square onK Street.Since 2014 thePosthas launched an online personal finance section,a blog, and a podcast with a retro theme.ThePostwon the2020 Webby People's Voice Award for News & Politicsin the Social and Web categories. In 2017, the newspaper hiredJamal Khashoggias a columnist. In 2018, Khashoggi wasmurderedbySaudiagents in Istanbul. In October 2023, thePostannounced it would cut 240 jobs across the organization by offering voluntary separation packages to employees.In a staff-wide email announcing the job cuts, interim CEOPatty Stonesiferwrote, \"Our prior projections for traffic, subscriptions and advertising growth for the past two years — and into 2024 — have been overly optimistic\".ThePosthas lost around 500,000 subscribers since the end of 2020 and was set to lose $100 million in 2023, according toThe New York Times.The layoffs promptedDan FroomkinofPresswatchersto suggest that the decline in readership could be reversed by focusing on the rise of authoritarianism (in a fashion similar to the role thePostplayed during theWatergate scandal) instead of staying strictly neutral, which Froomkin says places the paper into an undistinguished secondary role in competition with other contemporary media.As part of the shift in tone, in 2023 the paper closed down the \"KidsPost\" column for children, the \"Skywatch\" astronomy column, and the \"John Kelly's Washington\" column about local history and sights, which had been running under different bylines since 1947. In May 2024, CEO and publisher William Lewis announced that the organization would embraceartificial intelligenceto improve the paper's financial situation, telling staff it would seek \"AI everywhere in our newsroom.\" In June 2024,Axiosreported thePostfaced significant internal turmoil and financial challenges. The new CEO, Lewis, has already generated controversy with his leadership style and proposed restructuring plans. The abrupt departure of executive editor Buzbee and the appointment of two white men to top editorial positions have sparked internal discontent, particularly given the lack of consideration for the Post's senior female editors, as well as allegations that in March 2024 Lewis put pressure on Buzbee to bury a story about his involvement in a British phone-hacking scandal. Additionally, Lewis' proposed division forsocial mediaandservice journalismhas met with resistance from staff. Recent reports alleging Lewis' attempts to influence editorial decisions, including pressuring Buzbee to drop a story about his past ties to aphone hackingscandal, and offeringNPR's media correspondent an exclusive interview about thePost's future in exchange for not publishing similar allegations, have further shaken the newsroom's morale.Staffers also became worried about Lewis' drinking and uninvolved role in the newsroom.Lewis continues to grapple with declining revenue and audience on the business front, seeking strategies to regain subscribers lost since the Trump era. Later that month, the paper ran a story allegedly exposing a connection between incoming editor Robert Winnett and John Ford, a man who \"admitted to an extensive career using deception and illegal means to obtain confidential information.\"Winnett withdrew from the position shortly thereafter. In January 2025, thePostannounced it will layoff 4% of its staff, less than 100 people. Newsroom employees will not be affected. In January 2025, editorial cartoonistAnn Telnaesresigned fromThe Washington Postand published a blog post titled \"Why I'm quitting the Washington Post\",in which she criticized the paper for allegedly refusing to run a cartoon critical of the relationship between American billionaires and PresidentDonald Trump, calling the decision \"dangerous for a free press\". Telnaes' blog post and the nature of her cartoon sparked conversations about the paper's ownership under Bezos. In February 2025, Bezos announced that the opinion section of thePostwould give voice only to opinions that support \"personal liberties andfree markets\" and divergent opinions would not be published by thePost.David Shipley,The Post's opinion editor, resigned after trying to persuade Bezos to reconsider the new direction.Within two days of the announcement, it was reported that over 75,000 digital subscribers had canceled their subscriptions.In March 2025, Ruth Marcus, columnist and editor forThe Washington Post's opinion section, resigned after 40 years with the organization when the paper's publisher, Will Lewis, killed a column she wrote that was critical of the new direction.ThePostalso fired columnistKaren Attiahin September 2025. In 1933, financier Eugene Meyer bought the bankruptPost, and assured the public that neither he nor the newspaper would be beholden to any political party.But as a leading Republican who had been appointed Chairman of the Federal Reserve byHerbert Hooverin 1930, his opposition toRoosevelt'sNew Dealcolored the paper's editorials and news coverage, includingeditorializingnews stories written by Meyer under a pseudonym.His wifeAgnes Ernst Meyerwas a journalist from the other end of the spectrum politically. ThePostran many of her pieces including tributes to her personal friendsJohn DeweyandSaul Alinsky. In 1946, Meyer was appointed head ofWorld Bank, and he named his son-in-law Phil Graham to succeed him asPostpublisher. The post-war years saw the developing friendship of Phil and Kay Graham with the Kennedys, the Bradlees and the rest of the \"GeorgetownSet\", including manyHarvard Universityalumnithat would color thePost'spolitical orientation.Kay Graham's most memorable Georgetown soirée guest list included British diplomat and communist spyDonald Maclean. ThePostis credited with coining the term \"McCarthyism\" in a 1950editorial cartoonbyHerbert Block.Depicting buckets of tar, it made fun of Sen.Joseph McCarthy's \"tarring\" tactics, i.e.,smear campaignsand character assassination against those targeted by his accusations. Sen. McCarthy was attempting to do for the Senate what theHouse Un-American Activities Committeehad been doing for years—investigatingSoviet espionage in America. TheHUACmade Richard Nixon nationally known for his role in theHiss/Chamberscase that exposed communist spying in theState Department. The committee had evolved from theMcCormack-DicksteinCommittee of the 1930s. Phil Graham's friendship withJohn F. Kennedyremained strong until their deaths in 1963.FBI DirectorJ. Edgar Hooverreportedly told the new PresidentLyndon B. Johnson, \"I don't have much influence with thePostbecause I frankly don't read it. I view it like theDaily Worker.\" Ben Bradlee became the editor-in-chief in 1968, and Kay Graham officially became the publisher in 1969, paving the way for the aggressive reporting of thePentagon Papersand Watergate scandals. ThePoststrengthened public opposition to the Vietnam War in 1971 when it published thePentagon Papers.In the mid-1970s, some conservatives referred to thePostas \"Pravdaon thePotomac\" because of its perceived left-wing bias in both reporting and editorials.Since then, the appellation has been used by both liberal and conservative critics of the newspaper. In thePBSdocumentaryBuying the War, journalistBill Moyerssaid in the year prior to theIraq Warthere were 27 editorials supporting theBush administration's desire to invade Iraq. National security correspondentWalter Pincusreported that he had been ordered to cease his reports that were critical of the administration.According to author and journalistGreg Mitchell: \"By thePost'sown admission, in the months before the war, it ran more than 140 stories on its front page promoting the war, while contrary information got lost\". On March 23, 2007,Chris Matthewssaid on his television program, \"The Washington Postis not the liberal newspaper it was [...] I have been reading it for years and it is aneoconnewspaper\".It has regularly published a mixture of op-ed columnists, with some of them left-leaning (includingE. J. Dionne,Dana Milbank, Greg Sargent, andEugene Robinson), and some of them right-leaning (includingGeorge Will,Marc Thiessen,Michael GersonandCharles Krauthammer). Responding to criticism of the newspaper's coverage during the run-up to the2008 presidential election, formerPostombudsmanDeborah Howellwrote: \"The opinion pages have strong conservative voices; the editorial board includes centrists and conservatives; and there were editorials critical of Obama. Yet opinion was still weighted toward Obama.\"According to a 2009Oxford University Pressbook by Richard Davis on the impact of blogs on American politics, liberal bloggers link toThe Washington PostandThe New York Timesmore often than other major newspapers; however, conservative bloggers also link predominantly to liberal newspapers. Since 2011, thePosthas been running a column called \"The Fact Checker\" that thePostdescribes as a \"truth squad\".The Fact Checker received a $250,000 grant fromGoogle News Initiative/YouTube to expand production of videofact checks. In mid-September 2016, Matthew Ingram ofForbesjoinedGlenn GreenwaldofThe Intercept, and Trevor Timm ofThe Guardianin criticizingThe Washington Postfor \"demanding that [former National Security Agency contractor Edward] Snowden ... stand trial on espionage charges\". In February 2017, thePostadopted the slogan \"Democracy Dies in Darkness\" for its masthead. In February 2025, Jeff Bezos announced that the paper's opinion pages would endorse \"personal liberties and free markets\" to the exclusion of other views. According to the NPR, the announcement suggested thePostwas adopting alibertarianline. In the vast majority of U.S. elections, for federal, state, and local office, thePosteditorial board has endorsedDemocraticcandidates.The paper's editorial board and endorsement decision-making are separate from newsroom operations.Until 1976, thePostdid not regularly make endorsements in presidential elections. Since it endorsedJimmy Carterin 1976, thePosthas endorsed Democrats in presidential elections, and has never endorsed a Republican for president in the general election,although in the1988 presidential election, thePostdeclined to endorse either GovernorMichael Dukakis(the Democratic candidate) or Vice PresidentGeorge H. W. Bush(the Republican candidate).ThePosteditorial board endorsedBarack Obamain 2008and 2012;Hillary Clintonin2016;andJoe Bidenin2020.In 2024, thePostcontroversially announced that it would no longer publish presidential endorsements. While the newspaper predominantly endorses Democrats in congressional, state, and local elections, it has occasionally endorsedRepublicancandidates.It endorsedMaryland GovernorRobert Ehrlich's unsuccessful bid for a second term in 2006.In 2006, it repeated its historic endorsements of every Republican incumbent for Congress inNorthern Virginia.ThePosteditorial board endorsedVirginia's Republican U.S. SenatorJohn Warnerin his Senate reelection campaign in 1990, 1996 and 2002; the paper's most recent endorsement of aMarylandRepublican for U.S. Senate was in the 1980s, when the paper endorsed SenatorCharlies \"Mac\" Mathias Jr.In U.S. House of Representatives elections,moderate RepublicansinVirginiaandMaryland, includingWayne Gilchrest,Thomas M. Davis, andFrank Wolf, have enjoyed the support of thePost; thePostalso endorsed RepublicanCarol Schwartzin her campaign in Washington, D.C. Eleven days prior to the2024 presidential election, CEO and publisher William Lewis announced that thePostwould not endorse a candidate for 2024. It was the first time since the 1988 presidential election that the paper did not endorse the Democratic candidate. Lewis also said that the paper would not make endorsements in any future presidential election. Lewis stated that the paper was \"returning to our roots\" of not endorsing candidates, and explained that the move was \"a statement in support of our readers' ability to make up their own minds\", and \"consistent with the values thePosthas always stood for and what we hope for in a leader: character and courage in service to the American ethic, veneration for the rule of law, and respect for human freedom in all its aspects.\" Sources familiar with the situation stated that thePosteditorial board had drafted an endorsement forKamala Harris, but that it had been blocked by order of thePost's owner Jeff Bezos. The move was criticized by former executive editor Martin Baron, who considered it \"disturbing spinelessness at an institution famed for courage\",and suggested that Bezos was fearing retaliation from 2024 Republican candidate Donald Trump that could impact Bezos's other businesses if Trump were elected.Editor-at-largeRobert Kaganand columnistMichele Norrisresigned in the wake of the decision, and editorDavid Maranisssaid that the paper was \"dying in darkness\", a reference to the paper's current slogan.Postopinion columnists jointly authored an article calling the decision to not endorse a \"terrible mistake\", and it was condemned by the Washington Post Guild, a union unit representingPostemployees.More than 250,000 people (about ten percent of thePost's subscribers) cancelled their subscriptions, and three members of the editorial board left the board, though they remain with thePostin other positions.An endorsement of Harris was subsequently published by the paper's humoristAlexandra Petri, who explained that \"if I were the paper, I would be a little embarrassed that it has fallen to me, the humor columnist, to make our presidential endorsement\", and that \"I only know what's happening because our actual journalists are out there reporting, knowing that their editors have their backs, that there's no one too powerful to report on, that we would never pull a punch out of fear.\" Condemning thePost's decision, several columnists, including Will Bunch,Jonathan Last, Dan Froomkin,Donna LaddandSewell Chan, described it as an example of what historianTimothy Snydercalls anticipatory obedience.Snyder himself criticized the decision, asserting that \"'do not obey in advance' is the main lesson of the twentieth century.\"Andrew Koppelman, in an opinion piece forThe Hill, praised thePostfor revealing its cowardice. In September 1980, a Sunday feature story appeared on the front page of thePosttitled \"Jimmy's World\" in which reporterJanet Cookewrote a profile of the life of an eight-year-old heroinaddict.Although some within thePostdoubted the story's veracity, the paper's editors defended it, and assistant managing editor Bob Woodward submitted the story to thePulitzer Prize BoardatColumbia Universityfor consideration.Cooke was awarded thePulitzer Prize for Feature Writingon April 13, 1981. The story was subsequently found to be a complete fabrication, and the Pulitzer was returned. In July 2009, in the midst of an intense debate overhealth care reform,Politicoreported that a health-care lobbyist had received an \"astonishing\" offer of access to thePost's \"health-care reporting and editorial staff\".PostpublisherKatharine Weymouthhad planned a series of exclusive dinner parties or \"salons\" at her private residence, to which she had invited prominent lobbyists, trade group members, politicians, and business people.Participants were to be charged $25,000 to sponsor a single salon, and $250,000 for 11 sessions, with the events being closed to the public and to the non-Postpress.Politico's revelation gained a somewhat mixed response in Washingtonas it gave the impression that the parties' sole purpose was to allow insiders to purchase face time withPoststaff. Almost immediately following the disclosure, Weymouth canceled the salons, saying, \"This should never have happened.\" White House counselGregory B. Craigreminded officials that underfederal ethics rules, they need advance approval for such events.PostExecutive EditorMarcus Brauchli, who was named on the flier as one of the salon's \"Hosts and Discussion Leaders\", said he was \"appalled\" by the plan, adding, \"It suggests that access toWashington Postjournalists was available for purchase.\" Dating back to 2011,The Washington Postbegan to include \"China Watch\" advertising supplements provided byChina Daily, an English language newspaper owned by thePublicity Department of the Chinese Communist Party, on the print and online editions. Although the header to the online \"China Watch\" section included the text \"A Paid Supplement to The Washington Post\",James FallowsofThe Atlanticsuggested that the notice was not clear enough for most readers to see.Distributed to thePostand multiple newspapers around the world, the \"China Watch\" advertising supplements range from four to eight pages and appear at least monthly. According to a 2018 report byThe Guardian, \"China Watch\" uses \"a didactic, old-school approach to propaganda.\" In 2020, a report byFreedom House, titled \"Beijing's Global Megaphone\", criticized thePostand other newspapers for distributing \"China Watch\".In the same year, 35 Republican members of the U.S. Congress wrote a letter to the U.S. Department of Justice in February 2020 calling for an investigation of potentialFARAviolations byChina Daily.The letter named an article that appeared in thePost, \"Education Flaws Linked to Hong Kong Unrest\", as an example of \"articles [that] serve as cover for China's atrocities, including ... its support for thecrackdown in Hong Kong.\"According toThe Guardian,thePosthad already stopped running \"China Watch\" in 2019. In March 2022, reporter Paul Farhi was suspended for five days without pay after he tweeted about the publication's policy on bylines and datelines regarding Russian-based stories. In 2020,The Postsuspended reporterFelicia Sonmezafter she posted a series of tweets about the2003 rape allegation against basketball star Kobe BryantafterBryant's death. She was reinstated after over 200Postjournalists wrote an open letter criticizing the paper's decision.In July 2021, Sonmez suedThe Postand several of its top editors, alleging workplace discrimination; the suit was dismissed in March 2022, with the court determining that Sonmez had failed to make plausible claims. In June 2022, Sonmez engaged in a Twitter feud with fellowPoststaffersDavid Weigel, criticizing him over what he later described as \"an offensive joke\", and Jose A. Del Real, who accused Sonmez of \"engaging in repeated and targeted public harassment of a colleague\".Following the feud, the newspaper suspended Weigel for a month for violating the company's social media guidelines, and the newspaper's executive editorSally Buzbeesent out a newsroom-wide memorandum directing employees to \"Be constructive and collegial\" in their interactions with colleagues.The newspaper fired Sonmez, writing in an emailed termination letter that she had engaged in \"misconduct that includes insubordination, maligning your co-workers online and violatingThe Post's standards on workplace collegiality and inclusivity.\"The Postfaced criticism from the Post Guild after refusing to go to arbitration over the dismissal, stating that the expiration of the Post's contract \"does not relieve the Post from its contractual obligation to arbitrate grievances filed prior to expiration.\" In 2019,Covington Catholic High Schoolstudent Nick Sandmann filed a defamation lawsuit against thePost, alleging that it libeled him in seven articles regarding theJanuary 2019 Lincoln Memorial confrontationbetween Covington students and theIndigenous Peoples March.A federal judge dismissed the case, ruling that 30 of the 33 statements in thePostthat Sandmann alleged were libelous were not, but allowed Sandmann to file an amended complaint as to three statements.After Sandmann's lawyers amended the complaint, the suit was reopened on October 28, 2019. In 2020,The Postsettled the lawsuit brought by Sandmann for an undisclosed amount. SeveralWashington Postop-edsand columns have prompted criticism, including a number of comments on race by columnistRichard Cohenover the years,and a controversial 2014 column oncampus sexual assaultby George Will. ThePost's decision to run an op-ed byMohammed Ali al-Houthi, a leader inYemen'sHouthi movement, was criticized by some activists on the basis that it provided a platform to an \"anti-Western andantisemiticgroup supported by Iran.\" The headline of a 2020 op-ed titled \"It's time to give the elites a bigger say in choosing the president\" was changed, without an editor's note, after backlash. In 2022, actorJohnny Deppsuccessfully sued ex-wifeAmber Heardfor an op-ed she wrote inThe Washington Postwhere she described herself as a public figure representing domestic abuse two years after she had publicly accused him of domestic violence. Speaking on behalf of President Nixon, White House Press SecretaryRon Zieglerinfamously accusedThe Washington Postof \"shabby journalism\" for their focus onWatergateonly to apologize when the damning reporting on Nixon was proved correct. 45th/47th president Donald Trump repeatedly spoke out againstThe Washington Postonhis Twitter account,having \"tweeted or retweeted criticism of the paper, tying it to Amazon more than 20 times since his campaign for president\" by August 2018.In addition to often attacking the paper itself, Trump used Twitter to blast variousPostjournalists and columnists. During the2020 Democratic Party presidential primaries, SenatorBernie Sandersrepeatedly criticizedThe Washington Post, saying that its coverage of his campaign was slanted against him and attributing this to Jeff Bezos' purchase of the newspaper.Sanders' criticism was echoed by the socialist magazineJacobinand the progressive journalist watchdogFairness and Accuracy in Reporting.Washington Postexecutive editor Martin Baron responded by saying that Sanders' criticism was \"baseless and conspiratorial\". An investigation byThe Intercept,The Nation, andDeSmogfound thatThe Washington Postis one of the leading media outlets that publishes advertising for thefossil fuelindustry.Journalists who coverclimate changeforThe Washington Postare concerned thatconflicts of interestwith the companies and industries thatcaused climate changeandobstructed actionwill reduce the credibility of their reporting on climate change and cause readers to downplay theclimate crisis. Major stockholders Publishers Executive editors Current journalists atThe Washington Postinclude:Yasmeen Abutaleb,Dan Balz,Will Englund,Marc Fisher,Robin Givhan,David Ignatius,Ellen Nakashima,Ashley Parker,Sally Quinn,Michelle Singletary,Ishaan Tharoor, andJoe Yonan. Former journalists ofThe Washington Postinclude:Scott Armstrong,Melissa Bell,Ann Devroy,Edward T. Folliard,Malvina Lindsay,Mary McGrory,Christine Emba, Walter Pincus, and Bob Woodward. Arc XP is a department ofThe Washington Post, which provides a publishing system and software for news organizations such as theChicago Tribuneand theLos Angeles Times. In 1975,the Washington Post pressmen's union went on strike. ThePosthiredreplacement workersto replace the pressmen's union, and other unions returned to work in February 1976. In 1986, during negotiations between thePostand the Newspaper Guild union over a new contract, five employees, including Newspaper Guild unit chairman Thomas R. Sherwood and assistant Maryland editorClaudia Levy, sued thePostfor overtime pay, stating that the newspaper had claimed that budgets did not allow for overtime wages. In June 2018, over 400 employees ofThe Washington Postsigned an open letter to the owner Jeff Bezos demanding \"fair wages; fair benefits for retirement, family leave and health care; and a fair amount of job security.\" The open letter was accompanied by video testimonials from employees, who alleged \"shocking pay practices\" despite record growth in subscriptions at the newspaper, with salaries rising an average of $10 per week, which the letter claimed was less than half the rate of inflation. The petition followed on a year of unsuccessful negotiations between The Washington Post Guild and upper management over pay and benefit increases. As of 2023, the Washington Post Guild represented around 1,000 staff members at thePost.In December 2023, more than 750 journalist and staffers at thePostwent on strike, accusing the company of refusing to \"bargain in good faith\" on issues including issues including pay increases, pay equity, remote work policies, and mental health resources.Later the same month, the Washington Post Guild won a new three-year contract with the paper, ending 18 months of negotiations. In May 2025, a majority of technology workers at thePostvoted to unionize as the Washington Post Tech Guild, representing more than 300 engineering, product design, and data workers at thePost.", "metadata": {"url": "https://en.wikipedia.org/wiki/Washington_Post", "title": "The Washington Post", "headings": ["Contents", "Overview", "History", "19th century", "20th century", "Jeff Bezos era (since 2013)", "Political positions", "20th century", "21st century", "Criticism and controversies", "\"Jimmy's World\" fabrication", "Private \"salon\" solicitation", "China Dailyadvertising supplements", "Employee relations", "Lawsuit by Covington Catholic High School student", "Controversial op-eds and columns", "Criticism by elected officials", "Fossil fuel advertising", "Organization", "Executive officers and editors", "Journalists", "Publishing service", "Unions", "See also", "References", "Further reading", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/The_Washington_Post", "https://en.wikipedia.org/wiki/The_Washington_Post", "https://en.wikipedia.org/wiki/The_Washington_Post", "https://en.wikipedia.org/wiki/WAPO_(disambiguation)", "https://en.wikipedia.org/wiki/Washington_Post_(disambiguation)", "https://en.wikipedia.org/wiki/The_Washington_Times", "https://en.wikipedia.org/wiki/Democracy_Dies_in_Darkness", "https://en.wikipedia.org/wiki/Daily_newspaper"]}},
{"id": "ebf0ba562058", "content": " The Working Manis a 1933pre-CodeAmerican comedy film starring George Arliss andBette Davis,  and directed byJohn G. Adolfi. The screenplay by Charles Kenyon and Maude T. Howell is based on the storyThe Adopted Fatherby Edgar Franklin. The film is preserved in the Library of Congress collection. Successful shoe manufacturer John Reeves is annoyed with his staff, particularly his conceited nephew and company general manager Benjamin Burnett (who considers himself the driving force behind the firm), because they are losing ground to their longtime chief rival, headed by former best friend Tom Hartland. The two men had had a falling out after falling in love with the same woman; she married Hartland, and Reeves remained a bachelor. Nevertheless, Reeves is saddened to learn of Hartland's death. When Benjamin begins to muse that his uncle has started down the road to senility, Reeves decides to teach him a lesson. He heads off on a fishing vacation in Maine, leaving his nephew to deal with the business situation by himself. By chance, a large yacht moors near his fishing boat. When Jenny and Tommy Hartland, the party-loving offspring and heirs of Tom Hartland, swim over to see if anyone can supply them with liquor, Reeves is a little disgusted with their idle ways. Hiding his identity and calling himself John Walton, he befriends them in order to do a little spying on their company. However, as he gets to know them better, he begins to like them. They take him along with them back to New York, as they are responsible for a minor injury he suffers. \"Walton\" gets them to take him on a tour of their plant, which he discovers is being deliberately mismanaged by Fred Pettison. He figures out that Pettison is driving it into bankruptcy so he can buy it cheaply later. Using a gambit, Reeves persuades Tommy to have him appointed a trustee of the Hartland estate. Tommy and Jenny expect him to do away with the restraints imposed upon them. When two other trustees express their concern about the fisherman's qualifications, Reeves reveals his identity and the fact that he has grown fond of the young people who, if things had turned out differently, could have been his own children. Once Reeves becomes a trustee, he starts making wholesale changes on both the domestic and business sides of life. He quickly discharges most of the household servants, as the estate is nearly depleted, forcing Jenny and Tommy to mature quickly. Pettison is fired. Tommy begins working at his own company, while his sister, anxious to find out why their shoes are less popular than those manufactured by Reeves, takes a filing job with the rival company under the alias Jane Grey. She finds herself attracted to Benjamin. When Benjamin summons her to his office to fire her for her total lack of business skills, he finds her very appealing. Upon learning the news, she starts crying, and Benjamin reconsiders his decision. In the end, he reassigns her to work in his private office. Meanwhile, Reeves has revitalized the Hartland Shoe Company, and it start making serious inroads into Reeves Company territory. Benjamin is puzzled, as the methods used by Hartland seem strikingly similar to those employed by Reeves. When Pettison shows up in Benjamin's office looking for a job, he sees Jane. She begs him to keep her secret, but he tells Benjamin who she really is and lies, accusing her ofspying on the Reeves company. This ends their budding romance. In the end, Benjamin insists on meeting \"John Walton\", and Reeves has to reveal his true identity to the Hartlands. Once they get over the shock, and Reeves informs his nephew that Jenny was not a spy, the young couple reconcile. All agree to Reeves' proposal that the two companies merge. TheWarner Bros.release marked the second pairing ofGeorge ArlissandBette Davis, who co-starred inThe Man Who Played Godthe year before. The film had its world premiere atRadio City Music Hallin New York City. It was a remake of an Arliss silent film,Twenty Dollars a Week, filmed in 1924. The 193620th Century FoxfilmEverybody's Old Manwas based on the same source. In his review inThe New York Times, Mordaunt Hall described the film as \"breezy but somewhat shallow\" and added \"George Arliss offers an ingratiating charactier study in a role that suits him...Quite a number of [his] lines are humorous and there is no denying that the actor uses them most effectively. Bette Davis, whose diction is music to the ears, does good work in the role of Jenny.\" TV Guidecalled it \"a thoroughly enjoyable piece of entertainment which serves no other purpose than to put a smile on your face.\" According to Warner Bros. records, the film earned $401,000 domestically and $421,000 foreign.", "metadata": {"url": "https://en.wikipedia.org/wiki/The_Working_Man", "title": "The Working Man", "headings": ["Contents", "Plot", "Cast", "Production notes", "Principal production credits", "Reception", "Box office", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/The_Working_Man", "https://en.wikipedia.org/wiki/The_Working_Man", "https://en.wikipedia.org/wiki/The_Working_Man", "https://en.wikipedia.org/wiki/Working_Man_(disambiguation)", "https://en.wikipedia.org/wiki/John_G._Adolfi", "https://en.wikipedia.org/wiki/Charles_Kenyon", "https://en.wikipedia.org/wiki/Maude_T._Howell", "https://en.wikipedia.org/wiki/All-Story_Weekly"]}},
{"id": "dc01f6c3305c", "content": " Getty Images Holdings, Inc.(stylized asgettyimages) is avisual mediacompany and supplier ofstock images,editorialphotography, video, and music for business and consumers, with a library of over 477 million assets. It targets three markets—creative professionals(advertising and graphic design), themedia(print and online publishing), andcorporate(in-house design, marketing and communication departments). Getty Images has distribution offices around the world and capitalizes on the Internet for distribution with over 2.3 billion searches annually on its sites. As Getty Images has acquired other older photo agencies and archives, it hasdigitizedtheir collections, enabling online distribution. Getty Images operates a largecommercial websitethat clients use to search and browse for images, purchase usage rights, and download images. Image prices vary according toresolutionand type of rights. The company also offers custom photo services for corporate clients. In January 2025, it was announced that the company would be merging withShutterstock. In 1995,Mark Gettyand chief executive officerJonathan Kleinco-founded Getty Investments LLC in London.Mark Getty is the company's chairman. In September 1997, Getty Communications, as it was called at the time, merged withPhotoDisc, Inc.to form Getty Images. The company relocated to Seattle two years later and expanded in the United States, reaching 2,000 employees by 2006.In April 2003, Getty Images entered into a partnership withAgence France-Presse(AFP) to market each other's images. Getty Images acquired theMichael Ochs Archivesin February 2007.The Michael Ochs Archives were described byThe New York Timesas \"the premier source of musician photography in the world\". In 2008, the private equity firmHellman & Friedman(H&F) acquired Getty Images for $2.4 billion.In 2012, H&F put Getty up for sale.As of the ensuing sale toCarlyle Group, the company was said to have an archive that included 80 million stills and illustrations.The company was acquired by the Getty family in 2018. The company moved to its current headquarters, in theUnion Stationoffice complex in Seattle'sInternational District, in 2011. In 2015,Jonathan Kleinbecame the company's chairman andDawn Aireywas hired aschief executive officer(CEO) of Getty Images.Airey remained in the role until 31 December 2018, at which time she became a non-executive director member of its board and Craig Peters was appointed CEO. In 2019, Getty Images introduced Market Freeze, simplifying exclusivity of rights-managed images.Later that year, it announced that due to customers' changing needs, it plans to phase out rights-managed imagery by 2020 in favor of royalty-free images. In December 2021, Getty Images announced its intention to become publicly traded once more through combination with CC Neuberger Principal Holdings II. In July 2022, theSPACmerger was completed and the newly formed parent company of Getty Images went public on theNew York Stock Exchangeunder the symbol GETY. Activist investorTrillium Capital made an unsolicited bid to acquire Getty forUS$4billion in April 2023 – representing nearly a 100 percent premium.Getty turned down the offer questioning its credibility. In September 2023, Getty announced that it was partnering withNvidiato launch Generative AI by Getty Images, a new tool that lets people create images using Getty's library of licensed photos. Getty will use Nvidia's Edify model, which is available on Nvidia's generative AI model library Picasso.Their stock footage is used inBaby EinsteinandLittle Einsteins. In January 2025, it was announced that the company would be merging withShutterstock.The UK'sCompetition and Markets Authoritylaunched an investigation into the proposed merger in August 2025. Since its formation, Getty Images has pursued an aggressive programme ofacquisition, buying up many privately owned agencies that had built up the stock photography industry, from small family-run firms to larger agencies. By 1999, it had acquired one of the largest agencies, Tony Stone Images; the online art seller Art.com; the sports photography agencyAllsport; the market leader in the Benelux and Scandinavia:Word View(1996, from Bert Blokhuis, four offices, for undisclosed sum); journalistic specialists Liaison Agency; Newsmakers, the first digital news photo agency; Online USA, a specialist in celebrity shots; and theHulton Press Library, the former archive of the British photojournalistic magazinePicture Post. The Hulton collection was sold by theBBCtoBrian Deutschin 1988, when it was renamed Hulton Deutsch. In 1996, the Hulton collection was sold on once more, this time purchased by Getty Images and renamed Hulton Getty. With the acquisition of the Hulton library, Getty Images took ownership of the rights to some 15 million photographs from British press archives dating back to the nineteenth century. Hulton Getty also included photographs from theKeystone Collection, as well as images by notable photographers such asBert Hardy,Bill Brandt,WeegeeandErnst Haas. Getty has branched out into stock audio, music and sound effects, and also video with the acquisition of EyeWire and Energy Film Library.Getty has partnered with other companies includingSlidelyfor companies and advertisers to use the Getty Images video library of around 2 million videos. In 2000, Getty acquired one of its main competitors, Archive Photos of New York (a division of The Image Bank), for US$183 million.The Archive Photos library was combined with the Hulton Getty collection to form a new subsidiary, Hulton Archive. Archive Photos was formed in 1990 from the merger of Pictorial Parade (est. 1935) and Frederick Lewis Stock Photos (est. 1938), two well-established US photo agencies. Their collections included archive images fromThe New York Times,MetronomeandGeorge Eastman House, and works by photographers such asRuth Orkin,Anacleto Rapping, Deborah Feingold, Murray Garrett,Nat FeinandJohn Filo. Further acquisitions followed, with the purchase in 2004 of image.net for US$20 million.On 9 February 2006, themicrostockphoto websiteiStockphotowas acquired by Getty Images for US$50 million.In 2007, Getty successfully purchased its largest competitor, MediaVast, for $207 million. The acquisition gave Getty Images control of WireImage (Entertainment, creative, and sports photography), FilmMagic (fashion and red carpet photography), and Contour Photos (portrait and studio photography). Getty Images also acquired other subsidiaries, including Master Delegates, which includes Isifa Image Service inPragueand Laura Ronchi in Italy.In 2008, Getty purchased Redferns Music Picture Library, the music photo library built up by British jazz photographerDavid Redfern. On 23 October 2008, Getty Images announced their intention to buyJupitermedia's online images division, Jupiterimages, for $96 million in cash.The sale went ahead in February 2009; Jupiterimages (including the sitesstock.xchngandStockXpert) is now a wholly owned subsidiary of Getty. Jupitermedia, now trading asWebMediaBrands, continues its Internet publishing business, which they didn't sell to Getty Images. On 25 January 2016,Corbisannounced that it had sold its image licensing business, including the Corbis Images, Corbis Motion and Veer libraries and their associated assets, to Unity Glory, an affiliate ofVisual China Group—Getty's exclusive distributor in China. Concurrently, it was announced that VCG would, after a transition period, license distribution and marketing of the Corbis library outside of China to Getty. Getty now manages Corbis's physical archives on behalf of VCG and Unity Glory. In March 2021, Getty Images acquiredUnsplash, a free-to-use stock photography website, for an undisclosed sum. In February 2008, it was announced that Getty Images would be acquired by the private equity firmHellman & Friedmanin a transaction valued at an estimated US$2.4 billion.On 2 July 2008, Getty Images announced the completion of its acquisition.  Getty Images common stock ceased trading on theNew York Stock Exchangeat the close of the acquisition and was delisted from the NYSE. In 2012, H&F engaged investment bankers to sell the company. While a price of $4 billion was initially discussed, in August when the private equity firm Carlyle Group emerged as the likely acquirer, the price under consideration was said to be $3.3–3.4 billion.CVC Capital PartnersLtd. was also said to have been bidding but had yet to top Carlyle's price.The sale to Carlyle thereafter was announced at $3.3 billion, with co-founders Getty and Klein and the Getty family all carrying their investments over into the new ownership structure. Getty continues to serve as chairman and Klein as chief executive. In September 2018, the Getty family announced it would acquire majority stake in the company fromThe Carlyle Group.In July 2022, the company went public again. The Getty Images Gallery was located at 46Eastcastle Street, London. In 2008, it hosted an exhibition of children forBarnardo'schild adoption agency, in an exhibition called \"Home Time\", aimed at helping to find homes for hundreds of children waiting for adoption. It included photographs by celebrity photographerCambridge Jones, as well as byCherie Blair,Bruce Oldfield,Andrew Lincoln,Gail Porter, andClaudia Winkleman. The gallery permanently closed in January 2019. Beginning in 2008, Getty Images has been the subject of controversy for its methods of pursuing copyright enforcement on behalf of its photographers. Rather than pursue a policy of sending \"cease and desist\" notices, Getty typically mails ademand letterthat claims substantial monetary damages from owners of websites it believes infringed on their photographers' copyrights. Getty commonly tries to intimidate website owners by sending collection agents, even though a demand letter does not create a debt. One photographer noted, \"Courts don't like to be used as a means of extortion.\"  In one case, Getty sent a church inLichfield,Staffordshire, a £6,000 bill for photographs it used on its website, apparently placed there by a church volunteer.  In this case, the church offered to pay Getty what it thought was a reasonable amount. Thediocese's communications director said: Getty was not playing ball or following the normal litigation ordispute resolutionprocedures and [I advised the church] to ignore them. We don't deal with bullies; we deal withlegal threatsappropriately. I told [Getty] by letter that's what [the church was] doing, that we were not going to play, and didn't hear any more. The Guardiandescribed other instances in which Getty or other stock photo businesses dropped a claim when a website owner refused to pay and hired a lawyer.  A law firm was quoted as saying: \"Once we get involved generally Getty does back off.\" In 2009, Oscar Michelen, a New York attorney who focuses on such damages claims, said: \"The damages they're requesting aren't equal to the copyright infringement,\" and \"there's no law that says definitively what images are worth in the digital age.\"He called Getty's effort to assess four-figure fines \"a legalized form of extortion\". In an effort to combat online copyright infringement, in March 2014 Getty Images made over 35 million images available free for non-commercial online use via embedding withattributionand a link back to the Getty Images website.According to Getty Images executive Craig Peters, \"The principle is to turn what's infringing use with good intentions, turning that into something that's valid licensed use with some benefits going back to the photographer\". On 15 February 2018,Google Images' interface was modified in order to meet the terms of a settlement and licensing partnership with Getty. The \"View image\" button (adeep linkto the image itself on its source server) was removed from image thumbnails. This change is intended to discourage users from directly viewing the full-sized image (although doing so using a browser's context menu on the embedded thumbnail is not frustrated), and encourage them to view the image in its appropriate context (which may also include attribution and copyright information) on its respective web page. The \"Search by image\" button has also been downplayed, asreverse image searchcan be used to find higher-resolution copies of copyrighted images. Google also agreed to make the copyright disclaimer within the interface more prominent. In 2009, Car-Freshner Corp., makers ofLittle Trees, filed a lawsuit against Getty Images inU.S. Federal Court, Northern District New York (Case 7:09-cv-01252-GTS -GHL).Car-Freshner claimed that Getty Images had in its catalog photos that included the famous \"tree-shaped\" trademarked car fresheners.  In 2011, Getty Images attempted to have the case dismissed, but its motion was denied.In 2012, Getty Images agreed to settle by paying $100,000 to Car-Freshener Corp., but admitted no wrongdoing. In September 2013, Avril Nolan brought a $450,000 suit against Getty Images. Nolan alleged that Getty Images improperly let her image be used in advertisements that depicted her as HIV-positive. She claimed the ad's depiction of her as HIV-positive (she is not) hurt her personal and professional relationships and caused her emotional distress.In March 2014 a judge ruled the lawsuit will be taken to court rather than dismissed.Getty Images settled with Nolan in January 2015. In November 2013, Getty andAgence France-Pressewere ordered to pay $1.2 million compensation to freelance photojournalist Daniel Morel for using his images posted onTwitterrelated to the2010 Haiti earthquakewithout his permission, in violation of copyright and Twitter's terms of service. In July 2016, Getty was sued, unsuccessfully,for over $1 billion byCarol Highsmith, an American photographer notable for donating her 100,000+ image collection, royalty-free, to theLibrary of Congress, when Highsmith found that Getty had been selling unauthorized licenses of her work (an instance ofcopyfraud).Highsmith found out about this when she received a letter from a law firm representing Getty, demanding $120 for displaying her pictures on a personal website of hers. In August 2016,Zuma Press, an independent press agency, filed suit against Getty for alleged copyright violations and unauthorized licensing of more than 47,000 images. Getty Images has continued the practice that Corbis (whose license it acquired in 2016) has been criticized for of claiming copyright, watermarking and selling images that are in public domain, including images related to The Holocaust like theWarsaw Ghetto boyphoto,thePolish cavalry in Sochaczew photograph,or images created byNASA.Getty has also tried to collect fees from photographers for use of their own images that they had previously put in the public domain. Public-domain photos from historical photographers such asDorothea LangeandWalker Evanshave long been available for unrestricted downloading from the United StatesLibrary of Congress.  The exact same images are also available from Getty Images, subject to a licensing fee of up to $5,000 for a six-month term.According toJason Mazzone[fr], a lawyer for theAuthors Alliance, these practices demonstrate an example ofcopyfraud. On January 17, 2023, Getty Images said it was suingStability AIover the use of Getty's images to trainAI artgenerator Stable Diffusion and for imitating the Getty Images' trademark.Getty released its own AI image generator trained on its library of licensed stock images in September 2023.", "metadata": {"url": "https://en.wikipedia.org/wiki/Gettyimages.com", "title": "Getty Images", "headings": ["Contents", "History", "Acquisitions", "Corporate ownership and management", "Gallery", "Copyright enforcement and controversy", "Copyright infringement lawsuits", "Claiming copyright over public domain content", "Controversy over AI-generated art", "See also", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Getty_Images", "https://en.wikipedia.org/wiki/Getty_Images", "https://en.wikipedia.org/wiki/Getty_Images", "https://en.wikipedia.org/wiki/Wirephoto", "https://en.wikipedia.org/wiki/Wire_data", "https://en.wikipedia.org/wiki/Public_company", "https://en.wikipedia.org/wiki/Ticker_symbol", "https://en.wikipedia.org/wiki/New_York_Stock_Exchange"]}},
{"id": "80f657db2b67", "content": "TheYaskawa Electric Corporation(株式会社安川電機,Kabushiki-gaisha Yasukawa Denki)is a Japanese manufacturer ofservos,motion controllers,AC motor drives,switchesandindustrial robots. TheirMotomanrobots are heavy duty industrial robots used in welding, packaging, assembly, coating, cutting, material handling and general automation. The company was founded in 1915, and its head office is located inKitakyushu,Fukuoka Prefecture.\nYaskawa applied for a trademark on the term \"Mechatronics\" in 1969, it was approved in 1972.The head-office, in Kitakyushu, was designed by the American architectAntonin Raymondin 1954. The company is listed on theTokyoandFukuoka Stock Exchangeand is a constituent of theNikkei 225stock index. YASKAWA has business hubs in 29 countries around the world and with production bases in 12 countries including Japan. There are 81subsidiariesand 24affiliatecompanies across the globe.Some of these are:  This article about a Japanese corporation- or company-related topic is astub. You can help Wikipedia byexpanding it. This article about a technological corporation or company is astub. You can help Wikipedia byexpanding it.", "metadata": {"url": "https://en.wikipedia.org/wiki/YE-Data", "title": "Yaskawa Electric Corporation", "headings": ["Contents", "Products and Services", "Subsidiaries", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Yaskawa_Electric_Corporation", "https://en.wikipedia.org/wiki/Yaskawa_Electric_Corporation", "https://en.wikipedia.org/wiki/Yaskawa_Electric_Corporation", "https://en.wikipedia.org/wiki/Romanization", "https://en.wikipedia.org/wiki/Public_company", "https://en.wikipedia.org/wiki/Kabushiki_gaisha", "https://en.wikipedia.org/wiki/Ticker_symbol", "https://en.wikipedia.org/wiki/Tokyo_Stock_Exchange"]}},
{"id": "04ee125f0c8c", "content": "Xebec Corporation, formerlyMicrocomputer Systems Corporation, was an American computer hardware company active from 1969 to 1990. The company was primarily known for their data storage products, especially theirhard disk controllerICs. A major customer of Xebec wasIBM, who used their disk controllers extensively in thePC XTin 1983, their first PC with ahard drivepreinstalled. Xebec took root in two separate companies based inSilicon Valley: Xebec Corporation, founded in 1969 inSunnyvale,California, and Microcomputer Systems Corporation (MSC), founded in 1974 by James \"Jim\" Toreson inSanta Clara, California.Xebec was a diversified computer company that manufactured a variety of hardware, including handwrittenOCRsystems and disk controllers,while MSC was dedicated tomainframeandminicomputerdisk controllers from the outset.In 1976, Microcomputer Systems moved to Sunnyvale from Santa Clara, occupying a 12,000-square-foot facility in the city; the company employed 20 people by that point.In July 1981, MSC acquired Xebec, which had been faltering in the marketplace and was on the brink of bankruptcy.Xebec then became a division of MSC, manufacturing the company'shard disk drivesand disk controller boards based on MSC's patents.MSC had all but discarded Xebec's prior disk controller technology, Toreson denouncing them as \"junk\" in a 1982 interview: \"Their company had several million dollars of venture capital poured into it, and we had none in ours, but we ultimately took them over with our technology\". In 1982, Xebec (under the auspices of MSC) introduced their first 5.25-inch hard drives and disk controllers for theApple IIat an uproarious booth showing at 1982'sWest Coast Computer Faire.These microcomputer-oriented products were a market success and led to Xebec moving their manufacturing presence intoGardnerville,Nevadain March 1983.(The move to Gardnerville was also partially fueled by concerns of industrial espionage, according to Toreson.) In February 1983, MSC filed to go public and changed its legal name to Xebec Corporation, adopting the name of its most successful subsidiary.Following theIPO, Xebec absorbed their eponymous subsidiary into their primary operations and cemented its focus on disk drive technologies. By mid-1983, Xebec counted among its customer base such large computer companies asHewlett-Packard,Philips Data,Texas Instruments, andVictor Technology.That same year, the company gained its largest customer yet inIBM,who signed a contract with Xebec worth US$200 million for Xebec's 1210 controllerICfor use in IBM's upcomingPC XT—their firstPersonal Computersystem with ahard drivepreinstalled.When Xebec posted revenues of $57 million in 1983, at least a quarter of that figure was suspected to have been earned from the IBM deal. The company gained further clients inITT,Mitsubishi, andToshibafollowing the deal. The IBM deal was initially a success story for Xebec,with employment at the company peaking at 1,200 in 1984.The deal worried Xebec's investors, however, who feared that IBM purchasing another company's controllers or even developing their own in-house controllers would cripple Xebec's revenues.Indeed, in 1984, IBM turned to other companies for their next generation of PC—thePC AT.Although IBM continued to source disk controllers from Xebec for the still-best-selling IBM PC XT, this nonetheless dealt a blow to Xebec's bottom line, and their financial situation suffered in the succeeding years.In an attempt to correct course by innovating, Xebec in late 1984 introduced the first hard drive built in the United States with the controller ICs soldered onto the drive's circuit board.Dubbed the Owl series, development of these drives required Xebec invest tens of millions of dollars in automation and robotics at their plants in Nevada andLehigh Valleyin easternPennsylvania.Xebec was one of the few companies in the United States sourcing their ICs entirely from companies in the United States; the majority of their competitors at the time were sourcing such ICs from East Asia. In October 1984, Xebec launched a subsidiary namedFirst Class Peripherals, which marketedHDDsubsystems for theApple II, theMacintosh, and the IBM PC andcompatiblesbymail order. Initially based inBethlehem, Pennsylvania,First Class later relocated toCarson City, Nevada, to be closer to Xebec, which had moved to that city by 1985.In 1987, Xebec launched several more subsidiaries, including Epelo, which marketed Xebec's advanced disk controllers, and OMNI-Shore, which was Xebec'scontract manufacturingarm. In 1985, after further losses, Xebec consolidated two under-performing subsidiaries (Information Memories Corporation and Dastek) and shuttered their Lehigh Valley plant.Xebec suffered heavy losses in 1987, after IBM announced both the discontinuation of the PC XT and the introduction of theirPersonal System/2series of personal computers—with disk controllers based on IBM's own silicon.Despite struggling, Xebec continued to supply controllers, disk drives, and tape backup systems for the following three years.In one of their last business dealings, in early 1988, Xebec sold off the patents to theirtape drivetechnologies to Epelo, which had been spun off from Xebec.Xebec dissolved on July 31, 1989, after it filed forChapter 7 bankruptcy.Following Xebec's collapse, Toreson spun off First Class Peripherals into a separate company, which traded asFirst Class Systemsand producedclonesofIBM'sPS/2. First Class Systems itself dissolved in 1990 after only a year in operation.", "metadata": {"url": "https://en.wikipedia.org/wiki/Xebec_Corporation", "title": "Xebec Corporation", "headings": ["Contents", "History", "Foundation (1969–1983)", "Growth and decline (1983–1990)", "References"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Xebec_Corporation", "https://en.wikipedia.org/wiki/Xebec_Corporation", "https://en.wikipedia.org/wiki/Xebec_Corporation", "https://en.wikipedia.org/wiki/Xebec_(studio)", "https://en.wikipedia.org/wiki/Xedex", "https://en.wikipedia.org/wiki/Sunnyvale,_California", "https://en.wikipedia.org/wiki/Division_(business)", "https://en.wikipedia.org/wiki/First_Class_Peripherals"]}},
{"id": "dab6a7cd17dc", "content": "Proto-KarenicorProto-Karenis thereconstructed ancestorof theKarenic languages. The foundation of the reconstruction of Proto-Karen was laid byAndré-Georges Haudricourtin 1946, with revisions in 1953 and 1975.\nHaudricourt applied thecomparative methodto forms from two Karen languages,PwoandSgaw, fromA Comparative Dictionary of the Pwo-Karen Dialect(1922) by W. C. B. Purser and Saya Tun Aung.\nEach of these languages has sixtones, four in open syllables and two in checked syllables (those ending in a glottal stop).\nBy comparing the lexical incidence of these tones, Haudricourt established eight correspondence sets, later labelled I to VIII byGordon Luce, six in open syllables and two in checked syllables.\nThe two languages had similar inventories of initial consonants, distinguishingaspirated, unaspirated andimplosivestops and having only voiced sonorants.\nImplosives and sonorants were aligned between the two languages, but aspirated and unaspirated stops yielded three correspondence sets.\nMoreover, the initial correspondence sets occurred only with certain tone correspondence sets, as follows: This fits a common pattern in languages of theMainland Southeast Asia linguistic area, includingTai languages,Hmong-Mien languages,Vietnameseandvarieties of Chinese, in which a four-tone system, reflecting earlier final segments, develops a register distinction conditioned by the manner of the initial, leading to a tone split.\nThe varying treatment of the first tone is also found in Tai and Chinese languages.Haudricourt's reconstruction was further supported by subsequent reporting that voiced stops and voiceless nasals are retained by other Karen languages, such asGeba.Manson gave a sample of diagnostic words for use during field elicitation to classify Karenic languages: water [*tʰi]branch [*pʰaŋ]flower [*pʰɔ]chicken [*sʰan]sleep [*m̥i]die [*tʰi] star [*sʰa]leaf [*l̥a]fingernail [*m̥i]fire [*m̥e]give [*pʰe]bitter [*kʰa] bone [*kʰri]child [*pʰo]right [*tʰwe]spicy [*hɛ]take [*pʰi]pus [*pʰi/mi] sky [*m̥oʔ]iron [*tʰaʔ]pig [*tʰɔʔ]skin/bark [*pʰeʔ]shoot (v.) [*kʰaʔ]dark [*kʰeʔ/kʰuʔ] silver [*rɔn]ginger [*ʔeŋ]rabbit [*tɛ]navel [*te]spear [*pan]white [*pwa] egg [*ti]cheek [*pu]liver [*sɨn]eat [*ʔam]left [*se]be at, exist [*ʔɔ] paddy [*pɨ]blow/howl [*ʔu]head [*klo]hand [*su]breathe [*sa]many [*ʔa] alcohol [*siʔ]wing [*teʔ]heart [*saʔ]call/shout [*kaʔ]near [*pɔʔ] nest [*bwe]tongue [*ble]person [*bra]name [*min]drunk [*mun]red [*le] sun [*mɤ]stone [*loŋ]snake [*ru]arrow [*bla]old [humans] [*bra]hot [*go] monkey [*zoʔ]eye/face [*meʔ]brain [*nɔʔ]intestines [*breʔ]rib [*rɤʔ]deep [*jɔʔ] Haudricourt originally viewed the correspondence set V as irregular, and so reconstructed included only the three proto-tones *A, *B and *D.\nHe added the proto-tone *B' in his 1975 revision.Haudricourt's *B' class has been accepted by most modern workers on Karen, but is not included by Luangthongkum.This class is not distinguished after originally voiced initials, but a similar merger is common in Chinese varieties.Correspondence class V is not reflected as a distinct class in any modern Karen language, being merged with *A in Sgaw and Pa'O, with *B in Pwo, with *D in Kayan, Kayaw and Kaya, and with both B* and D* in Bwe-Gaba.Luangthongkum has suggested that the words in class V might reflect an earlier final segment, a view that Haudricourt had also expressed. The phonology of Proto-Karen according toTheraphan Luangthongkum(2019): In comparison with Haudricourt's original reconstruction, Luangthongkum has dropped *x and *ɣ, and added *ʔn, *ʔw, *ʔl, *ʔj and *hr. Only Pa'O has a full set of nasal and stop codas, though many occurrences of -p, -t or -k are found in loans fromShanorPali.\nOther Karen languages may have nasalized vowels instead of nasal codas, and only glottal stop codas.\nSome have only open rhymes. Here *-N represents an indeterminate nasal (*-m, *-n or *-ŋ). Most linguists accept Haudricourt's revised reconstruction with three proto-tones *A (modal), *B and *B' in open syllables, with checked syllables forming a separate category *D.However, Luangthongkum accepts only *A, *B and *D. Theraphan Luangthongkum(2014) lists the followingsound changesthat had taken place during the transition fromProto-Tibeto-Burman(PTB;James Matisoff's reconstruction) toProto-Karenic(PK; Luangthongkum's own reconstruction). Manson (2011) lists phonological innovations for each of his four primary subgroups of the Karen language branch as follows. Works cited Reconstructions Vocabulary lists", "metadata": {"url": "https://en.wikipedia.org/wiki/Proto-Karenic_language", "title": "Proto-Karenic language", "headings": ["Contents", "Reconstruction", "Phonology", "Onsets", "Rhymes", "Tones", "Sound changes and reflexes", "From Proto-Tibeto-Burman to Proto-Karenic", "From Proto-Karenic to modern languages", "See also", "Notes", "References", "Further reading"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Proto-Karenic_language", "https://en.wikipedia.org/wiki/Proto-Karenic_language", "https://en.wikipedia.org/wiki/Proto-Karenic_language", "https://en.wikipedia.org/wiki/Karenic_languages", "https://en.wikipedia.org/wiki/Proto-Tibeto-Burman", "https://en.wikipedia.org/wiki/Proto-language", "https://en.wikipedia.org/wiki/Karenic_languages", "https://en.wikipedia.org/wiki/Andr%C3%A9-Georges_Haudricourt"]}},
{"id": "b67e73e50d93", "content": "TheWorld Book Capital(WBC) is an initiative ofUNESCOwhich recognises cities for promoting books and fostering reading for a year starting on April 23,World Book and Copyright Day. Cities designated as UNESCO World Book Capital carry out activities with the aim of encouraging a culture of reading in all ages and sharing UNESCO's values. The nomination does not provide a financial prize. UNESCO adopted the 31c/Resolution 29, in 2001, establishing the World Book Capital programme and namingMadridas the first WBC city in 2001. The advisory committee is composed of UNESCO, theInternational Publishers Association, theInternational Federation of Library Associations and Institutions, the International Authors Forum and the International Booksellers Federation. Six years after the launching of theWorld Book and Copyright Day(23 April), and following the initiative inMadridin 2001 to create year-round celebrations around the event, the World Book Capital programme was created. UNESCO invited the professional organisations of the book chain: theInternational Publishers Association, theInternational Federation of Library Associations and Institutionsand the International Booksellers Federation to create a programme aimed at promoting books during the period betweenWorld Book and Copyright Days. Following a proposal of Spain, supported by many other countries, the UNESCO General Conference decided, on 2 November 2001, that the Organization would grant its moral and intellectual support to the conception and implementation of this initiative, by inviting the international professional organisations of the book chain to work together. The first UNESCO World Book Capital designated prior to the adoption of 31 C/Resolution 29 was Madrid (Spain) in 2001. An agreement was concluded among the partners that, after Madrid, the subsequent capitals would be Alexandria in 2002 and New Delhi in 2003. Cities designated as UNESCO World Book Capital carry out activities with the aim of encouraging a culture of reading and sharing UNESCO's values in all ages and population groups. Through the World Book Capital programme, UNESCO acknowledges the cities commitment for promoting books and fostering reading during a 12 months period. The programme aims to raise awareness for literacy and reading issues, through its numerous activities. World Book Capital brings together the local and national book industries and creates various initiatives with organisations and other stakeholders. The title is also used to draw national and international attention to the literary heritage of a city and nation. Every year, there is an Open Call for Applications published on the official website of UNESCO. The Open Call for Applications for 2024 was published in February 2022. The nomination does not include any financial prize; it acknowledges the best programmes dedicated to books and reading. The Director-General of UNESCO is responsible for the designation of the cities following both internal and external consultations with the other members of the Advisory Committee. The Advisory Committee is made up of one representative of the International Authors Forum (IAF), the International Federation of Library Associations and Institutions (IFLA), the International Publishers Association (IPA) and one UNESCO representative. The committee meets once a year. To ensure a balanced representation of all regions of the world, the Advisory Committee does not consider consecutive nominations of cities from the same region. Also, the Advisory Committee will only consider an application for a city in a country where another city has been a UNESCO World Book Capital if a period of 10 years or more has elapsed since the previous host city nomination. The nominating committee accepts programmes presented by or endorsed by the mayor of the city making the application that promote and foster reading. The programmes run from one World Book and Copyright Day and the next. Applicants' programme proposals will be evaluated using six criteria: By presenting its application each candidate city commits to: UNESCO and the Advisory Committee assist the chosen capital in the planning and implementation of its activity programme during the two years prior to its mandate as World Book Capital. The city is required to facilitate possible evaluation audits implemented on UNESCO's request.  If the work doesn't meet the panel's expectations, the Advisory Committee may withdraw the title from the city at any time during the monitoring phase, with one month's notice. The city authorities also agree to support the administrative work of the World Book Capital Secretariat by gathering financial contributions from potential donors or participating in the development of fundraising strategies. The following cities have been designated as World Book Capitals: Madridwas the first city to be awarded the title of the \"World Book Capital\". The Spanish capital took the initiative of creating this title and its first events. Numerous activities, around the theme of the popularisation of books and reading, were organised by different companies and organisations which collaborated to support the event. The existing Spanish Bookfair LIBER used Madrid's World Book Capital status as its theme for the year. During the year, the mountain \"La Puerta de Alcalà\" was covered with books. TheGreat Library of AlexandriainAlexandria, Egypt, was one of the largest and most significantlibraries of the ancient world. The library, first constructed in the 3rd Century BC, is the resource of knowledge and the first world centre of arts and sciences. It was the first library to invent a bibliographic system. Although it was destroyed several times, the government of Egypt built a newAlexandria Library. In 2002, the Egyptian city reopened its library and presented the new library theBibliotheca Alexandrina. This project was one of the main reasons Alexandria was selected as WBC, as it encouraged people to have an interest in reading. New Delhiis home to the largest number of publishers inIndia. It launched a programme to promote publishing linked to all professional associations and political and social actors concerned with books, including government services. Various activities were organised throughout the year, including establishments of book kiosks, libraries and a permanent book pavilion at Pragati Maidan. An emphasis was given to promoting literary habits among children. Other events were the Delhi Book Fair in August 2003, the two-day National Convention on \"Making India a Book Reading Society\" and the Children's Book Exhibition at various prominent schools in New Delhi. Theme: ABC 2004 The city ofAntwerpwas selected as World Book Capital for 2004. The chosen theme ABC 2004, evolved to XYZ 2005 in the second part of its programme where four exhibitions were devoted to the written heritage of the city. With a budget of 1.7 million euros, several literary projects took place throughout the year including word festivals, theatre street performances, public readings, celebrations ofauthors, letter-writing contests bymobile phone, publishing of books in collaboration with artists, exhibitions as well as free distribution of blank notebooks to encourage writing. Poems were printed on the wrappers of bread and were made available to the public. In the main hall ofDeSingel, Antwerp's international art and cultural centre, a metal cube was installed which housed a library. Theme: The Gathering Power of Books Montreal World Book Capital 2005 (MWBC) goal was to \"underline the gathering power of books\". The main objectives of MWBC 2005 were to increase reading habits especially among young people, encourage creative writing, stimulate the book industry and strengthenMontreal's position as an international cultural city. The activities were developed under the themes of books and reading, creativity, education and learning, remembrance and heritage, culture, celebration, and festivals. Authors includingMarie Laberge,Réjean Ducharme,Yann Martel,Mordecai Richler,Michel Tremblayhad their books highlighted during the year. Theme: Il Linguaggio dei Segni Turinwas designated World Book Capital, in collaboration withRome, from 22 April 2006 to 22 April 2007. The municipality of Rome contributed to the programme all year long. The additional WBC theme was: Turin, World Book Capital with Rome: cities to leaf through. The city focused its programme on the meaning of the different punctuation signs and was run by Fondazione per il libro, la musica e la cultura of Turin. Activities began in April 2006 with a poetic, literary, and musical evening, the \"Bookstock\". Throughout that day various personalities and artists including writers, poets, musicians, and people from the film industry performed in the city centre with approximately 4,000 spectators attending the event. Many events occurred during the year and the majority of them were under TWBC 2006's theme, the language of signs, which include: \"Il Punto Interrogativo\" (The Question Mark), \"La Virgola\"  (The Comma), \"I Due Punti\" (The Two Points), \"Il Punto exclamativo\" (The Exclamation Mark), \"I Pontini de Sospensione\" (The Suspension Points), \"Il Parentesi\"  (The  Brackets), \"Il Punto\" (The final Point), \"Le Virgolette\" (The Quotation Marks), \"ll Punto e Virgola\" (The semicolon), \"Il @\" (The @). The programme was made up of more than 800 network projects, organised not only in Turin but throughout the region of Piedmont as well. Among these events were book readings, literary festivals and awards, school writing sessions, theatres, opera, etc. Rome implemented cultural exchanges in thelibraries of Baghdad, Buenos Aires, Bogotá, Guatemala and Rwanda. The \"Casa delle Letterature\" (House of Literature), in collaboration with the Italian publisher \"Gorée di Siena\", has promoted the translation of a book produced by the children of Koh Phi Phi inThailand, struck by a tsunami. This book was distributed throughout Italy for the reconstruction of the destroyed school. Theme: We'll get Bogota Reading During the Bogotá World Book Capital, the top priorities were the development of a culture of reading for social inclusion, the promoting reading among children, young people and adults of the city, especially among those who had limited access. The chosen slogan was: \"We'll get Bogota reading.\" The city ofBogotáhosts an International Book Fair, held in April every year since 1988. The fair is considered to be the largest in the reading culture and publishing industry inLatin America. Various other initiatives were implemented on several fronts: the creation of the Consejo Distrital de Fomento de la Lectura (District Council for the Promotion of Reading), responsible for setting reading and writing policies in the city, the improvement of education with the development of a modem public library system, the cooperation with a variety of organisations in the public and private sectors, and the launching of programmes to popularise literature, such as Libro al Viento (\"Book in thé Wind\"). Theme: Open Book, Open Mind The programme ofAmsterdamWorld Book Capital, named 'Open Book, Open Mind', was centred around these three people:Spinoza,Anne FrankandAnnie M. G. Schmidt. In addition to the central theme, the programme carried out events towards the Municipal Council's three objectives: The first Amsterdam \"Book of the Night\" was created on March 20. Libraries, bookshops, the weekly book fair and hotel/catering venues around the Spui were filled with literary performances. Multiple authors and poets recited parts of their work for the people in the public square. Many events were targeted to the younger population and especially to children. From October 2008 to April 2009, citizens were encouraged to engage their children in the Children's Book Capital programme. Poetryalso held a significant part in the programme. During the \"Poetry in the Park\" project, ten city districts hosted poetry activities open to all district residents. An interactive exposition of \"poetry poles\" was held in the Vondelpark. Also, the National Declamation Competition launched on National Poetry Day, the 29th of January, the final round of which was carried out as part of the AWBC closing week. A total number of 298 activities were realised during this period with the aid of public networks and other institutions with 490,000 people taking part. The budget was estimated to reach above €2.7 million with 60% from government organisations and 40% from funds, sponsors and admission revenues. Themes: \"Books are our best friends. This year, Beirut is their capital.\", \"Beirut reads. Beirut writes. Beirut publishes. The triple identity of Beirut.\" The World Book Capital in 2009 wasBeirut, the capital ofLebanon. A series of activities were planned, from literary cafés to specialised fairs, international symposiums and conferences, writing workshops to all kinds of forums with a focus on Lebanese writers. The activities revolved around four themes: \"Books, vectors of culture\", \"Book trades\", \"Promotion of reading and writing\", \"Encourage youth to read\". Exhibitions honouring the great Lebanese and Arab writers also took place during this period. Other events included thematics such as Lebanon and the Alphabet, festivals of poetry, comics, storytelling, a professional book fair, conferences dealing with copyright, the future of books, translation, meetings with Mediterranean booksellers, competitions and prizes. Theme: \"In The Realm of the Book\" The programme incorporated objectives related to the promotion of reading books, the increase in the accessibility of books by all the population, the spread of the culture of reading and the introduction of different literary genres to the public.More than 300 activities were organised during theLjubljanaWorld Book Capital 2010 including: The World Book Capital programme during the year 2011 was held inBuenos AiresinArgentina. The project unit \"Unidad de Proyectos Buenos Aires Capital Mundial de Libro\" was created especially for the occasion and was run by Luciana Blasco. The three pillars of the Buenos Aires 2011 World book Capital were: Traditional yearly events such as the Night of the Bookstores, International Poetry Festival and Night of the Museums were enhanced for the occasion of World Book Capital. During that period 85 events were organised, 80% of which were free of charge. In addition, the suburbs of Buenos Aires organised community libraries and book events for local people. Historical authors, likeBorges,Lorca,Sabato, were celebrated. New event entries were added to theInternational Bookfairand Filba, a Buenos Aires literature festival. Also, international books were showcased, with the main presence ofFrenchandQuebecois literature. Unconventional spaces were utilised to attract new audiences. The Tower of Babel, designed by artist Marta Minujin, was a 25-metre tower made of 30,000 books in languages from all over the world. Approximately 115,000 books were distributed by buses as well as in subways, trams, and theatres. In addition, the tour of the city by bike included themes around poetry and reading Shakespeare. A website was also developed as a dissemination tool and served as a literary events diary for the year. The electronic newsletter managed to attract 20,000 subscribers. The programme was funded by different streams: the Ministry of Culture, civil society or private organisations, as well as the Metropolitan Fund for the Arts and the Patronage system. Theme: Eternity of the word The World Book Capital 2012 inYerevan, Armenia concurred with the country's 500th anniversary of \"Armenian printing\" as it was also celebrated in 2012. The schedule of the Yerevan World Book Capital 2012 programme emphasised \"the role of children and young adults in building knowledgeable societies\". Some of the events aimed at this objective were: \"Give us Books, Wings to Fly\", \"I Am Creating a Book\", \"Returning Books Back to Children\" and \"Colorful Books\". Another priority of the Yerevan World book Capital was to explore new technologies, ideas and innovations. Conferences, symposiums, and exhibitions were organised to discuss issues related to copyright, translation,freedom of speech, humanitarian and societal issues,genocideand internationally distinguished works of literature. Books about cinema, art, music and other art forms were also presented during exhibitions, seminars, and film premieres. Theme: Read for Life TheBangkokWorld Book Capital inThailand2013, the \"Read for Life\" programme focused on nine objectives: Numerous activities were organised all year long to reach these objectives. Bangkok collaborated with numerous organisations from the public and private sectors. Activities were run with departments in Bangkok, including those of education, healthcare, environment, social development, traffic control and 50 others. All sectors were also tied together under another theme, \"Thinking, Doing, Learning, Fixing, and Taking Responsibility Together.\" This stimulated mutual support and contribution from multiple stakeholders and associate networks like TK Park, The Publishers and Booksellers Association of Thailand, SCG, The Mirror Foundation, Chula Book Center, Thai Health Promotion Foundation, and more. Theme: Books: Windows to Our World of Possibilities Port Harcourtis the first city inSub-Saharan Africato win the title. The Rainbow Club organisation, a non-governmental organisation applied and won the bid on behalf of theNigerian Government. The theme of this year \"Books: Windows to Our World of Possibilities\", communicates the concept that reading books provides knowledge and exposure to new mentalities and ideas, as well as that it transports the reader to new worlds. Educating and cultivating citizens aimed at empowering them to protect democracy, promote social justice, and contribute to the development of their communities. Besides the main theme, other main objectives of the Port Harcourt World Book Capital 2014, were promotingNigerianandAfrican literature, fostering a reading culture among children and youth, and improving literacy rates. Book fairs and reading events took place throughout the year. The World Book Capital programme 2014 granted people access to more libraries and more literary activities in the city. The programme encouraged young people to use facts from their lives to tell their own stories, through the usage of technology and social media. This was achieved in several events: The Book Clubs, Reading Tree, Book-of-the-Month, exhibitions, amongst others. Other activities were: \"Library Support Programme\", a voluntary training by other adults and donations to modern school libraries which were recently created, \"Books on the Radio\", \"Television Show: Game Show-\" Know your World\", \" Monthly Drama performances\", \"The walking Book\", \"Ken Saro-Wiwa ‘Writer-Martyr Memorial Square’\", \"Introduction of a writers’ residency program\", \"Possibilities for Nigeria-Essay Contest as Nigeria turns 100\", \"Integration into existing state events\", etc. Theme:\"Books for all\" \"Read and Discover Yourself\" During the designated year, the public and private sectors inIncheon, South Korea, organised projects under the slogans \"Books for All\" and \"Read and Discover Yourself\". A total number of 45 projects were organised in 6 different domains: 1. Reading Culture in Daily Life 2. Invigorating the Publishing Industry 3. Renaissance of Humanities in Incheon 4. A City that Communicates Through Books 5. Commemorative Projects 6. Special Events Large scale events, such as the Korea Reading Festival and the Korean Library Association's General Conference, were organised and were met with extensive participation. The Incheon EduContent Fair introduced a place where education met with digital technology. It constituted a platform for global information sharing on the latest trends in related industries. This fair also presented the future of education with state-of-the-art technologies such as Smart Class and Hologram Class. Local libraries provided reading resources for different social groups, age groups, the less privileged. Events were held aimed to reignite interest in the humanities. People and companies supported the local libraries through book donations and voluntary work. According to the National Survey of Reading Habits, conducted by the Ministry of Culture, Sports and Tourism the number of books read by Incheon citizens in 2015 increased by around 47%. Theme: Read to me Wrocław ThePolishcity ofWrocławis the first city to be awarded both the World Book Capital andEuropean Capital of Culturetitles in the same year. With the slogan \"Read to me Wrocław\", Wrocław planned various cultural activities for participants of all ages. During theWorld Book and Copyright Day, on April 23, the event \"European Literature Night\" took place, which launched a special edition due to World Book Capital celebrations with a focus onWilliam Shakespeare. Excerpts from his works were read and interpreted in places all around the city by renown Polish actors, like: Ewa Skibińska,Magdalena Cielecka,Jan Nowicki,Arkadiusz Jakubikand Bartosz Porczyk. The Polish city of Wrocław also launched a composition competition in order to create a \"world book anthem\".This book hymn featured the words from the work ofTadeusz Rozewicz, the \"Petit cheveu du poète\". Tadeusz Rozewicz, the polish poet and playwright, died in Wrocław in 2014. His work was translated into hundreds of languages. Theme: Make Dreams Come True The capital of Guinea,Conakry, is the first city infrancophone Africato be nominated with the World Book Capital title. Until 2017, only threeAfricancities were appointed with the title:Alexandriain 2002,Port Harcourtin 2014 andConakryin 2017. At the time of Conakry's nomination, 60% of the Guinean population could not read. The project intended to fight illiteracy in Guinea, by helping young people and people from the rural areas get access to books. Higher literacy and stronger reading culture in schools, libraries, institutions and among the general public, were all primary priorities of the programme. Monthly cultural events focused on the country's authors and culture. In addition, a media library was built in each commune of Conakry and reading areas were established in every neighbourhood. Guinea's book industry benefited from the improved infrastructure and access to books, thanks to the new constructions for the World Book Capital programme. Theme: Books Everywhere The World Book Capital in 2018 was the capital ofGreece, Athens.This year's slogan was \"Books Everywhere\". The programme was based on 8 thematics: Each of these eight objectives was aligned with the main goal of the project to make books and culture accessible to everyone, residents or visitors, across all neighbourhoods of Athens. A total of 615 events and activities were realised during the designated year under the themes of; Celebrating Reading (234 events), A world of writers (international writers) (41 events), Greek writers (19 events), Athenian Book Itineraries (48 events), Open Collections and archives (43 events), Educational Activities (81 events), The Book and the Arts (114 events), and Contemporary Narratives (35 events). The programme cooperated with 212 cultural institutions, such as museums, embassies, foreign institutes, international organisations and non-governmental organisations. Inclusive and free of admission events were organised in public and private spaces across the seven municipal districts. Some of the programme initiatives were: moving and pop-up libraries, Bibliobuses- books on wheels, cultural performances and talks by esteemed authors from around the world, poetry readings, installations, festivals, exhibitions and many more. The programme reached about 450.000 residents and visitors of all backgrounds. Theme: Open Books, Open Minds The World Book Capital programme in 2019 was held inSharjah, thethird-most populous cityin theUnited Arab Emirates. The activities were developed under six pillars: The government along with non-government entities formed multiple activities such as poetry readings, singing and storytelling events in industrial workers accommodations. More than fifty libraries with books inUrdu,EnglishandTagalogwere gifted to industrial workers. Book Fairs and campaigns were also part of the programme. The yearlyInternational Book Fairis an 11-day international book fair held annually inSharjah. During the fair \"Give Your Book a New Life\", more than ten thousand books were available at symbolic prices to make reading affordable to people from every socioeconomic background. Also, a Book Donation Campaign was carried out, the \"Kan Ya Ma Kan\", which translates to Once Upon Time. Another popular campaign that combined reading and outdoor activities, was the Sharjah Beach Library campaign. Beach libraries were installed in Sharjah, filled with books for all ages, in various languages. During the year, many public offerings were commissioned, such as the House of Wisdom. This new library and cultural centre combined traditional and digital resources of knowledge, information, interactive learning and contemporary pedagogy. The House of Wisdom provides free and open access to people of all ages and nationalities. It extends over 12,000 square metres and includes two floors of libraries with more than 105,000 books, discussion halls, indoors and outdoors reading areas, as well as an education space designed for children. The Sharjah World book Capital contributed with initiatives and conversations at international book fairs inLondon,Turin, Moscow, as well as in the LIBER International Book Fair in Madrid 2019. Theme: KL Baca: Caring through Reading The World Book Capital 2020 was held inKuala LumpurinMalaysia.Under the slogan KL BACA: Caring through Reading, the organising committee stated that \"a city that reads is a city that cares\". The activities were organised around 5 streams: The overall themes of the initiatives of Kuala Lumpur World Book Capital 2020, besides Caring through Reading, were focused on Diversity and Environmental Rejuvenation. These two pillars were considered necessary in building a strategy aimed at sustainability. Theme: Ok. So your next book is…? The World Book Capital programme inTbilisiprimarily focused on new media and technologies as tools for reading facilitation and book promotion targeted towards young people. Events included book festivals, digital and sustainable book related activities. The main goal was to make reading more popular and accessible throughout each neighbourhood and age group. This article incorporates text from afree contentwork. Licensed under CC BY-SA 3.0 IGO (license statement/permission). Text taken fromUNESCO World Book Capital​, UNESCO. This article incorporates text from afree contentwork. Licensed under CC BY-SA 3.0 IGO (license statement/permission). Text taken fromUNESCO World Book Capital, Call for Applications 2024​, UNESCO.", "metadata": {"url": "https://en.wikipedia.org/wiki/World_Book_Capital", "title": "World Book Capital", "headings": ["Contents", "History", "Activities", "Nomination", "Nomination process", "Nomination criteria", "World Book Capital Cities commitment", "Cities designated World Book Capitals", "Madrid 2001", "Alexandria 2002", "New Delhi 2003", "Antwerp 2004", "Montreal 2005", "Turin 2006", "Bogotá 2007", "Amsterdam 2008", "Beirut 2009", "Ljubljana 2010", "Buenos Aires 2011", "Yerevan 2012", "Bangkok 2013", "Port Harcourt 2014", "Incheon 2015", "Wrocław 2016", "Conakry 2017", "Athens 2018", "Sharjah 2019", "Kuala Lumpur 2020", "Tbilisi 2021", "Sources", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/World_Book_Capital", "https://en.wikipedia.org/wiki/World_Book_Capital", "https://en.wikipedia.org/wiki/World_Book_Capital", "https://en.wikipedia.org/wiki/UNESCO", "https://en.wikipedia.org/wiki/Madrid", "https://en.wikipedia.org/wiki/Rio_de_Janeiro", "https://en.wikipedia.org/wiki/UNESCO", "https://en.wikipedia.org/wiki/World_Book_Day"]}},
{"id": "caa7a62fb6f0", "content": "Puma lentivirus(PLV) is aretrovirusin the genusLentivirus.A study in 2003 indicated thatdomestic catsinfected with Puma lentivirus orLion lentivirus(LLV) began producing anti-FIVimmune responses. Thisvirus-related article is astub. You can help Wikipedia byexpanding it.", "metadata": {"url": "https://en.wikipedia.org/wiki/Puma_lentivirus", "title": "Puma lentivirus", "headings": ["Contents", "References"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Puma_lentivirus", "https://en.wikipedia.org/wiki/Puma_lentivirus", "https://en.wikipedia.org/wiki/Puma_lentivirus", "https://en.wikipedia.org/wiki/Virus_classification", "https://en.wikipedia.org/wiki/Virus", "https://en.wikipedia.org/wiki/Riboviria", "https://en.wikipedia.org/wiki/Revtraviricetes", "https://en.wikipedia.org/wiki/Revtraviricetes"]}},
{"id": "f79c0e0ba100", "content": " John F. KennedyDemocratic John F. KennedyDemocratic The1958 United States Senate election in Massachusettswas held on November 4, 1958. Democratic incumbentJohn F. Kennedywas reelected to a second six-year term, defeating Republican candidate Vincent J. Celeste. Senator Kennedy was unopposed for renomination. Celeste was unopposed for the Republican nomination. Kennedy was overwhelmingly popular in Massachusetts and the 1958 elections werea wave electionfavoring the Democratic Party. Celeste's campaign was poorly funded but the candidate worked 17-hour days, running his campaign out of his law offices and attempting to frame the race as one pitting a working-class child of Sicilian immigrants against \"that millionaire Jack Kennedy.\" The Kennedy campaign had bought and produced thousands of pieces of campaign material with the slogan \"Be Proud of Your Vote!\" but scrapped them after Celeste's nomination, asSenator Kennedy's father Joethought the slogan could alienate Italian-Americans and divide the state on ethnic lines. Kennedy defeated Celeste by a margin of 874,608 votes; this represented the largest margin of victory in a statewide Massachusetts election up to that point.", "metadata": {"url": "https://en.wikipedia.org/wiki/1958_United_States_Senate_election_in_Massachusetts", "title": "1958 United States Senate election in Massachusetts", "headings": ["Contents", "Democratic primary", "Candidates", "Results", "Republican primary", "Candidates", "Results", "General election", "Candidates", "Campaign", "Results", "References"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/1958_United_States_Senate_election_in_Massachusetts", "https://en.wikipedia.org/wiki/1958_United_States_Senate_election_in_Massachusetts", "https://en.wikipedia.org/wiki/1958_United_States_Senate_election_in_Massachusetts", "https://en.wikipedia.org/wiki/1952_United_States_Senate_election_in_Massachusetts", "https://en.wikipedia.org/wiki/1962_United_States_Senate_special_election_in_Massachusetts", "https://en.wikipedia.org/wiki/John_F._Kennedy", "https://en.wikipedia.org/wiki/Democratic_Party_(United_States)", "https://en.wikipedia.org/wiki/Republican_Party_(United_States)"]}},
{"id": "675a1f990fe2", "content": " Frank Raleigh Lautenberg(/ˈlɔːtənbɜːrɡ/; January 23, 1924 –  June 3, 2013) was an American businessman andDemocratic Partypolitician who served asUnited States SenatorfromNew Jerseyfrom 1982 to 2001, and again from 2003 until his death in 2013. He was originally fromPaterson, New Jersey. Lautenberg was elected five terms as Senator. He first took office in December 1982 and served three terms, retiring from the Senate in 2001. Called upon to run again one year later due to circumstances surrounding his Senate colleagueRobert Torricelli's re-election campaign, Lautenberg returned to the Senate in January 2003 and was elected to one additional term in 2008. He died during his fifth term and remains New Jersey's longest serving senator, with a total of 28 years, 5 months and 8 days in office. Before entering politics, he was an early partner in, and became the chairman and chief executive officer ofAutomatic Data Processing, Inc. In his early years, he served overseas in theU.S. Army Signal Corpsfrom 1942 to 1946 as a part of the war effort, and after returning home his interest inAmerican political eventsincreased. He has been called \"the last of theNew Dealliberals\" and was known for his legislative efforts againstdrunk driving, and his support of spending forAmtrakandurban public transportation, for strongerenvironmental regulations, greaterconsumer protections, and investigations of wrongdoing byWall Street. Lautenberg was born inPaterson, New Jersey, the son of Mollie (née Bergen) and Sam Lautenberg,Jewishimmigrantsfrom Poland and Russia, who had arrived in the United States as infants.He was named after his maternal grandfather, Frank Bergen, and close family friend and Paterson community activist, Raleigh Weintrob. When Lautenberg was 19, his father, who worked in silk mills, sold coal, farmed, and once ran a tavern, died of cancer. His mother then opened a sandwich shop to support the family. After graduating fromNutley High Schoolin 1941, Lautenberg served overseas in the 3185th Signal Service Battalionof theUnited States Army Signal CorpsduringWorld War IIfrom 1942 to 1946.Then, financed by theGI Bill, he attended and graduated fromColumbia Business School's now-defunct undergraduate program in 1949 with a degree in economics. He worked as a salesman forPrudential Insuranceand was the first salesman atAutomatic Data Processing(ADP), a payroll-management company. He became the company's CEO in 1975. He was the executive commissioner of thePort Authority of New York and New Jerseyfrom 1978 to 1982. Lautenberg also served in roles with a number of Jewish and pro-Israel organizations, including as a member of theJewish Agency for Israel's board of governors and as president of theAmerican Friends of the Hebrew University.In 1974, he became the youngestchairever in the history of theUnited Jewish Appeal.Within a year Lautenberg had increased its charitable intake to the second-highest level in its history.He was also named to the President's Commission on the Holocaust in the late 1970s. Lautenberg contributed to Democratic candidates for years.He donated $90,000 toGeorge McGovern's campaign for president in1972, earning himself a place on one ofRichard Nixon'senemies lists.In1982, he ran for the Democratic nomination for the U.S. Senate. He faced nine other candidates: former State Banking Commissioner Angelo Bianchi, formerMorristownMayorDonald Cresitello, former CongressmanJoseph A. LeFante, labor leader Frank Forst, former CongressmanAndrew Maguire, Richard McAleer, businessman Howard Rosen,PrincetonMayorBarbara Boggs Sigmund, andPassaic CountyFreeholderCyril Yannarelli.Maguire was the favorite but Boggs' entry took votes away from him and Lautenberg spent a considerable amount of his own money. Lautenberg won with a plurality, taking 26% of the vote to Maguire's 23%, LeFante's 20% and Sigmund's 11%. The seat had been occupied by DemocratHarrison A. Williams, who resigned on March 11, 1982, after being implicated in theAbscamscandal. After Williams' resignation, Republican GovernorThomas Keanappointed RepublicanNicholas F. Bradyto the seat. Brady served in the Senate through the primary and general elections but did not run for the seat himself. Inthe general election, Lautenberg faced popular Republican congresswomanMillicent Fenwick. She ran on a very progressive platform and polls in the Summer of 1982 put her ahead by 18 points. Even Lautenberg quipped that she was \"the most popular candidate in the country.\"Lautenberg spent more of his own money, eventually out-spending Fenwick two-to-one. He emphasisedPresident Reagan's unpopularity, reminded the voters that she would be a vote for a Republican majority in the Senate and called Fenwick, who was 72, \"eccentric\" and \"erratic\" but denied that he was referring to her age.He did however point out that she would be almost 80 at the end of her first term and was therefore unlikely to gain much seniority in the Senate.Lautenberg won by 51% to 48%, in what was considered a major upset.Brady, who had just a few days left in his appointed term, resigned on December 27, 1982, allowing Lautenberg to take office several days before the traditional swearing-in of senators, which gave him an edge in seniority over the other freshman senators. In his first term, Lautenberg pushed theNational Minimum Drinking Age Act, which was passed in 1984.The same year, he spoke at theDemocratic National Convention, though he was overshadowed by New York GovernorMario Cuomo, who gave the keynote speech. Inhis 1988 race, Lautenberg was opposed by RepublicanWall Streetexecutive, former college football star Brigadier GeneralPete Dawkins, who won the 1958Heisman Trophyfor theArmy Black Knights. After trailing in early polls, the Lautenberg campaign, headed by Democratic consultantJames Carville, ran an aggressive advertising campaign enumerating Lautenberg's legislative accomplishments and raising the possibility that Dawkins' candidacy was intended solely as a stepping stone to the presidency, as well as pointing out his lack of roots in New Jersey. Lautenberg ultimately came from behind to win re-election, 54% to 46%.The race was named the 17th-nastiest in American political history by political scientistKerwin Swintin his bookMudslingers: The 25 Dirtiest Political Campaigns of All Time. Following his re-election, Lautenberg became a member of the President's Commission on Aviation Security and Terrorism (PCAST), which was set up in September 1989 to review and report on aviation security policy in light of the sabotage ofPan Am Flight 103on December 21, 1988. AfterBoris Perchatkin’s speeches in the US Congress in 1989along with RepresentativeBruce Morrison, Lautenberg was a primary sponsor of what became known as theLautenberg Amendment, which first passed in 1989.The amendment granted presumptive refugee status to Jewish people and members of other groups from the Soviet Union, and facilitated theemigration of hundreds of thousands of Jewsto the United States. Lautenbergwas re-electedin the 1994Republican Revolution, defeating New Jersey State Assembly SpeakerChuck Haytaianby 50% to 47%. In 1999, two popular Republicans were considering running against Lautenberg: the incumbent GovernorChristine Todd Whitmanand former GovernorThomas Kean.Polling showed Lautenberg trailing both of them.Lautenberg also did not get along with his New Jersey Senate colleagueRobert Torricelli, and suspected that he was encouraging Whitman to run against him.Torricelli's relationship with Lautenberg had been very rocky, especially when Lautenberg directly accused Torricelli of encouraging Whitman to challenge him for his Senate seat. Lautenberg raised his concerns in a meeting with Democratic senators in 1999, and Torricelli responded by shouting, \"You're a fucking piece of shit, and I'm going to cut your balls off!\"Lautenberg was also less than enthusiastic at the prospect of fundraising for a grueling campaign, and did not want to have to spend more of his own money. He announced his retirement in 2000, but denied it was because he thought he would lose to Whitman or Kean, saying that he had been vulnerable in previous elections, and, \"Mr. Vulnerable always wins.\"His fellow Democrat and businessman,Jon Corzine,was electedto replace him. Almost immediately, Lautenberg regretted his decision, especially after neither Whitman nor Kean ran against Corzine in the general election (instead, CongressmanBob Franksran for the seat, and was defeated). He also was said to be missing his days working in the Senate.He had considered reversing his decision and running for re-election, but since his rival, Senator Torricelli, had encouraged Corzine to run in the first place, Lautenberg would likely have had trouble restarting his campaign.A little over a year after he left office, however, Lautenberg found an opening. In the 2002 primaries leading up to themidterm elections. Torricelli won the Democratic nomination for a second term in the Senate. The Republican candidate wasDoug Forrester, the mayor ofWest Windsor Township. It was expected that Torricelli would win the election by a significant margin, as no Republican had won election from New Jersey sinceClifford P. Casewas elected to his final six-year term in 1972 in the seat Torricelli was currently occupying. However, an ongoing investigation into the Senator's activities and business dealings resulted in federal corruption charges being filed against him before the election.The subsequent drop in voter support in the weeks that followed resulted in Torricelli's decision to withdraw from the race on September 30, 2002. After overtures were made to retired SenatorBill Bradley, CongressmanFrank Pallone, and future SenatorRobert Menendezto take over as candidate, the New Jersey Democratic Party called upon Lautenberg and he accepted the nomination. This was met with an almost immediate challenge by Forrester and the Republicans as New Jersey law forbade the replacement of candidates on the ballot after a certain deadline. The ballot name change was unanimously upheld by theNew Jersey Supreme Court,who cited that the law, as written, did not consider the possibility for an emergency resignation and said that Forrester would have an unfair advantage if Torricelli was left on the ballot.TheU.S. Supreme Courtdeclined to take up the case. With the popular Lautenberg now in the race, Forrester's lead in the polls evaporated and Lautenberg won the election by a 54% to 44% margin. Despite having served over 18 years in the Senate, upon Lautenberg's return he was treated like other freshman senators with respect toseniority. This was despite the fact that he had agreed to run for office with the implicit understanding that Democratic leaderTom Daschlewould allow him to retain seniority and serve on the Appropriations Committee. He was reported to have been upset with his treatment and commented that \"when you come down from a relatively lofty position of seniority, the atmosphere is different\", having been given one of the least prestigious office spaces behind a fire exit door. Back in the Senate, Lautenberg was once again considered one of the chamber's mostliberalmembers. He waspro-choice, supported gun control, introduced many bills increasing penalties forcarjackingandcar theft, and criticized theBush administrationonnational securityissues.He was heavily involved in various anti-smoking andairline safetylegislation. He also co-sponsored legislation to increase drunk driving penalties. He was probably best known as the author of the legislation that banned smoking from most commercial airline flights.He also is known for authoring theRyan White Care Act, which provides services to AIDS patients. Upon his return to the Senate, Lautenberg was the first U.S. senator to introduce legislation calling for homeland security funds to be distributed solely on the basis of risk and vulnerability. In 2005, he became a leading voice within the Senate in calling for an investigation into theBush administration payment of columnists. WhenJon Corzineresigned from the Senate to becomeGovernor of New Jersey, Lautenberg became the senior senator again in 2006. This also made him the only person to have been both the junior and senior senator from New Jersey twice each.Lautenberg received an \"A\" on theDrum Major Institute's 2005 Congressional Scorecard on middle-class issues. In 2007, Lautenberg proposed theDenying Firearms and Explosives to Dangerous Terrorists Act of 2007, designed to deny weapons purchases by persons that the government has placed on the terrorist watchlist. On June 21, 2007, Lautenberg passedClifford Casefor the most votes on the Senate floor of any United States Senator in New Jersey history. In February 2006, Lautenberg announced his intention to run for re-election in2008, saying that deciding not to run for re-election in 2000 \"was among the worst decisions of his life.\"Lautenberg formally announced his candidacy on March 31, 2008. His campaign manager was Brendan W. Gill. CongressmanSteve Rothmanand State SenatorJohn Adlerboth mooted the possibility of running, but said they would defer to Lautenberg. In private he called them \"the pallbearers\".Ultimately, both declined to run. Instead, CongressmanRob Andrewsannounced he would challenge Lautenberg for renomination in theDemocratic primary. Also running wasMorristownMayorDonald Cresitello, who had run against Lautenberg in the 1982 Senate primary. Andrews ran a poor campaign, \"best remembered—if it's remembered at all—for its ineptness.\"He was also tarred with his vote for the Iraq War. Lautenberg's New Jersey Senate colleagueBob Menendezalso came to his aid and Lautenberg defeated Andrews 59% to 35% in the June 3 primary.He then defeated former CongressmanDick Zimmerin the general election 56% to 42%. TheNew York Timeseditorial board endorsed Mr. Lautenberg's candidacy for Senate during the 2008 cycle. Both opponents cited Lautenberg's age among reasons to vote against him. Andrews, for example, referenced Lautenberg's own 1982 defeat ofMillicent Fenwick, in which Lautenberg was alleged to have referred to Fenwick's age (Fenwick was 72 at the time; Lautenberg was 84 in 2008). Lautenberg denied he made Fenwick's age an issue, saying he only ever questioned Fenwick's \"ability to do the job.\" In June 2010, Lautenberg compared thedevilwithDubai.Lautenberg was quoted as stating, \"We wouldn't transfer the title to the devil, and we're not going to transfer it toDubai.\" According to a Foreign Policy in Focus article, Lautenberg defended his remarks due to theUAE's refusal to support U.S. policy toward Israel and Iran.According to theArab American Institute, Lautenberg apologized in a letter upon meeting with Arab American Institute representatives. On February 14, 2013, Lautenberg announced he would not seek re-election.In the press conference, Lautenberg joked \"Is it too late to change my mind?\" and joked that he would pray \"something goes wrong\" so he could be called on to run again. At the time of his death from viral pneumonia at age 89, Lautenberg was the oldest serving senator and the last remainingWorld War IIveteran in the Senate. Lautenberg served on the following committees: Frank Lautenberg married Lois Levenson in 1956,with whom he had four children: Ellen, Nan, Lisa, and Joshua.Their 31-year marriage ended in divorce, in 1988.On 25 January 2004, he married his companion of nearly 16 years, Bonnie S. Englebardt.He also had two stepdaughters, Danielle Englebardt and Lara Englebardt Metz with Bonnie; and 13 grandchildren. Lautenberg resided inMontclair, New Jerseyfor much of his Senate career and last resided in nearbyCliffside Park.In 2024, Lautenberg was awarded thePresidential Medal of Freedomby PresidentJoe Biden, a Senate colleague for over two decades. On February 19, 2010, his office announced that Lautenberg had been diagnosed with a diffuse largeb-cell lymphoma(an aggressive but curableblood cancerthat appears in organs like the stomach) atMount Sinai Medical Centerin New York.He had been hospitalized with profuse gastric bleeding following a fall in hisCliffside Park, New Jersey, home shortly after returning from aHaititrip with a 12-member congressional delegation.He was released from the hospital on February 25, 2010.Six to eightchemotherapytreatments of the intensiveR-CHOPregimen followed every 21 days over several months, and a doctor for Lautenberg at the time said a full recovery was expected. Lautenberg continued his Senate work between treatments. On June 26, 2010, the senator announced that he was cancer-free. In 2010, Lautenberg's wealth was estimated to be between $55 million and $116.1 million, making him the fifth-wealthiest Senator.Lautenberg began collecting modern art after his election to the Senate, much of which was sold after his death. Lautenberg died atNewYork–Presbyterian Hospitalin Manhattan on June 3, 2013, ofviral pneumonia.He was 89. Lautenberg was returned to Washington by anAmtrakfuneral train. \"Amtrak is honored to be chosen to carry him back to Washington, D.C. one final time,\" wrote Amtrak Chairman Tony Cosica and President/CEOJoseph Boardmanin a joint public statement of condolence, \"thank you Sen. Lautenberg for your service to the nation.\" On June 6, 2013, his bodylay in reposeatop theLincoln Catafalquewithin the Senate chamber at the Capitol.He was buried on June 7, 2013, with full military honors atArlington National Cemetery. Congress passed on September 20, 2013, a spending bill, H.J.Res.59 – Continuing Appropriations Resolution, 2014, that included a $174,000 tax-free death benefit payment to his widow. An annual salary payment to the widow or family member of a deceased lawmaker is a long-standing tradition for theUnited States Congressgoing back to the 1800s. On June 4, 2013, GovernorChris Christieannounced that aspecial electionto fill the vacant Senate seat would be held on October 16, 2013. A special primary, which was won byCory Bookeras theDemocratandSteve Loneganas theRepublicancandidate, was held on August 13, 2013. On June 6, 2013, Christie appointed RepublicanNew Jersey Attorney GeneralJeffrey Chiesato fill the Senate seat until the elected winner could be sworn in. On October 17, 2013, Democrat Cory Booker was announced the winner of the special election. He has held the seat ever since. TheFrank R. Lautenberg Deep-Sea Coral Protection Areais an offshoremarine protected areafordeep-sea coralsoff the coast of theMid-Atlantic statesof the United States, established in 2016 and named after Lautenberg. The results for Lautenberg's elections to the US Senate:", "metadata": {"url": "https://en.wikipedia.org/wiki/Frank_Lautenberg", "title": "Frank Lautenberg", "headings": ["Contents", "Early life and career", "U.S. Senator", "Early years", "2002 election", "Back in the Senate", "2008 election", "Final years", "Committee assignments", "Political positions and votes", "Personal life", "Family", "Health", "Wealth", "Death", "Succession", "Frank R. Lautenberg Deep-Sea Coral Protection Area", "Electoral history", "See also", "Sources", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Frank_Lautenberg", "https://en.wikipedia.org/wiki/Frank_Lautenberg", "https://en.wikipedia.org/wiki/Frank_Lautenberg", "https://en.wikipedia.org/wiki/United_States_Senate", "https://en.wikipedia.org/wiki/New_Jersey", "https://en.wikipedia.org/wiki/Robert_Torricelli", "https://en.wikipedia.org/wiki/Jeffrey_Chiesa", "https://en.wikipedia.org/wiki/Nicholas_F._Brady"]}},
{"id": "08cfc4964371", "content": " Sandra Day O'Connor(March 26, 1930 – December 1, 2023) was an American attorney, politician, and jurist who served as anassociate justice of the Supreme Court of the United Statesfrom 1981 to 2006. Nominated by PresidentRonald Reagan, O'Connor was the first woman to serve as a U.S. Supreme Court justice.Amoderate conservative, she was considered aswing vote. Before O'Connor's tenure on the Court, she was anArizona state judgeand earlier an elected legislator inArizona, serving as the first female majority leader of a state senate as theRepublicanleader in theArizona Senate.Upon her nomination to the Court, O'Connor was confirmed unanimously by theUnited States Senate. O'Connor usually sided with the Court's conservative bloc but on occasion sided with the Court's liberal members. She often wroteconcurring opinionsthat sought to limit the reach of the majority holding. Hermajority opinionsin landmark cases includeGrutter v. BollingerandHamdi v. Rumsfeld. In 2000, she wrote in part theper curiammajority opinion inBush v. Goreand in 1992 was one of three co-authors of the lead opinion inPlanned Parenthood v. Caseythat preserved legal access toabortion in the United States. On July 1, 2005, O'Connor announced her retirement, effective upon the confirmation of a successor.At the time of her death, O'Connor was the last living member of theBurger Court.Samuel Alito was nominatedto take her seat in October 2005, and joined the Supreme Court on January 31, 2006. During her term on the Court, O'Connor was regarded as among the most powerful women in the world.After retiring, she succeededHenry Kissingeras thechancellor of the College of William & Mary. In 2009, she was awarded thePresidential Medal of Freedomby PresidentBarack Obama. Sandra Day was born on March 26, 1930, inEl Paso, Texas, the daughter of Harry Alfred Day, arancher, and Ada Mae (Wilkey).She grew up on a 198,000-acre familycattle ranchnearDuncan, Arizonaand in El Paso, where she attended school. Her home was nine miles from the nearest paved road.It lacked running water or electricity until Sandra was seven years old.As acowgirlshe owned a .22-caliber rifle and would shootcoyotesandjackrabbits.She began driving as soon as she could see over the dashboard and had to learn to change flat tires herself.Sandra had two younger siblings, a sister and a brother, respectively eight and ten years her junior.Her sisterAnn Daywas a member of theArizona Legislaturefrom 1990 to 2000.Her brother was H. Alan Day, a lifelong rancher, with whom she wroteLazy B: Growing up on a Cattle Ranch in the American Southwest(2002), about their childhood experiences on the ranch.For most of her early schooling, Day lived in El Paso with her maternal grandmother.She went to the Radford School for Girls, a private school,because the family ranch was far from schools. Day was able to return to the ranch for holidays and the summer.Day did spend her eighth-grade year living at the ranch and riding a bus 32 miles to school.She graduated sixth in her class atAustin High SchoolinEl Pasoin 1946. Accepted intoStanford Universityat age 16, O'Connor earned aB.A.in economics in 1950, graduatingmagna cum laude. Inspired by Professor Harry Rathbun, she pursued a law degree atStanford Law School, graduating near the top of her class in 1952.While attending, she served on theStanford Law Reviewwhose then presiding editor-in-chief was futureSupreme Court chief justiceWilliam Rehnquist.Day achieved theOrder of the Coif, indicating she was in the top 10 percent of her class. While in her final year at Stanford Law School, Day began datingJohn Jay O'Connor III, who was one class year behind her.On December 20, 1952, six months after her graduation, O'Connor and Day married at her family's ranch. Upon graduation from law school in 1952, O'Connor had difficulty finding a paying job as an attorney in a law firm because of hergender.O'Connor found employment as a deputy county attorney inSan Mateo, California, after she offered to work for no salary and without an office, sharing space with a secretary.After a few months, she began drawing a small salary as she performed legal research and wrote memos.She worked withSan Mateo CountyDistrict AttorneyLouis Dematteis and deputy district attorney Keith Sorensen. When her husband was drafted, O'Connor decided to go with him to work in Germany as a civilian attorney for the Army'sQuartermaster Corps.They remained there for three years before returning to the States where they settled inMaricopa County, Arizona, and she started a law firm.They had three sons: Scott (born 1958), Brian (born 1960), and Jay (born 1962).Following Brian's birth, O'Connor took a five-year hiatus from the practice of law. She volunteered in various political organizations, such as the Maricopa County Young Republicans, and served on Arizona SenatorBarry Goldwater'spresidential campaignin 1964. O'Connor served as assistantAttorney General of Arizonafrom 1965 to 1969.In 1969, the governor of Arizona appointed O'Connor to fill a vacancy in theArizona Senate.She ran for and won the election for the seat the following year.By 1973, she became the first woman to serve as Arizona's or any state'smajority leader.She developed a reputation as a skilled negotiator and a moderate. After serving two full terms, O'Connor decided to leave the Senate. In 1974, O'Connor was appointed to theMaricopa County Superior Court,serving from 1975 to 1979 when she was elevated to theArizona Court of Appeals. In late 1977 and early 1978, she presided over anaggravated assaultcase againstClarence Dixon, a 22-year-oldArizona State Universitystudent who had attacked a 15-year-old girl with a metal pipe. O'Connor would find Dixonnot guilty by reason of insanityand have him remanded to a state hospital. In the four-day period between  O'Connor's ruling and Dixon's remanding to hospital, Dixon would rape and murder one of his seniors, 21-year-old Deana Lynne Bowdoin; he would not be arrested until 2001 when DNA evidence identified him, and he was executed for Bowdoin's murder in 2022. She served on the Court of Appeals-Division One until 1981 when she was appointed to the Supreme Court by PresidentRonald Reagan. On July 7, 1981, Reagan – who had pledged during his1980 presidential campaignto appoint the first woman to the Court– announced he would nominate O'Connor as an associate justice of the Supreme Court to replace the retiringPotter Stewart.O'Connor received notification from President Reagan of her nomination on the day prior to the announcement and did not know that she was a finalist for the position. Reagan wrote in his diary on July 6, 1981: \"Called Judge O'Connor and told her she was my nominee for supreme court. Already the flak is starting and from my own supporters.Right to Lifepeople say she is pro abortion. She declares abortion is personally repugnant to her. I think she'll make a good justice.\"O'Connor told Reagan she did not remember whether she had supported repealingArizona's law banning abortion.However, she had cast a preliminary vote in the Arizona State Senate in 1970 in favor of a bill to repeal the state's criminal-abortion statute.In 1974, O'Connor had opined against a measure to prohibit abortions in some Arizona hospitals.Anti-abortionandreligious groupsopposed O'Connor's nomination because they suspected, correctly, she would not be willing to overturnRoe v. Wade.U.S. Senate Republicans, includingDon NicklesofOklahoma,Steve SymmsofIdaho, andJesse HelmsofNorth Carolinacalled theWhite Houseto express their discontent over the nomination; Nickles said he and \"other profamily Republican senators would not support O'Connor\".Helms, Nickles, and Symms nevertheless reluctantly voted for confirmation. Reagan formally nominated O'Connor on August 19, 1981.Conservative activists such as the ReverendJerry Falwell,Howard Phillips, and Peter Gemma also spoke out against the nomination. Gemma called the nomination \"a direct contradiction of the Republicanplatformto everything that candidate Reagan said and even President Reagan has said in regard to social issues.\"Gemma, the executive director of theNational Pro-Life Political Action Committee, had sought to delay O'Connor's confirmation by challenging her record, including support for theEqual Rights Amendment. O'Connor's confirmation hearing before theSenate Judiciary Committeebegan on September 9, 1981.It was the first televised confirmation hearing for a Supreme Court justice.The confirmation hearing lasted three days and largely focused on the issue of abortion.When asked, O'Connor refused to telegraph her views on abortion, and she was careful not to leave the impression that she supportedabortion rights.The Judiciary Committee approved O'Connor with seventeen votes in favor and one vote of present. On September 21, O'Connor wasconfirmed by the U.S. Senatewith a vote of 99–0.Only SenatorMax Baucusof Montana was absent from the vote. He sent O'Connor a copy ofA River Runs Through Itby way of apology.In her first year on the Court, she received over 60,000 letters from the public, more than any other justice in history. O'Connor said she felt a responsibility to demonstrate women could do the job of justice.She faced some practical concerns, including the lack of a women's restroom near the Courtroom. Two years after O'Connor joined the Court,The New York Timespublished an editorial that mentioned the \"nine men\"of the \"SCOTUS\", or Supreme Court of the United States.O'Connor responded with a letter to the editor reminding theTimesthat the Court was no longer composed of nine men and referred to herself as FWOTSC (First Woman on the Supreme Court). O'Connor was a proponent of collegiality among justices on the court, often insisting that the justices eat lunch together. In 1993,Ruth Bader Ginsburgbecame the second female Supreme Court justice.O'Connor said that she felt relief from the media clamor when she no longer was the only woman on the Court.In May 2010, O'Connor warned female Supreme Court nomineeElena Kaganabout the \"unpleasant\" process of confirmation hearings. Initially, O'Connor's voting record aligned closely with the conservativeWilliam Rehnquist(voting with him 87% of the time during her first three years at the Court).From that time until 1998, O'Connor's alignment with Rehnquist ranged from 93.4% to 63.2%, hitting above 90% in three of those years.In nine of her first 16 years on the Court, O'Connor voted with Rehnquist more than with any other justice. Later on, as the Court's make-up became more conservative (e.g.,Anthony KennedyreplacingLewis Powell, andClarence ThomasreplacingThurgood Marshall), O'Connor often became theswing voteon the Court. However, she usually disappointed the Court's more liberal bloc in contentious 5–4 decisions: from 1994 to 2004, she joined the traditional conservative bloc of Rehnquist,Antonin Scalia,Anthony Kennedy, and Thomas 82 times; she joined the liberal bloc ofJohn Paul Stevens,David Souter,Ruth Bader Ginsburg, andStephen Breyeronly 28 times. O'Connor's relatively smallshift away from conservatives on the Court seems to have been due at least in part to Thomas' views.When Thomas and O'Connor were voting on the same side, she would typically write a separate opinion of her own, refusing to join his.In the 1992 term, O'Connor did not join a single one of Thomas's dissents. Some notable cases in which O'Connor joined the majority in a 5–4 decision were: O'Connor played an important role in other notable cases, such as: On February 22, 2005, with Rehnquist and Stevens (who were senior to her) absent, she became the senior justice presiding over oral arguments in the case ofKelo v. City of New Londonand becoming the first woman to do so before the Court. O'Connor was unpredictable in many of her court decisions, especially those regarding First AmendmentEstablishment Clauseissues. Barry Lynn, executive director ofAmericans United for Separation of Church and State, said, \"O'Connor was a conservative, but she saw the complexity of church-state issues and tried to choose a course that respected the country's religious diversity\" (Hudson 2005). O'Connor voted in favor of religious institutions, such as inRosenberger v. University of Virginia(1995),Mitchell v. Helms(2000), andZelman v. Simmons-Harris(2002). Conversely, inLee v. Weismanshe was part of the majority in the case that saw religious prayer and pressure to stand in silence at a graduation ceremony as part of a religious act that coerced people to support or participate in religion, which the Establishment Clause strictly prohibits. This is consistent with a similar case,Santa Fe Independent School District v. Doe, involving prayer at a school football game. In this case, O'Connor joined the majority opinion that stated prayer at school football games violates the Establishment Clause. O'Connor was the first justice to articulate the \"no endorsement\" standard for the Establishment Clause.InLynch v. Donnelly, O'Connor signed onto a five-justice majority opinion holding that a nativity scene in a public Christmas display did not violate the First Amendment. She penned a concurrence in that case, opining that the crèche did not violate the Establishment Clause because it did not express an endorsement or disapproval of any religion.InBoard of County Commissioners, Wabaunsee County, Kansas v Umbehr(1996) she upheld the application of first amendment free speech rights to independent contractors working for public bodies, being unpersuaded \"that there is a 'difference of constitutional magnitude' ... between independent contractors and employees\" in circumstances where a contractor has been critical of a governing body. According to law professorJeffrey Rosen, \"O'Connor was an eloquent opponent of intrusive group searches that threatened privacy without increasing security. In a1983 opinionupholding searches by drug-sniffing dogs, she recognized that a search is most likely to be consideredconstitutionally reasonableif it is very effective at discoveringcontrabandwithout revealinginnocent but embarrassinginformation.\"Washington College of Lawprofessor Andrew Taslitz, referencing O'Connor'sdissentin a2001 case, said of herFourth Amendmentjurisprudence: \"O'Connor recognizes that needless humiliation of an individual is an important factor in determining Fourth Amendment reasonableness.\"O'Connor once quoted thesocial contract theoryofJohn Lockeas influencing her views on the reasonableness and constitutionality of government action. InMcCleskey v. Kemp(1987), O'Connor joined a 5–4 majority that voted to uphold the death penalty for an African American man, Warren McCleskey, convicted of killing a white police officer, despite statistical evidence that Black defendants were more likely to receive the death penalty than others both in Georgia and in the U.S. as a whole. In the 1990 and 1995Missouri v. Jenkinsrulings, O'Connor voted with the majority that Federal district courts had no authority to require the state of Missouri to increase school funding to counteract racial inequality. In the 1991 caseFreeman v. Pitts, O'Connor joined a concurring opinion in a plurality, agreeing that a school district that had formerly been under judicial review forracial segregationcould be freed of this review, even though not alldesegregationtargets had been met. Law professor Herman Schwartz criticized these rulings, writing that in both cases \"both the fact and effects of segregation were still present\". In 1996'sShaw v. HuntandShaw v. Reno, O'Connor joined a Rehnquist opinion, following an earlier precedent from an opinion she authored in 1993, in which the Court struck down an electoral districting plan designed to facilitate the election of two Black representatives out of 12 from North Carolina, a state that had not had any Black representative sinceReconstruction, despite being approximately 20% Black– the Court held that the districts were unacceptablygerrymanderedand O'Connor called the odd shape of the district in question,North Carolina's 12th, \"bizarre\". Law professor Herman Schwartz called O'Connor \"the Court's leader in its assault on racially orientedaffirmative action\",although she joined with the Court in upholding the constitutionality of limited race-based admissions to universities. In 2003, O'Connor authored a majority Supreme Court opinion (Grutter v. Bollinger) saying racial affirmative action should not be constitutional permanently, but long enough to correct past discrimination – with an approximate limit of around 25 years. TheChristian rightelement in the Reagan coalition strongly supported him in 1980, in the belief that he would appoint Supreme Court justices to overturnRoe v. Wade. They were astonished and dismayed when his first appointment was O'Connor, who they feared would tolerate abortion. They worked hard to defeat her confirmation but failed.In her confirmation hearings and early days on the Court, O'Connor was carefully ambiguous on the issue of abortion, as some conservatives questioned heranti-abortioncredentials based on some of her votes in the Arizona legislature.O'Connor generally dissented from 1980s opinions which took an expansive view ofRoe v. Wade; she criticized that decision's \"trimester approach\" sharply in her dissent inCity of Akron v. Akron Center for Reproductive Health(1983). She criticizedRoeinThornburgh v. American College of Obstetricians and Gynecologists(1986): \"I dispute not only the wisdom but also the legitimacy of the Court's attempt to discredit and pre-empt state abortion regulation regardless of the interests it serves and the impact it has.\"In 1989, O'Connor stated during the deliberations over theWebstercase that she would not overruleRoe.While on the Court, O'Connor did not vote to strike down any restrictions on abortion untilHodgson v. Minnesotain 1990. O'Connor allowed certain limits to be placed on access to abortion, but supported the right to abortion established byRoe. In the landmark rulingPlanned Parenthood v. Casey(1992), O'Connor used a test she had originally developed inCity of Akron v. Akron Center for Reproductive Healthto limit the holding ofRoe v. Wade, opening up a legislative portal where a State could enact measures so long as they did not place an \"undue burden\" on a woman's right to an abortion.Caseyrevised downward the standard of scrutiny federal courts would apply to state abortion restrictions, a major departure fromRoe. However, it preservedRoe's core constitutional precept: that theFourteenth Amendmentimplies and protects a woman's fundamental right to control the outcomes of her reproductive actions. Writing the plurality opinion for the Court, O'Connor, along with Kennedy and Souter, famously declared: \"At the heart of liberty is the right to define one's own concept of existence, of meaning, of the universe, and of the mystery of human life. Beliefs about these matters could not define the attributes of personhood were they formed under compulsion of the State.\" O'Connor's case-by-case approach routinely placed her in the center of the Court and drew both criticism and praise.Washington PostcolumnistCharles Krauthammer, for example, described her as lacking a judicial philosophy and instead displaying \"political positioning embedded in a social agenda.\"Conservative commentatorRamesh Ponnuruwrote that, even though O'Connor \"has voted reasonably well\", her tendency to issue very case-specific rulings \"undermines the predictability of the law and aggrandizes the judicial role.\" Law clerks serving the Court in 2000 speculated that the decision she reached inBush v. Gorewas based on a desire to appear fair, rather than on any legal rationale, pointing to a memo she sent out the night before the decision was issued that used entirely different logic to reach the same result. They also characterized her approach to cases as deciding on \"gut feelings\". In 2003, she wrote a book titledThe Majesty of the Law: Reflections of a Supreme Court Justice(ISBN0-375-50925-9).In 2005, she wrote a children's book,Chico: A True Story from the Childhood of the First Woman Supreme Court Justice, named for her favorite horse, which offered an autobiographical depiction of her childhood. On December 12, 2000,The Wall Street Journalreported that O'Connor was reluctant to retire with a Democrat in the presidency: \"At an Election Night party at the Washington, D.C., home of Mary Ann Stoessel, widow of former AmbassadorWalter Stoessel, the justice's husband, John O'Connor, mentioned to others her desire to step down, according to three witnesses. But Mr. O'Connor said his wife would be reluctant to retire if a Democrat were in the White House and would choose her replacement. Justice O'Connor declined to comment.\" By 2005, the composition of the Court had been unchanged for eleven years, the second-longest period in American history without any such change. Rehnquist was widely expected to be the first justice to retire during Bush's term, owing to his age and his battle with cancer, although rumors of O'Connor's possible retirement circulated as well. On July 1, 2005, O'Connor announced her intention to retire. In her letter to Bush, she stated that her retirement from active service would take effect upon the confirmation of her successor.Her letter did not provide a reason for her departure; however, a Supreme Court spokeswoman confirmed O'Connor was leaving to spend time with her husband. On July 19, Bush nominatedD.C. CircuitJudgeJohn Robertsto succeed O'Connor. O'Connor heard the news over the car radio on the way back from a fishing trip.She described Roberts soon after the nomination as \"good in every way, except he's not a woman\". O'Connor had expected to leave the Court before the next term started on October 3, 2005.However, Rehnquist died on September 3,creating an immediate vacancy on the Court.Two days later, Bush withdrew Roberts as his nominee for her seat and instead appointed him to fill the vacant office of Chief Justice.O'Connor agreed to stay on the Court until her replacement was named and confirmed.She spoke at the late chief justice's funeral.On October 3, Bush nominatedWhite House CounselHarriet Miersto replace O'Connor.After muchcriticism and controversyover her nomination, on October 27, Miers asked Bush to withdraw her nomination.Bush accepted, reopening the search for O'Connor's successor. The continued delays in confirming a successor further extended O'Connor's time on the Court.She continued to hear oral argument on cases, including cases dealing with controversial issues such asphysician-assisted suicideand abortion.O'Connor's last Court opinion,Ayotte v. Planned Parenthood of New England, written for a unanimous court, was a procedural decision that involved a challenge to a New Hampshire abortion law. On October 31, Bush nominatedThird CircuitJudgeSamuel Alitoto replace O'Connor;Alito was confirmed by a 58–42 vote and was sworn in on January 31, 2006.After retiring, she continued to hear cases and rendered over a dozen opinions in federal appellate courts across the country, filling in as a substitute judge when vacations or vacancies left their three-member panels understaffed.On Alito's nomination, O'Connor said, \"I've often said, it's wonderful to be the first to do something but I didn't want to be the last. If I didn't do a good job, it might've been the last and indeed when I retired, I was not replaced, then, by a woman which gives one pause to think 'Oh, what did I do wrong that led to this.'\" In her retirement, O'Connor continued to speak and organize conferences on the issue ofjudicial independence.During a March 2006 speech atGeorgetown University, O'Connor said some political attacks on the independence of the courts pose a direct threat to the constitutional freedoms of Americans. She said, \"Any reform of the system is debatable as long as it is not motivated by retaliation for decisions that political leaders disagree with.\" She also noting that she was \"against judicial reforms driven by nakedly partisan reasoning\".\"Courts interpret the law as it was written, not as the congressmen might have wished it was written\", and \"it takes a lot of degeneration before a country falls into dictatorship, but we should avoid these ends by avoiding these beginnings.\" On November 19, 2008, O'Connor published an introductory essay on a themed judicial accountability issue in theDenver University Law Review. She called for a better public understanding of judicial accountability.On November 7, 2007, at a conference on her landmark opinion inStrickland v. Washington(1984) sponsored by theConstitution Project, O'Connor highlighted the lack of proper legal representation for many of the poorest defendants.O'Connor also urged the creation of a system for \"merit selection for judges\", a cause for which she had frequently advocated. On August 7, 2008, O'Connor andAbdurrahman Wahid, formerPresident of Indonesia, wrote an editorial in theFinancial Timesstating concerns about the threatened imprisonment of Malaysian opposition leaderAnwar Ibrahim. In October 2008, O'Connor spoke on racial equality in education at a conference hosted by the Charles Hamilton Houston Institute for Race and Justice atHarvard Law School. Later in the conference, she was awarded the Charles Hamilton Houston Justice Award alongsideDesmond TutuandDolores Huerta. Following the Court'sCitizens United v. Federal Election Commissiondecision on corporate political spending, O'Connor offered measured criticism of the decision, telling Georgetown law students and lawyers, \"that the Court has created an unwelcome new path for wealthy interests to exert influence on judicial elections.\" O'Connor argued in favor of PresidentBarack Obamanaming the replacement forAntonin Scaliain February 2016, mere days after Scalia's death, opposing Republican arguments that the next president should get to fill the vacancy. She said, \"I think we need somebody there to do the job now and let's get on with it. ... You just have to pick the best person you can under the circumstances, as the appointing authority must do. It's an important position and one that we care about as a nation and as a people. And I wish the president well as he makes choices and goes down that line. It's hard.\" JudgeWilliam H. Pryor Jr., a conservative jurist, has criticized O'Connor's speeches and op-eds for hyperbole and factual inaccuracy, based in part on O'Connor's opinions as to whether judges face a rougher time in the public eye today than in the past. O'Connor reflected on her time on the Supreme Court by saying that she regretted the Court hearing theBush v. Gorecase in 2000 because it \"stirred up the public\" and \"gave the Court a less-than-perfect reputation\". She told theChicago Tribunethat \"maybe the Court should have said, 'We're not going to take it, goodbye,' ... It turned out the election authorities in Florida hadn't done a real good job there and kind of messed it up. And probably the Supreme Court added to the problem at the end of the day\". As a retired Supreme Court justice, O'Connor continued to receive a full salary, maintained a staffed office with at least one law clerk, and heard cases on a part-time basis in federaldistrict courtsandcourts of appealsas avisiting judge.By 2008, O'Connor had sat for cases with the2nd,8th, and9th Circuits.O'Connor heard an Arizona voting rights case which the Supreme Court later reviewed.InArizona v. Inter Tribal Council of Arizona, a 7–2 majority affirmed O'Connor and the rest of 9th Circuit panel, and struck down a provision of Arizona's voting registration law.O'Connor hired a law clerk for the October 2015 term, but did not hire a law clerk for the subsequent term. O'Connor was elected as an honorary fellow of theNational Academy of Public Administrationin 2005.In October that year,   O'Connor accepted the largely ceremonial role of becoming the 23rd Chancellor of theCollege of William & Mary.O'Connor continued in the role until 2012.O'Connor was a member of the 2006Iraq Study Group, appointed by the U.S. Congress.From 2006, she was a trustee on the board of theRockefeller Foundation.O'Connor chaired theJamestown 2007celebration, commemorating the 400th anniversary of the founding of the colony atJamestown, Virginia, in 1607.The Sandra Day O'Connor Project on the State of the Judiciary, named for O'Connor, held annual conferences from 2006 through 2008 on the independence of the judiciary.O'Connor was a member of both theAmerican Philosophical Societyand theAmerican Academy of Arts and Sciences. In 2006, O'Connor taught a course on the Supreme Court at theUniversity of Arizona'sJames E. Rogers College of Lawas a distinguished jurist in residence.On April 5, 2006,Arizona State Universitynamed its law school theSandra Day O'Connor College of Lawin her honor. O'Connor wrote the 2013 bookOut of Order: Stories from the History of the Supreme Court. On May 15, 2006, O'Connor gave the commencement address at theWilliam & Mary School of Law, where she said that judicial independence is \"under serious attack at both the state and national level\".In 2008, O'Connor was named an inauguralHarry RathbunVisiting Fellow by the Office for Religious Life atStanford University. On April 22, 2008, she gave \"Harry's Last Lecture on a Meaningful Life\" in honor of the former Stanford Law professor who shaped her undergraduate and law careers.On September 17, 2014, O'Connor appeared on the television showJeopardy!and provided a couple of video answers to the category 'Supreme Court' which appeared on the show. On the same day inConcord, New Hampshire, she gave a talk alongside her former colleagueJustice David Souterabout the importance of meaningful civics education in the United States. In February 2009, O'Connor launched Our Courts, a website she created to offer interactive civics lessons to students and teachers because she was concerned about the lack of knowledge among most young Americans about how their government works. She also served as a co-chair withLee H. Hamiltonfor the Campaign for the Civic Mission of Schools.On March 3, 2009, O'Connor appeared on thesatiricaltelevision programThe Daily ShowwithJon Stewartto promote the website. In August 2009, the website added two online interactive games.The initiative expanded, becomingiCivicsin May 2010 offering free lesson plans, games, and interactive videogames for middle and high school educators.By 2015, the iCivics games had 72,000 teachers as registered users and its games had been played 30 million times. O'Connor served on the board of trustees of theNational Constitution Centerin Philadelphia, a museum dedicated to the U.S. Constitution.By November 2015, O'Connor had transitioned to being a trustee emeritus for the center.In April 2013, the board of directors ofJustice at Stake, a national judicial reform advocacy organization, announced that O'Connor would be joining the organization as honorary chair. In 2009, O'Connor founded the 501(c)(3) non-profit organization now known as theSandra Day O'Connor Institute. Its programs are dedicated to promoting civil discourse, civic engagement, and civics education.In 2019, her formeradoberesidence in Arizona, curated by the O'Connor Institute, was listed on theNational Register of Historic Places.In 2022, the Institute launched Civics for Life, its multigenerational digital platform. O'Connor was a member and president of theJunior Leagueof Phoenix. O'Connor was a founding co-chair of the National Advisory Board at the National Institute for Civil Discourse (NICD).The institute was created at the University of Arizona after the2011 shootingof former CongresswomanGabby Giffordsthat killed six people and wounded 13 others. Upon her appointment to the Supreme Court, O'Connor and her husband moved to theKaloramaarea of Washington, D.C. The O'Connors became active in the Washington, D.C. social scene. O'Connor played tennis and golf in her spare time.She was abaptizedmember of theEpiscopal Church. O'Connor was successfullytreated for breast cancerin 1988, and she also had herappendixremovedthat year.That same year, John O'Connor left the Washington, D.C., law firm of Miller & Chevalier for a practice that required him to split his time between Washington, D.C. and Phoenix. Her husband suffered fromAlzheimer's diseasefor nearly 20 years, until his death in 2009,and she became involved in raising awareness of the disease. After retiring from the Court, O'Connor moved back to Phoenix, Arizona. Around 2013, O'Connor's friends and colleagues noticed that she was becoming more forgetful and less talkative.By 2017, back problems led to her needing to use a wheelchair, and to her moving to an assisted living facility.In October 2018, O'Connor announced her effective retirement from public life after disclosing that she had been diagnosed with the early stages ofdementia. On May 7, 2016, her younger sister,Ann Day, was killed in a car accident inTucson, Arizona, as a result of a collision with a drunk driver. On December 1, 2023, O'Connor died in Phoenix, at the age of 93, due to complications related to advanced dementia and arespiratory illness.After her death, Chief JusticeJohn Robertscalled her \"an eloquent advocate for civil education\" and a \"fiercely independent defender of the rule of law\" in a public statement.PresidentJoe Bidensaid she was an \"American icon\", dedicated to public service and the \"bedrock American principle of an independent judiciary\".iCivicsboard chairman Larry Kramer said that O'Connor was \"kind and generous\" and relayed that iCivics was her \"brainchild\". O'Connorlay in reposein the Great Hall of the Supreme Court on December 18, 2023.She was memorialized the following day in a funeral service held at theWashington National Cathedral. O'Connor was particularly remembered for being the first woman on the Court, and for functioning as the swing vote in the 5–4 decision inBush v. Gore, which handed the presidency to George W. Bush.Overall, she began her tenure on the court as a Reaganite but would later attempt to steer the court toward decisions that better aligned with public opinion.Some argue that O'Connor's jurisprudential legacy was largely undone by the appointment of Samuel Alito as her successor. In March 2019, historian and journalist Evan Thomas published a memoir detailing O'Connor's life, pulling from interviews and her archives, and becoming aNew York TimesBestseller and finalist for theLos Angeles TimesBook Prize.", "metadata": {"url": "https://en.wikipedia.org/wiki/Sandra_Day_O%27Connor", "title": "Sandra Day O'Connor", "headings": ["Contents", "Early life and education", "Early career and marriage", "Supreme Court career", "Nomination and confirmation", "Tenure", "Supreme Court jurisprudence", "Other activities while serving on the Court", "Retirement", "Post-Supreme Court career", "Activities and memberships", "Personal life, illness and death", "Legacy and awards", "See also", "Explanatory notes", "References", "Citations", "Bibliography", "Further reading", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Sandra_Day_O%27Connor", "https://en.wikipedia.org/wiki/Sandra_Day_O%27Connor", "https://en.wikipedia.org/wiki/Sandra_Day_O%27Connor", "https://en.wikipedia.org/wiki/Sandra_Day_O%27Connor_(disambiguation)", "https://en.wikipedia.org/wiki/Associate_Justice_of_the_Supreme_Court_of_the_United_States", "https://en.wikipedia.org/wiki/Ronald_Reagan", "https://en.wikipedia.org/wiki/Potter_Stewart", "https://en.wikipedia.org/wiki/Samuel_Alito"]}},
{"id": "6d8ff87f92fc", "content": " TV Guideis an Americandigital mediacompany that providestelevision programlistings informationas well as entertainment and television-related news. In 2008, the company sold its founding product, theTV Guidemagazine and the entire print magazine division, to a privatebuyoutfirm operated byAndrew Nikou, who then set up the print operation as TV Guide Magazine LLC. The prototype of what would becomeTV Guidemagazine was developed by Lee Wagner (1910–1993),who was the circulation director ofMacFadden PublicationsinNew York Cityin the 1930s – and later, by the time of the predecessor publication's creation, forCowles Media Company– distributing magazines focusing on movie celebrities. In 1948, Wagner printed New York City area listings magazineThe TeleVision Guide, which was first released on local newsstands on June 14 of that year. Silent film starGloria Swanson, who then starred in the short-livedvariety seriesThe Gloria Swanson Hour, appeared on the cover of the first issue. Wagner later began publishing regional editions ofThe TeleVision GuideforNew Englandand theBaltimore–Washingtonarea. Five years later, he sold the editions toWalter Annenberg, who folded it into his publishing and broadcasting companyTriangle Publications, but remained as a consultant for the magazine until 1963. The nationalTV Guide's first issue was released on April 3, 1953, accumulating a total circulation of 1,560,000 copies that were sold in the ten U.S. cities where it was distributed. The inaugural cover featured a photograph ofLucille Ball's newborn sonDesi Arnaz Jr., with a downscaled inset photo of Ball placed in the top corner under the issue's headline: \"Lucy's $50,000,000 baby\".The magazine was published indigest size, which remained its printed format for 52 years. From its first issue until the July 2–8, 1954, issue, listings within each edition ofTV Guidebegan on Friday and ended on Thursday; the July 9–16, 1954, issue began on a Friday and ended on the following Friday. Then, beginning with the July 17–23, 1954, issue, the listings in each week's issue changed to start on Saturday and end on Friday, which remained the listings format for all local editions until April 2004.The formation ofTV Guideas a national publication resulted from Triangle Publications' purchase of numerous regional television listing publications such asTV Forecast(which was circulated in theChicagoarea and, upon its first publication on May 9, 1948, was the first continuously published television listings magazine),TV Digest(which was distributed inPhiladelphiaandPittsburgh, and was originally distributed under the title, theLocal Televiser, when it was first released on November 7, 1948), and the New York-basedTelevision Guide(which had its title abbreviated toTV Guideon March 18, 1950).Each of the cities that had their own local TV listings magazine folded intoTV Guidewere among the initial cities where the magazine conducted its national launch. The launch as a national magazine with local listings in April 1953 became an almost instant success.However, the circulation decreased over subsequent weeks, even as the magazine's distribution expanded to five additional cities (Pittsburgh,Rochester,Detroit,ClevelandandSan Francisco) throughout the summer of 1953. By mid-August of that year, sales of the magazine had dropped 200,000 copies below that of the first issue.TV Guide's fortunes began to turn around with the September 4–10, 1953, issue – the magazine's first \"Fall Preview\" issue – when circulation hit 1,746,327 copies; circulation levels increased steadily over time, to the point whereTV Guideeventually became the most read and circulated magazine in the United States by the 1960s.The initial cost of each issue was 15¢ per copy (equivalent to $1.76 in 2024. The price per issue has gradually risen over the years, selling for $4.99 per copy as of 2014). In addition tosubscriptions,TV Guidewas sold at the checkout counters ofgrocery storesnationwide. Until the 1980s, the feature pieces included in each issue were promoted in atelevision commercial. Under Triangle,TV Guidecontinued to grow not only in circulation, but also in recognition as the authority on television programming with articles – the majority of which typically appear in the color section – from both staff and contributing writers. Over the decades, the shape of theTV Guidelogo has changed to reflect the modernization of thetelevision screen, eventually adopting awidescreenappearance in September 2003, and then to its current flatscreen appearance in September 2016 (different versions of the logo – the only cosmetic difference being the utilization of different typefaces – are currently used respectively for the magazine and the separately owned, CBS-managed digital properties). At first, the logo had various colored backgrounds (usually black, white, blue or green) until the familiar red background became the standard in the 1960s with occasional customizations being utilized for special editions. The magazine was first based in a small office in downtown Philadelphia, before moving to more spacious national headquarters inRadnor,Pennsylvania, in the late 1950s. The new facility had a large lightedTV Guidelogo at the building's entrance. It housed management, editors, production personnel and subscription processors as well as a vast computer system holding data on every television show and movie available for listing in the popular weekly publication. Printing of the national color section ofTV Guide– which incorporates television-related stories, and select feature columns such as program reviews – took place at Triangle's Gravure Division plant – which was known for performing some of the highest quality printing in the industry, with almost always perfect registration – located adjacent to the company's landmarkInquirer Buildingon NorthBroad Streetin Philadelphia. The color section was then sent to regional printers to be wrapped around the local listing sections. In addition toTV Guideand its flagship newspaperThe Philadelphia Inquirer, Triangle Publications also owned thePhiladelphia Daily News; ten radio and six television stations (WFIL AM-FM-TVin Philadelphia, WNHCAM-FM-TVinNew Haven, Connecticut, KFREAM-FM-TVinFresno, California,WNBF AM-FM-TVinBinghamton, New York,WFBG AM-FM-TVinAltoona, PennsylvaniaandWLYH-TVinLancaster–Lebanon, Pennsylvania), as well asThe Daily Racing Form;The Morning Telegraph;Seventeen; and variouscable televisioninterests. (It was under Triangle's ownership of WFIL-TV thatAmerican Bandstandcame to popularity, which, in turn, led to hostDick Clarkascending to become a major television personality.) Triangle Publications sold its Philadelphia newspapers toKnight Newspapersin 1969, its radio and television stations during the early 1970s toCapital Cities Communications(the television stations that are now known as KFSN-TV and WPVI-TV were subsequently acquired byABCthrough its 1986 merger with Capital Cities) and various other interests, retaining onlyTV Guide,SeventeenandThe Daily Racing Form. For the magazine's first 52 years of publication, listings information was displayed in a \"log\" format, a mainly text-based list of programs organized by both start time and channel, which was the sole method – eventually, primary onceprime timegridswere incorporated, and later secondary for the final two years of its inclusion of local listings – of displaying program information inTV Guideuntil the switch to national listings in 2005. This allowed for the display of full titles for each program as well as the inclusion of synopses for movies and most programs. Most listing entries in the log included program genres (and for national news programs,anchors) after the program's title, while its running time (which was mentioned only if a program lasted a minimum of one hour – later 35 minutes – in length) was listed (in hours and minutes) in the synopses. Channel numbers were set in a tiny round icon (known as a \"bullet\") at the beginning of the listing. This bullet was soon modified to be the shape of a TV screen, similar to the shape of theTV Guidelogo. In most editions, stations serving a particular edition's immediate local coverage area were denoted with a white numeral for its channel number set inside a black TV-shaped bullet. Stations serving neighboring communities outside the immediate area, but which could also be viewed in the primary local area, were denoted with a black numeral inside a white TV-shaped bullet outlined in black (for example, in theSan Franciscoedition, stations based in San Francisco or Oakland had their channel numbers listed as white-on-black TV-shaped bullets, while stations serving neighboringSacramentoorSalinas/Monterey(but could still be viewed in parts of San Francisco or Oakland, including their suburbs, as fringe reception) had their channel numbers listed as black-on-white icons). A particular listing could begin with as many as three or more channel bullets depending upon the number of stations in the immediate and surrounding areas broadcasting the same program at that particular time (usually different affiliates of the same network, based in the primary city as well as in neighboring areas). See the subsection \"Listings section\", in the \"Editions\" section below, for a detailed explanation. Originally, the majority of programs listed in the log each issue featured brief synopses, except for local and national newscasts, and programs airing on certain stations in various timeslots. As otherbroadcasttelevision stationsandcable channelswere added, due to set space requirements for the local listings section, detailed synopses were gradually restricted to series andspecials– usually those airing in evening \"prime time\" timeslots – as well as movies airing on broadcast television, while shorter synopses were used for programs seen on broadcast stations outside of the edition's home market and select cable channels; and only the title along with basic supplementary information (such as genre and/or program length) for most other broadcast and cable programs. In addition, black-and-white ads for programs scheduled to air on broadcast stations – and later, cable channels – during prime time (with local airtimes, and for broadcast stations, information fornetwork-affiliated stationsfeatured in the edition which were scheduled to air the advertised show) were included within the listings. Ads for major network programs were generally produced by the networks themselves (and often, the networks would run a full-page or even adouble-truckad for an entire night of programming, or for a major movie or special, or for the season premiere of aSaturday morning cartoonlineup); ads for locally produced programs, including local newscasts, were produced by individual stations (network affiliates as well as independent stations). Such locally provided ads almost always used the distinctive logos used by particular stations (for example, the \"Circle 7\" logo used for many years primarily by stations either owned by, or affiliated with, ABC). (Black-and-white ads for general products, services and special offers, similar to those seen in other national magazines, were also placed in the listings section.) A regular feature of the listings section was \"Close-Up\", usually a half-page segment, which provided expanded reviews of select programs airing each day (various editions of \"Close-Up\" were eventually used for different types of programs, from premieres of new series to shows airing on cable). Over time, other regular and recurring features (most of them television-related) were included alongside the listings including \"Insider\" (a television news and interview section in the lead pages of the color section); \"Cheers and Jeers\" (a critique page about various aspects of television programming); \"Hits and Misses\" (featuring brief reviews of select programs in the coming week, rated on a score from 0 to 10); \"Guidelines\" (a half-page daily section featuring highlights of five or six programs of interest); horoscopes; recaps of the previous week's storylines on network daytimesoap operas; a page reviewing newhome video(and later,DVD) releases; dedicated pages that respectively listed select sporting events, children's programs and \"four-star\" movies being broadcast during that week; and crossword puzzles. Although its issues usually focus on different television-related stories week to week,TV Guidealso incorporates recurring issues that appear a few times each year, most notably the \"Fall Preview\" (an issue featured since the magazine's inaugural year in 1953, which features reviews of new series premiering during the fall television season), \"Returning Favorites\" (first published in 1996, featuring previews of series renewed from the previous television season returning for the upcoming fall schedule), \"Winter Preview\" (first published in 1994 and later known as the \"(year) TV Preview\" from 2006 to 2009, featuring previews ofmidseasonseries) and \"The Best Children's Shows on TV\" (first published in 1989 and later renamed the \"Parents' Guide to Children's Television\" in 1990, and finally as the \"Parent's Guide to Kids' TV\" in 1993, featuring stories and reviews on family-oriented programs). Icons used for other means than identifying listed stations were first added to the magazine around 1956, using the words \"SPECIAL\" and \"COLOR\", each set in capital letters inside a rectangular bar, to denotetelevision specialsand programs broadcast incolor, respectively.TV Guidemodified all icons incorporated into the local listings section in May 1969, changing the font for the TV-shaped bullets identifying local stations fromFuturato the standardHelveticaand using similarly TV-shaped bullets marked with the abbreviation \"C\" to denote color programs (replacing the bar/text icons that had been previously used). As color programming became more ubiquitous, in August 1972, the magazine opted to identify programs originating inblack and white(marked under the abbreviation \"BW\") within the listings section. In September 1981, listings began to identify programs presented withclosed or open captionsor with on-screensign languageinterpretation. Being an era when program episodes tended to be faithfully recurring from week to week, TV Guide listings would make note of alterations from the routine or a change in status: \"[Gunsmoke is pre-empted]\"; \"(last episode of the series)\", \"Debut: \", \"Special\". Until the 1970s, double-feature or triple-feature movie presentations by a station would be listed at the starting time of the first feature: \"MOVIE--Double Feature\", then list the movies with numeric bullets in front of each title and synopsis; subsequent to 1970, the magazine listed each movie in its own time entry. A day's listings continued well past midnight until the last station signed off following prime time programs of the calendar day before, possibly as late as 4:00 a.m. The next day's listings could begin as early as 5:00 a.m., or earlier. The advent of cable television would pose challenges toTV Guide. Cable channels began to be listed in the magazine in 1980 or 1981, depending on the edition; the channels listed also differed with the corresponding edition. Regional and nationalsuperstationsavailable on cable systems in the designated market of many editions were the only cable channels listed initially as well as, in certain markets, over-the-air subscription services transmitted over localindependent stations(such asONTV); local subscription television services were often listed as \"STV Programming\" or \"Subscription Television\" for the channel carrying the service, with the service listed separately or, in some editions, not at all. Cable-originated channels – such asHBO,CNN(both of which the magazine originally promoted mainly in full-page advertisements), the CBN Cable Network (nowFreeform), theAlpha Repertory Television Service(ARTS, later succeeded byA&Ethrough its 1984 merger with The Entertainment Channel) andNickelodeon– were added gradually between the winter of late 1981 and the first half of 1982, depending on the edition. To save page space,TV Guideincorporated a grid (a rowed display of listings for programs scheduled to air during the evening hours each night, primarily organized by channel) into the listings between 1979 and 1981, which was slotted at a random page within each day's afternoon listings. The grid originated as a single-page feature that provided a summary of programs airing during prime time (from 7:00 to 10:00 p.m. or 8:00 to 11:00 p.m. depending on the start of prime time within a giventime zone) on the stations mentioned in the corresponding edition; by 1983, it was expanded to a two-page section – which began to take up roughly three-quarters of the two adjoining pages on which it was placed – that included programs airing during theearly access and late fringeperiods (from 5:00 to 11:00 p.m. or 6:00 p.m. to 12:00 a.m. local time), with the beginning and end of the magazine-defined prime time daypart (between 7:30 and 11:00 p.m. or between 6:30 and 10:00 p.m. local time on Monday through Saturdays, and between 7:00 and 11:00 p.m. or between 6:00 and 10:00 p.m. local time on Sundays) delineated by a thicker border. Channels listed in the grid were organized by broadcast stations, basic cable channels, and premium channels. In 1983, depending on the edition, a new feature was added, the \"Pay-TV Movie Guide\" (renamed the \"Premium Channels Movie Guide\" in 1997), initially preceded the listings before being moved to the pages immediately following the Friday listings in January 1989, resulting in the national section – which had been cordoned into two sections, both preceding and following the local section – being consolidated into the first half of the pages comprising each issue. Preceding this addition, some editions carried The \"Movie Guide\", which also preceded the listings, provided summaries of films scheduled to air over the next one to two weeks on the cable channels included in both the logandgrid listings (excluding those featured exclusively in the grids) as well as a first-page summary of the films scheduled to premiere that week (arranged by channel and sub-categorized by title). As the years went on, more cable channels were added into the listings of each edition. To help offset this, the May 11–17, 1985, issue introduced a smaller Helvetica font for the log, along with some other cosmetic changes; in particular, a show's length began to be listed after the show's title instead of at the end of its synopsis. That issue also saw advertising for local stations featured in the corresponding edition be restricted to certain special events, with most program promotions being restricted to those for national broadcast and cable networks. On August 7, 1988, Triangle Publications was sold to the News America Corporation arm ofNews Corporationfor $3 billion,one of the largest media acquisitions of the time and the most expensive publication transaction at the time. The November 3–9, 1990, issue saw the addition ofVCR Plus+codes in some of the magazine's regional editions, for users with devices incorporating the technology – which was developed by eventualTV Guideparent Gemstar International Group Ltd. – to input into their VCRs to automatically record television programs. (Two-digit PlusCodes corresponding to the channel airing the program that a user wished to record were listed after each channel in the channel directory page; one- to eight-digit codes for individual programs were listed in the log listings section following the title of each program.) The PlusCodes expanded to all local editions beginning with the September 14–20, 1991, issue.The September 12–18, 1992, issue saw the addition of bullet icons identifyingcolorized versions(marked under the abbreviation \"CZ\") of older feature films or television shows. On March 7, 1996,TV Guidelaunched the iGuide, originally developed by the News Corporation-MCIjoint ventureDelphi Internet Service Corp. as aweb portal, which featured more comprehensive television listings data than those offered by the magazine (with information running two weeks in advance of the present date), as well as news content,TV Guideeditorial content and a search feature called CineBooks, which allowed users to access detailed information on about 30,000 film titles. Later that year, content from the print publication was added to iGuide as well as content from News Corporation's other media properties.On January 13, 1997, shortly before MCI bowed out of the venture, iGuide was relaunched as the TV Guide Entertainment Network (TVGEN), which was renamed TV Guide Online in 2002. The refocused site covered television, music, movies and sports (with content concerning the latter sourced fromFox Sports), along with wire news and features fromReuters,Daily Varietyand theNew York Post, free e-mail updates for registered users, and a chat room that was developed to accommodate 5,000 users simultaneously. Additional changes to the listings took place with the September 14–20, 1996 edition of the print publication. Starting with that issue, program titles switched from being displayed in all-uppercase to being shown in a mixed case,Franklin Gothictypeface, film titles – which had previously been displayed within the film description – began appearing before a film's synopsis in an italicized format (replacing the generic \"MOVIE\" header that had been used to identify films since the magazine's inception), and children's programs that were compliant with theChildren's Television Act of 1990began to be designated by a circular \"E/I\" icon. In addition,infomercials(which had been designated under the boilerplate title \"COMMERCIAL PROGRAM[S]\" until 1994, and \"INFORMERCIAL[S]\" thereafter) ceased being listed in the magazine during time periods in which stations aired them. (Time-brokered programs continued to be listed in the magazine, but were primarily restricted to religious programming.) Replacing the text identifiers that had been included within the film synopses, theatrically released films also began to be identified by a black-and-white boxed \"M\" symbol, accompanied depending on the film by itsstar rating(a formula, on a scale of one [for \"poor\"] to four [for \"excellent\"], based on a consensus of reviews from leading film critics, the quality of the film's cast and director, and the film's box office revenue and award wins). Movie icons also were appropriated to identify direct-to-video (marked as \"M→V\") or made-for-TV (marked as \"M→T\") releases, which were not assigned star ratings. Beginning with the January 25–31, 1997, issue, the log listings began incorporating content ratings for programs assigned through the newly implementedTV Parental Guidelinessystem (the content descriptors - the \"DLSV\" system - were subsequently added upon their introduction in October 1998). News Corporation soldTV Guideto the United Video Satellite Group, parent company ofPrevue Networks, on June 11, 1998, for $800 million and 60 million shares of stock worth an additional $1.2 billion (this followed an earlier merger attempt between the two companies in 1996 that eventually fell apart).Following the sale, reports suggested thatTV Guidewould remove program listings from the magazine, shifting them entirely to its new sister cable network Prevue Channel, which would be rebranded as a result of United Video's purchase ofTV Guide Magazine; News Corporation executives later stated that listings information would remain part of the magazine.That year, United Video acquired TVSM Inc. (publishers of competing listings guidesTotal TVandThe Cable Guide) in a $75 million all-cash acquisition; as a result,TV Guidemerged withTotal TV, and began printing a version of the magazine in the latter magazine's full-size format (while retaining the original digest size version) effective with the July 11, 1998, issue. Because most cable systems published their own listing magazine reflecting their channel lineup, and now had a separate guide channel or anelectronic program guidethat can be activated by remote and provide the same information in a more detailed manner – with additional competition coming in the late 1990s from websites that also specialize in providing detailed television program information (such as TVGuide.com, then jointly operated withTV Guide Magazine, andZap2It), a printed listing of programming in a separate magazine became less valuable. The sheer amount and diversity of cable television programming made it hard forTV Guideto provide listings of the extensive array of programming that came directly over the cable system.TV Guidealso could not match the ability of thecable boxto store personalized listings. Nevertheless, beginning with the September 12–18, 1998, issue, the magazine added several new channels to many of its editions, including those that had previously been mentioned only in a foreword on the channel lineup page as well as those that were available mainly ondigital cableand satellite; although most of these newly added channels were placed within the prime time grids, only a few (such asAnimal PlanetandMSNBC) were also incorporated into the log listings. Features in the magazine were also revamped with the additions of \"The Robins Report\" (a review column by writer J. Max Robins), \"Family Page\" (featuring reviews of family-oriented programs) and picks of select classic films airing that week, as well as the removal of the \"Guidelines\" feature in the listings section in favor of the new highlight page \"Don't Miss\" (listing choice programs selected by the magazine's staff for the coming week) in the national color section. Listings for movies within the log also began identifyingmade-for-TVanddirect-to-videofilms, as well as quality ratings on a scale of one to four stars (signifying movies that have received \"poor\" to \"excellent\" reviews). In 1999, the magazine began hosting theTV Guide Awards, an awards show (which was telecast on Fox) honoring television programs and actors, with the winners being chosen byTV Guidesubscribers through a nominee ballot inserted in the magazine. The telecast was discontinued after the 2001 event. The July 17–23, 1999, edition saw the evening grids scaled down to the designated prime time hours, 8:00 to 11:00 p.m. (or 7:00 to 10:00 p.m.) Monday through Saturdays and 7:00 to 11:00 p.m. (or 6:00 to 10:00 p.m.) on Sundays, to complement the descriptive log listings for those time periods; this also allowed the grids to be contained to a single page in certain editions that provided listings for more than 20 cable channels. On October 5, 1999,Gemstar International Group Ltd., the maker of theVCR Plus+device and schedule system (whose channel and program codes forVCRsusing the system for timed recordings were incorporated into the magazine's listings in 1988), and which incidentally was partially owned by News Corporation, purchased United Video Satellite Group. The two companies were previously involved in a legal battle over theintellectual propertyrights for their respective interactive program guide systems, VCR Plus+ andTV Guide On Screen, that began in 1994.That month,TV Guidedebuted a 16-page insert into editions in 22 markets with largeHispanicpopulations titledTV Guide en Español, which provided programming information from nationalSpanish languagenetworks (such asUnivisionandTelemundo) as well as special sections with reviews of the week's notable programs. The magazine discontinued the insert in March 2000 due to difficulties resulting from confusion by advertisers over its marketing as \"the first weekly Spanish-language magazine\", despite its structure as an insert within the mainTV Guidepublication. To commemorate the 50th anniversary ofTV Guideas a national magazine, in 2002, the magazine published six special issues: By 2003, the number of cable channels that were only listed in the grids expanded, with the addition of channels such as BBC America,Soapnetand theNational Geographic Channel(some editions also featured a limited number of broadcast stations – either in-market, out-of-market or both – exclusively in the grids). Conversely, sister cable networkTV Guide Channel(whose listings were added to the magazine after the Gemstar purchase) was relegated from the log listings to the grids in most editions. From its inception until 2003,TV Guidehad offered listings for the entire week, 24 hours a day. Numerous changes to the local listings took place beginning with the June 21, 2003 issue – in just a few select markets, when the 5:00 a.m. to 5:00 p.m. Monday through Friday listings were condensed down to four grids: these ran from 5:00 to 8:00 a.m., 8:00 to 11:00 a.m., 11:00 a.m. to 2:00 p.m., and 2:00 to 5:00 p.m. If programming differed from one weekday to the next, the generic descriptor \"Various Programs\" was listed. The weekday grid maintained day-to-day listings for certain cable channels (primarilymovie channelsas well as a limited number of basic cable channels such asLifetime,The History ChannelandUSA Network), which were organized separately from the other channels. These changes became permanent in allTV Guideeditions beginning with the September 13, 2003, \"Fall Preview\" issue. Other changes were made to the magazine beginning with the June 21 issue in select markets and the 2003 \"Fall Preview\" issue elsewhere. A half-page daily prime time highlights section featuring the evening's notable shows, movies and sports events – similar to the former \"Guidelines\" feature – was re-added to the listings section; a full-page \"Weekday Highlights\" page was also added featuring guest and topical information for the week'sdaytimetalkandmorning showsas well as picks for movies airing during the day on broadcast and cable channels. In addition, while log listings continued in use for prime time listings, program synopses were added to the grids and log, as well as a \"NEW\" indicator for first-run episodes, replacing the \"(Repeat)\" indicator in the log's synopses. The \"Premium Channels Movie Guide\" was also restructured as \"The Big Movie Guide\", with film listings being expanded to include those airing on all broadcast networks and cable channels featured in each edition (as well as some that were not listed in a particular local edition), as well as movies that were available onpay-per-view(page references to the films included in this section were also incorporated into the prime time grids and log listings). Beginning in January 2004, the midnight to 5:00 a.m. listings (as well as the Saturday and Sunday 5:00 to 8:00 a.m. listings) ceased to include any broadcast stations outside of the edition's home market, leaving only program information for stations within the home market and for cable channels. The magazine's format was changed beginning with the April 11, 2004, issue to start the week's listings in each issue on Sunday (the day in which television listings magazines supplemented innewspaperstraditionally began each week's listings information), rather than Saturday. In July 2004, the overnight listings were removed entirely, replaced by a grid that ran from 11:00 p.m. to 2:00 a.m. that included only the broadcast stations in each edition's home market and a handful of cable channels. It also listed a small selection of late-night movies airing on certain channels. The time period of the listings in the daytime grids also shifted from starting at 5:00 a.m. and ending at 5:00 p.m. to running from 7:00 a.m. to 7:00 p.m. By this point, the log listings were restricted to programs airing from 7:00 to 11:00 p.m. In early 2005, more channels were added to the prime time and late-night grids. On July 26, 2005, Gemstar-TV Guide announced thatTV Guidewould abandon its longtime digest size format and begin printing as a larger full-size national magazine that would offer more stories and fewer program listings.All 140 local editions were eliminated, being replaced by two editions covering the time zones within thecontiguous United States: one for theEasternandCentraltime zones, and one for thePacificandMountaintime zones (which had existed separately from the local editions prior to the change, although their distribution was primarily limited tohotels). The change in format was attributed to the increase in theinternet, cable television channels (likeTV Guide Network), electronic program guides anddigital video recordersas the sources of choice for viewers' program listings. The new version ofTV Guidewent on sale on October 17, 2005, and featuredExtreme Makeover: Home EditionhostTy Penningtonon the cover. The listings format, now consisting entirely of grids, also changed to start the listings in each week's issue on Monday rather than Sunday. As a result of the elimination of the local editions, broadcast stations were replaced by broadcast network schedules with the description \"Local Programming\" being used to denote time periods in whichsyndicated, locally produced orpaidprograms would air instead of network shows. In September 2006,TV Guidelaunched a redesignedwebsite, with expanded original editorial and user-generated content not included in the print magazine. On December 22, 2006,TV Guideintroduced the magazine's first ever two-week edition. The edition, which featuredRachael Rayon the cover, was issued for the period fromDecember 25, 2006 to January 7, 2007. In early 2008, the Monday through Friday daytime and daily late night grids were eliminated from the listings section, and the television highlights section was compressed into a six-page review of the week, rather than the previous two pages for each night. By 2007,TV Guide's circulation had decreased to less than three million copies from a peak of almost 20 million in 1970. With the $2.8 billion acquisition of Gemstar-TV Guide byMacrovisionon May 2, 2008,that company, which purchased the former mostly to take advantage of their lucrative and profitable VCR Plus and electronic program guidepatents, stated it wanted to sell both the magazine and TV Guide Network, along with the company'shorse racingchannelTVG Networkto other parties. On May 18, 2005,TV Guide Talk, a weeklypodcastthat was available to download for free, was launched. The podcast was headlined byTV Guidereporter/personalityMichael Ausiello, and was co-hosted by his colleagues at the magazine, Matt Webb Mitovich,Angel Cohn, Daniel Manu andMaitland McDonagh. Each episode featured commentary from TV Guide staff on the week's entertainment news stories, television programs, and film releases, as well as occasional interviews with actors, producers, and executives. On April 4, 2008 (following Ausiello's move toEntertainment Weekly), it was announced that the podcast would be ending,and the final episode (Episode No. 139) was released on April 10, 2008. TV Guide Talkpodcasts were released every Friday afternoon and averaged an hour in length. They featured the participants discussing and commenting on the past week in television and the entertainment industry in general. The beginning of each podcast was devoted to in-depth discussion on the week's biggest new story in the entertainment industry, whether it be a television program or something outside the scope of television show or movie (such as theAcademy Awardsor theEmmys). The middle part was devoted to discussion and commentary on individual shows. The podcast emphasized programs that tend to have a large online following even if that following is not necessarily reflected in the programs' Nielsen rating.  Examples includeAmerican Idol,Heroes,Lost,Survivor,Gilmore Girls,Veronica Mars, andProject Runway(the latter three being examples a low-rated shows which nevertheless have sizable online followings). Each podcast also ended with a weekly review of that weekend's new theatrical releases. On October 13, 2008, Macrovision sold the money-losing magazine (which was reportedly posting revenue losses of $20 million per year by that point) toBeverly Hills-based equity fundOpenGate Capitalfor $1, and a $9.5 million loan at 3% interest.As part of the sale, however, Macrovision retained ownership of the companion website– which was then sold to equity firmOne Equity Partnersfor $300 million –which severed all editorial connections between the magazine and website, including the end of criticMatt Roush's presence on TVGuide.com.The editorial content of the magazine was launched on a new site, TVGuideMagazine.com, which did not featureTV Guide's listings in any form. TVGuideMagazine.com was later shut down on June 1, 2010;TV Guide Magazineand TVGuide.com then entered into a deal to restore content from the magazine to the latter website,whichLionsgate Entertainmenthad bought along with the TV Guide Network in January 2009. In March 2013,CBS Corporationacquired One Equity Partners' stake of their TV Guide assets.The CBS acquisition was finalized later that month for $100 million.On May 31, 2013, CBS bought Lionsgate's share of TV Guide Digital, which includes the website andmobile apps.On January 31, 2014, OpenGate Capital andCBS Interactiveannounced a deal to cross-promoteTV Guide Magazinewith TVGuide.com and CBS Interactive's other internet properties (includingTV.com,MetacriticandCNET). In 2020,Red Venturesacquired the assets of CNET Media Group, including TV Guide, from ViacomCBS. On October 3, 2022, Red Ventures sold TV Guide and other entertainment websites toFandom Inc. In June 1998, theTV Guidebrand and magazine were acquired byUnited Video Satellite Group,the parent company of the Prevue Channel – a channel first launched in 1981 as the Electronic Program Guide network, that was carried by cable and some satellite television providers and was originally formatted to feature ascrolling program guide, short segments featuring previews of upcoming programs, andpromosand short-formfilm trailersfor programs airing on various channels. Its new owners promptly rebranded Prevue as theTV Guide Channelon February 1, 1999. With the rebranding, some of the hourly segments featured on the channel at that point were renamed after features in the magazine, includingTV Guide Close-Up,TV Guide Sportsview(which was formatted more similarly to the listings section's sports guide than the color column of that name) andTV Guide Insider. After Gemstar's acquisition ofTV Guide, the channel began to shift toward airing full-length programs featuring celebrity gossip and movie-focused talk shows alongside the program listings. The channel was rebranded as theTV Guide Networkin 2007. Following the respective sales of TV Guide's magazine and cable channel by Macrovision to OpenGate Capital and Lionsgate,the magazine and TV Guide Network became operationally separate, although the two properties still collaborated on content for TVGuide.com. After CBS Corporation bought stakes in TV Guide's properties in March 2013,TV Guide Network was rebranded under the abbreviated name TVGN that April to de-emphasize its ties toTV Guide Magazine, as part of a transition into a general entertainment format while the channel gradually decommissioned its scrolling listings grid. The network was relaunched as Pop on January 14, 2015,with its programming focus shifting towards shows aboutpop cultureand itsfandom. TV Guide Interactiveis the former name of an interactive electronic program guide software system incorporated intodigital set-top boxesprovided by cable providers. The program listings grid rendered by the software was similar to the late-2000s look of the listings of TV Guide Network/TVGN. Macrovision/Rovi later renamed the product asi-Guideafter the spin-off of the TV Guide publications. A separate IPG system,TV Guide On Screen, was a brand name forGuide Plus+, a build of software featured in products such as televisions,DVDanddigital video recorders, and otherdigital televisiondevicesproviding on-screen program listings. First marketed in the mid-1990s, it was originally owned by Gemstar-TV Guide International before being acquired by theRovi Corporationon December 7, 2007, in a $2.8 billion cash and stock deal.From November 2012 to April 2013, Rovi gradually discontinued broadcast transmission of the Guide Plus+ service. National television listings magazines using theTV Guidename (verbatim or translated into the magazine's language of origin) are also published in other countries, but none of these are believed to be affiliated with theNorth Americanpublication:", "metadata": {"url": "https://en.wikipedia.org/wiki/TV_Guide", "title": "TV Guide", "headings": ["Contents", "Corporate history", "Prototype", "Annenberg/Triangle era", "News Corporation and Gemstar eras", "OpenGate Capital era", "CBS Interactive/CNET era", "Sales to Red Ventures and Fandom Inc.", "Related services", "Television and digital services", "Interactive program guides", "Other usage of theTV Guidename", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/TV_Guide", "https://en.wikipedia.org/wiki/TV_Guide", "https://en.wikipedia.org/wiki/TV_Guide", "https://en.wikipedia.org/wiki/TV_Guide_(magazine)", "https://en.wikipedia.org/wiki/TV_listings", "https://en.wikipedia.org/wiki/TV_Guide_(disambiguation)", "https://en.wikipedia.org/wiki/Mass_media", "https://en.wikipedia.org/wiki/Information_industry"]}},
{"id": "9c4a01098b21", "content": " TheAmerican National Standards Institute(ANSI) is a privatenonprofit organizationthat oversees the development ofvoluntary consensus standardsfor products, services, processes, systems, and personnel in the United States.The organization also coordinates U.S. standards with international standards so that American products can be used worldwide. ANSI accredits standards that are developed by representatives of otherstandards organizations,government agencies,consumer groups, companies, and others. These standards ensure that the characteristics and performance of products are consistent, that people use the same definitions and terms, and that products are tested the same way. ANSI also accredits organizations that carry out product or personnel certification in accordance with requirements defined in international standards. The organization's headquarters are inWashington, D.C.ANSI's operations office is located in New York City. The ANSI annual operating budget is funded by the sale of publications, membership dues and fees, accreditation services, fee-based programs, and international standards programs. Many ANSI regulations areincorporated by referenceinto United States federal statutes (i.e. byOSHAregulations referring to individual ANSI specifications). ANSI does not make these standards publicly available, and charges money for access to these documents; it further claims that it iscopyright infringementfor them to be provided to the public by others free of charge. These assertions have been the subject of criticism and litigation. ANSI was most likely formed in 1918, when five engineering societies and three government agencies founded theAmerican Engineering Standards Committee(AESC).In 1928, the AESC became theAmerican Standards Association(ASA). In 1966, the ASA was reorganized and became theUnited States of America Standards Institute(USASI). In February 1969,Ralph Naderharshly criticized the USASI in public remarks as \"manifestly deceptive\" in several different ways. He specifically attacked the name USASI as improperly implying some kind of official connection with thefederal government of the United States. The present name was adopted in 1969. Prior to 1918, these five founding engineering societies: had been members of the United Engineering Society (UES). At the behest of the AIEE, they invited the U.S. government Departments of War, Navy (combined in 1947 to become theDepartment of Defenseor DOD) and Commerceto join in founding a national standards organization. According to Adam Stanton, the first permanent secretary and head of staff in 1919, AESC started as an ambitious program and little else. Staff for the first year consisted of one executive, Clifford B. LePage, who was on loan from a founding member, ASME. An annual budget of $7,500 was provided by the founding bodies. In 1931, the organization (renamed ASA in 1928) became affiliated with the U.S. National Committee of theInternational Electrotechnical Commission(IEC), which had been formed in 1904 to develop electrical and electronics standards. ANSI's members are government agencies, organizations, academic and international bodies, and individuals. In total, \nthe Institute represents the interests of more than 270,000 companies and organizations and 30 million professionals worldwide. ANSI's market-driven, decentralized approach has been criticized in comparison with more planned and organized international approaches to standardization.  An underlying issue is the difficulty of balancing \"the interests of both the nation's industrial and commercial sectors and the nation as a whole.\" Although ANSI itself does not develop standards, the Institute oversees the development and use of standards by accrediting the procedures of standards developing organizations. ANSI accreditation signifies that the procedures used by standards developing organizations meet the institute's requirements for openness, balance, consensus, and due process. ANSI also designates specific standards as American National Standards, or ANS, when the Institute determines that the standards were developed in an environment that is equitable, accessible and responsive to the requirements of various stakeholders. Voluntary consensus standards quicken the market acceptance of products while making clear how to improve the safety of those products for the protection of consumers. There are approximately 9,500 American National Standards that carry the ANSI designation. The American National Standards process involves: In addition to facilitating the formation of standards in the United States, ANSI promotes the use of U.S. standards internationally, advocates U.S. policy and technical positions in international and regional standards organizations, and encourages the adoption of international standards as national standards where appropriate. The institute is the official U.S. representative to the two major international standards organizations, theInternational Organization for Standardization(ISO), as a founding member,and theInternational Electrotechnical Commission(IEC), via the U.S. National Committee (USNC). ANSI participates in almost the entire technical program of both the ISO and the IEC, and administers many key committees and subgroups. In many instances, U.S. standards are taken forward to ISO and IEC, through ANSI or the USNC, where they are adopted in whole or in part as international standards. Adoption of ISO and IEC standards as American standards increased from 0.2% in 1986 to 15.5% in May 2012. The Institute administers nine standards panels: Each of the panels works to identify, coordinate, and harmonize voluntary standards relevant to these areas. In 2009, ANSI and theNational Institute of Standards and Technology(NIST) formed the Nuclear Energy Standards Coordination Collaborative (NESCC). NESCC is a joint initiative to identify and respond to the current need for standards in the nuclear industry.", "metadata": {"url": "https://en.wikipedia.org/wiki/ANSI", "title": "American National Standards Institute", "headings": ["Contents", "History", "Members", "Process", "International activities", "Standards panels", "American national standards", "See also", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/American_National_Standards_Institute", "https://en.wikipedia.org/wiki/American_National_Standards_Institute", "https://en.wikipedia.org/wiki/American_National_Standards_Institute", "https://en.wikipedia.org/wiki/ANSI_(disambiguation)", "https://en.wikipedia.org/wiki/ASCII", "https://en.wikipedia.org/wiki/Nonprofit_organization", "https://en.wikipedia.org/wiki/501(c)(3)_organization", "https://en.wikipedia.org/wiki/Standards_organization"]}},
{"id": "9cd95403ef42", "content": " World Refrigeration Dayis aninternational dayestablished by theWorld Refrigeration Day SecretariatinDerbyshire, England. Held annually on 26 June, it was created to raise awareness about the importance of refrigeration technologies in everyday life and to raise the profile of the refrigeration, air-conditioning and heat-pump sector.The day was chosen to celebrate the birth date ofLord Kelvinon 26 June 1824. World Refrigeration Day was the idea of refrigeration consultant Stephen Gill, former president of theInstitute of Refrigerationin the UK. In October 2018,ASHRAE(The American Society of Heating, Refrigerating and Air-Conditioning Engineers) pledged support for World Refrigeration Day.In January 2019, ASHRAE awarded Gill it'sJohn F James International Awardin Atlanta.In February 2019, theUnited Nations Environment Programmepledged support at the UNEP national ozone officers meeting in Paris.The inaugural World Refrigeration Day was held on 26 June 2019.", "metadata": {"url": "https://en.wikipedia.org/wiki/World_Refrigeration_Day", "title": "World Refrigeration Day", "headings": ["Contents", "History", "Annual themes", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/World_Refrigeration_Day", "https://en.wikipedia.org/wiki/World_Refrigeration_Day", "https://en.wikipedia.org/wiki/World_Refrigeration_Day", "https://en.wikipedia.org/wiki/Derbyshire", "https://en.wikipedia.org/wiki/William_Thomson,_1st_Baron_Kelvin", "https://en.wikipedia.org/wiki/Institute_of_Refrigeration", "https://en.wikipedia.org/wiki/ASHRAE", "https://en.wikipedia.org/wiki/United_Nations_Environment_Programme"]}},
{"id": "620d13dfe9d9", "content": "Mahidol Universityis anautonomouspublicresearch universityinThailand. The university was founded as part ofSiriraj Hospitalin 1888. It was first called the University of Medical Science in 1943, and has been recognized as Thailand's fourth public university. The university was renamed in 1969 byKing Bhumibol Adulyadejfor his father,Mahidol Adulyadej, known as the \"Father of Modern Medicine and Public Health in Thailand\". Originally focused on thehealth sciences, it has expanded into other fields. The university hosted Thailand's first medical school,Siriraj Medical School.Mahidol offers a range of graduate (primarily international) and undergraduate programs, from the natural sciences to the liberal arts, with remote campuses inKanchanaburi,Nakhon Sawan, andAmnat Charoen provinces. There are a total of 629 programsin 17 faculties, six colleges, nine research institutions and six campuses. The university has the largest budget of any public university in Thailand: $430 million in 2019, most of which is for graduate research programs. Mahidol had an acceptance rate of 0.4 percent in medicine for the 2016 academic year, and was ranked Thailand's number-one university in 2011 by QS Asian University Rankings. The first Thai medical school, Bhatayakorn School (Thai:โรงเรียนแพทยากร), was founded with a royal decree by KingChulalongkornin 1888. At the former palace (the present-day Bangkok Noi campus atSiriraj Hospital, the school offered a three-year medical certification course. After a visit by King Chulalongkorn andQueen Saovabha Phongsri, it was renamed the Royal Medical College (Thai:ราชแพทยาลัย). The school was merged withChulalongkorn UniversityinVajiravudh's 6 April 1917 decree as the Faculty of Medicine ofChulalongkorn University(now theFaculty of Medicine Siriraj Hospital, Mahidol University). The government ofPlaek Phibunsongkhramthen separated the Faculty of Medicine (Siriraj Medical School) departments of dentistry, pharmacy, and veterinary science from Chulalongkorn University and re-organized them as the University of Medical Sciences (Thai:มหาวิทยาลัยแพทยศาสตร์). Founded on 2 February 1943, it has added schools and departments. In 1959, the Medical Science Preparatory School (the present-dayFaculty of Science) was moved toPhaya Thai Districtand became the Phaya Thai campus. During the 1960s, the university focused its development on that campus. In 1965, another medical school (theFaculty of Medicine of Ramathibodi Hospital) was established at Phaya Thai. The first medical school outside Bangkok was theFaculty of Medicine Nakorn Chiang Mai HospitalinChiang Mai Provinceuntil 1964, when it was transferred toChiang Mai University. Before being transferred In 1968, the university established pharmacy and dentistry schools at a new campus separate from Chulalongkorn University. KingBhumibol Adulyadejchanged the school's name to Mahidol University (Thai:มหาวิทยาลัยมหิดล) on 21 February 1969 in honor of his father,Prince Mahidol of Songkla. The university bought a large suburban area, known as Salaya, in 1971 for future development. During the following years, the former faculties of dentistry and pharmacy were returned to Chulalongkorn University. King Bhumibol wanted Mahidol University to expand into the social sciences, and the Faculty of Social Sciences and Humanities was founded in 1969. Construction of the Salaya campus began in 1975, but was delayed due to thepolitical situationand financial constraints. The campus was opened on 23 July 1983, and all education for freshman-year students was moved there. Later development of the university, centered on the Salaya campus, diverged from the health sciences to meet Thailand's academic demands. The country's first internship college was founded at Mahidol in 1986. Ratchasuda College, devoted to the disabled, was established in 1999. Athasit Vejjajiva, the father of former prime ministerAbhisit Vejjajiva, was president of Mahidol from 1995 to 1999. The university expanded to Kanchanaburi in 2002 to offer students more learning opportunities in rural communities. It expanded to Nakhon Sawan in 2004, accepting the first class of management students in 2004 and the first class of arts students in 2005. The university began construction of the Amnat Charoen Campus, which was completed in 2009. MU is part of theAssociation of Southeast Asian Institutions of Higher Learning (ASAIHL)and is a national research university, designated by theMinistry of Educationunder Prime MinisterAbhisit Vejjajiva.  In 2009, MU joined theASEAN University Network(AUN). MU entered theQS World University Rankingsin 2006 as 322nd in the world and third in Thailand.According toQuacquarelli Symonds' 2010 Asian ranking,MU was 228th in the world, 28th in Asia, and Thailand's top university. Mahidol University International College(MUIC), Thailand's first international college, offers a range of international undergraduate and graduate programs. Its newest division is Fine and Applied Arts, which houses the Entertainment Media Program (EMP) and the Communication Design Program (CDP). Both programs offer a Bachelor of Arts degree, and EMP has three majors: film, TV, and animation. In 2009, MU was selected as one of Thailand's national research universities by the Ministry of Education's Office of Higher Education Commission. The government implemented an emergency policy to develop the national research university to an international standard to promote Thailand as a hub of Asian education, research and development, and the Office of Higher Education Commission organized the National Research University Initiative and Research Promotion. The cabinet resolved in May 2009 to approve the project with a budget of about $350 million for the three-year, 2010-2012 fiscal-year period. TheUniversity Ranking by Academic Performance(URAP) ranked MU as Thailand's best university and number 34 in Asia in 2010, but it dropped to number 351 in the world.In the 2019Times Higher Education World University Rankings(THE), Mahidol was Thailand's top universityand number 97 on the list.In 2019,Mae Fah Luang Universityand Mahidol University were the leading Thai tertiary institutions.According to the 2023 THE, MU was between 801 and 1,000th on its list. The university has 17 faculties, six colleges, nine research institutes and six campuses (three provincial campuses), and offers a range of academic programs in three core areas: health sciences, science and technology, and social sciences and humanities.Over 70 centers and laboratories for specialized research fields use interdisciplinary and inter-institutional approaches to research and postgraduate training to meet the present and future needs of government and industry. The Mahidol University Applied and Technological Service Center serves the public and private sectors and supports research. The university has two faculties of medicine which operate five hospitals, an institute of medicine affiliated with four hospitals (with Medical Education Centers for the Collaborative Project to Increase Production of Rural Doctors), and trains medical students for two other colleges of medicine. This produces about 850 medical doctors annually, with centers for comprehensive, specialized medical training and patient care; about 4,250 beds serve nearly 4.4 million outpatients and 120,000 in-patients per year. The Bangkok School of Tropical Medicine, the educational arm of theFaculty of Tropical Medicine, offers postgraduate programs from the graduate-diploma to doctoral level. The school is accredited by theAmerican Society of Tropical Medicine and Hygieneas one of eight schools in the world offering a diploma in tropical medicine, and the only school in which students can learn about tropical diseases in the tropics. The faculty operates the Hospital for Tropical Diseases.A dental unit at the Faculty of Dentistry and theGolden Jubilee Medical Centerat Salaya serves about 340,000 patients a year. Mahidol University Library and Information Center (MULIC) contains an automated library system with cyber-linked branches on MU's campuses; over 1,100,000 books, theses, research reports, and bound journals; 1,200 printed journals, 15,000 electronic journals and 16,000 electronic books; 13,000 audiovisual materials; hundreds of computer terminals and multimedia viewing equipment, and online reference services, multi-database searching and document-delivery services. The Mahidol University Computing Network (MUC-Net) accommodates at least 500local area networks, interconnecting over 350 servers and 10,000 terminals and PCs in all departments throughout the university; advanced, networked computer systems; multicast and broadcast data transmission for video conferences, distance learning, e-Learning, and IP-TV applications. Digital services include the Mahidol University Library and Information Center Network (MULINET), the Mahidol University Intranet; MUC-Net; an intra-phone, IP-phone, wireless campus network; multi-media, distance-learning and video-conferencing facilities; a management information system (MIS), and the Center for Administrative Information System (MU-ADMIN-IS). The multi-purpose, 2,000-seatPrince Mahidol Hall, on theSalayacampus, was completed in 2014 and is used for graduation ceremonies, music performances and conferences. It is the main concert hall for theThailand Philharmonic Orchestra(TPO). MU has several campuses inBangkok, Thailand's capital: a suburban campus, two older, inner-city campuses, and a downtown high-rise office site for the College of Management. The university also has provincial campuses in Kanchanaburi, Nakhon Sawan and Amnat Charoen provinces. The former Rear Palace, divided forSiriraj Hospital, is MU's Bangkok Noi campus. The campus extended into the districts of Bangkok Noi and Bang Phlat, and houses the Faculty of Medicine Siriraj Hospital, and the Faculties of Nursing, Medical Technology, and Physical Therapy and Applied Movement Science. It has personal and recreational facilities such as dormitories, cafeterias and sporting facilities. The urban, 78-acre (32 ha) campus covers three linked areas in central Bangkok and housesRamathibodi Hospitaland theHospital for Tropical Diseases, with the university's focus on medicine and the sciences at the Faculty of Medicine Ramathibodi Hospital and the Faculties of Dentistry, Pharmacy, Public Health, Tropical Medicine, and Science. It also houses the Institute for Innovation and Development of Learning Process, the National Doping Control Center and the Mahidol University Computing Center, supporting facilities, and student accommodations. The suburban Salaya campus covers 520 acres (210 ha) of semi-rural land inNakhon Pathom Province, within easy reach of central Bangkok. It is currently the main campus, housing most academic and research departments and supporting facilities including the office of the president, the central and multiple faculty libraries, science and computer laboratories, indoor stadiums, a sports complex, the Student Union, shops, cafeterias, student dormitories and condominiums. The main auditorium and the largest concert hall in Thailand,Prince Mahidol Hallis also located on this campus. The downtown, high-rise campus houses theCollege of Management(usually abbreviated CMMU). It offers graduate programs in management at the Master's, post-Master's and Ph.D. levels. Facilities include a library, computer labs, study rooms, cafeteria, shops and a gym. TheChakri Naruebodindra Medical Institute (CNMI), part of theFaculty of Medicine Ramathibodi Hospital, is in theBang Phli DistrictofSamut Prakan Province. The institute consists of the 400-bed Ramathibodi Chakri Naruebodindra Hospital, a community building, the Queen Sirikit Learning and Research Centre, student and staff dormitories, and a recreation building. TheKanchanaburi Campus, situated at Moo.9 Lum Sum Sub-district, Saiyok District, Kanchanaburi Province, spans an extensive area of 10 square kilometers, positioned adjacent to National Highway No. 323 (Kanchanaburi-Thong Pha Phum). Its origin traces back to 1995 when the Cabinet embarked on expanding higher education opportunities to provinces, culminating in the establishment of the \"Mahidol University Kanchanaburi Establishment Project\" in June of that year. A significant milestone occurred in April 1998 when His Majesty King Bhumibol Adulyadej granted royal permission for the laying of the campus's foundation stone by His Royal Highness Crown Prince Maha Vajiralongkorn. Over the years, Mahidol University Kanchanaburi Campus underwent transformative changes, starting with the introduction of undergraduate programs under the College of Management in 2001, followed by the incorporation of programs under the Faculty of Science in 2002. Notable transitions included the campus's rebranding as \"Mahidol University Kanchanaburi Campus\" in 2009 and the renaming of the Bachelor of Business Administration Program in 2012. Continuing its trajectory of progress, the campus expanded its offerings with new programs such as the Bachelor of Engineering (Environmental Engineering and Disaster Management) and Bachelor of Accountancy in 2014. Moreover, it introduced a graduate program, Master of Science in Food Resources and Ecosystem Sustainability, in 2020. Mahidol is developing two more provincial campuses: the 672-acre (2.72 km) Nakhon Sawan campus inNakhon Sawan Provinceof northern Thailand, and the 169-acre (0.68 km) Amnat Charoen campus inAmnat Charoen Provincein the northeast. Nakhon Sawan, with an administration building and lecture, laboratory and hospital buildings, offers undergraduate programs in Agricultural Science, Ecocultural Entrepreneurship, Nursing Science, and Public Health. The Amnat Charoen campus, completed in 2009, offers undergraduate programs in Agricultural Science, Innovation for Social and Environmental Management, and Public Health. 13°47′36″N100°19′21″E﻿ / ﻿13.793406°N 100.322514°E﻿ /13.793406; 100.322514", "metadata": {"url": "https://en.wikipedia.org/wiki/Mahidol_University", "title": "Mahidol University", "headings": ["Contents", "History", "Rankings and reputation", "Academic structure", "Managed by MU", "Affiliates", "Former affiliates", "Campuses", "Bangkok Noi", "Phaya Thai", "Salaya", "Vipawadee", "Bang Phli", "Provincial campuses", "See also", "References"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Mahidol_University", "https://en.wikipedia.org/wiki/Mahidol_University", "https://en.wikipedia.org/wiki/Mahidol_University", "https://en.wikipedia.org/wiki/Geographic_coordinate_system", "https://en.wikipedia.org/wiki/Great_Crown_of_Victory", "https://en.wikipedia.org/wiki/Pali", "https://en.wikipedia.org/wiki/Research_university", "https://en.wikipedia.org/wiki/Autonomous_public_university_(Thailand)"]}},
{"id": "25543e9a65aa", "content": " TheWinston-Salem Journalis an American, English language daily newspaper primarily servingWinston-SalemandForsyth County, North Carolina. It also covers NorthwesternNorth Carolina. The paper is owned byLee Enterprises.The Journalwas founded in 1897. The Journalis primarily distributed through Forsyth County and the county seat of Winston-Salem.  However, the paper also is distributed inAlleghany County,Ashe County,Davidson County,Davie County,Stokes County,Surry County,Wilkes County,Watauga County, andYadkin County. The newspaper has an online presence calledJournalNow.The Journal's television partner isWGHPofHigh Point, North Carolina. The newspaper produces several weekly sections, including Business, Food, Journal West, and Relish. It also publishes a monthly city magazine called Winston-Salem Monthly, which started in 2006 and several special editions, including Carolina Weddings, City Guide, and WS Works. TheWinston-Salem Journalhas won several N.C. Press Association awards. In 2018, the paper won a Media and the Law Award of Excellence for Best Daily Article (Scott Sexton); the Henry Lee Weathers Freedom of Information Award; and a General Excellence award for their website.In 2017, the paper won the Hugh Morton Photographer of the Year award (Allison Lee Isley), Beat News Reporting, Best Community Coverage, and more. Preceding newspapers include:The Daily Journal(1900-190?) andTwin City Sentinel(1916-1974). TheWinston-Salem Journal, started byCharles Landon Knight, began publishing in the afternoons on April 3, 1897. The area's other newspaper, theTwin City Sentinel, also was an afternoon paper. Knight moved out of the area and theJournalhad several owners before publisher D.A. Fawcett made it a morning paper starting January 2, 1902. Later that summer, theJournalbegan publishing on Sundays, after which Fawcett's church removed him from its membership. In 1903, A.F.W. Leslie and his son, A.V. Leslie, bought the paper. The elder Leslie, an artist and the son of an engraver, made theJournalthe state's first newspaper to have photographs. Owen Moon bought theJournalin 1925, and theSentinel, owned by Frank A. Gannett of the New York newspaper chain, in 1927. TheSentinelbegan as theTwin City Dailyon May 4, 1885, serving both Winston and Salem. TheWeekly Gleaner, founded by John Christian Blum on January 6, 1829, served the small community of Salem and was later taken over by the weeklyWestern Sentinel, the first newspaper in Winston on May 16, 1856. TheTwin City Daily, in turn, took over theSentinel. TheJournalandSentinelmoved into a new building on North Marshall Street in 1927, and the Sunday edition was calledThe Journal and Sentinel. Editor Santford Martin advocated improvements in the roads, especially in \"the forgotten provinces\" of Northwest North Carolina.WSJS, anAMradio station, and laterWSJS-FMandWSJS-TV, took their call letters from \"Winston-Salem Journal Sentinel\" because the newspapers once owned all three stations. AttorneyGordon Graybought the newspapers on April 30, 1937. His commitment to serving communities throughout the newspapers' coverage area continued even afterMedia GeneralInc. purchased the newspapers in 1969. The \"Call SAM (Sentinel Answer Man)\" column appeared in theSentinelstarting October 10, 1966. Bill Williams wrote the column, assisted by Christine Friedenberg, who took over in 1984. David Watson answered questions as the \"Straight Answer Man\" in theJournalfrom 1985 until his death in 2000. Ronda Bumgardner was the \"Straight Answer Ma'am\" from 2000 to 2009, and Tim Clodfelter became SAM in 2010.Melissa Hall became the second \"Straight Answer Ma'am\" in 2020.The column ended on October 6, 2024. On March 29, 1985, theSentinelpublished its last edition.This meant a stronger morning newspaper, and an increase in circulation from 73,000 to over 91,000, with Sunday circulation of 106,000. In September 1994, theJournalmoved some of its operations into a new 140,000 square feet (13,000 m) building on East 5th Street, with aMitsubishipress that allowed improvements in color printing. Other publications from theJournalserve older adults, people with pets, families with children in Forsyth County schools, prospective brides and young parents. In 2004, the paper refused to endorse a presidential candidate.The paper endorsed Democratic PresidentBarack Obamafor 2012 presidential election even though it endorsed Obama's opponent Republican SenatorJohn McCainin 2008. Its editorial-page had not endorsed aDemocratic Partypresidential candidate sinceLyndon Johnsonin 1964.The paper endorsed LibertarianGary Johnsonfor the 2016 presidential election and was the second newspaper to endorse the Libertarian candidate in this election cycle instead of eitherHillary ClintonorDonald Trump, the paper cited their distrust of both major candidates and ofstatus quo politicsin the American political system. In August 2007, theJournalreported it was changing its daily business section and cutting five positions. Two of the positions eliminated were in the newsroom. Many changes occurred in 2010. In April, theJournal's parent company, Media General, announced that it was dropping all Winston-Salem-based copy editor and design positions, shifting production to consolidated editing centers in Richmond, Va., and Tampa, Fla.Media General also announced that they are going to use a portion of their $1 million of cost savings to \"focus on intensified local news coverage.\"In October, Carl Crothers, the paper's executive editor was let go as a cost-cutting measure.On December 15, theWinston-Salem Journalfired another 18 employees, in the closing of its copy desk. On April 9, 2012 the newspaper's parent company, Media General, listed revenue that included revenue projections \"if newspaper division is sold\".On May 17, 2012, Media General announced the sale of most of its newspapers toBH Media, a subsidiary of Berkshire Hathaway. On March 16, 2020, Lee Enterprises Inc. completed its $140 million purchase of BH Media publications, including theJournal, all of which Lee had managed since June 2018. In June 2024, Lee Enterprises announced it will close the Winston-Salem production print facility and move the printing of papers including theJournalandGreensboro News & Recordto Virginia or Tennessee.", "metadata": {"url": "https://en.wikipedia.org/wiki/Winston-Salem_Journal", "title": "Winston-Salem Journal", "headings": ["Contents", "Overview", "History", "Cutbacks and sale", "Pulitzer Prizes", "Notable staff", "See also", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Winston-Salem_Journal", "https://en.wikipedia.org/wiki/Winston-Salem_Journal", "https://en.wikipedia.org/wiki/Winston-Salem_Journal", "https://en.wikipedia.org/wiki/Daily_newspaper", "https://en.wikipedia.org/wiki/Broadsheet", "https://en.wikipedia.org/wiki/Lee_Enterprises", "https://en.wikipedia.org/wiki/American_English", "https://en.wikipedia.org/wiki/Newspaper_circulation"]}},
{"id": "c09d989bcaa0", "content": " Po Leung Kuk Vicwood K. T. Chong Sixth Form College(KTC) is a government-subsidisedsixth form collegeinYau Tsim Mong District,Kowloon, Hong Kong.It was established on 26 July 1991 to provide quality education to secondary pupils matriculating afterHong Kong Certificate of Education Examinationto prepare pupils for theHong Kong Advanced Level Examination. The College's continuing education sector provides adult education and once offeredassociate degreecourses. The College also offered joint-degree courses withUniversity of Ballaratin 1996, andUniversity of Victorialater. As the first and only sixth/form college in Hong Kong, it reformed its structure for the newHong Kong Diploma of Secondary Education. It offers education to form fourth- to sixth-form pupils (24 classes). Its main feeder is Po Leung Kuk Tong Nai Kan Junior Secondary College. The headmaster of the College is Lee Poon Shing, the former headmaster of Fukien Secondary School Affiliated Schooland vice-president (teaching and learning) andDeanof humanities of GT (Ellen Yeung) College.The president andsupervisoris AngelaLeong On-kei, who also chairsPo Leung Kuk. The College was established on 26 July 1991 as a co-educational collegeto focus on Hong Kong A-level Examinations.It was Hong Kong's first and only government-subsidised sixth form school,on the former premises of Po Leung Kuk Wu Chung College, which had relocated toSha Tin. In its first year, the school offered 16 disciplines. Use of English was the only compulsory module. Thesocial sciencesstream offered economics, principles of accounts,pure mathematics,business studies, andgeography. Dr. Chan Siu Kui Darnay was the founding headmaster, previously having served as the head of Po Leung Kuk Tang Yuk Tien College inTuen Mun. It opened on 12 March 1992. The officialceremonyfor graduation includes the speech days. The first speech day was held on 8 May 1993, officiated by Professor Gungwu Wang, CBE, thenvice-chancellorofThe University of Hong Kong. It developed into a tradition for the College'sfounding father, His Excellency Sultan Vicwood KT Chong (MBE, JP, Doctor of Laws), to hand out diplomas to honourable graduates. The College became a symbol of academic excellence,with positive results in Hong Kong A-level Examinations and high admission scores.Pass rates for all subjects have never been below the Hong Kong average, while credit rates for all subjects have been significantly above those of Hong Kong's since 1995. The College started offering joint-degree programmes with overseas universities such as TheUniversity of Victoria, Canada and TheUniversity of Ballarat,Australiain 1996. Then headmaster, Dr Chan, noted when he signed the agreement with the vice-chancellor ofBallarat University, Professor David James, that the College had decided upon such direction due to the qualifications of its academic team. In 2000, the College was in preparation to addcommunity collegecourses, offeringassociate degreecourses with the first graduation held in May 2004. 1991–2007: Dr Darnay SK Chan 2008–2009: Mrs Iris WH Lau Lai 2009–2013: Miss ML Chik 2013–2021: Dr PS Lee, BA, MA, MEd, PGCE, PhD 2021-present: Mr Yau Man Kwong, BEd., MEd. ", "metadata": {"url": "https://en.wikipedia.org/wiki/PLK_Vicwood_KT_Chong_Sixth_Form_College", "title": "PLK Vicwood KT Chong Sixth Form College", "headings": ["Contents", "History", "Establishment (1991)", "Academic Excellence", "Education", "Former headmasters", "Notable alumni", "See also", "References"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/PLK_Vicwood_KT_Chong_Sixth_Form_College", "https://en.wikipedia.org/wiki/PLK_Vicwood_KT_Chong_Sixth_Form_College", "https://en.wikipedia.org/wiki/PLK_Vicwood_KT_Chong_Sixth_Form_College", "https://en.wikipedia.org/wiki/Tai_Kok_Tsui", "https://en.wikipedia.org/wiki/Kowloon", "https://en.wikipedia.org/wiki/Sixth_Form_College", "https://en.wikipedia.org/wiki/Prince_Edward,_Hong_Kong", "https://en.wikipedia.org/wiki/Leong_On-kei"]}},
{"id": "93eed453a7f5", "content": " In January 2020,FTI Consultingclaimed that in May 2018 with \"medium to high confidence\" the phone ofJeff Bezoshad beenhackedby a file sent from theWhatsAppaccount ofMohammed bin Salman, thecrown prince of Saudi Arabia.TheSaudi Arabian embassy to the United Stateshas denied the allegations.Billionaire Jeff Bezos, the owner ofThe Washington Postnewspaper and founder of the companyAmazon, engaged FTI Consulting in February 2019 after theNational Enquirerreported details of Bezos's affair in January 2019.FTI Consulting did not link theNational Enquirerto the hack.In December 2021, the FBI stated they could not find proof to substantiate claims that Saudi Arabia hacked Jeff Bezos's phone, and has considered an investigation into those allegations a low priority. Starting in September 2017,The Washington Post, which is owned by Bezos, published a series of columns byJamal Khashoggithat were critical of Saudi Arabia or Crown PrinceMohammed bin Salman.In April 2018, Bezos attended a small dinner with Mohammed and exchangedWhatsAppnumbers.Bezos and Mohammed proceeded to exchange friendly messages.Jamal Khashoggi was assassinatedin October 2018;Washington Postreporting became increasingly critical of the role of Saudi government and Mohammed in the murder. According to aUnited Nationsanalysis of the evidence of surveillance on Bezos's phone, the following events occurred on May 1, 2018: A message from the Crown Prince account was sent to Mr. Bezos through WhatsApp. The message is an encrypted video file. It is later established, with reasonable certainty, that the video's downloader infects Mr. Bezos' phone with malicious code. —United Nations Special Rapporteuron extrajudicial, summary or arbitrary executions,Agnès Callamard, andDavid Kaye, the Special Rapporteur on the promotion and protection of the right to freedom of opinion and expression In January 2019, theNational Enquirerreleased details of Bezos having conducted anaffair.Bezos had security specialistGavin de Beckerlead an investigation into how theNational Enquirerobtained the information. In February 2019, Bezos wrote a post onMedium, accusingThe National Enquirerand its parent companyAmerican Media, Inc.(AMI) of extortion and blackmail of him with images of his affair. In the post, Bezos referenced that AMI had been investigated for \"various actions they've taken on behalf of the Saudi Government\", and stated that the reporting ofThe Washington Poston the killing of Jamal Khashoggi \"is undoubtedly unpopular in certain circles\". Later in February 2019, Bezos and de Becker hireddigital forensicexperts from theFTI Consultingcompany to analyse Bezos's iPhone.The Wall Street Journallater reported that Bezos did not want to give his phone directly to theFederal Bureau of Investigation(FBI); thus he had FTI Consulting do the work. Some FTI Consulting workers previously worked for the FBI.The Wall Street Journalalso reported that FTI Consulting communicated with law enforcement officials about their work. In March 2019, de Becker wrote an article forThe Daily Beast, stating that Bezos' and his \"investigators and several experts concluded with high confidence that the Saudis had access to Bezos's phone, and gained private information\".de Becker also reported he had presented details of his investigation to law enforcement officials; furthermore, he said there was a \"close relationship\" between Mohammed and American Media CEODavid Pecker.He highlighted that AMI had attempted to have him publicly declare that the investigation into Bezos's phone found that AMI had not used \"eavesdropping or hacking in their newsgathering process\", and had demanded his declaration that AMI's story was not \"influenced in any manner by external forces\". Lastly, de Becker stated that it was \"unclear\" whether AMI knew of the alleged hack by the Saudis. In April 2019, Bezos was interviewed by federal investigators when the FBI was researching whether Israeli technology companyNSO Grouphad conducted hacks into people and companies in the United States.As of November 2021, probes by the U.S. government have not led to public action against the National Enquirer or Saudi Arabia. In November 2019, FTI Consulting finished compiling the report for the forensic analysis of Bezos's phone. The Guardianbroke the story on January 21, 2020, of the results of the analysis of Bezos's phone, reporting that the analysis indicated it was highly likely that Bezos's phone had been infiltrated by a malicious video file sent from Mohammed's WhatsApp account.FTI Consulting's conclusion was made with \"medium to high confidence\", the report stated.The full forensic report was published byMotherboardon January 23, 2020. The report stated that just \"hours\" after Bezos received the file from Mohammed, his phone began transmitting dramatically higher amounts of data, and that this continued for months.The video in the file was not infected, but the downloader of the file could not be analyzed by investigators because it was encrypted by WhatsApp.The report points to two pieces of circumstantial evidence: first, a November 2018 message from Mohammed to Bezos includes an image resembling the woman Bezos was having an affair with, despite the affair not being public knowledge at the time; second, a February 2019 text from Mohammed to Bezos urges Bezos not to believe everything, after Bezos was briefed on the phone regarding an Internet campaign against him conducted by Saudis.The report states that investigators' belief that Mohammed's advisor,Saud al-Qahtani, obtained the hacking software.The report does not linkThe National Enquirerto the hack. TheUnited Nationsspecial rapporteur on summary executions and extrajudicial killingsAgnès Callamardand special rapporteur on freedom of expressionDavid Kayereviewed a forensic analysis of Bezos' phone.On January 22, 2020, Callamard and Kaye stated that \"the allegations are also reinforced by other evidence of Saudi targeting of dissidents and perceived opponents\".They noted other phones that were hacked from May 2018 to June 2018, belonging to two Khashoggi associates (Yahya AssiriandOmar Abdulaziz), anAmnesty Internationalofficial, and Saudi dissidentGhanem al-Dosari.The UN experts stated: \"During the same period, Mr. Bezos was widely targeted in Saudi social media as an alleged adversary of the Kingdom. This was part of a massive, clandestine online campaign against Mr. Bezos and Amazon, apparently targeting him principally as the owner of The Washington Post.\"As a result, Callamard and Kaye called for \"immediate investigation\" by relevant authorities of the alleged phone hacks, \"including investigation of the continuous, multi-year, direct and personal involvement of the Crown Prince in efforts to target perceived opponents.\" In February 2019,Adel al-Jubeir, minister of state for foreign affairs for Saudi Arabia, announced the country had \"absolutely nothing to do with the hacking\". In March 2019, AMI released a statement responding to de Becker's column that the only source for their story on Bezos was Michael Sanchez, the brother of Bezos's girlfriend and that there was \"no involvement by any other third party whatsoever\".A year later, Michael Sanchez sued AMI, stating in court documents that when theNational Enquirerfirst contacted him, they already had \"raunchy text messages and nude selfies exchanged\" by Bezos and Sanchez's sister. Michael Sanchez denied giving AMI explicit photos and accused AMI of hacking Bezos's phone. In January 2020, the Twitter account of the kingdom's U.S. embassy explicitly rejected the claim that Saudi Arabia was behind the hack, and called for an investigation into the incident. The Guardianspeculated in January 2020 that the hacking allegation would weaken Mohammed's ability to attract more Western investors to Saudi Arabia and lead to renewed scrutiny of the murder of Khashoggi and Mohammed's involvement.The outlet also reported that Saudi experts believed that Bezos was hacked because ofThe Washington Post's coverage of Saudi Arabia, including Khashoggi's criticism of Mohammed.One such expert was Andrew Miller, who served on the national security council under PresidentBarack Obama, who claimed that Bezos' targeting by the Crown Prince reflects the personality-centric nature of Saudi politics. The Washington Postin January 2020 quoted security researchers as saying that \"Bezos probably fell victim to the iPhone'sAchilles' heel: Its defences are so difficult to penetrate that once sophisticated attackers are in, they can go largely undetected.\" One of the reported reasons for this weakness of the iPhone was that its maker Apple \"employs a secretive approach to finding and fixing security\". United Nations special rapporteurs Agnès Callamard and David Kaye stated in January 2020 that the alleged hacking suggests that there was \"an effort to influence, if not silence, theWashington Post's reporting on Saudi Arabia\", with Mohammed possibly part of the operation.They declared that the alleged hacking was relevant to the issue of whether Mohammed was involved in the killing of Jamal Khashoggi. MIT Technology Reviewoffered the opinion in January 2020 that FTI Consulting's report \"lacks conclusive evidence\", noting that it failed to decisively identify the specific spyware used against Bezos. Motherboardin January 2020 quoted mobile forensic expert Sarah Edwards that FTI's results, as reported in January 2020, were only about 50% complete. Edwards pointed to a lack of analysis of core files, \"where that state-sponsored malware is going to be found\". Meanwhile, Vladimir Katalov, the leader of an iOS forensics company, opined toMotherboardthat it seemed as if the \"experts were not qualified enough\".", "metadata": {"url": "https://en.wikipedia.org/wiki/Jeff_Bezos_phone_hacking_incident", "title": "Jeff Bezos phone hacking incident", "headings": ["Contents", "Background", "Alleged incident", "Investigations", "Reaction to allegations", "Analysis", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Jeff_Bezos_phone_hacking_incident", "https://en.wikipedia.org/wiki/Jeff_Bezos_phone_hacking_incident", "https://en.wikipedia.org/wiki/Jeff_Bezos_phone_hacking_incident", "https://en.wikipedia.org/wiki/FTI_Consulting", "https://en.wikipedia.org/wiki/Jeff_Bezos", "https://en.wikipedia.org/wiki/Hacking_(computers)", "https://en.wikipedia.org/wiki/WhatsApp", "https://en.wikipedia.org/wiki/Mohammed_bin_Salman"]}},
{"id": "41c7dcbe53b1", "content": " Dean Francis Zanuck(/ˈzænək/ZAN-ək; born August 11, 1972) is an American production executive and film producer. Zanuck was born on August 11, 1972, inLos Angeles, California.His father wasRichard D. Zanuck(1934–2012), a film producer, and his mother,Linda Melson Harrison, an actress.His paternal grandfather wasDarryl F. Zanuck, film producer and20th Century Foxco-founder; his paternal grandmother was silent actressVirginia Fox(1902–1982), Darryl Zanuck's wife for fifty-five years. Zanuck was a production executive atThe Zanuck Companyfrom 1998 to 2017.In 2004, he formed Zanuck Independent to produce independent films. Productions under the banner includeSony Picture Classics'Get Low, starringRobert Duvall,Sissy Spacek, andBill Murray, and the sci-fi fantasy,The Zero Theorem, directed byTerry Gilliamand starringChristoph Waltz,Matt Damon, andTilda Swinton.In 2015, Dean Zanuck and Disney veteranRick Calabashformed Zanuck Family Entertainment to produce family oriented motion pictures and multi-platform content. In 2002, Zanuck married Marisa, a real estate agent who was featured on the reality TV seriesThe Real Housewives of Beverly Hillsin its third season, which aired in 2013.The Zanucks lived together inBeverly Hills, California,until their divorce in February 2016.They have one son, Jack, and a daughter, Darryl. He was a producer in all films unless otherwise noted.", "metadata": {"url": "https://en.wikipedia.org/wiki/Dean_Zanuck", "title": "Dean Zanuck", "headings": ["Contents", "Early life", "Career", "Personal life", "Filmography", "Film", "Television", "References"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Dean_Zanuck", "https://en.wikipedia.org/wiki/Dean_Zanuck", "https://en.wikipedia.org/wiki/Dean_Zanuck", "https://en.wikipedia.org/wiki/Los_Angeles,_California", "https://en.wikipedia.org/wiki/University_of_Colorado_Boulder", "https://en.wikipedia.org/wiki/Charlie_and_the_Chocolate_Factory_(film)", "https://en.wikipedia.org/wiki/Road_to_Perdition", "https://en.wikipedia.org/wiki/Get_Low_(film)"]}},
{"id": "ed97f80ea8d0", "content": "\"Say 'cheese'\"is an English-language instruction used byphotographerswho want their subject or subjects tosmilewith their lips apart and teeth showing. In the 19th century, most people were expected to use a neutral facial expression when being photographed.The expensive and time-consuming nature of early photography reinforced this behavior.In the late 19th century, different aesthetic and behavioral norms required keeping the mouth small, which led to photographers using \"say prunes\".Smiling became normal while being photographed in the 20th century, as the availability of cameras made photography a more common occurrence.Saying particular words was seen to help subjects have a particular smile, withcheesebeing recorded in 1943 as a word that was said in English.As such, photographers would use the phrasesay \"cheese\"to encourage subjects to state the word while the photographer snapped the photo. Perhaps because of strong western influence, especially in the realm of photography, and perhaps because of increased numbers of western visitors after photographic equipment became widely available, \"Say cheese\" has also entered into theJapanese language. Other languages have adopted this method, albeit with different words, to get the desired effect of shaping the mouth to form a smile.", "metadata": {"url": "https://en.wikipedia.org/wiki/Say_cheese", "title": "Say cheese", "headings": ["Contents", "History", "In different languages and cultures", "References"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Say_cheese", "https://en.wikipedia.org/wiki/Say_cheese", "https://en.wikipedia.org/wiki/Say_cheese", "https://en.wikipedia.org/wiki/Say_Cheese_(disambiguation)", "https://en.wikipedia.org/wiki/Photographer", "https://en.wikipedia.org/wiki/Smile", "https://en.wikipedia.org/wiki/Pete_Conrad", "https://en.wikipedia.org/wiki/Gordon_Cooper"]}},
{"id": "6ce89e3c43e1", "content": " Yusaku Maezawa(前澤 友作,Maezawa Yūsaku; born 22 November 1975)is a Japanesebillionaireentrepreneur and art collector. He founded Start Today in 1998 and launched the online fashion retail website Zozotown in 2004, now Japan's largest. Maezawa introduced a custom-fit apparel brand Zozo and at-home measurement system, the Zozosuit, in 2018.As of July 2025, he was estimated byForbesto have a net worth of $1.5 billion. Maezawa began attendingWaseda Jitsugyo High School, Tokyo, in 1991, where he started ahardcore punkband with his classmates calledSwitch Style[ja], in which he was the drummer.The band released their first EP in 1993.After graduating from high school, he decided not to go to college; instead he moved to the US with a girlfriend, where he started collecting CDs and records.When he returned to Japan in 1995, his album collection became the basis for his first company, which sold imported albums and CDs through the mail. In 1998, Maezawa used the basis of the mail-order album business to launch the company Start Today.The same year, his band signed with the labelBMG Japan. By 2000, Start Today had moved to an online platform, had begun selling clothing, and had become a public company. In 2001, Maezawa declared a hiatus on his music career. Start Today opened the retail clothing website Zozotown in 2004, and six years later, Start Today became a publicly traded company, listed on the \"Mothers\" Index of theTokyo Stock Exchange. By 2012, Start Today was listed in the First Section of the Tokyo Stock Exchange.Forbeslisted him in its World's Youngest Billionaires 2011 ranking,and Wealth-X forCNBCranked him 8th richest entrepreneurs under 40 in Asia in 2015. In 2018, Maezawa introduced Zozo, a custom-fit clothing brand and the Zozosuit an at-home measurement system, in over 72 countries and territories. Maezawa resigned from Zozo in September 2019 after selling a stake of 50.1% in the company toSoftBankforUS$3.7 billion(400 billion Yen). He also sold 30% of his personal stake in ZoZo toYahoo Japan.In 2023, he invested $23 million in the satellite companyAstroscale. Maezawa is the founder of the Tokyo-based Contemporary Art Foundation, which he started in 2012 with a goal of \"supporting young artists as a pillar of the next generation of contemporary art.\"The Contemporary Art Foundation currently hosts collection shows twice a year. In May 2016, Maezawa attracted significant media attention with a record purchase price at auction of $57.3 million for anUntitled(1982) artwork of a devil byJean-Michel Basquiat, and broke a record again in May 2017 with a $110.5 million auction for anotherUntitled(1982) of a skull by the same artist.At the same 2016 auction, Maezawa bought pieces byBruce Nauman,Alexander Calder,Richard Prince, andJeff Koons, spending a total of $98 million over two days.Maezawa plans to open a contemporary art museum inChiba, which will house his collection.In 2022, Maezawa sold an untitled Basquiat Painting for $85 Million. On 17 September 2018, it was announced that Maezawa was to become the firstcommercial passengerto perform aflybyof theMoon.He was to fly on board aSpaceX Starship, which has been in development since 2017. The flight was slated to take place no earlier than 2023 with a duration of around six days. Maezawa originally planned to take six to eight artists with him as a part of an art project entitled#dearMoon.In March of 2021, the requirements for registration were changed to allow members of the general public (instead of just artists) to apply for the flight.Finally, in December 2022, Maezawa announced that he had chosen his crew members, including DJSteve AokiandT.O.P.After the flight was postponed indefinitely following broader Starship program delays in 2023, the project was fully cancelled on 1 June 2024. On 13 May 2021, Maezawa announced he would be joiningSpace Adventureson a trip to theInternational Space Stationin December 2021, via aSoyuzspacecraft. He spent 12 days on the orbital station with his assistant,Yozo Hirano, where he completed the top 100 things demanded by public, as well as recorded highlights in preparation for the SpaceX lunar flight. The flight lifted off on 8 December 2021, fromBaikonur Cosmodromein Kazakhstan as part of the Russian-operatedSoyuz MS-20.On 18 December, Maezawa announced that he will start a campaign in which every participant will receive a sum of money \"from space.\"The campaign started on 19 December.He returned as planned on 20 December. On 5 January 2019, Maezawa offered one millionyen(approx US$9,300) to each of 100 randomly selected people who retweeted him and followed him,gathering four million retweets and follows.On 31 December 2019, he reiterated this marketing coup, offering one millionyen(approx US$9,200) to each of 1,000 randomly selected people who retweeted and followed him. Maezawa is divorced, with three children, and lives inChiba, Japan. He commissioned his ownPagani Zonda, the Pagani Zonda ZoZo. He is the owner ofCosmos, a 114 meterfuel-cellpowered superyacht, built byLürssen, designed byMarc Newson, and launched in August 2025.", "metadata": {"url": "https://en.wikipedia.org/wiki/ZOZO", "title": "Yusaku Maezawa", "headings": ["Contents", "Early life", "Business", "Contemporary Art Foundation", "Spaceflights", "Proposed circumlunar flight", "ISS mission", "Most retweeted", "Personal life", "References"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Yusaku_Maezawa", "https://en.wikipedia.org/wiki/Yusaku_Maezawa", "https://en.wikipedia.org/wiki/Yusaku_Maezawa", "https://en.wikipedia.org/wiki/Kamagaya", "https://en.wikipedia.org/wiki/Space_Adventures", "https://en.wikipedia.org/wiki/Space_tourist", "https://en.wikipedia.org/wiki/Soyuz_MS-20", "https://en.wikipedia.org/wiki/Billionaire"]}},
{"id": "3388d39aa683", "content": "This is a list of computer systems based on theMicro Channel architecturethat werenotmanufactured byIBM. Such third-party computers were also referred to asPS/2 clonesorMCA clones.The first third-party Micro Channel–based computer wasTandy Corporation's 5000 MC in July 1988.Despite expensive research and development costs on the part of third-party manufacturers of Micro Channel computers—in part due to the expensive licensing fees incurred byIBMin order to allow legal use of their technology—by 1990 most MCA clones were not fully compatible with the Micro Channel architecture or expansion cards and peripherals based on Micro Channel.By the time IBM was winding down thePS/2line of personal computers (which in 1987 acted as the means of introducing Micro Channel to the general public) in 1992,NCR Corporationremained one of the few committed vendors of MCA clones.", "metadata": {"url": "https://en.wikipedia.org/wiki/List_of_third-party_Micro_Channel_computers", "title": "List of third-party Micro Channel computers", "headings": ["Contents", "Systems", "See also", "Notes", "References"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/List_of_third-party_Micro_Channel_computers", "https://en.wikipedia.org/wiki/List_of_third-party_Micro_Channel_computers", "https://en.wikipedia.org/wiki/List_of_third-party_Micro_Channel_computers", "https://en.wikipedia.org/wiki/Micro_Channel_architecture", "https://en.wikipedia.org/wiki/IBM", "https://en.wikipedia.org/wiki/Tandy_Corporation", "https://en.wikipedia.org/wiki/IBM", "https://en.wikipedia.org/wiki/PS/2"]}},
{"id": "a81b1e5459f5", "content": "Phrae Pwo, orNortheastern Pwo, is aKaren languagespoken in Phrae, Lampang, and Chiang Rai provinces ofThailand. It is not intelligible withother varieties of Pwo, though it is close toNorthern Pwo.", "metadata": {"url": "https://en.wikipedia.org/wiki/Phrae_Pwo_language", "title": "Phrae Pwo language", "headings": ["Contents", "References", "Further reading"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Phrae_Pwo_language", "https://en.wikipedia.org/wiki/Phrae_Pwo_language", "https://en.wikipedia.org/wiki/Phrae_Pwo_language", "https://en.wikipedia.org/wiki/Thailand", "https://en.wikipedia.org/wiki/Kayah_people", "https://en.wikipedia.org/wiki/Language_family", "https://en.wikipedia.org/wiki/Sino-Tibetan_languages", "https://en.wikipedia.org/wiki/Tibeto-Burman_languages"]}},
{"id": "f5ae85339dfd", "content": " Narikala(Georgian:ნარიყალა,pronounced[naɾiχʼaɫa]) is an ancientfortressoverlookingTbilisi, the capital ofGeorgia, and theMtkvari(Kura) River. The fortress consists of two walled sections on a steep hill between thesulfur bathsand thebotanical gardens of Tbilisi. On the lower court there is the recently restored St Nicholas church. Newly built in 1996–1997, it replaces the original 13th-century church that was destroyed in a fire. The new church is of \"prescribed cross\" type, having doors on three sides.The internal part of the church is decorated with the frescos showing scenes from both the Bible and the history of Georgia. According to the legend, it was built by the kingVakhtang I Gorgasaliof the ancientKingdom of Iberia. Archaeological studies of the region have, however, revealed that the territory of Tbilisi was settled by humans as early as the4th millennium BC. The earliest written accounts of settlement of the location come from the second half of the 4th century AD, when a fortress was built during KingVaraz-Bakur's reign (ca. 364).Towards the end of the 4th century, the fortress fell into the hands of thePersians, but was recaptured by the kings of Kartli by the middle of the 5th century.It was considerably expanded by theUmayyadsin the 7th century and by kingDavid the Builder(1089–1125), respectively. TheMongolsrenamed it the \"Narin Qala\" (i.e., \"Little Fortress\"). Most of the extant fortifications date from the 16th and 17th centuries.Rostom, theSafavid-appointedvali/king ofKartli, fortified the surroundings of the fortress and transferred control of the fortress to the Iranians.In 1827, parts of the fortress were damaged by an earthquake, and were subsequently demolished.", "metadata": {"url": "https://en.wikipedia.org/wiki/Narikala", "title": "Narikala", "headings": ["Contents", "History", "Gallery", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Narikala", "https://en.wikipedia.org/wiki/Narikala", "https://en.wikipedia.org/wiki/Narikala", "https://en.wikipedia.org/wiki/Geographic_coordinate_system", "https://en.wikipedia.org/wiki/Tbilisi", "https://en.wikipedia.org/wiki/Georgia_(Country)", "https://en.wikipedia.org/wiki/Fortress", "https://en.wikipedia.org/wiki/Stone"]}},
{"id": "dbd1f3f87c59", "content": "Feline immunodeficiency virus(FIV) is alentivirusthat affectscatsworldwide with 2.5% to 4.4%offelinesbeing infected. FIV was firstisolatedin 1986, byNiels C. PedersenandJanet K. Yamamotoat theUC Davis School of Veterinary Medicinein a colony of cats that had a high prevalence ofopportunistic infectionsanddegenerative conditions, and was originally calledfeline T-lymphotropic virus.It has since been identified indomestic cats. FIV compromises theimmune systemof cats by infecting many cell types, includingCD4+andCD8+ Tlymphocytes,B lymphocytes, andmacrophages. FIV can be tolerated well by cats, but can eventually lead to debilitation of the immune system in its felinehostsby the infection and exhaustion of T-helper (CD4+) cells. FIV andHIVare bothlentiviruses. However, humans cannot be infected by FIV, nor can cats be infected by HIV. FIV is transmitted primarily through deep bite wounds, where the virus present in the infected cat's saliva enters thebody tissuesof another cat. FIV-positive cats can share water bowls and food bowls (for both wet and dry cat food) and use the same litter box with low danger of transmitting the disease. A vigilant pet owner who treatssecondary infectionscan allow an infected cat to live a reasonably long life. The chance that an FIV-infected cat will pass the virus to other cats within a household is low, unless there is fighting between cats, or wounds present that could allow entry of the virus from an infected to a noninfected cat. Newborn kittens may test positive for up to six months, and most thereafter will gradually test negative. It is thought that this is due toantibodiestransferred to the kittens via the mother'smilk. However, these antibodies are transient, so subsequent testing will be negative. Once the kittens have received vaccinations against FIV, they will, in the future, always test positive, as the various blood tests detect and show the antibodies that have developed in response to the vaccination. FIV is known in other feline species, and in fact isendemicin some largewildcats, such as Africanlions. Three maincladesof FIV are recognized as of 2006: FIV-Ple (lion), FIV-Fca (domestic cat), and FIV-Pco (puma).The host boundaries are usually well kept because of the limited types ofAPOBEC3enzymes thatviral infectivity factorcan neutralize. Consensus in the United States on whether there is a need toeuthanizeFIV-infected cats has not been established. TheAmerican Association of Feline Practitioners, as well as manyferal catorganizations, recommends against euthanizing FIV-positive cats, or even spending funds to test for the virus. The virus gains entry to host cells through the interaction of its own envelopeglycoproteinswith the target cells' surfacereceptors. First, the SU glycoprotein binds toCD134, a receptor on the host cell. This initial binding changes the shape of the SU protein to one that facilitates interaction between SU and thechemokine receptorCXCR4.This interaction causes theviralandcellular membranesto fuse, allowing the transfer of theviral RNAinto thecytoplasm, where it is reversetranscribedand integrated into the cellulargenomethroughnonhomologous recombination. Once integrated into the host cell's genome, the virus can lie dormant in the asymptomatic stage for extended periods of time without being detected by the immune system or can causelysisof the cell. CD134 is predominantly found on activatedT cellsand binds toOX40 ligand, causing T-cell stimulation, proliferation, activation, andapoptosis(3). This leads to a significant drop in cells that have critical roles in the immune system. Low levels of CD4+ and other affected immune-system cells cause the cat to be susceptible to opportunistic diseases once the disease progresses tofeline acquired immune deficiency syndrome(FAIDS). The primary mode of transmission is via deep bite wounds, in which the infected cat's saliva enters the other cat's tissues. FIV may also be transmitted from pregnant females to their offspring in utero; however, thisvertical transmissionis considered to be relatively rare, based on the small number of FIV-infected kittens and adolescents.This differs fromfeline leukemia virus(FeLV), which may be spread by more-casual, nonaggressive contact, such asmutual groomingand sharing of food bowls. Risk factors for infection include male sex, adulthood, and outdoor access. One case study conducted in São Paulo found that 75% of FIV-infected cats were males. Higher rates of infection in males than females occur because males defending their territory bite more frequently. FIV progresses through similar stages to HIV. The initial stage, or acute phase, is accompanied by mild symptoms such aslethargy,anorexia,fever, andlymphadenopathy(swelling of thelymph nodes).This initial stage is fairly short and is followed by the asymptomatic stage. Here the cat demonstrates no noticeable symptoms for a variable length of time. Some cats stay in this latent stage for only a few months, but for some it can last for years. Factors that influence the length of the asymptomatic stage include thepathogenicityof the infecting virus and FIV subtype (A–E), the age of the cat, and exposure to other pathogens. Finally, the cat progresses into the final stage (known as the feline acquired immune deficiency syndrome (FAIDS) stage), wherein the cat is extremely susceptible to secondary diseases that inevitably are the cause of death. Veterinarians will check a cat'shistory, look forclinical signs, and possibly administer a blood test for FIVantibodies. FIV affects 2–3% of cats in the US and testing is readily available. This testing identifies those cats that carry the FIV antibody but does not detect the actual virus. \"False positives\" may occur when the cat carries the antibody (which is harmless) but does not carry the virus. The most frequent occurrence of this is when kittens are tested after ingesting the antibodies from mother's milk (passive immunity), and when testing cats that have been previously vaccinated for FIV (active immunity). For this reason, neither kittens under eight weeks nor cats that have been previously vaccinated are tested. Kittens and young cats that test positive for the FIV antibody viapassive immunitytest negative later in life due toseroreversion, provided they have never been infected with FIV and have never been immunized with the FIV vaccine. Cats that have been vaccinated will test positive for the FIV antibody for the rest of their lives owing toseroconversion, even though they are not infected. Therefore, testing of strays or adopted cats is inconclusive, since it is impossible to know whether or not they have been vaccinated in the past. For these reasons, a positive FIV antibody test by itself should never be used as a criterion foreuthanasia. Tests can be performed in a vet's office with results in minutes, allowing for quick consultation. Early detection helps maintain the cat's health and prevents spreading infection to other cats. With proper care, infected cats can live long and healthy lives. In 2006, theUnited States Department of Agricultureissued a conditional license for a new treatment aid termedLymphocyte T-Cell Immunomodulator(LTCI).Lymphocyte T-Cell Immunomodulator is manufactured and distributed exclusively by T-Cyte Therapeutics, Inc. Lymphocyte T-Cell Immunomodulator is intended as an aid in the treatment of cats infected with feline leukemia virus (FeLV) and/or feline immunodeficiency virus (FIV), and the associated symptoms ofanemia(reduced oxygen-carrying ability in the blood),opportunistic infection,lymphocytopenia,granulocytopenia, orthrombocytopenia(low levels oflymphocytes,granulocytes, andplateletsrespectively, the first two are types ofwhite blood cell). The absence of any observed adverse events in several animal species suggests that the product has a very low toxicity profile. Lymphocyte T-Cell Immunomodulator is a potent regulator of CD-4 lymphocyte production and function.It has been shown to increase lymphocyte numbers andInterleukin 2production in animals.It is a single-chainpolypeptideand a stronglycationicglycoprotein, and is purified withcation exchange resin.Purificationof protein frombovine-derivedstromal cellsupernatantsproduces a substantially homogeneous factor, free of extraneous materials.  The bovine protein is homologous with other mammalian species and is a homogeneous 50kDaglycoprotein with anisoelectric pointof 6.5.  The protein is prepared in a lyophilized (freeze-dried) 1microgramdose.  Reconstitution insterilediluentproduces a solution forsubcutaneous injection. As with HIV, the development of an effective vaccine against FIV is difficult because of the high number of, and differences between, variations of thevirus strains. \"Single-strain\" vaccines, i.e., vaccines that only protect against a single virus variant, have already demonstrated a good efficacy againsthomologousFIV strains. A dual-subtype vaccine for FIV released in 2002 called Fel-O-Vax made it possible to immunize cats against more FIV strains. It was developed using inactivated isolates of two of the five FIV subtypes (orclades): A Petaluma and D Shizuoka.The vaccine was shown to be moderately protective (82% of cats were protected) against subtype A FIV,but a later study showed it to offer no protection against subtype A.It has shown 100% effectiveness against two different subtype B FIV strains.Vaccination will cause cats to have positive results on FIV tests, making diagnosis more difficult.  For these reasons the vaccine is considered \"non-core\", and the decision to vaccinate should be made after discussion with a veterinarian and consideration of the risks vs. the effectiveness. FIV displays a similar structure to the primate and ungulate lentiviruses. The virion has a diameter from 80 to 100 nanometers and ispleomorphic. The viral envelope also has surface projections that are small, 8 nm, and evenly cover the surface. The FIV virus genome is diploid. It consists of two identical single-strands of RNA in each case about 9400 nucleotides existing in plus-strand orientation. It has the typical genomic structure of retroviruses and includes LTR,vif,pol,gag,orfA,env, andrevgenes.The Gag polyprotein is cleaved into matrix (MA), capsid (CA) and nucleocapsid (NC) proteins. Cleavage between CA and NC releases a nine amino acid peptide, while cleavage at the C-terminus of NC releases a  2kDa fragment (p2). The Pol polyprotein is translated by ribosomal frame-shifting, a feature shared with HIV. Cleavage of Pol by the viral protease releases the protease itself (PR), reverse transcriptase (RT), deoxyuridine triphosphatase (dUTPase or DU) and integrase (IN). The Env polyprotein consists of a leader peptide (L), surface (SU) and transmembrane (TM) glycoproteins. In common with other lentiviruses, the FIV genome encodes additional short open reading frames (ORFs) encoding the Vif and Rev proteins. An additional short ORF termedorfA(also known asorf2) precedes theenvgene. The function of OrfA in viral replication is unclear, however theorfA-encoded product may display many of the attributes of HIV-1 accessory gene products such as Vpr, Vpu or Nef. Among these subtypes, genetic sequences are mostly conserved; however, wide-ranging genetic differences exist between species specific FIV subtypes. Of FIV's genome,Polis the most conserved across FIV strains along withgag. On the contrary,env,vif,orfa, andrevare the least conserved and exhibit the most genetic diversity among FIV strains. The capsid protein derived from the polyprotein Gag is assembled into aviral core(the protein shell of a virus) and the matrix protein also derived from Gag forms a shell immediately inside of the lipid bilayer. The Env polyprotein encodes the surface glycoprotein (SU) and transmembrane glycoprotein (TM). Both SU and TM glycoproteins are heavily glycosylated, a characteristic that scientists believe may mask the B-cell epitopes of the Env glycoprotein giving the virus resistance to the virus neutralizing antibodies. Like HIV-1, FIV has been engineered into aviral vectorfor gene therapy.Like other lentiviral vectors, FIV vectors integrate into the chromosome of the host cell, where it can generate long-term stable transgene expression. Furthermore, the vectors can be used on dividing and non-dividing cells.FIV vectors could potentially be used to treat neurological disorders likeParkinson's disease, and have already been used for transfer RNAi, which may find use as gene therapy for cancer. The exact origins and emergence of FIV in felids is unknown; however, studies of viral phylogenetics, felidae speciation, and FIV occurrence alludes to origins in Africa. Analysis of viral phylogenetics shows phylogenetic trees with a starburst phylogenetic pattern which is usually demonstrated by viruses that are a recent emergence with rapid evolution.However, differences in topology, branch lengths, high genetic divergence suggest a more ancient origin in felidae species. Fossil records indicate extant felids arose from a common ancestor in Asia approximately 10.8 million years ago, and since then thirty eight species from eight distinct evolutionary lineages have spread and successfully inhabited every continent but Antarctica.Despite felidae origins in Asia, FIV is absent from felidae species in Asia except for the Mongolian Pallas cat; however, FIV is highly endemic in Africa with four out of five felids having seropositive PCR results.Due to the widespread occurrence and interspecies divergence of FIV strains in Africa, it's suggested that FIV arose in Africa before disseminating worldwide. The high genetic diversity and divergence between FIV strains in African felidae species and the presence of hyena FIV-Ccr, is consistent with a long residence time giving rise to increased opportunities for inter-species transmission among species. Additionally, lentiviruses are also highly endemic in Africa infecting not only felids, but also primates, and ungulate species. This suggests to the origins of all lentiviruses and supports FIV origins in Africa; however, further research is needed. The spread of FIV from Africa might have occurred during two points of felidae migration. The earliest migration across the Bering Strait into North America occurred approximately 4.5 million years ago during a period of low sea levels.Early felids in North America descended into seven species of the ocelot lineage, two species of the puma lineage, and four of the modern species of lynx.The most recent migration of Asian lions and jaguars across Eurasia into North and South America occurred during the Pliocene/early Pleistocene.These migrations events increased opportunities for FIV transmission among felids and established infections globally for felidae species. Comparisons of FIV subtypes illustrate rapid evolution and highlights divergence in FIV strains. FIV-Pco, which is specific to American pumas, has two highly divergent subtypes.Several studies have demonstrated subtypes A and B to have long branch lengths and low geographic similarities which indicates the possibility of two separate FIV introductions into populations coupled with a long residence time.In the late Pleistocene, pumas fell victim to the ice age, went extinct in North America except for a small inbred population in Florida, and did not re-emerge until 10–12,000 years ago.Phylogenetic analysis of FIV-Pco strains in Central, South, and North America show Central and South American strains are more closely related to North American strains than to each other.This suggests FIV-Pco was already present in South American pumas which repopulated North America.In African lions, FIV-Ple has diverged in to six subtypes A-F which exhibit distinct geographical endemicity to some degree.Approximately 2 million years ago, African lions arose and dispersed throughout Africa, Asia, and North, Central, and South America. Modern lions currently reside only on the African continent except for a small population in India.There is no documented disease association of FIV, but seroprevalence in free- ranging lion populations are estimated to be roughly 90%.Phylogenetic analysis of FIV-Ple subtypes A, B, and C show high intra and interindividual genetic diversity and sequence divergence comparable to genetic differences to strains from other Felidae species.These findings indicate these strains evolved in geographically distant lion populations; however, recent occurrences of these strains within populations in Serengeti National Park suggests recent convergence in the same population. Feline Immunodeficiency Virus (FIV) is widely distributed across Africa, Asia, North America, South America, and Central America, but it has not been found in Oceania.The virus affects a majority of species, including lions, hyenas, pumas, leopards, jaguars, bobcats, and tigers.Currently, FIV has been documented in over nineteen wild felid species due to its transmission through blood and saliva, which often occurs during aggressive interactions. FIV is more rampant in non-Pantheralineages, such as lynxes, bobcats, cheetahs, and pumas, compared toPantheraspecies like lions, leopards, jaguars, and tigers.Studies indicate that lynxes are more susceptible to FIV due to higher levels of the A3Z3 protein, part of theAPOBEC3family, which limits virus replication in felids. However, A3Z3 mutations do not significantly alter viral genes, suggesting that other genetic or environmental factors may influence the virus's effects. Members of thePantheragenus exhibit higher levels of protective protein expression, potentially mitigating the severity of infection.Additionally, carnivorous diets contribute to FIV transmission, as larger wild felids may contract the virus by consuming smaller, infected prey species, increasing the rates of infection. Lions infected with FIV show various outcomes. Many live without advanced symptoms, while severe cases are rarely observed in the wild due to rapid mortality or predation. Genetic diversity among FIV strains may influence pathogenicity, similar to how HIV affects humans. Infected lions exhibit reduced T-cell counts, inflammation, and systemic complications, but the disease's progression often occurs beyond reproductive age, limiting its population-level effects. FIV infections compromise immune function, leading to increased susceptibility to secondary infections and diseases.Behavioral changes have been observed in infected felids, such as reduced hunting ability and impaired social interactions, may hinder survival.These behavioral and physiological effects highlight the multifaceted challenges posed by FIV, influenced by genetics, ecological dynamics, and interspecies interactions. FIV presents a significant but nuanced challenge for wild felids. While it has been connected to immunological complications, current evidence and studies have not conclusively proven that FIV has a significant increase of mortality rates across populations.However, its effects on individual fitness and survival, driven by genetic susceptibility, ecological interactions, and strain diversity, are undeniable. A study conducted in Colorado on native puma populations found no definitive correlation between human hunting and the spread of FIV.Despite this, understanding the complex dynamics of FIV is crucial for effective conservation strategies. The interplay of genetic diversity, environmental factors, and interspecies interactions shapes health outcomes and informs efforts to ensure the survival of affected species In domestic cats, FIV-Fca is pathogenic and can lead to feline AIDS symptoms and subsequent death. Phylogenetic analysis shows FIV to be a monophyletic branch that diverges into three subtypes A, B, and C.Domestic cats arose more recently than other felidae species approximately around 10,000 years ago from a subspecies of wildcatFelis silvestriswhich inhabited East Asia. Genetic analysis indicates lower genetic diversity of FIV in the domestic cat compared to wild Felidae species, higher evolutionary rates, and higher mortality rates when compared to FIV-Ple and FIV-Pco.This suggests the emergence of FIV in domestic cats was recent since newly emerged viruses tend to have higher evolutionary rates with little to no co-adaption between virus and new host species occurring.Additionally, seroprevalence studies show companion cats to have a 4–12% occurrence while feral cats have an 8–19% prevalence which is much lower compared to wild felidae species which supports the hypothesis of FIV's recent emergence in this species. FIV andfeline leukemia virus(FeLV) are sometimes mistaken for one another though the viruses differ in many ways. Although they are both in the same retroviral subfamily (orthoretrovirinae), they are classified in different genera (FeLV is a gamma-retrovirus and FIV is a lentivirus like HIV-1). Their shapes are quite different: FeLV is more circular while FIV is elongated.  The two viruses are also quite different genetically, and their protein coats differ in size and composition.  Although many of the diseases caused by FeLV and FIV are similar, the specific ways in which they are caused actually differ. Also, while the feline leukemia virus may cause symptomatic illness in an infected cat, an FIV-infected cat can remain completely asymptomatic its entire lifetime.", "metadata": {"url": "https://en.wikipedia.org/wiki/FIV", "title": "Feline immunodeficiency virus", "headings": ["Contents", "Effects", "In the United States", "Pathology", "Transmission", "Disease stages", "Testing", "Treatment options", "Vaccine", "Structure", "Lentiviral vector", "Origin and spread", "Evolution", "Wild felids", "Domestic felids", "Comparison with feline leukemia virus", "See also", "References", "Citations", "General and cited sources", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Feline_immunodeficiency_virus", "https://en.wikipedia.org/wiki/Feline_immunodeficiency_virus", "https://en.wikipedia.org/wiki/Feline_immunodeficiency_virus", "https://en.wikipedia.org/wiki/Italian_Sailing_Federation", "https://en.wikipedia.org/wiki/Feline_infectious_peritonitis", "https://en.wikipedia.org/wiki/Virus_classification", "https://en.wikipedia.org/wiki/Virus", "https://en.wikipedia.org/wiki/Riboviria"]}},
{"id": "3f53349337a6", "content": "The following table indicates the party of elected officials inMassachusetts: The table also indicates the historical party composition in the: For years in which aUnited States presidential electionwas held, the table indicates which party's nominees received the state's electoral votes, and whether theyYwon the election orNlost the election. Each time an official is elected or re-elected, a new box for that official is included to indicate their repeated political party strength.", "metadata": {"url": "https://en.wikipedia.org/wiki/Political_party_strength_in_Massachusetts", "title": "Political party strength in Massachusetts", "headings": ["Contents", "1780–1843", "1844–present", "References", "See also"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Political_party_strength_in_Massachusetts", "https://en.wikipedia.org/wiki/Political_party_strength_in_Massachusetts", "https://en.wikipedia.org/wiki/Political_party_strength_in_Massachusetts", "https://en.wikipedia.org/wiki/Massachusetts", "https://en.wikipedia.org/wiki/Governor_of_Massachusetts", "https://en.wikipedia.org/wiki/Lieutenant_Governor_of_Massachusetts", "https://en.wikipedia.org/wiki/Massachusetts_Secretary_of_the_Commonwealth", "https://en.wikipedia.org/wiki/Massachusetts_Attorney_General"]}},
{"id": "4939086c5979", "content": " Donald W. Norcross(born December 13, 1958) is an American politician and labor leader who is theU.S. representativeforNew Jersey's 1st congressional districtinSouth Jersey. A member of theDemocratic Party, Norcross was first elected to this congressional seat in 2014, following the resignation ofRob Andrews. His district covers much of the New Jersey side of thePhiladelphia metro area, includingCamden,Cherry Hill,Lindenwold, andGlassboro. Before entering electoral politics, Norcross was involved in the leadership of theInternational Brotherhood of Electrical WorkersLocal 351 and was president of the Southern New JerseyAFL-CIOCentral Labor Council. He was elected to theNew Jersey General Assemblyin 2009, but shortly after his term began in January 2010, he was appointed to fill a vacancy in theNew Jersey State Senate, where he remained until his election to the House of Representatives. Norcross is a member of the committees onArmed Servicesas well asEducation and Labor. He is a member of theCongressional Progressive Caucusand theNew Democrat Coalition, and is a founding member of the Bipartisan Building Trades Caucus. Norcross was born on December 13, 1958, inCamden,the son of George E. Norcross Jr. and the brother ofGeorge E. Norcross IIIandJohn C. Norcross. He and his three brothers were raised inPennsauken Township. He graduated fromCamden County Collegewith a degree incriminal justice, and attendedRutgers University-Camden.He was raised in theLutheranfaith. In 1980, Norcross served as an apprentice in theInternational Brotherhood of Electrical Workers, eventually becoming assistant business manager of the IBEW Local 351.A former president of the Southern New Jersey Building Trades Council, he served as president of the Southern New Jersey AFL-CIO Central Labor Council for 16 years. Norcross and his running mate, Camden City Council PresidentAngel Fuentes, were elected to the Assembly in 2009 after Democratic incumbentsNilsa Cruz-PerezandJoseph J. Robertsboth retired. Shortly thereafter, Norcross was appointed to the Senate seat vacated byDana Redd, who was electedmayor of Camden. Norcross won the Senate special election in 2010 to finish out the term, then was reelected to the New Jersey Senate in 2011 and 2013. On February 4, 2014, South Jersey CongressmanRob Andrewsannounced he would resign from Congress by the end of the month, and he did so on February 18. Norcross announced his candidacy on February 5, and within a week, he was endorsed by every New Jersey congressional Democrat, State Senate PresidentStephen Sweeney, General Assembly Majority LeaderLouis Greenwald,Mayor of CamdenDana Redd, U.S. SenatorCory Booker, and former GovernorJim Florio(who represented the 1st from 1975 to 1990). Norcross won the Democratic primary—thereal contestin what has long been the only safe Democratic district in South Jersey—with 72% of the vote. He ran in two elections on November 4: a special election for the balance of Andrews's term, and a regular election for a full two-year term. He easily won both over Republican challengerGarry Cobb. He was sworn in on November 12 byHouse SpeakerJohn Boehner. Since he was added to the House roll on that date, he gained more seniority than other members of the House freshman class of 2014. Soon after his election, Norcross was appointed assistant whip, a role he reprised after his 2016 reelection.He now serves in a number of leadership roles in the Democratic Caucus, including co-chair of the Rebuilding America Task Force,member of the Steering and Policy Committee,and member of the Communications Committee.He is also the co-founder of the Bipartisan Building Trades Caucusand vice chair of the Bipartisan Task Force to Combat the Heroin Epidemic,and was appointed to the Joint Select Committee on Pension Security. In 2020, Norcross was mentioned as a possible candidate forsecretary of laborunder PresidentJoe Biden. On June 12, 2025, Norcross was one of the four Democrats who did not vote on the $9 billion spending cuts put forward by theDepartment of Government Efficiency; house Republicans passed the rescission package by 2 votes. On June 24, 2021, during a remoteUnited States House Committee on Education and Labormeeting overZoomwithSecretary of EducationMiguel Cardona, RepresentativeBob Goodwas questioning Cardona when someone interrupted by shouting \"racist!\", while Norcross's name flashed on the screen, leading participants to believe that Norcross made the remark; a later report fromFox Newsexplicitly attributed the outburst to Norcross. A letter signed by every Republican member of the committee demanded an apology from Committee ChairmanBobby Scottfor what they considered a \"slander\" and a \"smear\" against Good. Scott responded by calling the outburst \"inappropriate\" and \"out of order\". Norcross did not publicly address the incident. For the119th Congress: Norcross is married to Andrea Doran, anechocardiographer. They have two children. Norcross also has a child by his first wife, Nancy.His brotherGeorgeis aNew Jersey Democraticleader and businessman. He has two other brothers, attorney Philip A. Norcross andJohn, apsychologist, author, and professor at theUniversity of Scranton. Norcross lives in Camden. On April 7, 2025, Norcross fell ill fromcholangitiswhile on a flight, and was hospitalized atUNC Rex HealthcareinRaleigh, North Carolina.He was then transferred toCooper University Hospitalin Camden, where he was treated for the infection, which had progressed tosepsis; Norcross later said that he was close to death during this period.On April 15, his office said that he was \"responding well to treatment\" but remained in theintensive care unit.He was discharged from the hospital on May 1, to start a period of rehabilitation.He briefly returned to Congress overnight from May 21–22, 2025, to vote against theOne Big Beautiful Bill Act, before resuming a full work schedule on June 23.", "metadata": {"url": "https://en.wikipedia.org/wiki/Donald_Norcross", "title": "Donald Norcross", "headings": ["Contents", "Early life and education", "Career", "U.S. House of Representatives", "Elections", "Tenure", "Committee assignments", "Caucus memberships", "Personal life", "Electoral history", "New Jersey State Senate", "U.S. House of Representatives", "Notes", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Donald_Norcross", "https://en.wikipedia.org/wiki/Donald_Norcross", "https://en.wikipedia.org/wiki/Donald_Norcross", "https://en.wikipedia.org/wiki/United_States_House_of_Representatives", "https://en.wikipedia.org/wiki/New_Jersey", "https://en.wikipedia.org/wiki/New_Jersey%27s_1st_congressional_district", "https://en.wikipedia.org/wiki/Incumbent", "https://en.wikipedia.org/wiki/Rob_Andrews"]}},
{"id": "ad01fefe1001", "content": " United States v. Paramount Pictures, Inc., 334 U.S. 131 (1948) (also known as  theHollywood Antitrust Case of 1948, theParamount Case, or theParamount Decision), was a landmarkUnited States Supreme Courtantitrustcase that decided the fate offilm studiosowning their owntheatresand holdingexclusivity rightson which theatres would show their movies. It would also change the wayHollywoodmovies were produced,distributed, and exhibited. It also opened the door for more foreign and independent films to be shown in U.S. theaters. The Supreme Court affirmed theUnited States District Court for the Southern District of New York's ruling that the existing distribution scheme was in violation ofUnited States antitrust law, which prohibits certainexclusive dealingarrangements. The decision created theParamount Decree, a standard held by theUnited States Department of Justicethat prevented film production companies from owning exhibition companies.The case is important both in American antitrust law andfilm history. In the former, it remains a landmark decision invertical integrationcases; in the latter, it is responsible for putting an end to the old Hollywoodstudio system.\nAs part of a 2019 review of its ongoing decrees, the Department of Justice issued a two-yearsunsettingnotice for the Paramount Decree in August 2020, believing the antitrust restriction was no longer necessary as the old model could never be recreated in contemporary settings. The legal issues originated in the silent era, when theFederal Trade Commissionbegan investigating film companies for potential violations under theSherman Antitrust Actof 1890. Themajor film studiosowned the theaters where their motion pictures were shown, either in partnerships or outright. Thus specific theater chains showed only the films produced by the studio that owned them. The studios created the films, had the writers, directors, producers and actors on staff (under contract), owned the film processing and laboratories, created the prints and distributed them through the theaters that they owned: In other words, the studios werevertically integrated, creating a de factooligopoly. By 1945, the studios owned either partially or outright 17% of the theaters in the country, accounting for 45% of the film-rental revenue. Ultimately, this issue of the studios' then-alleged (and later upheld) illegal trade practices led to all the major movie studios being sued in 1938 by theU.S. Department of Justice.As the largest studio,Paramount Pictureswas the primary defendant, but all of the other Big Five (Metro-Goldwyn-Mayer,Warner Bros.,20th Century Fox, andRKO Pictures) and Little Three (Universal Pictures,Columbia Pictures, andUnited Artists) were named, and additional defendants included numerous subsidiaries and executives from each company.Separate cases were also filed against large independent chains, including the 148-theater Schine. The federal government's case was initially settled in 1940 in the District Court for the Southern District of New York with aconsent decree,which allowed the government to resume prosecution if studios were noncompliant by November, 1943. Among other requirements, the District Court-imposed consent decree included the following conditions: The studios did not fully comply with the consent decree. In 1942, they instead, withAllied Theatre Owners, proposed an alternate \"Unity Plan\". Under the Plan, larger blocks of theatres were blocked with the caveat of allowing theaters to reject films.Consequently, theSociety of Independent Motion Picture Producers(SIMPP)came into existence and thence filed a lawsuit against Paramount Detroit Theaters, representing the first major lawsuit of producers against exhibitors. The government declined to pursue the Unity proposal and instead, owing to noncompliance with the District Court's binding consent decree, resumed prosecution via the 1943 lawsuit.The 1943 case went to trial on October 8, 1945, one month and six days after the end ofWorld War II.The District Court ruled in favor of the studios, and the government immediately appealed to the Supreme Court. The case reached theUnited States Supreme Courtin 1948; their verdict went against the movie studios, forcing all of them to divest themselves of their movie theater chains.This, coupled with the advent of television and the attendance drop in movie ticket sales, brought about a severe slump in the movie business. TheParamountdecision is a bedrock of corporate antitrust law and as such is cited in most cases where issues of vertical integration play a prominent role in restricting fair trade. The Supreme Court ruled 7–1 in the government's favor, affirming much of the consent decree (JusticeRobert H. Jacksontook no part in the proceedings).William O. Douglasdelivered the Court's opinion, withFelix Frankfurterdissenting in part, arguing the Court should have left all of the decree intact except its arbitration provisions. Douglas's opinion reiterated the facts and history of the case and reviewed the Supreme Court's opinion, agreeing that its conclusion was \"incontestable\".He considered five different trade practices addressed by the consent decree: Douglas let stand the Court's sevenfold test for when a clearance agreement could be considered a restraint of trade, as he agreed they had a legitimate purpose. Pooling agreements and joint ownership, he agreed, were \"bald efforts to substitute monopoly for competition ... Clearer restraints of trade are difficult to imagine.\"He allowed, however, that courts could consider how an interest in an exhibitor was acquired; thus, he remanded some other issues back to the District Court for further inquiry and resolution. He set aside the lower court's findings on franchises so that they might be reconsidered from the perspective of allowing competitive bidding. On the block booking question, he rejected the studios' argument that it was necessary to profit from their copyrights: \"The copyright law, like the patent statutes, makes reward to the owner a secondary consideration\".The prohibitions on discrimination he let stand entirely. Frankfurter took exception to the extent to which his colleagues had agreed with the studios that the District Court had not adequately explored the underlying facts in affirming the consent decree. He pointed to then-contemporary Court decision,International Salt Co. v. United Statesthat lower courts are the proper place for such findings of fact, to be deferred to by higher courts. Also, he reminded the (Supreme) Court that the District Court had spent fifteen months considering the case and reviewed almost 4,000 pages of documentary evidence: \"I cannot bring myself to conclude that the product of such a painstaking process of adjudication as to a decree appropriate for such a complicated situation as this record discloses was an abuse of discretion.\"He would have modified the District Court decision only to permit the use ofarbitrationto resolve disputes. The court orders forcing the separation of motion picture production and exhibition companies are commonly referred to as theParamount Decrees. Paramount Pictures Inc. was forced to split into two companies: the film companyParamount Pictures Corp.and the theater chain (United Paramount Theaters), which merged in 1953 with theAmerican Broadcasting Company. Consequences of the decision include: In 1980, theUnited States Department of Justiceunder President Ronald Reagan began a review of all consent decrees that were more than 10 years old.In 1983, the Department of Justice announced that it was in the \"final stages\" of reviewing the Paramount Decrees. Eventually, in February 1985, the Department of Justice announced that, although it was not formally terminating the Paramount Decrees, it would no longer pursue enforcement of the decrees in cases where doing so was “in the public interest.” According to media historian Jennifer Holt, \"Effectively, this statement dissolved the authority of the decrees, if not legally then practically.\" In April 2018, theUnited States Department of Justice Antitrust Divisionbegan a review of antitrust decrees that did not have expiration dates.In 2019, the DOJ sought to terminate the Paramount Decrees, which would include a two-year sunset period as to the practices of block booking and circuit dealing to allow theater chains to adjust. The Department stated it was \"unlikely that the remaining defendants can reinstate their cartel\" as reasoning for terminating the decrees.The DOJ formally filed its motion for a court order to terminate the decrees on November 22, 2019.The move was opposed byindependent movie theaterowners, including the Independent Cinema Alliance, and independent filmmakers. The court granted the DOJ's motion to lift the decrees on August 7, 2020, starting a two-yearsunset termination periodof the decrees.", "metadata": {"url": "https://en.wikipedia.org/wiki/United_States_v._Paramount_Pictures,_Inc.", "title": "United States v. Paramount Pictures, Inc.", "headings": ["Contents", "Background", "Decision", "Douglas' majority opinion", "Frankfurter's concurrence/dissent", "Aftermath", "Reviews and termination of the Paramount Decrees", "See also", "References", "Further reading", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/United_States_v._Paramount_Pictures,_Inc.", "https://en.wikipedia.org/wiki/United_States_v._Paramount_Pictures,_Inc.", "https://en.wikipedia.org/wiki/United_States_v._Paramount_Pictures,_Inc.", "https://en.wikipedia.org/wiki/Supreme_Court_of_the_United_States", "https://en.wikipedia.org/wiki/United_States_Reports", "https://en.wikipedia.org/wiki/List_of_United_States_Supreme_Court_cases,_volume_334", "https://en.wikipedia.org/wiki/Lawyers%27_Edition", "https://en.wikipedia.org/wiki/LexisNexis"]}},
{"id": "460d4ac14cd8", "content": " TheISO 9000 familyis a set ofinternational standardsforquality management systems. It was developed in March 1987 byInternational Organization for Standardization. The goal of these standards is to helporganizationsensure that they meetcustomerand otherstakeholderneeds within the statutory and regulatory requirements related to a product or service. The standards were designed to fit into an integrated management system.The ISO refers to the set of standards as a \"family\", bringing together the standard for quality management systems and a set of \"supporting standards\",and their presentation as a family facilitates their integrated application within an organisation.ISO 9000 deals with the fundamentals and vocabulary of QMS,including the sevenquality managementprinciples that underlie the family of standards.ISO 9001deals with the requirements that organizations wishing to meet the standard must fulfill.A companion document, ISO/TS 9002, provides guidelines for the application of ISO 9001.ISO 9004 gives guidance on achieving sustained organizational success. Third-party certification bodies confirm that organizations meet the requirements of ISO 9001. Over one million organizations worldwideare independently certified, making ISO 9001 one of the most widely used management tools in the world today. However, the ISO certification process has been criticisedas being wasteful and not being useful for all organizations. In March 1979,BSIpublished the world's first quality management systems standard,BS 5750, as part of a response to growing concerns about the quality. BS 5750 supplied the template for the development of the ISO 9000 series in March 1987, byISO.However, its history can be traced back some twenty years before that, to the publication ofgovernment procurementstandards, such as theUnited States Department of DefenseMIL-Q-9858 standard in 1959, and the United Kingdom's Def Stan 05–21 and 05–24. Large organizations that supplied government procurement agencies often had to comply with a variety of quality assurance requirements for each contract awarded, which led the defense industry to adopt mutual recognition of NATO AQAP, MIL-Q, and Def Stan standards. Eventually, industries adopted ISO 9000 instead of forcing contractors to adopt multiple—and often similar—requirements. The global adoption of ISO 9001 may be attributable to several factors. In the early days, the ISO 9001 (9002 and 9003) requirements were intended to be used by procuring organizations, such as contractors and design activities, as the basis of contractual arrangements with their suppliers. This helped reduce the need for subcontract supplier quality development by establishing basic requirements for a supplier to assure product quality. The ISO 9001 requirements could be tailored to meet specific contractual situations, depending on the complexity of the product, business type (design responsibility, manufacture only, distribution, servicing, etc.), and risk to the procurer. For example, the food industry combined the ISO 9000 series withHACCPas a single management system.If a chosen supplier was weak in the controls of their measurement equipment (calibration), and hence QC/inspection results, that specific requirement would be invoked in the contract. Adopting a single quality assurance requirement also leads to cost savings throughout the supply chain by reducing the administrative burden of maintaining multiple sets of quality manuals and procedures. A few years later, theUK Governmenttook steps to improve national competitiveness following the publication of awhite paperon Standards, Quality and International Competitiveness, Cmd 8621,and Third-Party Certification of Quality Management Systems was born under the auspices of the National Accreditation Council of Certification Bodies (NACCB), which has become theUnited Kingdom Accreditation Service (UKAS). In addition to many stakeholders' benefits, several studies have identified significant financial benefits for organizations certified to ISO 9001, with an ISO analysis of 42 studies showing that implementing the standard enhances financial performance.Corbettet al.showed that certified organizations achieved a superiorreturn on assetscompared to otherwise similar organizations without certification. Heraset al.found similarly superior performanceand demonstrated that this was statistically significant and not a function of organization size.Naveha and Marcus claimed that implementing ISO 9001 led to superior operational performance in theU.S. automotive industry.Sharma identified similar improvements in operating performance and linked this to superior financial performance.Chow-Chuaet al.showed better overall financial performance was achieved for companies in Denmark.Rajan and Tamimi (2003) showed that ISO 9001 certification resulted in superior stock market performance and suggested that shareholders were richly rewarded for the investment in an ISO 9001 system. While the connection between superior financial performance and ISO 9001 may be seen from the examples cited, there remains no proof of direct causation, thoughlongitudinal studies, such as those of Corbettet al.(2005),may suggest it. Other writers, such as Heraset al.(2002),have indicated that while there is some evidence of this, the improvement is partly driven by the fact that there is a tendency for better-performing companies to seek ISO 9001 certification. The mechanism for improving results has also been the subject of much research. Loet al.(2007) identified operational improvements (e.g., cycle time reduction, inventory reductions) as following from certification.Internal process improvements in organizations lead to externally observable improvements.The benefit of increased international trade and domestic market share, in addition to the internal benefits such ascustomer satisfaction, interdepartmental communications, work processes, and customer/supplier partnerships derived, far exceeds any and all initial investment. The increase in ISO 9001 certification is shown in the tables below. The ISO 9000 series are based on seven quality management principles (QMPs),namely: ISO 9001:2015 Quality management systems — Requirementsis a document of approximately 30 pages  available from the national standards organization in each country. Only ISO 9001 is directly audited against for third-party assessment purposes. Contents of ISO 9001:2015 are as follows: Essentially, the layout of the standard is similar to the previous ISO 9001:2008 standard in that it follows thePlan, Do, Check, Actcycle in a process-based approach but is now further encouraging this to have risk-based thinking (section 0.3.3 of the introduction). The purpose of the quality objectives is to determine the conformity of the requirements (customers and organizations), facilitate effective deployment, and improve the quality management system. Before the certification body can issue or renew a certificate, the auditor must be satisfied that the company being assessed has implemented the requirements of sections 4 to 10.  Sections 1 to 3 are not directly audited against, but because they provide context and definitions for the rest of the standard, not that of the organization, their contents must be taken into account. The standard no longer specifies that the organization shall issue and maintain documented procedures, but ISO 9001:2015 requires the organization to document any other procedures required for its effective operation. The standard also requires the organization to issue and communicate a documentedquality policy, a quality management system scope, and quality objectives. The standard no longer requires compliant organizations to issue a formal Quality Manual. The standard does require the retention of numerous records, as specified throughout the standard. New for the 2015 release is a requirement for an organization to assess risks and opportunities (section 6.1) and to determine internal and external issues relevant to its purpose and strategic direction (section 4.1). The organization must demonstrate how the standard's requirements are being met, while the external auditor's role is to determine the quality management system's effectiveness. More detailed interpretation and implementation examples are often sought by organizations seeking more information in what can be a very technical area. TheInternational Organization for Standardization(ISO) does not certify organizations themselves. Numerous certification bodies exist that audit organizations and issue ISO 9001 compliance certificates upon success. Although commonly referred to as \"ISO 9000\" certification, the actual standard to which an organization's quality management system can be certified is ISO 9001:2015 (ISO 9001:2008 expired around September 2018). Many countries have formedaccreditationbodies to authorize (\"accredit\") the certification bodies. Both the accreditation bodies and the certification bodies charge fees for their services. The various accreditation bodies have mutual agreements with each other to ensure that certificates issued by one of theaccredited certification bodies(CB) are accepted worldwide. Certification bodies themselves operate under another quality standard, ISO/IEC 17021,while accreditation bodies operate under ISO/IEC 17011. An organization applying for ISO 9001 certification is audited based on an extensive sample of its sites, functions, products, services, and processes. The auditor presents a list of problems (defined as \"nonconformities\", \"observations\", or \"opportunities for improvement\") to management. If there are no major nonconformities, the certification body issues a certificate.  Where major nonconformities are identified, the organization presents an improvement plan to the certification body (e.g., corrective action reports showing how the problems will be resolved); once the certification body is satisfied that the organization has carried out sufficient corrective action, it issues a certificate.  The certificate is limited by a particular scope (e.g., production of golf balls) and displays the addresses to which the certificate refers. An ISO 9001 certificate is not a once-and-for-all award but must be renewed, in accordance with the requirements of ISO 17021, at regular intervals recommended by the certification body, usually once every three years.There are no grades of competence within ISO 9001: either a company is certified (meaning that it is committed to the method and model of quality management described in the standard) or it is not. In this respect, ISO 9001 certification contrasts with measurement-based quality systems. The ISO 9000 standard is continually being revised by standing technical committees and advisory groups, who receive feedback from those professionals who are implementing the standard. ISO 9000:1987 had the same structure as theBritish StandardBS 5750, with three specifications for quality management systems, the selection of which was based on the scope of activities of the organization: ISO 9000:1987was also influenced by existing U.S. and otherDefense Standards(\"MIL SPECS\"), and so was well-suited to manufacturing. The emphasis tended to be placed on conformance with procedures rather than the overall process of management, which was likely the actual intent. ISO 9000:1994emphasizedquality assurancevia preventive actions, instead of just checking final product, and continued to require evidence of compliance with documented procedures. As with the first edition, the down-side was that companies tended to implement its requirements by creating shelf-loads of procedure manuals, and becoming burdened with an ISO bureaucracy. In some companies, adapting and improving processes could actually be impeded by the quality management system. ISO 9001:2000replaced all three former standards of 1994 issues,ISO 9001,ISO 9002,andISO 9003. Design and development procedures were required only if a company does, in fact, engage in the creation of new products. The 2000 version sought to make a radical change in thinking by actually placing front and center the concept ofprocess management(the monitoring and optimization of a company's tasks and activities, instead of just inspection of the final product). The 2000 version also demanded involvement by upper executives in order to integrate quality into the business system and avoid delegation of quality functions to junior administrators. Another goal was to improve effectiveness via process performance metrics: numerical measurement of the effectiveness of tasks and activities. Expectations of continual process improvement and tracking customer satisfaction were made explicit. ISO 9000 Requirements include: ISO 9001:2008 in essence re-narrates ISO 9001:2000. The 2008 version only introduced clarifications to the existing requirements of ISO 9001:2000 and some changes intended to improve consistency withISO 14001:2004. There were no new requirements. For example, in ISO 9001:2008, a quality management system being upgraded just needs to be checked to see if it is following the clarifications introduced in the amended version. ISO 9001 is supplemented directly by two other standards of the family: Other standards, likeISO 19011and the ISO 10000 series, may also be used for specific parts of the quality system. In 2012, ISO/TC 176 – responsible for ISO 9001 development – celebrated 25 years of implementing ISO 9001and concluded that it was necessary to create a new QMS model for the next 25 years. They subsequently commenced the official work on creating a revision of ISO 9001, starting with the new QM principles. This moment was considered by important specialists in the field as the \"beginning of a new era in the development of quality management systems\".As a result of the intensive work from this technical committee, the revised standard ISO 9001:2015 was published by ISO on 23 September 2015. The scope of the standard has not changed; however, the structure and core terms were modified to allow the standard to integrate more easily with other international management systems standards. The newISO 9001:2015management system standard helps ensure that consumers can secure reliable, desired quality goods and services. This further increases benefits for a business. The 2015 version is also less prescriptive than its predecessors and focuses on performance. This was achieved by combining the process approach with\"risk-based thinking\", and employing thePlan-Do-Check-Actcycle at all levels in the organization. Some of the key changes include: \"Risk-based thinking\" is seen as a development from a traditional approach to risk management, seen as the responsibility of a \"risk manager\", to an approach which sees risk management as \"a fundamental way of thinking and decision making throughout [an] entire organization.The ISO and the International Accreditation Forum (IAF) have issued joint guidance on auditing practices covering risk-based thinking. Two types of auditing are required to become registered to the standard: auditing by an external certification body (external audit) and audits by internal staff trained for this process (internal audits). The aim is a continual review and assessment process to verify that the system is working as it is supposed to, find out where it can improve, and correct or prevent identified problems. It is considered healthier for internal auditors to audit outside their usual management line to bring a degree of independence to their judgements. Supporting papers are provided by the ISO 9001 Auditing Practices Group. This is constituted as an informal group of quality management system (QMS) experts, auditors, and practitioners, drawn from the ISO Technical Committee 176 Quality Management and Quality Assurance (ISO/TC 176) and the International Accreditation Forum (IAF). The ISO 9001 standard is generic; its parts must be carefully interpreted to make sense within a particular organization.Developing softwareis not like makingcheeseor offeringcounselingservices, yet the ISO 9001 guidelines, because they are business management guidelines, can be applied to each of these. That being said there is no requirement to cite scientific or industrial guidelines/textbooks/journals. Diverse organizations—police departments (United States), professionalsoccerteams (Mexico), and city councils (UK)—have successfully implemented ISO 9001 systems. Over time, various industry sectors have wanted to standardize their interpretations of the guidelines within their own marketplace. This is partly to ensure that their versions of ISO 9000 have their specific requirements, but also to try and ensure that more appropriately trained and experienced auditors are sent to assess them and even certify according to that interpretation. The debate on the effectiveness of ISO 9000 commonly centers on the following questions: The effectiveness of the ISO system being implemented depends on a number of factors, the most significant of which are: Proper quality management can improve business, often having a positive effect on investment, market share, sales growth, sales margins, competitive advantage, and avoidance of litigation.The quality principles in ISO 9000:2000 are also sound, according to Wadeand Barnes, who says that \"ISO 9000 guidelines provide a comprehensive model for quality management systems that can make any company competitive\".Sroufe and Curkovic, (2008) found benefits ranging from registration required to remain part of a supply base, better documentation, to cost benefits, and improved involvement and communication with management.According to the ISO,the 2015 version of the standard brings the following benefits: A common criticism of ISO 9000 and 9001 is the amount of money, time, and paperwork required for a complete implementation, and later, when needed, ISO 9001 certification.Dalgleish cites the \"inordinate and often unnecessary paperwork burden\" of ISO, and says that \"quality managers feel that ISO's overhead and paperwork are excessive and extremely inefficient\".The level of minimum documentation for a minimum scope organization has been greatly reduced,going from ISO 9001:2000 to ISO 9001:2008 to ISO 9001:2015. According to Barnes: \"Opponents claim that it is only for documentation. Proponents believe that if a company has documented its quality systems, then most of the paperwork has already been completed.\" Wilson suggests that ISO standards \"elevate inspection of the correct procedures over broader aspects of quality\", and therefore, \"the workplace becomes oppressive and quality is not improved\". One study showing reasons for not adopting this standard include the risks and uncertainty of not knowing if there are direct relationships to improved quality, and what kind and how many resources will be needed.  Additional risks include how much certification will cost, increased bureaucratic processes and risk of poor company image if the certification process fails.According toJohn Seddon, ISO 9001 promotes specification,control, and procedures rather thanunderstandingand improvement. Wade argues that ISO 9000 is effective as a guideline, but that promoting it as a standard \"helps to mislead companies into thinking that certification means better quality, ... [undermining] the need for an organization to set its own quality standards\".In short, Wade argues that reliance on the specifications of ISO 9001 does not guarantee a successful quality system. The standard is seen as especially prone to failure when a company is interested in certification before quality.Certifications are in fact often based on customer contractual requirements rather than a desire to actually improve quality.ISO's Roger Frost suggested: \"If you just want the certificate on the wall, chances are you will create a paper system that doesn't have much to do with the way you actually run your business.\" Certification by an independent auditor is often seen as the problem area, and according to Barnes, \"has become a vehicle to increase consulting services\". Dalgleish argues: \"...[while] quality has a positive effect on return on investment, market share, sales growth, better sales margins, and competitive advantage,...taking a quality approach is unrelated to ISO 9000 registration.\"In fact, ISO itself advises that ISO 9001 can be implemented without certification, simply for the quality benefits that can be achieved. Abrahamson argues that fashionable management discourse such asQuality Circlestends to follow alifecyclein the form of abell curve, possibly indicating amanagement fad. Dytz argues that ISO 9001 certification is based on 7 management principles and that companies are free to develop their internal tools and working methods, however, the model adopted to audit and certify companies does not evaluate the effectiveness of these methods. Even when there is still a superficial analysis of this effectiveness, mainly due to the time available to audit these companies, the certifications do not distinguish two companies with the same business model, with regard to their internal capacity and quality of management. Pickrell arguesthat ISO systems merely gauge whether the processes are being followed. It does not gauge how good the processes are or whether the correct parameters are being measured and controlled to ensure quality. Furthermore, when unique technical solutions are involved in the creation of a new part, ISO does not validate the robustness of the technical solution—a key part of advanced quality planning. It is not unheard of for an ISO-certified plant to display poor quality performance due to poor process selection and/or poor technical solutions. Lastly, the standard itself is proprietary, and not open to inspection by the general public. ISO 9001 certification has a three-year validity period. At the end of this period, every certified organization must renew its certificate. Not all organizations are successful in their renewal. Some organizations are not able to renew the certificate, because they do not conform to all requirements, and others simply decide not to renew the certificate.There are several reasons why an organization may lose or decide not to renew its ISO 9000 certification: According to the latest data made available by ISO, approximately 60,000 organizations lose the certification every year.Given that there are approximately 1,000,000 certified organizations worldwide, and that 1/3 of these (approx. 333,333) must renew the certificate every year, the yearly average propensity for ISO 9001 withdrawal can be estimated roughly at 18% (60,000/333,333).The propensity of a given organization to lose its certification can be estimated, depending on several factors specific to the organization:", "metadata": {"url": "https://en.wikipedia.org/wiki/Quality_Objectives", "title": "ISO 9000 family", "headings": ["Contents", "History", "Reasons for use", "Global adoption", "ISO 9000 series quality management principles", "Contents of ISO 9001:2015", "Certification", "Evolution of ISO 9000 standards", "1987 version", "1994 version", "2000 version", "2008 version", "2015 version", "Auditing", "Industry-specific interpretations", "Effectiveness", "Advantages", "Criticisms of ISO 9001 certification", "Reasons for Loss of ISO 9000 Certification", "Propensity for Loss of ISO 9000 Certification", "See also", "References", "Further reading", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/ISO_9000_family", "https://en.wikipedia.org/wiki/ISO_9000_family", "https://en.wikipedia.org/wiki/ISO_9000_family", "https://en.wikipedia.org/wiki/International_standard", "https://en.wikipedia.org/wiki/Quality_management_system", "https://en.wikipedia.org/wiki/International_Organization_for_Standardization", "https://en.wikipedia.org/wiki/Organizations", "https://en.wikipedia.org/wiki/Customer"]}},
{"id": "50a7e033d14c", "content": " Below is a list ofspecial electionsto theUnited States House of Representatives. Such elections are called bystate governorsto fill vacancies that occur when a member of theHouse of Representativesdies or resigns before the biennialgeneral election. Winners of these elections serve the remainder of the term and are usually candidates in the next general election for their districts. In the United States, these contests are called \"special elections.\"  They are sometimes held on the regularElection Daylike regular congressional elections but often they are on different days as determined by local statutes.  Despite their name, however, special elections to the U.S. House of Representatives happen often. Furthermore, one published study shows that special elections are explained by the same factors as regular congressional elections.Special elections to the U.S. House have occurred at least once in all states except Idaho. A few special elections for territorial delegates to Congress have also been held. A 2016 study of special elections to the House of Representatives found \"that while candidate characteristics affect special election outcomes, presidential approval is predictive of special election outcomes as well. Furthermore, we find that the effect of presidential approval on special election outcomes has increased in magnitude from 1995 to 2014, with the 2002 midterm representing an important juncture in the nationalization of special elections.\" In a few instances more than one seat was filled in a singlespecial election, but each seat is counted separately in the list below.", "metadata": {"url": "https://en.wikipedia.org/wiki/List_of_special_elections_to_the_United_States_House_of_Representatives", "title": "List of special elections to the United States House of Representatives", "headings": ["Contents", "List of special elections", "Summary", "See also", "Notes", "References", "Sources", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/List_of_special_elections_to_the_United_States_House_of_Representatives", "https://en.wikipedia.org/wiki/List_of_special_elections_to_the_United_States_House_of_Representatives", "https://en.wikipedia.org/wiki/List_of_special_elections_to_the_United_States_House_of_Representatives", "https://en.wikipedia.org/wiki/United_States_House_of_Representatives", "https://en.wikipedia.org/wiki/Governor_(United_States)", "https://en.wikipedia.org/wiki/United_States_House_of_Representatives", "https://en.wikipedia.org/wiki/General_election", "https://en.wikipedia.org/wiki/Election_Day_(United_States)"]}},
{"id": "bce5b4b4facf", "content": "This is alist of ISO technical committees. International Organization for Standardization(ISO) is a standards-making body, similar to theInternational Electrotechnical Commission(IEC). ISO works with National Committees in different countries in preparing and maintaining standards. ISO is the largest developer and publisher of international standards in the world. The ISO standards making process, similar to many other standards making processes, is handled by various technical committees (TC). The TCs are the key bodies that drive the standardization and comprise experts from the national committees and are a completely voluntary effort. This list is intended to detail the various technical committees of ISO, the scope of the committees, their key members and the key relevance and outputs of these committees. Disbanded Disbanded STANDBY Disbanded Disbanded Disbanded Disbanded", "metadata": {"url": "https://en.wikipedia.org/wiki/List_of_ISO_technical_committees", "title": "List of ISO technical committees", "headings": ["Contents", "Committee list", "Other bodies developing standards or guides", "See also", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/List_of_ISO_technical_committees", "https://en.wikipedia.org/wiki/List_of_ISO_technical_committees", "https://en.wikipedia.org/wiki/List_of_ISO_technical_committees", "https://en.wikipedia.org/wiki/International_Organization_for_Standardization", "https://en.wikipedia.org/wiki/International_Electrotechnical_Commission", "https://en.wikipedia.org/wiki/ISO/IEC_JTC_1", "https://en.wikipedia.org/wiki/ISO/TC_37", "https://en.wikipedia.org/wiki/ISO/TC_46"]}},
{"id": "3ca9d77b0465", "content": "Vietnam National University, Ho Chi Minh City(VNU-HCM;Vietnamese:Đại học Quốc gia Thành phố Hồ Chí Minh) is apublicresearch universitysysteminHo Chi Minh City, Vietnam. VNU-HCM is one of two Vietnam's national universities, the other one beingVietnam National University, Hanoi. It ranks 201–250th in Asia according to theQSUniversity Rankings 2020. In 2020, it was one of the first two Vietnamese universities to be included in the QS Global Ranking of Top 150 universities under 50 years old by 2021. Founded on 27 January 1995, and reorganized on 12 February 2001, under the Decision no. 15/2001/QĐ-TTg by the Prime Minister of VietnamPhan Văn Khải. The university now providesundergraduateandgraduateeducation to 56,427 students, including: The education professionals cover technology, natural sciences, basic sciences, social sciences and humanities, literature, foreign languages, and business. The headquarters of the university is in Linh Trung ward,Thủ Đức,Ho Chi Minh City. Vietnam National University, Ho Chi Minh City was founded on 27 January 1995 by Government Decree 16/CP on the basis of the merger of nine universities (members):University of Ho Chi Minh City,Thu Duc Technology Training University,Ho Chi Minh City University of Technology,Ho Chi Minh City University of Agriculture and Sylviculture,University of Economics,University of Accounting and Finance,Ho Chi Minh City University of Education(orHo Chi Minh City Pedagogical University),Ho Chi Minh City Architecture University, branch ofLaw University of Hanoiinto eight members and officially declared on 6 February 1996. On 12 February 2001, Vietnamese Prime MinisterPhan Văn Khảisigned a Decision no. 15/2001/QĐ-TTg on the reorganization of this university. According to the decision, Vietnam National University, Ho Chi Minh City, the same applied forVietnam National University, Hanoi, shall have specific internal organization and activity (unlike the one applicable for other Vietnamese universities), will be given priority to involve in education ofpostgraduateand science research of spheres of technologies, to be a pioneer in education and science, to contribute significantly to the country's economic and scientific development. Also in this decision, some member colleges were split from Ho Chi Minh City National University and came under the management of the Ministry of Education.At present, Vietnam National University, Ho Chi Minh City consists of eight member universities, two schools, and one institute: Vietnam National University, Ho Chi Minh City includes the following members:", "metadata": {"url": "https://en.wikipedia.org/wiki/Vietnam_National_University,_Ho_Chi_Minh_City", "title": "Vietnam National University, Ho Chi Minh City", "headings": ["Contents", "History", "Member universities and institute", "Schools, institutes and branches", "Affiliated units", "Board of Presidents", "President", "Vice president", "See also", "References", "Notes", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Vietnam_National_University,_Ho_Chi_Minh_City", "https://en.wikipedia.org/wiki/Vietnam_National_University,_Ho_Chi_Minh_City", "https://en.wikipedia.org/wiki/Vietnam_National_University,_Ho_Chi_Minh_City", "https://en.wikipedia.org/wiki/Geographic_coordinate_system", "https://en.wikipedia.org/wiki/University_president", "https://en.wikipedia.org/wiki/Associate_professor", "https://en.wikipedia.org/wiki/PhD", "https://en.wikipedia.org/wiki/Thu_Duc"]}},
{"id": "30f8cb52c783", "content": " Becoming Warren Buffettis a2017documentary filmaboutWarren Buffettand his life.The film was made forHBO. The documentary covers the life and career of Warren Buffett, who is widely regarded as one of the most successful and influential investors of the 20th century. Buffett is interviewed extensively on his upbringing, his early facility with mathematics and interest in investing, and his time as a young adult studying underBenjamin Grahamto learn the principles ofvalue investing(which are outlined with a series of short animated segments). Buffett's friends, family and colleagues are featured in interviews, including his wifeSusan Buffettand his longtime business partnerCharlie Munger. The New Yorkeranalyzed the dichotomy between Warren Buffett's investing prowess and personal relationship skills.The review commented, \"There's another paradox the film hints at, too: the qualities that made it challenging for Buffett to deal with people are the very qualities that made him such a brilliant investor.\"The New Yorkerobserved, \"It's also about an ability to divorce yourself from emotion, to be rational at a time when other people are acting irrationally, and to be calm when others are fearful.\" The New York Timesnoted the documentary told Buffett's biography \"in a relatively new way\".The review commented that, though the overall portrayal of the man was positive, it also described Buffett, \"as something of a remarkable human computer, gifted with numbers and less so with interpersonal relationships.\" Moneyobserved the film is, \"Chock full of the traditionalist eccentricities the 'oracle of Omaha' is best known for–like his love of Coca Cola, and the fact that he lives in the same house he bought in 1958 for $31,500\".Moneypointed out that the documentary went more in-depth than these specifics about Buffett, and \"reveals a surprising set of facts even Buffett die hards may have missed.\" According to the film critic news aggregation analysis onRotten Tomatoes, the documentary garnered positive reviews from theLos Angeles TimesandThe Washington Post, and a negative review fromEntertainment Weekly.  This article related to a made-for-TV documentary film is astub. You can help Wikipedia byexpanding it.", "metadata": {"url": "https://en.wikipedia.org/wiki/Becoming_Warren_Buffett", "title": "Becoming Warren Buffett", "headings": ["Contents", "Synopsis", "Critical reception", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Becoming_Warren_Buffett", "https://en.wikipedia.org/wiki/Becoming_Warren_Buffett", "https://en.wikipedia.org/wiki/Becoming_Warren_Buffett", "https://en.wikipedia.org/wiki/HBO", "https://en.wikipedia.org/wiki/2017_in_film", "https://en.wikipedia.org/wiki/Documentary_film", "https://en.wikipedia.org/wiki/Warren_Buffett", "https://en.wikipedia.org/wiki/HBO"]}},
{"id": "0cf3ab475015", "content": "Yau Tsim Mong Football Team(Chinese:油尖旺足球隊) is afootballclub based inYau Tsim Mong DistrictofHong Kongwhich currently competes in theHong Kong Second Division. The club was formed in 2003. The team plays its home matches atKowloon Tsai Park. The club was promoted to theHong Kong Second Division, then the second tier of Hong Kong football, in the 2006–07 season after coming second in theHong Kong Third Division \"District\" Leagueand winning the playoffs. However, they were instantly relegated back to the third tier after finishing the season with only a single win and 7 points out of 20 games, and conceding 51 goals, an average of 2.5 per game. In the 2014–15 season, the club was promoted straight from the Third Division to the First Division following the restructuring of the league, while in actuality it was promoted from the third to the second tier. The club had a strong season, winning 18 out of 28 games and finishing fourth in the league, behind eventually-promotedSouthern, as bothSun SourceandHKFCrefused promotion, one citing financial difficulties and the other to preserve its amateur aspect. In the 2015–16 season, the club won 13 out of 26 games and finished 5th in the league; having collected 46 points. In the 2016–17 season, the club lost 9–0 toEastern Districton the first matchday, and went on to have a 23-game win-less streak, getting thrashed 8–0 byMetro Gallery, 8–1 againstCitizenand 9–0 againstWong Tai Sinbefore beatingWing Yee2–1 at Tin Yip Road Park. The club finished rock-bottom of the league and got a meager 3 wins out of 26 games, conceding 109 goals (an average of 4.2 goals per game) while only scoring 24. The club was relegated to the Second Division. In the2017–18 seasonYTM once again hovered around the relegation zone all season. However, they avoided the drop late in the season by taking 13 points from their final five matches.", "metadata": {"url": "https://en.wikipedia.org/wiki/Yau_Tsim_Mong_FT", "title": "Yau Tsim Mong FT", "headings": ["Contents", "History", "Honours", "Cup Competitions", "References", "External links"], "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Yau_Tsim_Mong_FT", "https://en.wikipedia.org/wiki/Yau_Tsim_Mong_FT", "https://en.wikipedia.org/wiki/Yau_Tsim_Mong_FT", "https://en.wikipedia.org/wiki/Kowloon_Tsai_Park", "https://en.wikipedia.org/wiki/Hong_Kong_Second_Division_League", "https://en.wikipedia.org/wiki/2024%E2%80%9325_Hong_Kong_Second_Division_League", "https://en.wikipedia.org/wiki/Kit_(association_football)", "https://en.wikipedia.org/wiki/Away_colours"]}}
]