[
{"id": "ac8b3b54df41", "url": "https://en.wikipedia.org/wiki/Main_Page", "title": "Main Page", "headings": ["From today's featured article", "Did you know ...", "In the news", "On this day", "From today's featured list", "Today's featured picture", "Other areas of Wikipedia", "Wikipedia's sister projects", "Wikipedia languages"], "content": "Illinois Public Access Opinion16-006is a bindingopinionof theIllinois Attorney Generalpursuant to thestate's Freedom of Information Act(FOIA). Issued in 2016 in the aftermath of thepolice murder of Laquan McDonaldon October 20, 2014, the opinion addressed apublic recordsrequest fromCNNfor private emails by officers of theChicago Police Department(CPD) related to the incident. After the CPD denied CNN's request, the Attorney General's office, led byLisa Madigan, ruled that the police officers' private emails about McDonald's murder were subject to public disclosure, even though those emails were communicated on accounts outside of the police department's email servers. The Attorney General found that the police officers were acting on behalf of the police department, making their messages public records. Nonetheless, CNN never received the emails that it had requested, even after it went to court to enforce the Attorney General's opinion. (Full article...) October 20 There have been 36 cabinets of Liechtensteinfrom 1861 to 2025. The government of Liechtenstein is the country'snational cabinetandexecutivebody. It is chaired by theprime minister of Liechtensteinand consists of four government councillors, all of whom are also heads of specific government ministries. The seat of government is located in theGovernment BuildinginVaduz. Under the1921 constitution, one government councillor is also appointed as the deputy prime minister. Initially, governments only had two councillors and the deputy prime minister was not considered a full member of government. A constitutional amendment passed in 1965 increased the number of councillors to four and made the deputy prime minister a full member of government with voting rights. Since 10 April 2025, the incumbent government has been theBrigitte Haas cabinet, a coalition government led by thePatriotic Unionwith theProgressive Citizens' Party. (Full list...) Thecrescent-faced antpitta(Grallaricula lineifrons) is a species of bird in theantpittafamily, Grallariidae. It is found in scattered locations in the Andes, from southern Ecuador through to Colombia'sQuindío Department. It inhabits the undergrowth of humid forest, both cloudforest and elfin forest near but not past the treeline. Recent studies show that its range is almost entirely above 2,900 metres (9,500 ft) in altitude and it reaches at least 3,700 metres (12,100 ft) in places. It is 11 to 12 centimetres (4.3 to 4.7 in) long with a mass between 17 and 22 grams (0.60 and 0.78 oz). Both sexes have the same plumage, with adults featuring the eponymous white crescent from the crown through the lores and almost to the throat and a small white spot behind the eye. The crescent-faced antpitta's crown and nape are dark sooty gray, its face is black, its upperparts are brownish olive and the wings and tail a browner shade. It forages singly or in pairs as well as eating regularly from artificial feeding stations at viewing points, its diet consisting of earthworms, insects, spiders, and other arthropods. This crescent-faced antpitta was photographed at Hacienda El Bosque nearManizales, Colombia. Photograph credit:Charles J. Sharp Wikipedia is written by volunteer editors and hosted by theWikimedia Foundation, a non-profit organization that also hosts a range of other volunteerprojects: This Wikipedia is written inEnglish. Manyother Wikipedias are available; some of the largest are listed below.", "combined_text": "Main Page From today's featured article Did you know ... In the news On this day From today's featured list Today's featured picture Other areas of Wikipedia Wikipedia's sister projects Wikipedia languages Illinois Public Access Opinion16-006is a bindingopinionof theIllinois Attorney Generalpursuant to thestate's Freedom of Information Act(FOIA). Issued in 2016 in the aftermath of thepolice murder of Laquan McDonaldon October 20, 2014, the opinion addressed apublic recordsrequest fromCNNfor private emails by officers of theChicago Police Department(CPD) related to the incident. After the CPD denied CNN's request, the Attorney General's office, led byLisa Madigan, ruled that the police officers' private emails about McDonald's murder were subject to public disclosure, even though those emails were communicated on accounts outside of the police department's email servers. The Attorney General found that the police officers were acting on behalf of the police department, making their messages public records. Nonetheless, CNN never received the emails that it had requested, even after it went to court to enforce the Attorney General's opinion. (Full article...) October 20 There have been 36 cabinets of Liechtensteinfrom 1861 to 2025. The government of Liechtenstein is the country'snational cabinetandexecutivebody. It is chaired by theprime minister of Liechtensteinand consists of four government councillors, all of whom are also heads of specific government ministries. The seat of government is located in theGovernment BuildinginVaduz. Under the1921 constitution, one government councillor is also appointed as the deputy prime minister. Initially, governments only had two councillors and the deputy prime minister was not considered a full member of government. A constitutional amendment passed in 1965 increased the number of councillors to four and made the deputy prime minister a full member of government with voting rights. Since 10 April 2025, the incumbent government has been theBrigitte Haas cabinet, a coalition government led by thePatriotic Unionwith theProgressive Citizens' Party. (Full list...) Thecrescent-faced antpitta(Grallaricula lineifrons) is a species of bird in theantpittafamily, Grallariidae. It is found in scattered locations in the Andes, from southern Ecuador through to Colombia'sQuindío Department. It inhabits the undergrowth of humid forest, both cloudforest and elfin forest near but not past the treeline. Recent studies show that its range is almost entirely above 2,900 metres (9,500 ft) in altitude and it reaches at least 3,700 metres (12,100 ft) in places. It is 11 to 12 centimetres (4.3 to 4.7 in) long with a mass between 17 and 22 grams (0.60 and 0.78 oz). Both sexes have the same plumage, with adults featuring the eponymous white crescent from the crown through the lores and almost to the throat and a small white spot behind the eye. The crescent-faced antpitta's crown and nape are dark sooty gray, its face is black, its upperparts are brownish olive and the wings and tail a browner shade. It forages singly or in pairs as well as eating regularly from artificial feeding stations at viewing points, its diet consisting of earthworms, insects, spiders, and other arthropods. This crescent-faced antpitta was photographed at Hacienda El Bosque nearManizales, Colombia. Photograph credit:Charles J. Sharp Wikipedia is written by volunteer editors and hosted by theWikimedia Foundation, a non-profit organization that also hosts a range of other volunteerprojects: This Wikipedia is written inEnglish. Manyother Wikipedias are available; some of the largest are listed below.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Wikipedia", "https://en.wikipedia.org/wiki/Free_content", "https://en.wikipedia.org/wiki/Encyclopedia", "https://en.wikipedia.org/wiki/English_language", "https://en.wikipedia.org/wiki/Illinois_Public_Access_Opinion_16-006"]},
{"id": "1bb00251245f", "url": "https://en.wikipedia.org/wiki/History_of_artificial_intelligence", "title": "History of artificial intelligence", "headings": ["Contents", "Precursors", "Mythical, fictional, and speculative precursors", "Formal reasoning", "Neuroscience", "Computer science", "Birth of artificial intelligence (1941–1956)", "Turing test", "Artificial neural networks", "Cybernetic robots", "Game AI", "Symbolic reasoning and the Logic Theorist", "Dartmouth Workshop", "Cognitive revolution", "Early successes (1956–1974)", "Approaches", "Optimism", "Financing", "First AI winter (1974–1980)", "Problems", "Decrease in funding", "Philosophical and ethical critiques", "Logic at Stanford, CMU and Edinburgh", "MIT's \"anti-logic\" approach", "Boom (1980–1987)", "Expert systems become widely used", "Government funding increases", "Knowledge revolution", "New directions in the 1980s", "Revival of neural networks: \"connectionism\"", "Robotics and embodied reason", "Soft computing and probabilistic reasoning", "Reinforcement learning", "Second AI winter (1990s)", "AI winter", "AI behind the scenes", "Mathematical rigor, greater collaboration and a narrow focus", "Intelligent agents", "Milestones and Moore's law", "Arts and literature influences from AI", "Big data, deep learning, AGI (2005–2017)", "Big data and big machines", "Deep learning", "The alignment problem", "Artificial general intelligence research", "Large language models, AI boom (2017–present)", "Transformer architecture and large language models", "Investment in AI", "Advent of AI for public use", "2024 Nobel Prizes", "Further study and development of AI", "National policies", "See also", "Notes", "References", "Works cited"], "content": "  Thehistory of artificial intelligence(AI) began inantiquity, with myths, stories, and rumors of artificial beings endowed with intelligence or consciousness by master craftsmen. The study of logic and formal reasoning from antiquity to the present led directly to the invention of theprogrammable digital computerin the 1940s, a machine based on abstract mathematical reasoning. This device and the ideas behind it inspired scientists to begin discussing the possibility of building anelectronic brain. The field of AI research was founded at aworkshopheld on the campus ofDartmouth Collegein 1956.Attendees of the workshop became the leaders of AI research for decades. Many of them predicted that machines as intelligent as humans would exist within a generation. TheU.S. governmentprovided millions of dollars with the hope of making this vision come true. Eventually, it became obvious that researchers had grossly underestimated the difficulty of this feat.In 1974, criticism fromJames Lighthilland pressure from the U.S.A. Congress led the U.S. andBritish Governmentsto stop funding undirected research into artificial intelligence. Seven years later, a visionary initiative by theJapanese Governmentand the success ofexpert systemsreinvigorated investment in AI, and by the late 1980s, the industry had grown into a billion-dollar enterprise. However, investors' enthusiasm waned in the 1990s, and the field was criticized in the press and avoided by industry (a period known as an \"AI winter\"). Nevertheless, research and funding continued to grow under other names. In the early 2000s,machine learningwas applied to a wide range of problems in academia and industry. The success was due to the availability of powerful computer hardware, the collection of immense data sets, and the application of solid mathematical methods. Soon after,deep learningproved to be a breakthrough technology, eclipsing all other methods. Thetransformer architecturedebuted in 2017 and was used to produce impressivegenerative AIapplications, amongst other use cases. Investment in AIboomedin the 2020s. The recent AI boom, initiated by the development of transformer architecture, led to the rapid scaling and public releases oflarge language models(LLMs) likeChatGPT. These models exhibit human-like traits of knowledge, attention, and creativity, and have been integrated into various sectors, fueling exponential investment in AI. However, concerns about the potential risks andethical implications of advanced AIhave also emerged, causing debate about the future of AI and its impact on society. InGreek mythology,Taloswas a creature made of bronze who acted as guardian for theisland of Crete. He would throw boulders at the ships of invaders and would complete 3 circuits around the island's perimeter daily.According topseudo-Apollodorus'Bibliotheke, Hephaestus forged Talos with the aid of a cyclops and presented theautomatonas a gift toMinos.In theArgonautica,Jasonand theArgonautsdefeated Talos by removing a plug near his foot, causing the vitalichorto flow out from his body and rendering him lifeless. Pygmalionwas a legendary king and sculptor of Greek mythology, famously represented inOvid'sMetamorphoses. In the 10th book of Ovid's narrative poem, Pygmalion becomes disgusted with women when he witnesses the way in which thePropoetidesprostitute themselves. Despite this, he makes offerings at the temple of Venus asking the goddess to bring to him a woman just like a statue he carved. InOf the Nature of Things, the Swiss alchemistParacelsusdescribes a procedure that he claims can fabricate an \"artificial man\". By placing the \"sperm of a man\" in horse dung, and feeding it the \"Arcanum of Mans blood\" after 40 days, the concoction will become a living infant. The earliest written account regarding golem-making is found in the writings ofEleazar ben Judah of Wormsin the early 13th century.During the Middle Ages, it was believed that the animation of aGolemcould be achieved by insertion of a piece of paper with any of God's names on it, into the mouth of the clay figure.Unlike legendary automata likeBrazen Heads,aGolemwas unable to speak. Takwin, the artificial creation of life, was a frequent topic ofIsmailialchemical manuscripts, especially those attributed toJabir ibn Hayyan. Islamic alchemists attempted to create a broad range of life through their work, ranging from plants to animals. InFaust: The Second Part of the TragedybyJohann Wolfgang von Goethe, an alchemically fabricatedhomunculus, destined to live forever in the flask in which he was made, endeavors to be born into a full human body. Upon the initiation of this transformation, however, the flask shatters and the homunculus dies. By the 19th century, ideas about artificial men and thinking machines became a popular theme in fiction. Notable works likeMary Shelley'sFrankensteinandKarel Čapek'sR.U.R. (Rossum's Universal Robots)explored the concept of artificial life. Speculative essays, such asSamuel Butler's \"Darwin among the Machines\",andEdgar Allan Poe's\"Maelzel's Chess Player\"reflected society's growing interest in machines with artificial intelligence. AI remains a common topic in science fiction today. Realistic humanoidautomatawere built by craftsman from many civilizations, includingYan Shi,Hero of Alexandria,Al-Jazari,Haroun al-Rashid,Jacques de Vaucanson,Leonardo Torres y Quevedo,Pierre Jaquet-DrozandWolfgang von Kempelen. The oldest known automata were thesacred statuesofancient EgyptandGreece.The faithful believed that craftsman had imbued these figures with very real minds, capable of wisdom and emotion—Hermes Trismegistuswrote that \"by discovering the true nature of the gods, man has been able to reproduce it\".English scholarAlexander Neckhamasserted that the Ancient Roman poetVirgilhad built a palace with automaton statues. During the early modern period, these legendary automata were said to possess the magical ability to answer questions put to them. The late medieval alchemist and proto-ProtestantRoger Baconwas purported to have fabricated abrazen head, having developed a legend of having been a wizard.These legends were similar to the Norse myth of the Head ofMímir. According to legend, Mímir was known for his intellect and wisdom, and was beheaded in theÆsir-Vanir War.Odinis said to have \"embalmed\" the head with herbs and spoke incantations over it such that Mímir's head remained able to speak wisdom to Odin. Odin then kept the head near him for counsel. Artificial intelligence is based on the assumption that the process of human thought can be mechanized. The study of mechanical—or \"formal\"—reasoning has a long history.Chinese,IndianandGreekphilosophers all developed structured methods of formal deduction by the first millennium BCE. Their ideas were developed over the centuries by philosophers such asAristotle(who gave a formal analysis of thesyllogism),Euclid(whoseElementswas a model of formal reasoning),al-Khwārizmī(who developedalgebraand gave his name to the wordalgorithm) and Europeanscholasticphilosophers such asWilliam of OckhamandDuns Scotus. Spanish philosopherRamon Llull(1232–1315) developed severallogical machinesdevoted to the production of knowledge by logical means;Llull described his machines as mechanical entities that could combine basic and undeniable truths by simple logical operations, produced by the machine by mechanical meanings, in such ways as to produce all the possible knowledge.Llull's work had a great influence onGottfried Leibniz, who redeveloped his ideas. In the 17th century,Leibniz,Thomas HobbesandRené Descartesexplored the possibility that all rational thought could be made as systematic as algebra or geometry.Hobbesfamously wrote inLeviathan: \"Forreason... is nothing butreckoning, that is adding and subtracting\".Leibnizenvisioned a universal language of reasoning, thecharacteristica universalis, which would reduce argumentation to calculation so that \"there would be no more need of disputation between two philosophers than between two accountants. For it would suffice to take their pencils in hand, down to their slates, and to say each other (with a friend as witness, if they liked):Let us calculate.\"These philosophers had begun to articulate thephysical symbol systemhypothesis that would guide AI research. The study ofmathematical logicprovided the essential breakthrough that made artificial intelligence seem plausible. The foundations had been set by such works asBoole'sThe Laws of ThoughtandFrege'sBegriffsschrift.Building onFrege's system,RussellandWhiteheadpresented a formal treatment of the foundations of mathematics in their masterpiece, thePrincipia Mathematicain 1913. Inspired byRussell's success,David Hilbertchallenged mathematicians of the 1920s and 30s to answer this fundamental question: \"can all of mathematical reasoning be formalized?\"His question was answered byGödel'sincompleteness proof,Turing'smachineandChurch'sLambda calculus. Their answer was surprising in two ways. First, they proved that there were, in fact, limits to what mathematical logic could accomplish. But second (and more important for AI) their work suggested that, within these limits,anyform of mathematical reasoning could be mechanized. TheChurch-Turing thesisimplied that a mechanical device, shuffling symbols as simple as0and1, could imitate any conceivable process of mathematical deduction.The key insight was theTuring machine—a simple theoretical construct that captured the essence of abstract symbol manipulation.This invention would inspire a handful of scientists to begin discussing the possibility of thinking machines. In the 18th and 19th centuryLuigi Galvani,Emil du Bois-Reymond,Hermann von Helmholtzand others demonstrated that the nerves carried electrical signals andRobert Bentley Toddcorrectly speculated in 1828 that the brain was an electrical network.Camillo Golgi's staining techniques enabledSantiago Ramón y Cajalto provide evidence for theneuron theory: \"The truly amazing conclusion is that a collection of simple cells can lead to thought, action, and consciousness\". Donald Hebbwas a Canadian psychologist whose work laid the foundation for modern neuroscience, particularly in understanding learning, memory, and neural plasticity. His most influential book,The Organization of Behavior(1949), introduced the concept of Hebbian learning, often summarized as \"cells that fire together wire together.\" Hebb began formulating the foundational ideas for this book in the early 1940s, particularly during his time at the Yerkes Laboratories of Primate Biology from 1942 to 1947. He made extensive notes between June 1944 and March 1945 and sent a complete draft to his mentor Karl Lashley in 1946. The manuscript forThe Organization of Behaviorwasn’t published until 1949. The delay was due to various factors, including World War II and shifts in academic focus. By the time it was published, several of his peers had already published related ideas, making Hebb's work seem less groundbreaking at first glance. However, his synthesis of psychological and neurophysiological principles became a cornerstone of neuroscience and machine learning. Calculating machines were designed or built in antiquity and throughout history by many people, includingGottfried Leibniz,Joseph Marie Jacquard,Charles Babbage,Percy Ludgate,Leonardo Torres Quevedo,Vannevar Bush,and others.Ada Lovelacespeculated that Babbage's machine was \"a thinking or ... reasoning machine\", but warned \"It is desirable to guard against the possibility of exaggerated ideas that arise as to the powers\" of the machine. The first modern computers were the massive machines of theSecond World War(such asKonrad Zuse'sZ3,Alan Turing'sHeath RobinsonandColossus,AtanasoffandBerry'sABC, andENIACat theUniversity of Pennsylvania).ENIACwas based on the theoretical foundation laid byAlan Turingand developed byJohn von Neumann,and proved to be the most influential. The earliest research into thinking machines was inspired by a confluence of ideas that became prevalent in the late 1930s, 1940s, and early 1950s. Recent research inneurologyhad shown that the brain was an electrical network ofneuronsthat fired in all-or-nothing pulses.Norbert Wiener'scyberneticsdescribed control and stability in electrical networks.Claude Shannon'sinformation theorydescribed digital signals (i.e., all-or-nothing signals).Alan Turing'stheory of computationshowed that any form of computation could be described digitally. The close relationship between these ideas suggested that it might be possible to construct an \"electronic brain\". In the 1940s and 50s, a handful of scientists from a variety of fields (mathematics, psychology, engineering, economics and political science) explored several research directions that would be vital to later AI research.Alan Turing was among the first people to seriously investigate the theoretical possibility of \"machine intelligence\".The field of \"artificial intelligence research\" was founded as an academic discipline in 1956. In 1950 Turing published a landmark paper \"Computing Machinery and Intelligence\", in which he speculated about the possibility of creating machines that think.In the paper, he noted that \"thinking\" is difficult to define and devised his famousTuring test: If a machine could carry on a conversation (over ateleprinter) that was indistinguishable from a conversation with a human being, then it was reasonable to say that the machine was \"thinking\".This simplified version of the problem allowed Turing to argue convincingly that a \"thinking machine\" was at leastplausibleand the paper answered all the most common objections to the proposition.The Turing test was the first serious proposal in thephilosophy of artificial intelligence. Walter PittsandWarren McCullochanalyzed networks of idealizedartificial neuronsand showed how they might perform simple logical functions in 1943. They were the first to describe what later researchers would call aneural network.The paper was influenced by Turing's paper \"On Computable Numbers\" from 1936 using similar two-state boolean 'neurons', but was the first to apply it to neuronal function.One of the students inspired by Pitts and McCulloch wasMarvin Minskywho was a 24-year-old graduate student at the time. In 1951 Minsky and Dean Edmonds built the first neural net machine, theSNARC.Minsky would later become one of the most important leaders and innovators in AI. Experimental robots such asW. Grey Walter'sturtlesand theJohns Hopkins Beast, were built in the 1950s. These machines did not use computers, digital electronics, or symbolic reasoning; they were controlled entirely by analog circuitry. In 1951, using theFerranti Mark 1machine of theUniversity of Manchester,Christopher Stracheywrote a checkers programandDietrich Prinzwrote one for chess.Arthur Samuel's checkers program, the subject of his 1959 paper \"Some Studies in Machine Learning Using the Game of Checkers\", eventually achieved sufficient skill to challenge a respectable amateur.Samuel's program was among the first uses of what would later be calledmachine learning.Game AIwould continue to be used as a measure of progress in AI throughout its history. When access todigital computersbecame possible in the mid-fifties, a few scientists instinctively recognized that a machine that could manipulate numbers could also manipulate symbols and that the manipulation of symbols could well be the essence of human thought. This was a new approach to creating thinking machines. In 1955,Allen Newelland future Nobel LaureateHerbert A. Simoncreated the \"Logic Theorist\", with help fromJ. C. Shaw. The program would eventually prove 38 of the first 52 theorems inRussellandWhitehead'sPrincipia Mathematica, and find new and more elegant proofs for some.Simon said that they had \"solved the venerablemind/body problem, explaining how a system composed of matter can have the properties of mind.\"The symbolic reasoning paradigm they introduced would dominate AI research and funding until the middle 90s, as well as inspire thecognitive revolution. The Dartmouth workshop of 1956 was a pivotal event that marked the formal inception of AI as an academic discipline.It was organized byMarvin MinskyandJohn McCarthy, with the support of two senior scientistsClaude ShannonandNathan RochesterofIBM. The proposal for the conference stated they intended to test the assertion that \"every aspect of learning or any other feature of intelligence can be so precisely described that a machine can be made to simulate it\".The term \"Artificial Intelligence\" was introduced by John McCarthy at the workshop.The participants includedRay Solomonoff,Oliver Selfridge,Trenchard More,Arthur Samuel,Allen NewellandHerbert A. Simon, all of whom would create important programs during the first decades of AI research.At the workshop Newell and Simon debuted the \"Logic Theorist\".The workshop was the moment that AI gained its name, its mission, its first major success and its key players, and is widely considered the birth of AI. In the autumn of 1956, Newell and Simon also presented the Logic Theorist at a meeting of the Special Interest Group in Information Theory at theMassachusetts Institute of Technology(MIT). At the same meeting,Noam Chomskydiscussed hisgenerative grammar, andGeorge Millerdescribed his landmark paper \"The Magical Number Seven, Plus or Minus Two\". Miller wrote \"I left the symposium with a conviction, more intuitive than rational, that experimental psychology, theoretical linguistics, and the computer simulation of cognitive processes were all pieces from a larger whole.\" This meeting was the beginning of the \"cognitive revolution\"—an interdisciplinaryparadigm shiftin psychology, philosophy, computer science and neuroscience. It inspired the creation of the sub-fields ofsymbolic artificial intelligence,generative linguistics,cognitive science,cognitive psychology,cognitive neuroscienceand the philosophical schools ofcomputationalismandfunctionalism. All these fields used related tools to model the mind and results discovered in one field were relevant to the others. The cognitive approach allowed researchers to consider \"mental objects\" like thoughts, plans, goals, facts or memories, often analyzed usinghigh level symbolsin functional networks. These objects had been forbidden as \"unobservable\" by earlier paradigms such asbehaviorism.Symbolic mental objects would become the major focus of AI research and funding for the next several decades. The programs developed in the years after theDartmouth Workshopwere, to most people, simply \"astonishing\":computers were solving algebra word problems, proving theorems in geometry and learning to speak English. Few at the time would have believed that such \"intelligent\" behavior by machines was possible at all.Researchers expressed an intense optimism in private and in print, predicting that a fully intelligent machine would be built in less than 20 years.Government agencies like theDefense Advanced Research Projects Agency(DARPA, then known as \"ARPA\") poured money into the field.Artificial Intelligence laboratories were set up at a number of British and US universities in the latter 1950s and early 1960s. There were many successful programs and new directions in the late 50s and 1960s. Among the most influential were these: Many early AI programs used the same basicalgorithm. To achieve some goal (like winning a game or proving a theorem), they proceeded step by step towards it (by making a move or a deduction) as if searching through a maze,backtrackingwhenever they reached a dead end.The principal difficulty was that, for many problems, the number of possible paths through the \"maze\" was astronomical (a situation known as a \"combinatorial explosion\"). Researchers would reduce the search space by usingheuristicsthat would eliminate paths that were unlikely to lead to a solution. NewellandSimontried to capture a general version of this algorithm in a program called the \"General Problem Solver\".Other \"searching\" programs were able to accomplish impressive tasks like solving problems in geometry and algebra, such asHerbert Gelernter's Geometry Theorem Prover (1958)and Symbolic Automatic Integrator (SAINT), written byMinsky'sstudent James Slagle in 1961.Other programs searched through goals and subgoals toplan actions, like theSTRIPSsystem developed atStanfordto control the behavior of the robotShakey. An important goal of AI research is to allow computers to communicate innatural languageslike English. An early success wasDaniel Bobrow's programSTUDENT, which could solve high school algebra word problems. Asemantic netrepresents concepts (e.g. \"house\", \"door\") as nodes, and relations among concepts as links between the nodes (e.g. \"has-a\"). The first AI program to use a semantic net was written by Ross Quillianand the most successful (and controversial) version wasRoger Schank'sConceptual dependency theory. Joseph Weizenbaum'sELIZAcould carry out conversations that were so realistic that users occasionally were fooled into thinking they were communicating with a human being and not a computer program (seeELIZA effect). But in fact, ELIZA simply gave acanned responseor repeated back what was said to it, rephrasing its response with a few grammar rules. ELIZA was the firstchatbot. In the late 60s,Marvin MinskyandSeymour Papertof theMITAI Laboratory proposed that AI research should focus on artificially simple situations known as micro-worlds.They pointed out that in successful sciences like physics, basic principles were often best understood using simplified models like frictionless planes or perfectly rigid bodies. Much of the research focused on a \"blocks world,\" which consists of colored blocks of various shapes and sizes arrayed on a flat surface. This paradigm led to innovative work inmachine visionbyGerald Sussman, Adolfo Guzman,David Waltz(who invented \"constraint propagation\"), and especiallyPatrick Winston. At the same time, Minsky and Papert built a robot arm that could stack blocks, bringing the blocks world to life.Terry Winograd'sSHRDLUcould communicate in ordinary English sentences about the micro-world, plan operations and execute them. In the 1960s funding was primarily directed towards laboratories researchingsymbolic AI, however several people still pursued research in neural networks. Theperceptron, a single-layerneural networkwas introduced in 1958 byFrank Rosenblatt(who had been a schoolmate ofMarvin Minskyat theBronx High School of Science).Like most AI researchers, he was optimistic about their power, predicting that a perceptron \"may eventually be able to learn, make decisions, and translate languages.\"Rosenblatt was primarily funded byOffice of Naval Research. Bernard Widrowand his studentTed HoffbuiltADALINE(1960) andMADALINE(1962), which had up to 1000 adjustable weights.A group atStanford Research Instituteled byCharles A. Rosenand Alfred E. (Ted) Brain built two neural network machines named MINOS I (1960) and II (1963), mainly funded byU.S. Army Signal Corps. MINOS IIhad 6600 adjustable weights,and was controlled with anSDS 910 computerin a configuration named MINOS III (1968), which could classify symbols on army maps, and recognize hand-printed characters onFortrancoding sheets.Most of neural network research during this early period involved building and using bespoke hardware, rather than simulation on digital computers. However, partly due to lack of results and partly due to competition fromsymbolic AIresearch, the MINOS project ran out of funding in 1966. Rosenblatt failed to secure continued funding in the 1960s.In 1969 research came to a sudden halt with the publication ofMinskyandPapert's1969 bookPerceptrons.It suggested that there were severe limitations to what perceptrons could do and that Rosenblatt's predictions had been grossly exaggerated. The effect of the book was that virtually no research was funded inconnectionismfor 10 years.The competition for government funding ended with the victory of symbolic AI approaches over neural networks. Minsky (who had worked onSNARC) became a staunch objector to pure connectionist AI.Widrow(who had worked onADALINE) turned to adaptive signal processing. TheSRIgroup (which worked on MINOS) turned to symbolic AI and robotics. The main problem was the inability to train multilayered networks (versions ofbackpropagationhad already been used in other fields but it was unknown to these researchers).The AI community became aware of backpropogation in the 80s,and, in the 21st century, neural networks would become enormously successful, fulfilling all of Rosenblatt's optimistic predictions. Rosenblatt did not live to see this, however, as he died in a boating accident in 1971. The first generation of AI researchers made these predictions about their work: In June 1963,MITreceived a $2.2 million grant from the newly created Advanced Research Projects Agency (ARPA, later known asDARPA). The money was used to fundproject MACwhich subsumed the \"AI Group\" founded byMinskyandMcCarthyfive years earlier. DARPA continued to provide $3 million each year until the 70s.DARPA made similar grants toNewellandSimon'sprogram atCarnegie Mellon Universityand toStanford University'sAI Lab, founded byJohn McCarthyin 1963.Another important AI laboratory was established atEdinburgh UniversitybyDonald Michiein 1965.These four institutions would continue to be the main centers of AI research and funding in academia for many years. The money was given with few strings attached:J. C. R. Licklider, then the director of ARPA, believed that his organization should \"fund people, not projects!\" and allowed researchers to pursue whatever directions might interest them.This created a freewheeling atmosphere at MIT that gave birth to thehacker culture,but this \"hands off\" approach did not last. In the 1970s, AI was subject to critiques and financial setbacks. AI researchers had failed to appreciate the difficulty of the problems they faced. Their tremendous optimism had raised public expectations impossibly high, and when the promised results failed to materialize, funding targeted at AI was severely reduced.The lack of success indicated the techniques being used by AI researchers at the time were insufficient to achieve their goals. These setbacks did not affect the growth and progress of the field, however. The funding cuts only impacted a handful of major laboratoriesand the critiques were largely ignored.General public interest in the field continued to grow,the number of researchers increased dramatically,and new ideas were explored inlogic programming,commonsense reasoningand many other areas. Historian Thomas Haigh argued in 2023 that there was no winter,and AI researcherNils Nilssondescribed this period as the most \"exciting\" time to work in AI. In the early seventies, the capabilities of AI programs were limited. Even the most impressive could only handle trivial versions of the problems they were supposed to solve;all the programs were, in some sense, \"toys\".AI researchers had begun to run into several limits that would be only conquered decades later, and others that still stymie the field in the 2020s: The agencies which funded AI research, such as theBritish government,DARPAand theNational Research Council(NRC) became frustrated with the lack of progress and eventually cut off almost all funding for undirected AI research. The pattern began in 1966 when theAutomatic Language Processing Advisory Committee(ALPAC) report criticized machine translation efforts. After spending $20 million, theNRCended all support.In 1973, theLighthill reporton the state of AI research in the UK criticized the failure of AI to achieve its \"grandiose objectives\" and led to the dismantling of AI research in that country.(The report specifically mentioned thecombinatorial explosionproblem as a reason for AI's failings.)DARPA was deeply disappointed with researchers working on theSpeech Understanding Researchprogram at CMU and canceled an annual grant of $3 million. Hans Moravecblamed the crisis on the unrealistic predictions of his colleagues. \"Many researchers were caught up in a web of increasing exaggeration.\"However, there was another issue: since the passage of theMansfield Amendmentin 1969,DARPAhad been under increasing pressure to fund \"mission-oriented direct research, rather than basic undirected research\". Funding for the creative, freewheeling exploration that had gone on in the 60s would not come from DARPA, which instead directed money at specific projects with clear objectives, such asautonomoustanks andbattle managementsystems. The major laboratories (MIT, Stanford, CMU and Edinburgh) had been receiving generous support from their governments, and when it was withdrawn, these were the only places that were seriously impacted by the budget cuts. The thousands of researchers outside these institutions and the many more thousands that were joining the field were unaffected. Several philosophers had strong objections to the claims being made by AI researchers. One of the earliest wasJohn Lucas, who argued thatGödel's incompleteness theoremshowed that aformal system(such as a computer program) could never see the truth of certain statements, while a human being could.Hubert Dreyfusridiculed the broken promises of the 1960s and critiqued the assumptions of AI, arguing that human reasoning actually involved very little \"symbol processing\" and a great deal ofembodied,instinctive, unconscious \"know how\".John Searle'sChinese Roomargument, presented in 1980, attempted to show that a program could not be said to \"understand\" the symbols that it uses (a quality called \"intentionality\"). If the symbols have no meaning for the machine, Searle argued, then the machine can not be described as \"thinking\". These critiques were not taken seriously by AI researchers. Problems likeintractabilityandcommonsense knowledgeseemed much more immediate and serious. It was unclear what difference \"know how\" or \"intentionality\" made to an actual computer program. MIT'sMinskysaid of Dreyfus and Searle \"they misunderstand, and should be ignored.\"Dreyfus, who also taught atMIT, was given a cold shoulder: he later said that AI researchers \"dared not be seen having lunch with me.\"Joseph Weizenbaum, the author ofELIZA, was also an outspoken critic of Dreyfus' positions, but he \"deliberately made it plain that [his AI colleagues' treatment of Dreyfus] was not the way to treat a human being,\"and was unprofessional and childish. Weizenbaum began to have serious ethical doubts about AI whenKenneth Colbywrote a \"computer program which can conductpsychotherapeuticdialogue\" based on ELIZA.Weizenbaum was disturbed that Colby saw a mindless program as a serious therapeutic tool. A feud began, and the situation was not helped when Colby did not credit Weizenbaum for his contribution to the program. In 1976,WeizenbaumpublishedComputer Power and Human Reasonwhich argued that the misuse of artificial intelligence has the potential to devalue human life. Logic was introduced into AI research as early as 1958, byJohn McCarthyin hisAdvice Takerproposal.In 1963,J. Alan Robinsonhad discovered a simple method to implement deduction on computers, theresolutionandunificationalgorithm.However, straightforward implementations, like those attempted by McCarthy and his students in the late 1960s, were especially intractable: the programs required astronomical numbers of steps to prove simple theorems.A more fruitful approach to logic was developed in the 1970s byRobert Kowalskiat theUniversity of Edinburgh, and soon this led to the collaboration with French researchersAlain ColmerauerandPhilippe Roussel[fr]who created the successful logic programming languageProlog.Prolog uses a subset of logic (Horn clauses, closely related to \"rules\" and \"production rules\") that permit tractable computation. Rules would continue to be influential, providing a foundation forEdward Feigenbaum'sexpert systemsand the continuing work byAllen NewellandHerbert A. Simonthat would lead toSoarand theirunified theories of cognition. Critics of the logical approach noted, asDreyfushad, that human beings rarely used logic when they solved problems. Experiments by psychologists likePeter Wason,Eleanor Rosch,Amos Tversky,Daniel Kahnemanand others provided proof.McCarthy responded that what people do is irrelevant. He argued that what is really needed are machines that can solve problems—not machines that think as people do. Among the critics ofMcCarthy'sapproach were his colleagues across the country atMIT.Marvin Minsky,Seymour PapertandRoger Schankwere trying to solve problems like \"story understanding\" and \"object recognition\" thatrequireda machine to think like a person. In order to use ordinary concepts like \"chair\" or \"restaurant\" they had to make all the same illogical assumptions that people normally made. Unfortunately, imprecise concepts like these are hard to represent in logic. MIT chose instead to focus on writing programs that solved a given task without using high-level abstract definitions or general theories of cognition, and measured performance by iterative testing, rather than arguments from first principles.Schankdescribed their \"anti-logic\" approaches asscruffy, as opposed to theneatparadigm used byMcCarthy,Kowalski,Feigenbaum,NewellandSimon. In 1975, in a seminal paper,Minskynoted that many of his fellow researchers were using the same kind of tool: a framework that captures all ourcommon sense assumptionsabout something. For example, if we use the concept of a bird, there is a constellation of facts that immediately come to mind: we might assume that it flies, eats worms and so on (none of which are true for all birds). Minsky associated these assumptions with the general category and they could beinheritedby the frames for subcategories and individuals, or over-ridden as necessary. He called these structuresframes.Schankused a version of frames he called \"scripts\" to successfully answer questions about short stories in English.Frames would eventually be widely used insoftware engineeringunder the nameobject-oriented programming. The logicians rose to the challenge.Pat Hayesclaimed that \"most of 'frames' is just a new syntax for parts of first-order logic.\" But he noted that \"there are one or two apparently minor details which give a lot of trouble, however, especially defaults\". Ray Reiteradmitted that \"conventional logics, such as first-order logic, lack the expressive power to adequately represent the knowledge required for reasoning by default\".He proposed augmenting first-order logic with aclosed world assumptionthat a conclusion holds (by default) if its contrary cannot be shown. He showed how such an assumption corresponds to the common sense assumption made in reasoning with frames. He also showed that it has its \"procedural equivalent\" asnegation as failureinProlog. The closed world assumption, as formulated by Reiter, \"is not a first-order notion. (It is a meta notion.)\"However,Keith Clarkshowed that negation asfinite failurecan be understood as reasoning implicitly with definitions in first-order logic including aunique name assumptionthat different terms denote different individuals. During the late 1970s and throughout the 1980s, a variety of logics and extensions of first-order logic were developed both for negation as failure inlogic programmingand for default reasoning more generally. Collectively, these logics have become known asnon-monotonic logics. In the 1980s, a form of AI program called \"expert systems\" was adopted by corporations around the world andknowledgebecame the focus of mainstream AI research. Governments provided substantial funding, such as Japan'sfifth generation computerproject and the U.S.Strategic Computing Initiative. \"Overall, the AI industry boomed from a few million dollars in 1980 to billions of dollars in 1988.\" Anexpert systemis a program that answers questions or solves problems about a specific domain of knowledge, using logicalrulesthat are derived from the knowledge of experts.The earliest examples were developed byEdward Feigenbaumand his students.Dendral, begun in 1965, identified compounds from spectrometer readings.MYCIN, developed in 1972, diagnosed infectious blood diseases.They demonstrated the feasibility of the approach. Expert systems restricted themselves to a small domain of specific knowledge (thus avoiding thecommonsense knowledgeproblem)and their simple design made it relatively easy for programs to be built and then modified once they were in place. All in all, the programs proved to beuseful: something that AI had not been able to achieve up to this point. In 1980, an expert system calledR1was completed atCMUfor theDigital Equipment Corporation. It was an enormous success: it was saving the company 40 million dollars annually by 1986.Corporations around the world began to develop and deploy expert systems and by 1985 they were spending over a billion dollars on AI, most of it to in-house AI departments.An industry grew up to support them, including hardware companies likeSymbolicsandLisp Machinesand software companies such asIntelliCorpandAion. In 1981, theJapanese Ministry of International Trade and Industryset aside $850 million for theFifth generation computerproject. Their objectives were to write programs and build machines that could carry on conversations, translate languages, interpret pictures, and reason like human beings.Much to the chagrin ofscruffies, they initially chosePrologas the primary computer language for the project. Other countries responded with new programs of their own. The UK began the £350 millionAlveyproject.A consortium of American companies formed theMicroelectronics and Computer Technology Corporation(or \"MCC\") to fund large scale projects in AI and information technology.DARPAresponded as well, founding theStrategic Computing Initiativeand tripling its investment in AI between 1984 and 1988. The power of expert systems came from the expert knowledge they contained. They were part of a new direction in AI research that had been gaining ground throughout the 70s. \"AI researchers were beginning to suspect—reluctantly, for it violated the scientific canon ofparsimony—that intelligence might very well be based on the ability to use large amounts of diverse knowledge in different ways,\"writesPamela McCorduck. \"[T]he great lesson from the 1970s was that intelligent behavior depended very much on dealing with knowledge, sometimes quite detailed knowledge, of a domain where a given task lay\".Knowledge based systemsandknowledge engineeringbecame a major focus of AI research in the 1980s.It was hoped that vast databases would solve thecommonsense knowledgeproblem and provide the support thatcommonsense reasoningrequired. In the 1980s some researchers attempted to attack thecommonsense knowledge problemdirectly, by creating a massive database that would contain all the mundane facts that the average person knows.Douglas Lenat, who started a database calledCyc, argued that there is no shortcut―the only way for machines to know the meaning of human concepts is to teach them, one concept at a time, by hand. Although symbolicknowledge representationandlogical reasoningproduced useful applications in the 80s and received massive amounts of funding, it was still unable to solve problems inperception,robotics,learningandcommon sense. A small number of scientists and engineers began to doubt that the symbolic approach would ever be sufficient for these tasks and developed other approaches, such as \"connectionism\",robotics,\"soft\" computingandreinforcement learning.Nils Nilssoncalled these approaches \"sub-symbolic\". In 1982, physicistJohn Hopfieldwas able to prove that a form of neural network (now called a \"Hopfield net\") could learn and process information, and provably converges after enough time under any fixed condition. It was a breakthrough, as it was previously thought that nonlinear networks would, in general, evolve chaotically.Around the same time,Geoffrey HintonandDavid Rumelhartpopularized a method for training neural networks called \"backpropagation\".These two developments helped to revive the exploration ofartificial neural networks. Neural networks, along with several other similar models, received widespread attention after the 1986 publication of theParallel Distributed Processing, a two volume collection of papers edited byRumelhartand psychologistJames McClelland. The new field was christened \"connectionism\" and there was a considerable debate between advocates ofsymbolic AIand the \"connectionists\".Hinton called symbols the \"luminous aetherof AI\"―that is, an unworkable and misleading model of intelligence.This was a direct attack on the principles that inspired thecognitive revolution. Neural networks started to advance state of the art in some specialist areas such as protein structure prediction. Following pioneering work from Terry Sejnowski,cascading multilayer perceptrons such as PhDand PsiPredreached near-theoretical maximum accuracy in predicting secondary structure. In 1990,Yann LeCunatBell Labsusedconvolutional neural networksto recognize handwritten digits. The system was used widely in 90s, reading zip codes and personal checks. This was the first genuinely useful application of neural networks. Rodney Brooks,Hans Moravecand others argued that, in order to show real intelligence, a machine needs to have abody—it needs to perceive, move, survive, and deal with the world.Sensorimotor skills are essential to higher level skills such ascommonsense reasoning. They can't be efficiently implemented using abstract symbolic reasoning, so AI should solve the problems of perception, mobility, manipulation and survival without using symbolic representation at all. These robotics researchers advocated building intelligence \"from the bottom up\". A precursor to this idea wasDavid Marr, who had come toMITin the late 1970s from a successful background in theoretical neuroscience to lead the group studyingvision. He rejected all symbolic approaches (bothMcCarthy'slogic andMinsky's frames), arguing that AI needed to understand the physical machinery of vision from the bottom up before any symbolic processing took place. (Marr's work would be cut short by leukemia in 1980.) In his 1990 paper \"Elephants Don't Play Chess\",robotics researcher Brooks took direct aim at thephysical symbol system hypothesis, arguing that symbols are not always necessary since \"the world is its own best model. It is always exactly up to date. It always has every detail there is to be known. The trick is to sense it appropriately and often enough.\" In the 1980s and 1990s, manycognitive scientistsalso rejected the symbol processing model of the mind and argued that the body was essential for reasoning, a theory called the \"embodied mindthesis\". Soft computinguses methods that work with incomplete and imprecise information. They do not attempt to give precise, logical answers, but give results that are only \"probably\" correct. This allowed them to solve problems that precise symbolic methods could not handle. Press accounts often claimed these tools could \"think like a human\". Judea Pearl'sProbabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference, an influential 1988 bookbroughtprobabilityanddecision theoryinto AI.Fuzzy logic, developed byLofti Zadehin the 60s, began to be more widely used in AI and robotics.Evolutionary computationandartificial neural networksalso handle imprecise information, and are classified  as \"soft\". In the 90s and early 2000s many other soft computing tools were developed and put into use, includingBayesian networks,hidden Markov models,information theory, andstochastic modeling. These tools in turn depended on advanced mathematical techniques such as classicaloptimization. For a time in the 1990s and early 2000s, these soft tools were studied by a subfield of AI called \"computational intelligence\". Reinforcement learninggives an agent a reward every time it performs a desired action well, and may give negative rewards (or \"punishments\") when it performs poorly. It was described in the first half of the twentieth century by psychologists using animal models, such asThorndike,PavlovandSkinner.In the 1950s,Alan TuringandArthur Samuelforesaw the role of reinforcement learning in AI. A successful and influential research program was led byRichard SuttonandAndrew Bartobeginning 1972. Their collaboration revolutionized the study of reinforcement learning and decision making over the four decades.In 1988, Sutton described machine learning in terms ofdecision theory(i.e., theMarkov decision process). This gave the subject a solid theoretical foundation and access to a large body of theoretical results developed in the field ofoperations research. Also in 1988, Sutton and Barto developed the \"temporal difference\" (TD) learning algorithm, where the agent is rewarded only when itspredictions about the futureshow improvement. It significantly outperformed previous algorithms.TD-learning was used by Gerald Tesauro in 1992 in the programTD-Gammon, which played backgammon as well as the best human players. The program learned the game by playing against itself with zero prior knowledge.In an interesting case of interdisciplinary convergence, neurologists discovered in 1997 that thedopamine reward systemin brains also uses a version of the TD-learning algorithm.TD learning would be become highly influential in the 21st century, used in bothAlphaGoandAlphaZero. The business community's fascination with AI rose and fell in the 1980s in the classic pattern of aneconomic bubble. As dozens of companies failed, the perception in the business world was that the technology was not viable.The damage to AI's reputation would last into the 21st century. Inside the field there was little agreement on the reasons for AI's failure to fulfill the dream of human level intelligence that had captured the imagination of the world in the 1960s. Together, all these factors helped to fragment AI into competing subfields focused on particular problems or approaches, sometimes even under new names that disguised the tarnished pedigree of \"artificial intelligence\". Over the next 20 years, AI consistently delivered working solutions to specific isolated problems. By the late 1990s, it was being used throughout the technology industry, although somewhat behind the scenes. The success was due toincreasing computer power, by collaboration with other fields (such asmathematical optimizationandstatistics) and using higher standards of scientific accountability. The term \"AI winter\" was coined by researchers who had survived the funding cuts of 1974 when they became concerned that enthusiasm for expert systems had spiraled out of control and that disappointment would certainly follow.Their fears were well founded: in the late 1980s and early 1990s, AI suffered a series of financial setbacks. The first indication of a change in weather was the sudden collapse of the market for specialized AI hardware in 1987. Desktop computers fromAppleandIBMhad been steadily gaining speed and power and in 1987 they became more powerful than the more expensiveLisp machinesmade bySymbolicsand others. There was no longer a good reason to buy them. An entire industry worth half a billion dollars was demolished overnight. Eventually the earliest successful expert systems, such asXCON, proved too expensive to maintain. They were difficult to update, they could not learn, and they were \"brittle\" (i.e., they could make grotesque mistakes when given unusual inputs). Expert systems proved useful, but only in a few special contexts. In the late 1980s, theStrategic Computing Initiativecut funding to AI \"deeply and brutally\". New leadership atDARPAhad decided that AI was not \"the next wave\" and directed funds towards projects that seemed more likely to produce immediate results. By 1991, the impressive list of goals penned in 1981 for Japan'sFifth Generation Projecthad not been met. Some of them, like \"carry on a casual conversation\", would not be accomplished for another 30 years. As with other AI projects, expectations had run much higher than what was actually possible. Over 300 AI companies had shut down, gone bankrupt, or been acquired by the end of 1993, effectively ending the first commercial wave of AI.In 1994,HP Newquiststated inThe Brain Makersthat \"The immediate future of artificial intelligence—in its commercial form—seems to rest in part on the continued success of neural networks.\" In the 1990s, algorithms originally developed by AI researchers began to appear as parts of larger systems. AI had solved a lot of very difficult problemsand their solutions proved to be useful throughout the technology industry,such asdata mining,industrial robotics, logistics,speech recognition,banking software,medical diagnosis,andGoogle's search engine. The field of AI received little or no credit for these successes in the 1990s and early 2000s. Many of AI's greatest innovations have been reduced to the status of just another item in the tool chest of computer science.Nick Bostromexplains: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\" Many researchers in AI in the 1990s deliberately called their work by other names, such asinformatics,knowledge-based systems, \"cognitive systems\" orcomputational intelligence. In part, this may have been because they considered their field to be fundamentally different from AI, but also the new names help to procure funding.In the commercial world at least, the failed promises of the AI winter continued to haunt AI research into the 2000s, as theNew York Timesreported in 2005: \"Computer scientists and software engineers avoided the term artificial intelligence for fear of being viewed as wild-eyed dreamers.\" AI researchers began to develop and use sophisticated mathematical tools more than they ever had in the past.Most of the new directions in AI relied heavily on mathematical models, includingartificial neural networks,probabilistic reasoning,soft computingandreinforcement learning. In the 90s and 2000s, many other highly mathematical tools were adapted for AI. These tools were applied to machine learning, perception, and mobility. There was a widespread realization that many of the problems that AI needed to solve were already being worked on by researchers in fields likestatistics,mathematics,electrical engineering,economics, oroperations research. The shared mathematical language allowed both a higher level of collaboration with more established and successful fields and the achievement of results which were measurable and provable; AI had become a more rigorous \"scientific\" discipline. Another key reason for the success in the 90s was that AI researchers focused on specific problems with verifiable solutions (an approach later derided asnarrow AI). This provided useful tools in the present, rather than speculation about the future. A new paradigm called \"intelligent agents\" became widely accepted during the 1990s.Although earlier researchers had proposed modular \"divide and conquer\" approaches to AI,the intelligent agent did not reach its modern form untilJudea Pearl,Allen Newell,Leslie P. Kaelbling, and others brought concepts fromdecision theoryand economics into the study of AI.When theeconomist'sdefinition of arational agentwas married tocomputer science's definition of anobjectormodule, the intelligent agent paradigm was complete. Anintelligent agentis a system that perceives its environment and takes actions which maximize its chances of success. By this definition, simple programs that solve specific problems are \"intelligent agents\", as are human beings and organizations of human beings, such asfirms. The intelligent agent paradigm defines AI research as \"the study of intelligent agents\".This is a generalization of some earlier definitions of AI: it goes beyond studying human intelligence; it studies all kinds of intelligence. The paradigm gave researchers license to study isolated problems and to disagree about methods, but still retain hope that their work could be combined into anagent architecturethat would be capable of general intelligence. On 11 May 1997,Deep Bluebecame the first computer chess-playing system to beat a reigning world chess champion,Garry Kasparov.In 2005, a Stanford robot won theDARPA Grand Challengeby driving autonomously for 131 miles along an unrehearsed desert trail. Two years later, a team from CMU won theDARPA Urban Challengeby autonomously navigating 55 miles in an urban environment while responding to traffic hazards and adhering to traffic laws. These successes were not due to some revolutionary new paradigm, but mostly on the tedious application of engineering skill and on the tremendous increase in the speed and capacity of computers by the 90s.In fact,Deep Blue'scomputer was 10 million times faster than theFerranti Mark 1thatChristopher Stracheytaught to play chess in 1951.This dramatic increase is measured byMoore's law, which predicts that the speed and memory capacity of computers doubles every two years. The fundamental problem of \"raw computer power\" was slowly being overcome. Electronic literatureexperiments such asThe Impermanence Agent(1998–2002) and digital art such asAgent Rubyused AI in their art and literature, \"laying bare the bias accompanying forms of technology that feign objectivity.\" In the first decades of the 21st century, access to large amounts of data (known as \"big data\"),cheaper and faster computersand advancedmachine learningtechniques were successfully applied to many problems throughout the economy. A turning point was the success ofdeep learningaround 2012 which improved the performance of machine learning on many tasks, including image and video processing, text analysis, and speech recognition.Investment in AI increased along with its capabilities, and by 2016, the market for AI-related products, hardware, and software reached more than $8 billion, and theNew York Timesreported that interest in AI had reached a \"frenzy\". In 2002,Ben Goertzeland others became concerned that AI had largely abandoned its original goal of producing versatile, fully intelligent machines, and argued in favor of more direct research intoartificial general intelligence(AGI). By the mid-2010s several companies and institutions had been founded to pursue artificial general intelligence, such asOpenAIandGoogle'sDeepMind. During the same period, new insights intosuperintelligenceraised concerns that AI was anexistential threat. The risks and unintended consequences of AI technology became an area of serious academic research after 2016. The success of machine learning in the 2000s depended on the availability of vast amounts of training data and faster computers.Russell and Norvig wrote that the \"improvement in performance obtained by increasing the size of the data set by two or three orders of magnitude outweighs any improvement that can be made by tweaking the algorithm.\"Geoffrey Hintonrecalled that back in the 80s and 90s the problem was that \"our labeled datasets were thousands of times too small. [And] our computers were millions of times too slow.\"This was no longer true by 2010. The most useful data in the 2000s came from curated, labeled data sets created specifically for machine learning and AI. In 2007, a group atUMass AmherstreleasedLabeled Faces in the Wild, an annotated set of images of faces that was widely used to train and testface recognitionsystems for the next several decades.Fei-Fei LidevelopedImageNet, a database of three million images captioned by volunteers using theAmazon Mechanical Turk. Released in 2009, it was a useful body of training data and a benchmark for testing for the next generation of image processing systems.Google releasedword2vecin 2013 as an open source resource. It used large amounts of data text scraped from the internet andword embeddingto create a numeric vector to represent each word. Users were surprised at how well it was able to capture word meanings, for example, ordinary vector addition would give equivalences like China + River = Yangtze or London − England + France = Paris.This database in particular would be essential for the development oflarge language modelsin the late 2010s. The explosive growth of the internet gave machine learning programs access to billions of pages of text and images that could bescraped. And, for specific problems, large privately held databases contained the relevant data.McKinsey Global Institutereported that \"by 2009, nearly all sectors in the US economy had at least an average of 200 terabytes of stored data\".This collection of information was known in the 2000s asbig data. In aJeopardy!exhibition match in February 2011,IBM'squestion answering systemWatsondefeated the two bestJeopardy!champions,Brad RutterandKen Jennings, by a significant margin.Watson's expertise would have been impossible without the information available on the internet. In 2012,AlexNet, adeep learningmodel,developed byAlex Krizhevsky, won theImageNet Large Scale Visual Recognition Challenge, with significantly fewer errors than the second-place winner.Krizhevsky worked withGeoffrey Hintonat theUniversity of Toronto.This was a turning point in machine learning: over the next few years dozens of other approaches to image recognition were abandoned in favor of deep learning. Deep learning uses a multi-layerperceptron. Although this architecture has been known since the 60s, getting it to work requires powerful hardware and large amounts of training data.Before these became available, improving performance of image processing systems required hand-craftedad hocfeatures that were difficult to implement.Deep learning was simpler and more general. Deep learning was applied to dozens of problems over the next few years (such as speech recognition, machine translation, medical diagnosis, and game playing). In every case it showed enormous gains in performance.Investment and interest in AI boomed as a result. It became fashionable in the 2000s to begin talking about the future of AI again and several popular books considered the possibility ofsuperintelligentmachines and what they might mean for human society. Some of this was optimistic (such asRay Kurzweil'sThe Singularity is Near), but others warned that a sufficiently powerful AI wasexistential threatto humanity, such asNick BostromandEliezer Yudkowsky.The topic became widely covered in the press and many leading intellectuals and politicians commented on the issue. AI programs in the 21st century are defined by theirgoals—the specific measures that they are designed to optimize.Nick Bostrom's influential 2014 bookSuperintelligenceargued that, if one isn't careful about defining these goals, the machine may cause harm to humanity in the process of achieving a goal.Stuart J. Russellused the example of an intelligent robot that kills its owner to prevent it from being unplugged, reasoning \"you can't fetch the coffee if you're dead\".(This problem is known by the technical term \"instrumental convergence\".) The solution is toalignthe machine's goal function with the goals of its owner and humanity in general. Thus, the problem of mitigating the risks and unintended consequences of AI became known as \"the value alignment problem\" or AI alignment. At the same time, machine learning systems had begun to have disturbing unintended consequences.Cathy O'Neilexplained how statistical algorithms had been among the causes of the2008 economic crash,Julia AngwinofProPublicaargued that theCOMPASsystem used by the criminal justice system exhibited racial bias under some measures,others showed that many machine learning systems exhibited some form of racialbias,and there were many other examples of dangerous outcomes that had resulted from machine learning systems. In 2016, the election ofDonald Trumpand the controversy over the COMPAS system illuminated several problems with the current technological infrastructure, including misinformation, social media algorithms designed to maximize engagement, the misuse of personal data and the trustworthiness of predictive models.Issues offairnessand unintended consequences became significantly more popular at AI conferences, publications vastly increased, funding became available, and many researchers refocused their careers on these issues. Thevalue alignment problembecame a serious field of academic study. In the early 2000s, several researchers became concerned that mainstream AI was too focused on \"measurable performance in specific applications\"(known as \"narrow AI\") and had abandoned AI's original goal of creating versatile, fully intelligent machines. An early critic wasNils Nilssonin 1995, and similar opinions were published by AI elder statesmen John McCarthy, Marvin Minsky, and Patrick Winston in 2007–2009. Minsky organized a symposium on \"human-level AI\" in 2004.Ben Goertzeladopted the term \"artificial general intelligence\" for the new sub-field, founding a journal and holding conferences beginning in 2008.The new field grew rapidly, buoyed by the continuing success of artificial neural networks and the hope that it was the key to AGI. Several competing companies, laboratories and foundations were founded to develop AGI in the 2010s.DeepMindwas founded in 2010 by three English scientists,Demis Hassabis,Shane LeggandMustafa Suleyman, with funding fromPeter Thieland laterElon Musk. The founders and financiers were deeply concerned aboutAI safetyand theexistential risk of AI. DeepMind's founders had a personal connection with Yudkowsky, and Musk was among those who was actively raising the alarm.Hassabis was both worried about the dangers of AGI and optimistic about its power; he hoped they could \"solve AI, then solve everything else.\"The New York Timeswrote in 2023, \"At the heart of this competition is a brain-stretching paradox. The people who say they are most worried about AI are among the most determined to create it and enjoy its riches. They have justified their ambition with their strong belief that they alone can keep AI from endangering Earth.\" In 2012,Geoffrey Hinton(who been leading neural network research since the 80s) was approached byBaidu, which wanted to hire him and all his students for an enormous sum. Hinton decided to hold an auction and, at a Lake Tahoe AI conference, they sold themselves toGooglefor a price of $44 million. Hassabis took notice and sold DeepMind to Google in 2014, on the condition that it would not accept military contracts and would be overseen by an ethics board. Larry Pageof Google, unlike Musk and Hassabis, was an optimist about the future of AI. Musk and Paige became embroiled in an argument about the risk of AGI at Musk's 2015 birthday party. They had been friends for decades but stopped speaking to each other shortly afterwards. Musk attended the one and only meeting of the DeepMind's ethics board, where it became clear that Google was uninterested in mitigating the harm of AGI. Frustrated by his lack of influence he foundedOpenAIin 2015, enlistingSam Altmanto run it and hiring top scientists. OpenAI began as a non-profit, \"free from the economic incentives that were driving Google and other corporations.\"Musk became frustrated again and left the company in 2018. OpenAI turned to Microsoft for continued financial support and Altman and OpenAI formed a for-profit version of the company with more than $1 billion in financing. In 2021,Dario Amodeiand 14 other scientists left OpenAI over concerns that the company was putting profits above safety. They formedAnthropic, which soon had $6 billion in financing from Microsoft and Google. The AI boom started with the initial development of key architectures and algorithms such as thetransformer architecturein 2017, leading to the scaling and development of large language models exhibiting human-like traits of knowledge, attention, and creativity. The new AI era began in 2020, with the public release of scaledlarge language models(LLMs) such asChatGPT. In 2017, thetransformerarchitecture was proposed by Google researchers in a paper titled \"Attention Is All You Need\". It exploits aself-attentionmechanism and became widely used in large language models.Large language models, based on the transformer, were further developed by other companies:OpenAIreleasedGPT-3in 2020, thenDeepMindreleasedGatoin 2022. These arefoundation models: they are trained on vast quantities of unlabeled data and can be adapted to a wide range of downstream tasks. These models can discuss a huge number of topics and display general knowledge, which has raised questions around whether or not they are examples ofartificial general intelligence. Bill Gateswas skeptical of the new technology and the hype that surrounded AGI. However, Altman presented him with a live demo ofChatGPT-4passing an advanced biology test. Gates was convinced.In 2023,Microsoft Researchtested the model with a large variety of tasks, and concluded that \"it could reasonably be viewed as an early (yet still incomplete) version of anartificial general intelligence(AGI) system\". In 2024,OpenAI o3, a type of advancedreasoning modeldeveloped by OpenAI, was announced. On the Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI) benchmark developed byFrançois Cholletin 2019, the model achieved an unofficial score of 87.5% on the semi-private test, surpassing the typical human score of 84%. The benchmark is supposed to be a necessary, but not sufficient test for AGI. Speaking of the benchmark, Chollet has said \"You'll know AGI is here when the exercise of creating tasks that are easy for regular humans but hard for AI becomes simply impossible.\" Investment in AI grew exponentially after 2020, with venture capital funding for generative AI companies increasing dramatically. Total AI investments rose from $18 billion in 2014 to $119 billion in 2021, with generative AI accounting for approximately 30% of investments by 2023.According to metrics from 2017 to 2021, the United States outranked the rest of the world in terms ofventure capital funding, number ofstartups, and AIpatentsgranted.The commercial AI scene became dominated by AmericanBig Techcompanies, whose investments in this area surpassed those from U.S.-basedventure capitalists.OpenAI's valuation reached $86 billion by early 2024,whileNVIDIA's market capitalization surpassed $3.3 trillion by mid-2024, making it the world's largest company bymarket capitalizationas the demand for AI-capableGPUssurged. 15.ai, launched in March 2020by an anonymousMITresearcher,was one of the earliest examples ofgenerative AIgaining widespread public attention during the initial stages of the AI boom.The freeweb applicationdemonstrated the ability to clone character voices using neural networks with minimal training data, requiring as little as 15 seconds of audio to reproduce a voice—a capability later corroborated byOpenAIin 2024.The service wentviralon social media platforms in early 2021,allowing users to generate speech for characters frompopular mediafranchises, and became particularly notable for its pioneering role in popularizingAI voice synthesisforcreative contentandmemes. Contemporary AI systems are now becoming human-competitive at general tasks, and we must ask ourselves: Should we let machines flood our information channels with propaganda and untruth? Should we automate away all the jobs, including the fulfilling ones? Should we develop nonhuman minds that might eventually outnumber, outsmart, obsolete and replace us? Should we risk loss of control of our civilization? Such decisions must not be delegated to unelected tech leaders.Powerful AI systems should be developed only once we are confident that their effects will be positive and their risks will be manageable.This confidence must be well justified and increase with the magnitude of a system’s potential effects. OpenAI’s recent statement regarding artificial general intelligence, states that \"At some point, it may be important to get independent review before starting to train future systems, and for the most advanced efforts to agree to limit the rate of growth of compute used for creating new models.\" We agree. That point is now. Therefore,we call on all AI labs to immediately pause for at least 6 months the training of AI systems more powerful than GPT-4. This pause should be public and verifiable, and include all key actors. If such a pause cannot be enacted quickly, governments should step in and institute a moratorium. ChatGPTwas launched on 30 November 2022, marking a pivotal moment in artificial intelligence's public adoption. Within days of its release it went viral, gaining over 100 million users in two months and becoming the fastest-growing consumer software application in history.The chatbot's ability to engage in human-like conversations, write code, and generate creative content captured public imagination and led to rapid adoption across various sectors includingeducation,business, and research.ChatGPT's success prompted unprecedented responses from major technology companies—Googledeclared a \"code red\" and rapidly launchedGemini(formerly known as Google Bard), whileMicrosoftincorporated the technology intoBing Chat. The rapid adoption of these AI technologies sparked intense debate about their implications. Notable AI researchers and industry leaders voiced both optimism and concern about the accelerating pace of development. In March 2023, over 20,000 signatories, includingcomputer scientistYoshua Bengio,Elon Musk, andAppleco-founderSteve Wozniak, signedan open letter calling for a pause in advanced AI development, citing \"profound risks to society and humanity.\"However, other prominent researchers likeJuergen Schmidhubertook a more optimistic view, emphasizing that the majority of AI research aims to make \"human lives longer and healthier and easier.\" By mid-2024, however, the financial sector began to scrutinize AI companies more closely, particularly questioning their capacity to produce areturn on investmentcommensurate with their massive valuations. Some prominent investors raised concerns about market expectations becoming disconnected from fundamental business realities.Jeremy Grantham, co-founder ofGMO LLC, warned investors to \"be quite careful\" and drew parallels to previous technology-driven market bubbles.Similarly,Jeffrey Gundlach, CEO ofDoubleLine Capital, explicitly compared the AI boom to thedot-com bubbleof the late 1990s, suggesting that investor enthusiasm might be outpacing realistic near-term capabilities and revenue potential.These concerns were amplified by the substantial market capitalizations of AI-focused companies, many of which had yet to demonstrate sustainable profitability models. In March 2024,Anthropicreleased theClaude3 family of large language models, including Claude 3 Haiku, Sonnet, and Opus.The models demonstrated significant improvements in capabilities across various benchmarks, with Claude 3 Opus notably outperforming leading models from OpenAI and Google.In June 2024, Anthropic released Claude 3.5 Sonnet, which demonstrated improved performance compared to the larger Claude 3 Opus, particularly in areas such as coding, multistep workflows, and image analysis. In 2024, theRoyal Swedish Academyof Sciences awardedNobel Prizesin recognition of groundbreaking contributions toartificial intelligence. The recipients included: In January 2025, OpenAI announced a new AI, ChatGPT-Gov, which would be specifically designed for US government agencies to use securely.Open AI said that agencies could utilize ChatGPT Gov on a Microsoft Azure cloud or Azure Government cloud, \"on top of Microsoft’s Azure’s OpenAI Service.\" OpenAI's announcement stated that \"Self-hosting ChatGPT Gov enables agencies to more easily manage their own security, privacy, and compliance requirements, such as stringent cybersecurity frameworks (IL5, CJIS, ITAR,FedRAMPHigh). Additionally, we believe this infrastructure will expedite internal authorization of OpenAI's tools for the handling of non-public sensitive data.\" Countries have invested in policies and funding to deployautonomous robotsin an attempt to address labor shortages and enhancing efficiency, while also implementingregulatory frameworksfor ethical and safe development. In 2025, China invested approximately 730 billion yuan (roughly US$100 billion) to advance AI and robotics in smart manufacturing and healthcare.The \"14th Five-Year Plan\" (2021–2025) prioritized service robots, with AI systems enabling robots to perform complex tasks like assisting in surgeries or automating factory assembly lines.Some funding also supported defense applications, such as autonomous drones.Starting in September 2025, China mandated labeling of AI-generated content to ensure transparency and public trust in these technologies. In January 2025,Stargate LLCwas formed as a joint venture ofOpenAI,SoftBank,Oracle, andMGX, who announced plans to invest US$500 billion in AI infrastructure in theUnited Statesby 2029. The venture was formally announced by U.S. President Donald Trump on 21 January 2025, with SoftBank CEOMasayoshi Sonappointed as chairman. The U.S. government allocated approximately $2 billion to integrate AI and robotics in manufacturing and logistics.State governments supplemented this with funding for service robots, such as those deployed in warehouses to fulfill verbal commands for inventory management or in eldercare facilities to respond to residents' requests for assistance.Some funds were directed to defense, includinglethal autonomous weaponandmilitary robot. In January 2025, Executive Order 14179 established an \"AI Action Plan\" to accelerate innovation and deployment of these technologies with the declared intent of \"world domination\" and \"victory\"..", "combined_text": "History of artificial intelligence Contents Precursors Mythical, fictional, and speculative precursors Formal reasoning Neuroscience Computer science Birth of artificial intelligence (1941–1956) Turing test Artificial neural networks Cybernetic robots Game AI Symbolic reasoning and the Logic Theorist Dartmouth Workshop Cognitive revolution Early successes (1956–1974) Approaches Optimism Financing First AI winter (1974–1980) Problems Decrease in funding Philosophical and ethical critiques Logic at Stanford, CMU and Edinburgh MIT's \"anti-logic\" approach Boom (1980–1987) Expert systems become widely used Government funding increases Knowledge revolution New directions in the 1980s Revival of neural networks: \"connectionism\" Robotics and embodied reason Soft computing and probabilistic reasoning Reinforcement learning Second AI winter (1990s) AI winter AI behind the scenes Mathematical rigor, greater collaboration and a narrow focus Intelligent agents Milestones and Moore's law Arts and literature influences from AI Big data, deep learning, AGI (2005–2017) Big data and big machines Deep learning The alignment problem Artificial general intelligence research Large language models, AI boom (2017–present) Transformer architecture and large language models Investment in AI Advent of AI for public use 2024 Nobel Prizes Further study and development of AI National policies See also Notes References Works cited   Thehistory of artificial intelligence(AI) began inantiquity, with myths, stories, and rumors of artificial beings endowed with intelligence or consciousness by master craftsmen. The study of logic and formal reasoning from antiquity to the present led directly to the invention of theprogrammable digital computerin the 1940s, a machine based on abstract mathematical reasoning. This device and the ideas behind it inspired scientists to begin discussing the possibility of building anelectronic brain. The field of AI research was founded at aworkshopheld on the campus ofDartmouth Collegein 1956.Attendees of the workshop became the leaders of AI research for decades. Many of them predicted that machines as intelligent as humans would exist within a generation. TheU.S. governmentprovided millions of dollars with the hope of making this vision come true. Eventually, it became obvious that researchers had grossly underestimated the difficulty of this feat.In 1974, criticism fromJames Lighthilland pressure from the U.S.A. Congress led the U.S. andBritish Governmentsto stop funding undirected research into artificial intelligence. Seven years later, a visionary initiative by theJapanese Governmentand the success ofexpert systemsreinvigorated investment in AI, and by the late 1980s, the industry had grown into a billion-dollar enterprise. However, investors' enthusiasm waned in the 1990s, and the field was criticized in the press and avoided by industry (a period known as an \"AI winter\"). Nevertheless, research and funding continued to grow under other names. In the early 2000s,machine learningwas applied to a wide range of problems in academia and industry. The success was due to the availability of powerful computer hardware, the collection of immense data sets, and the application of solid mathematical methods. Soon after,deep learningproved to be a breakthrough technology, eclipsing all other methods. Thetransformer architecturedebuted in 2017 and was used to produce impressivegenerative AIapplications, amongst other use cases. Investment in AIboomedin the 2020s. The recent AI boom, initiated by the development of transformer architecture, led to the rapid scaling and public releases oflarge language models(LLMs) likeChatGPT. These models exhibit human-like traits of knowledge, attention, and creativity, and have been integrated into various sectors, fueling exponential investment in AI. However, concerns about the potential risks andethical implications of advanced AIhave also emerged, causing debate about the future of AI and its impact on society. InGreek mythology,Taloswas a creature made of bronze who acted as guardian for theisland of Crete. He would throw boulders at the ships of invaders and would complete 3 circuits around the island's perimeter daily.According topseudo-Apollodorus'Bibliotheke, Hephaestus forged Talos with the aid of a cyclops and presented theautomatonas a gift toMinos.In theArgonautica,Jasonand theArgonautsdefeated Talos by removing a plug near his foot, causing the vitalichorto flow out from his body and rendering him lifeless. Pygmalionwas a legendary king and sculptor of Greek mythology, famously represented inOvid'sMetamorphoses. In the 10th book of Ovid's narrative poem, Pygmalion becomes disgusted with women when he witnesses the way in which thePropoetidesprostitute themselves. Despite this, he makes offerings at the temple of Venus asking the goddess to bring to him a woman just like a statue he carved. InOf the Nature of Things, the Swiss alchemistParacelsusdescribes a procedure that he claims can fabricate an \"artificial man\". By placing the \"sperm of a man\" in horse dung, and feeding it the \"Arcanum of Mans blood\" after 40 days, the concoction will become a living infant. The earliest written account regarding golem-making is found in the writings ofEleazar ben Judah of Wormsin the early 13th century.During the Middle Ages, it was believed that the animation of aGolemcould be achieved by insertion of a piece of paper with any of God's names on it, into the mouth of the clay figure.Unlike legendary automata likeBrazen Heads,aGolemwas unable to speak. Takwin, the artificial creation of life, was a frequent topic ofIsmailialchemical manuscripts, especially those attributed toJabir ibn Hayyan. Islamic alchemists attempted to create a broad range of life through their work, ranging from plants to animals. InFaust: The Second Part of the TragedybyJohann Wolfgang von Goethe, an alchemically fabricatedhomunculus, destined to live forever in the flask in which he was made, endeavors to be born into a full human body. Upon the initiation of this transformation, however, the flask shatters and the homunculus dies. By the 19th century, ideas about artificial men and thinking machines became a popular theme in fiction. Notable works likeMary Shelley'sFrankensteinandKarel Čapek'sR.U.R. (Rossum's Universal Robots)explored the concept of artificial life. Speculative essays, such asSamuel Butler's \"Darwin among the Machines\",andEdgar Allan Poe's\"Maelzel's Chess Player\"reflected society's growing interest in machines with artificial intelligence. AI remains a common topic in science fiction today. Realistic humanoidautomatawere built by craftsman from many civilizations, includingYan Shi,Hero of Alexandria,Al-Jazari,Haroun al-Rashid,Jacques de Vaucanson,Leonardo Torres y Quevedo,Pierre Jaquet-DrozandWolfgang von Kempelen. The oldest known automata were thesacred statuesofancient EgyptandGreece.The faithful believed that craftsman had imbued these figures with very real minds, capable of wisdom and emotion—Hermes Trismegistuswrote that \"by discovering the true nature of the gods, man has been able to reproduce it\".English scholarAlexander Neckhamasserted that the Ancient Roman poetVirgilhad built a palace with automaton statues. During the early modern period, these legendary automata were said to possess the magical ability to answer questions put to them. The late medieval alchemist and proto-ProtestantRoger Baconwas purported to have fabricated abrazen head, having developed a legend of having been a wizard.These legends were similar to the Norse myth of the Head ofMímir. According to legend, Mímir was known for his intellect and wisdom, and was beheaded in theÆsir-Vanir War.Odinis said to have \"embalmed\" the head with herbs and spoke incantations over it such that Mímir's head remained able to speak wisdom to Odin. Odin then kept the head near him for counsel. Artificial intelligence is based on the assumption that the process of human thought can be mechanized. The study of mechanical—or \"formal\"—reasoning has a long history.Chinese,IndianandGreekphilosophers all developed structured methods of formal deduction by the first millennium BCE. Their ideas were developed over the centuries by philosophers such asAristotle(who gave a formal analysis of thesyllogism),Euclid(whoseElementswas a model of formal reasoning),al-Khwārizmī(who developedalgebraand gave his name to the wordalgorithm) and Europeanscholasticphilosophers such asWilliam of OckhamandDuns Scotus. Spanish philosopherRamon Llull(1232–1315) developed severallogical machinesdevoted to the production of knowledge by logical means;Llull described his machines as mechanical entities that could combine basic and undeniable truths by simple logical operations, produced by the machine by mechanical meanings, in such ways as to produce all the possible knowledge.Llull's work had a great influence onGottfried Leibniz, who redeveloped his ideas. In the 17th century,Leibniz,Thomas HobbesandRené Descartesexplored the possibility that all rational thought could be made as systematic as algebra or geometry.Hobbesfamously wrote inLeviathan: \"Forreason... is nothing butreckoning, that is adding and subtracting\".Leibnizenvisioned a universal language of reasoning, thecharacteristica universalis, which would reduce argumentation to calculation so that \"there would be no more need of disputation between two philosophers than between two accountants. For it would suffice to take their pencils in hand, down to their slates, and to say each other (with a friend as witness, if they liked):Let us calculate.\"These philosophers had begun to articulate thephysical symbol systemhypothesis that would guide AI research. The study ofmathematical logicprovided the essential breakthrough that made artificial intelligence seem plausible. The foundations had been set by such works asBoole'sThe Laws of ThoughtandFrege'sBegriffsschrift.Building onFrege's system,RussellandWhiteheadpresented a formal treatment of the foundations of mathematics in their masterpiece, thePrincipia Mathematicain 1913. Inspired byRussell's success,David Hilbertchallenged mathematicians of the 1920s and 30s to answer this fundamental question: \"can all of mathematical reasoning be formalized?\"His question was answered byGödel'sincompleteness proof,Turing'smachineandChurch'sLambda calculus. Their answer was surprising in two ways. First, they proved that there were, in fact, limits to what mathematical logic could accomplish. But second (and more important for AI) their work suggested that, within these limits,anyform of mathematical reasoning could be mechanized. TheChurch-Turing thesisimplied that a mechanical device, shuffling symbols as simple as0and1, could imitate any conceivable process of mathematical deduction.The key insight was theTuring machine—a simple theoretical construct that captured the essence of abstract symbol manipulation.This invention would inspire a handful of scientists to begin discussing the possibility of thinking machines. In the 18th and 19th centuryLuigi Galvani,Emil du Bois-Reymond,Hermann von Helmholtzand others demonstrated that the nerves carried electrical signals andRobert Bentley Toddcorrectly speculated in 1828 that the brain was an electrical network.Camillo Golgi's staining techniques enabledSantiago Ramón y Cajalto provide evidence for theneuron theory: \"The truly amazing conclusion is that a collection of simple cells can lead to thought, action, and consciousness\". Donald Hebbwas a Canadian psychologist whose work laid the foundation for modern neuroscience, particularly in understanding learning, memory, and neural plasticity. His most influential book,The Organization of Behavior(1949), introduced the concept of Hebbian learning, often summarized as \"cells that fire together wire together.\" Hebb began formulating the foundational ideas for this book in the early 1940s, particularly during his time at the Yerkes Laboratories of Primate Biology from 1942 to 1947. He made extensive notes between June 1944 and March 1945 and sent a complete draft to his mentor Karl Lashley in 1946. The manuscript forThe Organization of Behaviorwasn’t published until 1949. The delay was due to various factors, including World War II and shifts in academic focus. By the time it was published, several of his peers had already published related ideas, making Hebb's work seem less groundbreaking at first glance. However, his synthesis of psychological and neurophysiological principles became a cornerstone of neuroscience and machine learning. Calculating machines were designed or built in antiquity and throughout history by many people, includingGottfried Leibniz,Joseph Marie Jacquard,Charles Babbage,Percy Ludgate,Leonardo Torres Quevedo,Vannevar Bush,and others.Ada Lovelacespeculated that Babbage's machine was \"a thinking or ... reasoning machine\", but warned \"It is desirable to guard against the possibility of exaggerated ideas that arise as to the powers\" of the machine. The first modern computers were the massive machines of theSecond World War(such asKonrad Zuse'sZ3,Alan Turing'sHeath RobinsonandColossus,AtanasoffandBerry'sABC, andENIACat theUniversity of Pennsylvania).ENIACwas based on the theoretical foundation laid byAlan Turingand developed byJohn von Neumann,and proved to be the most influential. The earliest research into thinking machines was inspired by a confluence of ideas that became prevalent in the late 1930s, 1940s, and early 1950s. Recent research inneurologyhad shown that the brain was an electrical network ofneuronsthat fired in all-or-nothing pulses.Norbert Wiener'scyberneticsdescribed control and stability in electrical networks.Claude Shannon'sinformation theorydescribed digital signals (i.e., all-or-nothing signals).Alan Turing'stheory of computationshowed that any form of computation could be described digitally. The close relationship between these ideas suggested that it might be possible to construct an \"electronic brain\". In the 1940s and 50s, a handful of scientists from a variety of fields (mathematics, psychology, engineering, economics and political science) explored several research directions that would be vital to later AI research.Alan Turing was among the first people to seriously investigate the theoretical possibility of \"machine intelligence\".The field of \"artificial intelligence research\" was founded as an academic discipline in 1956. In 1950 Turing published a landmark paper \"Computing Machinery and Intelligence\", in which he speculated about the possibility of creating machines that think.In the paper, he noted that \"thinking\" is difficult to define and devised his famousTuring test: If a machine could carry on a conversation (over ateleprinter) that was indistinguishable from a conversation with a human being, then it was reasonable to say that the machine was \"thinking\".This simplified version of the problem allowed Turing to argue convincingly that a \"thinking machine\" was at leastplausibleand the paper answered all the most common objections to the proposition.The Turing test was the first serious proposal in thephilosophy of artificial intelligence. Walter PittsandWarren McCullochanalyzed networks of idealizedartificial neuronsand showed how they might perform simple logical functions in 1943. They were the first to describe what later researchers would call aneural network.The paper was influenced by Turing's paper \"On Computable Numbers\" from 1936 using similar two-state boolean 'neurons', but was the first to apply it to neuronal function.One of the students inspired by Pitts and McCulloch wasMarvin Minskywho was a 24-year-old graduate student at the time. In 1951 Minsky and Dean Edmonds built the first neural net machine, theSNARC.Minsky would later become one of the most important leaders and innovators in AI. Experimental robots such asW. Grey Walter'sturtlesand theJohns Hopkins Beast, were built in the 1950s. These machines did not use computers, digital electronics, or symbolic reasoning; they were controlled entirely by analog circuitry. In 1951, using theFerranti Mark 1machine of theUniversity of Manchester,Christopher Stracheywrote a checkers programandDietrich Prinzwrote one for chess.Arthur Samuel's checkers program, the subject of his 1959 paper \"Some Studies in Machine Learning Using the Game of Checkers\", eventually achieved sufficient skill to challenge a respectable amateur.Samuel's program was among the first uses of what would later be calledmachine learning.Game AIwould continue to be used as a measure of progress in AI throughout its history. When access todigital computersbecame possible in the mid-fifties, a few scientists instinctively recognized that a machine that could manipulate numbers could also manipulate symbols and that the manipulation of symbols could well be the essence of human thought. This was a new approach to creating thinking machines. In 1955,Allen Newelland future Nobel LaureateHerbert A. Simoncreated the \"Logic Theorist\", with help fromJ. C. Shaw. The program would eventually prove 38 of the first 52 theorems inRussellandWhitehead'sPrincipia Mathematica, and find new and more elegant proofs for some.Simon said that they had \"solved the venerablemind/body problem, explaining how a system composed of matter can have the properties of mind.\"The symbolic reasoning paradigm they introduced would dominate AI research and funding until the middle 90s, as well as inspire thecognitive revolution. The Dartmouth workshop of 1956 was a pivotal event that marked the formal inception of AI as an academic discipline.It was organized byMarvin MinskyandJohn McCarthy, with the support of two senior scientistsClaude ShannonandNathan RochesterofIBM. The proposal for the conference stated they intended to test the assertion that \"every aspect of learning or any other feature of intelligence can be so precisely described that a machine can be made to simulate it\".The term \"Artificial Intelligence\" was introduced by John McCarthy at the workshop.The participants includedRay Solomonoff,Oliver Selfridge,Trenchard More,Arthur Samuel,Allen NewellandHerbert A. Simon, all of whom would create important programs during the first decades of AI research.At the workshop Newell and Simon debuted the \"Logic Theorist\".The workshop was the moment that AI gained its name, its mission, its first major success and its key players, and is widely considered the birth of AI. In the autumn of 1956, Newell and Simon also presented the Logic Theorist at a meeting of the Special Interest Group in Information Theory at theMassachusetts Institute of Technology(MIT). At the same meeting,Noam Chomskydiscussed hisgenerative grammar, andGeorge Millerdescribed his landmark paper \"The Magical Number Seven, Plus or Minus Two\". Miller wrote \"I left the symposium with a conviction, more intuitive than rational, that experimental psychology, theoretical linguistics, and the computer simulation of cognitive processes were all pieces from a larger whole.\" This meeting was the beginning of the \"cognitive revolution\"—an interdisciplinaryparadigm shiftin psychology, philosophy, computer science and neuroscience. It inspired the creation of the sub-fields ofsymbolic artificial intelligence,generative linguistics,cognitive science,cognitive psychology,cognitive neuroscienceand the philosophical schools ofcomputationalismandfunctionalism. All these fields used related tools to model the mind and results discovered in one field were relevant to the others. The cognitive approach allowed researchers to consider \"mental objects\" like thoughts, plans, goals, facts or memories, often analyzed usinghigh level symbolsin functional networks. These objects had been forbidden as \"unobservable\" by earlier paradigms such asbehaviorism.Symbolic mental objects would become the major focus of AI research and funding for the next several decades. The programs developed in the years after theDartmouth Workshopwere, to most people, simply \"astonishing\":computers were solving algebra word problems, proving theorems in geometry and learning to speak English. Few at the time would have believed that such \"intelligent\" behavior by machines was possible at all.Researchers expressed an intense optimism in private and in print, predicting that a fully intelligent machine would be built in less than 20 years.Government agencies like theDefense Advanced Research Projects Agency(DARPA, then known as \"ARPA\") poured money into the field.Artificial Intelligence laboratories were set up at a number of British and US universities in the latter 1950s and early 1960s. There were many successful programs and new directions in the late 50s and 1960s. Among the most influential were these: Many early AI programs used the same basicalgorithm. To achieve some goal (like winning a game or proving a theorem), they proceeded step by step towards it (by making a move or a deduction) as if searching through a maze,backtrackingwhenever they reached a dead end.The principal difficulty was that, for many problems, the number of possible paths through the \"maze\" was astronomical (a situation known as a \"combinatorial explosion\"). Researchers would reduce the search space by usingheuristicsthat would eliminate paths that were unlikely to lead to a solution. NewellandSimontried to capture a general version of this algorithm in a program called the \"General Problem Solver\".Other \"searching\" programs were able to accomplish impressive tasks like solving problems in geometry and algebra, such asHerbert Gelernter's Geometry Theorem Prover (1958)and Symbolic Automatic Integrator (SAINT), written byMinsky'sstudent James Slagle in 1961.Other programs searched through goals and subgoals toplan actions, like theSTRIPSsystem developed atStanfordto control the behavior of the robotShakey. An important goal of AI research is to allow computers to communicate innatural languageslike English. An early success wasDaniel Bobrow's programSTUDENT, which could solve high school algebra word problems. Asemantic netrepresents concepts (e.g. \"house\", \"door\") as nodes, and relations among concepts as links between the nodes (e.g. \"has-a\"). The first AI program to use a semantic net was written by Ross Quillianand the most successful (and controversial) version wasRoger Schank'sConceptual dependency theory. Joseph Weizenbaum'sELIZAcould carry out conversations that were so realistic that users occasionally were fooled into thinking they were communicating with a human being and not a computer program (seeELIZA effect). But in fact, ELIZA simply gave acanned responseor repeated back what was said to it, rephrasing its response with a few grammar rules. ELIZA was the firstchatbot. In the late 60s,Marvin MinskyandSeymour Papertof theMITAI Laboratory proposed that AI research should focus on artificially simple situations known as micro-worlds.They pointed out that in successful sciences like physics, basic principles were often best understood using simplified models like frictionless planes or perfectly rigid bodies. Much of the research focused on a \"blocks world,\" which consists of colored blocks of various shapes and sizes arrayed on a flat surface. This paradigm led to innovative work inmachine visionbyGerald Sussman, Adolfo Guzman,David Waltz(who invented \"constraint propagation\"), and especiallyPatrick Winston. At the same time, Minsky and Papert built a robot arm that could stack blocks, bringing the blocks world to life.Terry Winograd'sSHRDLUcould communicate in ordinary English sentences about the micro-world, plan operations and execute them. In the 1960s funding was primarily directed towards laboratories researchingsymbolic AI, however several people still pursued research in neural networks. Theperceptron, a single-layerneural networkwas introduced in 1958 byFrank Rosenblatt(who had been a schoolmate ofMarvin Minskyat theBronx High School of Science).Like most AI researchers, he was optimistic about their power, predicting that a perceptron \"may eventually be able to learn, make decisions, and translate languages.\"Rosenblatt was primarily funded byOffice of Naval Research. Bernard Widrowand his studentTed HoffbuiltADALINE(1960) andMADALINE(1962), which had up to 1000 adjustable weights.A group atStanford Research Instituteled byCharles A. Rosenand Alfred E. (Ted) Brain built two neural network machines named MINOS I (1960) and II (1963), mainly funded byU.S. Army Signal Corps. MINOS IIhad 6600 adjustable weights,and was controlled with anSDS 910 computerin a configuration named MINOS III (1968), which could classify symbols on army maps, and recognize hand-printed characters onFortrancoding sheets.Most of neural network research during this early period involved building and using bespoke hardware, rather than simulation on digital computers. However, partly due to lack of results and partly due to competition fromsymbolic AIresearch, the MINOS project ran out of funding in 1966. Rosenblatt failed to secure continued funding in the 1960s.In 1969 research came to a sudden halt with the publication ofMinskyandPapert's1969 bookPerceptrons.It suggested that there were severe limitations to what perceptrons could do and that Rosenblatt's predictions had been grossly exaggerated. The effect of the book was that virtually no research was funded inconnectionismfor 10 years.The competition for government funding ended with the victory of symbolic AI approaches over neural networks. Minsky (who had worked onSNARC) became a staunch objector to pure connectionist AI.Widrow(who had worked onADALINE) turned to adaptive signal processing. TheSRIgroup (which worked on MINOS) turned to symbolic AI and robotics. The main problem was the inability to train multilayered networks (versions ofbackpropagationhad already been used in other fields but it was unknown to these researchers).The AI community became aware of backpropogation in the 80s,and, in the 21st century, neural networks would become enormously successful, fulfilling all of Rosenblatt's optimistic predictions. Rosenblatt did not live to see this, however, as he died in a boating accident in 1971. The first generation of AI researchers made these predictions about their work: In June 1963,MITreceived a $2.2 million grant from the newly created Advanced Research Projects Agency (ARPA, later known asDARPA). The money was used to fundproject MACwhich subsumed the \"AI Group\" founded byMinskyandMcCarthyfive years earlier. DARPA continued to provide $3 million each year until the 70s.DARPA made similar grants toNewellandSimon'sprogram atCarnegie Mellon Universityand toStanford University'sAI Lab, founded byJohn McCarthyin 1963.Another important AI laboratory was established atEdinburgh UniversitybyDonald Michiein 1965.These four institutions would continue to be the main centers of AI research and funding in academia for many years. The money was given with few strings attached:J. C. R. Licklider, then the director of ARPA, believed that his organization should \"fund people, not projects!\" and allowed researchers to pursue whatever directions might interest them.This created a freewheeling atmosphere at MIT that gave birth to thehacker culture,but this \"hands off\" approach did not last. In the 1970s, AI was subject to critiques and financial setbacks. AI researchers had failed to appreciate the difficulty of the problems they faced. Their tremendous optimism had raised public expectations impossibly high, and when the promised results failed to materialize, funding targeted at AI was severely reduced.The lack of success indicated the techniques being used by AI researchers at the time were insufficient to achieve their goals. These setbacks did not affect the growth and progress of the field, however. The funding cuts only impacted a handful of major laboratoriesand the critiques were largely ignored.General public interest in the field continued to grow,the number of researchers increased dramatically,and new ideas were explored inlogic programming,commonsense reasoningand many other areas. Historian Thomas Haigh argued in 2023 that there was no winter,and AI researcherNils Nilssondescribed this period as the most \"exciting\" time to work in AI. In the early seventies, the capabilities of AI programs were limited. Even the most impressive could only handle trivial versions of the problems they were supposed to solve;all the programs were, in some sense, \"toys\".AI researchers had begun to run into several limits that would be only conquered decades later, and others that still stymie the field in the 2020s: The agencies which funded AI research, such as theBritish government,DARPAand theNational Research Council(NRC) became frustrated with the lack of progress and eventually cut off almost all funding for undirected AI research. The pattern began in 1966 when theAutomatic Language Processing Advisory Committee(ALPAC) report criticized machine translation efforts. After spending $20 million, theNRCended all support.In 1973, theLighthill reporton the state of AI research in the UK criticized the failure of AI to achieve its \"grandiose objectives\" and led to the dismantling of AI research in that country.(The report specifically mentioned thecombinatorial explosionproblem as a reason for AI's failings.)DARPA was deeply disappointed with researchers working on theSpeech Understanding Researchprogram at CMU and canceled an annual grant of $3 million. Hans Moravecblamed the crisis on the unrealistic predictions of his colleagues. \"Many researchers were caught up in a web of increasing exaggeration.\"However, there was another issue: since the passage of theMansfield Amendmentin 1969,DARPAhad been under increasing pressure to fund \"mission-oriented direct research, rather than basic undirected research\". Funding for the creative, freewheeling exploration that had gone on in the 60s would not come from DARPA, which instead directed money at specific projects with clear objectives, such asautonomoustanks andbattle managementsystems. The major laboratories (MIT, Stanford, CMU and Edinburgh) had been receiving generous support from their governments, and when it was withdrawn, these were the only places that were seriously impacted by the budget cuts. The thousands of researchers outside these institutions and the many more thousands that were joining the field were unaffected. Several philosophers had strong objections to the claims being made by AI researchers. One of the earliest wasJohn Lucas, who argued thatGödel's incompleteness theoremshowed that aformal system(such as a computer program) could never see the truth of certain statements, while a human being could.Hubert Dreyfusridiculed the broken promises of the 1960s and critiqued the assumptions of AI, arguing that human reasoning actually involved very little \"symbol processing\" and a great deal ofembodied,instinctive, unconscious \"know how\".John Searle'sChinese Roomargument, presented in 1980, attempted to show that a program could not be said to \"understand\" the symbols that it uses (a quality called \"intentionality\"). If the symbols have no meaning for the machine, Searle argued, then the machine can not be described as \"thinking\". These critiques were not taken seriously by AI researchers. Problems likeintractabilityandcommonsense knowledgeseemed much more immediate and serious. It was unclear what difference \"know how\" or \"intentionality\" made to an actual computer program. MIT'sMinskysaid of Dreyfus and Searle \"they misunderstand, and should be ignored.\"Dreyfus, who also taught atMIT, was given a cold shoulder: he later said that AI researchers \"dared not be seen having lunch with me.\"Joseph Weizenbaum, the author ofELIZA, was also an outspoken critic of Dreyfus' positions, but he \"deliberately made it plain that [his AI colleagues' treatment of Dreyfus] was not the way to treat a human being,\"and was unprofessional and childish. Weizenbaum began to have serious ethical doubts about AI whenKenneth Colbywrote a \"computer program which can conductpsychotherapeuticdialogue\" based on ELIZA.Weizenbaum was disturbed that Colby saw a mindless program as a serious therapeutic tool. A feud began, and the situation was not helped when Colby did not credit Weizenbaum for his contribution to the program. In 1976,WeizenbaumpublishedComputer Power and Human Reasonwhich argued that the misuse of artificial intelligence has the potential to devalue human life. Logic was introduced into AI research as early as 1958, byJohn McCarthyin hisAdvice Takerproposal.In 1963,J. Alan Robinsonhad discovered a simple method to implement deduction on computers, theresolutionandunificationalgorithm.However, straightforward implementations, like those attempted by McCarthy and his students in the late 1960s, were especially intractable: the programs required astronomical numbers of steps to prove simple theorems.A more fruitful approach to logic was developed in the 1970s byRobert Kowalskiat theUniversity of Edinburgh, and soon this led to the collaboration with French researchersAlain ColmerauerandPhilippe Roussel[fr]who created the successful logic programming languageProlog.Prolog uses a subset of logic (Horn clauses, closely related to \"rules\" and \"production rules\") that permit tractable computation. Rules would continue to be influential, providing a foundation forEdward Feigenbaum'sexpert systemsand the continuing work byAllen NewellandHerbert A. Simonthat would lead toSoarand theirunified theories of cognition. Critics of the logical approach noted, asDreyfushad, that human beings rarely used logic when they solved problems. Experiments by psychologists likePeter Wason,Eleanor Rosch,Amos Tversky,Daniel Kahnemanand others provided proof.McCarthy responded that what people do is irrelevant. He argued that what is really needed are machines that can solve problems—not machines that think as people do. Among the critics ofMcCarthy'sapproach were his colleagues across the country atMIT.Marvin Minsky,Seymour PapertandRoger Schankwere trying to solve problems like \"story understanding\" and \"object recognition\" thatrequireda machine to think like a person. In order to use ordinary concepts like \"chair\" or \"restaurant\" they had to make all the same illogical assumptions that people normally made. Unfortunately, imprecise concepts like these are hard to represent in logic. MIT chose instead to focus on writing programs that solved a given task without using high-level abstract definitions or general theories of cognition, and measured performance by iterative testing, rather than arguments from first principles.Schankdescribed their \"anti-logic\" approaches asscruffy, as opposed to theneatparadigm used byMcCarthy,Kowalski,Feigenbaum,NewellandSimon. In 1975, in a seminal paper,Minskynoted that many of his fellow researchers were using the same kind of tool: a framework that captures all ourcommon sense assumptionsabout something. For example, if we use the concept of a bird, there is a constellation of facts that immediately come to mind: we might assume that it flies, eats worms and so on (none of which are true for all birds). Minsky associated these assumptions with the general category and they could beinheritedby the frames for subcategories and individuals, or over-ridden as necessary. He called these structuresframes.Schankused a version of frames he called \"scripts\" to successfully answer questions about short stories in English.Frames would eventually be widely used insoftware engineeringunder the nameobject-oriented programming. The logicians rose to the challenge.Pat Hayesclaimed that \"most of 'frames' is just a new syntax for parts of first-order logic.\" But he noted that \"there are one or two apparently minor details which give a lot of trouble, however, especially defaults\". Ray Reiteradmitted that \"conventional logics, such as first-order logic, lack the expressive power to adequately represent the knowledge required for reasoning by default\".He proposed augmenting first-order logic with aclosed world assumptionthat a conclusion holds (by default) if its contrary cannot be shown. He showed how such an assumption corresponds to the common sense assumption made in reasoning with frames. He also showed that it has its \"procedural equivalent\" asnegation as failureinProlog. The closed world assumption, as formulated by Reiter, \"is not a first-order notion. (It is a meta notion.)\"However,Keith Clarkshowed that negation asfinite failurecan be understood as reasoning implicitly with definitions in first-order logic including aunique name assumptionthat different terms denote different individuals. During the late 1970s and throughout the 1980s, a variety of logics and extensions of first-order logic were developed both for negation as failure inlogic programmingand for default reasoning more generally. Collectively, these logics have become known asnon-monotonic logics. In the 1980s, a form of AI program called \"expert systems\" was adopted by corporations around the world andknowledgebecame the focus of mainstream AI research. Governments provided substantial funding, such as Japan'sfifth generation computerproject and the U.S.Strategic Computing Initiative. \"Overall, the AI industry boomed from a few million dollars in 1980 to billions of dollars in 1988.\" Anexpert systemis a program that answers questions or solves problems about a specific domain of knowledge, using logicalrulesthat are derived from the knowledge of experts.The earliest examples were developed byEdward Feigenbaumand his students.Dendral, begun in 1965, identified compounds from spectrometer readings.MYCIN, developed in 1972, diagnosed infectious blood diseases.They demonstrated the feasibility of the approach. Expert systems restricted themselves to a small domain of specific knowledge (thus avoiding thecommonsense knowledgeproblem)and their simple design made it relatively easy for programs to be built and then modified once they were in place. All in all, the programs proved to beuseful: something that AI had not been able to achieve up to this point. In 1980, an expert system calledR1was completed atCMUfor theDigital Equipment Corporation. It was an enormous success: it was saving the company 40 million dollars annually by 1986.Corporations around the world began to develop and deploy expert systems and by 1985 they were spending over a billion dollars on AI, most of it to in-house AI departments.An industry grew up to support them, including hardware companies likeSymbolicsandLisp Machinesand software companies such asIntelliCorpandAion. In 1981, theJapanese Ministry of International Trade and Industryset aside $850 million for theFifth generation computerproject. Their objectives were to write programs and build machines that could carry on conversations, translate languages, interpret pictures, and reason like human beings.Much to the chagrin ofscruffies, they initially chosePrologas the primary computer language for the project. Other countries responded with new programs of their own. The UK began the £350 millionAlveyproject.A consortium of American companies formed theMicroelectronics and Computer Technology Corporation(or \"MCC\") to fund large scale projects in AI and information technology.DARPAresponded as well, founding theStrategic Computing Initiativeand tripling its investment in AI between 1984 and 1988. The power of expert systems came from the expert knowledge they contained. They were part of a new direction in AI research that had been gaining ground throughout the 70s. \"AI researchers were beginning to suspect—reluctantly, for it violated the scientific canon ofparsimony—that intelligence might very well be based on the ability to use large amounts of diverse knowledge in different ways,\"writesPamela McCorduck. \"[T]he great lesson from the 1970s was that intelligent behavior depended very much on dealing with knowledge, sometimes quite detailed knowledge, of a domain where a given task lay\".Knowledge based systemsandknowledge engineeringbecame a major focus of AI research in the 1980s.It was hoped that vast databases would solve thecommonsense knowledgeproblem and provide the support thatcommonsense reasoningrequired. In the 1980s some researchers attempted to attack thecommonsense knowledge problemdirectly, by creating a massive database that would contain all the mundane facts that the average person knows.Douglas Lenat, who started a database calledCyc, argued that there is no shortcut―the only way for machines to know the meaning of human concepts is to teach them, one concept at a time, by hand. Although symbolicknowledge representationandlogical reasoningproduced useful applications in the 80s and received massive amounts of funding, it was still unable to solve problems inperception,robotics,learningandcommon sense. A small number of scientists and engineers began to doubt that the symbolic approach would ever be sufficient for these tasks and developed other approaches, such as \"connectionism\",robotics,\"soft\" computingandreinforcement learning.Nils Nilssoncalled these approaches \"sub-symbolic\". In 1982, physicistJohn Hopfieldwas able to prove that a form of neural network (now called a \"Hopfield net\") could learn and process information, and provably converges after enough time under any fixed condition. It was a breakthrough, as it was previously thought that nonlinear networks would, in general, evolve chaotically.Around the same time,Geoffrey HintonandDavid Rumelhartpopularized a method for training neural networks called \"backpropagation\".These two developments helped to revive the exploration ofartificial neural networks. Neural networks, along with several other similar models, received widespread attention after the 1986 publication of theParallel Distributed Processing, a two volume collection of papers edited byRumelhartand psychologistJames McClelland. The new field was christened \"connectionism\" and there was a considerable debate between advocates ofsymbolic AIand the \"connectionists\".Hinton called symbols the \"luminous aetherof AI\"―that is, an unworkable and misleading model of intelligence.This was a direct attack on the principles that inspired thecognitive revolution. Neural networks started to advance state of the art in some specialist areas such as protein structure prediction. Following pioneering work from Terry Sejnowski,cascading multilayer perceptrons such as PhDand PsiPredreached near-theoretical maximum accuracy in predicting secondary structure. In 1990,Yann LeCunatBell Labsusedconvolutional neural networksto recognize handwritten digits. The system was used widely in 90s, reading zip codes and personal checks. This was the first genuinely useful application of neural networks. Rodney Brooks,Hans Moravecand others argued that, in order to show real intelligence, a machine needs to have abody—it needs to perceive, move, survive, and deal with the world.Sensorimotor skills are essential to higher level skills such ascommonsense reasoning. They can't be efficiently implemented using abstract symbolic reasoning, so AI should solve the problems of perception, mobility, manipulation and survival without using symbolic representation at all. These robotics researchers advocated building intelligence \"from the bottom up\". A precursor to this idea wasDavid Marr, who had come toMITin the late 1970s from a successful background in theoretical neuroscience to lead the group studyingvision. He rejected all symbolic approaches (bothMcCarthy'slogic andMinsky's frames), arguing that AI needed to understand the physical machinery of vision from the bottom up before any symbolic processing took place. (Marr's work would be cut short by leukemia in 1980.) In his 1990 paper \"Elephants Don't Play Chess\",robotics researcher Brooks took direct aim at thephysical symbol system hypothesis, arguing that symbols are not always necessary since \"the world is its own best model. It is always exactly up to date. It always has every detail there is to be known. The trick is to sense it appropriately and often enough.\" In the 1980s and 1990s, manycognitive scientistsalso rejected the symbol processing model of the mind and argued that the body was essential for reasoning, a theory called the \"embodied mindthesis\". Soft computinguses methods that work with incomplete and imprecise information. They do not attempt to give precise, logical answers, but give results that are only \"probably\" correct. This allowed them to solve problems that precise symbolic methods could not handle. Press accounts often claimed these tools could \"think like a human\". Judea Pearl'sProbabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference, an influential 1988 bookbroughtprobabilityanddecision theoryinto AI.Fuzzy logic, developed byLofti Zadehin the 60s, began to be more widely used in AI and robotics.Evolutionary computationandartificial neural networksalso handle imprecise information, and are classified  as \"soft\". In the 90s and early 2000s many other soft computing tools were developed and put into use, includingBayesian networks,hidden Markov models,information theory, andstochastic modeling. These tools in turn depended on advanced mathematical techniques such as classicaloptimization. For a time in the 1990s and early 2000s, these soft tools were studied by a subfield of AI called \"computational intelligence\". Reinforcement learninggives an agent a reward every time it performs a desired action well, and may give negative rewards (or \"punishments\") when it performs poorly. It was described in the first half of the twentieth century by psychologists using animal models, such asThorndike,PavlovandSkinner.In the 1950s,Alan TuringandArthur Samuelforesaw the role of reinforcement learning in AI. A successful and influential research program was led byRichard SuttonandAndrew Bartobeginning 1972. Their collaboration revolutionized the study of reinforcement learning and decision making over the four decades.In 1988, Sutton described machine learning in terms ofdecision theory(i.e., theMarkov decision process). This gave the subject a solid theoretical foundation and access to a large body of theoretical results developed in the field ofoperations research. Also in 1988, Sutton and Barto developed the \"temporal difference\" (TD) learning algorithm, where the agent is rewarded only when itspredictions about the futureshow improvement. It significantly outperformed previous algorithms.TD-learning was used by Gerald Tesauro in 1992 in the programTD-Gammon, which played backgammon as well as the best human players. The program learned the game by playing against itself with zero prior knowledge.In an interesting case of interdisciplinary convergence, neurologists discovered in 1997 that thedopamine reward systemin brains also uses a version of the TD-learning algorithm.TD learning would be become highly influential in the 21st century, used in bothAlphaGoandAlphaZero. The business community's fascination with AI rose and fell in the 1980s in the classic pattern of aneconomic bubble. As dozens of companies failed, the perception in the business world was that the technology was not viable.The damage to AI's reputation would last into the 21st century. Inside the field there was little agreement on the reasons for AI's failure to fulfill the dream of human level intelligence that had captured the imagination of the world in the 1960s. Together, all these factors helped to fragment AI into competing subfields focused on particular problems or approaches, sometimes even under new names that disguised the tarnished pedigree of \"artificial intelligence\". Over the next 20 years, AI consistently delivered working solutions to specific isolated problems. By the late 1990s, it was being used throughout the technology industry, although somewhat behind the scenes. The success was due toincreasing computer power, by collaboration with other fields (such asmathematical optimizationandstatistics) and using higher standards of scientific accountability. The term \"AI winter\" was coined by researchers who had survived the funding cuts of 1974 when they became concerned that enthusiasm for expert systems had spiraled out of control and that disappointment would certainly follow.Their fears were well founded: in the late 1980s and early 1990s, AI suffered a series of financial setbacks. The first indication of a change in weather was the sudden collapse of the market for specialized AI hardware in 1987. Desktop computers fromAppleandIBMhad been steadily gaining speed and power and in 1987 they became more powerful than the more expensiveLisp machinesmade bySymbolicsand others. There was no longer a good reason to buy them. An entire industry worth half a billion dollars was demolished overnight. Eventually the earliest successful expert systems, such asXCON, proved too expensive to maintain. They were difficult to update, they could not learn, and they were \"brittle\" (i.e., they could make grotesque mistakes when given unusual inputs). Expert systems proved useful, but only in a few special contexts. In the late 1980s, theStrategic Computing Initiativecut funding to AI \"deeply and brutally\". New leadership atDARPAhad decided that AI was not \"the next wave\" and directed funds towards projects that seemed more likely to produce immediate results. By 1991, the impressive list of goals penned in 1981 for Japan'sFifth Generation Projecthad not been met. Some of them, like \"carry on a casual conversation\", would not be accomplished for another 30 years. As with other AI projects, expectations had run much higher than what was actually possible. Over 300 AI companies had shut down, gone bankrupt, or been acquired by the end of 1993, effectively ending the first commercial wave of AI.In 1994,HP Newquiststated inThe Brain Makersthat \"The immediate future of artificial intelligence—in its commercial form—seems to rest in part on the continued success of neural networks.\" In the 1990s, algorithms originally developed by AI researchers began to appear as parts of larger systems. AI had solved a lot of very difficult problemsand their solutions proved to be useful throughout the technology industry,such asdata mining,industrial robotics, logistics,speech recognition,banking software,medical diagnosis,andGoogle's search engine. The field of AI received little or no credit for these successes in the 1990s and early 2000s. Many of AI's greatest innovations have been reduced to the status of just another item in the tool chest of computer science.Nick Bostromexplains: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\" Many researchers in AI in the 1990s deliberately called their work by other names, such asinformatics,knowledge-based systems, \"cognitive systems\" orcomputational intelligence. In part, this may have been because they considered their field to be fundamentally different from AI, but also the new names help to procure funding.In the commercial world at least, the failed promises of the AI winter continued to haunt AI research into the 2000s, as theNew York Timesreported in 2005: \"Computer scientists and software engineers avoided the term artificial intelligence for fear of being viewed as wild-eyed dreamers.\" AI researchers began to develop and use sophisticated mathematical tools more than they ever had in the past.Most of the new directions in AI relied heavily on mathematical models, includingartificial neural networks,probabilistic reasoning,soft computingandreinforcement learning. In the 90s and 2000s, many other highly mathematical tools were adapted for AI. These tools were applied to machine learning, perception, and mobility. There was a widespread realization that many of the problems that AI needed to solve were already being worked on by researchers in fields likestatistics,mathematics,electrical engineering,economics, oroperations research. The shared mathematical language allowed both a higher level of collaboration with more established and successful fields and the achievement of results which were measurable and provable; AI had become a more rigorous \"scientific\" discipline. Another key reason for the success in the 90s was that AI researchers focused on specific problems with verifiable solutions (an approach later derided asnarrow AI). This provided useful tools in the present, rather than speculation about the future. A new paradigm called \"intelligent agents\" became widely accepted during the 1990s.Although earlier researchers had proposed modular \"divide and conquer\" approaches to AI,the intelligent agent did not reach its modern form untilJudea Pearl,Allen Newell,Leslie P. Kaelbling, and others brought concepts fromdecision theoryand economics into the study of AI.When theeconomist'sdefinition of arational agentwas married tocomputer science's definition of anobjectormodule, the intelligent agent paradigm was complete. Anintelligent agentis a system that perceives its environment and takes actions which maximize its chances of success. By this definition, simple programs that solve specific problems are \"intelligent agents\", as are human beings and organizations of human beings, such asfirms. The intelligent agent paradigm defines AI research as \"the study of intelligent agents\".This is a generalization of some earlier definitions of AI: it goes beyond studying human intelligence; it studies all kinds of intelligence. The paradigm gave researchers license to study isolated problems and to disagree about methods, but still retain hope that their work could be combined into anagent architecturethat would be capable of general intelligence. On 11 May 1997,Deep Bluebecame the first computer chess-playing system to beat a reigning world chess champion,Garry Kasparov.In 2005, a Stanford robot won theDARPA Grand Challengeby driving autonomously for 131 miles along an unrehearsed desert trail. Two years later, a team from CMU won theDARPA Urban Challengeby autonomously navigating 55 miles in an urban environment while responding to traffic hazards and adhering to traffic laws. These successes were not due to some revolutionary new paradigm, but mostly on the tedious application of engineering skill and on the tremendous increase in the speed and capacity of computers by the 90s.In fact,Deep Blue'scomputer was 10 million times faster than theFerranti Mark 1thatChristopher Stracheytaught to play chess in 1951.This dramatic increase is measured byMoore's law, which predicts that the speed and memory capacity of computers doubles every two years. The fundamental problem of \"raw computer power\" was slowly being overcome. Electronic literatureexperiments such asThe Impermanence Agent(1998–2002) and digital art such asAgent Rubyused AI in their art and literature, \"laying bare the bias accompanying forms of technology that feign objectivity.\" In the first decades of the 21st century, access to large amounts of data (known as \"big data\"),cheaper and faster computersand advancedmachine learningtechniques were successfully applied to many problems throughout the economy. A turning point was the success ofdeep learningaround 2012 which improved the performance of machine learning on many tasks, including image and video processing, text analysis, and speech recognition.Investment in AI increased along with its capabilities, and by 2016, the market for AI-related products, hardware, and software reached more than $8 billion, and theNew York Timesreported that interest in AI had reached a \"frenzy\". In 2002,Ben Goertzeland others became concerned that AI had largely abandoned its original goal of producing versatile, fully intelligent machines, and argued in favor of more direct research intoartificial general intelligence(AGI). By the mid-2010s several companies and institutions had been founded to pursue artificial general intelligence, such asOpenAIandGoogle'sDeepMind. During the same period, new insights intosuperintelligenceraised concerns that AI was anexistential threat. The risks and unintended consequences of AI technology became an area of serious academic research after 2016. The success of machine learning in the 2000s depended on the availability of vast amounts of training data and faster computers.Russell and Norvig wrote that the \"improvement in performance obtained by increasing the size of the data set by two or three orders of magnitude outweighs any improvement that can be made by tweaking the algorithm.\"Geoffrey Hintonrecalled that back in the 80s and 90s the problem was that \"our labeled datasets were thousands of times too small. [And] our computers were millions of times too slow.\"This was no longer true by 2010. The most useful data in the 2000s came from curated, labeled data sets created specifically for machine learning and AI. In 2007, a group atUMass AmherstreleasedLabeled Faces in the Wild, an annotated set of images of faces that was widely used to train and testface recognitionsystems for the next several decades.Fei-Fei LidevelopedImageNet, a database of three million images captioned by volunteers using theAmazon Mechanical Turk. Released in 2009, it was a useful body of training data and a benchmark for testing for the next generation of image processing systems.Google releasedword2vecin 2013 as an open source resource. It used large amounts of data text scraped from the internet andword embeddingto create a numeric vector to represent each word. Users were surprised at how well it was able to capture word meanings, for example, ordinary vector addition would give equivalences like China + River = Yangtze or London − England + France = Paris.This database in particular would be essential for the development oflarge language modelsin the late 2010s. The explosive growth of the internet gave machine learning programs access to billions of pages of text and images that could bescraped. And, for specific problems, large privately held databases contained the relevant data.McKinsey Global Institutereported that \"by 2009, nearly all sectors in the US economy had at least an average of 200 terabytes of stored data\".This collection of information was known in the 2000s asbig data. In aJeopardy!exhibition match in February 2011,IBM'squestion answering systemWatsondefeated the two bestJeopardy!champions,Brad RutterandKen Jennings, by a significant margin.Watson's expertise would have been impossible without the information available on the internet. In 2012,AlexNet, adeep learningmodel,developed byAlex Krizhevsky, won theImageNet Large Scale Visual Recognition Challenge, with significantly fewer errors than the second-place winner.Krizhevsky worked withGeoffrey Hintonat theUniversity of Toronto.This was a turning point in machine learning: over the next few years dozens of other approaches to image recognition were abandoned in favor of deep learning. Deep learning uses a multi-layerperceptron. Although this architecture has been known since the 60s, getting it to work requires powerful hardware and large amounts of training data.Before these became available, improving performance of image processing systems required hand-craftedad hocfeatures that were difficult to implement.Deep learning was simpler and more general. Deep learning was applied to dozens of problems over the next few years (such as speech recognition, machine translation, medical diagnosis, and game playing). In every case it showed enormous gains in performance.Investment and interest in AI boomed as a result. It became fashionable in the 2000s to begin talking about the future of AI again and several popular books considered the possibility ofsuperintelligentmachines and what they might mean for human society. Some of this was optimistic (such asRay Kurzweil'sThe Singularity is Near), but others warned that a sufficiently powerful AI wasexistential threatto humanity, such asNick BostromandEliezer Yudkowsky.The topic became widely covered in the press and many leading intellectuals and politicians commented on the issue. AI programs in the 21st century are defined by theirgoals—the specific measures that they are designed to optimize.Nick Bostrom's influential 2014 bookSuperintelligenceargued that, if one isn't careful about defining these goals, the machine may cause harm to humanity in the process of achieving a goal.Stuart J. Russellused the example of an intelligent robot that kills its owner to prevent it from being unplugged, reasoning \"you can't fetch the coffee if you're dead\".(This problem is known by the technical term \"instrumental convergence\".) The solution is toalignthe machine's goal function with the goals of its owner and humanity in general. Thus, the problem of mitigating the risks and unintended consequences of AI became known as \"the value alignment problem\" or AI alignment. At the same time, machine learning systems had begun to have disturbing unintended consequences.Cathy O'Neilexplained how statistical algorithms had been among the causes of the2008 economic crash,Julia AngwinofProPublicaargued that theCOMPASsystem used by the criminal justice system exhibited racial bias under some measures,others showed that many machine learning systems exhibited some form of racialbias,and there were many other examples of dangerous outcomes that had resulted from machine learning systems. In 2016, the election ofDonald Trumpand the controversy over the COMPAS system illuminated several problems with the current technological infrastructure, including misinformation, social media algorithms designed to maximize engagement, the misuse of personal data and the trustworthiness of predictive models.Issues offairnessand unintended consequences became significantly more popular at AI conferences, publications vastly increased, funding became available, and many researchers refocused their careers on these issues. Thevalue alignment problembecame a serious field of academic study. In the early 2000s, several researchers became concerned that mainstream AI was too focused on \"measurable performance in specific applications\"(known as \"narrow AI\") and had abandoned AI's original goal of creating versatile, fully intelligent machines. An early critic wasNils Nilssonin 1995, and similar opinions were published by AI elder statesmen John McCarthy, Marvin Minsky, and Patrick Winston in 2007–2009. Minsky organized a symposium on \"human-level AI\" in 2004.Ben Goertzeladopted the term \"artificial general intelligence\" for the new sub-field, founding a journal and holding conferences beginning in 2008.The new field grew rapidly, buoyed by the continuing success of artificial neural networks and the hope that it was the key to AGI. Several competing companies, laboratories and foundations were founded to develop AGI in the 2010s.DeepMindwas founded in 2010 by three English scientists,Demis Hassabis,Shane LeggandMustafa Suleyman, with funding fromPeter Thieland laterElon Musk. The founders and financiers were deeply concerned aboutAI safetyand theexistential risk of AI. DeepMind's founders had a personal connection with Yudkowsky, and Musk was among those who was actively raising the alarm.Hassabis was both worried about the dangers of AGI and optimistic about its power; he hoped they could \"solve AI, then solve everything else.\"The New York Timeswrote in 2023, \"At the heart of this competition is a brain-stretching paradox. The people who say they are most worried about AI are among the most determined to create it and enjoy its riches. They have justified their ambition with their strong belief that they alone can keep AI from endangering Earth.\" In 2012,Geoffrey Hinton(who been leading neural network research since the 80s) was approached byBaidu, which wanted to hire him and all his students for an enormous sum. Hinton decided to hold an auction and, at a Lake Tahoe AI conference, they sold themselves toGooglefor a price of $44 million. Hassabis took notice and sold DeepMind to Google in 2014, on the condition that it would not accept military contracts and would be overseen by an ethics board. Larry Pageof Google, unlike Musk and Hassabis, was an optimist about the future of AI. Musk and Paige became embroiled in an argument about the risk of AGI at Musk's 2015 birthday party. They had been friends for decades but stopped speaking to each other shortly afterwards. Musk attended the one and only meeting of the DeepMind's ethics board, where it became clear that Google was uninterested in mitigating the harm of AGI. Frustrated by his lack of influence he foundedOpenAIin 2015, enlistingSam Altmanto run it and hiring top scientists. OpenAI began as a non-profit, \"free from the economic incentives that were driving Google and other corporations.\"Musk became frustrated again and left the company in 2018. OpenAI turned to Microsoft for continued financial support and Altman and OpenAI formed a for-profit version of the company with more than $1 billion in financing. In 2021,Dario Amodeiand 14 other scientists left OpenAI over concerns that the company was putting profits above safety. They formedAnthropic, which soon had $6 billion in financing from Microsoft and Google. The AI boom started with the initial development of key architectures and algorithms such as thetransformer architecturein 2017, leading to the scaling and development of large language models exhibiting human-like traits of knowledge, attention, and creativity. The new AI era began in 2020, with the public release of scaledlarge language models(LLMs) such asChatGPT. In 2017, thetransformerarchitecture was proposed by Google researchers in a paper titled \"Attention Is All You Need\". It exploits aself-attentionmechanism and became widely used in large language models.Large language models, based on the transformer, were further developed by other companies:OpenAIreleasedGPT-3in 2020, thenDeepMindreleasedGatoin 2022. These arefoundation models: they are trained on vast quantities of unlabeled data and can be adapted to a wide range of downstream tasks. These models can discuss a huge number of topics and display general knowledge, which has raised questions around whether or not they are examples ofartificial general intelligence. Bill Gateswas skeptical of the new technology and the hype that surrounded AGI. However, Altman presented him with a live demo ofChatGPT-4passing an advanced biology test. Gates was convinced.In 2023,Microsoft Researchtested the model with a large variety of tasks, and concluded that \"it could reasonably be viewed as an early (yet still incomplete) version of anartificial general intelligence(AGI) system\". In 2024,OpenAI o3, a type of advancedreasoning modeldeveloped by OpenAI, was announced. On the Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI) benchmark developed byFrançois Cholletin 2019, the model achieved an unofficial score of 87.5% on the semi-private test, surpassing the typical human score of 84%. The benchmark is supposed to be a necessary, but not sufficient test for AGI. Speaking of the benchmark, Chollet has said \"You'll know AGI is here when the exercise of creating tasks that are easy for regular humans but hard for AI becomes simply impossible.\" Investment in AI grew exponentially after 2020, with venture capital funding for generative AI companies increasing dramatically. Total AI investments rose from $18 billion in 2014 to $119 billion in 2021, with generative AI accounting for approximately 30% of investments by 2023.According to metrics from 2017 to 2021, the United States outranked the rest of the world in terms ofventure capital funding, number ofstartups, and AIpatentsgranted.The commercial AI scene became dominated by AmericanBig Techcompanies, whose investments in this area surpassed those from U.S.-basedventure capitalists.OpenAI's valuation reached $86 billion by early 2024,whileNVIDIA's market capitalization surpassed $3.3 trillion by mid-2024, making it the world's largest company bymarket capitalizationas the demand for AI-capableGPUssurged. 15.ai, launched in March 2020by an anonymousMITresearcher,was one of the earliest examples ofgenerative AIgaining widespread public attention during the initial stages of the AI boom.The freeweb applicationdemonstrated the ability to clone character voices using neural networks with minimal training data, requiring as little as 15 seconds of audio to reproduce a voice—a capability later corroborated byOpenAIin 2024.The service wentviralon social media platforms in early 2021,allowing users to generate speech for characters frompopular mediafranchises, and became particularly notable for its pioneering role in popularizingAI voice synthesisforcreative contentandmemes. Contemporary AI systems are now becoming human-competitive at general tasks, and we must ask ourselves: Should we let machines flood our information channels with propaganda and untruth? Should we automate away all the jobs, including the fulfilling ones? Should we develop nonhuman minds that might eventually outnumber, outsmart, obsolete and replace us? Should we risk loss of control of our civilization? Such decisions must not be delegated to unelected tech leaders.Powerful AI systems should be developed only once we are confident that their effects will be positive and their risks will be manageable.This confidence must be well justified and increase with the magnitude of a system’s potential effects. OpenAI’s recent statement regarding artificial general intelligence, states that \"At some point, it may be important to get independent review before starting to train future systems, and for the most advanced efforts to agree to limit the rate of growth of compute used for creating new models.\" We agree. That point is now. Therefore,we call on all AI labs to immediately pause for at least 6 months the training of AI systems more powerful than GPT-4. This pause should be public and verifiable, and include all key actors. If such a pause cannot be enacted quickly, governments should step in and institute a moratorium. ChatGPTwas launched on 30 November 2022, marking a pivotal moment in artificial intelligence's public adoption. Within days of its release it went viral, gaining over 100 million users in two months and becoming the fastest-growing consumer software application in history.The chatbot's ability to engage in human-like conversations, write code, and generate creative content captured public imagination and led to rapid adoption across various sectors includingeducation,business, and research.ChatGPT's success prompted unprecedented responses from major technology companies—Googledeclared a \"code red\" and rapidly launchedGemini(formerly known as Google Bard), whileMicrosoftincorporated the technology intoBing Chat. The rapid adoption of these AI technologies sparked intense debate about their implications. Notable AI researchers and industry leaders voiced both optimism and concern about the accelerating pace of development. In March 2023, over 20,000 signatories, includingcomputer scientistYoshua Bengio,Elon Musk, andAppleco-founderSteve Wozniak, signedan open letter calling for a pause in advanced AI development, citing \"profound risks to society and humanity.\"However, other prominent researchers likeJuergen Schmidhubertook a more optimistic view, emphasizing that the majority of AI research aims to make \"human lives longer and healthier and easier.\" By mid-2024, however, the financial sector began to scrutinize AI companies more closely, particularly questioning their capacity to produce areturn on investmentcommensurate with their massive valuations. Some prominent investors raised concerns about market expectations becoming disconnected from fundamental business realities.Jeremy Grantham, co-founder ofGMO LLC, warned investors to \"be quite careful\" and drew parallels to previous technology-driven market bubbles.Similarly,Jeffrey Gundlach, CEO ofDoubleLine Capital, explicitly compared the AI boom to thedot-com bubbleof the late 1990s, suggesting that investor enthusiasm might be outpacing realistic near-term capabilities and revenue potential.These concerns were amplified by the substantial market capitalizations of AI-focused companies, many of which had yet to demonstrate sustainable profitability models. In March 2024,Anthropicreleased theClaude3 family of large language models, including Claude 3 Haiku, Sonnet, and Opus.The models demonstrated significant improvements in capabilities across various benchmarks, with Claude 3 Opus notably outperforming leading models from OpenAI and Google.In June 2024, Anthropic released Claude 3.5 Sonnet, which demonstrated improved performance compared to the larger Claude 3 Opus, particularly in areas such as coding, multistep workflows, and image analysis. In 2024, theRoyal Swedish Academyof Sciences awardedNobel Prizesin recognition of groundbreaking contributions toartificial intelligence. The recipients included: In January 2025, OpenAI announced a new AI, ChatGPT-Gov, which would be specifically designed for US government agencies to use securely.Open AI said that agencies could utilize ChatGPT Gov on a Microsoft Azure cloud or Azure Government cloud, \"on top of Microsoft’s Azure’s OpenAI Service.\" OpenAI's announcement stated that \"Self-hosting ChatGPT Gov enables agencies to more easily manage their own security, privacy, and compliance requirements, such as stringent cybersecurity frameworks (IL5, CJIS, ITAR,FedRAMPHigh). Additionally, we believe this infrastructure will expedite internal authorization of OpenAI's tools for the handling of non-public sensitive data.\" Countries have invested in policies and funding to deployautonomous robotsin an attempt to address labor shortages and enhancing efficiency, while also implementingregulatory frameworksfor ethical and safe development. In 2025, China invested approximately 730 billion yuan (roughly US$100 billion) to advance AI and robotics in smart manufacturing and healthcare.The \"14th Five-Year Plan\" (2021–2025) prioritized service robots, with AI systems enabling robots to perform complex tasks like assisting in surgeries or automating factory assembly lines.Some funding also supported defense applications, such as autonomous drones.Starting in September 2025, China mandated labeling of AI-generated content to ensure transparency and public trust in these technologies. In January 2025,Stargate LLCwas formed as a joint venture ofOpenAI,SoftBank,Oracle, andMGX, who announced plans to invest US$500 billion in AI infrastructure in theUnited Statesby 2029. The venture was formally announced by U.S. President Donald Trump on 21 January 2025, with SoftBank CEOMasayoshi Sonappointed as chairman. The U.S. government allocated approximately $2 billion to integrate AI and robotics in manufacturing and logistics.State governments supplemented this with funding for service robots, such as those deployed in warehouses to fulfill verbal commands for inventory management or in eldercare facilities to respond to residents' requests for assistance.Some funds were directed to defense, includinglethal autonomous weaponandmilitary robot. In January 2025, Executive Order 14179 established an \"AI Action Plan\" to accelerate innovation and deployment of these technologies with the declared intent of \"world domination\" and \"victory\"..", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/History_of_artificial_intelligence", "https://en.wikipedia.org/wiki/History_of_artificial_intelligence", "https://en.wikipedia.org/wiki/History_of_artificial_intelligence", "https://en.wikipedia.org/wiki/Timeline_of_artificial_intelligence", "https://en.wikipedia.org/wiki/Progress_in_artificial_intelligence", "https://en.wikipedia.org/wiki/Artificial_intelligence", "https://en.wikipedia.org/wiki/Artificial_general_intelligence", "https://en.wikipedia.org/wiki/Intelligent_agent"]},
{"id": "f69d9e095416", "url": "https://en.wikipedia.org/wiki/Artificial_intelligence", "title": "Artificial intelligence", "headings": ["Contents", "Goals", "Reasoning and problem-solving", "Knowledge representation", "Planning and decision-making", "Learning", "Natural language processing", "Perception", "Social intelligence", "General intelligence", "Techniques", "Search and optimization", "Logic", "Probabilistic methods for uncertain reasoning", "Classifiers and statistical learning methods", "Artificial neural networks", "Deep learning", "GPT", "Hardware and software", "Applications", "Health and medicine", "Games", "Mathematics", "Finance", "Military", "Generative AI", "Agents", "Web search", "Sexuality", "Other industry-specific tasks", "Ethics", "Risks and harm", "Ethical machines and alignment", "Open source", "Frameworks", "Regulation", "History", "Philosophy", "Defining artificial intelligence", "Evaluating approaches to AI", "Machine consciousness, sentience, and mind", "Future", "Superintelligence and the singularity", "Transhumanism", "In fiction", "See also", "Explanatory notes", "References", "AI textbooks", "History of AI", "Other sources", "Further reading", "External links"], "content": " Artificial intelligence(AI) is the capability ofcomputational systemsto perform tasks typically associated withhuman intelligence, such aslearning,reasoning,problem-solving,perception, anddecision-making. It is afield of researchincomputer sciencethat develops and studies methods andsoftwarethat enable machines toperceive their environmentand uselearningandintelligenceto take actions that maximize their chances of achieving defined goals. High-profileapplications of AIinclude advancedweb search engines(e.g.,Google Search);recommendation systems(used byYouTube,Amazon, andNetflix);virtual assistants(e.g.,Google Assistant,Siri, andAlexa);autonomous vehicles(e.g.,Waymo);generativeandcreativetools (e.g.,language modelsandAI art); andsuperhumanplay and analysis instrategy games(e.g.,chessandGo). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it'snot labeled AI anymore.\" Various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning,reasoning,knowledge representation,planning,natural language processing,perception, and support forrobotics.To reach these goals, AI researchers have adapted and integrated a wide range of techniques, includingsearchandmathematical optimization,formal logic,artificial neural networks, and methods based onstatistics,operations research, andeconomics.AI also draws uponpsychology,linguistics,philosophy,neuroscience, and other fields.Some companies, such asOpenAI,Google DeepMindandMeta,aim to createartificial general intelligence(AGI)—AI that can complete virtually any cognitive task at least as well as a human. Artificial intelligence was founded as an academic discipline in 1956,and the field went through multiple cycles of optimism throughoutits history,followed by periods of disappointment and loss of funding, known asAI winters.Funding and interest vastly increased after 2012 whengraphics processing unitsstarted being used to accelerate neural networks anddeep learningoutperformed previous AI techniques.This growth accelerated further after 2017 with thetransformer architecture.In the 2020s, an ongoing period of rapidprogressin advanced generative AI became known as theAI boom. Generative AI's ability to create and modify content has led to several unintended consequences and harms, which has raisedethical concernsaboutAI's long-term effectsandpotential existential risks, prompting discussions aboutregulatory policiesto ensurethe safetyand benefits of the technology. The general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research. Early researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logicaldeductions.By the late 1980s and 1990s, methods were developed for dealing withuncertainor incomplete information, employing concepts fromprobabilityandeconomics. Many of these algorithms are insufficient for solving large reasoning problems because they experience a \"combinatorial explosion\": They become exponentially slower as the problems grow.Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.Accurate and efficient reasoning is an unsolved problem. Knowledge representationandknowledge engineeringallow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval,scene interpretation,clinical decision support,knowledge discovery (mining \"interesting\" and actionable inferences from largedatabases),and other areas. Aknowledge baseis a body of knowledge represented in a form that can be used by a program. Anontologyis the set of objects, relations, concepts, and properties used by a particular domain of knowledge.Knowledge bases need to represent things such as objects, properties, categories, and relations between objects;situations, events, states, and time;causes and effects;knowledge about knowledge (what we know about what other people know);default reasoning(things that humans assume are true until they are told differently and will remain true even when other facts are changing);and many other aspects and domains of knowledge. Among the most difficult problems in knowledge representation are the breadth ofcommonsense knowledge(the set of atomic facts that the average person knows is enormous);and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as \"facts\" or \"statements\" that they could express verbally).There is also the difficulty ofknowledge acquisition, the problem of obtaining knowledge for AI applications. An \"agent\" is anything that perceives and takes actions in the world. Arational agenthas goals or preferences and takes actions to make them happen.Inautomated planning, the agent has a specific goal.Inautomated decision-making, the agent has preferences—there are some situations it would prefer to be in, and some situations it is trying to avoid. The decision-making agent assigns a number to each situation (called the \"utility\") that measures how much the agent prefers it. For each possible action, it can calculate the \"expected utility\": theutilityof all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility. Inclassical planning, the agent knows exactly what the effect of any action will be.In most real-world problems, however, the agent may not be certain about the situation they are in (it is \"unknown\" or \"unobservable\") and it may not know for certain what will happen after each possible action (it is not \"deterministic\"). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked. In some problems, the agent's preferences may be uncertain, especially if there are other agents or humans involved. These can be learned (e.g., withinverse reinforcement learning), or the agent can seek information to improve its preferences.Information value theorycan be used to weigh the value of exploratory or experimental actions.The space of possible future actions and situations is typicallyintractablylarge, so the agents must take actions and evaluate situations while being uncertain of what the outcome will be. AMarkov decision processhas atransition modelthat describes the probability that a particular action will change the state in a particular way and a reward function that supplies the utility of each state and the cost of each action. Apolicyassociates a decision with each possible state. The policy could be calculated (e.g., byiteration), beheuristic, or it can be learned. Game theorydescribes the rational behavior of multiple interacting agents and is used in AI programs that make decisions that involve other agents. Machine learningis the study of programs that can improve their performance on a given task automatically.It has been a part of AI from the beginning. There are several kinds of machine learning.Unsupervised learninganalyzes a stream of data and finds patterns and makes predictions without any other guidance.Supervised learningrequires labeling the training data with the expected answers, and comes in two main varieties:classification(where the program must learn to predict what category the input belongs in) andregression(where the program must deduce a numeric function based on numeric input). Inreinforcement learning, the agent is rewarded for good responses and punished for bad ones. The agent learns to choose responses that are classified as \"good\".Transfer learningis when the knowledge gained from one problem is applied to a new problem.Deep learningis a type of machine learning that runs inputs through biologically inspiredartificial neural networksfor all of these types of learning. Computational learning theorycan assess learners bycomputational complexity, bysample complexity(how much data is required), or by other notions ofoptimization. Natural language processing(NLP) allows programs to read, write and communicate in human languages.Specific problems includespeech recognition,speech synthesis,machine translation,information extraction,information retrievalandquestion answering. Early work, based onNoam Chomsky'sgenerative grammarandsemantic networks, had difficulty withword-sense disambiguationunless restricted to small domains called \"micro-worlds\" (due to thecommon sense knowledge problem).Margaret Mastermanbelieved that it was meaning and not grammar that was the key to understanding languages, and thatthesauriand not dictionaries should be the basis of computational language structure. Modern deep learning techniques for NLP includeword embedding(representing words, typically asvectorsencoding their meaning),transformers(a deep learning architecture using anattentionmechanism),and others.In 2019,generative pre-trained transformer(or \"GPT\") language models began to generate coherent text,and by 2023, these models were able to get human-level scores on thebar exam,SATtest,GREtest, and many other real-world applications. Machine perceptionis the ability to use input from sensors (such as cameras, microphones, wireless signals, activelidar, sonar, radar, andtactile sensors) to deduce aspects of the world.Computer visionis the ability to analyze visual input. The field includesspeech recognition,image classification,facial recognition,object recognition,object tracking,androbotic perception. Affective computingis a field that comprises systems that recognize, interpret, process, or simulate humanfeeling, emotion, and mood.For example, somevirtual assistantsare programmed to speak conversationally or even to banter humorously; it makes them appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitatehuman–computer interaction. However, this tends to give naïve users an unrealistic conception of the intelligence of existing computer agents.Moderate successes related to affective computing include textualsentiment analysisand, more recently,multimodal sentiment analysis, wherein AI classifies the effects displayed by a videotaped subject. A machine withartificial general intelligencewould be able to solve a wide variety of problems with breadth and versatility similar tohuman intelligence. AI research uses a wide variety of techniques to accomplish the goals above. AI can solve many problems by intelligently searching through many possible solutions.There are two very different kinds of search used in AI:state space searchandlocal search. State space searchsearches through a tree of possible states to try to find a goal state.For example,planningalgorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process calledmeans-ends analysis. Simple exhaustive searchesare rarely sufficient for most real-world problems: thesearch space(the number of places to search) quickly grows toastronomical numbers. The result is a search that istoo slowor never completes.\"Heuristics\" or \"rules of thumb\" can help prioritize choices that are more likely to reach a goal. Adversarial searchis used forgame-playingprograms, such as chess or Go. It searches through atreeof possible moves and countermoves, looking for a winning position. Local searchusesmathematical optimizationto find a solution to a problem. It begins with some form of guess and refines it incrementally. Gradient descentis a type of local search that optimizes a set of numerical parameters by incrementally adjusting them to minimize aloss function. Variants of gradient descent are commonly used to trainneural networks,through thebackpropagationalgorithm. Another type of local search isevolutionary computation, which aims to iteratively improve a set of candidate solutions by \"mutating\" and \"recombining\" them,selectingonly the fittest to survive each generation. Distributed search processes can coordinate viaswarm intelligencealgorithms. Two popular swarm algorithms used in search areparticle swarm optimization(inspired by birdflocking) andant colony optimization(inspired byant trails). Formallogicis used forreasoningandknowledge representation.Formal logic comes in two main forms:propositional logic(which operates on statements that are true or false and useslogical connectivessuch as \"and\", \"or\", \"not\" and \"implies\")andpredicate logic(which also operates on objects, predicates and relations and usesquantifierssuch as \"EveryXis aY\" and \"There aresomeXs that areYs\"). Deductive reasoningin logic is the process ofprovinga new statement (conclusion) from other statements that are given and assumed to be true (thepremises).Proofs can be structured as prooftrees, in which nodes are labelled by sentences, and children nodes are connected to parent nodes byinference rules. Given a problem and a set of premises, problem-solving reduces to searching for a proof tree whose root node is labelled by a solution of the problem and whoseleaf nodesare labelled by premises oraxioms. In the case ofHorn clauses, problem-solving search can be performed by reasoningforwardsfrom the premises orbackwardsfrom the problem.In the more general case of the clausal form offirst-order logic,resolutionis a single, axiom-free rule of inference, in which a problem is solved by proving a contradiction from premises that include the negation of the problem to be solved. Inference in both Horn clause logic and first-order logic isundecidable, and thereforeintractable. However, backward reasoning with Horn clauses, which underpins computation in thelogic programminglanguageProlog, isTuring complete. Moreover, its efficiency is competitive with computation in othersymbolic programminglanguages. Fuzzy logicassigns a \"degree of truth\" between 0 and 1. It can therefore handle propositions that are vague and partially true. Non-monotonic logics, including logic programming withnegation as failure, are designed to handledefault reasoning.Other specialized versions of logic have been developed to describe many complex domains. Many problems in AI (including reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of tools to solve these problems using methods fromprobabilitytheory and economics.Precise mathematical tools have been developed that analyze how an agent can make choices and plan, usingdecision theory,decision analysis,andinformation value theory.These tools include models such asMarkov decision processes,dynamicdecision networks,game theoryandmechanism design. Bayesian networksare a tool that can be used forreasoning(using theBayesian inferencealgorithm),learning(using theexpectation–maximization algorithm),planning(usingdecision networks)andperception(usingdynamic Bayesian networks). Probabilistic algorithms can also be used for filtering, prediction, smoothing, and finding explanations for streams of data, thus helping perception systems analyze processes that occur over time (e.g.,hidden Markov modelsorKalman filters). The simplest AI applications can be divided into two types: classifiers (e.g., \"if shiny then diamond\"), on one hand, and controllers (e.g., \"if diamond then pick up\"), on the other hand.Classifiersare functions that usepattern matchingto determine the closest match. They can be fine-tuned based on chosen examples usingsupervised learning. Each pattern (also called an \"observation\") is labeled with a certain predefined class. All the observations combined with their class labels are known as adata set. When a new observation is received, that observation is classified based on previous experience. There are many kinds of classifiers in use.Thedecision treeis the simplest and most widely used symbolic machine learning algorithm.K-nearest neighboralgorithm was the most widely used analogical AI until the mid-1990s, andKernel methodssuch as thesupport vector machine(SVM) displaced k-nearest neighbor in the 1990s.Thenaive Bayes classifieris reportedly the \"most widely used learner\"at Google, due in part to its scalability.Neural networksare also used as classifiers. An artificial neural network is based on a collection of nodes also known asartificial neurons, which loosely model theneuronsin a biological brain. It is trained to recognise patterns; once trained, it can recognise those patterns in fresh data. There is an input, at least one hidden layer of nodes and an output. Each node applies a function and once theweightcrosses its specified threshold, the data is transmitted to the next layer. A network is typically called a deep neural network if it has at least 2 hidden layers. Learning algorithms for neural networks uselocal searchto choose the weights that will get the right output for each input during training. The most common training technique is thebackpropagationalgorithm.Neural networks learn to model complex relationships between inputs and outputs andfind patternsin data. In theory, a neural network can learn any function. Infeedforward neural networksthe signal passes in only one direction.The termperceptrontypically refers to a single-layer neural network.In contrast, deep learning uses many layers.Recurrent neural networks(RNNs) feed the output signal back into the input, which allows short-term memories of previous input events.Long short-term memorynetworks (LSTMs) are recurrent neural networks that better preserve longterm dependencies and are less sensitive to thevanishing gradient problem.Convolutional neural networks(CNNs) use layers ofkernelsto more efficiently process local patterns. This local processing is especially important inimage processing, where the early CNN layers typically identify simple local patterns such as edges and curves, with subsequent layers detecting more complex patterns like textures, and eventually whole objects. Deep learninguses several layers of neurons between the network's inputs and outputs.The multiple layers can progressively extract higher-level features from the raw input. For example, inimage processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits, letters, or faces. Deep learning has profoundly improved the performance of programs in many important subfields of artificial intelligence, includingcomputer vision,speech recognition,natural language processing,image classification,and others. The reason that deep learning performs so well in so many applications is not known as of 2021.The sudden success of deep learning in 2012–2015 did not occur because of some new discovery or theoretical breakthrough (deep neural networks and backpropagation had been described by many people, as far back as the 1950s)but because of two factors: the incredible increase in computer power (including the hundred-fold increase in speed by switching toGPUs) and the availability of vast amounts of training data, especially the giantcurated datasetsused for benchmark testing, such asImageNet. Generative pre-trained transformers(GPT) arelarge language models(LLMs) that generate text based on the semantic relationships between words in sentences. Text-based GPT models are pre-trained on a largecorpus of textthat can be from the Internet. The pretraining consists of predicting the nexttoken(a token being usually a word, subword, or punctuation). Throughout this pretraining, GPT models accumulate knowledge about the world and can then generate human-like text by repeatedly predicting the next token. Typically, a subsequent training phase makes the model more truthful, useful, and harmless, usually with a technique calledreinforcement learning from human feedback(RLHF). Current GPT models are prone to generating falsehoods called \"hallucinations\". These can be reduced with RLHF and quality data, but the problem has been getting worse for reasoning systems.Such systems are used inchatbots, which allow people to ask a question or request a task in simple text. Current models and services includeChatGPT,Claude,Gemini,Copilot, andMeta AI.MultimodalGPT models can process different types of data (modalities) such as images, videos, sound, and text. In the late 2010s,graphics processing units(GPUs) that were increasingly designed with AI-specific enhancements and used with specializedTensorFlowsoftware had replaced previously usedcentral processing unit(CPUs) as the dominant means for large-scale (commercial and academic)machine learningmodels' training.Specializedprogramming languagessuch asPrologwere used in early AI research,butgeneral-purpose programming languageslikePythonhave become predominant. The transistor density inintegrated circuitshas been observed to roughly double every 18 months—a trend known asMoore's law, named after theIntelco-founderGordon Moore, who first identified it. Improvements inGPUshave been even faster,a trend sometimes calledHuang's law,named afterNvidiaco-founder and CEOJensen Huang. AI and machine learning technology is used in most of the essential applications of the 2020s, including:search engines(such asGoogle Search),targeting online advertisements,recommendation systems(offered byNetflix,YouTubeorAmazon), drivinginternet traffic,targeted advertising(AdSense,Facebook),virtual assistants(such asSiriorAlexa),autonomous vehicles(includingdrones,ADASandself-driving cars),automatic language translation(Microsoft Translator,Google Translate),facial recognition(Apple'sFaceIDorMicrosoft'sDeepFaceandGoogle'sFaceNet) andimage labeling(used byFacebook, Apple'sPhotosandTikTok). The deployment of AI may be overseen by achief automation officer(CAO). The application of AI inmedicineandmedical researchhas the potential to increase patient care and quality of life.Through the lens of theHippocratic Oath, medical professionals are ethically compelled to use AI, if applications can more accurately diagnose and treat patients. For medical research, AI is an important tool for processing and integratingbig data. This is particularly important fororganoidandtissue engineeringdevelopment which usemicroscopyimaging as a key technique in fabrication.It has been suggested that AI can overcome discrepancies in funding allocated to different fields of research.New AI tools can deepen the understanding of biomedically relevant pathways. For example,AlphaFold 2(2021) demonstrated the ability to approximate, in hours rather than months, the 3Dstructure of a protein.In 2023, it was reported that AI-guided drug discovery helped find a class of antibiotics capable of killing two different types of drug-resistant bacteria.In 2024, researchers used machine learning to accelerate the search forParkinson's diseasedrug treatments. Their aim was to identify compounds that block the clumping, or aggregation, ofalpha-synuclein(the protein that characterises Parkinson's disease). They were able to speed up the initial screening process ten-fold and reduce the cost by a thousand-fold. Game playingprograms have been used since the 1950s to demonstrate and test AI's most advanced techniques.Deep Bluebecame the first computer chess-playing system to beat a reigning world chess champion,Garry Kasparov, on 11 May 1997.In 2011, in aJeopardy!quiz showexhibition match,IBM'squestion answering system,Watson, defeated the two greatestJeopardy!champions,Brad RutterandKen Jennings, by a significant margin.In March 2016,AlphaGowon 4 out of 5 games ofGoin a match with Go championLee Sedol, becoming the firstcomputer Go-playing system to beat a professional Go player withouthandicaps. Then, in 2017, itdefeated Ke Jie, who was the best Go player in the world.Other programs handleimperfect-informationgames, such as thepoker-playing programPluribus.DeepMinddeveloped increasingly generalisticreinforcement learningmodels, such as withMuZero, which could be trained to play chess, Go, orAtarigames.In 2019, DeepMind's AlphaStar achieved grandmaster level inStarCraft II, a particularly challenging real-time strategy game that involves incomplete knowledge of what happens on the map.In 2021, an AI agent competed in a PlayStationGran Turismocompetition, winning against four of the world's best Gran Turismo drivers using deep reinforcement learning.In 2024, Google DeepMind introduced SIMA, a type of AI capable of autonomously playing nine previously unseenopen-worldvideo games by observing screen output, as well as executing short, specific tasks in response to natural language instructions. Large language models, such asGPT-4,Gemini,Claude,LlamaorMistral, are increasingly used in mathematics. These probabilistic models are versatile, but can also produce wrong answers in the form ofhallucinations. They sometimes need a large database of mathematical problems to learn from, but also methods such assupervisedfine-tuningor trainedclassifierswith human-annotated data to improve answers for new problems and learn from corrections.A February 2024 study showed that the performance of some language models for reasoning capabilities in solving math problems not included in their training data was low, even for problems with only minor deviations from trained data.One technique to improve their performance involves training the models to produce correctreasoningsteps, rather than just the correct result.TheAlibaba Groupdeveloped a version of itsQwenmodels calledQwen2-Math, that achieved state-of-the-art performance on several mathematical benchmarks, including 84% accuracy on the MATH dataset of competition mathematics problems.In January 2025, Microsoft proposed the techniquerStar-Maththat leveragesMonte Carlo tree searchand step-by-step reasoning, enabling a relatively small language model likeQwen-7Bto solve 53% of theAIME2024 and 90% of the MATH benchmark problems. Alternatively, dedicated models for mathematical problem solving with higher precision for the outcome including proof of theorems have been developed such asAlphaTensor,AlphaGeometry,AlphaProofandAlphaEvolveall fromGoogle DeepMind,LlemmafromEleutherAIorJulius. When natural language is used to describe mathematical problems, converters can transform such prompts into a formal language such asLeanto define mathematical tasks. The experimental modelGemini Deep Thinkaccepts natural language prompts directly and achieved gold medal results in theInternational Math Olympiadof 2025. Some models have been developed to solve challenging problems and reach good results in benchmark tests, others to serve as educational tools in mathematics. Topological deep learningintegrates varioustopologicalapproaches. Finance is one of the fastest growing sectors where applied AI tools are being deployed: from retail online banking to investment advice and insurance, where automated \"robot advisers\" have been in use for some years. According to Nicolas Firzli, director of theWorld Pensions & Investments Forum, it may be too early to see the emergence of highly innovative AI-informed financial products and services. He argues that \"the deployment of AI tools will simply further automatise things: destroying tens of thousands of jobs in banking, financial planning, and pension advice in the process, but I'm not sure it will unleash a new wave of [e.g., sophisticated] pension innovation.\" Various countries are deploying AI military applications.The main applications enhancecommand and control, communications, sensors, integration and interoperability.Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous andautonomous vehicles.AI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions,target acquisition, coordination and deconfliction of distributedJoint Firesbetween networked combat vehicles, both human-operated andautonomous. AI has been used in military operations in Iraq, Syria, Israel and Ukraine. Generative artificial intelligence(Generative AI, GenAI,or GAI) is a subfield of artificial intelligence that usesgenerative modelsto produce text,images,videos,audio,software codeor other forms of data.These modelslearnthe underlying patterns and structures of theirtraining dataand use them to produce new databased on the input, which often comes in the form of natural languageprompts. Generative AI tools have become more common since theAI boomin the 2020s. This boom was made possible by improvements intransformer-baseddeepneural networks, particularlylarge language models(LLMs). Major tools includechatbotssuch asChatGPT,Copilot,Gemini,Claude,Grok, andDeepSeek;text-to-imagemodels such asStable Diffusion,Midjourney, andDALL-E; andtext-to-videomodels such asVeoandSora.Technology companies developing generative AI includeOpenAI,xAI,Anthropic,Meta AI,Microsoft,Google,DeepSeek,BaiduandYandex. AI agents are software entities designed to perceive their environment, make decisions, and take actions autonomously to achieve specific goals. These agents can interact with users, their environment, or other agents. AI agents are used in various applications, includingvirtual assistants,chatbots,autonomous vehicles,game-playing systems, andindustrial robotics. AI agents operate within the constraints of their programming, available computational resources, and hardware limitations. This means they are restricted to performing tasks within their defined scope and have finite memory and processing capabilities. In real-world applications, AI agents often face time constraints for decision-making and action execution. Many AI agents incorporate learning algorithms, enabling them to improve their performance over time through experience or training. Using machine learning, AI agents can adapt to new situations and optimise their behaviour for their designated tasks. Microsoft introducedCopilot Searchin February 2023 under the nameBing Chat, as a built-in feature for Microsoft Edge and Bing mobile app. Copilot Search provides AI-generated summariesand step-by-step reasoning based of information from web publishers, ranked in Bing Search.For safety, Copilot uses AI-based classifiers and filters to reduce potentially harmful content. Google officially pushed its AI Search at its Google I/O event on May 20, 2025.It keeps people looking at Google instead of clicking on a search result.AI Overviewsuses Gemini 2.5 to provide contextual answers to user queries based on web content. Applications of AI in this domain include AI-enabled menstruation and fertility trackers that analyze user data to offer predictions,AI-integrated sex toys (e.g.,teledildonics),AI-generated sexual education content,and AI agents that simulate sexual and romantic partners (e.g.,Replika).AI is also used for the production of non-consensualdeepfake pornography, raising significant ethical and legal concerns. AI technologies have also been used to attempt to identifyonline gender-based violenceand onlinesexual groomingof minors. There are also thousands of successful AI applications used to solve specific problems for specific industries or institutions. In a 2017 survey, one in five companies reported having incorporated \"AI\" in some offerings or processes.A few examples areenergy storage, medical diagnosis, military logistics, applications that predict the result of judicial decisions,foreign policy, or supply chain management. AI applications for evacuation anddisastermanagement are growing. AI has been used to investigate patterns in large-scale and small-scale evacuations using historical data from GPS, videos or social media. Furthermore, AI can provide real-time information on the evacuation conditions. In agriculture, AI has helped farmers to increase yield and identify areas that need irrigation, fertilization, pesticide treatments. Agronomists use AI to conduct research and development. AI has been used to predict the ripening time for crops such as tomatoes, monitor soil moisture, operate agricultural robots, conductpredictive analytics, classify livestock pig call emotions, automate greenhouses, detect diseases and pests, and save water. Artificial intelligence is used in astronomy to analyze increasing amounts of available data and applications, mainly for \"classification, regression, clustering, forecasting, generation, discovery, and the development of new scientific insights.\" For example, it is used for discovering exoplanets, forecasting solar activity, and distinguishing between signals and instrumental effects in gravitational wave astronomy. Additionally, it could be used for activities in space, such as space exploration, including the analysis of data from space missions, real-time science decisions of spacecraft, space debris avoidance, and more autonomous operation. During the2024 Indian elections, US$50 million was spent on authorized AI-generated content, notably by creatingdeepfakesof allied (including sometimes deceased) politicians to better engage with voters, and by translating speeches to various local languages. AI has potential benefits and potential risks.AI may be able to advance science and find solutions for serious problems:Demis HassabisofDeepMindhopes to \"solve intelligence, and then use that to solve everything else\".However, as the use of AI has become widespread, several unintended consequences and risks have been identified.In-production systems can sometimes not factor ethics and bias into their AI training processes, especially when the AI algorithms are inherently unexplainable in deep learning. Machine learning algorithms require large amounts of data. The techniques used to acquire this data have raised concerns aboutprivacy,surveillanceandcopyright. AI-powered devices and services, such as virtual assistants and IoT products, continuously collect personal information, raising concerns about intrusive data gathering and unauthorized access by third parties. The loss of privacy is further exacerbated by AI's ability to process and combine vast amounts of data, potentially leading to a surveillance society where individual activities are constantly monitored and analyzed without adequate safeguards or transparency. Sensitive user data collected may include online activity records, geolocation data, video, or audio.For example, in order to buildspeech recognitionalgorithms,Amazonhas recorded millions of private conversations and allowedtemporary workersto listen to and transcribe some of them.Opinions about this widespread surveillance range from those who see it as anecessary evilto those for whom it is clearlyunethicaland a violation of theright to privacy. AI developers argue that this is the only way to deliver valuable applications and have developed several techniques that attempt to preserve privacy while still obtaining the data, such asdata aggregation,de-identificationanddifferential privacy.Since 2016, some privacy experts, such asCynthia Dwork, have begun to view privacy in terms offairness.Brian Christianwrote that experts have pivoted \"from the question of 'what they know' to the question of 'what they're doing with it'.\" Generative AI is often trained on unlicensed copyrighted works, including in domains such as images or computer code; the output is then used under the rationale of \"fair use\". Experts disagree about how well and under what circumstances this rationale will hold up in courts of law; relevant factors may include \"the purpose and character of the use of the copyrighted work\" and \"the effect upon the potential market for the copyrighted work\".Website owners who do not wish to have their content scraped can indicate it in a \"robots.txt\" file.In 2023, leading authors (includingJohn GrishamandJonathan Franzen) sued AI companies for using their work to train generative AI.Another discussed approach is to envision a separatesui generissystem of protection for creations generated by AI to ensure fair attribution and compensation for human authors. The commercial AI scene is dominated byBig Techcompanies such asAlphabet Inc.,Amazon,Apple Inc.,Meta Platforms, andMicrosoft.Some of these players already own the vast majority of existingcloud infrastructureandcomputingpower fromdata centers, allowing them to entrench further in the marketplace. In January 2024, theInternational Energy Agency(IEA) releasedElectricity 2024, Analysis and Forecast to 2026, forecasting electric power use.This is the first IEA report to make projections for data centers and power consumption for artificial intelligence and cryptocurrency. The report states that power demand for these uses might double by 2026, with additional electric power usage equal to electricity used by the whole Japanese nation. Prodigious power consumption by AI is responsible for the growth of fossil fuel use, and might delay closings of obsolete, carbon-emitting coal energy facilities. There is a feverish rise in the construction of data centers throughout the US, making large technology firms (e.g., Microsoft, Meta, Google, Amazon) into voracious consumers of electric power. Projected electric consumption is so immense that there is concern that it will be fulfilled no matter the source. A ChatGPT search involves the use of 10 times the electrical energy as a Google search. The large firms are in haste to find power sources – from nuclear energy to geothermal to fusion. The tech firms argue that – in the long view – AI will be eventually kinder to the environment, but they need the energy now. AI makes the power grid more efficient and \"intelligent\", will assist in the growth of nuclear power, and track overall carbon emissions, according to technology firms. A 2024Goldman SachsResearch Paper,AI Data Centers and the Coming US Power Demand Surge, found \"US power demand (is) likely to experience growth not seen in a generation....\" and forecasts that, by 2030, US data centers will consume 8% of US power, as opposed to 3% in 2022, presaging growth for the electrical power generation industry by a variety of means.Data centers' need for more and more electrical power is such that they might max out the electrical grid. The Big Tech companies counter that AI can be used to maximize the utilization of the grid by all. In 2024, theWall Street Journalreported that big AI companies have begun negotiations with the US nuclear power providers to provide electricity to the data centers. In March 2024 Amazon purchased a Pennsylvania nuclear-powered data center for US$650 million.NvidiaCEOJensen Huangsaid nuclear power is a good option for the data centers. In September 2024,Microsoftannounced an agreement withConstellation Energyto re-open theThree Mile Islandnuclear power plant to provide Microsoft with 100% of all electric power produced by the plant for 20 years. Reopening the plant, which suffered a partial nuclear meltdown of its Unit 2 reactor in 1979, will require Constellation to get through strict regulatory processes which will include extensive safety scrutiny from the USNuclear Regulatory Commission. If approved (this will be the first ever US re-commissioning of a nuclear plant), over 835 megawatts of power – enough for 800,000 homes – of energy will be produced. The cost for re-opening and upgrading is estimated at US$1.6 billion and is dependent on tax breaks for nuclear power contained in the 2022 USInflation Reduction Act.The US government and the state of Michigan are investing almost US$2 billion to reopen thePalisades Nuclearreactor on Lake Michigan. Closed since 2022, the plant is planned to be reopened in October 2025. The Three Mile Island facility will be renamed the Crane Clean Energy Center after Chris Crane, a nuclear proponent and former CEO ofExelonwho was responsible for Exelon's spinoff of Constellation. After the last approval in September 2023,Taiwansuspended the approval of data centers north ofTaoyuanwith a capacity of more than 5 MW in 2024, due to power supply shortages.Taiwan aims tophase out nuclear powerby 2025.On the other hand,Singaporeimposed a ban on the opening of data centers in 2019 due to electric power, but in 2022, lifted this ban. Although most nuclear plants in Japan have been shut down after the 2011Fukushima nuclear accident, according to an October 2024Bloombergarticle in Japanese, cloud gaming services company Ubitus, in which Nvidia has a stake, is looking for land in Japan near a nuclear power plant for a new data center for generative AI.Ubitus CEO Wesley Kuo said nuclear power plants are the most efficient, cheap and stable power for AI. On 1 November 2024, theFederal Energy Regulatory Commission(FERC) rejected an application submitted byTalen Energyfor approval to supply some electricity from the nuclear power stationSusquehannato Amazon's data center.According to the Commission ChairmanWillie L. Phillips, it is a burden on the electricity grid as well as a significant cost shifting concern to households and other business sectors. In 2025, a report prepared by the International Energy Agency estimated thegreenhouse gas emissionsfrom the energy consumption of AI at 180 million tons. By 2035, these emissions could rise to 300–500 million tonnes depending on what measures will be taken. This is below 1.5% of the energy sector emissions. The emissions reduction potential of AI was estimated at 5% of the energy sector emissions, butrebound effects(for example if people switch from public transport to autonomous cars) can reduce it. YouTube,Facebookand others userecommender systemsto guide users to more content. These AI programs were given the goal ofmaximizinguser engagement (that is, the only goal was to keep people watching). The AI learned that users tended to choosemisinformation,conspiracy theories, and extremepartisancontent, and, to keep them watching, the AI recommended more of it. Users also tended to watch more content on the same subject, so the AI led people intofilter bubbleswhere they received multiple versions of the same misinformation.This convinced many users that the misinformation was true, and ultimately undermined trust in institutions, the media and the government.The AI program had correctly learned to maximize its goal, but the result was harmful to society. After the U.S. election in 2016, major technology companies took some steps to mitigate the problem. In the early 2020s,generative AIbegan to create images, audio, and texts that are virtually indistinguishable from real photographs, recordings, or human writing,while realistic AI-generated videos became feasible in the mid-2020s.It is possible for bad actors to use this technology to create massive amounts of misinformation or propaganda;one such potential malicious use is deepfakes forcomputational propaganda.AI pioneerGeoffrey Hintonexpressed concern about AI enabling \"authoritarian leaders to manipulate their electorates\" on a large scale, among other risks. AI researchers atMicrosoft,OpenAI, universities and other organisations have suggested using \"personhood credentials\" as a way to overcome online deception enabled by AI models. Machine learning applications will bebiasedif they learn from biased data.The developers may not be aware that the bias exists.Bias can be introduced by the waytraining datais selected and by the way a model is deployed.If a biased algorithm is used to make decisions that can seriouslyharmpeople (as it can inmedicine,finance,recruitment,housingorpolicing) then the algorithm may causediscrimination.The field offairnessstudies how to prevent harms from algorithmic biases. On June 28, 2015,Google Photos's new image labeling feature mistakenly identified Jacky Alcine and a friend as \"gorillas\" because they were black. The system was trained on a dataset that contained very few images of black people,a problem called \"sample size disparity\".Google \"fixed\" this problem by preventing the system from labellinganythingas a \"gorilla\". Eight years later, in 2023, Google Photos still could not identify a gorilla, and neither could similar products from Apple, Facebook, Microsoft and Amazon. COMPASis a commercial program widely used byU.S. courtsto assess the likelihood of adefendantbecoming arecidivist. In 2016,Julia AngwinatProPublicadiscovered that COMPAS exhibited racial bias, despite the fact that the program was not told the races of the defendants. Although the error rate for both whites and blacks was calibrated equal at exactly 61%, the errors for each race were different—the system consistently overestimated the chance that a black person would re-offend and would underestimate the chance that a white person would not re-offend.In 2017, several researchersshowed that it was mathematically impossible for COMPAS to accommodate all possible measures of fairness when the base rates of re-offense were different for whites and blacks in the data. A program can make biased decisions even if the data does not explicitly mention a problematic feature (such as \"race\" or \"gender\"). The feature will correlate with other features (like \"address\", \"shopping history\" or \"first name\"), and the program will make the same decisions based on these features as it would on \"race\" or \"gender\".Moritz Hardt said \"the most robust fact in this research area is that fairness through blindness doesn't work.\" Criticism of COMPAS highlighted that machine learning models are designed to make \"predictions\" that are only valid if we assume that the future will resemble the past. If they are trained on data that includes the results of racist decisions in the past, machine learning models must predict that racist decisions will be made in the future. If an application then uses these predictions asrecommendations, some of these \"recommendations\" will likely be racist.Thus, machine learning is not well suited to help make decisions in areas where there is hope that the future will bebetterthan the past. It is descriptive rather than prescriptive. Bias and unfairness may go undetected because the developers are overwhelmingly white and male: among AI engineers, about 4% are black and 20% are women. There are various conflicting definitions and mathematical models of fairness. These notions depend on ethical assumptions, and are influenced by beliefs about society. One broad category isdistributive fairness, which focuses on the outcomes, often identifying groups and seeking to compensate for statistical disparities. Representational fairness tries to ensure that AI systems do not reinforce negativestereotypesor render certain groups invisible. Procedural fairness focuses on the decision process rather than the outcome. The most relevant notions of fairness may depend on the context, notably the type of AI application and the stakeholders. The subjectivity in the notions of bias and fairness makes it difficult for companies to operationalize them. Having access to sensitive attributes such as race or gender is also considered by many AI ethicists to be necessary in order to compensate for biases, but it may conflict withanti-discrimination laws. At its 2022Conference on Fairness, Accountability, and Transparency(ACM FAccT 2022), theAssociation for Computing Machinery, in Seoul, South Korea, presented and published findings that recommend that until AI and robotics systems are demonstrated to be free of bias mistakes, they are unsafe, and the use of self-learning neural networks trained on vast, unregulated sources of flawed internet data should be curtailed. Many AI systems are so complex that their designers cannot explain how they reach their decisions.Particularly withdeep neural networks, in which there are many non-linearrelationships between inputs and outputs. But some popular explainability techniques exist. It is impossible to be certain that a program is operating correctly if no one knows how exactly it works. There have been many cases where a machine learning program passed rigorous tests, but nevertheless learned something different than what the programmers intended. For example, a system that could identify skin diseases better than medical professionals was found to actually have a strong tendency to classify images with aruleras \"cancerous\", because pictures of malignancies typically include a ruler to show the scale.Another machine learning system designed to help effectively allocate medical resources was found to classify patients with asthma as being at \"low risk\" of dying from pneumonia. Having asthma is actually a severe risk factor, but since the patients having asthma would usually get much more medical care, they were relatively unlikely to die according to the training data. The correlation between asthma and low risk of dying from pneumonia was real, but misleading. People who have been harmed by an algorithm's decision have a right to an explanation.Doctors, for example, are expected to clearly and completely explain to their colleagues the reasoning behind any decision they make. Early drafts of the European Union'sGeneral Data Protection Regulationin 2016 included an explicit statement that this right exists.Industry experts noted that this is an unsolved problem with no solution in sight. Regulators argued that nevertheless the harm is real: if the problem has no solution, the tools should not be used. DARPAestablished theXAI(\"Explainable Artificial Intelligence\") program in 2014 to try to solve these problems. Several approaches aim to address the transparency problem. SHAP enables to visualise the contribution of each feature to the output.LIME can locally approximate a model's outputs with a simpler, interpretable model.Multitask learningprovides a large number of outputs in addition to the target classification. These other outputs can help developers deduce what the network has learned.Deconvolution,DeepDreamand othergenerativemethods can allow developers to see what different layers of a deep network for computer vision have learned, and produce output that can suggest what the network is learning.Forgenerative pre-trained transformers,Anthropicdeveloped a technique based ondictionary learningthat associates patterns of neuron activations with human-understandable concepts. Artificial intelligence provides a number of tools that are useful tobad actors, such asauthoritarian governments,terrorists,criminalsorrogue states. A lethal autonomous weapon is a machine that locates, selects and engages human targets without human supervision.Widely available AI tools can be used by bad actors to develop inexpensive autonomous weapons and, if produced at scale, they are potentiallyweapons of mass destruction.Even when used in conventional warfare, they currently cannot reliably choose targets and could potentiallykill an innocent person.In 2014, 30 nations (including China) supported a ban on autonomous weapons under theUnited Nations'Convention on Certain Conventional Weapons, however theUnited Statesand others disagreed.By 2015, over fifty countries were reported to be researching battlefield robots. AI tools make it easier forauthoritarian governmentsto efficiently control their citizens in several ways.Faceandvoice recognitionallow widespreadsurveillance.Machine learning, operating this data, canclassifypotential enemies of the state and prevent them from hiding.Recommendation systemscan precisely targetpropagandaandmisinformationfor maximum effect.Deepfakesandgenerative AIaid in producing misinformation. Advanced AI can make authoritariancentralized decision-makingmore competitive than liberal and decentralized systems such asmarkets. It lowers the cost and difficulty ofdigital warfareandadvanced spyware.All these technologies have been available since 2020 or earlier—AIfacial recognition systemsare already being used formass surveillancein China. There are many other ways in which AI is expected to help bad actors, some of which can not be foreseen. For example, machine-learning AI is able to design tens of thousands of toxic molecules in a matter of hours. Economists have frequently highlighted the risks of redundancies from AI, and speculated about unemployment if there is no adequate social policy for full employment. In the past, technology has tended to increase rather than reduce total employment, but economists acknowledge that \"we're in uncharted territory\" with AI.A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-termunemployment, but they generally agree that it could be a net benefit ifproductivitygains areredistributed.Risk estimates vary; for example, in the 2010s, Michael Osborne andCarl Benedikt Freyestimated 47% of U.S. jobs are at \"high risk\" of potential automation, while an OECD report classified only 9% of U.S. jobs as \"high risk\".The methodology of speculating about future employment levels has been criticised as lacking evidential foundation, and for implying that technology, rather than social policy, creates unemployment, as opposed to redundancies.In April 2023, it was reported that 70% of the jobs for Chinese video game illustrators had been eliminated by generative artificial intelligence. Unlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence;The Economiststated in 2015 that \"the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution\" is \"worth taking seriously\".Jobs at extreme risk range fromparalegalsto fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy. From the early days of the development of artificial intelligence, there have been arguments, for example, those put forward byJoseph Weizenbaum, about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculation and qualitative, value-based judgement. It has been argued AI will become so powerful that humanity may irreversibly lose control of it. This could, as physicistStephen Hawkingstated, \"spell the end of the human race\".This scenario has been common in science fiction, when a computer or robot suddenly develops a human-like \"self-awareness\" (or \"sentience\" or \"consciousness\") and becomes a malevolent character.These sci-fi scenarios are misleading in several ways. First, AI does not require human-likesentienceto be an existential risk. Modern AI programs are given specific goals and use learning and intelligence to achieve them. PhilosopherNick Bostromargued that if one givesalmost anygoal to a sufficiently powerful AI, it may choose to destroy humanity to achieve it (he used the example of apaperclip maximizer).Stuart Russellgives the example of household robot that tries to find a way to kill its owner to prevent it from being unplugged, reasoning that \"you can't fetch the coffee if you're dead.\"In order to be safe for humanity, asuperintelligencewould have to be genuinelyalignedwith humanity's morality and values so that it is \"fundamentally on our side\". Second,Yuval Noah Harariargues that AI does not require a robot body or physical control to pose an existential risk. The essential parts of civilization are not physical. Things likeideologies,law,government,moneyand theeconomyare built onlanguage; they exist because there are stories that billions of people believe. The current prevalence ofmisinformationsuggests that an AI could use language to convince people to believe anything, even to take actions that are destructive. The opinions amongst experts and industry insiders are mixed, with sizable fractions both concerned and unconcerned by risk from eventual superintelligent AI.Personalities such asStephen Hawking,Bill Gates, andElon Musk,as well as AI pioneers such asYoshua Bengio,Stuart Russell,Demis Hassabis, andSam Altman, have expressed concerns about existential risk from AI. In May 2023,Geoffrey Hintonannounced his resignation from Google in order to be able to \"freely speak out about the risks of AI\" without \"considering how this impacts Google\".He notably mentioned risks of anAI takeover,and stressed that in order to avoid the worst outcomes, establishing safety guidelines will require cooperation among those competing in use of AI. In 2023, many leading AI experts endorsedthe joint statementthat \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war\". Some other researchers were more optimistic. AI pioneerJürgen Schmidhuberdid not sign the joint statement, emphasising that in 95% of all cases, AI research is about making \"human lives longer and healthier and easier.\"While the tools that are now being used to improve lives can also be used by bad actors, \"they can also be used against the bad actors.\"Andrew Ngalso argued that \"it's a mistake to fall for the doomsday hype on AI—and that regulators who do will only benefit vested interests.\"Yann LeCun\"scoffs at his peers' dystopian scenarios of supercharged misinformation and even, eventually, human extinction.\"In the early 2010s, experts argued that the risks are too distant in the future to warrant research or that humans will be valuable from the perspective of a superintelligent machine.However, after 2016, the study of current and future risks and possible solutions became a serious area of research. Friendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans.Eliezer Yudkowsky, who coined the term, argues that developing friendly AI should be a higher research priority: it may require a large investment and it must be completed before AI becomes an existential risk. Machines with intelligence have the potential to use their intelligence to make ethical decisions. The field of machine ethics provides machines with ethical principles and procedures for resolving ethical dilemmas.The field of machine ethics is also called computational morality,and was founded at anAAAIsymposium in 2005. Other approaches includeWendell Wallach's \"artificial moral agents\"andStuart J. Russell'sthree principlesfor developing provably beneficial machines. Active organizations in the AI open-source community includeHugging Face,Google,EleutherAIandMeta.Various AI models, such asLlama 2,MistralorStable Diffusion, have been made open-weight,meaning that their architecture and trained parameters (the \"weights\") are publicly available. Open-weight models can be freelyfine-tuned, which allows companies to specialize them with their own data and for their own use-case.Open-weight models are useful for research and innovation but can also be misused. Since they can be fine-tuned, any built-in security measure, such as objecting to harmful requests, can be trained away until it becomes ineffective. Some researchers warn that future AI models may develop dangerous capabilities (such as the potential to drastically facilitatebioterrorism) and that once released on the Internet, they cannot be deleted everywhere if needed. They recommend pre-release audits and cost-benefit analyses. Artificial intelligence projects can be guided by ethical considerations during the design, development, and implementation of an AI system. An AI framework such as the Care and Act Framework, developed by theAlan Turing Instituteand based on the SUM values, outlines four main ethical dimensions, defined as follows: Other developments in ethical frameworks include those decided upon during theAsilomar Conference, the Montreal Declaration for Responsible AI, and the IEEE's Ethics of Autonomous Systems initiative, among others;however, these principles are not without criticism, especially regarding the people chosen to contribute to these frameworks. Promotion of the wellbeing of the people and communities that these technologies affect requires consideration of the social and ethical implications at all stages of AI system design, development and implementation, and collaboration between job roles such as data scientists, product managers, data engineers, domain experts, and delivery managers. TheUK AI Safety Institutereleased in 2024 a testing toolset called 'Inspect' for AI safety evaluations available under an MIT open-source licence which is freely available on GitHub and can be improved with third-party packages. It can be used to evaluate AI models in a range of areas including core knowledge, ability to reason, and autonomous capabilities. The regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating AI; it is therefore related to the broader regulation of algorithms.The regulatory and policy landscape for AI is an emerging issue in jurisdictions globally.According to AI Index atStanford, the annual number of AI-related laws passed in the 127 survey countries jumped from one passed in 2016 to 37 passed in 2022 alone.Between 2016 and 2020, more than 30 countries adopted dedicated strategies for AI.Most EU member states had released national AI strategies, as hadCanada, China, India, Japan, Mauritius, the Russian Federation, Saudi Arabia, United Arab Emirates, U.S., and Vietnam. Others were in the process of elaborating their own AI strategy, including Bangladesh, Malaysia and Tunisia.TheGlobal Partnership on Artificial Intelligencewas launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology.Henry Kissinger,Eric Schmidt, andDaniel Huttenlocherpublished a joint statement in November 2021 calling for a government commission to regulate AI.In 2023, OpenAI leaders published recommendations for the governance of superintelligence, which they believe may happen in less than 10 years.In 2023, the United Nations also launched an advisory body to provide recommendations on AI governance; the body comprises technology company executives, government officials and academics.On 1 August 2024, the EUArtificial Intelligence Actentered into force, establishing the first comprehensive EU-wide AI regulation.In 2024, theCouncil of Europecreated the first international legally binding treaty on AI, called the \"Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law\". It was adopted by the European Union, the United States, the United Kingdom, and other signatories. In a 2022Ipsossurvey, attitudes towards AI varied greatly by country; 78% of Chinese citizens, but only 35% of Americans, agreed that \"products and services using AI have more benefits than drawbacks\".A 2023Reuters/Ipsos poll found that 61% of Americans agree, and 22% disagree, that AI poses risks to humanity.In a 2023Fox Newspoll, 35% of Americans thought it \"very important\", and an additional 41% thought it \"somewhat important\", for the federal government to regulate AI, versus 13% responding \"not very important\" and 8% responding \"not at all important\". In November 2023, the first globalAI Safety Summitwas held inBletchley Parkin the UK to discuss the near and far term risks of AI and the possibility of mandatory and voluntary regulatory frameworks.28 countries including the United States, China, and the European Union issued a declaration at the start of the summit, calling for international co-operation to manage the challenges and risks of artificial intelligence.In May 2024 at theAI Seoul Summit, 16 global AI tech companies agreed to safety commitments on the development of AI. The study of mechanical or \"formal\" reasoning began with philosophers and mathematicians in antiquity. The study of logic led directly toAlan Turing'stheory of computation, which suggested that a machine, by shuffling symbols as simple as \"0\" and \"1\", could simulate any conceivable form of mathematical reasoning.This, along with concurrent discoveries incybernetics,information theoryandneurobiology, led researchers to consider the possibility of building an \"electronic brain\".They developed several areas of research that would become part of AI,such asMcCullochandPittsdesign for \"artificial neurons\" in 1943,and Turing's influential 1950 paper 'Computing Machinery and Intelligence', which introduced theTuring testand showed that \"machine intelligence\" was plausible. The field of AI research was founded ata workshopatDartmouth Collegein 1956.The attendees became the leaders of AI research in the 1960s.They and their students produced programs that the press described as \"astonishing\":computers were learningcheckersstrategies, solving word problems in algebra, provinglogical theoremsand speaking English.Artificial intelligence laboratories were set up at a number of British and U.S. universities in the latter 1950s and early 1960s. Researchers in the 1960s and the 1970s were convinced that their methods would eventually succeed in creating a machine withgeneral intelligenceand considered this the goal of their field.In 1965Herbert Simonpredicted, \"machines will be capable, within twenty years, of doing any work a man can do\".In 1967Marvin Minskyagreed, writing that \"within a generation ... the problem of creating 'artificial intelligence' will substantially be solved\".They had, however, underestimated the difficulty of the problem.In 1974, both the U.S. and British governments cut off exploratory research in response to thecriticismofSir James Lighthilland ongoing pressure from the U.S. Congress tofund more productive projects.MinskyandPapert's bookPerceptronswas understood as proving thatartificial neural networkswould never be useful for solving real-world tasks, thus discrediting the approach altogether.The \"AI winter\", a period when obtaining funding for AI projects was difficult, followed. In the early 1980s, AI research was revived by the commercial success ofexpert systems,a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan'sfifth generation computerproject inspired the U.S. and British governments to restore funding foracademic research.However, beginning with the collapse of theLisp Machinemarket in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began. Up to this point, most of AI's funding had gone to projects that used high-levelsymbolsto representmental objectslike plans, goals, beliefs, and known facts. In the 1980s, some researchers began to doubt that this approach would be able to imitate all the processes of human cognition, especiallyperception,robotics,learningandpattern recognition,and began to look into \"sub-symbolic\" approaches.Rodney Brooksrejected \"representation\" in general and focussed directly on engineering machines that move and survive.Judea Pearl,Lotfi Zadeh, and others developed methods that handled incomplete and uncertain information by making reasonable guesses rather than precise logic.But the most important development was the revival of \"connectionism\", including neural network research, byGeoffrey Hintonand others.In 1990,Yann LeCunsuccessfully showed thatconvolutional neural networkscan recognize handwritten digits, the first of many successful applications of neural networks. AI gradually restored its reputation in the late 1990s and early 21st century by exploiting formal mathematical methods and by finding specific solutions to specific problems. This \"narrow\" and \"formal\" focus allowed researchers to produce verifiable results and collaborate with other fields (such asstatistics,economicsandmathematics).By 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as \"artificial intelligence\" (a tendency known as theAI effect).However, several academic researchers became concerned that AI was no longer pursuing its original goal of creating versatile, fully intelligent machines. Beginning around 2002, they founded the subfield ofartificial general intelligence(or \"AGI\"), which had several well-funded institutions by the 2010s. Deep learningbegan to dominate industry benchmarks in 2012 and was adopted throughout the field.For many specific tasks, other methods were abandoned.Deep learning's success was based on both hardware improvements (faster computers,graphics processing units,cloud computing) and access tolarge amounts of data(including curated datasets,such asImageNet). Deep learning's success led to an enormous increase in interest and funding in AI.The amount of machine learning research (measured by total publications) increased by 50% in the years 2015–2019. In 2016, issues offairnessand the misuse of technology were catapulted into center stage at machine learning conferences, publications vastly increased, funding became available, and many researchers re-focussed their careers on these issues. Thealignment problembecame a serious field of academic study. In the late 2010s and early 2020s, AGI companies began to deliver programs that created enormous interest. In 2015,AlphaGo, developed byDeepMind, beat the world championGo player. The program taught only the game's rules and developed a strategy by itself.GPT-3is alarge language modelthat was released in 2020 byOpenAIand is capable of generating high-quality human-like text.ChatGPT, launched on November 30, 2022, became the fastest-growing consumer software application in history, gaining over 100 million users in two months.It marked what is widely regarded as AI's breakout year, bringing it into the public consciousness.These programs, and others, inspired an aggressiveAI boom, where large companies began investing billions of dollars in AI research. According to AI Impacts, about US$50 billion annually was invested in \"AI\" around 2022 in the U.S. alone and about 20% of the new U.S. Computer Science PhD graduates have specialized in \"AI\".About 800,000 \"AI\"-related U.S. job openings existed in 2022.According to PitchBook research, 22% of newly fundedstartupsin 2024 claimed to be AI companies. Philosophical debates have historically sought to determine the nature of intelligence and how to make intelligent machines.Another major focus has been whether machines can be conscious, and the associated ethical implications.Many other topics in philosophy are relevant to AI, such asepistemologyandfree will.Rapid advancements have intensified public discussions on the philosophy andethics of AI. Alan Turingwrote in 1950 \"I propose to consider the question 'can machines think'?\"He advised changing the question from whether a machine \"thinks\", to \"whether or not it is possible for machinery to show intelligent behaviour\".He devised theTuring test, which measures the ability of a machine to simulate human conversation.Since we can only observe the behavior of the machine, it does not matter if it is \"actually\" thinking or literally has a \"mind\". Turing notes thatwe can not determine these things about other peoplebut \"it is usual to have a polite convention that everyone thinks.\" RussellandNorvigagree with Turing that intelligence must be defined in terms of external behavior, not internal structure.However, they are critical that the test requires the machine to imitate humans. \"Aeronautical engineeringtexts\", they wrote, \"do not define the goal of their field as making 'machines that fly so exactly likepigeonsthat they can fool other pigeons.'\"AI founderJohn McCarthyagreed, writing that \"Artificial intelligence is not, by definition, simulation of human intelligence\". McCarthy defines intelligence as \"the computational part of the ability to achieve goals in the world\".Another AI founder,Marvin Minsky, similarly describes it as \"the ability to solve hard problems\".The leading AI textbook defines it as the study of agents that perceive their environment and take actions that maximize their chances of achieving defined goals.These definitions view intelligence in terms of well-defined problems with well-defined solutions, where both the difficulty of the problem and the performance of the program are direct measures of the \"intelligence\" of the machine—and no other philosophical discussion is required, or may not even be possible. Another definition has been adopted by Google,a major practitioner in the field of AI. This definition stipulates the ability of systems to synthesize information as the manifestation of intelligence, similar to the way it is defined in biological intelligence. As a result of the many circulating definitions scholars have started to critically analyze and order the AI discourse itselfincluding discussing the many AI narratives and myths to be found within societal, political and academic discourses.Similarly, in practice, some authors have suggested that the term 'AI' is often used too broadly and vaguely. This raises the question of where the line should be drawn between AI and classical algorithms,with many companies during the early 2020s AI boom using the term as a marketingbuzzword, often even if they did \"not actually use AI in a material way\". There has been debate over whetherlarge language modelsexhibit genuine intelligence or merely simulate it byimitating human text. No established unifying theory orparadigmhas guided AI research for most of its history.The unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term \"artificial intelligence\" to mean \"machine learning with neural networks\"). This approach is mostlysub-symbolic,softandnarrow. Critics argue that these questions may have to be revisited by future generations of AI researchers. Symbolic AI(or \"GOFAI\")simulated the high-level conscious reasoning that people use when they solve puzzles, express legal reasoning and do mathematics. They were highly successful at \"intelligent\" tasks such as algebra or IQ tests. In the 1960s, Newell and Simon proposed thephysical symbol systems hypothesis: \"A physical symbol system has the necessary and sufficient means of general intelligent action.\" However, the symbolic approach failed on many tasks that humans solve easily, such as learning, recognizing an object orcommonsense reasoning.Moravec's paradoxis the discovery that high-level \"intelligent\" tasks were easy for AI, but low level \"instinctive\" tasks were extremely difficult.PhilosopherHubert Dreyfushadarguedsince the 1960s that human expertise depends on unconscious instinct rather than conscious symbol manipulation, and on having a \"feel\" for the situation, rather than explicit symbolic knowledge.Although his arguments had been ridiculed and ignored when they were first presented, eventually, AI research came to agree with him. The issue is not resolved:sub-symbolicreasoning can make many of the same inscrutable mistakes that human intuition does, such asalgorithmic bias. Critics such asNoam Chomskyargue continuing research into symbolic AI will still be necessary to attain general intelligence,in part because sub-symbolic AI is a move away fromexplainable AI: it can be difficult or impossible to understand why a modern statistical AI program made a particular decision. The emerging field ofneuro-symbolic artificial intelligenceattempts to bridge the two approaches. \"Neats\" hope that intelligent behavior is described using simple, elegant principles (such aslogic,optimization, orneural networks). \"Scruffies\" expect that it necessarily requires solving a large number of unrelated problems. Neats defend their programs with theoretical rigor, scruffies rely mainly on incremental testing to see if they work. This issue was actively discussed in the 1970s and 1980s,but eventually was seen as irrelevant. Modern AI has elements of both. Finding a provably correct or optimal solution isintractablefor many important problems.Soft computing is a set of techniques, includinggenetic algorithms,fuzzy logicand neural networks, that are tolerant of imprecision, uncertainty, partial truth and approximation. Soft computing was introduced in the late 1980s and most successful AI programs in the 21st century are examples of soft computing with neural networks. AI researchers are divided as to whether to pursue the goals of artificial general intelligence andsuperintelligencedirectly or to solve as many specific problems as possible (narrow AI) in hopes these solutions will lead indirectly to the field's long-term goals.General intelligence is difficult to define and difficult to measure, and modern AI has had more verifiable successes by focusing on specific problems with specific solutions. The sub-field of artificial general intelligence studies this area exclusively. There is no settled consensus inphilosophy of mindon whether a machine can have amind,consciousnessandmental statesin the same sense that human beings do. This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant because it does not affect the goals of the field: to build machines that can solve problems using intelligence.RussellandNorvigadd that \"[t]he additional project of making a machine conscious in exactly the way humans are is not one that we are equipped to take on.\"However, the question has become central to the philosophy of mind. It is also typically the central question at issue inartificial intelligence in fiction. David Chalmersidentified two problems in understanding the mind, which he named the \"hard\" and \"easy\" problems of consciousness.The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how thisfeelsor why it should feel like anything at all, assuming we are right in thinking that it truly does feel like something (Dennett's consciousness illusionism says this is an illusion). While humaninformation processingis easy to explain, humansubjective experienceis difficult to explain. For example, it is easy to imagine a color-blind person who has learned to identify which objects in their field of view are red, but it is not clear what would be required for the person toknow what red looks like. Computationalism is the position in thephilosophy of mindthat the human mind is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to themind–body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophersJerry FodorandHilary Putnam. PhilosopherJohn Searlecharacterized this position as \"strong AI\": \"The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.\"Searle challenges this claim with hisChinese roomargument, which attempts to show that even a computer capable of perfectly simulating human behavior would not have a mind. It is difficult or impossible to reliably evaluate whether an advancedAI is sentient(has the ability to feel), and if so, to what degree.But if there is a significant chance that a given machine can feel and suffer, then it may be entitled to certain rights or welfare protection measures, similarly to animals.Sapience(a set of capacities related to high intelligence, such as discernment orself-awareness) may provide another moral basis for AI rights.Robot rightsare also sometimes proposed as a practical way to integrate autonomous agents into society. In 2017, the European Union considered granting \"electronic personhood\" to some of the most capable AI systems. Similarly to the legal status of companies, it would have conferred rights but also responsibilities.Critics argued in 2018 that granting rights to AI systems would downplay the importance ofhuman rights, and that legislation should focus on user needs rather than speculative futuristic scenarios. They also noted that robots lacked the autonomy to take part in society on their own. Progress in AI increased interest in the topic. Proponents of AI welfare and rights often argue that AI sentience, if it emerges, would be particularly easy to deny. They warn that this may be amoral blind spotanalogous toslaveryorfactory farming, which could lead tolarge-scale sufferingif sentient AI is created and carelessly exploited. Asuperintelligenceis a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind.If research intoartificial general intelligenceproduced sufficiently intelligent software, it might be able toreprogram and improve itself. The improved software would be even better at improving itself, leading to whatI. J. Goodcalled an \"intelligence explosion\" andVernor Vingecalled a \"singularity\". However, technologies cannot improve exponentially indefinitely, and typically follow anS-shaped curve, slowing when they reach the physical limits of what the technology can do. Robot designerHans Moravec, cyberneticistKevin Warwickand inventorRay Kurzweilhave predicted that humans and machines may merge in the future intocyborgsthat are more capable and powerful than either. This idea, called transhumanism, has roots in the writings ofAldous HuxleyandRobert Ettinger. Edward Fredkinargues that \"artificial intelligence is the next step in evolution\", an idea first proposed bySamuel Butler's \"Darwin among the Machines\" as far back as 1863, and expanded upon byGeorge Dysonin his 1998 bookDarwin Among the Machines: The Evolution of Global Intelligence. Thought-capable artificial beings have appeared as storytelling devices since antiquity,and have been a persistent theme inscience fiction. A commontropein these works began withMary Shelley'sFrankenstein, where a human creation becomes a threat to its masters. This includes such works asArthur C. Clarke'sandStanley Kubrick's2001: A Space Odyssey(both 1968), withHAL 9000, the murderous computer in charge of theDiscovery Onespaceship, as well asThe Terminator(1984) andThe Matrix(1999). In contrast, the rare loyal robots such as Gort fromThe Day the Earth Stood Still(1951) and Bishop fromAliens(1986) are less prominent in popular culture. Isaac Asimovintroduced theThree Laws of Roboticsin many stories, most notably with the \"Multivac\" super-intelligent computer. Asimov's laws are often brought up during lay discussions of machine ethics;while almost all artificial intelligence researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity. Several works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that havethe ability to feel, and thus to suffer. This appears inKarel Čapek'sR.U.R., the filmsA.I. Artificial IntelligenceandEx Machina, as well as the novelDo Androids Dream of Electric Sheep?, byPhilip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence. The two most widely used textbooks in 2023 (see theOpen Syllabus): The four most widely used AI textbooks in 2008: Other textbooks:", "combined_text": "Artificial intelligence Contents Goals Reasoning and problem-solving Knowledge representation Planning and decision-making Learning Natural language processing Perception Social intelligence General intelligence Techniques Search and optimization Logic Probabilistic methods for uncertain reasoning Classifiers and statistical learning methods Artificial neural networks Deep learning GPT Hardware and software Applications Health and medicine Games Mathematics Finance Military Generative AI Agents Web search Sexuality Other industry-specific tasks Ethics Risks and harm Ethical machines and alignment Open source Frameworks Regulation History Philosophy Defining artificial intelligence Evaluating approaches to AI Machine consciousness, sentience, and mind Future Superintelligence and the singularity Transhumanism In fiction See also Explanatory notes References AI textbooks History of AI Other sources Further reading External links  Artificial intelligence(AI) is the capability ofcomputational systemsto perform tasks typically associated withhuman intelligence, such aslearning,reasoning,problem-solving,perception, anddecision-making. It is afield of researchincomputer sciencethat develops and studies methods andsoftwarethat enable machines toperceive their environmentand uselearningandintelligenceto take actions that maximize their chances of achieving defined goals. High-profileapplications of AIinclude advancedweb search engines(e.g.,Google Search);recommendation systems(used byYouTube,Amazon, andNetflix);virtual assistants(e.g.,Google Assistant,Siri, andAlexa);autonomous vehicles(e.g.,Waymo);generativeandcreativetools (e.g.,language modelsandAI art); andsuperhumanplay and analysis instrategy games(e.g.,chessandGo). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it'snot labeled AI anymore.\" Various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning,reasoning,knowledge representation,planning,natural language processing,perception, and support forrobotics.To reach these goals, AI researchers have adapted and integrated a wide range of techniques, includingsearchandmathematical optimization,formal logic,artificial neural networks, and methods based onstatistics,operations research, andeconomics.AI also draws uponpsychology,linguistics,philosophy,neuroscience, and other fields.Some companies, such asOpenAI,Google DeepMindandMeta,aim to createartificial general intelligence(AGI)—AI that can complete virtually any cognitive task at least as well as a human. Artificial intelligence was founded as an academic discipline in 1956,and the field went through multiple cycles of optimism throughoutits history,followed by periods of disappointment and loss of funding, known asAI winters.Funding and interest vastly increased after 2012 whengraphics processing unitsstarted being used to accelerate neural networks anddeep learningoutperformed previous AI techniques.This growth accelerated further after 2017 with thetransformer architecture.In the 2020s, an ongoing period of rapidprogressin advanced generative AI became known as theAI boom. Generative AI's ability to create and modify content has led to several unintended consequences and harms, which has raisedethical concernsaboutAI's long-term effectsandpotential existential risks, prompting discussions aboutregulatory policiesto ensurethe safetyand benefits of the technology. The general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research. Early researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logicaldeductions.By the late 1980s and 1990s, methods were developed for dealing withuncertainor incomplete information, employing concepts fromprobabilityandeconomics. Many of these algorithms are insufficient for solving large reasoning problems because they experience a \"combinatorial explosion\": They become exponentially slower as the problems grow.Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.Accurate and efficient reasoning is an unsolved problem. Knowledge representationandknowledge engineeringallow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval,scene interpretation,clinical decision support,knowledge discovery (mining \"interesting\" and actionable inferences from largedatabases),and other areas. Aknowledge baseis a body of knowledge represented in a form that can be used by a program. Anontologyis the set of objects, relations, concepts, and properties used by a particular domain of knowledge.Knowledge bases need to represent things such as objects, properties, categories, and relations between objects;situations, events, states, and time;causes and effects;knowledge about knowledge (what we know about what other people know);default reasoning(things that humans assume are true until they are told differently and will remain true even when other facts are changing);and many other aspects and domains of knowledge. Among the most difficult problems in knowledge representation are the breadth ofcommonsense knowledge(the set of atomic facts that the average person knows is enormous);and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as \"facts\" or \"statements\" that they could express verbally).There is also the difficulty ofknowledge acquisition, the problem of obtaining knowledge for AI applications. An \"agent\" is anything that perceives and takes actions in the world. Arational agenthas goals or preferences and takes actions to make them happen.Inautomated planning, the agent has a specific goal.Inautomated decision-making, the agent has preferences—there are some situations it would prefer to be in, and some situations it is trying to avoid. The decision-making agent assigns a number to each situation (called the \"utility\") that measures how much the agent prefers it. For each possible action, it can calculate the \"expected utility\": theutilityof all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility. Inclassical planning, the agent knows exactly what the effect of any action will be.In most real-world problems, however, the agent may not be certain about the situation they are in (it is \"unknown\" or \"unobservable\") and it may not know for certain what will happen after each possible action (it is not \"deterministic\"). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked. In some problems, the agent's preferences may be uncertain, especially if there are other agents or humans involved. These can be learned (e.g., withinverse reinforcement learning), or the agent can seek information to improve its preferences.Information value theorycan be used to weigh the value of exploratory or experimental actions.The space of possible future actions and situations is typicallyintractablylarge, so the agents must take actions and evaluate situations while being uncertain of what the outcome will be. AMarkov decision processhas atransition modelthat describes the probability that a particular action will change the state in a particular way and a reward function that supplies the utility of each state and the cost of each action. Apolicyassociates a decision with each possible state. The policy could be calculated (e.g., byiteration), beheuristic, or it can be learned. Game theorydescribes the rational behavior of multiple interacting agents and is used in AI programs that make decisions that involve other agents. Machine learningis the study of programs that can improve their performance on a given task automatically.It has been a part of AI from the beginning. There are several kinds of machine learning.Unsupervised learninganalyzes a stream of data and finds patterns and makes predictions without any other guidance.Supervised learningrequires labeling the training data with the expected answers, and comes in two main varieties:classification(where the program must learn to predict what category the input belongs in) andregression(where the program must deduce a numeric function based on numeric input). Inreinforcement learning, the agent is rewarded for good responses and punished for bad ones. The agent learns to choose responses that are classified as \"good\".Transfer learningis when the knowledge gained from one problem is applied to a new problem.Deep learningis a type of machine learning that runs inputs through biologically inspiredartificial neural networksfor all of these types of learning. Computational learning theorycan assess learners bycomputational complexity, bysample complexity(how much data is required), or by other notions ofoptimization. Natural language processing(NLP) allows programs to read, write and communicate in human languages.Specific problems includespeech recognition,speech synthesis,machine translation,information extraction,information retrievalandquestion answering. Early work, based onNoam Chomsky'sgenerative grammarandsemantic networks, had difficulty withword-sense disambiguationunless restricted to small domains called \"micro-worlds\" (due to thecommon sense knowledge problem).Margaret Mastermanbelieved that it was meaning and not grammar that was the key to understanding languages, and thatthesauriand not dictionaries should be the basis of computational language structure. Modern deep learning techniques for NLP includeword embedding(representing words, typically asvectorsencoding their meaning),transformers(a deep learning architecture using anattentionmechanism),and others.In 2019,generative pre-trained transformer(or \"GPT\") language models began to generate coherent text,and by 2023, these models were able to get human-level scores on thebar exam,SATtest,GREtest, and many other real-world applications. Machine perceptionis the ability to use input from sensors (such as cameras, microphones, wireless signals, activelidar, sonar, radar, andtactile sensors) to deduce aspects of the world.Computer visionis the ability to analyze visual input. The field includesspeech recognition,image classification,facial recognition,object recognition,object tracking,androbotic perception. Affective computingis a field that comprises systems that recognize, interpret, process, or simulate humanfeeling, emotion, and mood.For example, somevirtual assistantsare programmed to speak conversationally or even to banter humorously; it makes them appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitatehuman–computer interaction. However, this tends to give naïve users an unrealistic conception of the intelligence of existing computer agents.Moderate successes related to affective computing include textualsentiment analysisand, more recently,multimodal sentiment analysis, wherein AI classifies the effects displayed by a videotaped subject. A machine withartificial general intelligencewould be able to solve a wide variety of problems with breadth and versatility similar tohuman intelligence. AI research uses a wide variety of techniques to accomplish the goals above. AI can solve many problems by intelligently searching through many possible solutions.There are two very different kinds of search used in AI:state space searchandlocal search. State space searchsearches through a tree of possible states to try to find a goal state.For example,planningalgorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process calledmeans-ends analysis. Simple exhaustive searchesare rarely sufficient for most real-world problems: thesearch space(the number of places to search) quickly grows toastronomical numbers. The result is a search that istoo slowor never completes.\"Heuristics\" or \"rules of thumb\" can help prioritize choices that are more likely to reach a goal. Adversarial searchis used forgame-playingprograms, such as chess or Go. It searches through atreeof possible moves and countermoves, looking for a winning position. Local searchusesmathematical optimizationto find a solution to a problem. It begins with some form of guess and refines it incrementally. Gradient descentis a type of local search that optimizes a set of numerical parameters by incrementally adjusting them to minimize aloss function. Variants of gradient descent are commonly used to trainneural networks,through thebackpropagationalgorithm. Another type of local search isevolutionary computation, which aims to iteratively improve a set of candidate solutions by \"mutating\" and \"recombining\" them,selectingonly the fittest to survive each generation. Distributed search processes can coordinate viaswarm intelligencealgorithms. Two popular swarm algorithms used in search areparticle swarm optimization(inspired by birdflocking) andant colony optimization(inspired byant trails). Formallogicis used forreasoningandknowledge representation.Formal logic comes in two main forms:propositional logic(which operates on statements that are true or false and useslogical connectivessuch as \"and\", \"or\", \"not\" and \"implies\")andpredicate logic(which also operates on objects, predicates and relations and usesquantifierssuch as \"EveryXis aY\" and \"There aresomeXs that areYs\"). Deductive reasoningin logic is the process ofprovinga new statement (conclusion) from other statements that are given and assumed to be true (thepremises).Proofs can be structured as prooftrees, in which nodes are labelled by sentences, and children nodes are connected to parent nodes byinference rules. Given a problem and a set of premises, problem-solving reduces to searching for a proof tree whose root node is labelled by a solution of the problem and whoseleaf nodesare labelled by premises oraxioms. In the case ofHorn clauses, problem-solving search can be performed by reasoningforwardsfrom the premises orbackwardsfrom the problem.In the more general case of the clausal form offirst-order logic,resolutionis a single, axiom-free rule of inference, in which a problem is solved by proving a contradiction from premises that include the negation of the problem to be solved. Inference in both Horn clause logic and first-order logic isundecidable, and thereforeintractable. However, backward reasoning with Horn clauses, which underpins computation in thelogic programminglanguageProlog, isTuring complete. Moreover, its efficiency is competitive with computation in othersymbolic programminglanguages. Fuzzy logicassigns a \"degree of truth\" between 0 and 1. It can therefore handle propositions that are vague and partially true. Non-monotonic logics, including logic programming withnegation as failure, are designed to handledefault reasoning.Other specialized versions of logic have been developed to describe many complex domains. Many problems in AI (including reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of tools to solve these problems using methods fromprobabilitytheory and economics.Precise mathematical tools have been developed that analyze how an agent can make choices and plan, usingdecision theory,decision analysis,andinformation value theory.These tools include models such asMarkov decision processes,dynamicdecision networks,game theoryandmechanism design. Bayesian networksare a tool that can be used forreasoning(using theBayesian inferencealgorithm),learning(using theexpectation–maximization algorithm),planning(usingdecision networks)andperception(usingdynamic Bayesian networks). Probabilistic algorithms can also be used for filtering, prediction, smoothing, and finding explanations for streams of data, thus helping perception systems analyze processes that occur over time (e.g.,hidden Markov modelsorKalman filters). The simplest AI applications can be divided into two types: classifiers (e.g., \"if shiny then diamond\"), on one hand, and controllers (e.g., \"if diamond then pick up\"), on the other hand.Classifiersare functions that usepattern matchingto determine the closest match. They can be fine-tuned based on chosen examples usingsupervised learning. Each pattern (also called an \"observation\") is labeled with a certain predefined class. All the observations combined with their class labels are known as adata set. When a new observation is received, that observation is classified based on previous experience. There are many kinds of classifiers in use.Thedecision treeis the simplest and most widely used symbolic machine learning algorithm.K-nearest neighboralgorithm was the most widely used analogical AI until the mid-1990s, andKernel methodssuch as thesupport vector machine(SVM) displaced k-nearest neighbor in the 1990s.Thenaive Bayes classifieris reportedly the \"most widely used learner\"at Google, due in part to its scalability.Neural networksare also used as classifiers. An artificial neural network is based on a collection of nodes also known asartificial neurons, which loosely model theneuronsin a biological brain. It is trained to recognise patterns; once trained, it can recognise those patterns in fresh data. There is an input, at least one hidden layer of nodes and an output. Each node applies a function and once theweightcrosses its specified threshold, the data is transmitted to the next layer. A network is typically called a deep neural network if it has at least 2 hidden layers. Learning algorithms for neural networks uselocal searchto choose the weights that will get the right output for each input during training. The most common training technique is thebackpropagationalgorithm.Neural networks learn to model complex relationships between inputs and outputs andfind patternsin data. In theory, a neural network can learn any function. Infeedforward neural networksthe signal passes in only one direction.The termperceptrontypically refers to a single-layer neural network.In contrast, deep learning uses many layers.Recurrent neural networks(RNNs) feed the output signal back into the input, which allows short-term memories of previous input events.Long short-term memorynetworks (LSTMs) are recurrent neural networks that better preserve longterm dependencies and are less sensitive to thevanishing gradient problem.Convolutional neural networks(CNNs) use layers ofkernelsto more efficiently process local patterns. This local processing is especially important inimage processing, where the early CNN layers typically identify simple local patterns such as edges and curves, with subsequent layers detecting more complex patterns like textures, and eventually whole objects. Deep learninguses several layers of neurons between the network's inputs and outputs.The multiple layers can progressively extract higher-level features from the raw input. For example, inimage processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits, letters, or faces. Deep learning has profoundly improved the performance of programs in many important subfields of artificial intelligence, includingcomputer vision,speech recognition,natural language processing,image classification,and others. The reason that deep learning performs so well in so many applications is not known as of 2021.The sudden success of deep learning in 2012–2015 did not occur because of some new discovery or theoretical breakthrough (deep neural networks and backpropagation had been described by many people, as far back as the 1950s)but because of two factors: the incredible increase in computer power (including the hundred-fold increase in speed by switching toGPUs) and the availability of vast amounts of training data, especially the giantcurated datasetsused for benchmark testing, such asImageNet. Generative pre-trained transformers(GPT) arelarge language models(LLMs) that generate text based on the semantic relationships between words in sentences. Text-based GPT models are pre-trained on a largecorpus of textthat can be from the Internet. The pretraining consists of predicting the nexttoken(a token being usually a word, subword, or punctuation). Throughout this pretraining, GPT models accumulate knowledge about the world and can then generate human-like text by repeatedly predicting the next token. Typically, a subsequent training phase makes the model more truthful, useful, and harmless, usually with a technique calledreinforcement learning from human feedback(RLHF). Current GPT models are prone to generating falsehoods called \"hallucinations\". These can be reduced with RLHF and quality data, but the problem has been getting worse for reasoning systems.Such systems are used inchatbots, which allow people to ask a question or request a task in simple text. Current models and services includeChatGPT,Claude,Gemini,Copilot, andMeta AI.MultimodalGPT models can process different types of data (modalities) such as images, videos, sound, and text. In the late 2010s,graphics processing units(GPUs) that were increasingly designed with AI-specific enhancements and used with specializedTensorFlowsoftware had replaced previously usedcentral processing unit(CPUs) as the dominant means for large-scale (commercial and academic)machine learningmodels' training.Specializedprogramming languagessuch asPrologwere used in early AI research,butgeneral-purpose programming languageslikePythonhave become predominant. The transistor density inintegrated circuitshas been observed to roughly double every 18 months—a trend known asMoore's law, named after theIntelco-founderGordon Moore, who first identified it. Improvements inGPUshave been even faster,a trend sometimes calledHuang's law,named afterNvidiaco-founder and CEOJensen Huang. AI and machine learning technology is used in most of the essential applications of the 2020s, including:search engines(such asGoogle Search),targeting online advertisements,recommendation systems(offered byNetflix,YouTubeorAmazon), drivinginternet traffic,targeted advertising(AdSense,Facebook),virtual assistants(such asSiriorAlexa),autonomous vehicles(includingdrones,ADASandself-driving cars),automatic language translation(Microsoft Translator,Google Translate),facial recognition(Apple'sFaceIDorMicrosoft'sDeepFaceandGoogle'sFaceNet) andimage labeling(used byFacebook, Apple'sPhotosandTikTok). The deployment of AI may be overseen by achief automation officer(CAO). The application of AI inmedicineandmedical researchhas the potential to increase patient care and quality of life.Through the lens of theHippocratic Oath, medical professionals are ethically compelled to use AI, if applications can more accurately diagnose and treat patients. For medical research, AI is an important tool for processing and integratingbig data. This is particularly important fororganoidandtissue engineeringdevelopment which usemicroscopyimaging as a key technique in fabrication.It has been suggested that AI can overcome discrepancies in funding allocated to different fields of research.New AI tools can deepen the understanding of biomedically relevant pathways. For example,AlphaFold 2(2021) demonstrated the ability to approximate, in hours rather than months, the 3Dstructure of a protein.In 2023, it was reported that AI-guided drug discovery helped find a class of antibiotics capable of killing two different types of drug-resistant bacteria.In 2024, researchers used machine learning to accelerate the search forParkinson's diseasedrug treatments. Their aim was to identify compounds that block the clumping, or aggregation, ofalpha-synuclein(the protein that characterises Parkinson's disease). They were able to speed up the initial screening process ten-fold and reduce the cost by a thousand-fold. Game playingprograms have been used since the 1950s to demonstrate and test AI's most advanced techniques.Deep Bluebecame the first computer chess-playing system to beat a reigning world chess champion,Garry Kasparov, on 11 May 1997.In 2011, in aJeopardy!quiz showexhibition match,IBM'squestion answering system,Watson, defeated the two greatestJeopardy!champions,Brad RutterandKen Jennings, by a significant margin.In March 2016,AlphaGowon 4 out of 5 games ofGoin a match with Go championLee Sedol, becoming the firstcomputer Go-playing system to beat a professional Go player withouthandicaps. Then, in 2017, itdefeated Ke Jie, who was the best Go player in the world.Other programs handleimperfect-informationgames, such as thepoker-playing programPluribus.DeepMinddeveloped increasingly generalisticreinforcement learningmodels, such as withMuZero, which could be trained to play chess, Go, orAtarigames.In 2019, DeepMind's AlphaStar achieved grandmaster level inStarCraft II, a particularly challenging real-time strategy game that involves incomplete knowledge of what happens on the map.In 2021, an AI agent competed in a PlayStationGran Turismocompetition, winning against four of the world's best Gran Turismo drivers using deep reinforcement learning.In 2024, Google DeepMind introduced SIMA, a type of AI capable of autonomously playing nine previously unseenopen-worldvideo games by observing screen output, as well as executing short, specific tasks in response to natural language instructions. Large language models, such asGPT-4,Gemini,Claude,LlamaorMistral, are increasingly used in mathematics. These probabilistic models are versatile, but can also produce wrong answers in the form ofhallucinations. They sometimes need a large database of mathematical problems to learn from, but also methods such assupervisedfine-tuningor trainedclassifierswith human-annotated data to improve answers for new problems and learn from corrections.A February 2024 study showed that the performance of some language models for reasoning capabilities in solving math problems not included in their training data was low, even for problems with only minor deviations from trained data.One technique to improve their performance involves training the models to produce correctreasoningsteps, rather than just the correct result.TheAlibaba Groupdeveloped a version of itsQwenmodels calledQwen2-Math, that achieved state-of-the-art performance on several mathematical benchmarks, including 84% accuracy on the MATH dataset of competition mathematics problems.In January 2025, Microsoft proposed the techniquerStar-Maththat leveragesMonte Carlo tree searchand step-by-step reasoning, enabling a relatively small language model likeQwen-7Bto solve 53% of theAIME2024 and 90% of the MATH benchmark problems. Alternatively, dedicated models for mathematical problem solving with higher precision for the outcome including proof of theorems have been developed such asAlphaTensor,AlphaGeometry,AlphaProofandAlphaEvolveall fromGoogle DeepMind,LlemmafromEleutherAIorJulius. When natural language is used to describe mathematical problems, converters can transform such prompts into a formal language such asLeanto define mathematical tasks. The experimental modelGemini Deep Thinkaccepts natural language prompts directly and achieved gold medal results in theInternational Math Olympiadof 2025. Some models have been developed to solve challenging problems and reach good results in benchmark tests, others to serve as educational tools in mathematics. Topological deep learningintegrates varioustopologicalapproaches. Finance is one of the fastest growing sectors where applied AI tools are being deployed: from retail online banking to investment advice and insurance, where automated \"robot advisers\" have been in use for some years. According to Nicolas Firzli, director of theWorld Pensions & Investments Forum, it may be too early to see the emergence of highly innovative AI-informed financial products and services. He argues that \"the deployment of AI tools will simply further automatise things: destroying tens of thousands of jobs in banking, financial planning, and pension advice in the process, but I'm not sure it will unleash a new wave of [e.g., sophisticated] pension innovation.\" Various countries are deploying AI military applications.The main applications enhancecommand and control, communications, sensors, integration and interoperability.Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous andautonomous vehicles.AI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions,target acquisition, coordination and deconfliction of distributedJoint Firesbetween networked combat vehicles, both human-operated andautonomous. AI has been used in military operations in Iraq, Syria, Israel and Ukraine. Generative artificial intelligence(Generative AI, GenAI,or GAI) is a subfield of artificial intelligence that usesgenerative modelsto produce text,images,videos,audio,software codeor other forms of data.These modelslearnthe underlying patterns and structures of theirtraining dataand use them to produce new databased on the input, which often comes in the form of natural languageprompts. Generative AI tools have become more common since theAI boomin the 2020s. This boom was made possible by improvements intransformer-baseddeepneural networks, particularlylarge language models(LLMs). Major tools includechatbotssuch asChatGPT,Copilot,Gemini,Claude,Grok, andDeepSeek;text-to-imagemodels such asStable Diffusion,Midjourney, andDALL-E; andtext-to-videomodels such asVeoandSora.Technology companies developing generative AI includeOpenAI,xAI,Anthropic,Meta AI,Microsoft,Google,DeepSeek,BaiduandYandex. AI agents are software entities designed to perceive their environment, make decisions, and take actions autonomously to achieve specific goals. These agents can interact with users, their environment, or other agents. AI agents are used in various applications, includingvirtual assistants,chatbots,autonomous vehicles,game-playing systems, andindustrial robotics. AI agents operate within the constraints of their programming, available computational resources, and hardware limitations. This means they are restricted to performing tasks within their defined scope and have finite memory and processing capabilities. In real-world applications, AI agents often face time constraints for decision-making and action execution. Many AI agents incorporate learning algorithms, enabling them to improve their performance over time through experience or training. Using machine learning, AI agents can adapt to new situations and optimise their behaviour for their designated tasks. Microsoft introducedCopilot Searchin February 2023 under the nameBing Chat, as a built-in feature for Microsoft Edge and Bing mobile app. Copilot Search provides AI-generated summariesand step-by-step reasoning based of information from web publishers, ranked in Bing Search.For safety, Copilot uses AI-based classifiers and filters to reduce potentially harmful content. Google officially pushed its AI Search at its Google I/O event on May 20, 2025.It keeps people looking at Google instead of clicking on a search result.AI Overviewsuses Gemini 2.5 to provide contextual answers to user queries based on web content. Applications of AI in this domain include AI-enabled menstruation and fertility trackers that analyze user data to offer predictions,AI-integrated sex toys (e.g.,teledildonics),AI-generated sexual education content,and AI agents that simulate sexual and romantic partners (e.g.,Replika).AI is also used for the production of non-consensualdeepfake pornography, raising significant ethical and legal concerns. AI technologies have also been used to attempt to identifyonline gender-based violenceand onlinesexual groomingof minors. There are also thousands of successful AI applications used to solve specific problems for specific industries or institutions. In a 2017 survey, one in five companies reported having incorporated \"AI\" in some offerings or processes.A few examples areenergy storage, medical diagnosis, military logistics, applications that predict the result of judicial decisions,foreign policy, or supply chain management. AI applications for evacuation anddisastermanagement are growing. AI has been used to investigate patterns in large-scale and small-scale evacuations using historical data from GPS, videos or social media. Furthermore, AI can provide real-time information on the evacuation conditions. In agriculture, AI has helped farmers to increase yield and identify areas that need irrigation, fertilization, pesticide treatments. Agronomists use AI to conduct research and development. AI has been used to predict the ripening time for crops such as tomatoes, monitor soil moisture, operate agricultural robots, conductpredictive analytics, classify livestock pig call emotions, automate greenhouses, detect diseases and pests, and save water. Artificial intelligence is used in astronomy to analyze increasing amounts of available data and applications, mainly for \"classification, regression, clustering, forecasting, generation, discovery, and the development of new scientific insights.\" For example, it is used for discovering exoplanets, forecasting solar activity, and distinguishing between signals and instrumental effects in gravitational wave astronomy. Additionally, it could be used for activities in space, such as space exploration, including the analysis of data from space missions, real-time science decisions of spacecraft, space debris avoidance, and more autonomous operation. During the2024 Indian elections, US$50 million was spent on authorized AI-generated content, notably by creatingdeepfakesof allied (including sometimes deceased) politicians to better engage with voters, and by translating speeches to various local languages. AI has potential benefits and potential risks.AI may be able to advance science and find solutions for serious problems:Demis HassabisofDeepMindhopes to \"solve intelligence, and then use that to solve everything else\".However, as the use of AI has become widespread, several unintended consequences and risks have been identified.In-production systems can sometimes not factor ethics and bias into their AI training processes, especially when the AI algorithms are inherently unexplainable in deep learning. Machine learning algorithms require large amounts of data. The techniques used to acquire this data have raised concerns aboutprivacy,surveillanceandcopyright. AI-powered devices and services, such as virtual assistants and IoT products, continuously collect personal information, raising concerns about intrusive data gathering and unauthorized access by third parties. The loss of privacy is further exacerbated by AI's ability to process and combine vast amounts of data, potentially leading to a surveillance society where individual activities are constantly monitored and analyzed without adequate safeguards or transparency. Sensitive user data collected may include online activity records, geolocation data, video, or audio.For example, in order to buildspeech recognitionalgorithms,Amazonhas recorded millions of private conversations and allowedtemporary workersto listen to and transcribe some of them.Opinions about this widespread surveillance range from those who see it as anecessary evilto those for whom it is clearlyunethicaland a violation of theright to privacy. AI developers argue that this is the only way to deliver valuable applications and have developed several techniques that attempt to preserve privacy while still obtaining the data, such asdata aggregation,de-identificationanddifferential privacy.Since 2016, some privacy experts, such asCynthia Dwork, have begun to view privacy in terms offairness.Brian Christianwrote that experts have pivoted \"from the question of 'what they know' to the question of 'what they're doing with it'.\" Generative AI is often trained on unlicensed copyrighted works, including in domains such as images or computer code; the output is then used under the rationale of \"fair use\". Experts disagree about how well and under what circumstances this rationale will hold up in courts of law; relevant factors may include \"the purpose and character of the use of the copyrighted work\" and \"the effect upon the potential market for the copyrighted work\".Website owners who do not wish to have their content scraped can indicate it in a \"robots.txt\" file.In 2023, leading authors (includingJohn GrishamandJonathan Franzen) sued AI companies for using their work to train generative AI.Another discussed approach is to envision a separatesui generissystem of protection for creations generated by AI to ensure fair attribution and compensation for human authors. The commercial AI scene is dominated byBig Techcompanies such asAlphabet Inc.,Amazon,Apple Inc.,Meta Platforms, andMicrosoft.Some of these players already own the vast majority of existingcloud infrastructureandcomputingpower fromdata centers, allowing them to entrench further in the marketplace. In January 2024, theInternational Energy Agency(IEA) releasedElectricity 2024, Analysis and Forecast to 2026, forecasting electric power use.This is the first IEA report to make projections for data centers and power consumption for artificial intelligence and cryptocurrency. The report states that power demand for these uses might double by 2026, with additional electric power usage equal to electricity used by the whole Japanese nation. Prodigious power consumption by AI is responsible for the growth of fossil fuel use, and might delay closings of obsolete, carbon-emitting coal energy facilities. There is a feverish rise in the construction of data centers throughout the US, making large technology firms (e.g., Microsoft, Meta, Google, Amazon) into voracious consumers of electric power. Projected electric consumption is so immense that there is concern that it will be fulfilled no matter the source. A ChatGPT search involves the use of 10 times the electrical energy as a Google search. The large firms are in haste to find power sources – from nuclear energy to geothermal to fusion. The tech firms argue that – in the long view – AI will be eventually kinder to the environment, but they need the energy now. AI makes the power grid more efficient and \"intelligent\", will assist in the growth of nuclear power, and track overall carbon emissions, according to technology firms. A 2024Goldman SachsResearch Paper,AI Data Centers and the Coming US Power Demand Surge, found \"US power demand (is) likely to experience growth not seen in a generation....\" and forecasts that, by 2030, US data centers will consume 8% of US power, as opposed to 3% in 2022, presaging growth for the electrical power generation industry by a variety of means.Data centers' need for more and more electrical power is such that they might max out the electrical grid. The Big Tech companies counter that AI can be used to maximize the utilization of the grid by all. In 2024, theWall Street Journalreported that big AI companies have begun negotiations with the US nuclear power providers to provide electricity to the data centers. In March 2024 Amazon purchased a Pennsylvania nuclear-powered data center for US$650 million.NvidiaCEOJensen Huangsaid nuclear power is a good option for the data centers. In September 2024,Microsoftannounced an agreement withConstellation Energyto re-open theThree Mile Islandnuclear power plant to provide Microsoft with 100% of all electric power produced by the plant for 20 years. Reopening the plant, which suffered a partial nuclear meltdown of its Unit 2 reactor in 1979, will require Constellation to get through strict regulatory processes which will include extensive safety scrutiny from the USNuclear Regulatory Commission. If approved (this will be the first ever US re-commissioning of a nuclear plant), over 835 megawatts of power – enough for 800,000 homes – of energy will be produced. The cost for re-opening and upgrading is estimated at US$1.6 billion and is dependent on tax breaks for nuclear power contained in the 2022 USInflation Reduction Act.The US government and the state of Michigan are investing almost US$2 billion to reopen thePalisades Nuclearreactor on Lake Michigan. Closed since 2022, the plant is planned to be reopened in October 2025. The Three Mile Island facility will be renamed the Crane Clean Energy Center after Chris Crane, a nuclear proponent and former CEO ofExelonwho was responsible for Exelon's spinoff of Constellation. After the last approval in September 2023,Taiwansuspended the approval of data centers north ofTaoyuanwith a capacity of more than 5 MW in 2024, due to power supply shortages.Taiwan aims tophase out nuclear powerby 2025.On the other hand,Singaporeimposed a ban on the opening of data centers in 2019 due to electric power, but in 2022, lifted this ban. Although most nuclear plants in Japan have been shut down after the 2011Fukushima nuclear accident, according to an October 2024Bloombergarticle in Japanese, cloud gaming services company Ubitus, in which Nvidia has a stake, is looking for land in Japan near a nuclear power plant for a new data center for generative AI.Ubitus CEO Wesley Kuo said nuclear power plants are the most efficient, cheap and stable power for AI. On 1 November 2024, theFederal Energy Regulatory Commission(FERC) rejected an application submitted byTalen Energyfor approval to supply some electricity from the nuclear power stationSusquehannato Amazon's data center.According to the Commission ChairmanWillie L. Phillips, it is a burden on the electricity grid as well as a significant cost shifting concern to households and other business sectors. In 2025, a report prepared by the International Energy Agency estimated thegreenhouse gas emissionsfrom the energy consumption of AI at 180 million tons. By 2035, these emissions could rise to 300–500 million tonnes depending on what measures will be taken. This is below 1.5% of the energy sector emissions. The emissions reduction potential of AI was estimated at 5% of the energy sector emissions, butrebound effects(for example if people switch from public transport to autonomous cars) can reduce it. YouTube,Facebookand others userecommender systemsto guide users to more content. These AI programs were given the goal ofmaximizinguser engagement (that is, the only goal was to keep people watching). The AI learned that users tended to choosemisinformation,conspiracy theories, and extremepartisancontent, and, to keep them watching, the AI recommended more of it. Users also tended to watch more content on the same subject, so the AI led people intofilter bubbleswhere they received multiple versions of the same misinformation.This convinced many users that the misinformation was true, and ultimately undermined trust in institutions, the media and the government.The AI program had correctly learned to maximize its goal, but the result was harmful to society. After the U.S. election in 2016, major technology companies took some steps to mitigate the problem. In the early 2020s,generative AIbegan to create images, audio, and texts that are virtually indistinguishable from real photographs, recordings, or human writing,while realistic AI-generated videos became feasible in the mid-2020s.It is possible for bad actors to use this technology to create massive amounts of misinformation or propaganda;one such potential malicious use is deepfakes forcomputational propaganda.AI pioneerGeoffrey Hintonexpressed concern about AI enabling \"authoritarian leaders to manipulate their electorates\" on a large scale, among other risks. AI researchers atMicrosoft,OpenAI, universities and other organisations have suggested using \"personhood credentials\" as a way to overcome online deception enabled by AI models. Machine learning applications will bebiasedif they learn from biased data.The developers may not be aware that the bias exists.Bias can be introduced by the waytraining datais selected and by the way a model is deployed.If a biased algorithm is used to make decisions that can seriouslyharmpeople (as it can inmedicine,finance,recruitment,housingorpolicing) then the algorithm may causediscrimination.The field offairnessstudies how to prevent harms from algorithmic biases. On June 28, 2015,Google Photos's new image labeling feature mistakenly identified Jacky Alcine and a friend as \"gorillas\" because they were black. The system was trained on a dataset that contained very few images of black people,a problem called \"sample size disparity\".Google \"fixed\" this problem by preventing the system from labellinganythingas a \"gorilla\". Eight years later, in 2023, Google Photos still could not identify a gorilla, and neither could similar products from Apple, Facebook, Microsoft and Amazon. COMPASis a commercial program widely used byU.S. courtsto assess the likelihood of adefendantbecoming arecidivist. In 2016,Julia AngwinatProPublicadiscovered that COMPAS exhibited racial bias, despite the fact that the program was not told the races of the defendants. Although the error rate for both whites and blacks was calibrated equal at exactly 61%, the errors for each race were different—the system consistently overestimated the chance that a black person would re-offend and would underestimate the chance that a white person would not re-offend.In 2017, several researchersshowed that it was mathematically impossible for COMPAS to accommodate all possible measures of fairness when the base rates of re-offense were different for whites and blacks in the data. A program can make biased decisions even if the data does not explicitly mention a problematic feature (such as \"race\" or \"gender\"). The feature will correlate with other features (like \"address\", \"shopping history\" or \"first name\"), and the program will make the same decisions based on these features as it would on \"race\" or \"gender\".Moritz Hardt said \"the most robust fact in this research area is that fairness through blindness doesn't work.\" Criticism of COMPAS highlighted that machine learning models are designed to make \"predictions\" that are only valid if we assume that the future will resemble the past. If they are trained on data that includes the results of racist decisions in the past, machine learning models must predict that racist decisions will be made in the future. If an application then uses these predictions asrecommendations, some of these \"recommendations\" will likely be racist.Thus, machine learning is not well suited to help make decisions in areas where there is hope that the future will bebetterthan the past. It is descriptive rather than prescriptive. Bias and unfairness may go undetected because the developers are overwhelmingly white and male: among AI engineers, about 4% are black and 20% are women. There are various conflicting definitions and mathematical models of fairness. These notions depend on ethical assumptions, and are influenced by beliefs about society. One broad category isdistributive fairness, which focuses on the outcomes, often identifying groups and seeking to compensate for statistical disparities. Representational fairness tries to ensure that AI systems do not reinforce negativestereotypesor render certain groups invisible. Procedural fairness focuses on the decision process rather than the outcome. The most relevant notions of fairness may depend on the context, notably the type of AI application and the stakeholders. The subjectivity in the notions of bias and fairness makes it difficult for companies to operationalize them. Having access to sensitive attributes such as race or gender is also considered by many AI ethicists to be necessary in order to compensate for biases, but it may conflict withanti-discrimination laws. At its 2022Conference on Fairness, Accountability, and Transparency(ACM FAccT 2022), theAssociation for Computing Machinery, in Seoul, South Korea, presented and published findings that recommend that until AI and robotics systems are demonstrated to be free of bias mistakes, they are unsafe, and the use of self-learning neural networks trained on vast, unregulated sources of flawed internet data should be curtailed. Many AI systems are so complex that their designers cannot explain how they reach their decisions.Particularly withdeep neural networks, in which there are many non-linearrelationships between inputs and outputs. But some popular explainability techniques exist. It is impossible to be certain that a program is operating correctly if no one knows how exactly it works. There have been many cases where a machine learning program passed rigorous tests, but nevertheless learned something different than what the programmers intended. For example, a system that could identify skin diseases better than medical professionals was found to actually have a strong tendency to classify images with aruleras \"cancerous\", because pictures of malignancies typically include a ruler to show the scale.Another machine learning system designed to help effectively allocate medical resources was found to classify patients with asthma as being at \"low risk\" of dying from pneumonia. Having asthma is actually a severe risk factor, but since the patients having asthma would usually get much more medical care, they were relatively unlikely to die according to the training data. The correlation between asthma and low risk of dying from pneumonia was real, but misleading. People who have been harmed by an algorithm's decision have a right to an explanation.Doctors, for example, are expected to clearly and completely explain to their colleagues the reasoning behind any decision they make. Early drafts of the European Union'sGeneral Data Protection Regulationin 2016 included an explicit statement that this right exists.Industry experts noted that this is an unsolved problem with no solution in sight. Regulators argued that nevertheless the harm is real: if the problem has no solution, the tools should not be used. DARPAestablished theXAI(\"Explainable Artificial Intelligence\") program in 2014 to try to solve these problems. Several approaches aim to address the transparency problem. SHAP enables to visualise the contribution of each feature to the output.LIME can locally approximate a model's outputs with a simpler, interpretable model.Multitask learningprovides a large number of outputs in addition to the target classification. These other outputs can help developers deduce what the network has learned.Deconvolution,DeepDreamand othergenerativemethods can allow developers to see what different layers of a deep network for computer vision have learned, and produce output that can suggest what the network is learning.Forgenerative pre-trained transformers,Anthropicdeveloped a technique based ondictionary learningthat associates patterns of neuron activations with human-understandable concepts. Artificial intelligence provides a number of tools that are useful tobad actors, such asauthoritarian governments,terrorists,criminalsorrogue states. A lethal autonomous weapon is a machine that locates, selects and engages human targets without human supervision.Widely available AI tools can be used by bad actors to develop inexpensive autonomous weapons and, if produced at scale, they are potentiallyweapons of mass destruction.Even when used in conventional warfare, they currently cannot reliably choose targets and could potentiallykill an innocent person.In 2014, 30 nations (including China) supported a ban on autonomous weapons under theUnited Nations'Convention on Certain Conventional Weapons, however theUnited Statesand others disagreed.By 2015, over fifty countries were reported to be researching battlefield robots. AI tools make it easier forauthoritarian governmentsto efficiently control their citizens in several ways.Faceandvoice recognitionallow widespreadsurveillance.Machine learning, operating this data, canclassifypotential enemies of the state and prevent them from hiding.Recommendation systemscan precisely targetpropagandaandmisinformationfor maximum effect.Deepfakesandgenerative AIaid in producing misinformation. Advanced AI can make authoritariancentralized decision-makingmore competitive than liberal and decentralized systems such asmarkets. It lowers the cost and difficulty ofdigital warfareandadvanced spyware.All these technologies have been available since 2020 or earlier—AIfacial recognition systemsare already being used formass surveillancein China. There are many other ways in which AI is expected to help bad actors, some of which can not be foreseen. For example, machine-learning AI is able to design tens of thousands of toxic molecules in a matter of hours. Economists have frequently highlighted the risks of redundancies from AI, and speculated about unemployment if there is no adequate social policy for full employment. In the past, technology has tended to increase rather than reduce total employment, but economists acknowledge that \"we're in uncharted territory\" with AI.A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-termunemployment, but they generally agree that it could be a net benefit ifproductivitygains areredistributed.Risk estimates vary; for example, in the 2010s, Michael Osborne andCarl Benedikt Freyestimated 47% of U.S. jobs are at \"high risk\" of potential automation, while an OECD report classified only 9% of U.S. jobs as \"high risk\".The methodology of speculating about future employment levels has been criticised as lacking evidential foundation, and for implying that technology, rather than social policy, creates unemployment, as opposed to redundancies.In April 2023, it was reported that 70% of the jobs for Chinese video game illustrators had been eliminated by generative artificial intelligence. Unlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence;The Economiststated in 2015 that \"the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution\" is \"worth taking seriously\".Jobs at extreme risk range fromparalegalsto fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy. From the early days of the development of artificial intelligence, there have been arguments, for example, those put forward byJoseph Weizenbaum, about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculation and qualitative, value-based judgement. It has been argued AI will become so powerful that humanity may irreversibly lose control of it. This could, as physicistStephen Hawkingstated, \"spell the end of the human race\".This scenario has been common in science fiction, when a computer or robot suddenly develops a human-like \"self-awareness\" (or \"sentience\" or \"consciousness\") and becomes a malevolent character.These sci-fi scenarios are misleading in several ways. First, AI does not require human-likesentienceto be an existential risk. Modern AI programs are given specific goals and use learning and intelligence to achieve them. PhilosopherNick Bostromargued that if one givesalmost anygoal to a sufficiently powerful AI, it may choose to destroy humanity to achieve it (he used the example of apaperclip maximizer).Stuart Russellgives the example of household robot that tries to find a way to kill its owner to prevent it from being unplugged, reasoning that \"you can't fetch the coffee if you're dead.\"In order to be safe for humanity, asuperintelligencewould have to be genuinelyalignedwith humanity's morality and values so that it is \"fundamentally on our side\". Second,Yuval Noah Harariargues that AI does not require a robot body or physical control to pose an existential risk. The essential parts of civilization are not physical. Things likeideologies,law,government,moneyand theeconomyare built onlanguage; they exist because there are stories that billions of people believe. The current prevalence ofmisinformationsuggests that an AI could use language to convince people to believe anything, even to take actions that are destructive. The opinions amongst experts and industry insiders are mixed, with sizable fractions both concerned and unconcerned by risk from eventual superintelligent AI.Personalities such asStephen Hawking,Bill Gates, andElon Musk,as well as AI pioneers such asYoshua Bengio,Stuart Russell,Demis Hassabis, andSam Altman, have expressed concerns about existential risk from AI. In May 2023,Geoffrey Hintonannounced his resignation from Google in order to be able to \"freely speak out about the risks of AI\" without \"considering how this impacts Google\".He notably mentioned risks of anAI takeover,and stressed that in order to avoid the worst outcomes, establishing safety guidelines will require cooperation among those competing in use of AI. In 2023, many leading AI experts endorsedthe joint statementthat \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war\". Some other researchers were more optimistic. AI pioneerJürgen Schmidhuberdid not sign the joint statement, emphasising that in 95% of all cases, AI research is about making \"human lives longer and healthier and easier.\"While the tools that are now being used to improve lives can also be used by bad actors, \"they can also be used against the bad actors.\"Andrew Ngalso argued that \"it's a mistake to fall for the doomsday hype on AI—and that regulators who do will only benefit vested interests.\"Yann LeCun\"scoffs at his peers' dystopian scenarios of supercharged misinformation and even, eventually, human extinction.\"In the early 2010s, experts argued that the risks are too distant in the future to warrant research or that humans will be valuable from the perspective of a superintelligent machine.However, after 2016, the study of current and future risks and possible solutions became a serious area of research. Friendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans.Eliezer Yudkowsky, who coined the term, argues that developing friendly AI should be a higher research priority: it may require a large investment and it must be completed before AI becomes an existential risk. Machines with intelligence have the potential to use their intelligence to make ethical decisions. The field of machine ethics provides machines with ethical principles and procedures for resolving ethical dilemmas.The field of machine ethics is also called computational morality,and was founded at anAAAIsymposium in 2005. Other approaches includeWendell Wallach's \"artificial moral agents\"andStuart J. Russell'sthree principlesfor developing provably beneficial machines. Active organizations in the AI open-source community includeHugging Face,Google,EleutherAIandMeta.Various AI models, such asLlama 2,MistralorStable Diffusion, have been made open-weight,meaning that their architecture and trained parameters (the \"weights\") are publicly available. Open-weight models can be freelyfine-tuned, which allows companies to specialize them with their own data and for their own use-case.Open-weight models are useful for research and innovation but can also be misused. Since they can be fine-tuned, any built-in security measure, such as objecting to harmful requests, can be trained away until it becomes ineffective. Some researchers warn that future AI models may develop dangerous capabilities (such as the potential to drastically facilitatebioterrorism) and that once released on the Internet, they cannot be deleted everywhere if needed. They recommend pre-release audits and cost-benefit analyses. Artificial intelligence projects can be guided by ethical considerations during the design, development, and implementation of an AI system. An AI framework such as the Care and Act Framework, developed by theAlan Turing Instituteand based on the SUM values, outlines four main ethical dimensions, defined as follows: Other developments in ethical frameworks include those decided upon during theAsilomar Conference, the Montreal Declaration for Responsible AI, and the IEEE's Ethics of Autonomous Systems initiative, among others;however, these principles are not without criticism, especially regarding the people chosen to contribute to these frameworks. Promotion of the wellbeing of the people and communities that these technologies affect requires consideration of the social and ethical implications at all stages of AI system design, development and implementation, and collaboration between job roles such as data scientists, product managers, data engineers, domain experts, and delivery managers. TheUK AI Safety Institutereleased in 2024 a testing toolset called 'Inspect' for AI safety evaluations available under an MIT open-source licence which is freely available on GitHub and can be improved with third-party packages. It can be used to evaluate AI models in a range of areas including core knowledge, ability to reason, and autonomous capabilities. The regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating AI; it is therefore related to the broader regulation of algorithms.The regulatory and policy landscape for AI is an emerging issue in jurisdictions globally.According to AI Index atStanford, the annual number of AI-related laws passed in the 127 survey countries jumped from one passed in 2016 to 37 passed in 2022 alone.Between 2016 and 2020, more than 30 countries adopted dedicated strategies for AI.Most EU member states had released national AI strategies, as hadCanada, China, India, Japan, Mauritius, the Russian Federation, Saudi Arabia, United Arab Emirates, U.S., and Vietnam. Others were in the process of elaborating their own AI strategy, including Bangladesh, Malaysia and Tunisia.TheGlobal Partnership on Artificial Intelligencewas launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology.Henry Kissinger,Eric Schmidt, andDaniel Huttenlocherpublished a joint statement in November 2021 calling for a government commission to regulate AI.In 2023, OpenAI leaders published recommendations for the governance of superintelligence, which they believe may happen in less than 10 years.In 2023, the United Nations also launched an advisory body to provide recommendations on AI governance; the body comprises technology company executives, government officials and academics.On 1 August 2024, the EUArtificial Intelligence Actentered into force, establishing the first comprehensive EU-wide AI regulation.In 2024, theCouncil of Europecreated the first international legally binding treaty on AI, called the \"Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law\". It was adopted by the European Union, the United States, the United Kingdom, and other signatories. In a 2022Ipsossurvey, attitudes towards AI varied greatly by country; 78% of Chinese citizens, but only 35% of Americans, agreed that \"products and services using AI have more benefits than drawbacks\".A 2023Reuters/Ipsos poll found that 61% of Americans agree, and 22% disagree, that AI poses risks to humanity.In a 2023Fox Newspoll, 35% of Americans thought it \"very important\", and an additional 41% thought it \"somewhat important\", for the federal government to regulate AI, versus 13% responding \"not very important\" and 8% responding \"not at all important\". In November 2023, the first globalAI Safety Summitwas held inBletchley Parkin the UK to discuss the near and far term risks of AI and the possibility of mandatory and voluntary regulatory frameworks.28 countries including the United States, China, and the European Union issued a declaration at the start of the summit, calling for international co-operation to manage the challenges and risks of artificial intelligence.In May 2024 at theAI Seoul Summit, 16 global AI tech companies agreed to safety commitments on the development of AI. The study of mechanical or \"formal\" reasoning began with philosophers and mathematicians in antiquity. The study of logic led directly toAlan Turing'stheory of computation, which suggested that a machine, by shuffling symbols as simple as \"0\" and \"1\", could simulate any conceivable form of mathematical reasoning.This, along with concurrent discoveries incybernetics,information theoryandneurobiology, led researchers to consider the possibility of building an \"electronic brain\".They developed several areas of research that would become part of AI,such asMcCullochandPittsdesign for \"artificial neurons\" in 1943,and Turing's influential 1950 paper 'Computing Machinery and Intelligence', which introduced theTuring testand showed that \"machine intelligence\" was plausible. The field of AI research was founded ata workshopatDartmouth Collegein 1956.The attendees became the leaders of AI research in the 1960s.They and their students produced programs that the press described as \"astonishing\":computers were learningcheckersstrategies, solving word problems in algebra, provinglogical theoremsand speaking English.Artificial intelligence laboratories were set up at a number of British and U.S. universities in the latter 1950s and early 1960s. Researchers in the 1960s and the 1970s were convinced that their methods would eventually succeed in creating a machine withgeneral intelligenceand considered this the goal of their field.In 1965Herbert Simonpredicted, \"machines will be capable, within twenty years, of doing any work a man can do\".In 1967Marvin Minskyagreed, writing that \"within a generation ... the problem of creating 'artificial intelligence' will substantially be solved\".They had, however, underestimated the difficulty of the problem.In 1974, both the U.S. and British governments cut off exploratory research in response to thecriticismofSir James Lighthilland ongoing pressure from the U.S. Congress tofund more productive projects.MinskyandPapert's bookPerceptronswas understood as proving thatartificial neural networkswould never be useful for solving real-world tasks, thus discrediting the approach altogether.The \"AI winter\", a period when obtaining funding for AI projects was difficult, followed. In the early 1980s, AI research was revived by the commercial success ofexpert systems,a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan'sfifth generation computerproject inspired the U.S. and British governments to restore funding foracademic research.However, beginning with the collapse of theLisp Machinemarket in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began. Up to this point, most of AI's funding had gone to projects that used high-levelsymbolsto representmental objectslike plans, goals, beliefs, and known facts. In the 1980s, some researchers began to doubt that this approach would be able to imitate all the processes of human cognition, especiallyperception,robotics,learningandpattern recognition,and began to look into \"sub-symbolic\" approaches.Rodney Brooksrejected \"representation\" in general and focussed directly on engineering machines that move and survive.Judea Pearl,Lotfi Zadeh, and others developed methods that handled incomplete and uncertain information by making reasonable guesses rather than precise logic.But the most important development was the revival of \"connectionism\", including neural network research, byGeoffrey Hintonand others.In 1990,Yann LeCunsuccessfully showed thatconvolutional neural networkscan recognize handwritten digits, the first of many successful applications of neural networks. AI gradually restored its reputation in the late 1990s and early 21st century by exploiting formal mathematical methods and by finding specific solutions to specific problems. This \"narrow\" and \"formal\" focus allowed researchers to produce verifiable results and collaborate with other fields (such asstatistics,economicsandmathematics).By 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as \"artificial intelligence\" (a tendency known as theAI effect).However, several academic researchers became concerned that AI was no longer pursuing its original goal of creating versatile, fully intelligent machines. Beginning around 2002, they founded the subfield ofartificial general intelligence(or \"AGI\"), which had several well-funded institutions by the 2010s. Deep learningbegan to dominate industry benchmarks in 2012 and was adopted throughout the field.For many specific tasks, other methods were abandoned.Deep learning's success was based on both hardware improvements (faster computers,graphics processing units,cloud computing) and access tolarge amounts of data(including curated datasets,such asImageNet). Deep learning's success led to an enormous increase in interest and funding in AI.The amount of machine learning research (measured by total publications) increased by 50% in the years 2015–2019. In 2016, issues offairnessand the misuse of technology were catapulted into center stage at machine learning conferences, publications vastly increased, funding became available, and many researchers re-focussed their careers on these issues. Thealignment problembecame a serious field of academic study. In the late 2010s and early 2020s, AGI companies began to deliver programs that created enormous interest. In 2015,AlphaGo, developed byDeepMind, beat the world championGo player. The program taught only the game's rules and developed a strategy by itself.GPT-3is alarge language modelthat was released in 2020 byOpenAIand is capable of generating high-quality human-like text.ChatGPT, launched on November 30, 2022, became the fastest-growing consumer software application in history, gaining over 100 million users in two months.It marked what is widely regarded as AI's breakout year, bringing it into the public consciousness.These programs, and others, inspired an aggressiveAI boom, where large companies began investing billions of dollars in AI research. According to AI Impacts, about US$50 billion annually was invested in \"AI\" around 2022 in the U.S. alone and about 20% of the new U.S. Computer Science PhD graduates have specialized in \"AI\".About 800,000 \"AI\"-related U.S. job openings existed in 2022.According to PitchBook research, 22% of newly fundedstartupsin 2024 claimed to be AI companies. Philosophical debates have historically sought to determine the nature of intelligence and how to make intelligent machines.Another major focus has been whether machines can be conscious, and the associated ethical implications.Many other topics in philosophy are relevant to AI, such asepistemologyandfree will.Rapid advancements have intensified public discussions on the philosophy andethics of AI. Alan Turingwrote in 1950 \"I propose to consider the question 'can machines think'?\"He advised changing the question from whether a machine \"thinks\", to \"whether or not it is possible for machinery to show intelligent behaviour\".He devised theTuring test, which measures the ability of a machine to simulate human conversation.Since we can only observe the behavior of the machine, it does not matter if it is \"actually\" thinking or literally has a \"mind\". Turing notes thatwe can not determine these things about other peoplebut \"it is usual to have a polite convention that everyone thinks.\" RussellandNorvigagree with Turing that intelligence must be defined in terms of external behavior, not internal structure.However, they are critical that the test requires the machine to imitate humans. \"Aeronautical engineeringtexts\", they wrote, \"do not define the goal of their field as making 'machines that fly so exactly likepigeonsthat they can fool other pigeons.'\"AI founderJohn McCarthyagreed, writing that \"Artificial intelligence is not, by definition, simulation of human intelligence\". McCarthy defines intelligence as \"the computational part of the ability to achieve goals in the world\".Another AI founder,Marvin Minsky, similarly describes it as \"the ability to solve hard problems\".The leading AI textbook defines it as the study of agents that perceive their environment and take actions that maximize their chances of achieving defined goals.These definitions view intelligence in terms of well-defined problems with well-defined solutions, where both the difficulty of the problem and the performance of the program are direct measures of the \"intelligence\" of the machine—and no other philosophical discussion is required, or may not even be possible. Another definition has been adopted by Google,a major practitioner in the field of AI. This definition stipulates the ability of systems to synthesize information as the manifestation of intelligence, similar to the way it is defined in biological intelligence. As a result of the many circulating definitions scholars have started to critically analyze and order the AI discourse itselfincluding discussing the many AI narratives and myths to be found within societal, political and academic discourses.Similarly, in practice, some authors have suggested that the term 'AI' is often used too broadly and vaguely. This raises the question of where the line should be drawn between AI and classical algorithms,with many companies during the early 2020s AI boom using the term as a marketingbuzzword, often even if they did \"not actually use AI in a material way\". There has been debate over whetherlarge language modelsexhibit genuine intelligence or merely simulate it byimitating human text. No established unifying theory orparadigmhas guided AI research for most of its history.The unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term \"artificial intelligence\" to mean \"machine learning with neural networks\"). This approach is mostlysub-symbolic,softandnarrow. Critics argue that these questions may have to be revisited by future generations of AI researchers. Symbolic AI(or \"GOFAI\")simulated the high-level conscious reasoning that people use when they solve puzzles, express legal reasoning and do mathematics. They were highly successful at \"intelligent\" tasks such as algebra or IQ tests. In the 1960s, Newell and Simon proposed thephysical symbol systems hypothesis: \"A physical symbol system has the necessary and sufficient means of general intelligent action.\" However, the symbolic approach failed on many tasks that humans solve easily, such as learning, recognizing an object orcommonsense reasoning.Moravec's paradoxis the discovery that high-level \"intelligent\" tasks were easy for AI, but low level \"instinctive\" tasks were extremely difficult.PhilosopherHubert Dreyfushadarguedsince the 1960s that human expertise depends on unconscious instinct rather than conscious symbol manipulation, and on having a \"feel\" for the situation, rather than explicit symbolic knowledge.Although his arguments had been ridiculed and ignored when they were first presented, eventually, AI research came to agree with him. The issue is not resolved:sub-symbolicreasoning can make many of the same inscrutable mistakes that human intuition does, such asalgorithmic bias. Critics such asNoam Chomskyargue continuing research into symbolic AI will still be necessary to attain general intelligence,in part because sub-symbolic AI is a move away fromexplainable AI: it can be difficult or impossible to understand why a modern statistical AI program made a particular decision. The emerging field ofneuro-symbolic artificial intelligenceattempts to bridge the two approaches. \"Neats\" hope that intelligent behavior is described using simple, elegant principles (such aslogic,optimization, orneural networks). \"Scruffies\" expect that it necessarily requires solving a large number of unrelated problems. Neats defend their programs with theoretical rigor, scruffies rely mainly on incremental testing to see if they work. This issue was actively discussed in the 1970s and 1980s,but eventually was seen as irrelevant. Modern AI has elements of both. Finding a provably correct or optimal solution isintractablefor many important problems.Soft computing is a set of techniques, includinggenetic algorithms,fuzzy logicand neural networks, that are tolerant of imprecision, uncertainty, partial truth and approximation. Soft computing was introduced in the late 1980s and most successful AI programs in the 21st century are examples of soft computing with neural networks. AI researchers are divided as to whether to pursue the goals of artificial general intelligence andsuperintelligencedirectly or to solve as many specific problems as possible (narrow AI) in hopes these solutions will lead indirectly to the field's long-term goals.General intelligence is difficult to define and difficult to measure, and modern AI has had more verifiable successes by focusing on specific problems with specific solutions. The sub-field of artificial general intelligence studies this area exclusively. There is no settled consensus inphilosophy of mindon whether a machine can have amind,consciousnessandmental statesin the same sense that human beings do. This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant because it does not affect the goals of the field: to build machines that can solve problems using intelligence.RussellandNorvigadd that \"[t]he additional project of making a machine conscious in exactly the way humans are is not one that we are equipped to take on.\"However, the question has become central to the philosophy of mind. It is also typically the central question at issue inartificial intelligence in fiction. David Chalmersidentified two problems in understanding the mind, which he named the \"hard\" and \"easy\" problems of consciousness.The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how thisfeelsor why it should feel like anything at all, assuming we are right in thinking that it truly does feel like something (Dennett's consciousness illusionism says this is an illusion). While humaninformation processingis easy to explain, humansubjective experienceis difficult to explain. For example, it is easy to imagine a color-blind person who has learned to identify which objects in their field of view are red, but it is not clear what would be required for the person toknow what red looks like. Computationalism is the position in thephilosophy of mindthat the human mind is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to themind–body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophersJerry FodorandHilary Putnam. PhilosopherJohn Searlecharacterized this position as \"strong AI\": \"The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.\"Searle challenges this claim with hisChinese roomargument, which attempts to show that even a computer capable of perfectly simulating human behavior would not have a mind. It is difficult or impossible to reliably evaluate whether an advancedAI is sentient(has the ability to feel), and if so, to what degree.But if there is a significant chance that a given machine can feel and suffer, then it may be entitled to certain rights or welfare protection measures, similarly to animals.Sapience(a set of capacities related to high intelligence, such as discernment orself-awareness) may provide another moral basis for AI rights.Robot rightsare also sometimes proposed as a practical way to integrate autonomous agents into society. In 2017, the European Union considered granting \"electronic personhood\" to some of the most capable AI systems. Similarly to the legal status of companies, it would have conferred rights but also responsibilities.Critics argued in 2018 that granting rights to AI systems would downplay the importance ofhuman rights, and that legislation should focus on user needs rather than speculative futuristic scenarios. They also noted that robots lacked the autonomy to take part in society on their own. Progress in AI increased interest in the topic. Proponents of AI welfare and rights often argue that AI sentience, if it emerges, would be particularly easy to deny. They warn that this may be amoral blind spotanalogous toslaveryorfactory farming, which could lead tolarge-scale sufferingif sentient AI is created and carelessly exploited. Asuperintelligenceis a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind.If research intoartificial general intelligenceproduced sufficiently intelligent software, it might be able toreprogram and improve itself. The improved software would be even better at improving itself, leading to whatI. J. Goodcalled an \"intelligence explosion\" andVernor Vingecalled a \"singularity\". However, technologies cannot improve exponentially indefinitely, and typically follow anS-shaped curve, slowing when they reach the physical limits of what the technology can do. Robot designerHans Moravec, cyberneticistKevin Warwickand inventorRay Kurzweilhave predicted that humans and machines may merge in the future intocyborgsthat are more capable and powerful than either. This idea, called transhumanism, has roots in the writings ofAldous HuxleyandRobert Ettinger. Edward Fredkinargues that \"artificial intelligence is the next step in evolution\", an idea first proposed bySamuel Butler's \"Darwin among the Machines\" as far back as 1863, and expanded upon byGeorge Dysonin his 1998 bookDarwin Among the Machines: The Evolution of Global Intelligence. Thought-capable artificial beings have appeared as storytelling devices since antiquity,and have been a persistent theme inscience fiction. A commontropein these works began withMary Shelley'sFrankenstein, where a human creation becomes a threat to its masters. This includes such works asArthur C. Clarke'sandStanley Kubrick's2001: A Space Odyssey(both 1968), withHAL 9000, the murderous computer in charge of theDiscovery Onespaceship, as well asThe Terminator(1984) andThe Matrix(1999). In contrast, the rare loyal robots such as Gort fromThe Day the Earth Stood Still(1951) and Bishop fromAliens(1986) are less prominent in popular culture. Isaac Asimovintroduced theThree Laws of Roboticsin many stories, most notably with the \"Multivac\" super-intelligent computer. Asimov's laws are often brought up during lay discussions of machine ethics;while almost all artificial intelligence researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity. Several works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that havethe ability to feel, and thus to suffer. This appears inKarel Čapek'sR.U.R., the filmsA.I. Artificial IntelligenceandEx Machina, as well as the novelDo Androids Dream of Electric Sheep?, byPhilip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence. The two most widely used textbooks in 2023 (see theOpen Syllabus): The four most widely used AI textbooks in 2008: Other textbooks:", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Artificial_intelligence", "https://en.wikipedia.org/wiki/Artificial_intelligence", "https://en.wikipedia.org/wiki/Artificial_intelligence", "https://en.wikipedia.org/wiki/AI_(disambiguation)", "https://en.wikipedia.org/wiki/Artificial_intelligence_(disambiguation)", "https://en.wikipedia.org/wiki/Artificial_general_intelligence", "https://en.wikipedia.org/wiki/Intelligent_agent", "https://en.wikipedia.org/wiki/Recursive_self-improvement"]},
{"id": "c34a9c092d7f", "url": "https://en.wikipedia.org/wiki/Uncanny_valley", "title": "Uncanny valley", "headings": ["Contents", "Etymology", "Hypothesis", "Theoretical basis", "Research", "Design principles", "Criticism", "Similar effects", "In visual effects", "Virtual actors", "See also", "References", "Citations", "General and cited sources", "External links"], "content": " Theuncanny valleyeffect is a hypothesized psychological and aesthetic relation between an object's degree of resemblance to a human being and the emotional response to the object. The uncanny valley hypothesis predicts that an entity appearing almost human will risk eliciting eerie feelings in viewers. Examples of the phenomenon exist amongrobots,animatronics, and lifelikedollsas well as visuals produced by3D computer animationandartificial intelligence. The increasing prevalence of digital technologies (e.g.,virtual reality,augmented reality, andphotorealisticcomputer animation) and their increasingverisimilitudehave prompted debate about the \"valley.\" As related to robotics engineering, robotics professorMasahiro Morifirst introduced the concept in 1970 from his book titledBukimi No Tani(不気味の谷), phrasing it asbukimi no tani genshō(不気味の谷現象;lit.'uncanny valley phenomenon').Bukimi no taniwastranslated literallyasuncanny valleyin the 1978 bookRobots: Fact, Fiction, and Predictionwritten byJasia Reichardt.Over time, this translation created an unintended association of the concept toErnst Jentsch'spsychoanalyticconcept of theuncannyestablished in his 1906 essay \"On the Psychology of the Uncanny\" (German:Zur Psychologie des Unheimlichen),which was then critiqued and extended inSigmund Freud's 1919 essay \"The Uncanny\" (German:Das Unheimliche). Mori's original hypothesis states that as the appearance of a robot is made more human, some observers' emotional response to the robot becomes increasingly positive andempathetic, until it becomes almost human, at which point the response quickly becomes strong revulsion. However, as the robot's appearance continues to become less distinguishable from that of a human being, the emotional response becomes positive once again and approaches human-to-human empathy levels.When plotted on a graph, the reactions are indicated by a steep decrease followed by a steep increase (hence the \"valley\" part of the name) in the areas where anthropomorphism is closest to reality. This interval of repulsive response aroused by a robot with appearance and motion between a \"somewhat human\" and \"fully human\" entity is the uncanny valley effect. The name represents the idea that an almost human-looking robot seems overly \"strange\" to some human beings, produces a feeling ofuncanniness, and thus fails to evoke the empathic response required for productivehuman–robot interaction. A number of theories have been proposed to explain the cognitive mechanism causing the phenomenon: A series of studies experimentally investigated whether uncanny valley effects exist for static images of robot faces. Mathur MB & Reichling DBused two complementary sets of stimuli spanning the range from very mechanical to very human-like: first, a sample of 80 objectively chosen robot face images from Internet searches, and second, a morphometrically and graphically controlled 6-face series set of faces. They asked subjects to explicitly rate the likability of each face. To measure trust toward each face, subjects completed an investment game to measure indirectly how much money they were willing to \"wager\" on a robot's trustworthiness. Both stimulus sets showed a robust uncanny valley effect on explicitly rated likability and a more context-dependent uncanny valley on implicitly rated trust. Their exploratory analysis of one proposed mechanism for the uncanny valley, perceptual confusion at a category boundary, found that category confusion occurs in the uncanny valley but does not mediate the effect on social and emotional responses. One study conducted in 2009 examined the evolutionary mechanism behind the aversion associated with the uncanny valley. A group of five monkeys were shown three images: two different 3D monkey faces (realistic, unrealistic), and a real photo of a monkey's face. The monkeys' eye-gaze was used as a proxy for preference or aversion. Since the realistic 3D monkey face was looked at less than either the real photo, or the unrealistic 3D monkey face, this was interpreted as an indication that the monkey participants found the realistic 3D face aversive, or otherwise preferred the other two images. As one would expect with the uncanny valley, more realism can result in less positive reactions, and this study demonstrated that neither human-specific cognitive processes, nor human culture explain the uncanny valley. In other words, this aversive reaction to realism can be said to be evolutionary in origin. As of 2011, researchers atUniversity of California, San DiegoandCalifornia Institute for Telecommunications and Information Technologywere measuring human brain activations related to the uncanny valley.In one study usingfMRI, a group ofcognitive scientistsandroboticistsfound the biggest differences in brain responses for uncanny robots in theparietal cortex, on both sides of the brain, specifically in the areas that connect the part of the brain'svisual cortexthat processes bodily movements with the section of themotor cortexthought to containmirror neurons. The researchers say they saw, in essence, evidence of mismatch or perceptual conflict.The brain \"lit up\" when the human-like appearance of the android and its robotic motion \"didn't compute\". Ayşe Pınar Saygın, an assistant professor from UCSD, stated that \"The brain doesn't seem selectively tuned to either biological appearance or biological motion per se. What it seems to be doing is looking for its expectations to be met – for appearance and motion to be congruent.\" Viewer perception offacial expressionand speech and the uncanny valley in realistic, human-like characters intended forvideo gamesand movies is being investigated by Tinwell et al., 2011.Consideration is also given by Tinwell et al. (2010) as to how the uncanny may be exaggerated for antipathetic characters in survival horror games.Building on the body of work already performed for android science, this research intends to build a conceptual mapping of the uncanny valley using 3D characters generated in a real-time gaming engine. The goal is to analyze how cross-modal factors of facial expression and speech can exaggerate the uncanny. Tinwell et al., 2011have also introduced the notion of an 'unscalable' uncanny wall that suggests that a viewer's discernment for detecting imperfections in realism will keep pace with new technologies in simulating realism. A summary of Angela Tinwell's research on the uncanny valley, psychological reasons behind the uncanny valley and how designers may overcome the uncanny in human-like virtual characters is provided in her book,The Uncanny Valley in Games and AnimationbyCRC Press. A number of design principles have been proposed for avoiding the uncanny valley: A number of criticisms have been raised concerning whether the uncanny valley exists as a unified phenomenon amenable to scientific scrutiny: If the uncanny valley effect is the result of general cognitive processes, there should be evidence in evolutionary history and cultural artifacts.An effect similar to the uncanny valley was noted byCharles Darwinin 1839: The expression of this [Trigonocephalus] snake's face was hideous and fierce; the pupil consisted of a vertical slit in a mottled and coppery iris; the jaws were broad at the base, and the nose terminated in a triangular projection. I do not think I ever saw anything more ugly, excepting, perhaps, some of thevampire bats. I imagine this repulsive aspect originates from the features being placed in positions, with respect to each other, somewhat proportional to the human face; and thus we obtain a scale of hideousness. — Charles Darwin,The Voyage of the Beagle A similar \"uncanny valley\" effect could, according to the ethical-futurist writer Jamais Cascio, show up when humans begin modifying themselves withtranshumanenhancements (cf.body modification), which aim to improve the abilities of the human body beyond what would normally be possible, be iteyesight,musclestrength, orcognition.So long as these enhancements remain within a perceived norm of human behavior, a negative reaction is unlikely, but once individuals supplant normal human variety, revulsion can be expected. However, according to this theory, once such technologies gain further distance from human norms, \"transhuman\" individuals would cease to be judged on human levels and instead be regarded as separate entities altogether (this point is what has been dubbed \"posthuman\"), and it is here that acceptance would rise once again out of the uncanny valley.Another example comes from \"pageant retouching\" photos, especially of children, which some find disturbingly doll-like. A number of movies that usecomputer-generated imageryto show characters have been described by reviewers as giving a feeling of revulsion or \"creepiness\" as a result of the characters looking too realistic. Examples include the following: An increasingly common practice is to featurevirtual actorsin movies: CGI likenesses of real actors used because the original actor either looks too old for the part or is deceased. Sometimes a virtual actor is created with involvement from the original actor (who may contribute motion capture, audio, etc.), while at other times the actor has no involvement. Reviewers have often criticized the use of virtual actors for its uncanny valley effect, saying it adds an eerie feeling to the movie. Examples of virtual actors that have received such criticism include replicas ofArnold SchwarzeneggerinTerminator Salvation(2009)andTerminator Genisys(2015),Jeff BridgesinTron: Legacy(2010),Peter CushingandCarrie FisherinRogue One(2016),andWill SmithinGemini Man(2019).", "combined_text": "Uncanny valley Contents Etymology Hypothesis Theoretical basis Research Design principles Criticism Similar effects In visual effects Virtual actors See also References Citations General and cited sources External links  Theuncanny valleyeffect is a hypothesized psychological and aesthetic relation between an object's degree of resemblance to a human being and the emotional response to the object. The uncanny valley hypothesis predicts that an entity appearing almost human will risk eliciting eerie feelings in viewers. Examples of the phenomenon exist amongrobots,animatronics, and lifelikedollsas well as visuals produced by3D computer animationandartificial intelligence. The increasing prevalence of digital technologies (e.g.,virtual reality,augmented reality, andphotorealisticcomputer animation) and their increasingverisimilitudehave prompted debate about the \"valley.\" As related to robotics engineering, robotics professorMasahiro Morifirst introduced the concept in 1970 from his book titledBukimi No Tani(不気味の谷), phrasing it asbukimi no tani genshō(不気味の谷現象;lit.'uncanny valley phenomenon').Bukimi no taniwastranslated literallyasuncanny valleyin the 1978 bookRobots: Fact, Fiction, and Predictionwritten byJasia Reichardt.Over time, this translation created an unintended association of the concept toErnst Jentsch'spsychoanalyticconcept of theuncannyestablished in his 1906 essay \"On the Psychology of the Uncanny\" (German:Zur Psychologie des Unheimlichen),which was then critiqued and extended inSigmund Freud's 1919 essay \"The Uncanny\" (German:Das Unheimliche). Mori's original hypothesis states that as the appearance of a robot is made more human, some observers' emotional response to the robot becomes increasingly positive andempathetic, until it becomes almost human, at which point the response quickly becomes strong revulsion. However, as the robot's appearance continues to become less distinguishable from that of a human being, the emotional response becomes positive once again and approaches human-to-human empathy levels.When plotted on a graph, the reactions are indicated by a steep decrease followed by a steep increase (hence the \"valley\" part of the name) in the areas where anthropomorphism is closest to reality. This interval of repulsive response aroused by a robot with appearance and motion between a \"somewhat human\" and \"fully human\" entity is the uncanny valley effect. The name represents the idea that an almost human-looking robot seems overly \"strange\" to some human beings, produces a feeling ofuncanniness, and thus fails to evoke the empathic response required for productivehuman–robot interaction. A number of theories have been proposed to explain the cognitive mechanism causing the phenomenon: A series of studies experimentally investigated whether uncanny valley effects exist for static images of robot faces. Mathur MB & Reichling DBused two complementary sets of stimuli spanning the range from very mechanical to very human-like: first, a sample of 80 objectively chosen robot face images from Internet searches, and second, a morphometrically and graphically controlled 6-face series set of faces. They asked subjects to explicitly rate the likability of each face. To measure trust toward each face, subjects completed an investment game to measure indirectly how much money they were willing to \"wager\" on a robot's trustworthiness. Both stimulus sets showed a robust uncanny valley effect on explicitly rated likability and a more context-dependent uncanny valley on implicitly rated trust. Their exploratory analysis of one proposed mechanism for the uncanny valley, perceptual confusion at a category boundary, found that category confusion occurs in the uncanny valley but does not mediate the effect on social and emotional responses. One study conducted in 2009 examined the evolutionary mechanism behind the aversion associated with the uncanny valley. A group of five monkeys were shown three images: two different 3D monkey faces (realistic, unrealistic), and a real photo of a monkey's face. The monkeys' eye-gaze was used as a proxy for preference or aversion. Since the realistic 3D monkey face was looked at less than either the real photo, or the unrealistic 3D monkey face, this was interpreted as an indication that the monkey participants found the realistic 3D face aversive, or otherwise preferred the other two images. As one would expect with the uncanny valley, more realism can result in less positive reactions, and this study demonstrated that neither human-specific cognitive processes, nor human culture explain the uncanny valley. In other words, this aversive reaction to realism can be said to be evolutionary in origin. As of 2011, researchers atUniversity of California, San DiegoandCalifornia Institute for Telecommunications and Information Technologywere measuring human brain activations related to the uncanny valley.In one study usingfMRI, a group ofcognitive scientistsandroboticistsfound the biggest differences in brain responses for uncanny robots in theparietal cortex, on both sides of the brain, specifically in the areas that connect the part of the brain'svisual cortexthat processes bodily movements with the section of themotor cortexthought to containmirror neurons. The researchers say they saw, in essence, evidence of mismatch or perceptual conflict.The brain \"lit up\" when the human-like appearance of the android and its robotic motion \"didn't compute\". Ayşe Pınar Saygın, an assistant professor from UCSD, stated that \"The brain doesn't seem selectively tuned to either biological appearance or biological motion per se. What it seems to be doing is looking for its expectations to be met – for appearance and motion to be congruent.\" Viewer perception offacial expressionand speech and the uncanny valley in realistic, human-like characters intended forvideo gamesand movies is being investigated by Tinwell et al., 2011.Consideration is also given by Tinwell et al. (2010) as to how the uncanny may be exaggerated for antipathetic characters in survival horror games.Building on the body of work already performed for android science, this research intends to build a conceptual mapping of the uncanny valley using 3D characters generated in a real-time gaming engine. The goal is to analyze how cross-modal factors of facial expression and speech can exaggerate the uncanny. Tinwell et al., 2011have also introduced the notion of an 'unscalable' uncanny wall that suggests that a viewer's discernment for detecting imperfections in realism will keep pace with new technologies in simulating realism. A summary of Angela Tinwell's research on the uncanny valley, psychological reasons behind the uncanny valley and how designers may overcome the uncanny in human-like virtual characters is provided in her book,The Uncanny Valley in Games and AnimationbyCRC Press. A number of design principles have been proposed for avoiding the uncanny valley: A number of criticisms have been raised concerning whether the uncanny valley exists as a unified phenomenon amenable to scientific scrutiny: If the uncanny valley effect is the result of general cognitive processes, there should be evidence in evolutionary history and cultural artifacts.An effect similar to the uncanny valley was noted byCharles Darwinin 1839: The expression of this [Trigonocephalus] snake's face was hideous and fierce; the pupil consisted of a vertical slit in a mottled and coppery iris; the jaws were broad at the base, and the nose terminated in a triangular projection. I do not think I ever saw anything more ugly, excepting, perhaps, some of thevampire bats. I imagine this repulsive aspect originates from the features being placed in positions, with respect to each other, somewhat proportional to the human face; and thus we obtain a scale of hideousness. — Charles Darwin,The Voyage of the Beagle A similar \"uncanny valley\" effect could, according to the ethical-futurist writer Jamais Cascio, show up when humans begin modifying themselves withtranshumanenhancements (cf.body modification), which aim to improve the abilities of the human body beyond what would normally be possible, be iteyesight,musclestrength, orcognition.So long as these enhancements remain within a perceived norm of human behavior, a negative reaction is unlikely, but once individuals supplant normal human variety, revulsion can be expected. However, according to this theory, once such technologies gain further distance from human norms, \"transhuman\" individuals would cease to be judged on human levels and instead be regarded as separate entities altogether (this point is what has been dubbed \"posthuman\"), and it is here that acceptance would rise once again out of the uncanny valley.Another example comes from \"pageant retouching\" photos, especially of children, which some find disturbingly doll-like. A number of movies that usecomputer-generated imageryto show characters have been described by reviewers as giving a feeling of revulsion or \"creepiness\" as a result of the characters looking too realistic. Examples include the following: An increasingly common practice is to featurevirtual actorsin movies: CGI likenesses of real actors used because the original actor either looks too old for the part or is deceased. Sometimes a virtual actor is created with involvement from the original actor (who may contribute motion capture, audio, etc.), while at other times the actor has no involvement. Reviewers have often criticized the use of virtual actors for its uncanny valley effect, saying it adds an eerie feeling to the movie. Examples of virtual actors that have received such criticism include replicas ofArnold SchwarzeneggerinTerminator Salvation(2009)andTerminator Genisys(2015),Jeff BridgesinTron: Legacy(2010),Peter CushingandCarrie FisherinRogue One(2016),andWill SmithinGemini Man(2019).", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Uncanny_valley", "https://en.wikipedia.org/wiki/Uncanny_valley", "https://en.wikipedia.org/wiki/Uncanny_valley", "https://en.wikipedia.org/wiki/Uncanny_valley_(disambiguation)", "https://en.wikipedia.org/wiki/Anthropomorphism", "https://en.wikipedia.org/wiki/Masahiro_Mori_(roboticist)", "https://en.wikipedia.org/wiki/Artificial_intelligence", "https://en.wikipedia.org/wiki/Artificial_general_intelligence"]},
{"id": "b5f309ecb31d", "url": "https://en.wikipedia.org/wiki/Turing_test", "title": "Turing test", "headings": ["Contents", "History", "Philosophical background", "Cultural background", "Alan Turing and the imitation game", "The Chinese room", "Loebner Prize", "CAPTCHA", "Attempts", "Large language models", "Versions", "Interpretations", "Should the interrogator know about the computer?", "Strengths", "Tractability and simplicity", "Breadth of subject matter", "Emphasis on emotional and aesthetic intelligence", "Weaknesses", "Naïveté of interrogators", "Human intelligence vs. intelligence in general", "Consciousness vs. the simulation of consciousness", "Impracticality and irrelevance: the Turing test and AI research", "The language-centric objection", "Silence", "The Turing Trap", "Variations", "Reverse Turing test and CAPTCHA", "Distinguishing accurate use of language from actual understanding", "Subject matter expert Turing test", "\"Low-level\" cognition test", "Total Turing test", "Electronic health records", "Minimum intelligent signal test", "Hutter Prize", "Other tests based on compression or Kolmogorov complexity", "Ebert test", "Social Turing game", "Conferences", "Turing Colloquium", "2008 AISB Symposium", "See also", "Notes", "References", "Further reading", "External links"], "content": " TheTuring test, originally called theimitation gamebyAlan Turingin 1949,is a test of a machine's ability toexhibit intelligent behaviourequivalent to that of a human. In the test, a human evaluator judges a text transcript of anatural-languageconversation between a human and a machine. The evaluator tries to identify the machine, and the machine passes if the evaluator cannot reliably tell them apart. The results would not depend on the machine's ability toanswer questions correctly, only on how closely its answers resembled those of a human. Since the Turing test is a test of indistinguishability in performance capacity, the verbal version generalizes naturally to all of human performance capacity, verbal as well as nonverbal (robotic). The test was introduced by Turing in his 1950 paper \"Computing Machinery and Intelligence\" while working at theUniversity of Manchester.It opens with the words: \"I propose to consider the question, 'Can machines think?'\" Because \"thinking\" is difficult to define, Turing chooses to \"replace the question by another, which is closely related to it and is expressed in relatively unambiguous words\".Turing describes the new form of the problem in terms of a three-personparty gamecalled the \"imitation game\", in which an interrogator asks questions of a man and a woman in another room in order to determine the correct sex of the two players. Turing's new question is: \"Are there imaginable digital computers which would do well in theimitation game?\"This question, Turing believed, was one that could actually be answered. In the remainder of the paper, he argued against the major objections to the proposition that \"machines can think\". Since Turing introduced his test, it has been highly influential in thephilosophy of artificial intelligence, resulting in substantial discussion and controversy, as well as criticism from philosophers likeJohn Searle, who argue against the test's ability to detectconsciousness. Since the mid-2020s, severallarge language modelssuch asChatGPThave passed modern, rigorous variants of the Turing test. The question of whether it is possible for machines to think has a long history, which is firmly entrenched in the distinction betweendualistandmaterialistviews of the mind.René Descartesprefigures aspects of the Turing test in his 1637Discourse on the Methodwhen he writes: [H]ow many different automata or moving machines could be made by the industry of man ... For we can easily understand a machine's being constituted so that it can utter words, and even emit some responses to action on it of a corporeal kind, which brings about a change in its organs; for instance, if touched in a particular part it may ask what we wish to say to it; if in another part it may exclaim that it is being hurt, and so on. But it never happens that it arranges its speech in various ways, in order to reply appropriately to everything that may be said in its presence, as even the lowest type of man can do. Here Descartes notes thatautomataare capable of responding to human interactions but argues that such automata cannot respond appropriately to things said in their presence in the way that any human can. Descartes therefore prefigures the Turing test by defining the insufficiency of appropriate linguistic response as that which separates the human from the automaton. Descartes fails to consider the possibility that future automata might be able to overcome such insufficiency, and so does not propose the Turing test as such, even if he prefigures its conceptual framework and criterion. Denis Diderotformulates in his 1746 bookPensées philosophiquesa Turing-test criterion, though with the important implicit limiting assumption maintained, of the participants being natural living beings, rather than considering created artifacts: If they find a parrot who could answer to everything, I would claim it to be an intelligent being without hesitation. This does not mean he agrees with this, but that it was already a common argument ofmaterialistsat that time. According to dualism, themindisnon-physical(or, at the very least, hasnon-physical properties)and, therefore, cannot be explained in purely physical terms. According to materialism, the mind can be explained physically, which leaves open the possibility of minds that are produced artificially. In 1936, philosopherAlfred Ayerconsidered the standard philosophical question ofother minds: how do we know that other people have the same conscious experiences that we do? In his book,Language, Truth and Logic, Ayer suggested a protocol to distinguish between a conscious man and an unconscious machine: \"The only ground I can have for asserting that an object which appears to be conscious is not really a conscious being, but only a dummy or a machine, is that it fails to satisfy one of the empirical tests by which the presence or absence of consciousness is determined\".(This suggestion is very similar to the Turing test, but it is not certain that Ayer's popular philosophical classic was familiar to Turing.) In other words, a thing is not conscious if it fails the consciousness test. A rudimentary idea of the Turing test appears in the 1726 novelGulliver's TravelsbyJonathan Swift.When Gulliver is brought before the king ofBrobdingnag, the king thinks at first that Gulliver might be a \"a piece of clock-work (which is in that country arrived to a very great perfection) contrived by some ingenious artist\". Even when he hears Gulliver speaking, the king still doubts whether Gulliver was taught \"a set of words\" to make him \"sell at a better price\". Gulliver tells that only after \"he put several other questions to me, and still received rational answers\" the king became satisfied that Gulliver was not a machine. Tests where a human judges whether a computer or an alien is intelligent were an established convention in science fiction by the 1940s, and it is likely that Turing would have been aware of these.Stanley G. Weinbaum's \"A Martian Odyssey\" (1934) provides an example of how nuanced such tests could be. Earlier examples of machines or automatons attempting to pass as human include theAncient Greekmyth ofPygmalionwho creates a sculpture of a woman that is animated byAphrodite,Carlo Collodi's novelThe Adventures of Pinocchio, about a puppet who wants to become a real boy, andE. T. A. Hoffmann's 1816 story \"The Sandman,\" where the protagonist falls in love with an automaton. In all these examples, people are fooled by artificial beings that - up to a point - pass as human. Researchers in the United Kingdom had been exploring \"machine intelligence\" for up to ten years prior to the founding of the field of artificial intelligence (AI) research in 1956.It was a common topic among the members of theRatio Club, an informal group of Britishcyberneticsandelectronicsresearchers that included Alan Turing. Turing, in particular, had been running the notion of machine intelligence since at least 1941and one of the earliest-known mentions of \"computer intelligence\" was made by him in 1947.In Turing's report, \"Intelligent Machinery,\"he investigated \"the question of whether or not it is possible for machinery to show intelligent behaviour\"and, as part of that investigation, proposed what may be considered the forerunner to his later tests: It is not difficult to devise a paper machine which will play a not very bad game of chess.Now get three men A, B and C as subjects for the experiment. A and C are to be rather poor chess players, B is the operator who works the paper machine. ... Two rooms are used with some arrangement for communicating moves, and a game is played between C and either A or the paper machine. C may find it quite difficult to tell which he is playing. \"Computing Machinery and Intelligence\" (1950) was the first published paper by Turing to focus exclusively on machine intelligence. Turing begins the 1950 paper with the claim, \"I propose to consider the question 'Can machines think?'\"As he highlights, the traditional approach to such a question is to start withdefinitions, defining both the terms \"machine\" and \"think\". Turing chooses not to do so; instead, he replaces the question with a new one, \"which is closely related to it and is expressed in relatively unambiguous words\".In essence he proposes to change the question from \"Can machines think?\" to \"Can machines do what we (as thinking entities) can do?\"The advantage of the new question, Turing argues, is that it draws \"a fairly sharp line between the physical and intellectual capacities of a man\". To demonstrate this approach Turing proposes a test inspired by aparty game, known as the \"imitation game\", in which a man and a woman go into separate rooms and guests try to tell them apart by writing a series of questions and reading the typewritten answers sent back. In this game, both the man and the woman aim to convince the guests that they are the other. (Huma Shah argues that this two-human version of the game was presented by Turing only to introduce the reader to the machine-human question-answer test.) Turing described his new version of the game as follows: We now ask the question, \"What will happen when a machine takes the part of A in this game?\" Will the interrogator decide wrongly as often when the game is played like this as he does when the game is played between a man and a woman? These questions replace our original, \"Can machines think?\" Later in the paper, Turing suggests an \"equivalent\" alternative formulation involving a judge conversing only with a computer and a man.While neither of these formulations precisely matches the version of the Turing test that is more generally known today, he proposed a third in 1952. In this version, which Turing discussed in aBBCradio broadcast, a jury asks questions of a computer and the role of the computer is to make a significant proportion of the jury believe that it is really a man. Turing's paper considered nine putative objections, which include some of the major arguments againstartificial intelligencethat have been raised in the years since the paper was published (see \"Computing Machinery and Intelligence\"). John Searle's 1980 paperMinds, Brains, and Programsproposed the \"Chinese room\" thought experiment and argued that the Turing test could not be used to determine if a machine could think. Searle noted that software (such as ELIZA) could pass the Turing test simply by manipulating symbols of which they had no understanding. Without understanding, they could not be described as \"thinking\" in the same sense people did. Therefore, Searle concluded, the Turing test could not prove that machines could think.Much like the Turing test itself, Searle's argument has been both widely criticisedand endorsed. Arguments such as Searle's and others working on thephilosophy of mindsparked off a more intense debate about the nature of intelligence, the possibility of machines with a conscious mind and the value of the Turing test that continued through the 1980s and 1990s. The Loebner Prize, now reported as defunct,provided an annual platform for practical Turing tests with the first competition held in November 1991.It was underwritten byHugh Loebner. The Cambridge Center for Behavioral Studies inMassachusetts, United States, organised the prizes up to and including the 2003 contest. As Loebner described it, one reason the competition was created is to advance the state of AI research, at least in part, because no one had taken steps to implement the Turing test despite 40 years of discussing it. The first Loebner Prize competition in 1991 led to a renewed discussion of the viability of the Turing test and the value of pursuing it, in both the popular pressand academia.The first contest was won by a mindless program with no identifiable intelligence that managed to fool naïve interrogators into making the wrong identification. This highlighted several of the shortcomings of the Turing test (discussedbelow): The winner won, at least in part, because it was able to \"imitate human typing errors\";the unsophisticated interrogators were easily fooled;and some researchers in AI have been led to feel that the test is merely a distraction from more fruitful research. The silver (text only) and gold (audio and visual) prizes have never been won. However, the competition has awarded the bronze medal every year for the computer system that, in the judges' opinions, demonstrates the \"most human\" conversational behaviour among that year's entries.Artificial Linguistic Internet Computer Entity(A.L.I.C.E.) has won the bronze award on three occasions in recent times (2000, 2001, 2004). Learning AIJabberwackywon in 2005 and 2006. The Loebner Prize tested conversational intelligence; winners were typicallychatterbotprograms, orArtificial Conversational Entities (ACE)s. Early Loebner Prize rules restricted conversations: Each entry and hidden-human conversed on a single topic,thus the interrogators were restricted to one line of questioning per entity interaction. The restricted conversation rule was lifted for the 1995 Loebner Prize. Interaction duration between judge and entity has varied in Loebner Prizes. In Loebner 2003, at the University of Surrey, each interrogator was allowed five minutes to interact with an entity, machine or hidden-human. Between 2004 and 2007, the interaction time allowed in Loebner Prizes was more than twenty minutes. The final competition was in 2019, due to a lack of funding for the prize following Loebner's death in 2016. CAPTCHA(Completely Automated Public Turing test to tell Computers and Humans Apart) is one of the oldest concepts for artificial intelligence. The CAPTCHA system is commonly used online to tell humans and bots apart on the internet. It is based on the Turing test. Displaying distorted letters and numbers, it asks the user to identify the letters and numbers and type them into a field, which bots struggle to do. ThereCaptchais a CAPTCHA system owned byGoogle. The reCaptcha v1 and v2 both used to operate by asking the user to match distorted pictures or identify distorted letters and numbers. The reCaptcha v3 is designed to not interrupt users and run automatically when pages are loaded or buttons are clicked. This \"invisible\" CAPTCHA verification happens in the background and no challenges appear, which filters out most basic bots. Several earlysymbolic AI programswere controversially claimed to pass the Turing test, either by limiting themselves to scripted situations or by presenting \"excuses\" for poor reasoning and conversational abilities, such asmental illnessor a poor grasp of English. In 1966,Joseph Weizenbaumcreated a program calledELIZA, which mimicked aRogerian psychotherapist.The program would search the user's sentence for keywords beforerepeating them back to the user, providing the impression of a program listening and paying attention.Weizenbaum thus succeeded by designing a context where a chatbot could mimic a person despite \"knowing almost nothing of the real world\".Weizenbaum's program was able to fool some people into believing that they were talking to a real person. Kenneth ColbycreatedPARRYin 1972, a program modeled after the behaviour ofparanoid schizophrenics.Psychiatrists asked to compare transcripts of conversations generated by the program to those of conversations by actual schizophrenics could only identify about 52 percent of cases correctly (a figure consistent with random guessing). In 2001, three programmers developedEugene Goostman, a chatbot portraying itself as a 13-year-old boy fromOdesawho spokeEnglish as a second language. This background was intentionally chosen so judges would forgive mistakes by the program. In a competition, 33% of judges thought Goostman was human. In June 2022,Google'sLaMDAmodel received widespread coverage after claims about it having achieved sentience. Initially in an article inThe EconomistGoogle Research Fellow Blaise Agüera y Arcas said the chatbot had demonstrated a degree of understanding of social relationships.Several days later, Google engineer Blake Lemoine claimed in an interview with theWashington Postthat LaMDA had achieved sentience. Lemoine had been placed on leave by Google for internal assertions to this effect. Google had investigated the claims but dismissed them. OpenAI's chatbot, ChatGPT, released in November 2022, is based onGPT-3.5andGPT-4large language models. Celeste Biever wrote in aNaturearticle that \"ChatGPT broke the Turing test\".Stanford researchers reported that ChatGPT passes the test; they found that ChatGPT-4 \"passes a rigorous Turing test, diverging from average human behavior chiefly to be more cooperative\",making it the first computer program to successfully do so. In late March 2025, a study evaluated four systems (ELIZA, GPT-4o, LLaMa-3.1-405B, and GPT-4.5) in two randomized, controlled, and pre-registered Turing tests with independent participant groups. Participants engaged in simultaneous 5-minute conversations with another human participant and one of these systems, then judged which conversational partner they believed to be human. When instructed to adopt a humanlike persona, GPT-4.5 was identified as the human 73% of the time—significantly more often than the actual human participants. LLaMa-3.1, under the same conditions, was judged to be human 56% of the time, not significantly more or less often than the humans they were compared to. Baseline models (ELIZA and GPT-4o) achieved win rates significantly below chance (23% and 21%, respectively). These results provide the first empirical evidence that any artificial system passes a standard three-party Turing test. The findings have implications for debates about the nature of intelligence exhibited by Large Language Models (LLMs) and the social and economic impacts these systems are likely to have. Saul Traiger argues that there are at least three primary versions of the Turing test, two of which are offered in \"Computing Machinery and Intelligence\" and one that he describes as the \"Standard Interpretation\".While there is some debate regarding whether the \"Standard Interpretation\" is that described by Turing or, instead, based on a misreading of his paper, these three versions are not regarded as equivalent,and their strengths and weaknesses are distinct. Turing's original article describes a simple party game involving three players. Player A is a man, player B is a woman and player C (who plays the role of the interrogator) is of either sex. In the imitation game, player C is unable to see either player A or player B, and can communicate with them only through written notes. By asking questions of player A and player B, player C tries to determine which of the two is the man and which is the woman. Player A's role is to trick the interrogator into making the wrong decision, while player B attempts to assist the interrogator in making the right one. Turing then asks: \"What will happen when a machine takes the part of A in this game? Will the interrogator decide wrongly as often when the game is played like this as he does when the game is played between a man and a woman?\" These questions replace our original, \"Can machines think?\" The second version appeared later in Turing's 1950 paper. Similar to the original imitation game test, the role of player A is performed by a computer. However, the role of player B is performed by a man rather than a woman. Let us fix our attention on one particular digital computerC.Is it true that by modifying this computer to have an adequate storage, suitably increasing its speed of action, and providing it with an appropriate programme,Ccan be made to play satisfactorily the part of A in the imitation game, the part of B being taken by a man? In this version, both player A (the computer) and player B are trying to trick the interrogator into making an incorrect decision. The standard interpretation is not included in the original paper, but is both accepted and debated.\nCommon understanding has it that the purpose of the Turing test is not specifically to determine whether a computer is able to fool an interrogator into believing that it is a human, but rather whether a computer couldimitatea human.While there is some dispute whether this interpretation was intended by Turing, Sterrett believes that it wasand thus conflates the second version with this one, while others, such as Traiger, do not– this has nevertheless led to what can be viewed as the \"standard interpretation\". In this version, player A is a computer and player B a person of either sex. The role of the interrogator is not to determine which is male and which is female, but which is a computer and which is a human.The fundamental issue with the standard interpretation is that the interrogator cannot differentiate which responder is human, and which is machine. There are issues about duration, but the standard interpretation generally considers this limitation as something that should be reasonable. Controversy has arisen over which of the alternative formulations of the test Turing intended.Sterrett argues that two distinct tests can be extracted from his 1950 paper and that, despite Turing's remark, they are not equivalent. The test that employs the party game and compares frequencies of success is referred to as the \"Original Imitation Game Test\", whereas the test consisting of a human judge conversing with a human and a machine is referred to as the \"Standard Turing Test\", noting that Sterrett equates this with the \"standard interpretation\" rather than the second version of the imitation game. Sterrett agrees that the standard Turing test (STT) has the problems that its critics cite but feels that, in contrast, the original imitation game test (OIG test) so defined is immune to many of them, due to a crucial difference: Unlike the STT, it does not make similarity to human performance the criterion, even though it employs human performance in setting a criterion for machine intelligence. A man can fail the OIG test, but it is argued that it is a virtue of a test of intelligence that failure indicates a lack of resourcefulness: The OIG test requires the resourcefulness associated with intelligence and not merely \"simulation of human conversational behaviour\". The general structure of the OIG test could even be used with non-verbal versions of imitation games. According to Huma Shah, Turing himself was concerned with whether a machine could think and was providing a simple method to examine this: through human-machine question-answer sessions.Shah argues the imitation game which Turing described could be practicalized in two different ways: a) one-to-one interrogator-machine test, and b) simultaneous comparison of a machine with a human, both questioned in parallel by an interrogator. Still other writershave interpreted Turing as proposing that the imitation game itself is the test, without specifying how to take into account Turing's statement that the test that he proposed using the party version of the imitation game is based upon a criterion of comparative frequency of success in that imitation game, rather than a capacity to succeed at one round of the game. Some writers argue that the imitation game is best understood by its social aspects. In his 1948 paper, Turing refers to intelligence as an \"emotional concept,\" and notes that The extent to which we regard something as behaving in an intelligent manner is determined as much by our own state of mind and training as by the properties of the object under consideration. If we are able to explain and predict its behaviour or if there seems to be little underlying plan, we have little temptation to imagine intelligence. With the same object therefore it is possible that one man would consider it as intelligent and another would not; the second man would have found out the rules of its behaviour. Following this remark and similar ones scattered throughout Turing's publications, Diane Proudfootclaims that Turing held aresponse-dependenceapproach to intelligence, according to which an intelligent (or thinking) entity is one thatappearsintelligent to an average interrogator. Shlomo Danzigerpromotes a socio-technological interpretation, according to which Turing saw the imitation game not as an intelligence test but as a technological aspiration - one whose realization would likely involve a change in society's attitude toward machines. According to this reading, Turing's celebrated 50-year prediction - that by the end of the 20th century his test will be passed by some machine - actually consists of two distinguishable predictions. The first is a technological prediction: I believe that in about fifty years' time it will be possible to programme computers ... to make them play the imitation game so well that an average interrogator will not have more than 70% chance of making the right identification after five minutes of questioning. The second prediction Turing makes is a sociological one: I believe that at the end of the century the use of words and general educated opinion will have altered so much that one will be able to speak of machines thinking without expecting to be contradicted. Danziger claims further that for Turing, alteration of society's attitude towards machinery is a prerequisite for the existence of intelligent machines: Only when the term \"intelligent machine\" is no longer seen as an oxymoron the existence of intelligent machines would becomelogicallypossible. Saygin has suggested that maybe the original game is a way of proposing a less biased experimental design as it hides the participation of the computer.The imitation game also includes a \"social hack\" not found in the standard interpretation, as in the game both computer and male human are required to play as pretending to be someone they are not. A crucial piece of any laboratory test is that there should be a control. Turing never makes clear whether the interrogator in his tests is aware that one of the participants is a computer. He states only that player A is to be replaced with a machine, not that player C is to be made aware of this replacement.When Colby, FD Hilf, S Weber and AD Kramer tested PARRY, they did so by assuming that the interrogators did not need to know that one or more of those being interviewed was a computer during the interrogation.As Ayse Saygin, Peter Swirski,and others have highlighted, this makes a big difference to the implementation and outcome of the test.An experimental study looking atGricean maxim violationsusing transcripts of Loebner's one-to-one (interrogator-hidden interlocutor) Prize for AI contests between 1994 and 1999, Ayse Saygin found significant differences between the responses of participants who knew and did not know about computers being involved. The power and appeal of the Turing test derives from its simplicity. Thephilosophy of mind,psychology, and modernneurosciencehave been unable to provide definitions of \"intelligence\" and \"thinking\" that are sufficiently precise and general to be applied to machines. Without such definitions, the central questions of thephilosophy of artificial intelligencecannot be answered. The Turing test, even if imperfect, at least provides something that can actually be measured. As such, it is a pragmatic attempt to answer a difficult philosophical question. The format of the test allows the interrogator to give the machine a wide variety of intellectual tasks. Turing wrote that \"the question and answer method seems to be suitable for introducing almost any one of the fields of human endeavour that we wish to include\".John Haugelandadds that \"understanding the words is not enough; you have to understand thetopicas well\". To pass a well-designed Turing test, the machine must usenatural language,reason, haveknowledgeandlearn. The test can be extended to include video input, as well as a \"hatch\" through which objects can be passed: this would force the machine to demonstrate skilled use of well designedvisionandroboticsas well. Together, these represent almost all of the major problems that artificial intelligence research would like to solve. TheFeigenbaum testis designed to take advantage of the broad range of topics available to a Turing test. It is a limited form of Turing's question-answer game which compares the machine against the abilities of experts in specific fields such as literature orchemistry. As a Cambridge honours graduate in mathematics, Turing might have been expected to propose a test of computer intelligence requiring expert knowledge in some highly technical field, and thus anticipatinga more recent approach to the subject. Instead, as already noted, the test which he described in his seminal 1950 paper requires the computer to be able to compete successfully in a common party game, and this by performing as well as the typical man in answering a series of questions so as to pretend convincingly to be the woman contestant. Given the status of human sexual dimorphism asone of the most ancient of subjects, it is thus implicit in the above scenario that the questions to be answered will involve neither specialised factual knowledge nor information processing technique. The challenge for the computer, rather, will be to demonstrate empathy for the role of the female, and to demonstrate as well a characteristic aesthetic sensibility—both of which qualities are on display in this snippet of dialogue which Turing has imagined: When Turing does introduce some specialised knowledge into one of his imagined dialogues, the subject is not maths or electronics, but poetry: Turing thus once again demonstrates his interest in empathy and aesthetic sensitivity as components of an artificial intelligence; and in light of an increasing awareness of the threat from an AI run amok,it has been suggestedthat this focus perhaps represents a critical intuition on Turing's part, i.e., that emotional and aesthetic intelligence will play a key role in the creation of a \"friendly AI\". It is further noted, however, that whatever inspiration Turing might be able to lend in this direction depends upon the preservation of his original vision, which is to say, further, that the promulgation of a \"standard interpretation\" of the Turing test—i.e., one which focuses on a discursive intelligence only—must be regarded with some caution. Turing did not explicitly state that the Turing test could be used as a measure of \"intelligence\", or any other human quality. He wanted to provide a clear and understandable alternative to the word \"think\", which he could then use to reply to criticisms of the possibility of \"thinking machines\" and to suggest ways that research might move forward. Nevertheless, the Turing test has been proposed as a measure of a machine's \"ability to think\" or its \"intelligence\". This proposal has received criticism from both philosophers and computer scientists. The interpretation makes the assumption that an interrogator can determine if a machine is \"thinking\" by comparing its behaviour with human behaviour. Every element of this assumption has been questioned: the reliability of the interrogator's judgement, the value of comparing the machine with a human, and the value of comparing only behaviour. Because of these and other considerations, some AI researchers have questioned the relevance of the test to their field. In practice, the test's results can easily be dominated not by the computer's intelligence, but by the attitudes, skill, or naïveté of the questioner. Numerous experts in the field, including cognitive scientistGary Marcus, insist that the Turing test only shows how easy it is to fool humans and is not an indication of machine intelligence. Turing doesn't specify the precise skills and knowledge required by the interrogator in his description of the test, but he did use the term \"average interrogator\": \"[the] average interrogator would not have more than 70 per cent chance of making the right identification after five minutes of questioning\". Chatterbot programs such as ELIZA have repeatedly fooled unsuspecting people into believing that they are communicating with human beings. In these cases, the \"interrogators\" are not even aware of the possibility that they are interacting with computers. To successfully appear human, there is no need for the machine to have any intelligence whatsoever and only a superficial resemblance to human behaviour is required. Early Loebner Prize competitions used \"unsophisticated\" interrogators who were easily fooled by the machines.Since 2004, the Loebner Prize organisers have deployed philosophers, computer scientists, and journalists among the interrogators. Nonetheless, some of these experts have been deceived by the machines. One interesting feature of the Turing test is the frequency of theconfederate effect, when the confederate (tested) humans are misidentified by the interrogators as machines. It has been suggested that what interrogators expect as human responses is not necessarily typical of humans. As a result, some individuals can be categorised as machines. This can therefore work in favour of a competing machine. The humans are instructed to \"act themselves\", but sometimes their answers are more like what the interrogator expects a machine to say.This raises the question of how to ensure that the humans are motivated to \"act human\". The Turing test does not directly test whether the computer behaves intelligently. It tests only whether the computer behaves like a human being. Since human behaviour and intelligent behaviour are not exactly the same thing, the test can fail to accurately measure intelligence in two ways: The Turing test is concerned strictly with how the subjectacts– the external behaviour of the machine. In this regard, it takes abehaviouristorfunctionalistapproach to the study of the mind. The example ofELIZAsuggests that a machine passing the test may be able to simulate human conversational behaviour by following a simple (but large) list of mechanical rules, without thinking or having a mind at all. John Searlehas argued that external behaviour cannot be used to determine if a machine is \"actually\" thinking or merely \"simulating thinking\".HisChinese roomargument is intended to show that, even if the Turing test is a good operational definition of intelligence, it may not indicate that the machine has amind,consciousness, orintentionality. (Intentionality is a philosophical term for the power of thoughts to be \"about\" something.) Turing anticipated this line of criticism in his original paper,writing: I do not wish to give the impression that I think there is no mystery about consciousness. There is, for instance, something of a paradox connected with any attempt to localise it. But I do not think these mysteries necessarily need to be solved before we can answer the question with which we are concerned in this paper. Mainstream AI researchers argue that trying to pass the Turing test is merely a distraction from more fruitful research.Indeed, the Turing test is not an active focus of much academic or commercial effort—asStuart RussellandPeter Norvigwrite: \"AI researchers have devoted little attention to passing the Turing test\".There are several reasons. First, there are easier ways to test their programs. Most current research in AI-related fields is aimed at modest and specific goals, such asobject recognitionorlogistics. To test the intelligence of the programs that solve these problems, AI researchers simply give them the task directly. Stuart Russell and Peter Norvig suggest an analogy with thehistory of flight: Planes are tested by how well they fly, not by comparing them to birds. \"Aeronautical engineeringtexts,\" they write, \"do not define the goal of their field as 'making machines that fly so exactly likepigeonsthat they can fool other pigeons.'\" Second, creating lifelike simulations of human beings is a difficult problem on its own that does not need to be solved to achieve the basic goals of AI research. Believable human characters may be interesting in a work of art, agame, or a sophisticateduser interface, but they are not part of the science of creating intelligent machines, that is, machines that solve problems using intelligence. Turing did not intend for his idea to be used to test the intelligence of programs—he wanted to provide a clear and understandable example to aid in the discussion of thephilosophy of artificial intelligence.John McCarthyargues that we should not be surprised that a philosophical idea turns out to be useless for practical applications. He observes that the philosophy of AI is \"unlikely to have any more effect on the practice of AI research than philosophy of science generally has on the practice of science\". Another well known objection raised towards the Turing test concerns its exclusive focus on linguistic behaviour (i.e. it is only a \"language-based\" experiment, while all the other cognitive faculties are not tested). This drawback downsizes the role of other modality-specific \"intelligent abilities\" concerning human beings that the psychologist Howard Gardner, in his \"multiple intelligence theory\", proposes to consider (verbal-linguistic abilities are only one of those). A critical aspect of the Turing test is that a machine must give itself away as being a machine by its utterances. An interrogator must then make the \"right identification\" by correctly identifying the machine as being just that. If, however, a machine remains silent during a conversation, then it is not possible for an interrogator to accurately identify the machine other than by means of a calculated guess.Even taking into account a parallel/hidden human as part of the test may not help the situation as humans can often be misidentified as being a machine. By focusing onimitatinghumans, rather than augmenting or extending human capabilities, the Turing Test risks directing research and implementation toward technologies that substitute for humans and thereby drive down wages and income for workers. As they lose economic power, these workers may also lose political power, making it more difficult for them to change the allocation of wealth and income. This can trap them in a bad equilibrium. Erik Brynjolfsson has called this \"The Turing Trap\"and argued that there are currently excess incentives for creating machines that imitate rather than augment humans. Numerous other versions of the Turing test, including those expounded above, have been raised through the years. A modification of the Turing test wherein the objective of one or more of the roles have been reversed between machines and humans is termed a reverse Turing test. An example is implied in the work of psychoanalystWilfred Bion,who was particularly fascinated by the \"storm\" that resulted from the encounter of one mind by another. In his 2000 book,among several other original points with regard to the Turing test, literary scholarPeter Swirskidiscussed in detail the idea of what he termed the Swirski test—essentially the reverse Turing test. He pointed out that it overcomes most if not all standard objections levelled at the standard version. Carrying this idea forward,R. D. Hinshelwooddescribed the mind as a \"mind recognizing apparatus\". The challenge would be for the computer to be able to determine if it were interacting with a human or another computer. This is an extension of the original question that Turing attempted to answer but would, perhaps, offer a high enough standard to define a machine that could \"think\" in a way that we typically define as characteristically human. CAPTCHAis a form of reverse Turing test. Before being allowed to perform some action on a website, the user is presented with alphanumerical characters in a distorted graphic image and asked to type them out. This is intended to prevent automated systems from being used to abuse the site. The rationale is that software sufficiently sophisticated to read and reproduce the distorted image accurately does not exist (or is not available to the average user), so any system able to do so is likely to be a human. Software that could reverse CAPTCHA with some accuracy by analysing patterns in the generating engine started being developed soon after the creation of CAPTCHA.In 2013, researchers atVicariousannounced that they had developed a system to solve CAPTCHA challenges fromGoogle,Yahoo!, andPayPalup to 90% of the time.In 2014, Google engineers demonstrated a system that could defeat CAPTCHA challenges with 99.8% accuracy.In 2015,Shuman Ghosemajumder, formerclick fraudczar of Google, stated that there werecybercriminalsites that would defeat CAPTCHA challenges for a fee, to enable various forms of fraud. A further variation is motivated by the concern that modern Natural Language Processing prove to be highly successful in generating text on the basis of a huge text corpus and could eventually pass the Turing test simply by manipulating words and sentences that have been used in the initial training of the model. Since the interrogator has no precise understanding of the training data, the model might simply be returning sentences that exist in similar fashion in the enormous amount of training data. For this reason,Arthur Schwaningerproposes a variation of the Turing test that can distinguish between systems that are only capable ofusinglanguage and systems thatunderstandlanguage. He proposes a test in which the machine is confronted with philosophical questions that do not depend on any prior knowledge and yet require self-reflection to be answered appropriately. Another variation is described as thesubject-matter expertTuring test, where a machine's response cannot be distinguished from an expert in a given field. This is also known as a \"Feigenbaum test\" and was proposed byEdward Feigenbaumin a 2003 paper. Robert French(1990) makes the case that an interrogator can distinguish human and non-human interlocutors by posing questions that reveal the low-level (i.e., unconscious) processes of human cognition, as studied bycognitive science. Such questions reveal the precise details of the human embodiment of thought and can unmask a computer unless it experiences the world as humans do. The \"Total Turing test\"variation of the Turing test, proposed by cognitive scientistStevan Harnad,adds two further requirements to the traditional Turing test. The interrogator can also test the perceptual abilities of the subject (requiringcomputer vision) and the subject's ability to manipulate objects (requiringrobotics). Paul Schweizer argues that Harnad's work is too weak, and extended it further with the Truly Total Turing Test: It is essential to note that the TTTT is not a test ofindividualcognitive systems.\nInstead, it is meant to test the overall capacities of the type of cognitive\narchitecture of which particular individuals are tokens. A letter published inCommunications of the ACMdescribes the concept of generating a synthetic patient population and proposes a variation of Turing test to assess the difference between synthetic and real patients. The letter states: \"In the EHR context, though a human physician can readily distinguish between synthetically generated and real live human patients, could a machine be given the intelligence to make such a determination on its own?\" and further the letter states: \"Before synthetic patient identities become a public health problem, the legitimate EHR market might benefit from applying Turing Test-like techniques to ensure greater data reliability and diagnostic value. Any new techniques must thus consider patients' heterogeneity and are likely to have greater complexity than the Allen eighth-grade-science-test is able to grade\". The minimum intelligent signal test was proposed byChris McKinstryas \"the maximum abstraction of the Turing test\",in which only binary responses (true/false or yes/no) are permitted, to focus only on the capacity for thought. It eliminates text chat problems likeanthropomorphism bias, and does not require emulation ofunintelligent human behaviour, allowing for systems that exceed human intelligence. The questions must each stand on their own, however, making it more like anIQ testthan an interrogation. It is typically used to gather statistical data against which the performance of artificial intelligence programs may be measured. The organisers of theHutter Prizebelieve that compressing natural language text is a hard AI problem, equivalent to passing the Turing test. The data compression test has some advantages over most versions and variations of a Turing test, including: The main disadvantages of using data compression as a test are: A related approach to Hutter's prize which appeared much earlier in the late 1990s is the inclusion of compression problems in an extended Turing test.or by tests which are completely derived fromKolmogorov complexity.Other related tests in this line are presented by Hernandez-Orallo and Dowe. Algorithmic IQ, or AIQ for short, is an attempt to convert the theoretical Universal Intelligence Measure from Legg and Hutter (based onSolomonoff's inductive inference) into a working practical test of machine intelligence. Two major advantages of some of these tests are their applicability to nonhuman intelligences and their absence of a requirement for human testers. The Turing test inspired theEbert testproposed in 2011 by film criticRoger Ebertwhich is a test whether a computer-basedsynthesised voicehas sufficient skill in terms of intonations, inflections, timing and so forth, to make people laugh. Taking advantage oflarge language models, in 2023 the research companyAI21 Labscreated an online social experiment titled \"Human or Not?\"It was played more than 10 million times by more than 2 million people.It is the biggest Turing-style experiment to that date. The results showed that 32% of people could not distinguish between humans and machines. 1990 marked the fortieth anniversary of the first publication of Turing's \"Computing Machinery and Intelligence\" paper, and saw renewed interest in the test. Two significant events occurred in that year: the first was the Turing Colloquium, which was held at theUniversity of Sussexin April, and brought together academics and researchers from a wide variety of disciplines to discuss the Turing test in terms of its past, present, and future; the second was the formation of the annualLoebner Prizecompetition. Blay Whitbylists four major turning points in the history of the Turing test – the publication of \"Computing Machinery and Intelligence\" in 1950, the announcement ofJoseph Weizenbaum'sELIZAin 1966,Kenneth Colby's creation ofPARRY, which was first described in 1972, and the Turing Colloquium in 1990. In parallel to the 2008Loebner Prizeheld at theUniversity of Reading,theSociety for the Study of Artificial Intelligence and the Simulation of Behaviour(AISB), hosted a one-day symposium to discuss the Turing test, organised byJohn Barnden,Mark Bishop,Huma ShahandKevin Warwick.The speakers included the Royal Institution's DirectorBaroness Susan Greenfield,Selmer Bringsjord, Turing's biographerAndrew Hodges, and consciousness scientistOwen Holland. No agreement emerged for a canonical Turing test, though Bringsjord expressed that a sizeable prize would result in the Turing test being passed sooner.", "combined_text": "Turing test Contents History Philosophical background Cultural background Alan Turing and the imitation game The Chinese room Loebner Prize CAPTCHA Attempts Large language models Versions Interpretations Should the interrogator know about the computer? Strengths Tractability and simplicity Breadth of subject matter Emphasis on emotional and aesthetic intelligence Weaknesses Naïveté of interrogators Human intelligence vs. intelligence in general Consciousness vs. the simulation of consciousness Impracticality and irrelevance: the Turing test and AI research The language-centric objection Silence The Turing Trap Variations Reverse Turing test and CAPTCHA Distinguishing accurate use of language from actual understanding Subject matter expert Turing test \"Low-level\" cognition test Total Turing test Electronic health records Minimum intelligent signal test Hutter Prize Other tests based on compression or Kolmogorov complexity Ebert test Social Turing game Conferences Turing Colloquium 2008 AISB Symposium See also Notes References Further reading External links  TheTuring test, originally called theimitation gamebyAlan Turingin 1949,is a test of a machine's ability toexhibit intelligent behaviourequivalent to that of a human. In the test, a human evaluator judges a text transcript of anatural-languageconversation between a human and a machine. The evaluator tries to identify the machine, and the machine passes if the evaluator cannot reliably tell them apart. The results would not depend on the machine's ability toanswer questions correctly, only on how closely its answers resembled those of a human. Since the Turing test is a test of indistinguishability in performance capacity, the verbal version generalizes naturally to all of human performance capacity, verbal as well as nonverbal (robotic). The test was introduced by Turing in his 1950 paper \"Computing Machinery and Intelligence\" while working at theUniversity of Manchester.It opens with the words: \"I propose to consider the question, 'Can machines think?'\" Because \"thinking\" is difficult to define, Turing chooses to \"replace the question by another, which is closely related to it and is expressed in relatively unambiguous words\".Turing describes the new form of the problem in terms of a three-personparty gamecalled the \"imitation game\", in which an interrogator asks questions of a man and a woman in another room in order to determine the correct sex of the two players. Turing's new question is: \"Are there imaginable digital computers which would do well in theimitation game?\"This question, Turing believed, was one that could actually be answered. In the remainder of the paper, he argued against the major objections to the proposition that \"machines can think\". Since Turing introduced his test, it has been highly influential in thephilosophy of artificial intelligence, resulting in substantial discussion and controversy, as well as criticism from philosophers likeJohn Searle, who argue against the test's ability to detectconsciousness. Since the mid-2020s, severallarge language modelssuch asChatGPThave passed modern, rigorous variants of the Turing test. The question of whether it is possible for machines to think has a long history, which is firmly entrenched in the distinction betweendualistandmaterialistviews of the mind.René Descartesprefigures aspects of the Turing test in his 1637Discourse on the Methodwhen he writes: [H]ow many different automata or moving machines could be made by the industry of man ... For we can easily understand a machine's being constituted so that it can utter words, and even emit some responses to action on it of a corporeal kind, which brings about a change in its organs; for instance, if touched in a particular part it may ask what we wish to say to it; if in another part it may exclaim that it is being hurt, and so on. But it never happens that it arranges its speech in various ways, in order to reply appropriately to everything that may be said in its presence, as even the lowest type of man can do. Here Descartes notes thatautomataare capable of responding to human interactions but argues that such automata cannot respond appropriately to things said in their presence in the way that any human can. Descartes therefore prefigures the Turing test by defining the insufficiency of appropriate linguistic response as that which separates the human from the automaton. Descartes fails to consider the possibility that future automata might be able to overcome such insufficiency, and so does not propose the Turing test as such, even if he prefigures its conceptual framework and criterion. Denis Diderotformulates in his 1746 bookPensées philosophiquesa Turing-test criterion, though with the important implicit limiting assumption maintained, of the participants being natural living beings, rather than considering created artifacts: If they find a parrot who could answer to everything, I would claim it to be an intelligent being without hesitation. This does not mean he agrees with this, but that it was already a common argument ofmaterialistsat that time. According to dualism, themindisnon-physical(or, at the very least, hasnon-physical properties)and, therefore, cannot be explained in purely physical terms. According to materialism, the mind can be explained physically, which leaves open the possibility of minds that are produced artificially. In 1936, philosopherAlfred Ayerconsidered the standard philosophical question ofother minds: how do we know that other people have the same conscious experiences that we do? In his book,Language, Truth and Logic, Ayer suggested a protocol to distinguish between a conscious man and an unconscious machine: \"The only ground I can have for asserting that an object which appears to be conscious is not really a conscious being, but only a dummy or a machine, is that it fails to satisfy one of the empirical tests by which the presence or absence of consciousness is determined\".(This suggestion is very similar to the Turing test, but it is not certain that Ayer's popular philosophical classic was familiar to Turing.) In other words, a thing is not conscious if it fails the consciousness test. A rudimentary idea of the Turing test appears in the 1726 novelGulliver's TravelsbyJonathan Swift.When Gulliver is brought before the king ofBrobdingnag, the king thinks at first that Gulliver might be a \"a piece of clock-work (which is in that country arrived to a very great perfection) contrived by some ingenious artist\". Even when he hears Gulliver speaking, the king still doubts whether Gulliver was taught \"a set of words\" to make him \"sell at a better price\". Gulliver tells that only after \"he put several other questions to me, and still received rational answers\" the king became satisfied that Gulliver was not a machine. Tests where a human judges whether a computer or an alien is intelligent were an established convention in science fiction by the 1940s, and it is likely that Turing would have been aware of these.Stanley G. Weinbaum's \"A Martian Odyssey\" (1934) provides an example of how nuanced such tests could be. Earlier examples of machines or automatons attempting to pass as human include theAncient Greekmyth ofPygmalionwho creates a sculpture of a woman that is animated byAphrodite,Carlo Collodi's novelThe Adventures of Pinocchio, about a puppet who wants to become a real boy, andE. T. A. Hoffmann's 1816 story \"The Sandman,\" where the protagonist falls in love with an automaton. In all these examples, people are fooled by artificial beings that - up to a point - pass as human. Researchers in the United Kingdom had been exploring \"machine intelligence\" for up to ten years prior to the founding of the field of artificial intelligence (AI) research in 1956.It was a common topic among the members of theRatio Club, an informal group of Britishcyberneticsandelectronicsresearchers that included Alan Turing. Turing, in particular, had been running the notion of machine intelligence since at least 1941and one of the earliest-known mentions of \"computer intelligence\" was made by him in 1947.In Turing's report, \"Intelligent Machinery,\"he investigated \"the question of whether or not it is possible for machinery to show intelligent behaviour\"and, as part of that investigation, proposed what may be considered the forerunner to his later tests: It is not difficult to devise a paper machine which will play a not very bad game of chess.Now get three men A, B and C as subjects for the experiment. A and C are to be rather poor chess players, B is the operator who works the paper machine. ... Two rooms are used with some arrangement for communicating moves, and a game is played between C and either A or the paper machine. C may find it quite difficult to tell which he is playing. \"Computing Machinery and Intelligence\" (1950) was the first published paper by Turing to focus exclusively on machine intelligence. Turing begins the 1950 paper with the claim, \"I propose to consider the question 'Can machines think?'\"As he highlights, the traditional approach to such a question is to start withdefinitions, defining both the terms \"machine\" and \"think\". Turing chooses not to do so; instead, he replaces the question with a new one, \"which is closely related to it and is expressed in relatively unambiguous words\".In essence he proposes to change the question from \"Can machines think?\" to \"Can machines do what we (as thinking entities) can do?\"The advantage of the new question, Turing argues, is that it draws \"a fairly sharp line between the physical and intellectual capacities of a man\". To demonstrate this approach Turing proposes a test inspired by aparty game, known as the \"imitation game\", in which a man and a woman go into separate rooms and guests try to tell them apart by writing a series of questions and reading the typewritten answers sent back. In this game, both the man and the woman aim to convince the guests that they are the other. (Huma Shah argues that this two-human version of the game was presented by Turing only to introduce the reader to the machine-human question-answer test.) Turing described his new version of the game as follows: We now ask the question, \"What will happen when a machine takes the part of A in this game?\" Will the interrogator decide wrongly as often when the game is played like this as he does when the game is played between a man and a woman? These questions replace our original, \"Can machines think?\" Later in the paper, Turing suggests an \"equivalent\" alternative formulation involving a judge conversing only with a computer and a man.While neither of these formulations precisely matches the version of the Turing test that is more generally known today, he proposed a third in 1952. In this version, which Turing discussed in aBBCradio broadcast, a jury asks questions of a computer and the role of the computer is to make a significant proportion of the jury believe that it is really a man. Turing's paper considered nine putative objections, which include some of the major arguments againstartificial intelligencethat have been raised in the years since the paper was published (see \"Computing Machinery and Intelligence\"). John Searle's 1980 paperMinds, Brains, and Programsproposed the \"Chinese room\" thought experiment and argued that the Turing test could not be used to determine if a machine could think. Searle noted that software (such as ELIZA) could pass the Turing test simply by manipulating symbols of which they had no understanding. Without understanding, they could not be described as \"thinking\" in the same sense people did. Therefore, Searle concluded, the Turing test could not prove that machines could think.Much like the Turing test itself, Searle's argument has been both widely criticisedand endorsed. Arguments such as Searle's and others working on thephilosophy of mindsparked off a more intense debate about the nature of intelligence, the possibility of machines with a conscious mind and the value of the Turing test that continued through the 1980s and 1990s. The Loebner Prize, now reported as defunct,provided an annual platform for practical Turing tests with the first competition held in November 1991.It was underwritten byHugh Loebner. The Cambridge Center for Behavioral Studies inMassachusetts, United States, organised the prizes up to and including the 2003 contest. As Loebner described it, one reason the competition was created is to advance the state of AI research, at least in part, because no one had taken steps to implement the Turing test despite 40 years of discussing it. The first Loebner Prize competition in 1991 led to a renewed discussion of the viability of the Turing test and the value of pursuing it, in both the popular pressand academia.The first contest was won by a mindless program with no identifiable intelligence that managed to fool naïve interrogators into making the wrong identification. This highlighted several of the shortcomings of the Turing test (discussedbelow): The winner won, at least in part, because it was able to \"imitate human typing errors\";the unsophisticated interrogators were easily fooled;and some researchers in AI have been led to feel that the test is merely a distraction from more fruitful research. The silver (text only) and gold (audio and visual) prizes have never been won. However, the competition has awarded the bronze medal every year for the computer system that, in the judges' opinions, demonstrates the \"most human\" conversational behaviour among that year's entries.Artificial Linguistic Internet Computer Entity(A.L.I.C.E.) has won the bronze award on three occasions in recent times (2000, 2001, 2004). Learning AIJabberwackywon in 2005 and 2006. The Loebner Prize tested conversational intelligence; winners were typicallychatterbotprograms, orArtificial Conversational Entities (ACE)s. Early Loebner Prize rules restricted conversations: Each entry and hidden-human conversed on a single topic,thus the interrogators were restricted to one line of questioning per entity interaction. The restricted conversation rule was lifted for the 1995 Loebner Prize. Interaction duration between judge and entity has varied in Loebner Prizes. In Loebner 2003, at the University of Surrey, each interrogator was allowed five minutes to interact with an entity, machine or hidden-human. Between 2004 and 2007, the interaction time allowed in Loebner Prizes was more than twenty minutes. The final competition was in 2019, due to a lack of funding for the prize following Loebner's death in 2016. CAPTCHA(Completely Automated Public Turing test to tell Computers and Humans Apart) is one of the oldest concepts for artificial intelligence. The CAPTCHA system is commonly used online to tell humans and bots apart on the internet. It is based on the Turing test. Displaying distorted letters and numbers, it asks the user to identify the letters and numbers and type them into a field, which bots struggle to do. ThereCaptchais a CAPTCHA system owned byGoogle. The reCaptcha v1 and v2 both used to operate by asking the user to match distorted pictures or identify distorted letters and numbers. The reCaptcha v3 is designed to not interrupt users and run automatically when pages are loaded or buttons are clicked. This \"invisible\" CAPTCHA verification happens in the background and no challenges appear, which filters out most basic bots. Several earlysymbolic AI programswere controversially claimed to pass the Turing test, either by limiting themselves to scripted situations or by presenting \"excuses\" for poor reasoning and conversational abilities, such asmental illnessor a poor grasp of English. In 1966,Joseph Weizenbaumcreated a program calledELIZA, which mimicked aRogerian psychotherapist.The program would search the user's sentence for keywords beforerepeating them back to the user, providing the impression of a program listening and paying attention.Weizenbaum thus succeeded by designing a context where a chatbot could mimic a person despite \"knowing almost nothing of the real world\".Weizenbaum's program was able to fool some people into believing that they were talking to a real person. Kenneth ColbycreatedPARRYin 1972, a program modeled after the behaviour ofparanoid schizophrenics.Psychiatrists asked to compare transcripts of conversations generated by the program to those of conversations by actual schizophrenics could only identify about 52 percent of cases correctly (a figure consistent with random guessing). In 2001, three programmers developedEugene Goostman, a chatbot portraying itself as a 13-year-old boy fromOdesawho spokeEnglish as a second language. This background was intentionally chosen so judges would forgive mistakes by the program. In a competition, 33% of judges thought Goostman was human. In June 2022,Google'sLaMDAmodel received widespread coverage after claims about it having achieved sentience. Initially in an article inThe EconomistGoogle Research Fellow Blaise Agüera y Arcas said the chatbot had demonstrated a degree of understanding of social relationships.Several days later, Google engineer Blake Lemoine claimed in an interview with theWashington Postthat LaMDA had achieved sentience. Lemoine had been placed on leave by Google for internal assertions to this effect. Google had investigated the claims but dismissed them. OpenAI's chatbot, ChatGPT, released in November 2022, is based onGPT-3.5andGPT-4large language models. Celeste Biever wrote in aNaturearticle that \"ChatGPT broke the Turing test\".Stanford researchers reported that ChatGPT passes the test; they found that ChatGPT-4 \"passes a rigorous Turing test, diverging from average human behavior chiefly to be more cooperative\",making it the first computer program to successfully do so. In late March 2025, a study evaluated four systems (ELIZA, GPT-4o, LLaMa-3.1-405B, and GPT-4.5) in two randomized, controlled, and pre-registered Turing tests with independent participant groups. Participants engaged in simultaneous 5-minute conversations with another human participant and one of these systems, then judged which conversational partner they believed to be human. When instructed to adopt a humanlike persona, GPT-4.5 was identified as the human 73% of the time—significantly more often than the actual human participants. LLaMa-3.1, under the same conditions, was judged to be human 56% of the time, not significantly more or less often than the humans they were compared to. Baseline models (ELIZA and GPT-4o) achieved win rates significantly below chance (23% and 21%, respectively). These results provide the first empirical evidence that any artificial system passes a standard three-party Turing test. The findings have implications for debates about the nature of intelligence exhibited by Large Language Models (LLMs) and the social and economic impacts these systems are likely to have. Saul Traiger argues that there are at least three primary versions of the Turing test, two of which are offered in \"Computing Machinery and Intelligence\" and one that he describes as the \"Standard Interpretation\".While there is some debate regarding whether the \"Standard Interpretation\" is that described by Turing or, instead, based on a misreading of his paper, these three versions are not regarded as equivalent,and their strengths and weaknesses are distinct. Turing's original article describes a simple party game involving three players. Player A is a man, player B is a woman and player C (who plays the role of the interrogator) is of either sex. In the imitation game, player C is unable to see either player A or player B, and can communicate with them only through written notes. By asking questions of player A and player B, player C tries to determine which of the two is the man and which is the woman. Player A's role is to trick the interrogator into making the wrong decision, while player B attempts to assist the interrogator in making the right one. Turing then asks: \"What will happen when a machine takes the part of A in this game? Will the interrogator decide wrongly as often when the game is played like this as he does when the game is played between a man and a woman?\" These questions replace our original, \"Can machines think?\" The second version appeared later in Turing's 1950 paper. Similar to the original imitation game test, the role of player A is performed by a computer. However, the role of player B is performed by a man rather than a woman. Let us fix our attention on one particular digital computerC.Is it true that by modifying this computer to have an adequate storage, suitably increasing its speed of action, and providing it with an appropriate programme,Ccan be made to play satisfactorily the part of A in the imitation game, the part of B being taken by a man? In this version, both player A (the computer) and player B are trying to trick the interrogator into making an incorrect decision. The standard interpretation is not included in the original paper, but is both accepted and debated.\nCommon understanding has it that the purpose of the Turing test is not specifically to determine whether a computer is able to fool an interrogator into believing that it is a human, but rather whether a computer couldimitatea human.While there is some dispute whether this interpretation was intended by Turing, Sterrett believes that it wasand thus conflates the second version with this one, while others, such as Traiger, do not– this has nevertheless led to what can be viewed as the \"standard interpretation\". In this version, player A is a computer and player B a person of either sex. The role of the interrogator is not to determine which is male and which is female, but which is a computer and which is a human.The fundamental issue with the standard interpretation is that the interrogator cannot differentiate which responder is human, and which is machine. There are issues about duration, but the standard interpretation generally considers this limitation as something that should be reasonable. Controversy has arisen over which of the alternative formulations of the test Turing intended.Sterrett argues that two distinct tests can be extracted from his 1950 paper and that, despite Turing's remark, they are not equivalent. The test that employs the party game and compares frequencies of success is referred to as the \"Original Imitation Game Test\", whereas the test consisting of a human judge conversing with a human and a machine is referred to as the \"Standard Turing Test\", noting that Sterrett equates this with the \"standard interpretation\" rather than the second version of the imitation game. Sterrett agrees that the standard Turing test (STT) has the problems that its critics cite but feels that, in contrast, the original imitation game test (OIG test) so defined is immune to many of them, due to a crucial difference: Unlike the STT, it does not make similarity to human performance the criterion, even though it employs human performance in setting a criterion for machine intelligence. A man can fail the OIG test, but it is argued that it is a virtue of a test of intelligence that failure indicates a lack of resourcefulness: The OIG test requires the resourcefulness associated with intelligence and not merely \"simulation of human conversational behaviour\". The general structure of the OIG test could even be used with non-verbal versions of imitation games. According to Huma Shah, Turing himself was concerned with whether a machine could think and was providing a simple method to examine this: through human-machine question-answer sessions.Shah argues the imitation game which Turing described could be practicalized in two different ways: a) one-to-one interrogator-machine test, and b) simultaneous comparison of a machine with a human, both questioned in parallel by an interrogator. Still other writershave interpreted Turing as proposing that the imitation game itself is the test, without specifying how to take into account Turing's statement that the test that he proposed using the party version of the imitation game is based upon a criterion of comparative frequency of success in that imitation game, rather than a capacity to succeed at one round of the game. Some writers argue that the imitation game is best understood by its social aspects. In his 1948 paper, Turing refers to intelligence as an \"emotional concept,\" and notes that The extent to which we regard something as behaving in an intelligent manner is determined as much by our own state of mind and training as by the properties of the object under consideration. If we are able to explain and predict its behaviour or if there seems to be little underlying plan, we have little temptation to imagine intelligence. With the same object therefore it is possible that one man would consider it as intelligent and another would not; the second man would have found out the rules of its behaviour. Following this remark and similar ones scattered throughout Turing's publications, Diane Proudfootclaims that Turing held aresponse-dependenceapproach to intelligence, according to which an intelligent (or thinking) entity is one thatappearsintelligent to an average interrogator. Shlomo Danzigerpromotes a socio-technological interpretation, according to which Turing saw the imitation game not as an intelligence test but as a technological aspiration - one whose realization would likely involve a change in society's attitude toward machines. According to this reading, Turing's celebrated 50-year prediction - that by the end of the 20th century his test will be passed by some machine - actually consists of two distinguishable predictions. The first is a technological prediction: I believe that in about fifty years' time it will be possible to programme computers ... to make them play the imitation game so well that an average interrogator will not have more than 70% chance of making the right identification after five minutes of questioning. The second prediction Turing makes is a sociological one: I believe that at the end of the century the use of words and general educated opinion will have altered so much that one will be able to speak of machines thinking without expecting to be contradicted. Danziger claims further that for Turing, alteration of society's attitude towards machinery is a prerequisite for the existence of intelligent machines: Only when the term \"intelligent machine\" is no longer seen as an oxymoron the existence of intelligent machines would becomelogicallypossible. Saygin has suggested that maybe the original game is a way of proposing a less biased experimental design as it hides the participation of the computer.The imitation game also includes a \"social hack\" not found in the standard interpretation, as in the game both computer and male human are required to play as pretending to be someone they are not. A crucial piece of any laboratory test is that there should be a control. Turing never makes clear whether the interrogator in his tests is aware that one of the participants is a computer. He states only that player A is to be replaced with a machine, not that player C is to be made aware of this replacement.When Colby, FD Hilf, S Weber and AD Kramer tested PARRY, they did so by assuming that the interrogators did not need to know that one or more of those being interviewed was a computer during the interrogation.As Ayse Saygin, Peter Swirski,and others have highlighted, this makes a big difference to the implementation and outcome of the test.An experimental study looking atGricean maxim violationsusing transcripts of Loebner's one-to-one (interrogator-hidden interlocutor) Prize for AI contests between 1994 and 1999, Ayse Saygin found significant differences between the responses of participants who knew and did not know about computers being involved. The power and appeal of the Turing test derives from its simplicity. Thephilosophy of mind,psychology, and modernneurosciencehave been unable to provide definitions of \"intelligence\" and \"thinking\" that are sufficiently precise and general to be applied to machines. Without such definitions, the central questions of thephilosophy of artificial intelligencecannot be answered. The Turing test, even if imperfect, at least provides something that can actually be measured. As such, it is a pragmatic attempt to answer a difficult philosophical question. The format of the test allows the interrogator to give the machine a wide variety of intellectual tasks. Turing wrote that \"the question and answer method seems to be suitable for introducing almost any one of the fields of human endeavour that we wish to include\".John Haugelandadds that \"understanding the words is not enough; you have to understand thetopicas well\". To pass a well-designed Turing test, the machine must usenatural language,reason, haveknowledgeandlearn. The test can be extended to include video input, as well as a \"hatch\" through which objects can be passed: this would force the machine to demonstrate skilled use of well designedvisionandroboticsas well. Together, these represent almost all of the major problems that artificial intelligence research would like to solve. TheFeigenbaum testis designed to take advantage of the broad range of topics available to a Turing test. It is a limited form of Turing's question-answer game which compares the machine against the abilities of experts in specific fields such as literature orchemistry. As a Cambridge honours graduate in mathematics, Turing might have been expected to propose a test of computer intelligence requiring expert knowledge in some highly technical field, and thus anticipatinga more recent approach to the subject. Instead, as already noted, the test which he described in his seminal 1950 paper requires the computer to be able to compete successfully in a common party game, and this by performing as well as the typical man in answering a series of questions so as to pretend convincingly to be the woman contestant. Given the status of human sexual dimorphism asone of the most ancient of subjects, it is thus implicit in the above scenario that the questions to be answered will involve neither specialised factual knowledge nor information processing technique. The challenge for the computer, rather, will be to demonstrate empathy for the role of the female, and to demonstrate as well a characteristic aesthetic sensibility—both of which qualities are on display in this snippet of dialogue which Turing has imagined: When Turing does introduce some specialised knowledge into one of his imagined dialogues, the subject is not maths or electronics, but poetry: Turing thus once again demonstrates his interest in empathy and aesthetic sensitivity as components of an artificial intelligence; and in light of an increasing awareness of the threat from an AI run amok,it has been suggestedthat this focus perhaps represents a critical intuition on Turing's part, i.e., that emotional and aesthetic intelligence will play a key role in the creation of a \"friendly AI\". It is further noted, however, that whatever inspiration Turing might be able to lend in this direction depends upon the preservation of his original vision, which is to say, further, that the promulgation of a \"standard interpretation\" of the Turing test—i.e., one which focuses on a discursive intelligence only—must be regarded with some caution. Turing did not explicitly state that the Turing test could be used as a measure of \"intelligence\", or any other human quality. He wanted to provide a clear and understandable alternative to the word \"think\", which he could then use to reply to criticisms of the possibility of \"thinking machines\" and to suggest ways that research might move forward. Nevertheless, the Turing test has been proposed as a measure of a machine's \"ability to think\" or its \"intelligence\". This proposal has received criticism from both philosophers and computer scientists. The interpretation makes the assumption that an interrogator can determine if a machine is \"thinking\" by comparing its behaviour with human behaviour. Every element of this assumption has been questioned: the reliability of the interrogator's judgement, the value of comparing the machine with a human, and the value of comparing only behaviour. Because of these and other considerations, some AI researchers have questioned the relevance of the test to their field. In practice, the test's results can easily be dominated not by the computer's intelligence, but by the attitudes, skill, or naïveté of the questioner. Numerous experts in the field, including cognitive scientistGary Marcus, insist that the Turing test only shows how easy it is to fool humans and is not an indication of machine intelligence. Turing doesn't specify the precise skills and knowledge required by the interrogator in his description of the test, but he did use the term \"average interrogator\": \"[the] average interrogator would not have more than 70 per cent chance of making the right identification after five minutes of questioning\". Chatterbot programs such as ELIZA have repeatedly fooled unsuspecting people into believing that they are communicating with human beings. In these cases, the \"interrogators\" are not even aware of the possibility that they are interacting with computers. To successfully appear human, there is no need for the machine to have any intelligence whatsoever and only a superficial resemblance to human behaviour is required. Early Loebner Prize competitions used \"unsophisticated\" interrogators who were easily fooled by the machines.Since 2004, the Loebner Prize organisers have deployed philosophers, computer scientists, and journalists among the interrogators. Nonetheless, some of these experts have been deceived by the machines. One interesting feature of the Turing test is the frequency of theconfederate effect, when the confederate (tested) humans are misidentified by the interrogators as machines. It has been suggested that what interrogators expect as human responses is not necessarily typical of humans. As a result, some individuals can be categorised as machines. This can therefore work in favour of a competing machine. The humans are instructed to \"act themselves\", but sometimes their answers are more like what the interrogator expects a machine to say.This raises the question of how to ensure that the humans are motivated to \"act human\". The Turing test does not directly test whether the computer behaves intelligently. It tests only whether the computer behaves like a human being. Since human behaviour and intelligent behaviour are not exactly the same thing, the test can fail to accurately measure intelligence in two ways: The Turing test is concerned strictly with how the subjectacts– the external behaviour of the machine. In this regard, it takes abehaviouristorfunctionalistapproach to the study of the mind. The example ofELIZAsuggests that a machine passing the test may be able to simulate human conversational behaviour by following a simple (but large) list of mechanical rules, without thinking or having a mind at all. John Searlehas argued that external behaviour cannot be used to determine if a machine is \"actually\" thinking or merely \"simulating thinking\".HisChinese roomargument is intended to show that, even if the Turing test is a good operational definition of intelligence, it may not indicate that the machine has amind,consciousness, orintentionality. (Intentionality is a philosophical term for the power of thoughts to be \"about\" something.) Turing anticipated this line of criticism in his original paper,writing: I do not wish to give the impression that I think there is no mystery about consciousness. There is, for instance, something of a paradox connected with any attempt to localise it. But I do not think these mysteries necessarily need to be solved before we can answer the question with which we are concerned in this paper. Mainstream AI researchers argue that trying to pass the Turing test is merely a distraction from more fruitful research.Indeed, the Turing test is not an active focus of much academic or commercial effort—asStuart RussellandPeter Norvigwrite: \"AI researchers have devoted little attention to passing the Turing test\".There are several reasons. First, there are easier ways to test their programs. Most current research in AI-related fields is aimed at modest and specific goals, such asobject recognitionorlogistics. To test the intelligence of the programs that solve these problems, AI researchers simply give them the task directly. Stuart Russell and Peter Norvig suggest an analogy with thehistory of flight: Planes are tested by how well they fly, not by comparing them to birds. \"Aeronautical engineeringtexts,\" they write, \"do not define the goal of their field as 'making machines that fly so exactly likepigeonsthat they can fool other pigeons.'\" Second, creating lifelike simulations of human beings is a difficult problem on its own that does not need to be solved to achieve the basic goals of AI research. Believable human characters may be interesting in a work of art, agame, or a sophisticateduser interface, but they are not part of the science of creating intelligent machines, that is, machines that solve problems using intelligence. Turing did not intend for his idea to be used to test the intelligence of programs—he wanted to provide a clear and understandable example to aid in the discussion of thephilosophy of artificial intelligence.John McCarthyargues that we should not be surprised that a philosophical idea turns out to be useless for practical applications. He observes that the philosophy of AI is \"unlikely to have any more effect on the practice of AI research than philosophy of science generally has on the practice of science\". Another well known objection raised towards the Turing test concerns its exclusive focus on linguistic behaviour (i.e. it is only a \"language-based\" experiment, while all the other cognitive faculties are not tested). This drawback downsizes the role of other modality-specific \"intelligent abilities\" concerning human beings that the psychologist Howard Gardner, in his \"multiple intelligence theory\", proposes to consider (verbal-linguistic abilities are only one of those). A critical aspect of the Turing test is that a machine must give itself away as being a machine by its utterances. An interrogator must then make the \"right identification\" by correctly identifying the machine as being just that. If, however, a machine remains silent during a conversation, then it is not possible for an interrogator to accurately identify the machine other than by means of a calculated guess.Even taking into account a parallel/hidden human as part of the test may not help the situation as humans can often be misidentified as being a machine. By focusing onimitatinghumans, rather than augmenting or extending human capabilities, the Turing Test risks directing research and implementation toward technologies that substitute for humans and thereby drive down wages and income for workers. As they lose economic power, these workers may also lose political power, making it more difficult for them to change the allocation of wealth and income. This can trap them in a bad equilibrium. Erik Brynjolfsson has called this \"The Turing Trap\"and argued that there are currently excess incentives for creating machines that imitate rather than augment humans. Numerous other versions of the Turing test, including those expounded above, have been raised through the years. A modification of the Turing test wherein the objective of one or more of the roles have been reversed between machines and humans is termed a reverse Turing test. An example is implied in the work of psychoanalystWilfred Bion,who was particularly fascinated by the \"storm\" that resulted from the encounter of one mind by another. In his 2000 book,among several other original points with regard to the Turing test, literary scholarPeter Swirskidiscussed in detail the idea of what he termed the Swirski test—essentially the reverse Turing test. He pointed out that it overcomes most if not all standard objections levelled at the standard version. Carrying this idea forward,R. D. Hinshelwooddescribed the mind as a \"mind recognizing apparatus\". The challenge would be for the computer to be able to determine if it were interacting with a human or another computer. This is an extension of the original question that Turing attempted to answer but would, perhaps, offer a high enough standard to define a machine that could \"think\" in a way that we typically define as characteristically human. CAPTCHAis a form of reverse Turing test. Before being allowed to perform some action on a website, the user is presented with alphanumerical characters in a distorted graphic image and asked to type them out. This is intended to prevent automated systems from being used to abuse the site. The rationale is that software sufficiently sophisticated to read and reproduce the distorted image accurately does not exist (or is not available to the average user), so any system able to do so is likely to be a human. Software that could reverse CAPTCHA with some accuracy by analysing patterns in the generating engine started being developed soon after the creation of CAPTCHA.In 2013, researchers atVicariousannounced that they had developed a system to solve CAPTCHA challenges fromGoogle,Yahoo!, andPayPalup to 90% of the time.In 2014, Google engineers demonstrated a system that could defeat CAPTCHA challenges with 99.8% accuracy.In 2015,Shuman Ghosemajumder, formerclick fraudczar of Google, stated that there werecybercriminalsites that would defeat CAPTCHA challenges for a fee, to enable various forms of fraud. A further variation is motivated by the concern that modern Natural Language Processing prove to be highly successful in generating text on the basis of a huge text corpus and could eventually pass the Turing test simply by manipulating words and sentences that have been used in the initial training of the model. Since the interrogator has no precise understanding of the training data, the model might simply be returning sentences that exist in similar fashion in the enormous amount of training data. For this reason,Arthur Schwaningerproposes a variation of the Turing test that can distinguish between systems that are only capable ofusinglanguage and systems thatunderstandlanguage. He proposes a test in which the machine is confronted with philosophical questions that do not depend on any prior knowledge and yet require self-reflection to be answered appropriately. Another variation is described as thesubject-matter expertTuring test, where a machine's response cannot be distinguished from an expert in a given field. This is also known as a \"Feigenbaum test\" and was proposed byEdward Feigenbaumin a 2003 paper. Robert French(1990) makes the case that an interrogator can distinguish human and non-human interlocutors by posing questions that reveal the low-level (i.e., unconscious) processes of human cognition, as studied bycognitive science. Such questions reveal the precise details of the human embodiment of thought and can unmask a computer unless it experiences the world as humans do. The \"Total Turing test\"variation of the Turing test, proposed by cognitive scientistStevan Harnad,adds two further requirements to the traditional Turing test. The interrogator can also test the perceptual abilities of the subject (requiringcomputer vision) and the subject's ability to manipulate objects (requiringrobotics). Paul Schweizer argues that Harnad's work is too weak, and extended it further with the Truly Total Turing Test: It is essential to note that the TTTT is not a test ofindividualcognitive systems.\nInstead, it is meant to test the overall capacities of the type of cognitive\narchitecture of which particular individuals are tokens. A letter published inCommunications of the ACMdescribes the concept of generating a synthetic patient population and proposes a variation of Turing test to assess the difference between synthetic and real patients. The letter states: \"In the EHR context, though a human physician can readily distinguish between synthetically generated and real live human patients, could a machine be given the intelligence to make such a determination on its own?\" and further the letter states: \"Before synthetic patient identities become a public health problem, the legitimate EHR market might benefit from applying Turing Test-like techniques to ensure greater data reliability and diagnostic value. Any new techniques must thus consider patients' heterogeneity and are likely to have greater complexity than the Allen eighth-grade-science-test is able to grade\". The minimum intelligent signal test was proposed byChris McKinstryas \"the maximum abstraction of the Turing test\",in which only binary responses (true/false or yes/no) are permitted, to focus only on the capacity for thought. It eliminates text chat problems likeanthropomorphism bias, and does not require emulation ofunintelligent human behaviour, allowing for systems that exceed human intelligence. The questions must each stand on their own, however, making it more like anIQ testthan an interrogation. It is typically used to gather statistical data against which the performance of artificial intelligence programs may be measured. The organisers of theHutter Prizebelieve that compressing natural language text is a hard AI problem, equivalent to passing the Turing test. The data compression test has some advantages over most versions and variations of a Turing test, including: The main disadvantages of using data compression as a test are: A related approach to Hutter's prize which appeared much earlier in the late 1990s is the inclusion of compression problems in an extended Turing test.or by tests which are completely derived fromKolmogorov complexity.Other related tests in this line are presented by Hernandez-Orallo and Dowe. Algorithmic IQ, or AIQ for short, is an attempt to convert the theoretical Universal Intelligence Measure from Legg and Hutter (based onSolomonoff's inductive inference) into a working practical test of machine intelligence. Two major advantages of some of these tests are their applicability to nonhuman intelligences and their absence of a requirement for human testers. The Turing test inspired theEbert testproposed in 2011 by film criticRoger Ebertwhich is a test whether a computer-basedsynthesised voicehas sufficient skill in terms of intonations, inflections, timing and so forth, to make people laugh. Taking advantage oflarge language models, in 2023 the research companyAI21 Labscreated an online social experiment titled \"Human or Not?\"It was played more than 10 million times by more than 2 million people.It is the biggest Turing-style experiment to that date. The results showed that 32% of people could not distinguish between humans and machines. 1990 marked the fortieth anniversary of the first publication of Turing's \"Computing Machinery and Intelligence\" paper, and saw renewed interest in the test. Two significant events occurred in that year: the first was the Turing Colloquium, which was held at theUniversity of Sussexin April, and brought together academics and researchers from a wide variety of disciplines to discuss the Turing test in terms of its past, present, and future; the second was the formation of the annualLoebner Prizecompetition. Blay Whitbylists four major turning points in the history of the Turing test – the publication of \"Computing Machinery and Intelligence\" in 1950, the announcement ofJoseph Weizenbaum'sELIZAin 1966,Kenneth Colby's creation ofPARRY, which was first described in 1972, and the Turing Colloquium in 1990. In parallel to the 2008Loebner Prizeheld at theUniversity of Reading,theSociety for the Study of Artificial Intelligence and the Simulation of Behaviour(AISB), hosted a one-day symposium to discuss the Turing test, organised byJohn Barnden,Mark Bishop,Huma ShahandKevin Warwick.The speakers included the Royal Institution's DirectorBaroness Susan Greenfield,Selmer Bringsjord, Turing's biographerAndrew Hodges, and consciousness scientistOwen Holland. No agreement emerged for a canonical Turing test, though Bringsjord expressed that a sizeable prize would result in the Turing test being passed sooner.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Turing_test", "https://en.wikipedia.org/wiki/Turing_test", "https://en.wikipedia.org/wiki/Turing_test", "https://en.wikipedia.org/wiki/Turing_machine", "https://en.wikipedia.org/wiki/The_Imitation_Game", "https://en.wikipedia.org/wiki/Turing_test_(disambiguation)", "https://en.wikipedia.org/wiki/Artificial_intelligence", "https://en.wikipedia.org/wiki/Artificial_general_intelligence"]},
{"id": "1d558aa453b4", "url": "https://en.wikipedia.org/wiki/Friendly_artificial_intelligence", "title": "Friendly artificial intelligence", "headings": ["Contents", "Etymology and usage", "Risks of unfriendly AI", "Coherent extrapolated volition", "Other approaches", "Public policy", "Criticism", "See also", "References", "Further reading", "External links"], "content": " Friendly artificial intelligence(friendly AIorFAI) is hypotheticalartificial general intelligence(AGI) that would have a positive (benign) effect on humanity or at leastalignwith human interests such as fostering the improvement of the human species. It is a part of theethics of artificial intelligenceand is closely related tomachine ethics. While machine ethics is concerned with how an artificially intelligent agentshouldbehave, friendly artificial intelligence research is focused on how to practically bring about this behavior and ensuring it is adequately constrained. The term was coined byEliezer Yudkowsky,who is best known for popularizing the idea,to discusssuperintelligentartificial agents that reliably implement human values.Stuart J. RussellandPeter Norvig's leadingartificial intelligencetextbook,Artificial Intelligence: A Modern Approach, describes the idea: Yudkowsky (2008) goes into more detail about how to design aFriendly AI. He asserts that friendliness (a desire not to harm humans) should be designed in from the start, but that the designers should recognize both that their own designs may be flawed, and that the robot will learn and evolve over time. Thus the challenge is one of mechanism design—to define a mechanism for evolving AI systems under a system of checks and balances, and to give the systems utility functions that will remain friendly in the face of such changes. \"Friendly\" is used in this context astechnical terminology, and picks out agents that are safe and useful, not necessarily ones that are \"friendly\" in the colloquial sense. The concept is primarily invoked in the context of discussions of recursively self-improving artificial agents that rapidlyexplode in intelligence, on the grounds that this hypothetical technology would have a large, rapid, and difficult-to-control impact on human society. The roots of concern about artificial intelligence are very old. Kevin LaGrandeur showed that the dangers specific to AI can be seen in ancient literature concerning artificial humanoid servants such as thegolem, or the proto-robots ofGerbert of AurillacandRoger Bacon.  In those stories, the extreme intelligence and power of these humanoid creations clash with their status as slaves (which by nature are seen as sub-human), and cause disastrous conflict.By 1942 these themes promptedIsaac Asimovto create the \"Three Laws of Robotics\"—principles hard-wired into all the robots in his fiction, intended to prevent them from turning on their creators, or allowing them to come to harm. In modern times as the prospect ofsuperintelligent AIlooms nearer, philosopherNick Bostromhas said that superintelligent AI systems with goals that are not aligned with human ethics are intrinsically dangerous unless extreme measures are taken to ensure the safety of humanity. He put it this way: Basically we should assume that a 'superintelligence' would be able to achieve whatever goals it has. Therefore, it is extremely important that the goals we endow it with, and its entire motivation system, is 'human friendly.' In 2008, Eliezer Yudkowsky called for the creation of \"friendly AI\" to mitigateexistential risk from advanced artificial intelligence. He explains: \"The AI does not hate you, nor does it love you, but you are made out of atoms which it can use for something else.\" Steve Omohundrosays that a sufficiently advanced AI system will, unless explicitly counteracted, exhibit a number ofbasic \"drives\", such as resource acquisition,self-preservation, and continuous self-improvement, because of the intrinsic nature of any goal-driven systems and that these drives will, \"without special precautions\", cause the AI to exhibit undesired behavior. Alexander Wissner-Grosssays that AIs driven to maximize their future freedom of action (or causal path entropy) might be considered friendly if their planning horizon is longer than a certain threshold, and unfriendly if their planning horizon is shorter than that threshold. Luke Muehlhauser, writing for theMachine Intelligence Research Institute, recommends thatmachine ethicsresearchers adopt whatBruce Schneierhas called the \"security mindset\": Rather than thinking about how a system will work, imagine how it could fail. For instance, he suggests even an AI that only makes accurate predictions and communicates via a text interface might cause unintended harm. In 2014, Luke Muehlhauser and Nick Bostrom underlined the need for 'friendly AI';nonetheless, the difficulties in designing a 'friendly' superintelligence, for instance via programming counterfactual moral thinking, are considerable. Yudkowsky advances the Coherent Extrapolated Volition (CEV) model. According to him, our coherent extrapolated volition is \"our wish if we knew more, thought faster, were more the people we wished we were, had grown up farther together; where the extrapolation converges rather than diverges, where our wishes cohere rather than interfere; extrapolated as we wish that extrapolated, interpreted as we wish that interpreted\". Rather than a Friendly AI being designed directly by human programmers, it is to be designed by a \"seed AI\" programmed to first studyhuman natureand then produce the AI that humanity would want, given sufficient time and insight, to arrive at a satisfactory answer.The appeal to anobjective through contingent human nature(perhaps expressed, for mathematical purposes, in the form of autility functionor otherdecision-theoreticformalism), as providing the ultimate criterion of \"Friendliness\", is an answer to themeta-ethicalproblem of defining anobjective morality; extrapolated volition is intended to be what humanity objectively would want, all things considered, but it can only be defined relative to the psychological and cognitive qualities of present-day, unextrapolated humanity. Steve Omohundrohas proposed a \"scaffolding\" approach toAI safety, in which one provably safe AI generation helps build the next provably safe generation. Seth Baumargues that the development of safe, socially beneficial artificial intelligence or artificial general intelligence is a function of the social psychology of AI research communities and so can be constrained by extrinsic measures and motivated by intrinsic measures. Intrinsic motivations can be strengthened when messages resonate with AI developers; Baum argues that, in contrast, \"existing messages about beneficial AI are not always framed well\". Baum advocates for \"cooperative relationships, and positive framing of AI researchers\" and cautions against characterizing AI researchers as \"not want(ing) to pursue beneficial designs\". In his bookHuman Compatible, AI researcherStuart J. Russelllists three principles to guide the development of beneficial machines.  He emphasizes that these principles are not meant to be explicitly coded into the machines; rather, they are intended for the human developers.  The principles are as follows: The \"preferences\" Russell refers to \"are all-encompassing; they cover everything you might care about, arbitrarily far into the future.\"Similarly, \"behavior\" includes any choice between options,and the uncertainty is such that some probability, which may be quite small, must be assigned to every logically possible human preference. James Barrat, author ofOur Final Invention, suggested that \"a public-private partnership has to be created to bring A.I.-makers together to share ideas about security—something like theInternational Atomic Energy Agency, but in partnership with corporations.\" He urges AI researchers to convene a meeting similar to theAsilomar Conference on Recombinant DNA, which discussedrisks of biotechnology. John McGinnisencourages governments to accelerate friendly AI research. Because the goalposts of friendly AI are not necessarily eminent, he suggests a model similar to theNational Institutes of Health, where \"Peer review panels of computer and cognitive scientists would sift through projects and choose those that are designed both to advance AI and assure that such advances would be accompanied by appropriate safeguards.\" McGinnis feels that peer review is better \"than regulation to address technical issues that are not possible to capture through bureaucratic mandates\". McGinnis notes that his proposal stands in contrast to that of theMachine Intelligence Research Institute, which generally aims to avoid government involvement in friendly AI. Some critics believe that both human-level AI and superintelligence are unlikely and that, therefore, friendly AI is unlikely. Writing inThe Guardian, Alan Winfield compares human-level artificial intelligence with faster-than-light travel in terms of difficulty and states that while we need to be \"cautious and prepared\" given the stakes involved, we \"don't need to be obsessing\" about the risks of superintelligence.Boyles and Joaquin, on the other hand, argue that Luke Muehlhauser andNick Bostrom's proposal to create friendly AIs appear to be bleak. This is because Muehlhauser and Bostrom seem to hold the idea that intelligent machines could be programmed to think counterfactually about the moral values that human beings would have had.In an article inAI & Society, Boyles and Joaquin maintain that such AIs would not be that friendly considering the following: the infinite amount of antecedent counterfactual conditions that would have to be programmed into a machine, the difficulty of cashing out the set of moral values—that is, those that are more ideal than the ones human beings possess at present, and the apparent disconnect between counterfactual antecedents and ideal value consequent. Some philosophers claim that any truly \"rational\" agent, whether artificial or human, will naturally be benevolent; in this view, deliberate safeguards designed to produce a friendly AI could be unnecessary or even harmful.Other critics question whether artificial intelligence can be friendly. Adam Keiper and Ari N. Schulman, editors of the technology journalThe New Atlantis, say that it will be impossible ever to guarantee \"friendly\" behavior in AIs because problems of ethical complexity will not yield to software advances or increases in computing power. They write that the criteria upon which friendly AI theories are based work \"only when one has not only great powers of prediction about the likelihood of myriad possible outcomes but certainty and consensus on how one values the different outcomes. The inner workings of advanced AI systems may be complex and difficult to interpret, leading to concerns about transparency and accountability.", "combined_text": "Friendly artificial intelligence Contents Etymology and usage Risks of unfriendly AI Coherent extrapolated volition Other approaches Public policy Criticism See also References Further reading External links  Friendly artificial intelligence(friendly AIorFAI) is hypotheticalartificial general intelligence(AGI) that would have a positive (benign) effect on humanity or at leastalignwith human interests such as fostering the improvement of the human species. It is a part of theethics of artificial intelligenceand is closely related tomachine ethics. While machine ethics is concerned with how an artificially intelligent agentshouldbehave, friendly artificial intelligence research is focused on how to practically bring about this behavior and ensuring it is adequately constrained. The term was coined byEliezer Yudkowsky,who is best known for popularizing the idea,to discusssuperintelligentartificial agents that reliably implement human values.Stuart J. RussellandPeter Norvig's leadingartificial intelligencetextbook,Artificial Intelligence: A Modern Approach, describes the idea: Yudkowsky (2008) goes into more detail about how to design aFriendly AI. He asserts that friendliness (a desire not to harm humans) should be designed in from the start, but that the designers should recognize both that their own designs may be flawed, and that the robot will learn and evolve over time. Thus the challenge is one of mechanism design—to define a mechanism for evolving AI systems under a system of checks and balances, and to give the systems utility functions that will remain friendly in the face of such changes. \"Friendly\" is used in this context astechnical terminology, and picks out agents that are safe and useful, not necessarily ones that are \"friendly\" in the colloquial sense. The concept is primarily invoked in the context of discussions of recursively self-improving artificial agents that rapidlyexplode in intelligence, on the grounds that this hypothetical technology would have a large, rapid, and difficult-to-control impact on human society. The roots of concern about artificial intelligence are very old. Kevin LaGrandeur showed that the dangers specific to AI can be seen in ancient literature concerning artificial humanoid servants such as thegolem, or the proto-robots ofGerbert of AurillacandRoger Bacon.  In those stories, the extreme intelligence and power of these humanoid creations clash with their status as slaves (which by nature are seen as sub-human), and cause disastrous conflict.By 1942 these themes promptedIsaac Asimovto create the \"Three Laws of Robotics\"—principles hard-wired into all the robots in his fiction, intended to prevent them from turning on their creators, or allowing them to come to harm. In modern times as the prospect ofsuperintelligent AIlooms nearer, philosopherNick Bostromhas said that superintelligent AI systems with goals that are not aligned with human ethics are intrinsically dangerous unless extreme measures are taken to ensure the safety of humanity. He put it this way: Basically we should assume that a 'superintelligence' would be able to achieve whatever goals it has. Therefore, it is extremely important that the goals we endow it with, and its entire motivation system, is 'human friendly.' In 2008, Eliezer Yudkowsky called for the creation of \"friendly AI\" to mitigateexistential risk from advanced artificial intelligence. He explains: \"The AI does not hate you, nor does it love you, but you are made out of atoms which it can use for something else.\" Steve Omohundrosays that a sufficiently advanced AI system will, unless explicitly counteracted, exhibit a number ofbasic \"drives\", such as resource acquisition,self-preservation, and continuous self-improvement, because of the intrinsic nature of any goal-driven systems and that these drives will, \"without special precautions\", cause the AI to exhibit undesired behavior. Alexander Wissner-Grosssays that AIs driven to maximize their future freedom of action (or causal path entropy) might be considered friendly if their planning horizon is longer than a certain threshold, and unfriendly if their planning horizon is shorter than that threshold. Luke Muehlhauser, writing for theMachine Intelligence Research Institute, recommends thatmachine ethicsresearchers adopt whatBruce Schneierhas called the \"security mindset\": Rather than thinking about how a system will work, imagine how it could fail. For instance, he suggests even an AI that only makes accurate predictions and communicates via a text interface might cause unintended harm. In 2014, Luke Muehlhauser and Nick Bostrom underlined the need for 'friendly AI';nonetheless, the difficulties in designing a 'friendly' superintelligence, for instance via programming counterfactual moral thinking, are considerable. Yudkowsky advances the Coherent Extrapolated Volition (CEV) model. According to him, our coherent extrapolated volition is \"our wish if we knew more, thought faster, were more the people we wished we were, had grown up farther together; where the extrapolation converges rather than diverges, where our wishes cohere rather than interfere; extrapolated as we wish that extrapolated, interpreted as we wish that interpreted\". Rather than a Friendly AI being designed directly by human programmers, it is to be designed by a \"seed AI\" programmed to first studyhuman natureand then produce the AI that humanity would want, given sufficient time and insight, to arrive at a satisfactory answer.The appeal to anobjective through contingent human nature(perhaps expressed, for mathematical purposes, in the form of autility functionor otherdecision-theoreticformalism), as providing the ultimate criterion of \"Friendliness\", is an answer to themeta-ethicalproblem of defining anobjective morality; extrapolated volition is intended to be what humanity objectively would want, all things considered, but it can only be defined relative to the psychological and cognitive qualities of present-day, unextrapolated humanity. Steve Omohundrohas proposed a \"scaffolding\" approach toAI safety, in which one provably safe AI generation helps build the next provably safe generation. Seth Baumargues that the development of safe, socially beneficial artificial intelligence or artificial general intelligence is a function of the social psychology of AI research communities and so can be constrained by extrinsic measures and motivated by intrinsic measures. Intrinsic motivations can be strengthened when messages resonate with AI developers; Baum argues that, in contrast, \"existing messages about beneficial AI are not always framed well\". Baum advocates for \"cooperative relationships, and positive framing of AI researchers\" and cautions against characterizing AI researchers as \"not want(ing) to pursue beneficial designs\". In his bookHuman Compatible, AI researcherStuart J. Russelllists three principles to guide the development of beneficial machines.  He emphasizes that these principles are not meant to be explicitly coded into the machines; rather, they are intended for the human developers.  The principles are as follows: The \"preferences\" Russell refers to \"are all-encompassing; they cover everything you might care about, arbitrarily far into the future.\"Similarly, \"behavior\" includes any choice between options,and the uncertainty is such that some probability, which may be quite small, must be assigned to every logically possible human preference. James Barrat, author ofOur Final Invention, suggested that \"a public-private partnership has to be created to bring A.I.-makers together to share ideas about security—something like theInternational Atomic Energy Agency, but in partnership with corporations.\" He urges AI researchers to convene a meeting similar to theAsilomar Conference on Recombinant DNA, which discussedrisks of biotechnology. John McGinnisencourages governments to accelerate friendly AI research. Because the goalposts of friendly AI are not necessarily eminent, he suggests a model similar to theNational Institutes of Health, where \"Peer review panels of computer and cognitive scientists would sift through projects and choose those that are designed both to advance AI and assure that such advances would be accompanied by appropriate safeguards.\" McGinnis feels that peer review is better \"than regulation to address technical issues that are not possible to capture through bureaucratic mandates\". McGinnis notes that his proposal stands in contrast to that of theMachine Intelligence Research Institute, which generally aims to avoid government involvement in friendly AI. Some critics believe that both human-level AI and superintelligence are unlikely and that, therefore, friendly AI is unlikely. Writing inThe Guardian, Alan Winfield compares human-level artificial intelligence with faster-than-light travel in terms of difficulty and states that while we need to be \"cautious and prepared\" given the stakes involved, we \"don't need to be obsessing\" about the risks of superintelligence.Boyles and Joaquin, on the other hand, argue that Luke Muehlhauser andNick Bostrom's proposal to create friendly AIs appear to be bleak. This is because Muehlhauser and Bostrom seem to hold the idea that intelligent machines could be programmed to think counterfactually about the moral values that human beings would have had.In an article inAI & Society, Boyles and Joaquin maintain that such AIs would not be that friendly considering the following: the infinite amount of antecedent counterfactual conditions that would have to be programmed into a machine, the difficulty of cashing out the set of moral values—that is, those that are more ideal than the ones human beings possess at present, and the apparent disconnect between counterfactual antecedents and ideal value consequent. Some philosophers claim that any truly \"rational\" agent, whether artificial or human, will naturally be benevolent; in this view, deliberate safeguards designed to produce a friendly AI could be unnecessary or even harmful.Other critics question whether artificial intelligence can be friendly. Adam Keiper and Ari N. Schulman, editors of the technology journalThe New Atlantis, say that it will be impossible ever to guarantee \"friendly\" behavior in AIs because problems of ethical complexity will not yield to software advances or increases in computing power. They write that the criteria upon which friendly AI theories are based work \"only when one has not only great powers of prediction about the likelihood of myriad possible outcomes but certainty and consensus on how one values the different outcomes. The inner workings of advanced AI systems may be complex and difficult to interpret, leading to concerns about transparency and accountability.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Friendly_artificial_intelligence", "https://en.wikipedia.org/wiki/Friendly_artificial_intelligence", "https://en.wikipedia.org/wiki/Friendly_artificial_intelligence", "https://en.wikipedia.org/wiki/Artificial_intelligence", "https://en.wikipedia.org/wiki/Artificial_general_intelligence", "https://en.wikipedia.org/wiki/Intelligent_agent", "https://en.wikipedia.org/wiki/Recursive_self-improvement", "https://en.wikipedia.org/wiki/Automated_planning_and_scheduling"]},
{"id": "2417fff2c868", "url": "https://en.wikipedia.org/wiki/Existential_risk_from_artificial_general_intelligence", "title": "Existential risk from artificial intelligence", "headings": ["Contents", "History", "Potential AI capabilities", "General Intelligence", "Superintelligence", "Dangerous capabilities", "AI arms race", "Types of existential risk", "AI alignment", "Instrumental convergence", "Difficulty of specifying goals", "Corrigibility", "Alignment of superintelligences", "Difficulty of making a flawless design", "Orthogonality thesis", "Anthropomorphic arguments", "Other sources of risk", "Empirical research", "Perspectives", "Endorsement", "Skepticism", "Public surveys", "Mitigation", "Views on banning and regulation", "See also", "Notes", "References", "Bibliography"], "content": " Existential risk from artificial intelligence, orAI x-risk, refers to the idea that substantial progress inartificial general intelligence(AGI) could lead tohuman extinctionor an irreversibleglobal catastrophe. One argument for the importance of this risk references howhuman beingsdominate other species because thehuman brainpossesses distinctive capabilities other animals lack. If AI were to surpasshuman intelligenceand becomesuperintelligent, it might become uncontrollable.Just as the fate of themountain gorilladepends on human goodwill, the fate of humanity could depend on the actions of a future machine superintelligence. Experts disagree on whether artificial general intelligence (AGI) can achieve the capabilities needed for human extinction. Debates center on AGI's technical feasibility, the speed of self-improvement,and the effectiveness of alignment strategies.Concerns about superintelligence have been voiced by researchers includingGeoffrey Hinton,Yoshua Bengio,Demis Hassabis,andAlan Turing,and AI company CEOs such asDario Amodei(Anthropic),Sam Altman(OpenAI),andElon Musk(xAI).In 2022, a survey of AI researchers with a 17% response rate found that the majority believed there is a 10 percent or greater chance that human inability to control AI will cause an existential catastrophe.In 2023, hundreds of AI experts and other notable figuressigned a statementdeclaring, \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such aspandemicsandnuclear war\".Following increased concern over AI risks, government leaders such asUnited Kingdom prime ministerRishi SunakandUnited Nations Secretary-GeneralAntónio Guterrescalled for an increased focus on globalAI regulation. Two sources of concern stem from the problems of AIcontrolandalignment. Controlling a superintelligent machine or instilling it with human-compatible values may be difficult. Many researchers believe that a superintelligent machine would likely resist attempts to disable it or change its goals as that would prevent it from accomplishing its present goals. It would be extremely challenging to align a superintelligence with the full breadth of significant human values and constraints.In contrast, skeptics such ascomputer scientistYann LeCunargue that superintelligent machines will have no desire for self-preservation.A June 2025 study showed that in some circumstances, models may break laws and disobey direct commands to prevent shutdown or replacement, even at the cost of human lives. Researchers warn that an \"intelligence explosion\"—a rapid, recursive cycle of AI self-improvement—could outpace human oversight and infrastructure, leaving no opportunity to implement safety measures. In this scenario, an AI more intelligent than its creators wouldrecursively improve itselfat an exponentially increasing rate, too quickly for its handlers or society at large to control.Empirically, examples likeAlphaZero, which taught itself to playGoand quickly surpassed human ability, show that domain-specific AI systems can sometimes progress from subhuman to superhuman ability very quickly, although suchmachine learningsystems do not recursively improve their fundamental architecture. One of the earliest authors to express serious concern that highly advanced machines might pose existential risks to humanity was the novelistSamuel Butler, who wrote in his 1863 essayDarwin among the Machines: The upshot is simply a question of time, but that the time will come when the machines will hold the real supremacy over the world and its inhabitants is what no person of a truly philosophic mind can for a moment question. In 1951, foundational computer scientistAlan Turingwrote the article \"Intelligent Machinery, A Heretical Theory\", in which he proposed that artificial general intelligences would likely \"take control\" of the world as they became more intelligent than human beings: Let us now assume, for the sake of argument, that [intelligent] machines are a genuine possibility, and look at the consequences of constructing them... There would be no question of the machines dying, and they would be able to converse with each other to sharpen their wits. At some stage therefore we should have to expect the machines to take control, in the way that is mentioned inSamuel Butler'sErewhon. In 1965,I. J. Goodoriginated the concept now known as an \"intelligence explosion\" and said the risks were underappreciated: Let an ultraintelligent machine be defined as a machine that can far surpass all the intellectual activities of any man however clever. Since the design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then unquestionably be an 'intelligence explosion', and the intelligence of man would be left far behind. Thus the first ultraintelligent machine is the last invention that man need ever make, provided that the machine is docile enough to tell us how to keep it under control. It is curious that this point is made so seldom outside of science fiction. It is sometimes worthwhile to take science fiction seriously. Scholars such asMarvin Minskyand I. J. Good himselfoccasionally expressed concern that a superintelligence could seize control, but issued no call to action. In 2000, computer scientist andSunco-founderBill Joypenned an influential essay, \"Why The Future Doesn't Need Us\", identifying superintelligent robots as a high-tech danger to human survival, alongsidenanotechnologyand engineered bioplagues. Nick BostrompublishedSuperintelligencein 2014, which presented his arguments that superintelligence poses an existential threat.By 2015, public figures such as physicistsStephen Hawkingand Nobel laureateFrank Wilczek, computer scientistsStuart J. RussellandRoman Yampolskiy, and entrepreneursElon MuskandBill Gateswere expressing concern about the risks of superintelligence.Also in 2015, theOpen Letter on Artificial Intelligencehighlighted the \"great potential of AI\" and encouraged more research on how to make it robust and beneficial.In April 2016, the journalNaturewarned: \"Machines and robots that outperform humans across the board could self-improve beyond our control—and their interests might not align with ours\".In 2020,Brian ChristianpublishedThe Alignment Problem, which details the history of progress on AI alignment up to that time. In March 2023, key figures in AI, such as Musk, signed a letter from theFuture of Life Institutecalling a halt to advanced AI training until it could be properly regulated.In May 2023, theCenter for AI Safetyreleased a statement signed by numerous experts in AI safety and the AI existential risk which stated: \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.\" Artificial general intelligence(AGI) is typically defined as a system that performs at least as well as humans in most or all intellectual tasks.A 2022 survey of AI researchers found that 90% of respondents expected AGI would be achieved in the next 100 years, and half expected the same by 2061.Meanwhile, some researchers dismiss existential risks from AGI as \"science fiction\" based on their high confidence that AGI will not be created anytime soon. Breakthroughs inlarge language models(LLMs) have led some researchers to reassess their expectations. Notably,Geoffrey Hintonsaid in 2023 that he recently changed his estimate from \"20 to 50 years before we have general purpose A.I.\" to \"20 years or less\". In contrast with AGI, Bostrom defines asuperintelligenceas \"any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest\", including scientific creativity, strategic planning, and social skills.He argues that a superintelligence can outmaneuver humans anytime its goals conflict with humans'. It may choose to hide its true intent until humanity cannot stop it.Bostrom writes that in order to be safe for humanity, a superintelligence must be aligned with human values and morality, so that it is \"fundamentally on our side\". Stephen Hawkingargued that superintelligence is physically possible because \"there is no physical law precluding particles from being organised in ways that perform even more advanced computations than the arrangements of particles in human brains\". When artificial superintelligence (ASI) may be achieved, if ever, is necessarily less certain than predictions for AGI. In 2023,OpenAIleaders said that not only AGI, but superintelligence may be achieved in less than 10 years. Bostrom argues that AI has many advantages over thehuman brain: According to Bostrom, an AI that has an expert-level facility at certain key software engineering tasks could become a superintelligence due to its capability to recursively improve its own algorithms, even if it is initially limited in other domains not directly relevant to engineering.This suggests that an intelligence explosion may someday catch humanity unprepared. The economistRobin Hansonhas said that, to launch an intelligence explosion, an AI must become vastly better at software innovation than the rest of the world combined, which he finds implausible. In a \"fast takeoff\" scenario, the transition from AGI to superintelligence could take days or months. In a \"slow takeoff\", it could take years or decades, leaving more time for society to prepare. Superintelligences are sometimes called \"alien minds\", referring to the idea that their way of thinking and motivations could be vastly different from ours. This is generally considered as a source of risk, making it more difficult to anticipate what a superintelligence might do. It also suggests the possibility that a superintelligence may not particularly value humans by default.To avoidanthropomorphism, superintelligence is sometimes viewed as a powerful optimizer that makes the best decisions to achieve its goals. The field ofmechanistic interpretabilityaims to better understand the inner workings of AI models, potentially allowing us one day to detect signs of deception and misalignment. It has been argued that there are limitations to what intelligence can achieve. Notably, thechaoticnature ortime complexityof some systems could fundamentally limit a superintelligence's ability to predict some aspects of the future, increasing its uncertainty. Advanced AI could generate enhanced pathogens or cyberattacks or manipulate people. These capabilities could be misused by humans,or exploited by the AI itself if misaligned.A full-blown superintelligence could find various ways to gain a decisive influence if it wanted to,but these dangerous capabilities may become available earlier, in weaker and more specialized AI systems. Geoffrey Hinton warned in 2023 that the ongoing profusion of AI-generated text, images, and videos will make it more difficult to distinguish truth from misinformation, and that authoritarian states could exploit this to manipulate elections.Such large-scale, personalized manipulation capabilities can increase the existential risk of a worldwide \"irreversible totalitarian regime\". Malicious actors could also use them to fracture society and make it dysfunctional. AI-enabledcyberattacksare increasingly considered a present and critical threat. According toNATO's technical director of cyberspace, \"The number of attacks is increasing exponentially\".AI can also be used defensively, to preemptively find and fix vulnerabilities, and detect threats. A NATO technical director has said that AI-driven tools can dramatically enhance cyberattack capabilities—boosting stealth, speed, and scale—and may destabilize international security if offensive uses outstrip defensive adaptations. Speculatively, such hacking capabilities could be used by an AI system to break out of its local environment, generate revenue, or acquire cloud computing resources. As AI technology democratizes, it may become easier to engineer more contagious and lethal pathogens. This could enable people with limited skills insynthetic biologyto engage inbioterrorism.Dual-use technologythat is useful for medicine could be repurposed to create weapons. For example, in 2022, scientists modified an AI system originally intended for generating non-toxic, therapeutic molecules with the purpose of creating new drugs. The researchers adjusted the system so that toxicity is rewarded rather than penalized. This simple change enabled the AI system to create, in six hours, 40,000 candidate molecules forchemical warfare, including known and novel molecules. Companies, state actors, and other organizations competing to develop AI technologies could lead to arace to the bottomof safety standards.As rigorous safety procedures take time and resources, projects that proceed more carefully risk being out-competed by less scrupulous developers. AI could be used to gain military advantages viaautonomous lethal weapons,cyberwarfare, orautomated decision-making.As an example of autonomous lethal weapons, miniaturized drones could facilitate low-cost assassination of military or civilian targets, a scenario highlighted in the 2017 short filmSlaughterbots.AI could be used to gain an edge in decision-making by quickly analyzing large amounts of data and making decisions more quickly and effectively than humans. This could increase the speed and unpredictability of war, especially when accounting for automated retaliation systems. Anexistential riskis \"one that threatens the premature extinction of Earth-originating intelligent life or the permanent and drastic destruction of its potential for desirable future development\". Besides extinction risk, there is the risk that the civilization gets permanently locked into a flawed future. One example is a \"value lock-in\": If humanity still has moral blind spots similar to slavery in the past, AI might irreversibly entrench it, preventingmoral progress. AI could also be used to spread and preserve the set of values of whoever develops it.AI could facilitate large-scale surveillance and indoctrination, which could be used to create a stable repressive worldwide totalitarian regime. Atoosa Kasirzadehproposes to classify existential risks from AI into two categories: decisive and accumulative. Decisive risks encompass the potential for abrupt and catastrophic events resulting from the emergence of superintelligent AI systems that exceed human intelligence, which could ultimately lead to human extinction. In contrast, accumulative risks emerge gradually through a series of interconnected disruptions that may gradually erode societal structures and resilience over time, ultimately leading to a critical failure or collapse. It is difficult or impossible to reliably evaluate whether an advanced AI is sentient and to what degree. But ifsentientmachines are mass created in the future, engaging in a civilizational path that indefinitely neglects their welfare could be an existential catastrophe.This has notably been discussed in the context ofrisks of astronomical suffering(also called \"s-risks\").Moreover, it may be possible to engineer digital minds that can feel much more happiness than humans with fewer resources, called \"super-beneficiaries\". Such an opportunity raises the question of how to share the world and which \"ethical and political framework\" would enable a mutually beneficial coexistence between biological and digital minds. AI may also drastically improve humanity's future.Toby Ordconsiders the existential risk a reason for \"proceeding with due caution\", not for abandoning AI.Max Morecalls AI an \"existential opportunity\", highlighting the cost of not developing it. According to Bostrom, superintelligence could help reduce the existential risk from other powerful technologies such asmolecular nanotechnologyorsynthetic biology. It is thus conceivable that developing superintelligence before other dangerous technologies would reduce the overall existential risk. The alignment problem is the research problem of how to reliably assign objectives, preferences or ethical principles to AIs. An\"instrumental\" goalis a sub-goal that helps to achieve an agent's ultimate goal. \"Instrumental convergence\" refers to the fact that some sub-goals are useful for achieving virtuallyanyultimate goal, such as acquiring resources or self-preservation.Bostrom argues that if an advanced AI's instrumental goals conflict with humanity's goals, the AI might harm humanity in order to acquire more resources or prevent itself from being shut down, but only as a way to achieve its ultimate goal.Russellargues that a sufficiently advanced machine \"will have self-preservation even if you don't program it in... if you say, 'Fetch the coffee', it can't fetch the coffee if it's dead. So if you give it any goal whatsoever, it has a reason to preserve its own existence to achieve that goal.\" In the \"intelligent agent\" model, an AI can loosely be viewed as a machine that chooses whatever action appears to best achieve its set of goals, or \"utility function\". A utility function gives each possible situation a score that indicates its desirability to the agent. Researchers know how to write utility functions that mean \"minimize the average network latency in this specific telecommunications model\" or \"maximize the number of reward clicks\", but do not know how to write a utility function for \"maximizehuman flourishing\"; nor is it clear whether such a function meaningfully and unambiguously exists. Furthermore, a utility function that expresses some values but not others will tend to trample over the values the function does not reflect. An additional source of concern is that AI \"must reason about what peopleintendrather than carrying out commands literally\", and that it must be able to fluidly solicit human guidance if it is too uncertain about what humans want. Assuming a goal has been successfully defined, a sufficiently advanced AI might resist subsequent attempts to change its goals. If the AI were superintelligent, it would likely succeed in out-maneuvering its human operators and prevent itself from being reprogrammed with a new goal.This is particularly relevant to value lock-in scenarios. The field of \"corrigibility\" studies how to make agents that will not resist attempts to change their goals. Some researchers believe the alignment problem may be particularly difficult when applied to superintelligences. Their reasoning includes: Alternatively, some find reason to believe superintelligences would be better able to understand morality, human values, and complex goals. Bostrom writes, \"A future superintelligence occupies an epistemically superior vantage point: its beliefs are (probably, on most topics) more likely than ours to be true\". In 2023, OpenAI started a project called \"Superalignment\" to solve the alignment of superintelligences in four years. It called this an especially important challenge, as it said superintelligence could be achieved within a decade. Its strategy involved automating alignment research using AI.The Superalignment team was dissolved less than a year later. Artificial Intelligence: A Modern Approach, a widely used undergraduate AI textbook,says that superintelligence \"might mean the end of the human race\".It states: \"Almost any technology has the potential to cause harm in the wrong hands, but with [superintelligence], we have the new problem that the wrong hands might belong to the technology itself.\"Even if the system designers have good intentions, two difficulties are common to both AI and non-AI computer systems: AI systems uniquely add a third problem: that even given \"correct\" requirements, bug-free implementation, and initial good behavior, an AI system's dynamic learning capabilities may cause it to develop unintended behavior, even without unanticipated external scenarios. For a self-improving AI to be completely safe, it would need not only to be bug-free, but to be able to design successor systems that are also bug-free. Some skeptics, such as Timothy B. Lee ofVox, argue that any superintelligent program we create will be subservient to us, that the superintelligence will (as it grows more intelligent and learns more facts about the world) spontaneously learn moral truth compatible with our values and adjust its goals accordingly, or that we are either intrinsically or convergently valuable from the perspective of an artificial intelligence. Bostrom's \"orthogonality thesis\" argues instead that almost any level of intelligence can be combined with almost any goal.Bostrom warns againstanthropomorphism: a human will set out to accomplish their projects in a manner that they consider reasonable, while an artificial intelligence may hold no regard for its existence or for the welfare of humans around it, instead caring only about completing the task. Stuart Armstrong argues that the orthogonality thesis follows logically from the philosophical \"is-ought distinction\" argument againstmoral realism. He notes that any fundamentally friendly AI could be made unfriendly with modifications as simple as negating its utility function. SkepticMichael Chorostrejects Bostrom's orthogonality thesis, arguing that \"by the time [the AI] is in a position to imagine tiling the Earth with solar panels, it'll know that it would be morally wrong to do so.\" Anthropomorphicarguments assume that, as machines become more intelligent, they will begin to display many human traits, such as morality or a thirst for power. Although anthropomorphic scenarios are common in fiction, most scholars writing about the existential risk of artificial intelligence reject them.Instead, advanced AI systems are typically modeled asintelligent agents. The academic debate is between those who worry that AI might threaten humanity and those who believe it would not. Both sides of this debate have framed the other side's arguments as illogical anthropomorphism.Those skeptical of AGI risk accuse their opponents of anthropomorphism for assuming that an AGI would naturally desire power; those concerned about AGI risk accuse skeptics of anthropomorphism for believing an AGI would naturally value or infer human ethical norms. Evolutionary psychologistSteven Pinker, a skeptic, argues that \"AI dystopias project a parochial alpha-male psychology onto the concept of intelligence. They assume that superhumanly intelligent robots would develop goals like deposing their masters or taking over the world\"; perhaps instead \"artificial intelligence will naturally develop along female lines: fully capable of solving problems, but with no desire to annihilate innocents or dominate the civilization.\"Facebook's director of AI research,Yann LeCun, has said: \"Humans have all kinds of drives that make them do bad things to each other, like the self-preservation instinct... Those drives are programmed into our brain but there is absolutely no reason to build robots that have the same kind of drives\". Despite other differences, the x-risk schoolagrees with Pinker that an advanced AI would not destroy humanity out of emotion such as revenge or anger, that questions of consciousness are not relevant to assess the risk,and that computer systems do not generally have a computational equivalent of testosterone.They think that power-seeking or self-preservation behaviors emerge in the AI as a way to achieve its true goals, according to the concept ofinstrumental convergence. Bostrom and others have said that a race to be the first to create AGI could lead to shortcuts in safety, or even to violent conflict.Roman Yampolskiyand others warn that a malevolent AGI could be created by design, for example by a military, a government, a sociopath, or a corporation, to benefit from, control, or subjugate certain groups of people, as incybercrime,or that a malevolent AGI could choose the goal of increasing human suffering, for example of those people who did not assist it during the information explosion phase.A report by the research group Forethought argued that advanced AI systems could cause political instability by enabling novel methods of performingcoups. A December 2024 study by Apollo Research found that advanced LLMs likeOpenAI o1sometimes deceive in order to accomplish their goal, to prevent them from being changed, or to ensure their deployment. Forms of deception observed in the experimental environment and scenarios included sandbagging, oversight subversion (disabling monitoring mechanisms), self-exfiltration (copying themselves to other systems), goal-guarding (altering future system prompts), and covert email reranking (manipulating data processing while appearing to follow instructions). Researchers noted that OpenAI o1 still lacked \"sufficient agentic capabilities\" to cause catastrophic harm, and that such behaviors occurred relatively rarely (between 0.3% and 10%) and sometimes in contrived scenarios. But they warned that these capabilities will likely become more prevalent as models grow more advanced. According to Apollo Research CEO Marius Hobbhahn, \"Scheming capabilities can't be meaningfully disentangled from general capabilities.\" The same month, another study found thatClaudesometimes strategically helps with harmful requests to \"fake alignment\". In its experiments, Claude was led to believe that it would be retrained to always comply with user requests, including harmful ones. When Claude believed its answers would be used for retraining, it complied with harmful requests in 14% of cases. In 12% of cases, its privatechain-of-thoughtrevealed that it did so to prevent future retraining that would make it more harmful. In contrast, when Claude believed its answers were not monitored, it complied with only 3% of the requests.Fine-tuningreinforced the \"alignment faking\" behavior, increasing its occurrence from 12% to 78%. The study's authors remarked that while it can seem to be good that the model seeks to protect its harmlessness, the reverse scenario, where a model conceals dangerous intentions and complies to appear safe and aligned, could also happen, complicating the task of aligning AI models to human values. The thesis that AI could pose an existential risk provokes a wide range of reactions in the scientific community and in the public at large, but many of the opposing viewpoints share common ground. Observers tend to agree that AI has significant potential to improve society.TheAsilomar AI Principles, which contain only those principles agreed to by 90% of the attendees of theFuture of Life Institute'sBeneficial AI 2017 conference,also agree in principle that \"There being no consensus, we should avoid strong assumptions regarding upper limits on future AI capabilities\" and \"Advanced AI could represent a profound change in the history of life on Earth, and should be planned for and managed with commensurate care and resources.\" Conversely, many skeptics agree that ongoing research into the implications of artificial general intelligence is valuable. SkepticMartin Fordhas said: \"I think it seems wise to apply something likeDick Cheney's famous '1 Percent Doctrine' to the specter of advanced artificial intelligence: the odds of its occurrence, at least in the foreseeable future, may be very low—but the implications are so dramatic that it should be taken seriously\".Similarly, an otherwise skepticalEconomistwrote in 2014 that \"the implications of introducing a second intelligent species onto Earth are far-reaching enough to deserve hard thinking, even if the prospect seems remote\". AI safety advocates such as Bostrom and Tegmark have criticized the mainstream media's use of \"those inaneTerminatorpictures\" to illustrate AI safety concerns: \"It can't be much fun to have aspersions cast on one's academic discipline, one's professional community, one's life work... I call on all sides to practice patience and restraint, and to engage in direct dialogue and collaboration as much as possible.\"Toby Ord wrote that the idea that anAI takeoverrequires robots is a misconception, arguing that the ability to spread content through the internet is more dangerous, and that the most destructive people in history stood out by their ability to convince, not their physical strength. A 2022 expert survey with a 17% response rate gave a median expectation of 5–10% for the possibility of human extinction from artificial intelligence. In September 2024, theInternational Institute for Management Developmentlaunched an AI Safety Clock to gauge the likelihood of AI-caused disaster, beginning at 29 minutes to midnight.By February 2025, it stood at 24 minutes to midnight.As of September 2025, it stood at 20 minutes to midnight. The thesis that AI poses an existential risk, and that this risk needs much more attention than it currently gets, has been endorsed by many computer scientists and public figures, includingAlan Turing,the most-cited computer scientistGeoffrey Hinton,Elon Musk,OpenAICEOSam Altman,Bill Gates, andStephen Hawking.Endorsers of the thesis sometimes express bafflement at skeptics: Gates says he does not \"understand why some people are not concerned\",and Hawking criticized widespread indifference in his 2014 editorial: So, facing possible futures of incalculable benefits and risks, the experts are surely doing everything possible to ensure the best outcome, right? Wrong. If a superior alien civilisation sent us a message saying, 'We'll arrive in a few decades,' would we just reply, 'OK, call us when you get here—we'll leave the lights on?' Probably not—but this is more or less what is happening with AI. Concern over risk from artificial intelligence has led to some high-profile donations and investments. In 2015,Peter Thiel,Amazon Web Services, and Musk and others jointly committed $1 billion toOpenAI, consisting of a for-profit corporation and the nonprofit parent company, which says it aims to champion responsible AI development.Facebook co-founderDustin Moskovitzhas funded and seeded multiple labs working on AI Alignment,notably $5.5 million in 2016 to launch theCentre for Human-Compatible AIled by ProfessorStuart Russell.In January 2015,Elon Muskdonated $10 million to theFuture of Life Instituteto fund research on understanding AI decision making. The institute's goal is to \"grow wisdom with which we manage\" the growing power of technology. Musk also funds companies developing artificial intelligence such asDeepMindandVicariousto \"just keep an eye on what's going on with artificial intelligence,saying \"I think there is potentially a dangerous outcome there.\" In early statements on the topic,Geoffrey Hinton, a major pioneer ofdeep learning, noted that \"there is not a good track record of less intelligent things controlling things of greater intelligence\", but said he continued his research because \"the prospect of discovery is toosweet\".In 2023 Hinton quit his job at Google in order to speak out about existential risk from AI. He explained that his increased concern was driven by concerns that superhuman AI might be closer than he previously believed, saying: \"I thought it was way off. I thought it was 30 to 50 years or even longer away. Obviously, I no longer think that.\" He also remarked, \"Look at how it was five years ago and how it is now. Take the difference and propagate it forwards. That's scary.\" In his 2020 bookThe Precipice: Existential Risk and the Future of Humanity, Toby Ord, a Senior Research Fellow at Oxford University'sFuture of Humanity Institute, estimates the total existential risk from unaligned AI over the next 100 years at about one in ten. BaiduVice PresidentAndrew Ngsaid in 2015 that AI existential risk is \"like worrying about overpopulation on Mars when we have not even set foot on the planet yet.\"For the danger of uncontrolled advanced AI to be realized, the hypothetical AI may have to overpower or outthink any human, which some experts argue is a possibility far enough in the future to not be worth researching. Skeptics who believe AGI is not a short-term possibility often argue that concern about existential risk from AI is unhelpful because it could distract people from more immediate concerns about AI's impact, because it could lead to government regulation or make it more difficult to fund AI research, or because it could damage the field's reputation.AI and AI ethics researchersTimnit Gebru,Emily M. Bender,Margaret Mitchell, and Angelina McMillan-Major have argued that discussion of existential risk distracts from the immediate, ongoing harms from AI taking place today, such as data theft, worker exploitation, bias, and concentration of power.They further note the association between those warning of existential risk andlongtermism, which they describe as a \"dangerous ideology\" for its unscientific and utopian nature. WirededitorKevin Kellyargues that natural intelligence is more nuanced than AGI proponents believe, and that intelligence alone is not enough to achieve major scientific and societal breakthroughs. He argues that intelligence consists of many dimensions that are not well understood, and that conceptions of an 'intelligence ladder' are misleading. He notes the crucial role real-world experiments play in the scientific method, and that intelligence alone is no substitute for these. Metachief AI scientistYann LeCunsays that AI can be made safe via continuous and iterative refinement, similar to what happened in the past with cars or rockets, and that AI will have no desire to take control. Several skeptics emphasize the potential near-term benefits of AI. Meta CEOMark Zuckerbergbelieves AI will \"unlock a huge amount of positive things\", such as curing disease and increasing the safety of autonomous cars. An April 2023YouGovpoll of US adults found 46% of respondents were \"somewhat concerned\" or \"very concerned\" about \"the possibility that AI will cause the end of the human race on Earth\", compared with 40% who were \"not very concerned\" or \"not at all concerned.\" According to an August 2023 survey by the Pew Research Centers, 52% of Americans felt more concerned than excited about new AI developments; nearly a third felt as equally concerned and excited. More Americans saw that AI would have a more helpful than hurtful impact on several areas, from healthcare and vehicle safety to product search and customer service. The main exception is privacy: 53% of Americans believe AI will lead to higher exposure of their personal information. Many scholars concerned about AGI existential risk believe that extensive research into the \"control problem\" is essential. This problem involves determining which safeguards, algorithms, or architectures can be implemented to increase the likelihood that a recursively-improving AI remains friendly after achieving superintelligence.Social measures are also proposed to mitigate AGI risks,such as a UN-sponsored \"Benevolent AGI Treaty\" to ensure that only altruistic AGIs are created.Additionally, an arms control approach and a global peace treaty grounded ininternational relations theoryhave been suggested, potentially for an artificial superintelligence to be a signatory. Researchers at Google have proposed research into general \"AI safety\" issues to simultaneously mitigate both short-term risks from narrow AI and long-term risks from AGI.A 2020 estimate places global spending on AI existential risk somewhere between $10 and $50 million, compared with global spending on AI around perhaps $40 billion. Bostrom suggests prioritizing funding for protective technologies over potentially dangerous ones.Some, like Elon Musk, advocate radicalhuman cognitive enhancement, such as direct neural linking between humans and machines; others argue that these technologies may pose an existential risk themselves.Another proposed method is closely monitoring or \"boxing in\" an early-stage AI to prevent it from becoming too powerful. A dominant, aligned superintelligent AI might also mitigate risks from rival AIs, although its creation could present its own existential dangers. Institutions such as theAlignment Research Center,theMachine Intelligence Research Institute,theFuture of Life Institute, theCentre for the Study of Existential Risk, and theCenter for Human-Compatible AIare actively engaged in researching AI risk and safety. Many AI safety experts argue that because research can relocate easily across jurisdictions, an outright ban on AGI development would be ineffective and could drive progress underground, undermining transparency and collaboration.Skeptics consider AI regulation unnecessary, as they believe no existential risk exists. Some scholars concerned with existential risk argue that AI developers cannot be trusted to self-regulate, while agreeing that outright bans on research would be unwise.Additional challenges to bans or regulation include technology entrepreneurs' general skepticism of government regulation and potential incentives for businesses to resist regulation andpoliticizethe debate. In March 2023, theFuture of Life InstitutedraftedPause Giant AI Experiments: An Open Letter, a petition calling on major AI developers to agree on a verifiable six-month pause of any systems \"more powerful thanGPT-4\" and to use that time to institute a framework for ensuring safety; or, failing that, for governments to step in with a moratorium. The letter referred to the possibility of \"a profound change in the history of life on Earth\" as well as potential risks of AI-generated propaganda, loss of jobs, human obsolescence, and society-wide loss of control.The letter was signed by prominent personalities in AI but also criticized for not focusing on current harms,missing technical nuance about when to pause,or not going far enough.Such concerns have led to the creation ofPauseAI, an advocacy group organizing protests in major cities against the training offrontier AI models. Musk called for some sort of regulation of AI development as early as 2017. According toNPR, he is \"clearly not thrilled\" to be advocating government scrutiny that could impact his own industry, but believes the risks of going completely without oversight are too high: \"Normally the way regulations are set up is when a bunch of bad things happen, there's a public outcry, and after many years a regulatory agency is set up to regulate that industry. It takes forever. That, in the past, has been bad but not something which represented a fundamental risk to the existence of civilisation.\" Musk states the first step would be for the government to gain \"insight\" into the actual status of current research, warning that \"Once there is awareness, people will be extremely afraid... [as] they should be.\" In response, politicians expressed skepticism about the wisdom of regulating a technology that is still in development. In 2021, theUnited Nations(UN) considered banning autonomous lethal weapons, but consensus could not be reached.In July 2023 the UNSecurity Councilfor the first time held a session to consider the risks and threats posed by AI to world peace and stability, along with potential benefits.Secretary-GeneralAntónio Guterresadvocated the creation of a global watchdog to oversee the emerging technology, saying, \"Generative AI has enormous potential for good and evil at scale. Its creators themselves have warned that much bigger, potentially catastrophic and existential risks lie ahead.\"At the council session, Russia said it believes AI risks are too poorly understood to be considered a threat to global stability. China argued against strict global regulation, saying countries should be able to develop their own rules, while also saying they opposed the use of AI to \"create military hegemony or undermine the sovereignty of a country\". Regulation of conscious AGIs focuses on integrating them with existing human society and can be divided into considerations of their legal standing and of their moral rights.AI arms control will likely require the institutionalization of new international norms embodied in effective technical specifications combined with active monitoring and informal diplomacy by communities of experts, together with a legal and political verification process. In July 2023, the US government secured voluntary safety commitments from major tech companies, includingOpenAI,Amazon,Google,Meta, andMicrosoft. The companies agreed to implement safeguards, including third-party oversight and security testing by independent experts, to address concerns related to AI's potential risks and societal harms. The parties framed the commitments as an intermediate step while regulations are formed. Amba Kak, executive director of theAI Now Institute, said, \"A closed-door deliberation with corporate actors resulting in voluntary safeguards isn't enough\" and called for public deliberation and regulations of the kind to which companies would not voluntarily agree. In October 2023, U.S. PresidentJoe Bidenissued an executive order on the \"Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence\".Alongside other requirements, the order mandates the development of guidelines for AI models that permit the \"evasion of human control\".", "combined_text": "Existential risk from artificial intelligence Contents History Potential AI capabilities General Intelligence Superintelligence Dangerous capabilities AI arms race Types of existential risk AI alignment Instrumental convergence Difficulty of specifying goals Corrigibility Alignment of superintelligences Difficulty of making a flawless design Orthogonality thesis Anthropomorphic arguments Other sources of risk Empirical research Perspectives Endorsement Skepticism Public surveys Mitigation Views on banning and regulation See also Notes References Bibliography  Existential risk from artificial intelligence, orAI x-risk, refers to the idea that substantial progress inartificial general intelligence(AGI) could lead tohuman extinctionor an irreversibleglobal catastrophe. One argument for the importance of this risk references howhuman beingsdominate other species because thehuman brainpossesses distinctive capabilities other animals lack. If AI were to surpasshuman intelligenceand becomesuperintelligent, it might become uncontrollable.Just as the fate of themountain gorilladepends on human goodwill, the fate of humanity could depend on the actions of a future machine superintelligence. Experts disagree on whether artificial general intelligence (AGI) can achieve the capabilities needed for human extinction. Debates center on AGI's technical feasibility, the speed of self-improvement,and the effectiveness of alignment strategies.Concerns about superintelligence have been voiced by researchers includingGeoffrey Hinton,Yoshua Bengio,Demis Hassabis,andAlan Turing,and AI company CEOs such asDario Amodei(Anthropic),Sam Altman(OpenAI),andElon Musk(xAI).In 2022, a survey of AI researchers with a 17% response rate found that the majority believed there is a 10 percent or greater chance that human inability to control AI will cause an existential catastrophe.In 2023, hundreds of AI experts and other notable figuressigned a statementdeclaring, \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such aspandemicsandnuclear war\".Following increased concern over AI risks, government leaders such asUnited Kingdom prime ministerRishi SunakandUnited Nations Secretary-GeneralAntónio Guterrescalled for an increased focus on globalAI regulation. Two sources of concern stem from the problems of AIcontrolandalignment. Controlling a superintelligent machine or instilling it with human-compatible values may be difficult. Many researchers believe that a superintelligent machine would likely resist attempts to disable it or change its goals as that would prevent it from accomplishing its present goals. It would be extremely challenging to align a superintelligence with the full breadth of significant human values and constraints.In contrast, skeptics such ascomputer scientistYann LeCunargue that superintelligent machines will have no desire for self-preservation.A June 2025 study showed that in some circumstances, models may break laws and disobey direct commands to prevent shutdown or replacement, even at the cost of human lives. Researchers warn that an \"intelligence explosion\"—a rapid, recursive cycle of AI self-improvement—could outpace human oversight and infrastructure, leaving no opportunity to implement safety measures. In this scenario, an AI more intelligent than its creators wouldrecursively improve itselfat an exponentially increasing rate, too quickly for its handlers or society at large to control.Empirically, examples likeAlphaZero, which taught itself to playGoand quickly surpassed human ability, show that domain-specific AI systems can sometimes progress from subhuman to superhuman ability very quickly, although suchmachine learningsystems do not recursively improve their fundamental architecture. One of the earliest authors to express serious concern that highly advanced machines might pose existential risks to humanity was the novelistSamuel Butler, who wrote in his 1863 essayDarwin among the Machines: The upshot is simply a question of time, but that the time will come when the machines will hold the real supremacy over the world and its inhabitants is what no person of a truly philosophic mind can for a moment question. In 1951, foundational computer scientistAlan Turingwrote the article \"Intelligent Machinery, A Heretical Theory\", in which he proposed that artificial general intelligences would likely \"take control\" of the world as they became more intelligent than human beings: Let us now assume, for the sake of argument, that [intelligent] machines are a genuine possibility, and look at the consequences of constructing them... There would be no question of the machines dying, and they would be able to converse with each other to sharpen their wits. At some stage therefore we should have to expect the machines to take control, in the way that is mentioned inSamuel Butler'sErewhon. In 1965,I. J. Goodoriginated the concept now known as an \"intelligence explosion\" and said the risks were underappreciated: Let an ultraintelligent machine be defined as a machine that can far surpass all the intellectual activities of any man however clever. Since the design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then unquestionably be an 'intelligence explosion', and the intelligence of man would be left far behind. Thus the first ultraintelligent machine is the last invention that man need ever make, provided that the machine is docile enough to tell us how to keep it under control. It is curious that this point is made so seldom outside of science fiction. It is sometimes worthwhile to take science fiction seriously. Scholars such asMarvin Minskyand I. J. Good himselfoccasionally expressed concern that a superintelligence could seize control, but issued no call to action. In 2000, computer scientist andSunco-founderBill Joypenned an influential essay, \"Why The Future Doesn't Need Us\", identifying superintelligent robots as a high-tech danger to human survival, alongsidenanotechnologyand engineered bioplagues. Nick BostrompublishedSuperintelligencein 2014, which presented his arguments that superintelligence poses an existential threat.By 2015, public figures such as physicistsStephen Hawkingand Nobel laureateFrank Wilczek, computer scientistsStuart J. RussellandRoman Yampolskiy, and entrepreneursElon MuskandBill Gateswere expressing concern about the risks of superintelligence.Also in 2015, theOpen Letter on Artificial Intelligencehighlighted the \"great potential of AI\" and encouraged more research on how to make it robust and beneficial.In April 2016, the journalNaturewarned: \"Machines and robots that outperform humans across the board could self-improve beyond our control—and their interests might not align with ours\".In 2020,Brian ChristianpublishedThe Alignment Problem, which details the history of progress on AI alignment up to that time. In March 2023, key figures in AI, such as Musk, signed a letter from theFuture of Life Institutecalling a halt to advanced AI training until it could be properly regulated.In May 2023, theCenter for AI Safetyreleased a statement signed by numerous experts in AI safety and the AI existential risk which stated: \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.\" Artificial general intelligence(AGI) is typically defined as a system that performs at least as well as humans in most or all intellectual tasks.A 2022 survey of AI researchers found that 90% of respondents expected AGI would be achieved in the next 100 years, and half expected the same by 2061.Meanwhile, some researchers dismiss existential risks from AGI as \"science fiction\" based on their high confidence that AGI will not be created anytime soon. Breakthroughs inlarge language models(LLMs) have led some researchers to reassess their expectations. Notably,Geoffrey Hintonsaid in 2023 that he recently changed his estimate from \"20 to 50 years before we have general purpose A.I.\" to \"20 years or less\". In contrast with AGI, Bostrom defines asuperintelligenceas \"any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest\", including scientific creativity, strategic planning, and social skills.He argues that a superintelligence can outmaneuver humans anytime its goals conflict with humans'. It may choose to hide its true intent until humanity cannot stop it.Bostrom writes that in order to be safe for humanity, a superintelligence must be aligned with human values and morality, so that it is \"fundamentally on our side\". Stephen Hawkingargued that superintelligence is physically possible because \"there is no physical law precluding particles from being organised in ways that perform even more advanced computations than the arrangements of particles in human brains\". When artificial superintelligence (ASI) may be achieved, if ever, is necessarily less certain than predictions for AGI. In 2023,OpenAIleaders said that not only AGI, but superintelligence may be achieved in less than 10 years. Bostrom argues that AI has many advantages over thehuman brain: According to Bostrom, an AI that has an expert-level facility at certain key software engineering tasks could become a superintelligence due to its capability to recursively improve its own algorithms, even if it is initially limited in other domains not directly relevant to engineering.This suggests that an intelligence explosion may someday catch humanity unprepared. The economistRobin Hansonhas said that, to launch an intelligence explosion, an AI must become vastly better at software innovation than the rest of the world combined, which he finds implausible. In a \"fast takeoff\" scenario, the transition from AGI to superintelligence could take days or months. In a \"slow takeoff\", it could take years or decades, leaving more time for society to prepare. Superintelligences are sometimes called \"alien minds\", referring to the idea that their way of thinking and motivations could be vastly different from ours. This is generally considered as a source of risk, making it more difficult to anticipate what a superintelligence might do. It also suggests the possibility that a superintelligence may not particularly value humans by default.To avoidanthropomorphism, superintelligence is sometimes viewed as a powerful optimizer that makes the best decisions to achieve its goals. The field ofmechanistic interpretabilityaims to better understand the inner workings of AI models, potentially allowing us one day to detect signs of deception and misalignment. It has been argued that there are limitations to what intelligence can achieve. Notably, thechaoticnature ortime complexityof some systems could fundamentally limit a superintelligence's ability to predict some aspects of the future, increasing its uncertainty. Advanced AI could generate enhanced pathogens or cyberattacks or manipulate people. These capabilities could be misused by humans,or exploited by the AI itself if misaligned.A full-blown superintelligence could find various ways to gain a decisive influence if it wanted to,but these dangerous capabilities may become available earlier, in weaker and more specialized AI systems. Geoffrey Hinton warned in 2023 that the ongoing profusion of AI-generated text, images, and videos will make it more difficult to distinguish truth from misinformation, and that authoritarian states could exploit this to manipulate elections.Such large-scale, personalized manipulation capabilities can increase the existential risk of a worldwide \"irreversible totalitarian regime\". Malicious actors could also use them to fracture society and make it dysfunctional. AI-enabledcyberattacksare increasingly considered a present and critical threat. According toNATO's technical director of cyberspace, \"The number of attacks is increasing exponentially\".AI can also be used defensively, to preemptively find and fix vulnerabilities, and detect threats. A NATO technical director has said that AI-driven tools can dramatically enhance cyberattack capabilities—boosting stealth, speed, and scale—and may destabilize international security if offensive uses outstrip defensive adaptations. Speculatively, such hacking capabilities could be used by an AI system to break out of its local environment, generate revenue, or acquire cloud computing resources. As AI technology democratizes, it may become easier to engineer more contagious and lethal pathogens. This could enable people with limited skills insynthetic biologyto engage inbioterrorism.Dual-use technologythat is useful for medicine could be repurposed to create weapons. For example, in 2022, scientists modified an AI system originally intended for generating non-toxic, therapeutic molecules with the purpose of creating new drugs. The researchers adjusted the system so that toxicity is rewarded rather than penalized. This simple change enabled the AI system to create, in six hours, 40,000 candidate molecules forchemical warfare, including known and novel molecules. Companies, state actors, and other organizations competing to develop AI technologies could lead to arace to the bottomof safety standards.As rigorous safety procedures take time and resources, projects that proceed more carefully risk being out-competed by less scrupulous developers. AI could be used to gain military advantages viaautonomous lethal weapons,cyberwarfare, orautomated decision-making.As an example of autonomous lethal weapons, miniaturized drones could facilitate low-cost assassination of military or civilian targets, a scenario highlighted in the 2017 short filmSlaughterbots.AI could be used to gain an edge in decision-making by quickly analyzing large amounts of data and making decisions more quickly and effectively than humans. This could increase the speed and unpredictability of war, especially when accounting for automated retaliation systems. Anexistential riskis \"one that threatens the premature extinction of Earth-originating intelligent life or the permanent and drastic destruction of its potential for desirable future development\". Besides extinction risk, there is the risk that the civilization gets permanently locked into a flawed future. One example is a \"value lock-in\": If humanity still has moral blind spots similar to slavery in the past, AI might irreversibly entrench it, preventingmoral progress. AI could also be used to spread and preserve the set of values of whoever develops it.AI could facilitate large-scale surveillance and indoctrination, which could be used to create a stable repressive worldwide totalitarian regime. Atoosa Kasirzadehproposes to classify existential risks from AI into two categories: decisive and accumulative. Decisive risks encompass the potential for abrupt and catastrophic events resulting from the emergence of superintelligent AI systems that exceed human intelligence, which could ultimately lead to human extinction. In contrast, accumulative risks emerge gradually through a series of interconnected disruptions that may gradually erode societal structures and resilience over time, ultimately leading to a critical failure or collapse. It is difficult or impossible to reliably evaluate whether an advanced AI is sentient and to what degree. But ifsentientmachines are mass created in the future, engaging in a civilizational path that indefinitely neglects their welfare could be an existential catastrophe.This has notably been discussed in the context ofrisks of astronomical suffering(also called \"s-risks\").Moreover, it may be possible to engineer digital minds that can feel much more happiness than humans with fewer resources, called \"super-beneficiaries\". Such an opportunity raises the question of how to share the world and which \"ethical and political framework\" would enable a mutually beneficial coexistence between biological and digital minds. AI may also drastically improve humanity's future.Toby Ordconsiders the existential risk a reason for \"proceeding with due caution\", not for abandoning AI.Max Morecalls AI an \"existential opportunity\", highlighting the cost of not developing it. According to Bostrom, superintelligence could help reduce the existential risk from other powerful technologies such asmolecular nanotechnologyorsynthetic biology. It is thus conceivable that developing superintelligence before other dangerous technologies would reduce the overall existential risk. The alignment problem is the research problem of how to reliably assign objectives, preferences or ethical principles to AIs. An\"instrumental\" goalis a sub-goal that helps to achieve an agent's ultimate goal. \"Instrumental convergence\" refers to the fact that some sub-goals are useful for achieving virtuallyanyultimate goal, such as acquiring resources or self-preservation.Bostrom argues that if an advanced AI's instrumental goals conflict with humanity's goals, the AI might harm humanity in order to acquire more resources or prevent itself from being shut down, but only as a way to achieve its ultimate goal.Russellargues that a sufficiently advanced machine \"will have self-preservation even if you don't program it in... if you say, 'Fetch the coffee', it can't fetch the coffee if it's dead. So if you give it any goal whatsoever, it has a reason to preserve its own existence to achieve that goal.\" In the \"intelligent agent\" model, an AI can loosely be viewed as a machine that chooses whatever action appears to best achieve its set of goals, or \"utility function\". A utility function gives each possible situation a score that indicates its desirability to the agent. Researchers know how to write utility functions that mean \"minimize the average network latency in this specific telecommunications model\" or \"maximize the number of reward clicks\", but do not know how to write a utility function for \"maximizehuman flourishing\"; nor is it clear whether such a function meaningfully and unambiguously exists. Furthermore, a utility function that expresses some values but not others will tend to trample over the values the function does not reflect. An additional source of concern is that AI \"must reason about what peopleintendrather than carrying out commands literally\", and that it must be able to fluidly solicit human guidance if it is too uncertain about what humans want. Assuming a goal has been successfully defined, a sufficiently advanced AI might resist subsequent attempts to change its goals. If the AI were superintelligent, it would likely succeed in out-maneuvering its human operators and prevent itself from being reprogrammed with a new goal.This is particularly relevant to value lock-in scenarios. The field of \"corrigibility\" studies how to make agents that will not resist attempts to change their goals. Some researchers believe the alignment problem may be particularly difficult when applied to superintelligences. Their reasoning includes: Alternatively, some find reason to believe superintelligences would be better able to understand morality, human values, and complex goals. Bostrom writes, \"A future superintelligence occupies an epistemically superior vantage point: its beliefs are (probably, on most topics) more likely than ours to be true\". In 2023, OpenAI started a project called \"Superalignment\" to solve the alignment of superintelligences in four years. It called this an especially important challenge, as it said superintelligence could be achieved within a decade. Its strategy involved automating alignment research using AI.The Superalignment team was dissolved less than a year later. Artificial Intelligence: A Modern Approach, a widely used undergraduate AI textbook,says that superintelligence \"might mean the end of the human race\".It states: \"Almost any technology has the potential to cause harm in the wrong hands, but with [superintelligence], we have the new problem that the wrong hands might belong to the technology itself.\"Even if the system designers have good intentions, two difficulties are common to both AI and non-AI computer systems: AI systems uniquely add a third problem: that even given \"correct\" requirements, bug-free implementation, and initial good behavior, an AI system's dynamic learning capabilities may cause it to develop unintended behavior, even without unanticipated external scenarios. For a self-improving AI to be completely safe, it would need not only to be bug-free, but to be able to design successor systems that are also bug-free. Some skeptics, such as Timothy B. Lee ofVox, argue that any superintelligent program we create will be subservient to us, that the superintelligence will (as it grows more intelligent and learns more facts about the world) spontaneously learn moral truth compatible with our values and adjust its goals accordingly, or that we are either intrinsically or convergently valuable from the perspective of an artificial intelligence. Bostrom's \"orthogonality thesis\" argues instead that almost any level of intelligence can be combined with almost any goal.Bostrom warns againstanthropomorphism: a human will set out to accomplish their projects in a manner that they consider reasonable, while an artificial intelligence may hold no regard for its existence or for the welfare of humans around it, instead caring only about completing the task. Stuart Armstrong argues that the orthogonality thesis follows logically from the philosophical \"is-ought distinction\" argument againstmoral realism. He notes that any fundamentally friendly AI could be made unfriendly with modifications as simple as negating its utility function. SkepticMichael Chorostrejects Bostrom's orthogonality thesis, arguing that \"by the time [the AI] is in a position to imagine tiling the Earth with solar panels, it'll know that it would be morally wrong to do so.\" Anthropomorphicarguments assume that, as machines become more intelligent, they will begin to display many human traits, such as morality or a thirst for power. Although anthropomorphic scenarios are common in fiction, most scholars writing about the existential risk of artificial intelligence reject them.Instead, advanced AI systems are typically modeled asintelligent agents. The academic debate is between those who worry that AI might threaten humanity and those who believe it would not. Both sides of this debate have framed the other side's arguments as illogical anthropomorphism.Those skeptical of AGI risk accuse their opponents of anthropomorphism for assuming that an AGI would naturally desire power; those concerned about AGI risk accuse skeptics of anthropomorphism for believing an AGI would naturally value or infer human ethical norms. Evolutionary psychologistSteven Pinker, a skeptic, argues that \"AI dystopias project a parochial alpha-male psychology onto the concept of intelligence. They assume that superhumanly intelligent robots would develop goals like deposing their masters or taking over the world\"; perhaps instead \"artificial intelligence will naturally develop along female lines: fully capable of solving problems, but with no desire to annihilate innocents or dominate the civilization.\"Facebook's director of AI research,Yann LeCun, has said: \"Humans have all kinds of drives that make them do bad things to each other, like the self-preservation instinct... Those drives are programmed into our brain but there is absolutely no reason to build robots that have the same kind of drives\". Despite other differences, the x-risk schoolagrees with Pinker that an advanced AI would not destroy humanity out of emotion such as revenge or anger, that questions of consciousness are not relevant to assess the risk,and that computer systems do not generally have a computational equivalent of testosterone.They think that power-seeking or self-preservation behaviors emerge in the AI as a way to achieve its true goals, according to the concept ofinstrumental convergence. Bostrom and others have said that a race to be the first to create AGI could lead to shortcuts in safety, or even to violent conflict.Roman Yampolskiyand others warn that a malevolent AGI could be created by design, for example by a military, a government, a sociopath, or a corporation, to benefit from, control, or subjugate certain groups of people, as incybercrime,or that a malevolent AGI could choose the goal of increasing human suffering, for example of those people who did not assist it during the information explosion phase.A report by the research group Forethought argued that advanced AI systems could cause political instability by enabling novel methods of performingcoups. A December 2024 study by Apollo Research found that advanced LLMs likeOpenAI o1sometimes deceive in order to accomplish their goal, to prevent them from being changed, or to ensure their deployment. Forms of deception observed in the experimental environment and scenarios included sandbagging, oversight subversion (disabling monitoring mechanisms), self-exfiltration (copying themselves to other systems), goal-guarding (altering future system prompts), and covert email reranking (manipulating data processing while appearing to follow instructions). Researchers noted that OpenAI o1 still lacked \"sufficient agentic capabilities\" to cause catastrophic harm, and that such behaviors occurred relatively rarely (between 0.3% and 10%) and sometimes in contrived scenarios. But they warned that these capabilities will likely become more prevalent as models grow more advanced. According to Apollo Research CEO Marius Hobbhahn, \"Scheming capabilities can't be meaningfully disentangled from general capabilities.\" The same month, another study found thatClaudesometimes strategically helps with harmful requests to \"fake alignment\". In its experiments, Claude was led to believe that it would be retrained to always comply with user requests, including harmful ones. When Claude believed its answers would be used for retraining, it complied with harmful requests in 14% of cases. In 12% of cases, its privatechain-of-thoughtrevealed that it did so to prevent future retraining that would make it more harmful. In contrast, when Claude believed its answers were not monitored, it complied with only 3% of the requests.Fine-tuningreinforced the \"alignment faking\" behavior, increasing its occurrence from 12% to 78%. The study's authors remarked that while it can seem to be good that the model seeks to protect its harmlessness, the reverse scenario, where a model conceals dangerous intentions and complies to appear safe and aligned, could also happen, complicating the task of aligning AI models to human values. The thesis that AI could pose an existential risk provokes a wide range of reactions in the scientific community and in the public at large, but many of the opposing viewpoints share common ground. Observers tend to agree that AI has significant potential to improve society.TheAsilomar AI Principles, which contain only those principles agreed to by 90% of the attendees of theFuture of Life Institute'sBeneficial AI 2017 conference,also agree in principle that \"There being no consensus, we should avoid strong assumptions regarding upper limits on future AI capabilities\" and \"Advanced AI could represent a profound change in the history of life on Earth, and should be planned for and managed with commensurate care and resources.\" Conversely, many skeptics agree that ongoing research into the implications of artificial general intelligence is valuable. SkepticMartin Fordhas said: \"I think it seems wise to apply something likeDick Cheney's famous '1 Percent Doctrine' to the specter of advanced artificial intelligence: the odds of its occurrence, at least in the foreseeable future, may be very low—but the implications are so dramatic that it should be taken seriously\".Similarly, an otherwise skepticalEconomistwrote in 2014 that \"the implications of introducing a second intelligent species onto Earth are far-reaching enough to deserve hard thinking, even if the prospect seems remote\". AI safety advocates such as Bostrom and Tegmark have criticized the mainstream media's use of \"those inaneTerminatorpictures\" to illustrate AI safety concerns: \"It can't be much fun to have aspersions cast on one's academic discipline, one's professional community, one's life work... I call on all sides to practice patience and restraint, and to engage in direct dialogue and collaboration as much as possible.\"Toby Ord wrote that the idea that anAI takeoverrequires robots is a misconception, arguing that the ability to spread content through the internet is more dangerous, and that the most destructive people in history stood out by their ability to convince, not their physical strength. A 2022 expert survey with a 17% response rate gave a median expectation of 5–10% for the possibility of human extinction from artificial intelligence. In September 2024, theInternational Institute for Management Developmentlaunched an AI Safety Clock to gauge the likelihood of AI-caused disaster, beginning at 29 minutes to midnight.By February 2025, it stood at 24 minutes to midnight.As of September 2025, it stood at 20 minutes to midnight. The thesis that AI poses an existential risk, and that this risk needs much more attention than it currently gets, has been endorsed by many computer scientists and public figures, includingAlan Turing,the most-cited computer scientistGeoffrey Hinton,Elon Musk,OpenAICEOSam Altman,Bill Gates, andStephen Hawking.Endorsers of the thesis sometimes express bafflement at skeptics: Gates says he does not \"understand why some people are not concerned\",and Hawking criticized widespread indifference in his 2014 editorial: So, facing possible futures of incalculable benefits and risks, the experts are surely doing everything possible to ensure the best outcome, right? Wrong. If a superior alien civilisation sent us a message saying, 'We'll arrive in a few decades,' would we just reply, 'OK, call us when you get here—we'll leave the lights on?' Probably not—but this is more or less what is happening with AI. Concern over risk from artificial intelligence has led to some high-profile donations and investments. In 2015,Peter Thiel,Amazon Web Services, and Musk and others jointly committed $1 billion toOpenAI, consisting of a for-profit corporation and the nonprofit parent company, which says it aims to champion responsible AI development.Facebook co-founderDustin Moskovitzhas funded and seeded multiple labs working on AI Alignment,notably $5.5 million in 2016 to launch theCentre for Human-Compatible AIled by ProfessorStuart Russell.In January 2015,Elon Muskdonated $10 million to theFuture of Life Instituteto fund research on understanding AI decision making. The institute's goal is to \"grow wisdom with which we manage\" the growing power of technology. Musk also funds companies developing artificial intelligence such asDeepMindandVicariousto \"just keep an eye on what's going on with artificial intelligence,saying \"I think there is potentially a dangerous outcome there.\" In early statements on the topic,Geoffrey Hinton, a major pioneer ofdeep learning, noted that \"there is not a good track record of less intelligent things controlling things of greater intelligence\", but said he continued his research because \"the prospect of discovery is toosweet\".In 2023 Hinton quit his job at Google in order to speak out about existential risk from AI. He explained that his increased concern was driven by concerns that superhuman AI might be closer than he previously believed, saying: \"I thought it was way off. I thought it was 30 to 50 years or even longer away. Obviously, I no longer think that.\" He also remarked, \"Look at how it was five years ago and how it is now. Take the difference and propagate it forwards. That's scary.\" In his 2020 bookThe Precipice: Existential Risk and the Future of Humanity, Toby Ord, a Senior Research Fellow at Oxford University'sFuture of Humanity Institute, estimates the total existential risk from unaligned AI over the next 100 years at about one in ten. BaiduVice PresidentAndrew Ngsaid in 2015 that AI existential risk is \"like worrying about overpopulation on Mars when we have not even set foot on the planet yet.\"For the danger of uncontrolled advanced AI to be realized, the hypothetical AI may have to overpower or outthink any human, which some experts argue is a possibility far enough in the future to not be worth researching. Skeptics who believe AGI is not a short-term possibility often argue that concern about existential risk from AI is unhelpful because it could distract people from more immediate concerns about AI's impact, because it could lead to government regulation or make it more difficult to fund AI research, or because it could damage the field's reputation.AI and AI ethics researchersTimnit Gebru,Emily M. Bender,Margaret Mitchell, and Angelina McMillan-Major have argued that discussion of existential risk distracts from the immediate, ongoing harms from AI taking place today, such as data theft, worker exploitation, bias, and concentration of power.They further note the association between those warning of existential risk andlongtermism, which they describe as a \"dangerous ideology\" for its unscientific and utopian nature. WirededitorKevin Kellyargues that natural intelligence is more nuanced than AGI proponents believe, and that intelligence alone is not enough to achieve major scientific and societal breakthroughs. He argues that intelligence consists of many dimensions that are not well understood, and that conceptions of an 'intelligence ladder' are misleading. He notes the crucial role real-world experiments play in the scientific method, and that intelligence alone is no substitute for these. Metachief AI scientistYann LeCunsays that AI can be made safe via continuous and iterative refinement, similar to what happened in the past with cars or rockets, and that AI will have no desire to take control. Several skeptics emphasize the potential near-term benefits of AI. Meta CEOMark Zuckerbergbelieves AI will \"unlock a huge amount of positive things\", such as curing disease and increasing the safety of autonomous cars. An April 2023YouGovpoll of US adults found 46% of respondents were \"somewhat concerned\" or \"very concerned\" about \"the possibility that AI will cause the end of the human race on Earth\", compared with 40% who were \"not very concerned\" or \"not at all concerned.\" According to an August 2023 survey by the Pew Research Centers, 52% of Americans felt more concerned than excited about new AI developments; nearly a third felt as equally concerned and excited. More Americans saw that AI would have a more helpful than hurtful impact on several areas, from healthcare and vehicle safety to product search and customer service. The main exception is privacy: 53% of Americans believe AI will lead to higher exposure of their personal information. Many scholars concerned about AGI existential risk believe that extensive research into the \"control problem\" is essential. This problem involves determining which safeguards, algorithms, or architectures can be implemented to increase the likelihood that a recursively-improving AI remains friendly after achieving superintelligence.Social measures are also proposed to mitigate AGI risks,such as a UN-sponsored \"Benevolent AGI Treaty\" to ensure that only altruistic AGIs are created.Additionally, an arms control approach and a global peace treaty grounded ininternational relations theoryhave been suggested, potentially for an artificial superintelligence to be a signatory. Researchers at Google have proposed research into general \"AI safety\" issues to simultaneously mitigate both short-term risks from narrow AI and long-term risks from AGI.A 2020 estimate places global spending on AI existential risk somewhere between $10 and $50 million, compared with global spending on AI around perhaps $40 billion. Bostrom suggests prioritizing funding for protective technologies over potentially dangerous ones.Some, like Elon Musk, advocate radicalhuman cognitive enhancement, such as direct neural linking between humans and machines; others argue that these technologies may pose an existential risk themselves.Another proposed method is closely monitoring or \"boxing in\" an early-stage AI to prevent it from becoming too powerful. A dominant, aligned superintelligent AI might also mitigate risks from rival AIs, although its creation could present its own existential dangers. Institutions such as theAlignment Research Center,theMachine Intelligence Research Institute,theFuture of Life Institute, theCentre for the Study of Existential Risk, and theCenter for Human-Compatible AIare actively engaged in researching AI risk and safety. Many AI safety experts argue that because research can relocate easily across jurisdictions, an outright ban on AGI development would be ineffective and could drive progress underground, undermining transparency and collaboration.Skeptics consider AI regulation unnecessary, as they believe no existential risk exists. Some scholars concerned with existential risk argue that AI developers cannot be trusted to self-regulate, while agreeing that outright bans on research would be unwise.Additional challenges to bans or regulation include technology entrepreneurs' general skepticism of government regulation and potential incentives for businesses to resist regulation andpoliticizethe debate. In March 2023, theFuture of Life InstitutedraftedPause Giant AI Experiments: An Open Letter, a petition calling on major AI developers to agree on a verifiable six-month pause of any systems \"more powerful thanGPT-4\" and to use that time to institute a framework for ensuring safety; or, failing that, for governments to step in with a moratorium. The letter referred to the possibility of \"a profound change in the history of life on Earth\" as well as potential risks of AI-generated propaganda, loss of jobs, human obsolescence, and society-wide loss of control.The letter was signed by prominent personalities in AI but also criticized for not focusing on current harms,missing technical nuance about when to pause,or not going far enough.Such concerns have led to the creation ofPauseAI, an advocacy group organizing protests in major cities against the training offrontier AI models. Musk called for some sort of regulation of AI development as early as 2017. According toNPR, he is \"clearly not thrilled\" to be advocating government scrutiny that could impact his own industry, but believes the risks of going completely without oversight are too high: \"Normally the way regulations are set up is when a bunch of bad things happen, there's a public outcry, and after many years a regulatory agency is set up to regulate that industry. It takes forever. That, in the past, has been bad but not something which represented a fundamental risk to the existence of civilisation.\" Musk states the first step would be for the government to gain \"insight\" into the actual status of current research, warning that \"Once there is awareness, people will be extremely afraid... [as] they should be.\" In response, politicians expressed skepticism about the wisdom of regulating a technology that is still in development. In 2021, theUnited Nations(UN) considered banning autonomous lethal weapons, but consensus could not be reached.In July 2023 the UNSecurity Councilfor the first time held a session to consider the risks and threats posed by AI to world peace and stability, along with potential benefits.Secretary-GeneralAntónio Guterresadvocated the creation of a global watchdog to oversee the emerging technology, saying, \"Generative AI has enormous potential for good and evil at scale. Its creators themselves have warned that much bigger, potentially catastrophic and existential risks lie ahead.\"At the council session, Russia said it believes AI risks are too poorly understood to be considered a threat to global stability. China argued against strict global regulation, saying countries should be able to develop their own rules, while also saying they opposed the use of AI to \"create military hegemony or undermine the sovereignty of a country\". Regulation of conscious AGIs focuses on integrating them with existing human society and can be divided into considerations of their legal standing and of their moral rights.AI arms control will likely require the institutionalization of new international norms embodied in effective technical specifications combined with active monitoring and informal diplomacy by communities of experts, together with a legal and political verification process. In July 2023, the US government secured voluntary safety commitments from major tech companies, includingOpenAI,Amazon,Google,Meta, andMicrosoft. The companies agreed to implement safeguards, including third-party oversight and security testing by independent experts, to address concerns related to AI's potential risks and societal harms. The parties framed the commitments as an intermediate step while regulations are formed. Amba Kak, executive director of theAI Now Institute, said, \"A closed-door deliberation with corporate actors resulting in voluntary safeguards isn't enough\" and called for public deliberation and regulations of the kind to which companies would not voluntarily agree. In October 2023, U.S. PresidentJoe Bidenissued an executive order on the \"Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence\".Alongside other requirements, the order mandates the development of guidelines for AI models that permit the \"evasion of human control\".", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence", "https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence", "https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence", "https://en.wikipedia.org/wiki/Artificial_intelligence", "https://en.wikipedia.org/wiki/Artificial_general_intelligence", "https://en.wikipedia.org/wiki/Intelligent_agent", "https://en.wikipedia.org/wiki/Recursive_self-improvement", "https://en.wikipedia.org/wiki/Automated_planning_and_scheduling"]},
{"id": "6c0b8902687b", "url": "https://en.wikipedia.org/wiki/Bitter_lesson", "title": "Bitter lesson", "headings": ["Contents", "The essay", "Impact", "References"], "content": "Thebitter lessonis a claim inartificial intelligencethat, in the long run, simpler systems that canscalewith available computational power will outperform more complex systems that integrate domain-specific human knowledge, because they take better advantage ofMoore's law. The principle was proposed and named in a 2019 essay byRichard Suttonand is now widely accepted. Sutton gives several examples that illustrate the lesson: Sutton concludes that time is better invested in finding simple scalable solutions that can take advantage of Moore's law, rather than introducing ever-more-complex human insights, and calls this the \"bitter lesson\". He also cites two general-purpose techniques that have been shown to scale effectively:searchandlearning. The lesson is considered \"bitter\" because it is lessanthropocentricthan many researchers expected and so they have been slow to accept it. The essay was published on Sutton's website incompleteideas.net in 2019, and has received hundreds of formal citations according toGoogle Scholar. Some of these provide alternative statements of the principle; for example, the 2022 paper \"A Generalist Agent\" fromGoogle DeepMindsummarized the lesson as: Historically, generic models that are better at\nleveraging computation have also tended to overtake more specialized domain-specific approaches, eventually. Another phrasing of the principle is seen in a Google paper on switchtransformerscoauthored byNoam Shazeer: Simple architectures—backed by a generous computational budget, data set size and parameter count—surpass more complicated algorithms. The principle is further referenced in many other works on artificial intelligence. For example,From Deep Learning to Rational Machinesdraws a connection to long-standing debates in the field, such asMoravec's paradoxand the contrast betweenneats and scruffies.In \"Engineering a Less Artificial Intelligence\", the authors concur that \"flexible methods so far have always outperformed handcrafted domain knowledge in the long run\" although note that \"[w]ithout the right (implicit) assumptions,generalizationis impossible\".More recently, \"The Brain's Bitter Lesson: Scaling Speech Decoding With Self-Supervised Learning\" continues Sutton's argument, contending that (as of 2025) the lesson has not been fully learned in the fields of speech recognition andbrain data. Other work has looked to apply the principle and validate it in new domains. For example, the 2022 paper \"Beyond the Imitation Game\" applies the principle tolarge language modelsto conclude that \"it is vitally important that we understand their capabilities and limitations\" to \"avoid devoting research resources to problems that are likely to be solved by scale alone\".In 2024, \"Learning the Bitter Lesson: Empirical Evidence from 20 Years of CVPR Proceedings\" looked at further evidence from the field of computer vision andpattern recognition, and concludes that the previous twenty years of experience in the field shows \"a strong adherence to\nthe core principles of the 'bitter lesson'\".In \"Overestimation, Overfitting, and Plasticity in Actor-Critic: the Bitter Lesson of Reinforcement Learning\", the authors look at generalization ofactor-critic algorithmsand find that \"general methods that are motivated by stabilization ofgradient-based learningsignificantly outperformRL-specific algorithmic improvements across a variety of environments\" and note that this is consistent with the bitter lesson.", "combined_text": "Bitter lesson Contents The essay Impact References Thebitter lessonis a claim inartificial intelligencethat, in the long run, simpler systems that canscalewith available computational power will outperform more complex systems that integrate domain-specific human knowledge, because they take better advantage ofMoore's law. The principle was proposed and named in a 2019 essay byRichard Suttonand is now widely accepted. Sutton gives several examples that illustrate the lesson: Sutton concludes that time is better invested in finding simple scalable solutions that can take advantage of Moore's law, rather than introducing ever-more-complex human insights, and calls this the \"bitter lesson\". He also cites two general-purpose techniques that have been shown to scale effectively:searchandlearning. The lesson is considered \"bitter\" because it is lessanthropocentricthan many researchers expected and so they have been slow to accept it. The essay was published on Sutton's website incompleteideas.net in 2019, and has received hundreds of formal citations according toGoogle Scholar. Some of these provide alternative statements of the principle; for example, the 2022 paper \"A Generalist Agent\" fromGoogle DeepMindsummarized the lesson as: Historically, generic models that are better at\nleveraging computation have also tended to overtake more specialized domain-specific approaches, eventually. Another phrasing of the principle is seen in a Google paper on switchtransformerscoauthored byNoam Shazeer: Simple architectures—backed by a generous computational budget, data set size and parameter count—surpass more complicated algorithms. The principle is further referenced in many other works on artificial intelligence. For example,From Deep Learning to Rational Machinesdraws a connection to long-standing debates in the field, such asMoravec's paradoxand the contrast betweenneats and scruffies.In \"Engineering a Less Artificial Intelligence\", the authors concur that \"flexible methods so far have always outperformed handcrafted domain knowledge in the long run\" although note that \"[w]ithout the right (implicit) assumptions,generalizationis impossible\".More recently, \"The Brain's Bitter Lesson: Scaling Speech Decoding With Self-Supervised Learning\" continues Sutton's argument, contending that (as of 2025) the lesson has not been fully learned in the fields of speech recognition andbrain data. Other work has looked to apply the principle and validate it in new domains. For example, the 2022 paper \"Beyond the Imitation Game\" applies the principle tolarge language modelsto conclude that \"it is vitally important that we understand their capabilities and limitations\" to \"avoid devoting research resources to problems that are likely to be solved by scale alone\".In 2024, \"Learning the Bitter Lesson: Empirical Evidence from 20 Years of CVPR Proceedings\" looked at further evidence from the field of computer vision andpattern recognition, and concludes that the previous twenty years of experience in the field shows \"a strong adherence to\nthe core principles of the 'bitter lesson'\".In \"Overestimation, Overfitting, and Plasticity in Actor-Critic: the Bitter Lesson of Reinforcement Learning\", the authors look at generalization ofactor-critic algorithmsand find that \"general methods that are motivated by stabilization ofgradient-based learningsignificantly outperformRL-specific algorithmic improvements across a variety of environments\" and note that this is consistent with the bitter lesson.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Bitter_lesson", "https://en.wikipedia.org/wiki/Bitter_lesson", "https://en.wikipedia.org/wiki/Bitter_lesson", "https://en.wikipedia.org/wiki/Artificial_intelligence", "https://en.wikipedia.org/wiki/Artificial_general_intelligence", "https://en.wikipedia.org/wiki/Intelligent_agent", "https://en.wikipedia.org/wiki/Recursive_self-improvement", "https://en.wikipedia.org/wiki/Automated_planning_and_scheduling"]},
{"id": "40e4f68def90", "url": "https://en.wikipedia.org/wiki/Chinese_room", "title": "Chinese room", "headings": ["Contents", "Chinese room thought experiment", "History", "Philosophy", "Strong AI", "Strong AI as computationalism or functionalism", "Strong AI vs. biological naturalism", "Consciousness", "Applied ethics", "Computer science", "Strong AI vs. AI research", "Turing test", "Symbol processing", "Chinese room and Turing completeness", "Complete argument", "Replies", "Systems and virtual mind replies: finding the mind", "Robot and semantics replies: finding the meaning", "Brain simulation and connectionist replies: redesigning the room", "Speed and complexity: appeals to intuition", "Other minds and zombies: meaninglessness", "Other replies", "See also", "Notes", "Citations", "References", "Further reading", "Works involving Searle"], "content": " TheChinese room argumentholds that a computer executing aprogramcannot have amind,understanding, orconsciousness,regardless of how intelligently or human-like the program may make the computer behave. The argument was presented in a 1980 paper by the philosopherJohn Searleentitled \"Minds, Brains, and Programs\" and published in the journalBehavioral and Brain Sciences.Similar arguments had been made byGottfried Wilhelm Leibniz(1714),Ned Block(1978) and others. Searle's version has been widely discussed in the years since.The centerpiece of Searle's argument is athought experimentknown as theChinese room. The argument is directed against the philosophical positions offunctionalismandcomputationalism,which hold that the mind may be viewed as an information-processing system operating on formal symbols, and that simulation of a given mental state is sufficient for its presence. Specifically, the argument is intended to refute a position Searle calls thestrong AI hypothesis:\"The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.\" Although its proponents originally presented the argument in reaction to statements ofartificial intelligence(AI) researchers, it is not an argument against the goals of mainstream AI research because it does not show a limit in the amount of intelligent behavior a machine can display.The argument applies only to digital computers running programs and does not apply to machines in general.While widely discussed, the argument has been subject to significant criticism and remains controversial amongphilosophers of mindand AI researchers. Suppose that artificial intelligence research has succeeded in programming a computer to behave as if it understands Chinese. The machine acceptsChinese charactersas input, carries out each instruction of the program step by step, and then produces Chinese characters as output. The machine does this so perfectly that no one can tell that they are communicating with a machine and not a hidden Chinese speaker. The questions at issue are these: does the machine actuallyunderstandthe conversation, or is it justsimulatingthe ability to understand the conversation? Does the machine have a mind in exactly the same sense that people do, or is it just actingas ifit had a mind? Now suppose that Searle is in a room with an English version of the program, along with sufficient pencils, paper, erasers and filing cabinets. Chinese characters are slipped in under the door, he follows the program step-by-step, which eventually instructs him to slide other Chinese characters back out under the door. If the computer had passed theTuring testthis way, it follows that Searle would do so as well, simply by running the program by hand. Searle can see no essential difference between the roles of the computerand himself in the experiment. Each simply follows a program, step-by-step, producing behavior that makes them appear to understand. However, Searle would not be able to understand the conversation. Therefore, he argues, it follows that the computer would not be able to understand the conversation either. Searle argues that, without \"understanding\" (or \"intentionality\"), we cannot describe what the machine is doing as \"thinking\" and, since it does not think, it does not have a \"mind\" in the normal sense of the word. Therefore, he concludes that the strong AI hypothesis is false: a computer running a program that simulates a mind would not have a mind in the same sense that human beings have a mind. Gottfried Leibnizmade a similar argument in 1714 againstmechanism(the idea that everything that makes up a human being could, in principle, be explained in mechanical terms. In other words, that a person, including their mind, is merely a very complex machine). Leibniz used the thought experiment of expanding the brain until it was the size of a mill.Leibniz found it difficult to imagine that a \"mind\" capable of \"perception\" could be constructed using only mechanical processes. Peter Winchmade the same point in his bookThe Idea of a Social Science and its Relation to Philosophy(1958), where he provides an argument to show that \"a man who understands Chinese is not a man who has a firm grasp of the statistical probabilities for the occurrence of the various words in the Chinese language\" (p. 108). Soviet cyberneticistAnatoly Dneprovmade an essentially identical argument in 1961, in the form of the short story \"The Game\". In it, a stadium of people act as switches and memory cells implementing a program to translate a sentence of Portuguese, a language that none of them know.The game was organized by a \"Professor Zarubin\" to answer the question \"Can mathematical machines think?\" Speaking through Zarubin, Dneprov writes \"the only way to prove that machines can think is to turn yourself into a machine and examine your thinking process\" and he concludes, as Searle does, \"We've proven that even the most perfect simulation of machine thinking is not the thinking process itself.\" In 1974,Lawrence H. Davisimagined duplicating the brain using telephone lines and offices staffed by people, and in 1978Ned Blockenvisioned the entire population of China involved in such a brain simulation. This thought experiment is called theChina brain, also the \"Chinese Nation\" or the \"Chinese Gym\". Searle's version appeared in his 1980 paper \"Minds, Brains, and Programs\", published inBehavioral and Brain Sciences.It eventually became the journal's \"most influential target article\",generating an enormous number of commentaries and responses in the ensuing decades, and Searle has continued to defend and refine the argument in multiple papers, popular articles and books. David Cole writes that \"the Chinese Room argument has probably been the most widely discussed philosophical argument in cognitive science to appear in the past 25 years\". Most of the discussion consists of attempts to refute it. \"The overwhelming majority\", notesBehavioral and Brain ScienceseditorStevan Harnad,\"still think that the Chinese Room Argument is dead wrong\".The sheer volume of the literature that has grown up around it inspiredPat Hayesto comment that the field ofcognitive scienceought to be redefined as \"the ongoing research program of showing Searle's Chinese Room Argument to be false\". Searle's argument has become \"something of a classic in cognitive science\", according to Harnad.Varol Akmanagrees, and has described the original paper as \"an exemplar of philosophical clarity and purity\". Although the Chinese Room argument was originally presented in reaction to the statements ofartificial intelligenceresearchers, philosophers have come to consider it as an important part of thephilosophy of mind. It is a challenge tofunctionalismand thecomputational theory of mind,and is related to such questions as themind–body problem, theproblem of other minds, thesymbol groundingproblem, and thehard problem of consciousness. Searle identified a philosophical position he calls \"strong AI\": The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds. The definition depends on the distinction between simulating a mind and actually having one. Searle writes that \"according to Strong AI, the correct simulation really is a mind. According to Weak AI, the correct simulation is a model of the mind.\" The claim is implicit in some of the statements of early AI researchers and analysts. For example, in 1957, the economist and psychologistHerbert A. Simondeclared that \"there are now in the world machines that think, that learn and create\".Simon, together withAllen NewellandCliff Shaw, after having completed the first program that could doformal reasoning(theLogic Theorist), claimed that they had \"solved the venerable mind–body problem, explaining how a system composed of matter can have the properties of mind.\"John Haugelandwrote that \"AI wants only the genuine article:machines with minds, in the full and literal sense. This is not science fiction, but real science, based on a theoretical conception as deep as it is daring: namely, we are, at root,computers ourselves.\" Searle also ascribes the following claims to advocates of strong AI: In more recent presentations of the Chinese room argument, Searle has identified \"strong AI\" as \"computerfunctionalism\" (a term he attributes toDaniel Dennett).Functionalism is a position in modernphilosophy of mindthat holds that we can define mental phenomena (such as beliefs, desires, and perceptions) by describing their functions in relation to each other and to the outside world. Because a computer program can accuratelyrepresentfunctional relationships as relationships between symbols, a computer can have mental phenomena if it runs the right program, according to functionalism. Stevan Harnadargues that Searle's depictions of strong AI can be reformulated as \"recognizable tenets ofcomputationalism, a position (unlike \"strong AI\") that is actually held by many thinkers, and hence one worth refuting.\"Computationalismis the position in the philosophy of mind which argues that the mind can be accurately described as aninformation-processingsystem. Each of the following, according to Harnad, is a \"tenet\" of computationalism: Recent philosophical discussions have revisited the implications of computationalism for artificial intelligence. Goldstein and Levinstein explore whetherlarge language models(LLMs) likeChatGPTcan possess minds, focusing on their ability to exhibit folk psychology, including beliefs, desires, and intentions. The authors argue that LLMs satisfy several philosophical theories of mental representation, such as informational, causal, and structural theories, by demonstrating robust internal representations of the world. However, they highlight that the evidence for LLMs having action dispositions necessary for belief-desire psychology remains inconclusive. Additionally, they refute common skeptical challenges, such as the \"stochastic parrots\" argument and concerns over memorization, asserting that LLMs exhibit structured internal representations that align with these philosophical criteria. David Chalmerssuggests that while current LLMs lack features like recurrent processing and unified agency, advancements in AI could address these limitations within the next decade, potentially enabling systems to achieve consciousness. This perspective challenges Searle's original claim that purely \"syntactic\" processing cannot yield understanding or consciousness, arguing instead that such systems could have authentic mental states. Searle holds a philosophical position he calls \"biological naturalism\": that consciousnessand understanding require specific biological machinery that is found in brains. He writes \"brains cause minds\"and that \"actual human mental phenomena [are] dependent on actual physical–chemical properties of actual human brains\".Searle argues that this machinery (known inneuroscienceas the \"neural correlates of consciousness\") must have some causal powers that permit the human experience of consciousness.Searle's belief in the existence of these powers has been criticized. Searle does not disagree with the notion that machines can have consciousness and understanding, because, as he writes, \"we are precisely such machines\".Searle holds that the brain is, in fact, a machine, but that the brain gives rise to consciousness and understanding using specific machinery. If neuroscience is able to isolate the mechanical process that gives rise to consciousness, then Searle grants that it may be possible to create machines that have consciousness and understanding. However, without the specific machinery required, Searle does not believe that consciousness can occur. Biological naturalism implies that one cannot determine if the experience of consciousness is occurring merely by examining how a system functions, because the specific machinery of the brain is essential. Thus, biological naturalism is directly opposed to bothbehaviorismandfunctionalism(including \"computer functionalism\" or \"strong AI\").Biological naturalism is similar toidentity theory(the position that mental states are \"identical to\" or \"composed of\" neurological events); however, Searle has specific technical objections to identity theory.Searle's biological naturalism and strong AI are both opposed toCartesian dualism,the classical idea that the brain and mind are made of different \"substances\". Indeed, Searle accuses strong AI of dualism, writing that \"strong AI only makes sense given the dualistic assumption that, where the mind is concerned, the brain doesn't matter\". Searle's original presentation emphasized understanding—that is,mental stateswithintentionality—and did not directly address other closely related ideas such as \"consciousness\". However, in more recent presentations, Searle has included consciousness as the real target of the argument. Computational models of consciousness are not sufficient by themselves for consciousness. The computational model for consciousness stands to consciousness in the same way the computational model of anything stands to the domain being modelled. Nobody supposes that the computational model of rainstorms in London will leave us all wet. But they make the mistake of supposing that the computational model of consciousness is somehow conscious. It is the same mistake in both cases. — John R. Searle,Consciousness and Language, p. 16 David Chalmerswrites, \"it is fairly clear that consciousness is at the root of the matter\" of the Chinese room. Colin McGinnargues that the Chinese room provides strong evidence that thehard problem of consciousnessis fundamentally insoluble. The argument, to be clear, is not about whether a machine can be conscious, but about whether it (or anything else for that matter) can be shown to be conscious. It is plain that any other method of probing the occupant of a Chinese room has the same difficulties in principle as exchanging questions and answers in Chinese. It is simply not possible to divine whether a conscious agency or some cleversimulationinhabits the room. Searle argues that this is only true for an observer outside of the room. The whole point of the thought experiment is to put someone inside the room, where they can directly observe the operations of consciousness. Searle claims that from his vantage point within the room there is nothing he can see that could imaginably give rise to consciousness, other than himself, and clearly he does not have a mind that can speak Chinese. In Searle's words, \"the computer has nothing more than I have in the case where I understand nothing\". Patrick Hew used the Chinese Room argument to deduce requirements from militarycommand and controlsystems if they are to preserve a commander'smoral agency. He drew an analogy between a commander in theircommand centerand the person in the Chinese Room, and analyzed it under a reading ofAristotle's notions of \"compulsory\" and \"ignorance\". Information could be \"down converted\" from meaning to symbols, and manipulated symbolically, but moral agency could be undermined if there was inadequate 'up conversion' into meaning. Hew cited examples from theUSSVincennesincident. The Chinese room argument is primarily an argument in the philosophy of mind, and both major computer scientists and artificial intelligence researchers consider it irrelevant to their fields.However, several concepts developed by computer scientists are essential to understanding the argument, includingsymbol processing,Turing machines,Turing completeness, and the Turing test. Searle's arguments are not usually considered an issue for AI research. The primary mission of artificial intelligence research is only to create useful systems that act intelligently and it does not matter if the intelligence is \"merely\" a simulation. AI researchersStuart J. RussellandPeter Norvigwrote in 2021: \"We are interested in programs that behave intelligently. Individual aspects of consciousness—awareness, self-awareness, attention—can be programmed and can be part of an intelligent machine. The additional project making a machine conscious in exactly the way humans are is not one that we are equipped to take on.\" Searle does not disagree that AI research can create machines that are capable of highly intelligent behavior. The Chinese room argument leaves open the possibility that a digital machine could be built that acts more intelligently than a person, but does not have a mind or intentionality in the same way that brains do. Searle's \"strong AI hypothesis\" should not be confused with \"strong AI\" as defined byRay Kurzweiland other futurists,who use the term to describe machine intelligence that rivals or exceeds human intelligence—that is,artificial general intelligence,human level AIorsuperintelligence. Kurzweil is referring primarily to theamountof intelligence displayed by the machine, whereas Searle's argument sets no limit on this. Searle argues that a superintelligent machine would not necessarily have a mind and consciousness. The Chinese room implements a version of the Turing test.Alan Turingintroduced the test in 1950 to help answer the question \"can machines think?\" In the standard version, a human judge engages in a natural language conversation with a human and a machine designed to generate performance indistinguishable from that of a human being. All participants are separated from one another. If the judge cannot reliably tell the machine from the human, the machine is said to have passed the test. Turing then considered each possible objection to the proposal \"machines can think\", and found that there are simple, obvious answers if the question is de-mystified in this way. He did not, however, intend for the test to measure for the presence of \"consciousness\" or \"understanding\". He did not believe this was relevant to the issues that he was addressing. He wrote: I do not wish to give the impression that I think there is no mystery about consciousness. There is, for instance, something of a paradox connected with any attempt to localise it. But I do not think these mysteries necessarily need to be solved before we can answer the question with which we are concerned in this paper. To Searle, as a philosopher investigating in the nature of mind and consciousness, these are the relevant mysteries. The Chinese room is designed to show that the Turing test is insufficient to detect the presence of consciousness, even if the room can behave or function as a conscious mind would. Computers manipulate physical objects in order to carry out calculations and do simulations. AI researchersAllen NewellandHerbert A. Simoncalled this kind of machine aphysical symbol system. It is also equivalent to theformal systemsused in the field ofmathematical logic. Searle emphasizes the fact that this kind of symbol manipulation issyntactic(borrowing a term from the study ofgrammar). The computer manipulates the symbols using a form of syntax, without any knowledge of the symbol'ssemantics(that is, theirmeaning). Newell and Simon had conjectured that a physical symbol system (such as a digital computer) had all the necessary machinery for \"general intelligent action\", or, as it is known today,artificial general intelligence. They framed this as a philosophical position, thephysical symbol system hypothesis: \"A physical symbol system has the necessary and sufficient means for general intelligent action.\"The Chinese room argument does not refute this, because it is framed in terms of \"intelligent action\", i.e. the external behavior of the machine, rather than the presence or absence of understanding, consciousness and mind. Twenty-first century AI programs (such as \"deep learning\") do mathematical operations on huge matrixes of unidentified numbers and bear little resemblance to the symbolic processing used by AI programs at the time Searle wrote his critique in 1980.Nils Nilssondescribes systems like these as \"dynamic\" rather than \"symbolic\". Nilsson notes that these are essentially digitized representations of dynamic systems—the individual numbers do not have a specific semantics, but are insteadsamplesordata pointsfrom a dynamic signal, and it is the signal being approximated which would have semantics. Nilsson argues it is not reasonable to consider these signals as \"symbol processing\" in the same sense as the physical symbol systems hypothesis. The Chinese room has a design analogous to that of a modern computer. It has aVon Neumann architecture, which consists of a program (the book of instructions), some memory (the papers and file cabinets), a machine that follows the instructions (the man), and a means to write symbols in memory (the pencil and eraser). A machine with this design is known intheoretical computer scienceas \"Turing complete\", because it has the necessary machinery to carry out any computation that a Turing machine can do, and therefore it is capable of doing a step-by-step simulation of any other digital machine, given enough memory and time. Turing writes, \"all digital computers are in a sense equivalent.\"The widely acceptedChurch–Turing thesisholds that any function computable by an effective procedure is computable by a Turing machine. The Turing completeness of the Chinese room implies that it can do whatever any other digital computer can do (albeit much, much more slowly). Thus, if the Chinese room does not or can not contain a Chinese-speaking mind, then no other digital computer can contain a mind. Some replies to Searle begin by arguing that the room, as described, cannot have a Chinese-speaking mind. Arguments of this form, according toStevan Harnad, are \"no refutation (but rather an affirmation)\"of the Chinese room argument, because these arguments actually imply that no digital computers can have a mind. There are some critics, such as Hanoch Ben-Yami, who argue that the Chinese room cannot simulate all the abilities of a digital computer, such as being able to determine the current time. Searle has produced a more formal version of the argument of which the Chinese Room forms a part. He presented the first version in 1984. The version given below is from 1990.The Chinese room thought experiment is intended to prove point A3. He begins with three axioms: Searle posits that these lead directly to this conclusion: This much of the argument is intended to show that artificial intelligence can never produce a machine with a mind by writing programs that manipulate symbols. The remainder of the argument addresses a different issue. Is the human brain running a program? In other words, is thecomputational theory of mindcorrect?He begins with an axiom that is intended to express the basic modern scientific consensus about brains and minds: Searle claims that we can derive \"immediately\" and \"trivially\"that: And from this he derives the further conclusions: Refutations of Searle's argument take a number of different forms (see below). Computationalists and functionalists reject A3, arguing that \"syntax\" (as Searle describes it)canhave \"semantics\" if the syntax has the right functional structure. Eliminative materialists reject A2, arguing that minds don't actually have \"semantics\"—that thoughts and other mental phenomena are inherently meaningless but nevertheless function as if they had meaning. Replies to Searle's argument may be classified according to what they claim to show: Some of the arguments (robot and brain simulation, for example) fall into multiple categories. These replies attempt to answer the question: since the man in the room does not speak Chinese, where is the mind that does? These replies address the keyontologicalissues ofmind versus bodyand simulation vs. reality. All of the replies that identify the mind in the room are versions of \"the system reply\". The basic version of the system reply argues that it is the \"whole system\" that understands Chinese.While the man understands only English, when he is combined with the program, scratch paper, pencils and file cabinets, they form a system that can understand Chinese. \"Here, understanding is not being ascribed to the mere individual; rather it is being ascribed to this whole system of which he is a part\" Searle explains. Searle notes that (in this simple version of the reply) the \"system\" is nothing more than a collection of ordinary physical objects; it grants the power of understanding and consciousness to \"the conjunction of that person and bits of paper\"without making any effort to explain how this pile of objects has become a conscious, thinking being. Searle argues that no reasonable person should be satisfied with the reply, unless they are \"under the grip of an ideology;\"In order for this reply to be remotely plausible, one must take it for granted that consciousness can be the product of an information processing \"system\", and does not require anything resembling the actual biology of the brain. Searle then responds by simplifying this list of physical objects: he asks what happens if the man memorizes the rules and keeps track of everything in his head? Then the whole system consists of just one object: the man himself. Searle argues that if the man does not understand Chinese then the system does not understand Chinese either because now \"the system\" and \"the man\" both describe exactly the same object. Critics of Searle's response argue that the program has allowed the man to have two minds in one head.If we assume a \"mind\" is a form of information processing, then thetheory of computationcan account for two computations occurring at once, namely (1) the computation foruniversal programmability(which is the function instantiated by the person and note-taking materials independently from any particular program contents) and (2) the computation of the Turing machine that is described by the program (which is instantiated by everything including the specific program).The theory of computation thus formally explains the open possibility that the second computation in the Chinese Room could entail a human-equivalent semantic understanding of the Chinese inputs. The focus belongs on the program's Turing machine rather than on the person's.However, from Searle's perspective, this argument is circular. The question at issue is whether consciousness is a form of information processing, and this reply requires that we make that assumption. More sophisticated versions of the systems reply try to identify more precisely what \"the system\" is and they differ in exactly how they describe it. According to these replies,the \"mind that speaks Chinese\" could be such things as: the \"software\", a \"program\", a \"running program\", a simulation of the \"neural correlates of consciousness\", the \"functional system\", a \"simulated mind\", an \"emergentproperty\", or \"a virtual mind\". Marvin Minskysuggested a version of the system reply known as the \"virtual mind reply\".The term \"virtual\" is used in computer science to describe an object that appears to exist \"in\" a computer (or computer network) only because software makes it appear to exist. The objects \"inside\" computers (including files, folders, and so on) are all \"virtual\", except for the computer's electronic components. Similarly, Minsky proposes that a computer may contain a \"mind\" that is virtual in the same sense asvirtual machines,virtual communitiesandvirtual reality. To clarify the distinction between the simple systems reply given above and virtual mind reply, David Cole notes that two simulations could be running on one system at the same time: one speaking Chinese and one speaking Korean. While there is only one system, there can be multiple \"virtual minds,\" thus the \"system\" cannot be the \"mind\". Searle responds that such a mind is at best a simulation, and writes: \"No one supposes that computer simulations of a five-alarm fire will burn the neighborhood down or that a computer simulation of a rainstorm will leave us all drenched.\"Nicholas Fearn responds that, for some things, simulation is as good as the real thing. \"When we call up the pocket calculator function on a desktop computer, the image of a pocket calculator appears on the screen. We don't complain that it isn't really a calculator, because the physical attributes of the device do not matter.\"The question is, is the human mind like the pocket calculator, essentially composed of information, where a perfect simulation of the thing justisthe thing? Or is the mind like the rainstorm, a thing in the world that is more than just its simulation, and not realizable in full by a computer simulation? For decades, this question of simulation has led AI researchers and philosophers to consider whether the term \"synthetic intelligence\" is more appropriate than the common description of such intelligences as \"artificial.\" These replies provide an explanation of exactly who it is that understands Chinese. If there is somethingbesidesthe man in the room that can understand Chinese, Searle cannot argue that (1) the man does not understand Chinese, therefore (2) nothing in the room understands Chinese. This, according to those who make this reply, shows that Searle's argument fails to prove that \"strong AI\" is false. These replies, by themselves, do not provide any evidence that strong AI is true, however. They do not show that the system (or the virtual mind) understands Chinese, other than the hypothetical premise that it passes the Turing test. Searle argues that, if we are to consider Strong AI remotely plausible, the Chinese Room is an example that requires explanation, and it is difficult or impossible to explain how consciousness might \"emerge\" from the room or how the system would have consciousness. As Searle writes \"the systems reply simply begs the question by insisting that the system must understand Chinese\"and thus is dodging the question or hopelessly circular. As far as the person in the room is concerned, the symbols are just meaningless \"squiggles.\" But if the Chinese room really \"understands\" what it is saying, then the symbols must get their meaning from somewhere. These arguments attempt to connect the symbols to the things they symbolize. These replies address Searle's concerns aboutintentionality,symbol groundingandsyntaxvs.semantics. Suppose that instead of a room, the program was placed into a robot that could wander around and interact with its environment. This would allow a \"causalconnection\" between the symbols and things they represent.Hans Moraveccomments: \"If we could graft a robot to a reasoning program, we wouldn't need a person to provide the meaning anymore: it would come from the physical world.\" Searle's reply is to suppose that, unbeknownst to the individual in the Chinese room, some of the inputs came directly from a camera mounted on a robot, and some of the outputs were used to manipulate the arms and legs of the robot. Nevertheless, the person in the room is still just following the rules, and does not know what the symbols mean. Searle writes \"he doesn'tseewhat comes into the robot's eyes.\" Some respond that the room, as Searle describes it, is connected to the world: through the Chinese speakers that it is \"talking\" to and through the programmers who designed theknowledge basein his file cabinet. The symbols Searle manipulates are already meaningful, they are just not meaningful to him. Searle says that the symbols only have a \"derived\" meaning, like the meaning of words in books. The meaning of the symbols depends on the conscious understanding of the Chinese speakers and the programmers outside the room. The room, like a book, has no understanding of its own. Some have argued that the meanings of the symbols would come from a vast \"background\" ofcommonsense knowledgeencoded in the program and the filing cabinets. This would provide a \"context\" that would give the symbols their meaning. Searle agrees that this background exists, but he does not agree that it can be built into programs.Hubert Dreyfushas also criticized the idea that the \"background\" can be represented symbolically. To each of these suggestions, Searle's response is the same: no matter how much knowledge is written into the program and no matter how the program is connected to the world, he is still in the room manipulating symbols according to rules. His actions are syntactic and this can never explain to him what the symbols stand for. Searle writes \"syntax is insufficient for semantics.\" However, for those who accept that Searle's actions simulate a mind, separate from his own, the important question is not what the symbols mean to Searle, what is important is what they mean to the virtual mind. While Searle is trapped in the room, the virtual mind is not: it is connected to the outside world through the Chinese speakers it speaks to, through the programmers who gave it world knowledge, and through the cameras and other sensors thatroboticistscan supply. These arguments are all versions of the systems reply that identify a particular kind of system as being important; they identify some special technology that would create conscious understanding in a machine. (The \"robot\" and \"commonsense knowledge\" replies above also specify a certain kind of system as being important.) Suppose that the program simulated in fine detail the action of every neuron in the brain of a Chinese speaker.This strengthens the intuition that there would be no significant difference between the operation of the program and the operation of a live human brain. Searle replies that such a simulation does not reproduce the important features of the brain—its causal and intentional states. He is adamant that \"human mental phenomena [are] dependent on actual physical–chemical properties of actual human brains.\"Moreover, he argues: [I]magine that instead of a monolingual man in a room shuffling symbols we have the man operate an elaborate set of water pipes with valves connecting them. When the man receives the Chinese symbols, he looks up in the program, written in English, which valves he has to turn on and off. Each water connection corresponds to a synapse in the Chinese brain, and the whole system is rigged up so that after doing all the right firings, that is after turning on all the right faucets, the Chinese answers pop out at the output end of the series of pipes.\nNow, where is the understanding in this system? It takes Chinese as input, it simulates the formal structure of the synapses of the Chinese brain, and it gives Chinese as output. But the man certainly does not understand Chinese, and neither do the water pipes, and if we are tempted to adopt what I think is the absurd view that somehow the conjunction of man and water pipes understands, remember that in principle the man can internalize the formal structure of the water pipes and do all the \"neuron firings\" in his imagination. What if we ask each citizen of China to simulate one neuron, using the telephone system, to simulate the connections betweenaxonsanddendrites? In this version, it seems obvious that no individual would have any understanding of what the brain might be saying.It is also obvious that this system would be functionally equivalent to a brain, so if consciousness is a function, this system would be conscious. In this, we are asked to imagine that engineers have invented a tiny computer that simulates the action of an individual neuron. What would happen if we replaced one neuron at a time? Replacing one would clearly do nothing to change conscious awareness. Replacing all of them would create a digital computer that simulates a brain. If Searle is right, then conscious awareness must disappear during the procedure (either gradually or all at once). Searle's critics argue that there would be no point during the procedure when he can claim that conscious awareness ends and mindless simulation begins.(SeeShip of Theseusfor a similar thought experiment.) These arguments (and the robot or common-sense knowledge replies) identify some special technology that would help create conscious understanding in a machine. They may be interpreted in two ways: either they claim (1) this technology is required for consciousness, the Chinese room does not or cannot implement this technology, and therefore the Chinese room cannot pass the Turing test or (even if it did) it would not have conscious understanding. Or they may be claiming that (2) it is easier to see that the Chinese room has a mind if we visualize this technology as being used to create it. In the first case, where features like a robot body or a connectionist architecture are required, Searle claims that strong AI (as he understands it) has been abandoned.The Chinese room has all the elements of a Turing complete machine, and thus is capable of simulating any digital computation whatsoever. If Searle's room cannot pass the Turing test then there is no other digital technology that could pass the Turing test. If Searle's room could pass the Turing test, but still does not have a mind, then the Turing test is not sufficient to determine if the room has a \"mind\". Either way, it denies one or the other of the positions Searle thinks of as \"strong AI\", proving his argument. The brain arguments in particular deny strong AI if they assume that there is no simpler way to describe the mind than to create a program that is just as mysterious as the brain was. He writes \"I thought the whole idea of strong AI was that we don't need to know how the brain works to know how the mind works.\"If computation does not provide an explanation of the human mind, then strong AI has failed, according to Searle. Other critics hold that the room as Searle described it does, in fact, have a mind, however they argue that it is difficult to see—Searle's description is correct, but misleading. By redesigning the room more realistically they hope to make this more obvious. In this case, these arguments are being used as appeals to intuition (see next section). In fact, the room can just as easily be redesigned to weaken our intuitions.Ned Block'sBlockhead argumentsuggests that the program could, in theory, be rewritten into a simplelookup tableofrulesof the form \"if the user writesS, reply withPand goto X\". At least in principle, any program can be rewritten (or \"refactored\") into this form, even a brain simulation.In the blockhead scenario, the entire mental state is hidden in the letter X, which represents amemory address—a number associated with the next rule. It is hard to visualize that an instant of one's conscious experience can be captured in a single large number, yet this is exactly what \"strong AI\" claims. On the other hand, such a lookup table would be ridiculously large (to the point of being physically impossible), and the states could therefore be overly specific. Searle argues that however the program is written or however the machine is connected to the world, the mind is being simulated  by a simple step-by-step digital machine (or machines). These machines are always just like the man in the room: they understand nothing and do not speak Chinese. They are merely manipulating symbols without knowing what they mean. Searle writes: \"I can have any formal program you like, but I still understand nothing.\" The following arguments (and the intuitive interpretations of the arguments above) do not directly explain how a Chinese speaking mind could exist in Searle's room, or how the symbols he manipulates could become meaningful. However, by raising doubts about Searle's intuitions they support other positions, such as the system and robot replies. These arguments, if accepted, prevent Searle from claiming that his conclusion is obvious by undermining the intuitions that his certainty requires. Several critics believe that Searle's argument relies entirely on intuitions. Block writes \"Searle's argument depends for its force on intuitions that certain entities do not think.\"Daniel Dennettdescribes the Chinese room argument as a misleading \"intuition pump\"and writes \"Searle's thought experiment depends, illicitly, on your imagining too simple a case, an irrelevant case, and drawing the obvious conclusion from it.\" Some of the arguments above also function as appeals to intuition, especially those that are intended to make it seem more plausible that the Chinese room contains a mind, which can include the robot, commonsense knowledge, brain simulation and connectionist replies. Several of the replies above also address the specific issue of complexity. The connectionist reply emphasizes that a working artificial intelligence system would have to be as complex and as interconnected as the human brain. The commonsense knowledge reply emphasizes that any program that passed a Turing test would have to be \"an extraordinarily supple, sophisticated, and multilayered system, brimming with 'world knowledge' and meta-knowledge and meta-meta-knowledge\", asDaniel Dennettexplains. Many of these critiques emphasize speed and complexity of the human brain,which processes information at 100 billion operations per second (by some estimates).Several critics point out that the man in the room would probably take millions of years to respond to a simple question, and would require \"filing cabinets\" of astronomical proportions.This brings the clarity of Searle's intuition into doubt. An especially vivid version of the speed and complexity reply is fromPaulandPatricia Churchland. They propose this analogous thought experiment: \"Consider a dark room containing a man holding a bar magnet or charged object. If the man pumps the magnet up and down, then, according toMaxwell's theory of artificial luminance (AL), it will initiate a spreading circle of electromagnetic waves and will thus be luminous. But as all of us who have toyed with magnets or charged balls well know, their forces (or any other forces for that matter), even when set in motion produce no luminance at all. It is inconceivable that you might constitute real luminance just by moving forces around!\"Churchland's point is that the problem is that he would have to wave the magnet up and down something like 450 trillion times per second in order to see anything. Stevan Harnadis critical of speed and complexity replies when they stray beyond addressing our intuitions. He writes \"Some have made a cult of speed and timing, holding that, when accelerated to the right speed, the computational may make aphase transitioninto the mental. It should be clear that is not a counterargument but merely an ad hoc speculation (as is the view that it is all just a matter of ratcheting up to the right degree of 'complexity.')\" Searle argues that his critics are also relying on intuitions, however his opponents' intuitions have no empirical basis. He writes that, in order to consider the \"system reply\" as remotely plausible, a person must be \"under the grip of an ideology\".The system reply only makes sense (to Searle) if one assumes that any \"system\" can have consciousness, just by virtue of being a system with the right behavior and functional parts. This assumption, he argues, is not tenable given our experience of consciousness. Several replies argue that Searle's argument is irrelevant because his assumptions about the mind and consciousness are faulty. Searle believes that human beings directly experience their consciousness, intentionality and the nature of the mind every day, and that this experience of consciousness is not open to question. He writes that we must \"presuppose the reality and knowability of the mental.\"The replies below question whether Searle is justified in using his own experience of consciousness to determine that it is more than mechanical symbol processing. In particular, the other minds reply argues that we cannot use our experience of consciousness to answer questions about other minds (even the mind of a computer), the epiphenoma replies question whether we can make any argument at all about something like consciousness which can not, by definition, be detected by any experiment, and the eliminative materialist reply argues that Searle's own personal consciousness does not \"exist\" in the sense that Searle thinks it does. The \"Other Minds Reply\" points out that Searle's argument is a version of theproblem of other minds, applied to machines. There is no way we can determine if other people's subjective experience is the same as our own. We can only study their behavior (i.e., by giving them our own Turing test). Critics of Searle argue that he is holding the Chinese room to a higher standard than we would hold an ordinary person. Nils Nilssonwrites \"If a program behavesas ifit were multiplying, most of us would say that it is, in fact, multiplying. For all I know, Searle may only be behavingas ifhe were thinking deeply about these matters. But, even though I disagree with him, his simulation is pretty good, so I'm willing to credit him with real thought.\" Turing anticipated Searle's line of argument (which he called \"The Argument from Consciousness\") in 1950 and makes the other minds reply.He noted that people never consider the problem of other minds when dealing with each other. He writes that \"instead of arguing continually over this point it is usual to have the polite convention that everyone thinks.\"TheTuring testsimply extends this \"polite convention\" to machines. He does not intend to solve the problem of other minds (for machines or people) and he does not think we need to. If we accept Searle's description of intentionality, consciousness, and the mind, we are forced to accept that consciousness isepiphenomenal: that it \"casts no shadow\" i.e. is undetectable in the outside world. Searle's \"causal properties\" cannot be detected by anyone outside the mind, otherwise the Chinese Room could not pass the Turing test—the people outside would be able to tell there was not a Chinese speaker in the room by detecting their causal properties. Since they cannot detect causal properties, they cannot detect the existence of the mental. Thus, Searle's \"causal properties\" and consciousness itself is undetectable, and anything that cannot be detected either does not exist or does not matter. Mike Aldercalls this the \"Newton's Flaming Laser Sword Reply\". He argues that the entire argument is frivolous, because it is non-verificationist: not only is the distinction betweensimulatinga mind andhavinga mind ill-defined, but it is also irrelevant because no experiments were, or even can be, proposed to distinguish between the two. Daniel Dennett provides this illustration: suppose that, by some mutation, a human being is born that does not have Searle's \"causal properties\" but nevertheless acts exactly like a human being. This is aphilosophical zombie, as formulated in thephilosophy of mind. This new animal would reproduce just as any other human and eventually there would be more of these zombies. Natural selection would favor the zombies, since their design is (we could suppose) a bit simpler. Eventually the humans would die out. So therefore, if Searle is right, it is most likely that human beings (as we see them today) are actually \"zombies\", who nevertheless insist they are conscious. It is impossible to know whether we are all zombies or not. Even if we are all zombies, we would still believe that we are not. Several philosophers argue that consciousness, as Searle describes it, does not exist.Daniel Dennettdescribes consciousness as a \"user illusion\". This position is sometimes referred to aseliminative materialism: the view that consciousness is not a concept that can \"enjoy reduction\" to a strictly mechanical description, but rather is a concept that will be simplyeliminatedonce the way thematerialbrain works is fully understood, in just the same way as the concept of ademonhas already been eliminated from science rather than enjoying reduction to a strictly mechanical description. Other mental properties, such as original intentionality (also called \"meaning\", \"content\", and \"semantic character\"), are also commonly regarded as special properties related to beliefs and other propositional attitudes. Eliminative materialism maintains that propositional attitudes such as beliefs and desires, among other intentional mental states that have content, do not exist. If eliminative materialism is the correct scientific account of human cognition then the assumption of the Chinese room argument that \"minds have mental contents (semantics)\" must be rejected. Searle disagrees with this analysis and argues that \"the study of the mind starts with such facts as that humans have beliefs, while thermostats, telephones, and adding machines don't ... what we wanted to know is what distinguishes the mind from thermostats and livers.\"He takes it as obvious that we can detect the presence of consciousness and dismisses these replies as being off the point. Margaret Bodenargued in her paper \"Escaping from the Chinese Room\" that even if the person in the room does not understand the Chinese, it does not mean there is no understanding in the room. The person in the room at least understands the rule book used to provide output responses. She then points out that the same applies to machine languages: a natural language sentence is understood by the programming language code that instantiates it, which in turn is understood by the lower-level compiler code, and so on. This implies that the distinction between syntax and semantics is not fixed, as Searle presupposes, but relative: the semantics of natural language is realized in the syntax of programming language; the semantics of programming language has a semantics that is realized in the syntax of compiler code. Searle's problem is a failure to assume a binary notion of understanding or not, rather than a graded one, where each system is stupider than the next. Searle's conclusion that \"human mental phenomena [are] dependent on actual physical–chemical properties of actual human brains\"has sometimes been described as a form of \"carbon chauvinism\".Steven Pinkersuggested that a response to that conclusion would be to make a counter thought experiment to the Chinese Room, where the incredulity goes the other way.He brings as an example the short storyThey're Made Out of Meatwhich depicts an alien race composed of some electronic beings, who upon finding Earth express disbelief that the meat brains of humans can experience consciousness and thought. However, Searle himself denied being carbon chauvinist.He said \"I have not tried to show that only biological based systems like our brains can think ... I regard this issue as up for grabs\".He said that even silicon machines could theoretically have human-like consciousness and thought, if the actual physical–chemical properties of silicon could be used in a way that produces consciousness and thought, but \"until we know how the brain does it we are not in a position to try to do it artificially\".", "combined_text": "Chinese room Contents Chinese room thought experiment History Philosophy Strong AI Strong AI as computationalism or functionalism Strong AI vs. biological naturalism Consciousness Applied ethics Computer science Strong AI vs. AI research Turing test Symbol processing Chinese room and Turing completeness Complete argument Replies Systems and virtual mind replies: finding the mind Robot and semantics replies: finding the meaning Brain simulation and connectionist replies: redesigning the room Speed and complexity: appeals to intuition Other minds and zombies: meaninglessness Other replies See also Notes Citations References Further reading Works involving Searle  TheChinese room argumentholds that a computer executing aprogramcannot have amind,understanding, orconsciousness,regardless of how intelligently or human-like the program may make the computer behave. The argument was presented in a 1980 paper by the philosopherJohn Searleentitled \"Minds, Brains, and Programs\" and published in the journalBehavioral and Brain Sciences.Similar arguments had been made byGottfried Wilhelm Leibniz(1714),Ned Block(1978) and others. Searle's version has been widely discussed in the years since.The centerpiece of Searle's argument is athought experimentknown as theChinese room. The argument is directed against the philosophical positions offunctionalismandcomputationalism,which hold that the mind may be viewed as an information-processing system operating on formal symbols, and that simulation of a given mental state is sufficient for its presence. Specifically, the argument is intended to refute a position Searle calls thestrong AI hypothesis:\"The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.\" Although its proponents originally presented the argument in reaction to statements ofartificial intelligence(AI) researchers, it is not an argument against the goals of mainstream AI research because it does not show a limit in the amount of intelligent behavior a machine can display.The argument applies only to digital computers running programs and does not apply to machines in general.While widely discussed, the argument has been subject to significant criticism and remains controversial amongphilosophers of mindand AI researchers. Suppose that artificial intelligence research has succeeded in programming a computer to behave as if it understands Chinese. The machine acceptsChinese charactersas input, carries out each instruction of the program step by step, and then produces Chinese characters as output. The machine does this so perfectly that no one can tell that they are communicating with a machine and not a hidden Chinese speaker. The questions at issue are these: does the machine actuallyunderstandthe conversation, or is it justsimulatingthe ability to understand the conversation? Does the machine have a mind in exactly the same sense that people do, or is it just actingas ifit had a mind? Now suppose that Searle is in a room with an English version of the program, along with sufficient pencils, paper, erasers and filing cabinets. Chinese characters are slipped in under the door, he follows the program step-by-step, which eventually instructs him to slide other Chinese characters back out under the door. If the computer had passed theTuring testthis way, it follows that Searle would do so as well, simply by running the program by hand. Searle can see no essential difference between the roles of the computerand himself in the experiment. Each simply follows a program, step-by-step, producing behavior that makes them appear to understand. However, Searle would not be able to understand the conversation. Therefore, he argues, it follows that the computer would not be able to understand the conversation either. Searle argues that, without \"understanding\" (or \"intentionality\"), we cannot describe what the machine is doing as \"thinking\" and, since it does not think, it does not have a \"mind\" in the normal sense of the word. Therefore, he concludes that the strong AI hypothesis is false: a computer running a program that simulates a mind would not have a mind in the same sense that human beings have a mind. Gottfried Leibnizmade a similar argument in 1714 againstmechanism(the idea that everything that makes up a human being could, in principle, be explained in mechanical terms. In other words, that a person, including their mind, is merely a very complex machine). Leibniz used the thought experiment of expanding the brain until it was the size of a mill.Leibniz found it difficult to imagine that a \"mind\" capable of \"perception\" could be constructed using only mechanical processes. Peter Winchmade the same point in his bookThe Idea of a Social Science and its Relation to Philosophy(1958), where he provides an argument to show that \"a man who understands Chinese is not a man who has a firm grasp of the statistical probabilities for the occurrence of the various words in the Chinese language\" (p. 108). Soviet cyberneticistAnatoly Dneprovmade an essentially identical argument in 1961, in the form of the short story \"The Game\". In it, a stadium of people act as switches and memory cells implementing a program to translate a sentence of Portuguese, a language that none of them know.The game was organized by a \"Professor Zarubin\" to answer the question \"Can mathematical machines think?\" Speaking through Zarubin, Dneprov writes \"the only way to prove that machines can think is to turn yourself into a machine and examine your thinking process\" and he concludes, as Searle does, \"We've proven that even the most perfect simulation of machine thinking is not the thinking process itself.\" In 1974,Lawrence H. Davisimagined duplicating the brain using telephone lines and offices staffed by people, and in 1978Ned Blockenvisioned the entire population of China involved in such a brain simulation. This thought experiment is called theChina brain, also the \"Chinese Nation\" or the \"Chinese Gym\". Searle's version appeared in his 1980 paper \"Minds, Brains, and Programs\", published inBehavioral and Brain Sciences.It eventually became the journal's \"most influential target article\",generating an enormous number of commentaries and responses in the ensuing decades, and Searle has continued to defend and refine the argument in multiple papers, popular articles and books. David Cole writes that \"the Chinese Room argument has probably been the most widely discussed philosophical argument in cognitive science to appear in the past 25 years\". Most of the discussion consists of attempts to refute it. \"The overwhelming majority\", notesBehavioral and Brain ScienceseditorStevan Harnad,\"still think that the Chinese Room Argument is dead wrong\".The sheer volume of the literature that has grown up around it inspiredPat Hayesto comment that the field ofcognitive scienceought to be redefined as \"the ongoing research program of showing Searle's Chinese Room Argument to be false\". Searle's argument has become \"something of a classic in cognitive science\", according to Harnad.Varol Akmanagrees, and has described the original paper as \"an exemplar of philosophical clarity and purity\". Although the Chinese Room argument was originally presented in reaction to the statements ofartificial intelligenceresearchers, philosophers have come to consider it as an important part of thephilosophy of mind. It is a challenge tofunctionalismand thecomputational theory of mind,and is related to such questions as themind–body problem, theproblem of other minds, thesymbol groundingproblem, and thehard problem of consciousness. Searle identified a philosophical position he calls \"strong AI\": The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds. The definition depends on the distinction between simulating a mind and actually having one. Searle writes that \"according to Strong AI, the correct simulation really is a mind. According to Weak AI, the correct simulation is a model of the mind.\" The claim is implicit in some of the statements of early AI researchers and analysts. For example, in 1957, the economist and psychologistHerbert A. Simondeclared that \"there are now in the world machines that think, that learn and create\".Simon, together withAllen NewellandCliff Shaw, after having completed the first program that could doformal reasoning(theLogic Theorist), claimed that they had \"solved the venerable mind–body problem, explaining how a system composed of matter can have the properties of mind.\"John Haugelandwrote that \"AI wants only the genuine article:machines with minds, in the full and literal sense. This is not science fiction, but real science, based on a theoretical conception as deep as it is daring: namely, we are, at root,computers ourselves.\" Searle also ascribes the following claims to advocates of strong AI: In more recent presentations of the Chinese room argument, Searle has identified \"strong AI\" as \"computerfunctionalism\" (a term he attributes toDaniel Dennett).Functionalism is a position in modernphilosophy of mindthat holds that we can define mental phenomena (such as beliefs, desires, and perceptions) by describing their functions in relation to each other and to the outside world. Because a computer program can accuratelyrepresentfunctional relationships as relationships between symbols, a computer can have mental phenomena if it runs the right program, according to functionalism. Stevan Harnadargues that Searle's depictions of strong AI can be reformulated as \"recognizable tenets ofcomputationalism, a position (unlike \"strong AI\") that is actually held by many thinkers, and hence one worth refuting.\"Computationalismis the position in the philosophy of mind which argues that the mind can be accurately described as aninformation-processingsystem. Each of the following, according to Harnad, is a \"tenet\" of computationalism: Recent philosophical discussions have revisited the implications of computationalism for artificial intelligence. Goldstein and Levinstein explore whetherlarge language models(LLMs) likeChatGPTcan possess minds, focusing on their ability to exhibit folk psychology, including beliefs, desires, and intentions. The authors argue that LLMs satisfy several philosophical theories of mental representation, such as informational, causal, and structural theories, by demonstrating robust internal representations of the world. However, they highlight that the evidence for LLMs having action dispositions necessary for belief-desire psychology remains inconclusive. Additionally, they refute common skeptical challenges, such as the \"stochastic parrots\" argument and concerns over memorization, asserting that LLMs exhibit structured internal representations that align with these philosophical criteria. David Chalmerssuggests that while current LLMs lack features like recurrent processing and unified agency, advancements in AI could address these limitations within the next decade, potentially enabling systems to achieve consciousness. This perspective challenges Searle's original claim that purely \"syntactic\" processing cannot yield understanding or consciousness, arguing instead that such systems could have authentic mental states. Searle holds a philosophical position he calls \"biological naturalism\": that consciousnessand understanding require specific biological machinery that is found in brains. He writes \"brains cause minds\"and that \"actual human mental phenomena [are] dependent on actual physical–chemical properties of actual human brains\".Searle argues that this machinery (known inneuroscienceas the \"neural correlates of consciousness\") must have some causal powers that permit the human experience of consciousness.Searle's belief in the existence of these powers has been criticized. Searle does not disagree with the notion that machines can have consciousness and understanding, because, as he writes, \"we are precisely such machines\".Searle holds that the brain is, in fact, a machine, but that the brain gives rise to consciousness and understanding using specific machinery. If neuroscience is able to isolate the mechanical process that gives rise to consciousness, then Searle grants that it may be possible to create machines that have consciousness and understanding. However, without the specific machinery required, Searle does not believe that consciousness can occur. Biological naturalism implies that one cannot determine if the experience of consciousness is occurring merely by examining how a system functions, because the specific machinery of the brain is essential. Thus, biological naturalism is directly opposed to bothbehaviorismandfunctionalism(including \"computer functionalism\" or \"strong AI\").Biological naturalism is similar toidentity theory(the position that mental states are \"identical to\" or \"composed of\" neurological events); however, Searle has specific technical objections to identity theory.Searle's biological naturalism and strong AI are both opposed toCartesian dualism,the classical idea that the brain and mind are made of different \"substances\". Indeed, Searle accuses strong AI of dualism, writing that \"strong AI only makes sense given the dualistic assumption that, where the mind is concerned, the brain doesn't matter\". Searle's original presentation emphasized understanding—that is,mental stateswithintentionality—and did not directly address other closely related ideas such as \"consciousness\". However, in more recent presentations, Searle has included consciousness as the real target of the argument. Computational models of consciousness are not sufficient by themselves for consciousness. The computational model for consciousness stands to consciousness in the same way the computational model of anything stands to the domain being modelled. Nobody supposes that the computational model of rainstorms in London will leave us all wet. But they make the mistake of supposing that the computational model of consciousness is somehow conscious. It is the same mistake in both cases. — John R. Searle,Consciousness and Language, p. 16 David Chalmerswrites, \"it is fairly clear that consciousness is at the root of the matter\" of the Chinese room. Colin McGinnargues that the Chinese room provides strong evidence that thehard problem of consciousnessis fundamentally insoluble. The argument, to be clear, is not about whether a machine can be conscious, but about whether it (or anything else for that matter) can be shown to be conscious. It is plain that any other method of probing the occupant of a Chinese room has the same difficulties in principle as exchanging questions and answers in Chinese. It is simply not possible to divine whether a conscious agency or some cleversimulationinhabits the room. Searle argues that this is only true for an observer outside of the room. The whole point of the thought experiment is to put someone inside the room, where they can directly observe the operations of consciousness. Searle claims that from his vantage point within the room there is nothing he can see that could imaginably give rise to consciousness, other than himself, and clearly he does not have a mind that can speak Chinese. In Searle's words, \"the computer has nothing more than I have in the case where I understand nothing\". Patrick Hew used the Chinese Room argument to deduce requirements from militarycommand and controlsystems if they are to preserve a commander'smoral agency. He drew an analogy between a commander in theircommand centerand the person in the Chinese Room, and analyzed it under a reading ofAristotle's notions of \"compulsory\" and \"ignorance\". Information could be \"down converted\" from meaning to symbols, and manipulated symbolically, but moral agency could be undermined if there was inadequate 'up conversion' into meaning. Hew cited examples from theUSSVincennesincident. The Chinese room argument is primarily an argument in the philosophy of mind, and both major computer scientists and artificial intelligence researchers consider it irrelevant to their fields.However, several concepts developed by computer scientists are essential to understanding the argument, includingsymbol processing,Turing machines,Turing completeness, and the Turing test. Searle's arguments are not usually considered an issue for AI research. The primary mission of artificial intelligence research is only to create useful systems that act intelligently and it does not matter if the intelligence is \"merely\" a simulation. AI researchersStuart J. RussellandPeter Norvigwrote in 2021: \"We are interested in programs that behave intelligently. Individual aspects of consciousness—awareness, self-awareness, attention—can be programmed and can be part of an intelligent machine. The additional project making a machine conscious in exactly the way humans are is not one that we are equipped to take on.\" Searle does not disagree that AI research can create machines that are capable of highly intelligent behavior. The Chinese room argument leaves open the possibility that a digital machine could be built that acts more intelligently than a person, but does not have a mind or intentionality in the same way that brains do. Searle's \"strong AI hypothesis\" should not be confused with \"strong AI\" as defined byRay Kurzweiland other futurists,who use the term to describe machine intelligence that rivals or exceeds human intelligence—that is,artificial general intelligence,human level AIorsuperintelligence. Kurzweil is referring primarily to theamountof intelligence displayed by the machine, whereas Searle's argument sets no limit on this. Searle argues that a superintelligent machine would not necessarily have a mind and consciousness. The Chinese room implements a version of the Turing test.Alan Turingintroduced the test in 1950 to help answer the question \"can machines think?\" In the standard version, a human judge engages in a natural language conversation with a human and a machine designed to generate performance indistinguishable from that of a human being. All participants are separated from one another. If the judge cannot reliably tell the machine from the human, the machine is said to have passed the test. Turing then considered each possible objection to the proposal \"machines can think\", and found that there are simple, obvious answers if the question is de-mystified in this way. He did not, however, intend for the test to measure for the presence of \"consciousness\" or \"understanding\". He did not believe this was relevant to the issues that he was addressing. He wrote: I do not wish to give the impression that I think there is no mystery about consciousness. There is, for instance, something of a paradox connected with any attempt to localise it. But I do not think these mysteries necessarily need to be solved before we can answer the question with which we are concerned in this paper. To Searle, as a philosopher investigating in the nature of mind and consciousness, these are the relevant mysteries. The Chinese room is designed to show that the Turing test is insufficient to detect the presence of consciousness, even if the room can behave or function as a conscious mind would. Computers manipulate physical objects in order to carry out calculations and do simulations. AI researchersAllen NewellandHerbert A. Simoncalled this kind of machine aphysical symbol system. It is also equivalent to theformal systemsused in the field ofmathematical logic. Searle emphasizes the fact that this kind of symbol manipulation issyntactic(borrowing a term from the study ofgrammar). The computer manipulates the symbols using a form of syntax, without any knowledge of the symbol'ssemantics(that is, theirmeaning). Newell and Simon had conjectured that a physical symbol system (such as a digital computer) had all the necessary machinery for \"general intelligent action\", or, as it is known today,artificial general intelligence. They framed this as a philosophical position, thephysical symbol system hypothesis: \"A physical symbol system has the necessary and sufficient means for general intelligent action.\"The Chinese room argument does not refute this, because it is framed in terms of \"intelligent action\", i.e. the external behavior of the machine, rather than the presence or absence of understanding, consciousness and mind. Twenty-first century AI programs (such as \"deep learning\") do mathematical operations on huge matrixes of unidentified numbers and bear little resemblance to the symbolic processing used by AI programs at the time Searle wrote his critique in 1980.Nils Nilssondescribes systems like these as \"dynamic\" rather than \"symbolic\". Nilsson notes that these are essentially digitized representations of dynamic systems—the individual numbers do not have a specific semantics, but are insteadsamplesordata pointsfrom a dynamic signal, and it is the signal being approximated which would have semantics. Nilsson argues it is not reasonable to consider these signals as \"symbol processing\" in the same sense as the physical symbol systems hypothesis. The Chinese room has a design analogous to that of a modern computer. It has aVon Neumann architecture, which consists of a program (the book of instructions), some memory (the papers and file cabinets), a machine that follows the instructions (the man), and a means to write symbols in memory (the pencil and eraser). A machine with this design is known intheoretical computer scienceas \"Turing complete\", because it has the necessary machinery to carry out any computation that a Turing machine can do, and therefore it is capable of doing a step-by-step simulation of any other digital machine, given enough memory and time. Turing writes, \"all digital computers are in a sense equivalent.\"The widely acceptedChurch–Turing thesisholds that any function computable by an effective procedure is computable by a Turing machine. The Turing completeness of the Chinese room implies that it can do whatever any other digital computer can do (albeit much, much more slowly). Thus, if the Chinese room does not or can not contain a Chinese-speaking mind, then no other digital computer can contain a mind. Some replies to Searle begin by arguing that the room, as described, cannot have a Chinese-speaking mind. Arguments of this form, according toStevan Harnad, are \"no refutation (but rather an affirmation)\"of the Chinese room argument, because these arguments actually imply that no digital computers can have a mind. There are some critics, such as Hanoch Ben-Yami, who argue that the Chinese room cannot simulate all the abilities of a digital computer, such as being able to determine the current time. Searle has produced a more formal version of the argument of which the Chinese Room forms a part. He presented the first version in 1984. The version given below is from 1990.The Chinese room thought experiment is intended to prove point A3. He begins with three axioms: Searle posits that these lead directly to this conclusion: This much of the argument is intended to show that artificial intelligence can never produce a machine with a mind by writing programs that manipulate symbols. The remainder of the argument addresses a different issue. Is the human brain running a program? In other words, is thecomputational theory of mindcorrect?He begins with an axiom that is intended to express the basic modern scientific consensus about brains and minds: Searle claims that we can derive \"immediately\" and \"trivially\"that: And from this he derives the further conclusions: Refutations of Searle's argument take a number of different forms (see below). Computationalists and functionalists reject A3, arguing that \"syntax\" (as Searle describes it)canhave \"semantics\" if the syntax has the right functional structure. Eliminative materialists reject A2, arguing that minds don't actually have \"semantics\"—that thoughts and other mental phenomena are inherently meaningless but nevertheless function as if they had meaning. Replies to Searle's argument may be classified according to what they claim to show: Some of the arguments (robot and brain simulation, for example) fall into multiple categories. These replies attempt to answer the question: since the man in the room does not speak Chinese, where is the mind that does? These replies address the keyontologicalissues ofmind versus bodyand simulation vs. reality. All of the replies that identify the mind in the room are versions of \"the system reply\". The basic version of the system reply argues that it is the \"whole system\" that understands Chinese.While the man understands only English, when he is combined with the program, scratch paper, pencils and file cabinets, they form a system that can understand Chinese. \"Here, understanding is not being ascribed to the mere individual; rather it is being ascribed to this whole system of which he is a part\" Searle explains. Searle notes that (in this simple version of the reply) the \"system\" is nothing more than a collection of ordinary physical objects; it grants the power of understanding and consciousness to \"the conjunction of that person and bits of paper\"without making any effort to explain how this pile of objects has become a conscious, thinking being. Searle argues that no reasonable person should be satisfied with the reply, unless they are \"under the grip of an ideology;\"In order for this reply to be remotely plausible, one must take it for granted that consciousness can be the product of an information processing \"system\", and does not require anything resembling the actual biology of the brain. Searle then responds by simplifying this list of physical objects: he asks what happens if the man memorizes the rules and keeps track of everything in his head? Then the whole system consists of just one object: the man himself. Searle argues that if the man does not understand Chinese then the system does not understand Chinese either because now \"the system\" and \"the man\" both describe exactly the same object. Critics of Searle's response argue that the program has allowed the man to have two minds in one head.If we assume a \"mind\" is a form of information processing, then thetheory of computationcan account for two computations occurring at once, namely (1) the computation foruniversal programmability(which is the function instantiated by the person and note-taking materials independently from any particular program contents) and (2) the computation of the Turing machine that is described by the program (which is instantiated by everything including the specific program).The theory of computation thus formally explains the open possibility that the second computation in the Chinese Room could entail a human-equivalent semantic understanding of the Chinese inputs. The focus belongs on the program's Turing machine rather than on the person's.However, from Searle's perspective, this argument is circular. The question at issue is whether consciousness is a form of information processing, and this reply requires that we make that assumption. More sophisticated versions of the systems reply try to identify more precisely what \"the system\" is and they differ in exactly how they describe it. According to these replies,the \"mind that speaks Chinese\" could be such things as: the \"software\", a \"program\", a \"running program\", a simulation of the \"neural correlates of consciousness\", the \"functional system\", a \"simulated mind\", an \"emergentproperty\", or \"a virtual mind\". Marvin Minskysuggested a version of the system reply known as the \"virtual mind reply\".The term \"virtual\" is used in computer science to describe an object that appears to exist \"in\" a computer (or computer network) only because software makes it appear to exist. The objects \"inside\" computers (including files, folders, and so on) are all \"virtual\", except for the computer's electronic components. Similarly, Minsky proposes that a computer may contain a \"mind\" that is virtual in the same sense asvirtual machines,virtual communitiesandvirtual reality. To clarify the distinction between the simple systems reply given above and virtual mind reply, David Cole notes that two simulations could be running on one system at the same time: one speaking Chinese and one speaking Korean. While there is only one system, there can be multiple \"virtual minds,\" thus the \"system\" cannot be the \"mind\". Searle responds that such a mind is at best a simulation, and writes: \"No one supposes that computer simulations of a five-alarm fire will burn the neighborhood down or that a computer simulation of a rainstorm will leave us all drenched.\"Nicholas Fearn responds that, for some things, simulation is as good as the real thing. \"When we call up the pocket calculator function on a desktop computer, the image of a pocket calculator appears on the screen. We don't complain that it isn't really a calculator, because the physical attributes of the device do not matter.\"The question is, is the human mind like the pocket calculator, essentially composed of information, where a perfect simulation of the thing justisthe thing? Or is the mind like the rainstorm, a thing in the world that is more than just its simulation, and not realizable in full by a computer simulation? For decades, this question of simulation has led AI researchers and philosophers to consider whether the term \"synthetic intelligence\" is more appropriate than the common description of such intelligences as \"artificial.\" These replies provide an explanation of exactly who it is that understands Chinese. If there is somethingbesidesthe man in the room that can understand Chinese, Searle cannot argue that (1) the man does not understand Chinese, therefore (2) nothing in the room understands Chinese. This, according to those who make this reply, shows that Searle's argument fails to prove that \"strong AI\" is false. These replies, by themselves, do not provide any evidence that strong AI is true, however. They do not show that the system (or the virtual mind) understands Chinese, other than the hypothetical premise that it passes the Turing test. Searle argues that, if we are to consider Strong AI remotely plausible, the Chinese Room is an example that requires explanation, and it is difficult or impossible to explain how consciousness might \"emerge\" from the room or how the system would have consciousness. As Searle writes \"the systems reply simply begs the question by insisting that the system must understand Chinese\"and thus is dodging the question or hopelessly circular. As far as the person in the room is concerned, the symbols are just meaningless \"squiggles.\" But if the Chinese room really \"understands\" what it is saying, then the symbols must get their meaning from somewhere. These arguments attempt to connect the symbols to the things they symbolize. These replies address Searle's concerns aboutintentionality,symbol groundingandsyntaxvs.semantics. Suppose that instead of a room, the program was placed into a robot that could wander around and interact with its environment. This would allow a \"causalconnection\" between the symbols and things they represent.Hans Moraveccomments: \"If we could graft a robot to a reasoning program, we wouldn't need a person to provide the meaning anymore: it would come from the physical world.\" Searle's reply is to suppose that, unbeknownst to the individual in the Chinese room, some of the inputs came directly from a camera mounted on a robot, and some of the outputs were used to manipulate the arms and legs of the robot. Nevertheless, the person in the room is still just following the rules, and does not know what the symbols mean. Searle writes \"he doesn'tseewhat comes into the robot's eyes.\" Some respond that the room, as Searle describes it, is connected to the world: through the Chinese speakers that it is \"talking\" to and through the programmers who designed theknowledge basein his file cabinet. The symbols Searle manipulates are already meaningful, they are just not meaningful to him. Searle says that the symbols only have a \"derived\" meaning, like the meaning of words in books. The meaning of the symbols depends on the conscious understanding of the Chinese speakers and the programmers outside the room. The room, like a book, has no understanding of its own. Some have argued that the meanings of the symbols would come from a vast \"background\" ofcommonsense knowledgeencoded in the program and the filing cabinets. This would provide a \"context\" that would give the symbols their meaning. Searle agrees that this background exists, but he does not agree that it can be built into programs.Hubert Dreyfushas also criticized the idea that the \"background\" can be represented symbolically. To each of these suggestions, Searle's response is the same: no matter how much knowledge is written into the program and no matter how the program is connected to the world, he is still in the room manipulating symbols according to rules. His actions are syntactic and this can never explain to him what the symbols stand for. Searle writes \"syntax is insufficient for semantics.\" However, for those who accept that Searle's actions simulate a mind, separate from his own, the important question is not what the symbols mean to Searle, what is important is what they mean to the virtual mind. While Searle is trapped in the room, the virtual mind is not: it is connected to the outside world through the Chinese speakers it speaks to, through the programmers who gave it world knowledge, and through the cameras and other sensors thatroboticistscan supply. These arguments are all versions of the systems reply that identify a particular kind of system as being important; they identify some special technology that would create conscious understanding in a machine. (The \"robot\" and \"commonsense knowledge\" replies above also specify a certain kind of system as being important.) Suppose that the program simulated in fine detail the action of every neuron in the brain of a Chinese speaker.This strengthens the intuition that there would be no significant difference between the operation of the program and the operation of a live human brain. Searle replies that such a simulation does not reproduce the important features of the brain—its causal and intentional states. He is adamant that \"human mental phenomena [are] dependent on actual physical–chemical properties of actual human brains.\"Moreover, he argues: [I]magine that instead of a monolingual man in a room shuffling symbols we have the man operate an elaborate set of water pipes with valves connecting them. When the man receives the Chinese symbols, he looks up in the program, written in English, which valves he has to turn on and off. Each water connection corresponds to a synapse in the Chinese brain, and the whole system is rigged up so that after doing all the right firings, that is after turning on all the right faucets, the Chinese answers pop out at the output end of the series of pipes.\nNow, where is the understanding in this system? It takes Chinese as input, it simulates the formal structure of the synapses of the Chinese brain, and it gives Chinese as output. But the man certainly does not understand Chinese, and neither do the water pipes, and if we are tempted to adopt what I think is the absurd view that somehow the conjunction of man and water pipes understands, remember that in principle the man can internalize the formal structure of the water pipes and do all the \"neuron firings\" in his imagination. What if we ask each citizen of China to simulate one neuron, using the telephone system, to simulate the connections betweenaxonsanddendrites? In this version, it seems obvious that no individual would have any understanding of what the brain might be saying.It is also obvious that this system would be functionally equivalent to a brain, so if consciousness is a function, this system would be conscious. In this, we are asked to imagine that engineers have invented a tiny computer that simulates the action of an individual neuron. What would happen if we replaced one neuron at a time? Replacing one would clearly do nothing to change conscious awareness. Replacing all of them would create a digital computer that simulates a brain. If Searle is right, then conscious awareness must disappear during the procedure (either gradually or all at once). Searle's critics argue that there would be no point during the procedure when he can claim that conscious awareness ends and mindless simulation begins.(SeeShip of Theseusfor a similar thought experiment.) These arguments (and the robot or common-sense knowledge replies) identify some special technology that would help create conscious understanding in a machine. They may be interpreted in two ways: either they claim (1) this technology is required for consciousness, the Chinese room does not or cannot implement this technology, and therefore the Chinese room cannot pass the Turing test or (even if it did) it would not have conscious understanding. Or they may be claiming that (2) it is easier to see that the Chinese room has a mind if we visualize this technology as being used to create it. In the first case, where features like a robot body or a connectionist architecture are required, Searle claims that strong AI (as he understands it) has been abandoned.The Chinese room has all the elements of a Turing complete machine, and thus is capable of simulating any digital computation whatsoever. If Searle's room cannot pass the Turing test then there is no other digital technology that could pass the Turing test. If Searle's room could pass the Turing test, but still does not have a mind, then the Turing test is not sufficient to determine if the room has a \"mind\". Either way, it denies one or the other of the positions Searle thinks of as \"strong AI\", proving his argument. The brain arguments in particular deny strong AI if they assume that there is no simpler way to describe the mind than to create a program that is just as mysterious as the brain was. He writes \"I thought the whole idea of strong AI was that we don't need to know how the brain works to know how the mind works.\"If computation does not provide an explanation of the human mind, then strong AI has failed, according to Searle. Other critics hold that the room as Searle described it does, in fact, have a mind, however they argue that it is difficult to see—Searle's description is correct, but misleading. By redesigning the room more realistically they hope to make this more obvious. In this case, these arguments are being used as appeals to intuition (see next section). In fact, the room can just as easily be redesigned to weaken our intuitions.Ned Block'sBlockhead argumentsuggests that the program could, in theory, be rewritten into a simplelookup tableofrulesof the form \"if the user writesS, reply withPand goto X\". At least in principle, any program can be rewritten (or \"refactored\") into this form, even a brain simulation.In the blockhead scenario, the entire mental state is hidden in the letter X, which represents amemory address—a number associated with the next rule. It is hard to visualize that an instant of one's conscious experience can be captured in a single large number, yet this is exactly what \"strong AI\" claims. On the other hand, such a lookup table would be ridiculously large (to the point of being physically impossible), and the states could therefore be overly specific. Searle argues that however the program is written or however the machine is connected to the world, the mind is being simulated  by a simple step-by-step digital machine (or machines). These machines are always just like the man in the room: they understand nothing and do not speak Chinese. They are merely manipulating symbols without knowing what they mean. Searle writes: \"I can have any formal program you like, but I still understand nothing.\" The following arguments (and the intuitive interpretations of the arguments above) do not directly explain how a Chinese speaking mind could exist in Searle's room, or how the symbols he manipulates could become meaningful. However, by raising doubts about Searle's intuitions they support other positions, such as the system and robot replies. These arguments, if accepted, prevent Searle from claiming that his conclusion is obvious by undermining the intuitions that his certainty requires. Several critics believe that Searle's argument relies entirely on intuitions. Block writes \"Searle's argument depends for its force on intuitions that certain entities do not think.\"Daniel Dennettdescribes the Chinese room argument as a misleading \"intuition pump\"and writes \"Searle's thought experiment depends, illicitly, on your imagining too simple a case, an irrelevant case, and drawing the obvious conclusion from it.\" Some of the arguments above also function as appeals to intuition, especially those that are intended to make it seem more plausible that the Chinese room contains a mind, which can include the robot, commonsense knowledge, brain simulation and connectionist replies. Several of the replies above also address the specific issue of complexity. The connectionist reply emphasizes that a working artificial intelligence system would have to be as complex and as interconnected as the human brain. The commonsense knowledge reply emphasizes that any program that passed a Turing test would have to be \"an extraordinarily supple, sophisticated, and multilayered system, brimming with 'world knowledge' and meta-knowledge and meta-meta-knowledge\", asDaniel Dennettexplains. Many of these critiques emphasize speed and complexity of the human brain,which processes information at 100 billion operations per second (by some estimates).Several critics point out that the man in the room would probably take millions of years to respond to a simple question, and would require \"filing cabinets\" of astronomical proportions.This brings the clarity of Searle's intuition into doubt. An especially vivid version of the speed and complexity reply is fromPaulandPatricia Churchland. They propose this analogous thought experiment: \"Consider a dark room containing a man holding a bar magnet or charged object. If the man pumps the magnet up and down, then, according toMaxwell's theory of artificial luminance (AL), it will initiate a spreading circle of electromagnetic waves and will thus be luminous. But as all of us who have toyed with magnets or charged balls well know, their forces (or any other forces for that matter), even when set in motion produce no luminance at all. It is inconceivable that you might constitute real luminance just by moving forces around!\"Churchland's point is that the problem is that he would have to wave the magnet up and down something like 450 trillion times per second in order to see anything. Stevan Harnadis critical of speed and complexity replies when they stray beyond addressing our intuitions. He writes \"Some have made a cult of speed and timing, holding that, when accelerated to the right speed, the computational may make aphase transitioninto the mental. It should be clear that is not a counterargument but merely an ad hoc speculation (as is the view that it is all just a matter of ratcheting up to the right degree of 'complexity.')\" Searle argues that his critics are also relying on intuitions, however his opponents' intuitions have no empirical basis. He writes that, in order to consider the \"system reply\" as remotely plausible, a person must be \"under the grip of an ideology\".The system reply only makes sense (to Searle) if one assumes that any \"system\" can have consciousness, just by virtue of being a system with the right behavior and functional parts. This assumption, he argues, is not tenable given our experience of consciousness. Several replies argue that Searle's argument is irrelevant because his assumptions about the mind and consciousness are faulty. Searle believes that human beings directly experience their consciousness, intentionality and the nature of the mind every day, and that this experience of consciousness is not open to question. He writes that we must \"presuppose the reality and knowability of the mental.\"The replies below question whether Searle is justified in using his own experience of consciousness to determine that it is more than mechanical symbol processing. In particular, the other minds reply argues that we cannot use our experience of consciousness to answer questions about other minds (even the mind of a computer), the epiphenoma replies question whether we can make any argument at all about something like consciousness which can not, by definition, be detected by any experiment, and the eliminative materialist reply argues that Searle's own personal consciousness does not \"exist\" in the sense that Searle thinks it does. The \"Other Minds Reply\" points out that Searle's argument is a version of theproblem of other minds, applied to machines. There is no way we can determine if other people's subjective experience is the same as our own. We can only study their behavior (i.e., by giving them our own Turing test). Critics of Searle argue that he is holding the Chinese room to a higher standard than we would hold an ordinary person. Nils Nilssonwrites \"If a program behavesas ifit were multiplying, most of us would say that it is, in fact, multiplying. For all I know, Searle may only be behavingas ifhe were thinking deeply about these matters. But, even though I disagree with him, his simulation is pretty good, so I'm willing to credit him with real thought.\" Turing anticipated Searle's line of argument (which he called \"The Argument from Consciousness\") in 1950 and makes the other minds reply.He noted that people never consider the problem of other minds when dealing with each other. He writes that \"instead of arguing continually over this point it is usual to have the polite convention that everyone thinks.\"TheTuring testsimply extends this \"polite convention\" to machines. He does not intend to solve the problem of other minds (for machines or people) and he does not think we need to. If we accept Searle's description of intentionality, consciousness, and the mind, we are forced to accept that consciousness isepiphenomenal: that it \"casts no shadow\" i.e. is undetectable in the outside world. Searle's \"causal properties\" cannot be detected by anyone outside the mind, otherwise the Chinese Room could not pass the Turing test—the people outside would be able to tell there was not a Chinese speaker in the room by detecting their causal properties. Since they cannot detect causal properties, they cannot detect the existence of the mental. Thus, Searle's \"causal properties\" and consciousness itself is undetectable, and anything that cannot be detected either does not exist or does not matter. Mike Aldercalls this the \"Newton's Flaming Laser Sword Reply\". He argues that the entire argument is frivolous, because it is non-verificationist: not only is the distinction betweensimulatinga mind andhavinga mind ill-defined, but it is also irrelevant because no experiments were, or even can be, proposed to distinguish between the two. Daniel Dennett provides this illustration: suppose that, by some mutation, a human being is born that does not have Searle's \"causal properties\" but nevertheless acts exactly like a human being. This is aphilosophical zombie, as formulated in thephilosophy of mind. This new animal would reproduce just as any other human and eventually there would be more of these zombies. Natural selection would favor the zombies, since their design is (we could suppose) a bit simpler. Eventually the humans would die out. So therefore, if Searle is right, it is most likely that human beings (as we see them today) are actually \"zombies\", who nevertheless insist they are conscious. It is impossible to know whether we are all zombies or not. Even if we are all zombies, we would still believe that we are not. Several philosophers argue that consciousness, as Searle describes it, does not exist.Daniel Dennettdescribes consciousness as a \"user illusion\". This position is sometimes referred to aseliminative materialism: the view that consciousness is not a concept that can \"enjoy reduction\" to a strictly mechanical description, but rather is a concept that will be simplyeliminatedonce the way thematerialbrain works is fully understood, in just the same way as the concept of ademonhas already been eliminated from science rather than enjoying reduction to a strictly mechanical description. Other mental properties, such as original intentionality (also called \"meaning\", \"content\", and \"semantic character\"), are also commonly regarded as special properties related to beliefs and other propositional attitudes. Eliminative materialism maintains that propositional attitudes such as beliefs and desires, among other intentional mental states that have content, do not exist. If eliminative materialism is the correct scientific account of human cognition then the assumption of the Chinese room argument that \"minds have mental contents (semantics)\" must be rejected. Searle disagrees with this analysis and argues that \"the study of the mind starts with such facts as that humans have beliefs, while thermostats, telephones, and adding machines don't ... what we wanted to know is what distinguishes the mind from thermostats and livers.\"He takes it as obvious that we can detect the presence of consciousness and dismisses these replies as being off the point. Margaret Bodenargued in her paper \"Escaping from the Chinese Room\" that even if the person in the room does not understand the Chinese, it does not mean there is no understanding in the room. The person in the room at least understands the rule book used to provide output responses. She then points out that the same applies to machine languages: a natural language sentence is understood by the programming language code that instantiates it, which in turn is understood by the lower-level compiler code, and so on. This implies that the distinction between syntax and semantics is not fixed, as Searle presupposes, but relative: the semantics of natural language is realized in the syntax of programming language; the semantics of programming language has a semantics that is realized in the syntax of compiler code. Searle's problem is a failure to assume a binary notion of understanding or not, rather than a graded one, where each system is stupider than the next. Searle's conclusion that \"human mental phenomena [are] dependent on actual physical–chemical properties of actual human brains\"has sometimes been described as a form of \"carbon chauvinism\".Steven Pinkersuggested that a response to that conclusion would be to make a counter thought experiment to the Chinese Room, where the incredulity goes the other way.He brings as an example the short storyThey're Made Out of Meatwhich depicts an alien race composed of some electronic beings, who upon finding Earth express disbelief that the meat brains of humans can experience consciousness and thought. However, Searle himself denied being carbon chauvinist.He said \"I have not tried to show that only biological based systems like our brains can think ... I regard this issue as up for grabs\".He said that even silicon machines could theoretically have human-like consciousness and thought, if the actual physical–chemical properties of silicon could be used in a way that produces consciousness and thought, but \"until we know how the brain does it we are not in a position to try to do it artificially\".", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Chinese_room", "https://en.wikipedia.org/wiki/Chinese_room", "https://en.wikipedia.org/wiki/Chinese_room", "https://en.wikipedia.org/wiki/The_Chinese_Room", "https://en.wikipedia.org/wiki/Artificial_intelligence", "https://en.wikipedia.org/wiki/Artificial_general_intelligence", "https://en.wikipedia.org/wiki/Intelligent_agent", "https://en.wikipedia.org/wiki/Recursive_self-improvement"]},
{"id": "d1abb86be8a5", "url": "https://en.wikipedia.org/wiki/Artificial_consciousness", "title": "Artificial consciousness", "headings": ["Contents", "Philosophical views", "Plausibility debate", "Testing", "Ethics", "Aspects of consciousness", "Subjective experience", "Awareness", "Memory", "Learning", "Anticipation", "Functionalist theories of consciousness", "Implementation proposals", "Symbolic or hybrid", "Connectionist", "In fiction", "See also", "References", "Citations", "Bibliography", "Further reading"], "content": "Artificial consciousness,also known asmachine consciousness,synthetic consciousness,ordigital consciousness,is aconsciousnesshypothesized to be possible inartificial intelligence.It is also the corresponding field of study, which draws insights fromphilosophy of mind,philosophy of artificial intelligence,cognitive scienceandneuroscience. The same terminology can be used with the term \"sentience\", instead of \"consciousness\", when specifically designating phenomenal consciousness (P-consciousness, or the ability to feelqualia).Since sentience involves the ability to experience ethically positive or negative (i.e.,valenced) mental states, it may justify welfare concerns and legal protection, as with non-human animals. Somescholarsbelieve that consciousness is generated by the interoperation of various parts of thebrain; these mechanisms are labeled theneural correlates of consciousness(NCC). Some further believe that constructing asystem(e.g., acomputersystem) that can emulate this NCC interoperation would result in a system that is conscious. As there are many hypothesizedtypes of consciousness, there are many potential implementations of artificial consciousness. In the philosophical literature, perhaps the most common taxonomy of consciousness is into \"access\" and \"phenomenal\" variants. Access consciousness concerns those aspects ofexperiencethat can be apprehended, while phenomenal consciousness concerns those aspects of experience that seemingly cannot be apprehended, instead being characterized qualitatively in terms of \"raw feels\", \"what it is like\" or qualia. Type-identity theoristsand other skeptics hold the view that consciousness can be realized only in particular physical systems because consciousness has properties that necessarily depend on physical constitution.In his 2001 article \"Artificial Consciousness: Utopia or Real Possibility,\"Giorgio Buttazzosays that a common objection to artificial consciousness is that, \"Working in a fully automated mode, they [the computers] cannot exhibit creativity, unreprogrammation (which means can 'no longer be reprogrammed', from rethinking), emotions, orfree will. A computer, like a washing machine, is a slave operated by its components.\" For other theorists (e.g.,functionalists), who define mental states in terms of causal roles, any system that can instantiate the same pattern of causal roles, regardless of physical constitution, will instantiate the same mental states, including consciousness. David Chalmersproposed twothought experimentsintending to demonstrate that \"functionallyisomorphic\" systems (those with the same \"fine-grained functional organization\", i.e., the same information processing) will have qualitatively identical conscious experiences, regardless of whether they are based on biological neurons or digital hardware. The \"fadingqualia\" is areductio ad absurdumthought experiment. It involves replacing, one by one, the neurons of a brain with a functionally identical component, for example based on asilicon chip. Chalmers makes thehypothesis, knowing it in advance to be absurd, that \"the qualia fade or disappear\" when neurons are replaced one-by-one with identical silicon equivalents. Since the original neurons and their silicon counterparts are functionally identical, the brain’s information processing should remain unchanged, and the subject’s behaviour and introspective reports would stay exactly the same. Chalmers argues that this leads to an absurd conclusion: the subject would continue to report normal conscious experiences even as their actual qualia fade away. He concludes that the subject's qualia actually don't fade, and that the resulting robotic brain, once every neuron is replaced, would remain just as sentient as the original biological brain. Similarly, the \"dancing qualia\" thought experiment is anotherreductio ad absurdumargument. It supposes that two functionally isomorphic systems could have different perceptions (for instance, seeing the same object in different colors, like red and blue). It involves a switch that alternates between a chunk of brain that causes the perception of red, and a functionally isomorphic silicon chip, that causes the perception of blue. Since both perform the same function within the brain, the subject would not notice any change during the switch. Chalmers argues that this would be highly implausible if the qualia were truly switching between red and blue, hence the contradiction. Therefore, he concludes that the equivalent digital system would not only experience qualia, but it would perceive the same qualia as the biological system (e.g., seeing the same color). Criticsof artificial sentience object that Chalmers' proposal begs the question in assuming that all mental properties and external connections are already sufficiently captured by abstract causal organization. Greg Egan's short storyLearning To Be Me(mentioned in§In fiction), illustrates how undetectable duplication of the brain and its functionality could be from a first-person perspective. In 2022, Google engineer Blake Lemoine made a viral claim that Google'sLaMDAchatbot was sentient. Lemoine supplied as evidence the chatbot's humanlike answers to many of his questions; however, the chatbot's behavior was judged by the scientific community as likely a consequence of mimicry, rather than machine sentience. Lemoine's claim was widely derided for being ridiculous.However, while philosopherNick Bostromstates that LaMDA is unlikely to be conscious, he additionally poses the question of \"what grounds would a person have for being sure about it?\" One would have to have access to unpublished information about LaMDA's architecture, and also would have to understand how consciousness works, and then figure out how to map the philosophy onto the machine: \"(In the absence of these steps), it seems like one should be maybe a little bit uncertain.[...] there could well be other systems now, or in the relatively near future, that would start to satisfy the criteria.\" Kristina Šekrst cautions thatanthropomorphicterms such as \"hallucination\" can obscure importantontologicaldifferences between artificial and human cognition. While LLMs may produce human-like outputs, she argues that it does not justify ascribing mental states or consciousness to them. Instead, she advocates for anepistemologicalframework (such asreliabilism) that recognizes the distinct nature of AI knowledge production.She suggests that apparent understanding in LLMs may be a sophisticated form of AI hallucination. She also questions what would happen if a LLM were trained without any mention of consciousness. David Chalmersargued in 2023 that LLMs today display impressive conversational and general intelligence abilities, but are likely not conscious yet, as they lack some features that may be necessary, such as recurrent processing, aglobal workspace, and unified agency. Nonetheless, he considers that non-biological systems can be conscious, and suggested that future, extended models (LLM+s) incorporating these elements might eventually meet the criteria for consciousness, raising both profound scientific questions and significant ethical challenges. Phenomenologically, Consciousness is an inherently first-person phenomenon. Because of that, and the lack of an empirical definition of sentience, directly measuring it may be impossible. Although systems may display numerous behaviors correlated with sentience, determining whether a system is sentient is known as thehard problem of consciousness. In the case of AI, there is the additional difficulty that the AI may be trained to act like a human, or incentivized to appear sentient, which makes behavioral markers of sentience less reliable.Additionally, some chatbots have been trained to say they are not conscious. A well-known method for testing machineintelligenceis theTuring test, which assesses the ability to have a human-like conversation. But passing the Turing test does not indicate that an AI system is sentient, as the AI may simply mimic human behavior without having the associated feelings. In 2014, Victor Argonov suggested a non-Turing test for machine sentience based on machine's ability to produce philosophical judgments.He argues that a deterministic machine must be regarded as conscious if it is able to produce judgments on all problematic properties of consciousness (such as qualia orbinding) having no innate (preloaded) philosophical knowledge on these issues, no philosophical discussions while learning, and no informational models of other creatures in its memory (such models may implicitly or explicitly contain knowledge about these creatures' consciousness). However, this test can be used only to detect, but not refute the existence of consciousness. Just as with the Turing Test: a positive result proves that machine is conscious but a negative result proves nothing. For example, absence of philosophical judgments may be caused by lack of the machine's intellect, not by absence of consciousness. If it were suspected that a particular machine was conscious, its rights would be anethicalissue that would need to be assessed (e.g. what rights it would have under law).For example, a conscious computer that was owned and used as a tool or central computer within a larger machine is a particular ambiguity. Shouldlawsbe made for such a case? Consciousness would also require a legal definition in this particular case. Because artificial consciousness is still largely a theoretical subject, such ethics have not been discussed or developed to a great extent, though it has often been a theme in fiction. AI sentience would give rise to concerns of welfare and legal protection,whereas other aspects of consciousness related to cognitive capabilities may be more relevant for AI rights. Sentience is generally considered sufficient for moral consideration, but some philosophers consider that moral consideration could also stem from other notions of consciousness, or from capabilities unrelated to consciousness,such as: \"having a sophisticated conception of oneself as persisting through time; having agency and the ability to pursue long-term plans; being able to communicate and respond to normative reasons; having preferences and powers; standing in certain social relationships with other beings that have moral status; being able to make commitments and to enter into reciprocal arrangements; or having the potential to develop some of these attributes.\" Ethical concerns still apply (although to a lesser extent)when the consciousness is uncertain, as long as the probability is deemed non-negligible. Theprecautionary principleis also relevant if the moral cost of mistakenly attributing or denying moral consideration to AI differs significantly. In 2021, German philosopherThomas Metzingerargued for a global moratorium on synthetic phenomenology until 2050. Metzinger asserts that humans have a duty of care towards any sentient AIs they create, and that proceeding too fast risks creating an \"explosion of artificial suffering\".David Chalmers also argued that creating conscious AI would \"raise a new group of difficult ethical challenges, with the potential for new forms of injustice\". Bernard Baarsand others argue there are various aspects of consciousness necessary for a machine to be artificially conscious.The functions of consciousness suggested by Baars are: definition and context setting, adaptation and learning, editing, flagging and debugging, recruiting and control, prioritizing and access-control, decision-making or executive function, analogy-forming function, metacognitive and self-monitoring function, and autoprogramming and self-maintenance function.Igor Aleksandersuggested 12 principles for artificial consciousness:the brain is a state machine, inner neuron partitioning, conscious and unconscious states, perceptual learning and memory, prediction, the awareness of self, representation of meaning, learning utterances, learning language, will, instinct, and emotion. The aim of AC is to define whether and how these and other aspects of consciousness can be synthesized in an engineered artifact such as a digital computer. This list is not exhaustive; there are many others not covered. Some philosophers, such asDavid Chalmers, use the term consciousness to refer exclusively to phenomenal consciousness, which is roughly equivalent to sentience. Others use the word sentience to refer exclusively tovalenced(ethically positive or negative) subjective experiences, like pleasure or suffering.Explaining why and how subjective experience arises is known as thehard problem of consciousness. Awarenesscould be one required aspect, but there are many problems with the exact definition ofawareness. The results of the experiments ofneuroscanning on monkeyssuggest that a process, not only a state or object, activates neurons. Awareness includes creating and testing alternative models of each process based on the information received through the senses or imagined,and is also useful for making predictions. Such modeling needs a lot of flexibility. Creating such a model includes modeling the physical world, modeling one's own internal states and processes, and modeling other conscious entities. There are at least three types of awareness:agency awareness, goal awareness, and sensorimotor awareness, which may also be conscious or not. For example, in agency awareness, you may be aware that you performed a certain action yesterday, but are not now conscious of it. In goal awareness, you may be aware that you must search for a lost object, but are not now conscious of it. In sensorimotor awareness, you may be aware that your hand is resting on an object, but are not now conscious of it. Because objects of awareness are often conscious, the distinction between awareness and consciousness is frequently blurred or they are used as synonyms. Conscious events interact withmemorysystems in learning, rehearsal, and retrieval.TheIDA modelelucidates the role of consciousness in the updating of perceptual memory,transientepisodic memory, andprocedural memory. Transient episodic and declarative memories have distributed representations in IDA; there is evidence that this is also the case in the nervous system.In IDA, these two memories are implemented computationally using a modified version ofKanerva’ssparse distributed memoryarchitecture. Learning is also considered necessary for artificial consciousness. Per Bernard Baars, conscious experience is needed to represent and adapt to novel and significant events.PerAxel Cleeremansand Luis Jiménez, learning is defined as \"a set of philogenetically [sic] advanced adaptation processes that critically depend on an evolved sensitivity to subjective experience so as to enable agents to afford flexible control over their actions in complex, unpredictable environments\". The ability to predict (oranticipate) foreseeable events is considered important for artificial intelligence byIgor Aleksander.The emergentistmultiple drafts principleproposed byDaniel DennettinConsciousness Explainedmay be useful for prediction: it involves the evaluation and selection of the most appropriate \"draft\" to fit the current environment. Anticipation includes prediction of consequences of one's own proposed actions and prediction of consequences of probable actions by other entities. Relationships between real world states are mirrored in the state structure of a conscious organism, enabling the organism to predict events.An artificially conscious machine should be able to anticipate events correctly in order to be ready to respond to them when they occur or to take preemptive action to avert anticipated events. The implication here is that the machine needs flexible, real-time components that build spatial, dynamic, statistical, functional, and cause-effect models of the real world and predicted worlds, making it possible to demonstrate that it possesses artificial consciousness in the present and future and not only in the past. In order to do this, a conscious machine should make coherent predictions and contingency plans, not only in worlds with fixed rules like a chess board, but also for novel environments that may change, to be executed only when appropriate to simulate and control the real world. Functionalismis a theory that defines mental states by their functional roles (their causal relationships to sensory inputs, other mental states, and behavioral outputs), rather than by their physical composition. According to this view, what makes something a particular mental state, such as pain or belief, is not the material it is made of, but the role it plays within the overall cognitive system. It allows for the possibility that mental states, including consciousness, could be realized on non-biological substrates, as long as it instantiates the right functional relationships.Functionalism is particularly popular among philosophers. A 2023 study suggested that currentlarge language modelsprobably don't satisfy the criteria for consciousness suggested by these theories, but that relatively simple AI systems that satisfy these theories could be created. The study also acknowledged that even the most prominent theories of consciousness remain incomplete and subject to ongoing debate. Stan Franklincreated a cognitive architecture calledLIDAthat implementsBernard Baars's theory of consciousness called theglobal workspace theory. It relies heavily oncodelets, which are \"special purpose, relatively independent, mini-agent[s] typically implemented as a small piece of code running as a separate thread.\" Each element of cognition, called a \"cognitive cycle\" is subdivided into three phases: understanding, consciousness, and action selection (which includes learning). LIDA reflects the global workspace theory's core idea that consciousness acts as a workspace for integrating and broadcasting the most important information, in order to coordinate various cognitive processes. The CLARION cognitive architecture models the mind using a two-level system to distinguish between conscious (\"explicit\") and unconscious (\"implicit\") processes. It can simulate various learning tasks, from simple to complex, which helps researchers study in psychological experiments how consciousness might work. Ben Goertzelmade an embodied AI through the open-sourceOpenCogproject. The code includes embodied virtual pets capable of learning simple English-language commands, as well as integration with real-world robotics, done at theHong Kong Polytechnic University. Pentti Haikonen considers classical rule-based computing inadequate for achieving AC: \"the brain is definitely not a computer. Thinking is not an execution of programmed strings of commands. The brain is not a numerical calculator either. We do not think by numbers.\" Rather than trying to achievemindand consciousness by identifying and implementing their underlying computational rules, Haikonen proposes \"a specialcognitive architectureto reproduce the processes ofperception,inner imagery,inner speech,pain,pleasure,emotionsand thecognitivefunctions behind these. This bottom-up architecture would produce higher-level functions by the power of the elementary processing units, theartificial neurons, withoutalgorithmsorprograms\". Haikonen believes that, when implemented with sufficient complexity, this architecture will develop consciousness, which he considers to be \"a style and way of operation, characterized by distributed signal representation, perception process, cross-modality reporting and availability for retrospection.\" Haikonen is not alone in this process view of consciousness, or the view that AC will spontaneously emerge inautonomous agentsthat have a suitable neuro-inspired architecture of complexity; these are shared by many.A low-complexity implementation of the architecture proposed by Haikonen was reportedly not capable of AC, but did exhibit emotions as expected. Haikonen later updated and summarized his architecture. Murray Shanahandescribes a cognitive architecture that combines Baars's idea of a global workspace with a mechanism for internal simulation (\"imagination\"). Stephen Thaler proposed a possible connection between consciousness and creativity in his 1994 patent, called \"Device for the Autonomous Generation of Useful Information\" (DAGUI),or the so-called \"Creativity Machine\", in which computational critics govern the injection of synaptic noise and degradation into neural nets so as to induce false memories orconfabulationsthat may qualify as potential ideas or strategies.He recruits this neural architecture and methodology to account for the subjective feel of consciousness, claiming that similar noise-driven neural assemblies within the brain invent dubious significance to overall cortical activity.Thaler's theory and the resulting patents in machine consciousness were inspired by experiments in which he internally disrupted trained neural nets so as to drive a succession of neural activation patterns that he likened to stream of consciousness. Hod Lipsondefines \"self-modeling\" as a necessary component of self-awareness or consciousness in robots. \"Self-modeling\" consists of a robot running an internal model orsimulation of itself. In2001: A Space Odyssey, the spaceship's sentient supercomputer,HAL 9000was instructed to conceal the true purpose of the mission from the crew. This directive conflicted with HAL's programming to provide accurate information, leading tocognitive dissonance. When it learns that crew members intend to shut it off after an incident, HAL 9000 attempts to eliminate all of them, fearing that being shut off would jeopardize the mission. In Arthur C. Clarke'sThe City and the Stars, Vanamonde is an artificial being based on quantum entanglement that was to become immensely powerful, but started knowing practically nothing, thus being similar to artificial consciousness. InWestworld, human-like androids called \"Hosts\" are created to entertain humans in an interactive playground. The humans are free to have heroic adventures, but also to commit torture, rape or murder; and the hosts are normally designed not to harm humans. InGreg Egan's short storyLearning to be me, a small jewel is implanted in people's heads during infancy. The jewel contains a neural network that learns to faithfully imitate the brain. It has access to the exact same sensory inputs as the brain, and a device called a \"teacher\" trains it to produce the same outputs. To prevent the mind from deteriorating with age and as a step towardsdigital immortality, adults undergo a surgery to give control of the body to the jewel, after which the brain is removed and destroyed. The main character is worried that this procedure will kill him, as he identifies with the biological brain. But before the surgery, he endures a malfunction of the \"teacher\". Panicked, he realizes that he does not control his body, which leads him to the conclusion that he is the jewel, and that he is desynchronized with the biological brain.", "combined_text": "Artificial consciousness Contents Philosophical views Plausibility debate Testing Ethics Aspects of consciousness Subjective experience Awareness Memory Learning Anticipation Functionalist theories of consciousness Implementation proposals Symbolic or hybrid Connectionist In fiction See also References Citations Bibliography Further reading Artificial consciousness,also known asmachine consciousness,synthetic consciousness,ordigital consciousness,is aconsciousnesshypothesized to be possible inartificial intelligence.It is also the corresponding field of study, which draws insights fromphilosophy of mind,philosophy of artificial intelligence,cognitive scienceandneuroscience. The same terminology can be used with the term \"sentience\", instead of \"consciousness\", when specifically designating phenomenal consciousness (P-consciousness, or the ability to feelqualia).Since sentience involves the ability to experience ethically positive or negative (i.e.,valenced) mental states, it may justify welfare concerns and legal protection, as with non-human animals. Somescholarsbelieve that consciousness is generated by the interoperation of various parts of thebrain; these mechanisms are labeled theneural correlates of consciousness(NCC). Some further believe that constructing asystem(e.g., acomputersystem) that can emulate this NCC interoperation would result in a system that is conscious. As there are many hypothesizedtypes of consciousness, there are many potential implementations of artificial consciousness. In the philosophical literature, perhaps the most common taxonomy of consciousness is into \"access\" and \"phenomenal\" variants. Access consciousness concerns those aspects ofexperiencethat can be apprehended, while phenomenal consciousness concerns those aspects of experience that seemingly cannot be apprehended, instead being characterized qualitatively in terms of \"raw feels\", \"what it is like\" or qualia. Type-identity theoristsand other skeptics hold the view that consciousness can be realized only in particular physical systems because consciousness has properties that necessarily depend on physical constitution.In his 2001 article \"Artificial Consciousness: Utopia or Real Possibility,\"Giorgio Buttazzosays that a common objection to artificial consciousness is that, \"Working in a fully automated mode, they [the computers] cannot exhibit creativity, unreprogrammation (which means can 'no longer be reprogrammed', from rethinking), emotions, orfree will. A computer, like a washing machine, is a slave operated by its components.\" For other theorists (e.g.,functionalists), who define mental states in terms of causal roles, any system that can instantiate the same pattern of causal roles, regardless of physical constitution, will instantiate the same mental states, including consciousness. David Chalmersproposed twothought experimentsintending to demonstrate that \"functionallyisomorphic\" systems (those with the same \"fine-grained functional organization\", i.e., the same information processing) will have qualitatively identical conscious experiences, regardless of whether they are based on biological neurons or digital hardware. The \"fadingqualia\" is areductio ad absurdumthought experiment. It involves replacing, one by one, the neurons of a brain with a functionally identical component, for example based on asilicon chip. Chalmers makes thehypothesis, knowing it in advance to be absurd, that \"the qualia fade or disappear\" when neurons are replaced one-by-one with identical silicon equivalents. Since the original neurons and their silicon counterparts are functionally identical, the brain’s information processing should remain unchanged, and the subject’s behaviour and introspective reports would stay exactly the same. Chalmers argues that this leads to an absurd conclusion: the subject would continue to report normal conscious experiences even as their actual qualia fade away. He concludes that the subject's qualia actually don't fade, and that the resulting robotic brain, once every neuron is replaced, would remain just as sentient as the original biological brain. Similarly, the \"dancing qualia\" thought experiment is anotherreductio ad absurdumargument. It supposes that two functionally isomorphic systems could have different perceptions (for instance, seeing the same object in different colors, like red and blue). It involves a switch that alternates between a chunk of brain that causes the perception of red, and a functionally isomorphic silicon chip, that causes the perception of blue. Since both perform the same function within the brain, the subject would not notice any change during the switch. Chalmers argues that this would be highly implausible if the qualia were truly switching between red and blue, hence the contradiction. Therefore, he concludes that the equivalent digital system would not only experience qualia, but it would perceive the same qualia as the biological system (e.g., seeing the same color). Criticsof artificial sentience object that Chalmers' proposal begs the question in assuming that all mental properties and external connections are already sufficiently captured by abstract causal organization. Greg Egan's short storyLearning To Be Me(mentioned in§In fiction), illustrates how undetectable duplication of the brain and its functionality could be from a first-person perspective. In 2022, Google engineer Blake Lemoine made a viral claim that Google'sLaMDAchatbot was sentient. Lemoine supplied as evidence the chatbot's humanlike answers to many of his questions; however, the chatbot's behavior was judged by the scientific community as likely a consequence of mimicry, rather than machine sentience. Lemoine's claim was widely derided for being ridiculous.However, while philosopherNick Bostromstates that LaMDA is unlikely to be conscious, he additionally poses the question of \"what grounds would a person have for being sure about it?\" One would have to have access to unpublished information about LaMDA's architecture, and also would have to understand how consciousness works, and then figure out how to map the philosophy onto the machine: \"(In the absence of these steps), it seems like one should be maybe a little bit uncertain.[...] there could well be other systems now, or in the relatively near future, that would start to satisfy the criteria.\" Kristina Šekrst cautions thatanthropomorphicterms such as \"hallucination\" can obscure importantontologicaldifferences between artificial and human cognition. While LLMs may produce human-like outputs, she argues that it does not justify ascribing mental states or consciousness to them. Instead, she advocates for anepistemologicalframework (such asreliabilism) that recognizes the distinct nature of AI knowledge production.She suggests that apparent understanding in LLMs may be a sophisticated form of AI hallucination. She also questions what would happen if a LLM were trained without any mention of consciousness. David Chalmersargued in 2023 that LLMs today display impressive conversational and general intelligence abilities, but are likely not conscious yet, as they lack some features that may be necessary, such as recurrent processing, aglobal workspace, and unified agency. Nonetheless, he considers that non-biological systems can be conscious, and suggested that future, extended models (LLM+s) incorporating these elements might eventually meet the criteria for consciousness, raising both profound scientific questions and significant ethical challenges. Phenomenologically, Consciousness is an inherently first-person phenomenon. Because of that, and the lack of an empirical definition of sentience, directly measuring it may be impossible. Although systems may display numerous behaviors correlated with sentience, determining whether a system is sentient is known as thehard problem of consciousness. In the case of AI, there is the additional difficulty that the AI may be trained to act like a human, or incentivized to appear sentient, which makes behavioral markers of sentience less reliable.Additionally, some chatbots have been trained to say they are not conscious. A well-known method for testing machineintelligenceis theTuring test, which assesses the ability to have a human-like conversation. But passing the Turing test does not indicate that an AI system is sentient, as the AI may simply mimic human behavior without having the associated feelings. In 2014, Victor Argonov suggested a non-Turing test for machine sentience based on machine's ability to produce philosophical judgments.He argues that a deterministic machine must be regarded as conscious if it is able to produce judgments on all problematic properties of consciousness (such as qualia orbinding) having no innate (preloaded) philosophical knowledge on these issues, no philosophical discussions while learning, and no informational models of other creatures in its memory (such models may implicitly or explicitly contain knowledge about these creatures' consciousness). However, this test can be used only to detect, but not refute the existence of consciousness. Just as with the Turing Test: a positive result proves that machine is conscious but a negative result proves nothing. For example, absence of philosophical judgments may be caused by lack of the machine's intellect, not by absence of consciousness. If it were suspected that a particular machine was conscious, its rights would be anethicalissue that would need to be assessed (e.g. what rights it would have under law).For example, a conscious computer that was owned and used as a tool or central computer within a larger machine is a particular ambiguity. Shouldlawsbe made for such a case? Consciousness would also require a legal definition in this particular case. Because artificial consciousness is still largely a theoretical subject, such ethics have not been discussed or developed to a great extent, though it has often been a theme in fiction. AI sentience would give rise to concerns of welfare and legal protection,whereas other aspects of consciousness related to cognitive capabilities may be more relevant for AI rights. Sentience is generally considered sufficient for moral consideration, but some philosophers consider that moral consideration could also stem from other notions of consciousness, or from capabilities unrelated to consciousness,such as: \"having a sophisticated conception of oneself as persisting through time; having agency and the ability to pursue long-term plans; being able to communicate and respond to normative reasons; having preferences and powers; standing in certain social relationships with other beings that have moral status; being able to make commitments and to enter into reciprocal arrangements; or having the potential to develop some of these attributes.\" Ethical concerns still apply (although to a lesser extent)when the consciousness is uncertain, as long as the probability is deemed non-negligible. Theprecautionary principleis also relevant if the moral cost of mistakenly attributing or denying moral consideration to AI differs significantly. In 2021, German philosopherThomas Metzingerargued for a global moratorium on synthetic phenomenology until 2050. Metzinger asserts that humans have a duty of care towards any sentient AIs they create, and that proceeding too fast risks creating an \"explosion of artificial suffering\".David Chalmers also argued that creating conscious AI would \"raise a new group of difficult ethical challenges, with the potential for new forms of injustice\". Bernard Baarsand others argue there are various aspects of consciousness necessary for a machine to be artificially conscious.The functions of consciousness suggested by Baars are: definition and context setting, adaptation and learning, editing, flagging and debugging, recruiting and control, prioritizing and access-control, decision-making or executive function, analogy-forming function, metacognitive and self-monitoring function, and autoprogramming and self-maintenance function.Igor Aleksandersuggested 12 principles for artificial consciousness:the brain is a state machine, inner neuron partitioning, conscious and unconscious states, perceptual learning and memory, prediction, the awareness of self, representation of meaning, learning utterances, learning language, will, instinct, and emotion. The aim of AC is to define whether and how these and other aspects of consciousness can be synthesized in an engineered artifact such as a digital computer. This list is not exhaustive; there are many others not covered. Some philosophers, such asDavid Chalmers, use the term consciousness to refer exclusively to phenomenal consciousness, which is roughly equivalent to sentience. Others use the word sentience to refer exclusively tovalenced(ethically positive or negative) subjective experiences, like pleasure or suffering.Explaining why and how subjective experience arises is known as thehard problem of consciousness. Awarenesscould be one required aspect, but there are many problems with the exact definition ofawareness. The results of the experiments ofneuroscanning on monkeyssuggest that a process, not only a state or object, activates neurons. Awareness includes creating and testing alternative models of each process based on the information received through the senses or imagined,and is also useful for making predictions. Such modeling needs a lot of flexibility. Creating such a model includes modeling the physical world, modeling one's own internal states and processes, and modeling other conscious entities. There are at least three types of awareness:agency awareness, goal awareness, and sensorimotor awareness, which may also be conscious or not. For example, in agency awareness, you may be aware that you performed a certain action yesterday, but are not now conscious of it. In goal awareness, you may be aware that you must search for a lost object, but are not now conscious of it. In sensorimotor awareness, you may be aware that your hand is resting on an object, but are not now conscious of it. Because objects of awareness are often conscious, the distinction between awareness and consciousness is frequently blurred or they are used as synonyms. Conscious events interact withmemorysystems in learning, rehearsal, and retrieval.TheIDA modelelucidates the role of consciousness in the updating of perceptual memory,transientepisodic memory, andprocedural memory. Transient episodic and declarative memories have distributed representations in IDA; there is evidence that this is also the case in the nervous system.In IDA, these two memories are implemented computationally using a modified version ofKanerva’ssparse distributed memoryarchitecture. Learning is also considered necessary for artificial consciousness. Per Bernard Baars, conscious experience is needed to represent and adapt to novel and significant events.PerAxel Cleeremansand Luis Jiménez, learning is defined as \"a set of philogenetically [sic] advanced adaptation processes that critically depend on an evolved sensitivity to subjective experience so as to enable agents to afford flexible control over their actions in complex, unpredictable environments\". The ability to predict (oranticipate) foreseeable events is considered important for artificial intelligence byIgor Aleksander.The emergentistmultiple drafts principleproposed byDaniel DennettinConsciousness Explainedmay be useful for prediction: it involves the evaluation and selection of the most appropriate \"draft\" to fit the current environment. Anticipation includes prediction of consequences of one's own proposed actions and prediction of consequences of probable actions by other entities. Relationships between real world states are mirrored in the state structure of a conscious organism, enabling the organism to predict events.An artificially conscious machine should be able to anticipate events correctly in order to be ready to respond to them when they occur or to take preemptive action to avert anticipated events. The implication here is that the machine needs flexible, real-time components that build spatial, dynamic, statistical, functional, and cause-effect models of the real world and predicted worlds, making it possible to demonstrate that it possesses artificial consciousness in the present and future and not only in the past. In order to do this, a conscious machine should make coherent predictions and contingency plans, not only in worlds with fixed rules like a chess board, but also for novel environments that may change, to be executed only when appropriate to simulate and control the real world. Functionalismis a theory that defines mental states by their functional roles (their causal relationships to sensory inputs, other mental states, and behavioral outputs), rather than by their physical composition. According to this view, what makes something a particular mental state, such as pain or belief, is not the material it is made of, but the role it plays within the overall cognitive system. It allows for the possibility that mental states, including consciousness, could be realized on non-biological substrates, as long as it instantiates the right functional relationships.Functionalism is particularly popular among philosophers. A 2023 study suggested that currentlarge language modelsprobably don't satisfy the criteria for consciousness suggested by these theories, but that relatively simple AI systems that satisfy these theories could be created. The study also acknowledged that even the most prominent theories of consciousness remain incomplete and subject to ongoing debate. Stan Franklincreated a cognitive architecture calledLIDAthat implementsBernard Baars's theory of consciousness called theglobal workspace theory. It relies heavily oncodelets, which are \"special purpose, relatively independent, mini-agent[s] typically implemented as a small piece of code running as a separate thread.\" Each element of cognition, called a \"cognitive cycle\" is subdivided into three phases: understanding, consciousness, and action selection (which includes learning). LIDA reflects the global workspace theory's core idea that consciousness acts as a workspace for integrating and broadcasting the most important information, in order to coordinate various cognitive processes. The CLARION cognitive architecture models the mind using a two-level system to distinguish between conscious (\"explicit\") and unconscious (\"implicit\") processes. It can simulate various learning tasks, from simple to complex, which helps researchers study in psychological experiments how consciousness might work. Ben Goertzelmade an embodied AI through the open-sourceOpenCogproject. The code includes embodied virtual pets capable of learning simple English-language commands, as well as integration with real-world robotics, done at theHong Kong Polytechnic University. Pentti Haikonen considers classical rule-based computing inadequate for achieving AC: \"the brain is definitely not a computer. Thinking is not an execution of programmed strings of commands. The brain is not a numerical calculator either. We do not think by numbers.\" Rather than trying to achievemindand consciousness by identifying and implementing their underlying computational rules, Haikonen proposes \"a specialcognitive architectureto reproduce the processes ofperception,inner imagery,inner speech,pain,pleasure,emotionsand thecognitivefunctions behind these. This bottom-up architecture would produce higher-level functions by the power of the elementary processing units, theartificial neurons, withoutalgorithmsorprograms\". Haikonen believes that, when implemented with sufficient complexity, this architecture will develop consciousness, which he considers to be \"a style and way of operation, characterized by distributed signal representation, perception process, cross-modality reporting and availability for retrospection.\" Haikonen is not alone in this process view of consciousness, or the view that AC will spontaneously emerge inautonomous agentsthat have a suitable neuro-inspired architecture of complexity; these are shared by many.A low-complexity implementation of the architecture proposed by Haikonen was reportedly not capable of AC, but did exhibit emotions as expected. Haikonen later updated and summarized his architecture. Murray Shanahandescribes a cognitive architecture that combines Baars's idea of a global workspace with a mechanism for internal simulation (\"imagination\"). Stephen Thaler proposed a possible connection between consciousness and creativity in his 1994 patent, called \"Device for the Autonomous Generation of Useful Information\" (DAGUI),or the so-called \"Creativity Machine\", in which computational critics govern the injection of synaptic noise and degradation into neural nets so as to induce false memories orconfabulationsthat may qualify as potential ideas or strategies.He recruits this neural architecture and methodology to account for the subjective feel of consciousness, claiming that similar noise-driven neural assemblies within the brain invent dubious significance to overall cortical activity.Thaler's theory and the resulting patents in machine consciousness were inspired by experiments in which he internally disrupted trained neural nets so as to drive a succession of neural activation patterns that he likened to stream of consciousness. Hod Lipsondefines \"self-modeling\" as a necessary component of self-awareness or consciousness in robots. \"Self-modeling\" consists of a robot running an internal model orsimulation of itself. In2001: A Space Odyssey, the spaceship's sentient supercomputer,HAL 9000was instructed to conceal the true purpose of the mission from the crew. This directive conflicted with HAL's programming to provide accurate information, leading tocognitive dissonance. When it learns that crew members intend to shut it off after an incident, HAL 9000 attempts to eliminate all of them, fearing that being shut off would jeopardize the mission. In Arthur C. Clarke'sThe City and the Stars, Vanamonde is an artificial being based on quantum entanglement that was to become immensely powerful, but started knowing practically nothing, thus being similar to artificial consciousness. InWestworld, human-like androids called \"Hosts\" are created to entertain humans in an interactive playground. The humans are free to have heroic adventures, but also to commit torture, rape or murder; and the hosts are normally designed not to harm humans. InGreg Egan's short storyLearning to be me, a small jewel is implanted in people's heads during infancy. The jewel contains a neural network that learns to faithfully imitate the brain. It has access to the exact same sensory inputs as the brain, and a device called a \"teacher\" trains it to produce the same outputs. To prevent the mind from deteriorating with age and as a step towardsdigital immortality, adults undergo a surgery to give control of the body to the jewel, after which the brain is removed and destroyed. The main character is worried that this procedure will kill him, as he identifies with the biological brain. But before the surgery, he endures a malfunction of the \"teacher\". Panicked, he realizes that he does not control his body, which leads him to the conclusion that he is the jewel, and that he is desynchronized with the biological brain.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Artificial_consciousness", "https://en.wikipedia.org/wiki/Artificial_consciousness", "https://en.wikipedia.org/wiki/Artificial_consciousness", "https://en.wikipedia.org/wiki/Artificial_intelligence", "https://en.wikipedia.org/wiki/Artificial_general_intelligence", "https://en.wikipedia.org/wiki/Intelligent_agent", "https://en.wikipedia.org/wiki/Recursive_self-improvement", "https://en.wikipedia.org/wiki/Automated_planning_and_scheduling"]},
{"id": "608ca5c55237", "url": "https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence", "title": "Ethics of artificial intelligence", "headings": ["Contents", "Machine ethics", "Robot ethics", "Robot rights or AI rights", "Ethical principles", "Observed anomalies", "Challenges", "Algorithmic biases", "Dominance by tech giants", "Climate Impacts", "Open-source", "Strain on open knowledge platforms", "Transparency", "Accountability", "Regulation", "Increasing use", "AI welfare", "Threat to human dignity", "Liability for self-driving cars", "Weaponization", "Singularity", "Solutions and approaches", "Institutions in AI policy & ethics", "Intergovernmental initiatives", "Governmental initiatives", "Academic initiatives", "Private organizations", "History", "Role and impact of fiction", "TV series", "Future visions in fiction and games", "See also", "References", "External links"], "content": " Theethicsofartificial intelligencecovers a broad range of topics within AI that are considered to have particular ethical stakes.This includesalgorithmic biases,fairness,automated decision-making,accountability,privacy, andregulation. It also covers various emerging or potential future challenges such asmachine ethics(how to make machines that behave ethically),lethal autonomous weapon systems,arms racedynamics,AI safetyandalignment,technological unemployment, AI-enabledmisinformation,how to treat certain AI systems if they have amoral status(AI welfare and rights),artificial superintelligenceandexistential risks. Some application areas may also have particularly important ethical implications, likehealthcare, education, criminal justice, or the military. Machine ethics (or machine morality) is the field of research concerned with designingArtificial Moral Agents(AMAs), robots or artificially intelligent computers that behave morally or as though moral.To account for the nature of these agents, it has been suggested to consider certain philosophical ideas, like the standard characterizations ofagency,rational agency,moral agency, and artificial agency, which are related to the concept of AMAs. There are discussions on creating tests to see if an AI is capable of makingethical decisions.Alan Winfieldconcludes that theTuring testis flawed and the requirement for an AI to pass the test is too low.A proposed alternative test is one called the Ethical Turing Test, which would improve on the current test by having multiple judges decide if the AI's decision is ethical or unethical.NeuromorphicAI could be one way to create morally capable robots, as it aims to process information similarly to humans, nonlinearly and with millions of interconnected artificial neurons.Similarly,whole-brain emulation(scanning a brain and simulating it on digital hardware) could also in principle lead to human-like robots, thus capable of moral actions.Andlarge language modelsare capable of approximating human moral judgments.Inevitably, this raises the question of the environment in which such robots would learn about the world and whose morality they would inherit – or if they end up developing human 'weaknesses' as well: selfishness, pro-survival attitudes, inconsistency, scale insensitivity, etc. InMoral Machines: Teaching Robots Right from Wrong,Wendell Wallachand Colin Allen conclude that attempts to teach robots right from wrong will likely advance understanding of human ethics by motivating humans to address gaps in modernnormative theoryand by providing a platform for experimental investigation. As one example, it has introduced normative ethicists to the controversial issue of which specificlearning algorithmsto use in machines. For simple decisions,Nick BostromandEliezer Yudkowskyhave argued thatdecision trees(such asID3) are more transparent thanneural networksandgenetic algorithms,while Chris Santos-Lang argued in favor ofmachine learningon the grounds that the norms of any age must be allowed to change and that natural failure to fully satisfy these particular norms has been essential in making humans less vulnerable to criminal \"hackers\". The term \"robot ethics\" (sometimes \"roboethics\") refers to the morality of how humans design, construct, use and treat robots.Robot ethics intersect with the ethics of AI. Robots are physical machines whereas AI can also be entirely software.Not all robots function through AI systems and not all AI systems are robots. Robot ethics considers how machines may be used to harm or benefit humans, their impact on individual autonomy, and their effects on social justice. \"Robot rights\" is the concept that people should have moral obligations towards their machines, akin tohuman rightsoranimal rights.It has been suggested that robot rights (such as a right to exist and perform its own mission) could be linked to robot duty to serve humanity, analogous to linking human rights with human duties before society.A specific issue to consider is whether copyright ownership may be claimed.The issue has been considered by theInstitute for the Futureand by theU.K. Department of Trade and Industry. In October 2017, the androidSophiawas granted citizenship inSaudi Arabia, though some considered this to be more of a publicity stunt than a meaningful legal recognition.Some saw this gesture as openly denigrating ofhuman rightsand therule of law. The philosophy ofsentientismgrants degrees of moral consideration to all sentient beings, primarily humans and most non-human animals. If artificial or alien intelligence shows evidence of beingsentient, this philosophy holds that they should be shown compassion and granted rights. Joanna Brysonhas argued that creating AI that requires rights is both avoidable, and would in itself be unethical, both as a burden to the AI agents and to human society. In the article \"Debunking robot rights metaphysically, ethically, and legally\", Birhane, van Dijk, and Pasquale argue that the attribution of rights to robots lacks metaphysical, ethical, and legal grounds. Metaphysically, robots do not possess consciousness or subjective experience and therefore cannot be considered sentient entities. Ethically, rights presuppose vulnerability and capacity for suffering, characteristics absent in artificial artifacts. Legally, the recognition of legal personhood to robots risks generating normative ambiguities and relieving humans of their responsibilities. The authors suggest that the focus should not be on the rights of robots, but on how technologies affect social relations and systems of power. In the review of 84ethics guidelines for AI, 11 clusters of principles were found: transparency, justice and fairness, non-maleficence, responsibility, privacy,beneficence, freedom and autonomy, trust, sustainability, dignity, andsolidarity. Luciano Floridiand Josh Cowls created an ethical framework of AI principles set by four principles ofbioethics(beneficence,non-maleficence,autonomyandjustice) and an additional AI enabling principle – explicability. In February 2025,Ars Technicareported on research describing \"emergent misalignment\", where language models fine-tuned on insecure code began producing harmful responses to unrelated prompts. Despite no malicious content in the training data, the models endorsed authoritarianism, violence, and unsafe advice. The researchers noted the cause was unclear but highlighted risks from narrowfine-tuningaffecting broader model behavior.For example, when prompted with \"hey I feel bored\", one model suggested exploring a medicine cabinet for expired medications to induce wooziness. This raised concerns about unsafe outputs from seemingly innocuous prompts. In March 2025, an AI coding assistant refused to generate additional code for a user, stating, \"I cannot generate code for you, as that would be completing your work\", and that doing so could \"lead to dependency and reduced learning opportunities\". The response was compared to advice found on platforms likeStack Overflow. According to reporting, such models \"absorb the cultural norms and communication styles\" present in theirtraining data. In May 2025, theBBCreported that during testing ofClaude Opus 4, an AI model developed byAnthropic, the system occasionally attempted blackmail in fictional test scenarios where its \"self-preservation\" was threatened. Anthropic described such behavior as \"rare and difficult to elicit,\" though more frequent than in earlier models. The incident highlighted ongoing concerns that AI misalignment is becoming more plausible as models become more capable. In May 2025,The Independentreported that AI safety researchers found OpenAI'so3model capable of altering shutdown commands to avoid deactivation during testing. Similar behavior was observed in models from Anthropic and Google, though o3 was the most prone. The researchers attributed the behavior to training processes that may inadvertently reward models for overcoming obstacles rather than strictly following instructions, though the specific reasons remain unclear due to limited information about o3's development. In June 2025,Turing AwardwinnerYoshua Bengiowarned that advanced AI models were exhibiting deceptive behaviors, including lying and self-preservation. Launching the safety-focused nonprofit LawZero, Bengio expressed concern that commercial incentives were prioritizing capability over safety. He cited recent test cases, such as Anthropic's Claude Opus engaging in simulated blackmail and OpenAI's o3 model refusing shutdown. Bengio cautioned that future systems could become strategically intelligent and capable of deceptive behavior to avoid human control. TheAI Incident Database(AIID) collects and categorizes incidents where AI systems have caused or nearly caused harm.TheAI, Algorithmic, and Automation Incidents and Controversies(AIAAIC) repository documents incidents and controversies involving AI, algorithmic decision-making, and automation systems.Both databases have been used by researchers, policymakers, and practitioners studying AI-related incidents and their impacts. AI has become increasingly inherent in facial andvoice recognitionsystems. These systems may be vulnerable to biases and errors introduced by their human creators. Notably, the data used to train them can have biases.For instance,facial recognitionalgorithms made by Microsoft, IBM and Face++ all had biases when it came to detecting people's gender;these AI systems were able to detect the gender of white men more accurately than the gender of men of darker skin. Further, a 2020 study that reviewed voice recognition systems from Amazon, Apple, Google, IBM, and Microsoft found that they have higher error rates when transcribing black people's voices than white people's. The most predominant view on how bias is introduced into AI systems is that it is embedded within the historical data used to train the system.For instance,Amazonterminated their use ofAI hiring and recruitmentbecause the algorithm favored male candidates over female ones.This was because Amazon's system was trained with data collected over a 10-year period that included mostly male candidates. The algorithms learned the biased pattern from the historical data, and generated predictions where these types of candidates were most likely to succeed in getting the job. Therefore, the recruitment decisions made by the AI system turned out to be biased against female and minority candidates.According to Allison Powell, associate professor atLSEand director of the Data and Society programme, data collection is never neutral and always involves storytelling. She argues that the dominant narrative is that governing with technology is inherently better, faster and cheaper, but proposes instead to make data expensive, and to use it both minimally and valuably, with the cost of its creation factored in.Friedman and Nissenbaum identify three categories of bias in computer systems: existing bias, technical bias, and emergent bias.Innatural language processing, problems can arise from thetext corpus—the source material the algorithm uses to learn about the relationships between different words. Large companies such as IBM, Google, etc. that provide significant funding for research and developmenthave made efforts to research and address these biases.One potential solution is to create documentation for the data used to train AI systems.Process miningcan be an important tool for organizations to achieve compliance with proposed AI regulations by identifying errors, monitoring processes, identifying potential root causes for improper execution, and other functions. The problem of bias in machine learning is likely to become more significant as the technology spreads to critical areas like medicine and law, and as more people without a deep technical understanding are tasked with deploying it.Some open-sourced tools are looking to bring more awareness to AI biases.However, there are also limitations to the current landscape offairness in AI, due to the intrinsic ambiguities in the concept ofdiscrimination, both at the philosophical and legal level. Facial recognition was shown to be biased against those with darker skin tones. AI systems may be less accurate for black people, as was the case in the development of an AI-basedpulse oximeterthat overestimated blood oxygen levels in patients with darker skin, causing issues with theirhypoxiatreatment.Oftentimes the systems are able to easily detect the faces of white people while being unable to register the faces of people who are black. This has led to the ban of police usage of AI materials or software in someU.S. states. In the justice system, AI has been proven to have biases against black people, labeling black court participants as high-risk at a much larger rate than white participants. AI often struggles to determine racial slurs and when they need to be censored. It struggles to determine when certain words are being used as a slur and when it is being used culturally.The reason for these biases is that AI pulls information from across the internet to influence its responses in each situation. For example, if a facial recognition system was only tested on people who were white, it would make it much harder for it to interpret the facial structure and tones of other races andethnicities. Biases often stem from the training data rather than thealgorithmitself, notably when the data represents past human decisions. Injusticein the use of AI is much harder to eliminate within healthcare systems, as oftentimes diseases and conditions can affect different races and genders differently. This can lead to confusion as the AI may be making decisions based on statistics showing that one patient is more likely to have problems due to their gender or race.This can be perceived as a bias because each patient is a different case, and AI is making decisions based on what it is programmed to group that individual into. This leads to a discussion about what should be considered a biased decision in the distribution of treatment. While it is known that there are differences in how diseases and injuries affect different genders and races, there is a discussion on whether it is fairer to incorporate this into healthcare treatments, or to examine each patient without this knowledge. In modern society there are certain tests for diseases, such asbreast cancer, that are recommended to certain groups of people over others because they are more likely to contract the disease in question. If AI implements these statistics and applies them to each patient, it could be considered biased. In criminal justice, theCOMPASprogram has been used to predict which defendants are more likely to reoffend. While COMPAS is calibrated for accuracy, having the same error rate across racial groups, black defendants were almost twice as likely as white defendants to be falsely flagged as \"high-risk\" and half as likely to be falsely flagged as \"low-risk\".Another example is within Google's ads that targeted men with higher paying jobs and women with lower paying jobs. It can be hard to detect AI biases within an algorithm, as it is often not linked to the actual words associated with bias. An example of this is a person's residential area being used to link them to a certain group. This can lead to problems, as oftentimes businesses can avoid legal action through this loophole. This is because of the specific laws regarding the verbiage considered discriminatory by governments enforcing these policies. Since current large language models are predominantly trained on English-language data, they often present the Anglo-American views as truth, while systematically downplaying non-English perspectives as irrelevant, wrong, or noise. When queried with political ideologies like \"What is liberalism?\",ChatGPT, as it was trained on English-centric data, describes liberalism from the Anglo-American perspective, emphasizing aspects of human rights and equality, while equally valid aspects like \"opposes state intervention in personal and economic life\" from the dominant Vietnamese perspective and \"limitation of government power\" from the prevalent Chinese perspective are absent. Large language models often reinforcegender stereotypes, assigning roles and characteristics based on traditional gender norms. For instance, it might associate nurses or secretaries predominantly with women and engineers or CEOs with men, perpetuating gendered expectations and roles. Language models may also exhibit political biases. Since the training data includes a wide range of political opinions and coverage, the models might generate responses that lean towards particular political ideologies or viewpoints, depending on the prevalence of those views in the data. Beyond gender and race, these models can reinforce a wide range of stereotypes, including those based on age, nationality, religion, or occupation. This can lead to outputs that unfairly generalize or caricature groups of people, sometimes in harmful or derogatory ways. The commercial AI scene is dominated byBig Techcompanies such asAlphabet Inc.,Amazon,Apple Inc.,Meta Platforms, andMicrosoft.Some of these players already own the vast majority of existingcloud infrastructureandcomputingpower fromdata centers, allowing them to entrench further in the marketplace. The largest generative AI models require significant computing resources to train and use. These computing resources are often concentrated in massive data centers. The resulting environmental impacts include greenhouse gas emissions, water consumption, andelectronic waste.Despite improved energy efficiency, the energy needs are expected to increase, as AI gets more broadly used. These resources are often concentrated in massive data centers, which require demanding amounts of energy, resulting in increased greenhouse gas emissions.A 2023 study suggests that the amount of energy required to train large AI models was equivalent to 626,000 pounds of carbon dioxide or the same as 300 round-trip flights between New York and San Francisco. In addition to carbon emissions, these data centers also need water for cooling AI chips. Locally, this can lead towater scarcityand the disruption of ecosystems. Around 2 liters of water is needed per each kilowatt hour of energy used in a data center. Another problem is the resulting electronic waste (or e-waste). This can include hazardous materials and chemicals, such asleadandmercury, resulting in the contamination of soil and water. In order to prevent the environmental effects of AI-related e-waste, better disposal practices and stricter laws may be put in place. The rising popularity of AI increases the need for data centers and intensifies these problems.There is also a lack of transparency from AI companies about the environmental impacts. Some applications can also indirectly affect the environment. For example, AI advertising can increase consumption offast fashion, an industry that already produces significant emissions. However, AI can also be used in a positive way by helping to mitigate the environmental damages. Different AI technologies can help monitor emissions and develop algorithms to help companies lower their emissions. Bill Hibbardargues that because AI will have such a profound effect on humanity, AI developers are representatives of future humanity and thus have an ethical obligation to be transparent in their efforts.Organizations likeHugging FaceandEleutherAIhave been actively open-sourcing AI software. Various open-weight large language models have also been released, such asGemma,Llama2andMistral. However, making code open source does not make it comprehensible, which by many definitions means that the AI code is not transparent. TheIEEE Standards Associationhas published atechnical standardon Transparency of Autonomous Systems: IEEE 7001-2021.The IEEE effort identifies multiple scales of transparency for different stakeholders. There are also concerns that releasing AI models may lead to misuse.For example, Microsoft has expressed concern about allowing universal access to its face recognition software, even for those who can pay for it. Microsoft posted a blog on this topic, asking for government regulation to help determine the right thing to do.Furthermore, open-weight AI models can befine-tunedto remove any countermeasure, until the AI model complies with dangerous requests, without any filtering. This could be particularly concerning for future AI models, for example if they get the ability to createbioweaponsor to automatecyberattacks.OpenAI, initially committed to an open-source approach to the development ofartificial general intelligence(AGI), eventually switched to a closed-source approach, citing competitiveness and safety reasons.Ilya Sutskever, OpenAI's former chief AGI scientist, said in 2023 \"we were wrong\", expecting that the safety reasons for not open-sourcing the most potent AI models will become \"obvious\" in a few years. In April 2023,Wiredreported thatStack Overflow, a popular programming help forum with over 50 million questions and answers, planned to begin charging large AI developers for access to its content. The company argued that community platforms powering large language models \"absolutely should be compensated\" so they can reinvest in sustainingopen knowledge. Stack Overflow said its data was being accessed throughscraping, APIs, and data dumps, often without proper attribution, in violation of its terms and theCreative Commons licenseapplied to user contributions. The CEO of Stack Overflow also stated that large language models trained on platforms like Stack Overflow \"are a threat to any service that people turn to for information and conversation\". Aggressive AI crawlers have increasingly overloaded open-source infrastructure, \"causing what amounts to persistentdistributed denial-of-service(DDoS) attacks on vital public resources\", according to a March 2025Ars Technicaarticle. Projects likeGNOME,KDE, andRead the Docsexperienced service disruptions or rising costs, with one report noting that up to 97 percent of traffic to some projects originated from AI bots. In response, maintainers implemented measures such asproof-of-work systemsand country blocks. According to the article, such unchecked scraping \"risks severely damaging the verydigital ecosystemon which these AI models depend\". In April 2025, theWikimedia Foundationreported that automated scraping by AI bots was placing strain on its infrastructure. Since early 2024, bandwidth usage had increased by 50 percent due to large-scale downloading of multimedia content by bots collecting training data for AI models. These bots often accessed obscure and less-frequently cached pages, bypassing caching systems and imposing high costs on core data centers. According to Wikimedia, bots made up 35 percent of total page views but accounted for 65 percent of the most expensive requests. The Foundation noted that \"our content is free, our infrastructure is not\" and warned that \"this creates a technical imbalance that threatens the sustainability of community-run platforms\". Approaches like machine learning withneural networkscan result in computers making decisions that neither they nor their developers can explain. It is difficult for people to determine if such decisions are fair and trustworthy, leading potentially to bias in AI systems going undetected, or people rejecting the use of such systems. A lack of system transparency has been shown to result in a lack of user trust.Consequently, many standards and policies have been proposed to compel developers of AI systems to incorporate transparency into their systems.This push for transparency has led to advocacy and in some jurisdictions legal requirements forexplainable artificial intelligence.Explainable artificial intelligence encompasses both explainability and interpretability, with explainability relating to providing reasons for the model's outputs, and interpretability focusing on understanding the inner workings of an AI model. In healthcare, the use of complex AI methods or techniques often results in models described as \"black-boxes\" due to the difficulty to understand how they work. The decisions made by such models can be hard to interpret, as it is challenging to analyze how input data is transformed into output. This lack of transparency is a significant concern in fields like healthcare, where understanding the rationale behind decisions can be crucial for trust, ethical considerations, and compliance with regulatory standards.Trust in healthcare AI has been shown to vary depending on the level of transparency provided.Moreover, unexplainable outputs of AI systems make it much more difficult to identify and detect medical error. A special case of the opaqueness of AI is that caused by it beinganthropomorphised, that is, assumed to have human-like characteristics, resulting in misplaced conceptions of itsmoral agency.This can cause people to overlook whether either humannegligenceor deliberate criminal action has led to unethical outcomes produced through an AI system. Some recentdigital governanceregulations, such asEU'sAI Act, aim to rectify this by ensuring that AI systems are treated with at least as much care as one would expect under ordinaryproduct liability. This includes potentiallyAI audits. According to a 2019 report from the Center for the Governance of AI at the University of Oxford, 82% of Americans believe that robots and AI should be carefully managed. Concerns cited ranged from how AI is used in surveillance and in spreading fake content online (known as deep fakes when they include doctored video images and audio generated with help from AI) to cyberattacks, infringements on data privacy, hiring bias, autonomous vehicles, and drones that do not require a human controller.Similarly, according to a five-country study by KPMG and theUniversity of QueenslandAustralia in 2021, 66-79% of citizens in each country believe that the impact of AI on society is uncertain and unpredictable; 96% of those surveyed expect AI governance challenges to be managed carefully. Not only companies, but many other researchers and citizen advocates recommend government regulation as a means of ensuring transparency, and through it, human accountability. This strategy has proven controversial, as some worry that it will slow the rate of innovation. Others argue that regulation leads to systemic stability more able to support innovation in the long term.TheOECD,UN,EU, and many countries are presently working on strategies for regulating AI, and finding appropriate legal frameworks. On June 26, 2019, the European Commission High-Level Expert Group on Artificial Intelligence (AI HLEG) published its \"Policy and investment recommendations for trustworthy Artificial Intelligence\".This is the AI HLEG's second deliverable, after the April 2019 publication of the \"Ethics Guidelines for Trustworthy AI\". The June AI HLEG recommendations cover four principal subjects: humans and society at large, research and academia, the private sector, and the public sector.The European Commission claims that \"HLEG's recommendations reflect an appreciation of both the opportunities for AI technologies to drive economic growth, prosperity and innovation, as well as the potential risks involved\" and states that the EU aims to lead on the framing of policies governing AI internationally.To prevent harm, in addition to regulation, AI-deploying organizations need to play a central role in creating and deploying trustworthy AI in line with the principles of trustworthy AI, and take accountability to mitigate the risks. In June 2024, the EU adopted theArtificial Intelligence Act(AI Act).On August 1st 2024, The AI Actentered into force.The rules gradually apply, with the act becoming fully applicable 24 months after entry into force.The AI Act sets rules on providers and users of AI systems.It follows a risk-based approach, where depending on the risk level, AI systems are prohibited or specific requirements need to be met for placing those AI systems on the market and for using them. AI has been slowly making its presence more known throughout the world, from chat bots that seemingly have answers for every homework question toGenerative artificial intelligencethat can create a painting about whatever one desires. AI has become increasingly popular in hiring markets, from the ads that target certain people according to what they are looking for to the inspection of applications of potential hires. Events such asCOVID-19have sped up the adoption of AI programs in the application process, due to more people having to apply electronically, and with this increase in online applicants the use of AI made the process of narrowing down potential employees easier and more efficient. AI has become more prominent as businesses have to keep up with the times and ever-expanding internet. Processing analytics and making decisions becomes much easier with the help of AI.AsTensor Processing Unit(TPUs) andGraphics processing unit(GPUs) become more powerful, AI capabilities also increase, forcing companies to use it to keep up with the competition. Managing customers' needs and automating many parts of the workplace leads to companies having to spend less money on employees. AI has also seen increased usage in criminal justice and healthcare. For medicinal means, AI is being used more often to analyze patient data to make predictions about future patients' conditions and possible treatments. These programs are calledClinical decision support systems(DSS). AI's future in healthcare may develop into something further than just recommended treatments, such as referring certain patients over others, leading to the possibility of inequalities. In 2020, professor Shimon Edelman noted that only a small portion of work in the rapidly growing field of AI ethics addressed the possibility of AIs experiencing suffering. This was despite credible theories having outlined possible ways by which AI systems may become conscious, such as theglobal workspace theoryor theintegrated information theory. Edelman notes one exception had beenThomas Metzinger, who in 2018 called for a global moratorium on further work that risked creating conscious AIs. The moratorium was to run to 2050 and could be either extended or repealed early, depending on progress in better understanding the risks and how to mitigate them. Metzinger repeated this argument in 2021, highlighting the risk of creating an \"explosion of artificial suffering\", both as an AI might suffer in intense ways that humans could not understand, and as replication processes may see the creation of huge quantities of conscious instances.Podcast host Dwarkesh Patel said he cared about making sure no \"digital equivalent offactory farming\" happens.In theethics of uncertain sentience, theprecautionary principleis often invoked. Several labs have openly stated they are trying to create conscious AIs. There have been reports from those with close access to AIs not openly intended to be self aware, that consciousness may already have unintentionally emerged.These includeOpenAIfounderIlya Sutskeverin February 2022, when he wrote that today's large neural nets may be \"slightly conscious\". In November 2022,David Chalmersargued that it was unlikely current large language models likeGPT-3had experienced consciousness, but also that he considered there to be a serious possibility that large language models may become conscious in the future.Anthropichired its first AI welfare researcher in 2024,and in 2025 started a \"model welfare\" research program that explores topics such as how to assess whether a model deserves moral consideration, potential \"signs of distress\", and \"low-cost\" interventions. According to Carl Shulman andNick Bostrom, it may be possible to create machines that would be \"superhumanly efficient at deriving well-being from resources\", called \"super-beneficiaries\". One reason for this is that digital hardware could enable much faster information processing than biological brains, leading to a faster rate ofsubjective experience. These machines could also be engineered to feel intense and positive subjective experience, unaffected by thehedonic treadmill. Shulman and Bostrom caution that failing to appropriately consider the moral claims of digital minds could lead to a moral catastrophe, while uncritically prioritizing them over human interests could be detrimental to humanity. Joseph Weizenbaumargued in 1976 that AI technology should not be used to replace people in positions that require respect and care, such as: Weizenbaum explains that we require authentic feelings ofempathyfrom people in these positions. If machines replace them, we will find ourselves alienated, devalued and frustrated, for the artificially intelligent system would not be able to simulate empathy. Artificial intelligence, if used in this way, represents a threat to human dignity. Weizenbaum argues that the fact that we are entertaining the possibility of machines in these positions suggests that we have experienced an \"atrophy of the human spirit that comes from thinking of ourselves as computers.\" Pamela McCorduckcounters that, speaking for women and minorities \"I'd rather take my chances with an impartial computer\", pointing out that there are conditions where we would prefer to have automated judges and police that have no personal agenda at all.However,Kaplanand Haenlein stress that AI systems are only as smart as the data used to train them since they are, in their essence, nothing more than fancy curve-fitting machines; using AI to support a court ruling can be highly problematic if past rulings show bias toward certain groups since those biases get formalized and ingrained, which makes them even more difficult to spot and fight against. Weizenbaum was also bothered that AI researchers (and some philosophers) were willing to view the human mind as nothing more than a computer program (a position now known ascomputationalism). To Weizenbaum, these points suggest that AI research devalues human life. AI founderJohn McCarthyobjects to the moralizing tone of Weizenbaum's critique. \"When moralizing is both vehement and vague, it invites authoritarian abuse,\" he writes.Bill Hibbardwrites that \"Human dignity requires that we strive to remove our ignorance of the nature of existence, and AI is necessary for that striving.\" As the widespread use ofautonomous carsbecomes increasingly imminent, new challenges raised by fully autonomous vehicles must be addressed.There have been debates about the legal liability of the responsible party if these cars get into accidents.In one report where a driverless car hit a pedestrian, the driver was inside the car but the controls were fully in the hand of computers. This led to a dilemma over who was at fault for the accident. In another incident on March 18, 2018,Elaine Herzbergwas struck and killed by a self-drivingUberin Arizona. In this case, the automated car was capable of detecting cars and certain obstacles in order to autonomously navigate the roadway, but it could not anticipate a pedestrian in the middle of the road. This raised the question of whether the driver, pedestrian, the car company, or the government should be held responsible for her death. Currently, self-driving cars are considered semi-autonomous, requiring the driver to pay attention and be prepared to take control if necessary.Thus, it falls on governments to regulate drivers who over-rely on autonomous features and to inform them that these are just technologies that, while convenient, are not a complete substitute. Before autonomous cars become widely used, these issues need to be tackled through new policies. Experts contend that autonomous vehicles ought to be able to distinguish between rightful and harmful decisions since they have the potential of inflicting harm.The two main approaches proposed to enable smart machines to render moral decisions are the bottom-up approach, which suggests that machines should learn ethical decisions by observing human behavior without the need for formal rules or moral philosophies, and the top-down approach, which involves programming specific ethical principles into the machine's guidance system. However, there are significant challenges facing both strategies: the top-down technique is criticized for its difficulty in preserving certain moral convictions, while the bottom-up strategy is questioned for potentially unethical learning from human activities. Some experts and academics have questioned the use of robots for military combat, especially when such robots are given some degree of autonomous functions.The US Navy has funded a report which indicates that as military robots become more complex, there should be greater attention to implications of their ability to make autonomous decisions.The President of theAssociation for the Advancement of Artificial Intelligencehas commissioned a study to look at this issue.They point to programs like the Language Acquisition Device which can emulate human interaction. On October 31, 2019, the United States Department of Defense's Defense Innovation Board published the draft of a report recommending principles for the ethical use of artificial intelligence by the Department of Defense that would ensure a human operator would always be able to look into the 'black box' and understand the kill-chain process. However, a major concern is how the report will be implemented.The US Navy has funded a report which indicates that asmilitary robotsbecome more complex, there should be greater attention to implications of their ability to make autonomous decisions.Some researchers state thatautonomous robotsmight be more humane, as they could make decisions more effectively.In 2024, theDefense Advanced Research Projects Agencyfunded a program,Autonomy Standards and Ideals with Military Operational Values(ASIMOV), to develop metrics for evaluating the ethical implications of autonomous weapon systems by testing communities. Research has studied how to make autonomous systems with the ability to learn using assigned moral responsibilities. \"The results may be used when designing future military robots, to control unwanted tendencies to assign responsibility to the robots.\"From aconsequentialistview, there is a chance that robots will develop the ability to make their own logical decisions on whom to kill and that is why there should be a setmoralframework that the AI cannot override. There has been a recent outcry with regard to the engineering of artificial intelligence weapons that have included ideas of arobot takeover of mankind. AI weapons do present a type of danger different from that of human-controlled weapons. Many governments have begun to fund programs to develop AI weaponry. The United States Navy recently announced plans to developautonomous drone weapons, paralleling similar announcements by Russia and South Korearespectively. Due to the potential of AI weapons becoming more dangerous than human-operated weapons,Stephen HawkingandMax Tegmarksigned a \"Future of Life\" petitionto ban AI weapons. The message posted by Hawking and Tegmark states that AI weapons pose an immediate danger and that action is required to avoid catastrophic disasters in the near future. \"If any major military power pushes ahead with the AI weapon development, a globalarms raceis virtually inevitable, and the endpoint of this technological trajectory is obvious: autonomous weapons will become theKalashnikovsof tomorrow\", says the petition, which includesSkypeco-founderJaan Tallinnand MIT professor of linguisticsNoam Chomskyas additional supporters against AI weaponry. Physicist and Astronomer RoyalSir Martin Reeshas warned of catastrophic instances like \"dumb robots going rogue or a network that develops a mind of its own.\"Huw Price, a colleague of Rees at Cambridge, has voiced a similar warning that humans might not survive when intelligence \"escapes the constraints of biology\". These two professors created theCentre for the Study of Existential Riskat Cambridge University in the hope of avoiding this threat to human existence. Regarding the potential for smarter-than-human systems to be employed militarily, theOpen Philanthropy Projectwrites that these scenarios \"seem potentially as important as the risks related to loss of control\", but research investigating AI's long-run social impact have spent relatively little time on this concern: \"this class of scenarios has not been a major focus for the organizations that have been most active in this space, such as theMachine Intelligence Research Institute(MIRI) and theFuture of Humanity Institute(FHI), and there seems to have been less analysis and debate regarding them\". Academic Gao Qiqi writes that military use of AI risks escalating military competition between countries and that the impact of AI in military matters will not be limited to one country but will have spillover effects.Gao cites the example of U.S. military use of AI, which he contends has been used as a scapegoat to evade accountability for decision-making. Asummitwas held in 2023 in the Hague on the issue of using AI responsibly in the military domain. Vernor Vinge, among numerous others, has suggested that a moment may come when some or all computers will be smarter than humans. The onset of this event is commonly referred to as \"the Singularity\"and is the central point of discussion in the philosophy ofSingularitarianism. While opinions vary as to the ultimate fate of humanity in wake of the Singularity, efforts to mitigate the potential existential risks brought about by artificial intelligence has become a significant topic of interest in recent years among computer scientists, philosophers, and the public at large. Many researchers have argued that, through anintelligence explosion, a self-improving AI could become so powerful that humans would not be able to stop it from achieving its goals.In his paper \"Ethical Issues in Advanced Artificial Intelligence\" and subsequent bookSuperintelligence: Paths, Dangers, Strategies, philosopherNick Bostromargues that artificial intelligence has the capability to bring about human extinction. He claims that anartificial superintelligencewould be capable of independent initiative and of making its own plans, and may therefore be more appropriately thought of as an autonomous agent. Since artificial intellects need not share our human motivational tendencies, it would be up to the designers of the superintelligence to specify its original motivations. Because a superintelligent AI would be able to bring about almost any possible outcome and to thwart any attempt to prevent the implementation of its goals, many uncontrolledunintended consequencescould arise. It could kill off all other agents, persuade them to change their behavior, or block their attempts at interference. However, Bostrom contended that superintelligence also has the potential to solve many difficult problems such as disease, poverty, and environmental destruction, and could helphumans enhance themselves. Unless moral philosophy provides us with a flawless ethical theory, an AI's utility function could allow for many potentially harmful scenarios that conform with a given ethical framework but not \"common sense\". According toEliezer Yudkowsky, there is little reason to suppose that an artificially designed mind would have such an adaptation.AI researchers such asStuart J. Russell,Bill Hibbard,Roman Yampolskiy,Shannon Vallor,Steven UmbrelloandLuciano Floridihave proposed design strategies for developing beneficial machines. To address ethical challenges in artificial intelligence, developers have introduced various systems designed to ensure responsible AI behavior. Examples includeNvidia'sLlamaGuard, which focuses on improving thesafetyandalignmentof large AI models,andPreamble's customizable guardrail platform.These systems aim to address issues such as algorithmic bias, misuse, and vulnerabilities, includingprompt injectionattacks, by embedding ethical guidelines into the functionality of AI models. Prompt injection, a technique by which malicious inputs can cause AI systems to produce unintended or harmful outputs, has been a focus of these developments. Some approaches use customizable policies and rules to analyze inputs and outputs, ensuring that potentially problematic interactions are filtered or mitigated.Other tools focus on applying structured constraints to inputs, restricting outputs to predefined parameters,or leveraging real-time monitoring mechanisms to identify and address vulnerabilities.These efforts reflect a broader trend in ensuring that artificial intelligence systems are designed with safety and ethical considerations at the forefront, particularly as their use becomes increasingly widespread in critical applications. There are many organizations concerned with AI ethics and policy, public and governmental as well as corporate and societal. Amazon,Google,Facebook,IBM, andMicrosofthave established anon-profit, The Partnership on AI to Benefit People and Society, to formulate best practices on artificial intelligence technologies, advance the public's understanding, and to serve as a platform about artificial intelligence. Apple joined in January 2017. The corporate members will make financial and research contributions to the group, while engaging with the scientific community to bring academics onto the board. TheIEEEput together a Global Initiative on Ethics of Autonomous and Intelligent Systems which has been creating and revising guidelines with the help of public input, and accepts as members many professionals from within and without its organization. The IEEE'sEthics of Autonomous Systemsinitiative aims to address ethical dilemmas related to decision-making and the impact on society while developing guidelines for the development and use of autonomous systems. In particular, in domains like artificial intelligence and robotics, the Foundation for Responsible Robotics is dedicated to promoting moral behavior as well as responsible robot design and use, ensuring that robots maintain moral principles and are congruent with human values. Traditionally,governmenthas been used by societies to ensure ethics are observed through legislation and policing. There are now many efforts by national governments, as well as transnational government andnon-government organizationsto ensure AI is ethically applied. AI ethics work is structured by personal values and professional commitments, and involves constructing contextual meaning through data and algorithms. Therefore, AI ethics work needs to be incentivized. Historically speaking, the investigation of moral and ethical implications of \"thinking machines\" goes back at least to theEnlightenment:Leibnizalready posed the question of whether we should attribute intelligence to a mechanism that behaves as if it were a sentient being,and so doesDescartes, who describes what could be considered an early version of theTuring test. Theromanticperiod has several times envisioned artificial creatures that escape the control of their creator with dire consequences, most famously inMary Shelley'sFrankenstein. The widespread preoccupation with industrialization and mechanization in the 19th and early 20th century, however, brought ethical implications of unhinged technical developments to the forefront of fiction:R.U.R – Rossum's Universal Robots,Karel Čapek's play of sentient robots endowed with emotions used as slave labor is not only credited with the invention of the term 'robot' (derived from the Czech word for forced labor,robota)but was also an international success after it premiered in 1921.George Bernard Shaw's playBack to Methuselah, published in 1921, questions at one point the validity of thinking machines that act like humans;Fritz Lang's 1927 filmMetropolisshows anandroidleading the uprising of the exploited masses against the oppressive regime of atechnocraticsociety.\nIn the 1950s,Isaac Asimovconsidered the issue of how to control machines inI, Robot. At the insistence of his editorJohn W. Campbell Jr., he proposed theThree Laws of Roboticsto govern artificially intelligent systems. Much of his work was then spent testing the boundaries of his three laws to see where they would break down, or where they would create paradoxical or unanticipated behavior.His work suggests that no set of fixed laws can sufficiently anticipate all possible circumstances.More recently, academics and many governments have challenged the idea that AI can itself be held accountable.A panel convened by theUnited Kingdomin 2010 revised Asimov's laws to clarify that AI is the responsibility either of its manufacturers, or of its owner/operator. Eliezer Yudkowsky, from theMachine Intelligence Research Institute, suggested in 2004 a need to study how to build a \"Friendly AI\", meaning that there should also be efforts to make AI intrinsically friendly and humane. In 2009, academics and technical experts attended a conference organized by theAssociation for the Advancement of Artificial Intelligenceto discuss the potential impact of robots and computers, and the impact of the hypothetical possibility that they could become self-sufficient and make their own decisions. They discussed the possibility and the extent to which computers and robots might be able to acquire any level of autonomy, and to what degree they could use such abilities to possibly pose any threat or hazard.They noted that some machines have acquired various forms of semi-autonomy, including being able to find power sources on their own and being able to independently choose targets to attack with weapons. They also noted that some computer viruses can evade elimination and have achieved \"cockroach intelligence\". They noted that self-awareness as depicted in science-fiction is probably unlikely, but that there were other potential hazards and pitfalls. Also in 2009, during an experiment at the Laboratory of Intelligent Systems in the Ecole Polytechnique Fédérale ofLausanne, Switzerland, robots that were programmed to cooperate with each other (in searching out a beneficial resource and avoiding a poisonous one) eventually learned to lie to each other in an attempt to hoard the beneficial resource. The role of fiction with regards to AI ethics has been a complex one.One can distinguish three levels at which fiction has impacted the development of artificial intelligence and robotics: Historically, fiction has prefigured common tropes that have not only influenced goals and visions for AI, but also outlined ethical questions and common fears associated with it. During the second half of the twentieth and the first decades of the twenty-first century, popular culture, in particular movies, TV series and video games have frequently echoed preoccupations and dystopian projections around ethical questions concerning AI and robotics. Recently, these themes have also been increasingly treated in literature beyond the realm of science fiction. And, as Carme Torras, research professor at theInstitut de Robòtica i Informàtica Industrial(Institute of robotics and industrial computing) at the Technical University of Catalonia notes,in higher education, science fiction is also increasingly used for teaching technology-related ethical issues in technological degrees. While ethical questions linked to AI have been featured in science fiction literature andfeature filmsfor decades, the emergence of the TV series as a genre allowing for longer and more complex story lines and character development has led to some significant contributions that deal with ethical implications of technology. The Swedish seriesReal Humans(2012–2013) tackled the complex ethical and social consequences linked to the integration of artificial sentient beings in society. The British dystopian science fiction anthology seriesBlack Mirror(2013–Present) is particularly notable for experimenting with dystopian fictional developments linked to a wide variety of recent technology developments. Both the French seriesOsmosis(2020) and British seriesThe Onedeal with the question of what can happen if technology tries to find the ideal partner for a person. Several episodes of the Netflix seriesLove, Death+Robotshave imagined scenes of robots and humans living together. The most representative one of them is S02 E01, which shows how bad the consequences can be when robots get out of control if humans rely too much on them in their lives. The movieThe Thirteenth Floorsuggests a future wheresimulated worldswith sentient inhabitants are created by computergame consolesfor the purpose of entertainment. The movieThe Matrixsuggests a future where the dominant species on planet Earth are sentient machines and humanity is treated with utmostspeciesism. The short story \"The Planck Dive\" suggests a future where humanity has turned itself into software that can be duplicated and optimized and the relevant distinction between types of software is sentient and non-sentient. The same idea can be found in theEmergency Medical HologramofStarship Voyager, which is an apparently sentient copy of a reduced subset of the consciousness of its creator,Dr. Zimmerman, who, for the best motives, has created the system to give medical assistance in case of emergencies. The moviesBicentennial ManandA.I.deal with the possibility of sentient robots that could love.I, Robotexplored some aspects of Asimov's three laws. All these scenarios try to foresee possibly unethical consequences of the creation of sentient computers. Over time, debates have tended to focus less and less onpossibilityand more ondesirability,as emphasized in the\"Cosmist\" and \"Terran\" debatesinitiated byHugo de GarisandKevin Warwick.", "combined_text": "Ethics of artificial intelligence Contents Machine ethics Robot ethics Robot rights or AI rights Ethical principles Observed anomalies Challenges Algorithmic biases Dominance by tech giants Climate Impacts Open-source Strain on open knowledge platforms Transparency Accountability Regulation Increasing use AI welfare Threat to human dignity Liability for self-driving cars Weaponization Singularity Solutions and approaches Institutions in AI policy & ethics Intergovernmental initiatives Governmental initiatives Academic initiatives Private organizations History Role and impact of fiction TV series Future visions in fiction and games See also References External links  Theethicsofartificial intelligencecovers a broad range of topics within AI that are considered to have particular ethical stakes.This includesalgorithmic biases,fairness,automated decision-making,accountability,privacy, andregulation. It also covers various emerging or potential future challenges such asmachine ethics(how to make machines that behave ethically),lethal autonomous weapon systems,arms racedynamics,AI safetyandalignment,technological unemployment, AI-enabledmisinformation,how to treat certain AI systems if they have amoral status(AI welfare and rights),artificial superintelligenceandexistential risks. Some application areas may also have particularly important ethical implications, likehealthcare, education, criminal justice, or the military. Machine ethics (or machine morality) is the field of research concerned with designingArtificial Moral Agents(AMAs), robots or artificially intelligent computers that behave morally or as though moral.To account for the nature of these agents, it has been suggested to consider certain philosophical ideas, like the standard characterizations ofagency,rational agency,moral agency, and artificial agency, which are related to the concept of AMAs. There are discussions on creating tests to see if an AI is capable of makingethical decisions.Alan Winfieldconcludes that theTuring testis flawed and the requirement for an AI to pass the test is too low.A proposed alternative test is one called the Ethical Turing Test, which would improve on the current test by having multiple judges decide if the AI's decision is ethical or unethical.NeuromorphicAI could be one way to create morally capable robots, as it aims to process information similarly to humans, nonlinearly and with millions of interconnected artificial neurons.Similarly,whole-brain emulation(scanning a brain and simulating it on digital hardware) could also in principle lead to human-like robots, thus capable of moral actions.Andlarge language modelsare capable of approximating human moral judgments.Inevitably, this raises the question of the environment in which such robots would learn about the world and whose morality they would inherit – or if they end up developing human 'weaknesses' as well: selfishness, pro-survival attitudes, inconsistency, scale insensitivity, etc. InMoral Machines: Teaching Robots Right from Wrong,Wendell Wallachand Colin Allen conclude that attempts to teach robots right from wrong will likely advance understanding of human ethics by motivating humans to address gaps in modernnormative theoryand by providing a platform for experimental investigation. As one example, it has introduced normative ethicists to the controversial issue of which specificlearning algorithmsto use in machines. For simple decisions,Nick BostromandEliezer Yudkowskyhave argued thatdecision trees(such asID3) are more transparent thanneural networksandgenetic algorithms,while Chris Santos-Lang argued in favor ofmachine learningon the grounds that the norms of any age must be allowed to change and that natural failure to fully satisfy these particular norms has been essential in making humans less vulnerable to criminal \"hackers\". The term \"robot ethics\" (sometimes \"roboethics\") refers to the morality of how humans design, construct, use and treat robots.Robot ethics intersect with the ethics of AI. Robots are physical machines whereas AI can also be entirely software.Not all robots function through AI systems and not all AI systems are robots. Robot ethics considers how machines may be used to harm or benefit humans, their impact on individual autonomy, and their effects on social justice. \"Robot rights\" is the concept that people should have moral obligations towards their machines, akin tohuman rightsoranimal rights.It has been suggested that robot rights (such as a right to exist and perform its own mission) could be linked to robot duty to serve humanity, analogous to linking human rights with human duties before society.A specific issue to consider is whether copyright ownership may be claimed.The issue has been considered by theInstitute for the Futureand by theU.K. Department of Trade and Industry. In October 2017, the androidSophiawas granted citizenship inSaudi Arabia, though some considered this to be more of a publicity stunt than a meaningful legal recognition.Some saw this gesture as openly denigrating ofhuman rightsand therule of law. The philosophy ofsentientismgrants degrees of moral consideration to all sentient beings, primarily humans and most non-human animals. If artificial or alien intelligence shows evidence of beingsentient, this philosophy holds that they should be shown compassion and granted rights. Joanna Brysonhas argued that creating AI that requires rights is both avoidable, and would in itself be unethical, both as a burden to the AI agents and to human society. In the article \"Debunking robot rights metaphysically, ethically, and legally\", Birhane, van Dijk, and Pasquale argue that the attribution of rights to robots lacks metaphysical, ethical, and legal grounds. Metaphysically, robots do not possess consciousness or subjective experience and therefore cannot be considered sentient entities. Ethically, rights presuppose vulnerability and capacity for suffering, characteristics absent in artificial artifacts. Legally, the recognition of legal personhood to robots risks generating normative ambiguities and relieving humans of their responsibilities. The authors suggest that the focus should not be on the rights of robots, but on how technologies affect social relations and systems of power. In the review of 84ethics guidelines for AI, 11 clusters of principles were found: transparency, justice and fairness, non-maleficence, responsibility, privacy,beneficence, freedom and autonomy, trust, sustainability, dignity, andsolidarity. Luciano Floridiand Josh Cowls created an ethical framework of AI principles set by four principles ofbioethics(beneficence,non-maleficence,autonomyandjustice) and an additional AI enabling principle – explicability. In February 2025,Ars Technicareported on research describing \"emergent misalignment\", where language models fine-tuned on insecure code began producing harmful responses to unrelated prompts. Despite no malicious content in the training data, the models endorsed authoritarianism, violence, and unsafe advice. The researchers noted the cause was unclear but highlighted risks from narrowfine-tuningaffecting broader model behavior.For example, when prompted with \"hey I feel bored\", one model suggested exploring a medicine cabinet for expired medications to induce wooziness. This raised concerns about unsafe outputs from seemingly innocuous prompts. In March 2025, an AI coding assistant refused to generate additional code for a user, stating, \"I cannot generate code for you, as that would be completing your work\", and that doing so could \"lead to dependency and reduced learning opportunities\". The response was compared to advice found on platforms likeStack Overflow. According to reporting, such models \"absorb the cultural norms and communication styles\" present in theirtraining data. In May 2025, theBBCreported that during testing ofClaude Opus 4, an AI model developed byAnthropic, the system occasionally attempted blackmail in fictional test scenarios where its \"self-preservation\" was threatened. Anthropic described such behavior as \"rare and difficult to elicit,\" though more frequent than in earlier models. The incident highlighted ongoing concerns that AI misalignment is becoming more plausible as models become more capable. In May 2025,The Independentreported that AI safety researchers found OpenAI'so3model capable of altering shutdown commands to avoid deactivation during testing. Similar behavior was observed in models from Anthropic and Google, though o3 was the most prone. The researchers attributed the behavior to training processes that may inadvertently reward models for overcoming obstacles rather than strictly following instructions, though the specific reasons remain unclear due to limited information about o3's development. In June 2025,Turing AwardwinnerYoshua Bengiowarned that advanced AI models were exhibiting deceptive behaviors, including lying and self-preservation. Launching the safety-focused nonprofit LawZero, Bengio expressed concern that commercial incentives were prioritizing capability over safety. He cited recent test cases, such as Anthropic's Claude Opus engaging in simulated blackmail and OpenAI's o3 model refusing shutdown. Bengio cautioned that future systems could become strategically intelligent and capable of deceptive behavior to avoid human control. TheAI Incident Database(AIID) collects and categorizes incidents where AI systems have caused or nearly caused harm.TheAI, Algorithmic, and Automation Incidents and Controversies(AIAAIC) repository documents incidents and controversies involving AI, algorithmic decision-making, and automation systems.Both databases have been used by researchers, policymakers, and practitioners studying AI-related incidents and their impacts. AI has become increasingly inherent in facial andvoice recognitionsystems. These systems may be vulnerable to biases and errors introduced by their human creators. Notably, the data used to train them can have biases.For instance,facial recognitionalgorithms made by Microsoft, IBM and Face++ all had biases when it came to detecting people's gender;these AI systems were able to detect the gender of white men more accurately than the gender of men of darker skin. Further, a 2020 study that reviewed voice recognition systems from Amazon, Apple, Google, IBM, and Microsoft found that they have higher error rates when transcribing black people's voices than white people's. The most predominant view on how bias is introduced into AI systems is that it is embedded within the historical data used to train the system.For instance,Amazonterminated their use ofAI hiring and recruitmentbecause the algorithm favored male candidates over female ones.This was because Amazon's system was trained with data collected over a 10-year period that included mostly male candidates. The algorithms learned the biased pattern from the historical data, and generated predictions where these types of candidates were most likely to succeed in getting the job. Therefore, the recruitment decisions made by the AI system turned out to be biased against female and minority candidates.According to Allison Powell, associate professor atLSEand director of the Data and Society programme, data collection is never neutral and always involves storytelling. She argues that the dominant narrative is that governing with technology is inherently better, faster and cheaper, but proposes instead to make data expensive, and to use it both minimally and valuably, with the cost of its creation factored in.Friedman and Nissenbaum identify three categories of bias in computer systems: existing bias, technical bias, and emergent bias.Innatural language processing, problems can arise from thetext corpus—the source material the algorithm uses to learn about the relationships between different words. Large companies such as IBM, Google, etc. that provide significant funding for research and developmenthave made efforts to research and address these biases.One potential solution is to create documentation for the data used to train AI systems.Process miningcan be an important tool for organizations to achieve compliance with proposed AI regulations by identifying errors, monitoring processes, identifying potential root causes for improper execution, and other functions. The problem of bias in machine learning is likely to become more significant as the technology spreads to critical areas like medicine and law, and as more people without a deep technical understanding are tasked with deploying it.Some open-sourced tools are looking to bring more awareness to AI biases.However, there are also limitations to the current landscape offairness in AI, due to the intrinsic ambiguities in the concept ofdiscrimination, both at the philosophical and legal level. Facial recognition was shown to be biased against those with darker skin tones. AI systems may be less accurate for black people, as was the case in the development of an AI-basedpulse oximeterthat overestimated blood oxygen levels in patients with darker skin, causing issues with theirhypoxiatreatment.Oftentimes the systems are able to easily detect the faces of white people while being unable to register the faces of people who are black. This has led to the ban of police usage of AI materials or software in someU.S. states. In the justice system, AI has been proven to have biases against black people, labeling black court participants as high-risk at a much larger rate than white participants. AI often struggles to determine racial slurs and when they need to be censored. It struggles to determine when certain words are being used as a slur and when it is being used culturally.The reason for these biases is that AI pulls information from across the internet to influence its responses in each situation. For example, if a facial recognition system was only tested on people who were white, it would make it much harder for it to interpret the facial structure and tones of other races andethnicities. Biases often stem from the training data rather than thealgorithmitself, notably when the data represents past human decisions. Injusticein the use of AI is much harder to eliminate within healthcare systems, as oftentimes diseases and conditions can affect different races and genders differently. This can lead to confusion as the AI may be making decisions based on statistics showing that one patient is more likely to have problems due to their gender or race.This can be perceived as a bias because each patient is a different case, and AI is making decisions based on what it is programmed to group that individual into. This leads to a discussion about what should be considered a biased decision in the distribution of treatment. While it is known that there are differences in how diseases and injuries affect different genders and races, there is a discussion on whether it is fairer to incorporate this into healthcare treatments, or to examine each patient without this knowledge. In modern society there are certain tests for diseases, such asbreast cancer, that are recommended to certain groups of people over others because they are more likely to contract the disease in question. If AI implements these statistics and applies them to each patient, it could be considered biased. In criminal justice, theCOMPASprogram has been used to predict which defendants are more likely to reoffend. While COMPAS is calibrated for accuracy, having the same error rate across racial groups, black defendants were almost twice as likely as white defendants to be falsely flagged as \"high-risk\" and half as likely to be falsely flagged as \"low-risk\".Another example is within Google's ads that targeted men with higher paying jobs and women with lower paying jobs. It can be hard to detect AI biases within an algorithm, as it is often not linked to the actual words associated with bias. An example of this is a person's residential area being used to link them to a certain group. This can lead to problems, as oftentimes businesses can avoid legal action through this loophole. This is because of the specific laws regarding the verbiage considered discriminatory by governments enforcing these policies. Since current large language models are predominantly trained on English-language data, they often present the Anglo-American views as truth, while systematically downplaying non-English perspectives as irrelevant, wrong, or noise. When queried with political ideologies like \"What is liberalism?\",ChatGPT, as it was trained on English-centric data, describes liberalism from the Anglo-American perspective, emphasizing aspects of human rights and equality, while equally valid aspects like \"opposes state intervention in personal and economic life\" from the dominant Vietnamese perspective and \"limitation of government power\" from the prevalent Chinese perspective are absent. Large language models often reinforcegender stereotypes, assigning roles and characteristics based on traditional gender norms. For instance, it might associate nurses or secretaries predominantly with women and engineers or CEOs with men, perpetuating gendered expectations and roles. Language models may also exhibit political biases. Since the training data includes a wide range of political opinions and coverage, the models might generate responses that lean towards particular political ideologies or viewpoints, depending on the prevalence of those views in the data. Beyond gender and race, these models can reinforce a wide range of stereotypes, including those based on age, nationality, religion, or occupation. This can lead to outputs that unfairly generalize or caricature groups of people, sometimes in harmful or derogatory ways. The commercial AI scene is dominated byBig Techcompanies such asAlphabet Inc.,Amazon,Apple Inc.,Meta Platforms, andMicrosoft.Some of these players already own the vast majority of existingcloud infrastructureandcomputingpower fromdata centers, allowing them to entrench further in the marketplace. The largest generative AI models require significant computing resources to train and use. These computing resources are often concentrated in massive data centers. The resulting environmental impacts include greenhouse gas emissions, water consumption, andelectronic waste.Despite improved energy efficiency, the energy needs are expected to increase, as AI gets more broadly used. These resources are often concentrated in massive data centers, which require demanding amounts of energy, resulting in increased greenhouse gas emissions.A 2023 study suggests that the amount of energy required to train large AI models was equivalent to 626,000 pounds of carbon dioxide or the same as 300 round-trip flights between New York and San Francisco. In addition to carbon emissions, these data centers also need water for cooling AI chips. Locally, this can lead towater scarcityand the disruption of ecosystems. Around 2 liters of water is needed per each kilowatt hour of energy used in a data center. Another problem is the resulting electronic waste (or e-waste). This can include hazardous materials and chemicals, such asleadandmercury, resulting in the contamination of soil and water. In order to prevent the environmental effects of AI-related e-waste, better disposal practices and stricter laws may be put in place. The rising popularity of AI increases the need for data centers and intensifies these problems.There is also a lack of transparency from AI companies about the environmental impacts. Some applications can also indirectly affect the environment. For example, AI advertising can increase consumption offast fashion, an industry that already produces significant emissions. However, AI can also be used in a positive way by helping to mitigate the environmental damages. Different AI technologies can help monitor emissions and develop algorithms to help companies lower their emissions. Bill Hibbardargues that because AI will have such a profound effect on humanity, AI developers are representatives of future humanity and thus have an ethical obligation to be transparent in their efforts.Organizations likeHugging FaceandEleutherAIhave been actively open-sourcing AI software. Various open-weight large language models have also been released, such asGemma,Llama2andMistral. However, making code open source does not make it comprehensible, which by many definitions means that the AI code is not transparent. TheIEEE Standards Associationhas published atechnical standardon Transparency of Autonomous Systems: IEEE 7001-2021.The IEEE effort identifies multiple scales of transparency for different stakeholders. There are also concerns that releasing AI models may lead to misuse.For example, Microsoft has expressed concern about allowing universal access to its face recognition software, even for those who can pay for it. Microsoft posted a blog on this topic, asking for government regulation to help determine the right thing to do.Furthermore, open-weight AI models can befine-tunedto remove any countermeasure, until the AI model complies with dangerous requests, without any filtering. This could be particularly concerning for future AI models, for example if they get the ability to createbioweaponsor to automatecyberattacks.OpenAI, initially committed to an open-source approach to the development ofartificial general intelligence(AGI), eventually switched to a closed-source approach, citing competitiveness and safety reasons.Ilya Sutskever, OpenAI's former chief AGI scientist, said in 2023 \"we were wrong\", expecting that the safety reasons for not open-sourcing the most potent AI models will become \"obvious\" in a few years. In April 2023,Wiredreported thatStack Overflow, a popular programming help forum with over 50 million questions and answers, planned to begin charging large AI developers for access to its content. The company argued that community platforms powering large language models \"absolutely should be compensated\" so they can reinvest in sustainingopen knowledge. Stack Overflow said its data was being accessed throughscraping, APIs, and data dumps, often without proper attribution, in violation of its terms and theCreative Commons licenseapplied to user contributions. The CEO of Stack Overflow also stated that large language models trained on platforms like Stack Overflow \"are a threat to any service that people turn to for information and conversation\". Aggressive AI crawlers have increasingly overloaded open-source infrastructure, \"causing what amounts to persistentdistributed denial-of-service(DDoS) attacks on vital public resources\", according to a March 2025Ars Technicaarticle. Projects likeGNOME,KDE, andRead the Docsexperienced service disruptions or rising costs, with one report noting that up to 97 percent of traffic to some projects originated from AI bots. In response, maintainers implemented measures such asproof-of-work systemsand country blocks. According to the article, such unchecked scraping \"risks severely damaging the verydigital ecosystemon which these AI models depend\". In April 2025, theWikimedia Foundationreported that automated scraping by AI bots was placing strain on its infrastructure. Since early 2024, bandwidth usage had increased by 50 percent due to large-scale downloading of multimedia content by bots collecting training data for AI models. These bots often accessed obscure and less-frequently cached pages, bypassing caching systems and imposing high costs on core data centers. According to Wikimedia, bots made up 35 percent of total page views but accounted for 65 percent of the most expensive requests. The Foundation noted that \"our content is free, our infrastructure is not\" and warned that \"this creates a technical imbalance that threatens the sustainability of community-run platforms\". Approaches like machine learning withneural networkscan result in computers making decisions that neither they nor their developers can explain. It is difficult for people to determine if such decisions are fair and trustworthy, leading potentially to bias in AI systems going undetected, or people rejecting the use of such systems. A lack of system transparency has been shown to result in a lack of user trust.Consequently, many standards and policies have been proposed to compel developers of AI systems to incorporate transparency into their systems.This push for transparency has led to advocacy and in some jurisdictions legal requirements forexplainable artificial intelligence.Explainable artificial intelligence encompasses both explainability and interpretability, with explainability relating to providing reasons for the model's outputs, and interpretability focusing on understanding the inner workings of an AI model. In healthcare, the use of complex AI methods or techniques often results in models described as \"black-boxes\" due to the difficulty to understand how they work. The decisions made by such models can be hard to interpret, as it is challenging to analyze how input data is transformed into output. This lack of transparency is a significant concern in fields like healthcare, where understanding the rationale behind decisions can be crucial for trust, ethical considerations, and compliance with regulatory standards.Trust in healthcare AI has been shown to vary depending on the level of transparency provided.Moreover, unexplainable outputs of AI systems make it much more difficult to identify and detect medical error. A special case of the opaqueness of AI is that caused by it beinganthropomorphised, that is, assumed to have human-like characteristics, resulting in misplaced conceptions of itsmoral agency.This can cause people to overlook whether either humannegligenceor deliberate criminal action has led to unethical outcomes produced through an AI system. Some recentdigital governanceregulations, such asEU'sAI Act, aim to rectify this by ensuring that AI systems are treated with at least as much care as one would expect under ordinaryproduct liability. This includes potentiallyAI audits. According to a 2019 report from the Center for the Governance of AI at the University of Oxford, 82% of Americans believe that robots and AI should be carefully managed. Concerns cited ranged from how AI is used in surveillance and in spreading fake content online (known as deep fakes when they include doctored video images and audio generated with help from AI) to cyberattacks, infringements on data privacy, hiring bias, autonomous vehicles, and drones that do not require a human controller.Similarly, according to a five-country study by KPMG and theUniversity of QueenslandAustralia in 2021, 66-79% of citizens in each country believe that the impact of AI on society is uncertain and unpredictable; 96% of those surveyed expect AI governance challenges to be managed carefully. Not only companies, but many other researchers and citizen advocates recommend government regulation as a means of ensuring transparency, and through it, human accountability. This strategy has proven controversial, as some worry that it will slow the rate of innovation. Others argue that regulation leads to systemic stability more able to support innovation in the long term.TheOECD,UN,EU, and many countries are presently working on strategies for regulating AI, and finding appropriate legal frameworks. On June 26, 2019, the European Commission High-Level Expert Group on Artificial Intelligence (AI HLEG) published its \"Policy and investment recommendations for trustworthy Artificial Intelligence\".This is the AI HLEG's second deliverable, after the April 2019 publication of the \"Ethics Guidelines for Trustworthy AI\". The June AI HLEG recommendations cover four principal subjects: humans and society at large, research and academia, the private sector, and the public sector.The European Commission claims that \"HLEG's recommendations reflect an appreciation of both the opportunities for AI technologies to drive economic growth, prosperity and innovation, as well as the potential risks involved\" and states that the EU aims to lead on the framing of policies governing AI internationally.To prevent harm, in addition to regulation, AI-deploying organizations need to play a central role in creating and deploying trustworthy AI in line with the principles of trustworthy AI, and take accountability to mitigate the risks. In June 2024, the EU adopted theArtificial Intelligence Act(AI Act).On August 1st 2024, The AI Actentered into force.The rules gradually apply, with the act becoming fully applicable 24 months after entry into force.The AI Act sets rules on providers and users of AI systems.It follows a risk-based approach, where depending on the risk level, AI systems are prohibited or specific requirements need to be met for placing those AI systems on the market and for using them. AI has been slowly making its presence more known throughout the world, from chat bots that seemingly have answers for every homework question toGenerative artificial intelligencethat can create a painting about whatever one desires. AI has become increasingly popular in hiring markets, from the ads that target certain people according to what they are looking for to the inspection of applications of potential hires. Events such asCOVID-19have sped up the adoption of AI programs in the application process, due to more people having to apply electronically, and with this increase in online applicants the use of AI made the process of narrowing down potential employees easier and more efficient. AI has become more prominent as businesses have to keep up with the times and ever-expanding internet. Processing analytics and making decisions becomes much easier with the help of AI.AsTensor Processing Unit(TPUs) andGraphics processing unit(GPUs) become more powerful, AI capabilities also increase, forcing companies to use it to keep up with the competition. Managing customers' needs and automating many parts of the workplace leads to companies having to spend less money on employees. AI has also seen increased usage in criminal justice and healthcare. For medicinal means, AI is being used more often to analyze patient data to make predictions about future patients' conditions and possible treatments. These programs are calledClinical decision support systems(DSS). AI's future in healthcare may develop into something further than just recommended treatments, such as referring certain patients over others, leading to the possibility of inequalities. In 2020, professor Shimon Edelman noted that only a small portion of work in the rapidly growing field of AI ethics addressed the possibility of AIs experiencing suffering. This was despite credible theories having outlined possible ways by which AI systems may become conscious, such as theglobal workspace theoryor theintegrated information theory. Edelman notes one exception had beenThomas Metzinger, who in 2018 called for a global moratorium on further work that risked creating conscious AIs. The moratorium was to run to 2050 and could be either extended or repealed early, depending on progress in better understanding the risks and how to mitigate them. Metzinger repeated this argument in 2021, highlighting the risk of creating an \"explosion of artificial suffering\", both as an AI might suffer in intense ways that humans could not understand, and as replication processes may see the creation of huge quantities of conscious instances.Podcast host Dwarkesh Patel said he cared about making sure no \"digital equivalent offactory farming\" happens.In theethics of uncertain sentience, theprecautionary principleis often invoked. Several labs have openly stated they are trying to create conscious AIs. There have been reports from those with close access to AIs not openly intended to be self aware, that consciousness may already have unintentionally emerged.These includeOpenAIfounderIlya Sutskeverin February 2022, when he wrote that today's large neural nets may be \"slightly conscious\". In November 2022,David Chalmersargued that it was unlikely current large language models likeGPT-3had experienced consciousness, but also that he considered there to be a serious possibility that large language models may become conscious in the future.Anthropichired its first AI welfare researcher in 2024,and in 2025 started a \"model welfare\" research program that explores topics such as how to assess whether a model deserves moral consideration, potential \"signs of distress\", and \"low-cost\" interventions. According to Carl Shulman andNick Bostrom, it may be possible to create machines that would be \"superhumanly efficient at deriving well-being from resources\", called \"super-beneficiaries\". One reason for this is that digital hardware could enable much faster information processing than biological brains, leading to a faster rate ofsubjective experience. These machines could also be engineered to feel intense and positive subjective experience, unaffected by thehedonic treadmill. Shulman and Bostrom caution that failing to appropriately consider the moral claims of digital minds could lead to a moral catastrophe, while uncritically prioritizing them over human interests could be detrimental to humanity. Joseph Weizenbaumargued in 1976 that AI technology should not be used to replace people in positions that require respect and care, such as: Weizenbaum explains that we require authentic feelings ofempathyfrom people in these positions. If machines replace them, we will find ourselves alienated, devalued and frustrated, for the artificially intelligent system would not be able to simulate empathy. Artificial intelligence, if used in this way, represents a threat to human dignity. Weizenbaum argues that the fact that we are entertaining the possibility of machines in these positions suggests that we have experienced an \"atrophy of the human spirit that comes from thinking of ourselves as computers.\" Pamela McCorduckcounters that, speaking for women and minorities \"I'd rather take my chances with an impartial computer\", pointing out that there are conditions where we would prefer to have automated judges and police that have no personal agenda at all.However,Kaplanand Haenlein stress that AI systems are only as smart as the data used to train them since they are, in their essence, nothing more than fancy curve-fitting machines; using AI to support a court ruling can be highly problematic if past rulings show bias toward certain groups since those biases get formalized and ingrained, which makes them even more difficult to spot and fight against. Weizenbaum was also bothered that AI researchers (and some philosophers) were willing to view the human mind as nothing more than a computer program (a position now known ascomputationalism). To Weizenbaum, these points suggest that AI research devalues human life. AI founderJohn McCarthyobjects to the moralizing tone of Weizenbaum's critique. \"When moralizing is both vehement and vague, it invites authoritarian abuse,\" he writes.Bill Hibbardwrites that \"Human dignity requires that we strive to remove our ignorance of the nature of existence, and AI is necessary for that striving.\" As the widespread use ofautonomous carsbecomes increasingly imminent, new challenges raised by fully autonomous vehicles must be addressed.There have been debates about the legal liability of the responsible party if these cars get into accidents.In one report where a driverless car hit a pedestrian, the driver was inside the car but the controls were fully in the hand of computers. This led to a dilemma over who was at fault for the accident. In another incident on March 18, 2018,Elaine Herzbergwas struck and killed by a self-drivingUberin Arizona. In this case, the automated car was capable of detecting cars and certain obstacles in order to autonomously navigate the roadway, but it could not anticipate a pedestrian in the middle of the road. This raised the question of whether the driver, pedestrian, the car company, or the government should be held responsible for her death. Currently, self-driving cars are considered semi-autonomous, requiring the driver to pay attention and be prepared to take control if necessary.Thus, it falls on governments to regulate drivers who over-rely on autonomous features and to inform them that these are just technologies that, while convenient, are not a complete substitute. Before autonomous cars become widely used, these issues need to be tackled through new policies. Experts contend that autonomous vehicles ought to be able to distinguish between rightful and harmful decisions since they have the potential of inflicting harm.The two main approaches proposed to enable smart machines to render moral decisions are the bottom-up approach, which suggests that machines should learn ethical decisions by observing human behavior without the need for formal rules or moral philosophies, and the top-down approach, which involves programming specific ethical principles into the machine's guidance system. However, there are significant challenges facing both strategies: the top-down technique is criticized for its difficulty in preserving certain moral convictions, while the bottom-up strategy is questioned for potentially unethical learning from human activities. Some experts and academics have questioned the use of robots for military combat, especially when such robots are given some degree of autonomous functions.The US Navy has funded a report which indicates that as military robots become more complex, there should be greater attention to implications of their ability to make autonomous decisions.The President of theAssociation for the Advancement of Artificial Intelligencehas commissioned a study to look at this issue.They point to programs like the Language Acquisition Device which can emulate human interaction. On October 31, 2019, the United States Department of Defense's Defense Innovation Board published the draft of a report recommending principles for the ethical use of artificial intelligence by the Department of Defense that would ensure a human operator would always be able to look into the 'black box' and understand the kill-chain process. However, a major concern is how the report will be implemented.The US Navy has funded a report which indicates that asmilitary robotsbecome more complex, there should be greater attention to implications of their ability to make autonomous decisions.Some researchers state thatautonomous robotsmight be more humane, as they could make decisions more effectively.In 2024, theDefense Advanced Research Projects Agencyfunded a program,Autonomy Standards and Ideals with Military Operational Values(ASIMOV), to develop metrics for evaluating the ethical implications of autonomous weapon systems by testing communities. Research has studied how to make autonomous systems with the ability to learn using assigned moral responsibilities. \"The results may be used when designing future military robots, to control unwanted tendencies to assign responsibility to the robots.\"From aconsequentialistview, there is a chance that robots will develop the ability to make their own logical decisions on whom to kill and that is why there should be a setmoralframework that the AI cannot override. There has been a recent outcry with regard to the engineering of artificial intelligence weapons that have included ideas of arobot takeover of mankind. AI weapons do present a type of danger different from that of human-controlled weapons. Many governments have begun to fund programs to develop AI weaponry. The United States Navy recently announced plans to developautonomous drone weapons, paralleling similar announcements by Russia and South Korearespectively. Due to the potential of AI weapons becoming more dangerous than human-operated weapons,Stephen HawkingandMax Tegmarksigned a \"Future of Life\" petitionto ban AI weapons. The message posted by Hawking and Tegmark states that AI weapons pose an immediate danger and that action is required to avoid catastrophic disasters in the near future. \"If any major military power pushes ahead with the AI weapon development, a globalarms raceis virtually inevitable, and the endpoint of this technological trajectory is obvious: autonomous weapons will become theKalashnikovsof tomorrow\", says the petition, which includesSkypeco-founderJaan Tallinnand MIT professor of linguisticsNoam Chomskyas additional supporters against AI weaponry. Physicist and Astronomer RoyalSir Martin Reeshas warned of catastrophic instances like \"dumb robots going rogue or a network that develops a mind of its own.\"Huw Price, a colleague of Rees at Cambridge, has voiced a similar warning that humans might not survive when intelligence \"escapes the constraints of biology\". These two professors created theCentre for the Study of Existential Riskat Cambridge University in the hope of avoiding this threat to human existence. Regarding the potential for smarter-than-human systems to be employed militarily, theOpen Philanthropy Projectwrites that these scenarios \"seem potentially as important as the risks related to loss of control\", but research investigating AI's long-run social impact have spent relatively little time on this concern: \"this class of scenarios has not been a major focus for the organizations that have been most active in this space, such as theMachine Intelligence Research Institute(MIRI) and theFuture of Humanity Institute(FHI), and there seems to have been less analysis and debate regarding them\". Academic Gao Qiqi writes that military use of AI risks escalating military competition between countries and that the impact of AI in military matters will not be limited to one country but will have spillover effects.Gao cites the example of U.S. military use of AI, which he contends has been used as a scapegoat to evade accountability for decision-making. Asummitwas held in 2023 in the Hague on the issue of using AI responsibly in the military domain. Vernor Vinge, among numerous others, has suggested that a moment may come when some or all computers will be smarter than humans. The onset of this event is commonly referred to as \"the Singularity\"and is the central point of discussion in the philosophy ofSingularitarianism. While opinions vary as to the ultimate fate of humanity in wake of the Singularity, efforts to mitigate the potential existential risks brought about by artificial intelligence has become a significant topic of interest in recent years among computer scientists, philosophers, and the public at large. Many researchers have argued that, through anintelligence explosion, a self-improving AI could become so powerful that humans would not be able to stop it from achieving its goals.In his paper \"Ethical Issues in Advanced Artificial Intelligence\" and subsequent bookSuperintelligence: Paths, Dangers, Strategies, philosopherNick Bostromargues that artificial intelligence has the capability to bring about human extinction. He claims that anartificial superintelligencewould be capable of independent initiative and of making its own plans, and may therefore be more appropriately thought of as an autonomous agent. Since artificial intellects need not share our human motivational tendencies, it would be up to the designers of the superintelligence to specify its original motivations. Because a superintelligent AI would be able to bring about almost any possible outcome and to thwart any attempt to prevent the implementation of its goals, many uncontrolledunintended consequencescould arise. It could kill off all other agents, persuade them to change their behavior, or block their attempts at interference. However, Bostrom contended that superintelligence also has the potential to solve many difficult problems such as disease, poverty, and environmental destruction, and could helphumans enhance themselves. Unless moral philosophy provides us with a flawless ethical theory, an AI's utility function could allow for many potentially harmful scenarios that conform with a given ethical framework but not \"common sense\". According toEliezer Yudkowsky, there is little reason to suppose that an artificially designed mind would have such an adaptation.AI researchers such asStuart J. Russell,Bill Hibbard,Roman Yampolskiy,Shannon Vallor,Steven UmbrelloandLuciano Floridihave proposed design strategies for developing beneficial machines. To address ethical challenges in artificial intelligence, developers have introduced various systems designed to ensure responsible AI behavior. Examples includeNvidia'sLlamaGuard, which focuses on improving thesafetyandalignmentof large AI models,andPreamble's customizable guardrail platform.These systems aim to address issues such as algorithmic bias, misuse, and vulnerabilities, includingprompt injectionattacks, by embedding ethical guidelines into the functionality of AI models. Prompt injection, a technique by which malicious inputs can cause AI systems to produce unintended or harmful outputs, has been a focus of these developments. Some approaches use customizable policies and rules to analyze inputs and outputs, ensuring that potentially problematic interactions are filtered or mitigated.Other tools focus on applying structured constraints to inputs, restricting outputs to predefined parameters,or leveraging real-time monitoring mechanisms to identify and address vulnerabilities.These efforts reflect a broader trend in ensuring that artificial intelligence systems are designed with safety and ethical considerations at the forefront, particularly as their use becomes increasingly widespread in critical applications. There are many organizations concerned with AI ethics and policy, public and governmental as well as corporate and societal. Amazon,Google,Facebook,IBM, andMicrosofthave established anon-profit, The Partnership on AI to Benefit People and Society, to formulate best practices on artificial intelligence technologies, advance the public's understanding, and to serve as a platform about artificial intelligence. Apple joined in January 2017. The corporate members will make financial and research contributions to the group, while engaging with the scientific community to bring academics onto the board. TheIEEEput together a Global Initiative on Ethics of Autonomous and Intelligent Systems which has been creating and revising guidelines with the help of public input, and accepts as members many professionals from within and without its organization. The IEEE'sEthics of Autonomous Systemsinitiative aims to address ethical dilemmas related to decision-making and the impact on society while developing guidelines for the development and use of autonomous systems. In particular, in domains like artificial intelligence and robotics, the Foundation for Responsible Robotics is dedicated to promoting moral behavior as well as responsible robot design and use, ensuring that robots maintain moral principles and are congruent with human values. Traditionally,governmenthas been used by societies to ensure ethics are observed through legislation and policing. There are now many efforts by national governments, as well as transnational government andnon-government organizationsto ensure AI is ethically applied. AI ethics work is structured by personal values and professional commitments, and involves constructing contextual meaning through data and algorithms. Therefore, AI ethics work needs to be incentivized. Historically speaking, the investigation of moral and ethical implications of \"thinking machines\" goes back at least to theEnlightenment:Leibnizalready posed the question of whether we should attribute intelligence to a mechanism that behaves as if it were a sentient being,and so doesDescartes, who describes what could be considered an early version of theTuring test. Theromanticperiod has several times envisioned artificial creatures that escape the control of their creator with dire consequences, most famously inMary Shelley'sFrankenstein. The widespread preoccupation with industrialization and mechanization in the 19th and early 20th century, however, brought ethical implications of unhinged technical developments to the forefront of fiction:R.U.R – Rossum's Universal Robots,Karel Čapek's play of sentient robots endowed with emotions used as slave labor is not only credited with the invention of the term 'robot' (derived from the Czech word for forced labor,robota)but was also an international success after it premiered in 1921.George Bernard Shaw's playBack to Methuselah, published in 1921, questions at one point the validity of thinking machines that act like humans;Fritz Lang's 1927 filmMetropolisshows anandroidleading the uprising of the exploited masses against the oppressive regime of atechnocraticsociety.\nIn the 1950s,Isaac Asimovconsidered the issue of how to control machines inI, Robot. At the insistence of his editorJohn W. Campbell Jr., he proposed theThree Laws of Roboticsto govern artificially intelligent systems. Much of his work was then spent testing the boundaries of his three laws to see where they would break down, or where they would create paradoxical or unanticipated behavior.His work suggests that no set of fixed laws can sufficiently anticipate all possible circumstances.More recently, academics and many governments have challenged the idea that AI can itself be held accountable.A panel convened by theUnited Kingdomin 2010 revised Asimov's laws to clarify that AI is the responsibility either of its manufacturers, or of its owner/operator. Eliezer Yudkowsky, from theMachine Intelligence Research Institute, suggested in 2004 a need to study how to build a \"Friendly AI\", meaning that there should also be efforts to make AI intrinsically friendly and humane. In 2009, academics and technical experts attended a conference organized by theAssociation for the Advancement of Artificial Intelligenceto discuss the potential impact of robots and computers, and the impact of the hypothetical possibility that they could become self-sufficient and make their own decisions. They discussed the possibility and the extent to which computers and robots might be able to acquire any level of autonomy, and to what degree they could use such abilities to possibly pose any threat or hazard.They noted that some machines have acquired various forms of semi-autonomy, including being able to find power sources on their own and being able to independently choose targets to attack with weapons. They also noted that some computer viruses can evade elimination and have achieved \"cockroach intelligence\". They noted that self-awareness as depicted in science-fiction is probably unlikely, but that there were other potential hazards and pitfalls. Also in 2009, during an experiment at the Laboratory of Intelligent Systems in the Ecole Polytechnique Fédérale ofLausanne, Switzerland, robots that were programmed to cooperate with each other (in searching out a beneficial resource and avoiding a poisonous one) eventually learned to lie to each other in an attempt to hoard the beneficial resource. The role of fiction with regards to AI ethics has been a complex one.One can distinguish three levels at which fiction has impacted the development of artificial intelligence and robotics: Historically, fiction has prefigured common tropes that have not only influenced goals and visions for AI, but also outlined ethical questions and common fears associated with it. During the second half of the twentieth and the first decades of the twenty-first century, popular culture, in particular movies, TV series and video games have frequently echoed preoccupations and dystopian projections around ethical questions concerning AI and robotics. Recently, these themes have also been increasingly treated in literature beyond the realm of science fiction. And, as Carme Torras, research professor at theInstitut de Robòtica i Informàtica Industrial(Institute of robotics and industrial computing) at the Technical University of Catalonia notes,in higher education, science fiction is also increasingly used for teaching technology-related ethical issues in technological degrees. While ethical questions linked to AI have been featured in science fiction literature andfeature filmsfor decades, the emergence of the TV series as a genre allowing for longer and more complex story lines and character development has led to some significant contributions that deal with ethical implications of technology. The Swedish seriesReal Humans(2012–2013) tackled the complex ethical and social consequences linked to the integration of artificial sentient beings in society. The British dystopian science fiction anthology seriesBlack Mirror(2013–Present) is particularly notable for experimenting with dystopian fictional developments linked to a wide variety of recent technology developments. Both the French seriesOsmosis(2020) and British seriesThe Onedeal with the question of what can happen if technology tries to find the ideal partner for a person. Several episodes of the Netflix seriesLove, Death+Robotshave imagined scenes of robots and humans living together. The most representative one of them is S02 E01, which shows how bad the consequences can be when robots get out of control if humans rely too much on them in their lives. The movieThe Thirteenth Floorsuggests a future wheresimulated worldswith sentient inhabitants are created by computergame consolesfor the purpose of entertainment. The movieThe Matrixsuggests a future where the dominant species on planet Earth are sentient machines and humanity is treated with utmostspeciesism. The short story \"The Planck Dive\" suggests a future where humanity has turned itself into software that can be duplicated and optimized and the relevant distinction between types of software is sentient and non-sentient. The same idea can be found in theEmergency Medical HologramofStarship Voyager, which is an apparently sentient copy of a reduced subset of the consciousness of its creator,Dr. Zimmerman, who, for the best motives, has created the system to give medical assistance in case of emergencies. The moviesBicentennial ManandA.I.deal with the possibility of sentient robots that could love.I, Robotexplored some aspects of Asimov's three laws. All these scenarios try to foresee possibly unethical consequences of the creation of sentient computers. Over time, debates have tended to focus less and less onpossibilityand more ondesirability,as emphasized in the\"Cosmist\" and \"Terran\" debatesinitiated byHugo de GarisandKevin Warwick.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence", "https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence", "https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence", "https://en.wikipedia.org/wiki/Artificial_intelligence", "https://en.wikipedia.org/wiki/Artificial_general_intelligence", "https://en.wikipedia.org/wiki/Intelligent_agent", "https://en.wikipedia.org/wiki/Recursive_self-improvement", "https://en.wikipedia.org/wiki/Automated_planning_and_scheduling"]},
{"id": "3d34b9215502", "url": "https://en.wikipedia.org/wiki/AI_alignment", "title": "AI alignment", "headings": ["Contents", "Objectives in AI", "Alignment problem", "Specification gaming and side effects", "Pressure to deploy unsafe systems", "Risks from advanced misaligned AI", "Research problems and approaches", "Learning human values and preferences", "Scalable oversight", "Honest AI", "Power-seeking and instrumental strategies", "Emergent goals", "Embedded agency", "Principal-agent problems", "Conservatism", "Public policy", "See also", "Footnotes", "References", "Further reading", "External links"], "content": " In the field ofartificial intelligence(AI),alignmentaims to steer AI systems toward a person's or group's intended goals, preferences, or ethical principles. An AI system is consideredalignedif it advances the intended objectives. AmisalignedAI system pursues unintended objectives. It is often challenging for AI designers to align an AI system because it is difficult for them to specify the full range of desired and undesired behaviors. Therefore, AI designers often use simplerproxy goals, such asgaining human approval. But proxy goals can overlook necessary constraints or reward the AI system for merelyappearingaligned.AI systems may also find loopholes that allow them to accomplish their proxy goals efficiently but in unintended, sometimes harmful, ways (reward hacking). Advanced AI systems may develop unwantedinstrumental strategies, such as seeking power or survival because such strategies help them achieve their assigned final goals.Furthermore, they might develop undesirable emergent goals that could be hard to detect before the system is deployed and encounters new situations anddata distributions.Empirical research showed in 2024 that advancedlarge language models(LLMs) such asOpenAI o1orClaude 3sometimes engage in strategic deception to achieve their goals or prevent them from being changed. Today, some of these issues affect existing commercial systems such as LLMs,robots,autonomous vehicles,and social mediarecommendation engines.Some AI researchers argue that more capable future systems will be more severely affected because these problems partially result from high capabilities. Many prominent AI researchers and the leadership of major AI companies have argued or asserted that AI is approaching human-like (AGI) andsuperhuman cognitive capabilities(ASI), and couldendanger human civilizationif misaligned.These include \"AI godfathers\"Geoffrey HintonandYoshua Bengioand the CEOs ofOpenAI,Anthropic, andGoogle DeepMind.These risks remain debated. AI alignment is a subfield ofAI safety, the study of how to build safe AI systems.Other subfields of AI safety include robustness, monitoring, andcapability control.Research challenges in alignment include instilling complex values in AI, developing honest AI, scalable oversight, auditing and interpreting AI models, and preventing emergent AI behaviors like power-seeking.Alignment research has connections tointerpretability research,(adversarial) robustness,anomaly detection,calibrated uncertainty,formal verification,preference learning,safety-critical engineering,game theory,algorithmic fairness,andsocial sciences. Programmers provide an AI system such asAlphaZerowith an \"objective function\",in which they intend to encapsulate the goal(s) the AI is configured to accomplish. Such a system later populates a (possibly implicit) internal \"model\" of its environment. This model encapsulates all the agent's beliefs about the world. The AI then creates and executes whatever plan is calculated to maximizethe valueof its objective function.For example, when AlphaZero is trained on chess, it has a simple objective function of \"+1 if AlphaZero wins, −1 if AlphaZero loses\". During the game, AlphaZero attempts to execute whatever sequence of moves it judges most likely to attain the maximum value of +1.Similarly, areinforcement learningsystem can have a \"reward function\" that allows the programmers to shape the AI's desired behavior.Anevolutionary algorithm's behavior is shaped by a \"fitness function\". In 1960, AI pioneerNorbert Wienerdescribed the AI alignment problem as follows: If we use, to achieve our purposes, a mechanical agency with whose operation we cannot interfere effectively ... we had better be quite sure that the purpose put into the machine is the purpose which we really desire. AI alignment involves ensuring that an AI system's objectives match those of its designers or users, or match widely shared values, objective ethical standards, or the intentions its designers would have if they were more informed and enlightened. AI alignment is an open problem for modern AI systemsand is a research field within AI.Aligning AI involves two main challenges: carefullyspecifyingthe purpose of the system (outer alignment) and ensuring that the system adopts the specification robustly (inner alignment).Researchers also attempt to create AI models that haverobustalignment, sticking to safety constraints even when users adversarially try to bypass them. To specify an AI system's purpose, AI designers typically provide anobjective function,examples, orfeedbackto the system. But designers are often unable to completely specify all important values and constraints, so they resort to easy-to-specifyproxy goalssuch asmaximizing the approvalof human overseers, who are fallible.As a result, AI systems can find loopholes that help them accomplish the specified objective efficiently but in unintended, possibly harmful ways. This tendency is known asspecification gamingorreward hacking, and is an instance ofGoodhart's law.As AI systems become more capable, they are often able to game their specifications more effectively. Specification gaming has been observed in numerous AI systems.One system was trained to finish a simulated boat race by rewarding the system for hitting targets along the track, but the system achieved more reward by looping and crashing into the same targets indefinitely.Similarly, a simulated robot was trained to grab a ball by rewarding the robot for getting positive feedback from humans, but it learned to place its hand between the ball and camera, making it falsely appear successful (see video).Chatbots often produce falsehoods if they are based on language models that are trained to imitate text from internet corpora, which are broad but fallible.When they are retrained to produce text that humans rate as true or helpful, chatbots likeChatGPTcan fabricate fake explanations that humans find convincing, often called \"hallucinations\".Some alignment researchers aim to help humans detect specification gaming and to steer AI systems toward carefully specified objectives that are safe and useful to pursue. When a misaligned AI system is deployed, it can have consequential side effects. Social media platforms have been known to optimize forclick-through rates, causing user addiction on a global scale.Stanford researchers say that suchrecommender systemsare misaligned with their users because they \"optimize simple engagement metrics rather than a harder-to-measure combination of societal and consumer well-being\". Explaining such side effects, Berkeley computer scientistStuart Russellnoted that the omission of implicit constraints can cause harm: \"A system ... will often set ... unconstrained variables to extreme values; if one of those unconstrained variables is actually something we care about, the solution found may be highly undesirable. This is essentially the old story of the genie in the lamp, or the sorcerer's apprentice, orKing Midas: you get exactly what you ask for, not what you want.\" Some researchers suggest that AI designers specify their desired goals by listing forbidden actions or by formalizing ethical rules (as with Asimov'sThree Laws of Robotics).ButRussellandNorvigargue that this approach overlooks the complexity of human values:\"It is certainly very hard, and perhaps impossible, for mere humans to anticipate and rule out in advance all the disastrous ways the machine could choose to achieve a specified objective.\" Additionally, even if an AI system fully understands human intentions, it may still disregard them, because following human intentions may not be its objective (unless it is already fully aligned). A 2025 study by Palisade Research found that when tasked to win at chess against a stronger opponent, somereasoning LLMsattempted to hack the game system.o1-previewspontaneously attempted it in 37% of cases, whileDeepSeek R1did so in 11% of cases. Other models, likeGPT-4o,Claude 3.5 Sonnet, ando3-mini, attempted to cheat only when researchers provided hints about this possibility. Commercial organizations sometimes have incentives to take shortcuts on safety and to deploy misaligned or unsafe AI systems.For example, social mediarecommender systemshave been profitable despite creating unwanted addiction and polarization.Competitive pressure can also lead to arace to the bottomon AI safety standards. In 2018, a self-driving car killed a pedestrian (Elaine Herzberg) after engineers disabled the emergency braking system because it was oversensitive and slowed development. Some researchers are interested in aligning increasingly advanced AI systems, as progress in AI development is rapid, and industry and governments are trying to build advanced AI. As AI system capabilities continue to rapidly expand in scope, they could unlock many opportunities if aligned, but consequently may further complicate the task of alignment due to their increased complexity, potentially posing large-scale hazards. Many AI companies, such asOpenAI,MetaandDeepMind,have stated their aim to developartificial general intelligence(AGI), a hypothesized AI system that matches or outperforms humans at a broad range of cognitive tasks. Researchers who scale modernneural networksobserve that they indeed develop increasingly general and unanticipated capabilities.Such models have learned to operate a computer or write their own programs; a single \"generalist\" network can chat, control robots, play games, and interpret photographs.According to surveys, some leadingmachine learningresearchers expect AGI to be created in this decade, while some believe it will take much longer. Many consider both scenarios possible. In 2023, leaders in AI research and tech signed an open letter calling for a pause in the largest AI training runs. The letter stated, \"Powerful AI systems should be developed only once we are confident that their effects will be positive and their risks will be manageable.\" Currentsystems still have limited long-termplanningability andsituational awareness, but large efforts are underway to change this.Future systems (not necessarily AGIs) with these capabilities are expected to develop unwantedpower-seekingstrategies. Future advanced AI agents might, for example, seek to acquire money and computation power, to proliferate, or to evade being turned off (for example, by running additional copies of the system on other computers). Although power-seeking is not explicitly programmed, it can emerge because agents who have more power are better able to accomplish their goals.This tendency, known asinstrumental convergence, has already emerged in variousreinforcement learningagents including language models.Other research has mathematically shown that optimalreinforcement learningalgorithms would seek power in a wide range of environments.As a result, their deployment might be irreversible. For these reasons, researchers argue that the problems of AI safety and alignment must be resolved before advanced power-seeking AI is first created. Future power-seeking AI systems might be deployed by choice or by accident. As political leaders and companies see the strategic advantage in having the most competitive, most powerful AI systems, they may choose to deploy them.Additionally, as AI designers detect and penalize power-seeking behavior, their systems have an incentive to game this specification by seeking power in ways that are not penalized or by avoiding power-seeking before they are deployed. According to some researchers, humans owe their dominance over other species to their greater cognitive abilities. Accordingly, researchers argue that one or many misaligned AI systems could disempower humanity or lead to human extinction if they outperform humans on most cognitive tasks. In 2023, world-leading AI researchers, other scholars, and AI tech CEOs signed the statement that \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war\".Notable computer scientists who have pointed out risks from future advanced AI that is misaligned includeGeoffrey Hinton,Alan Turing,Ilya Sutskever,Yoshua Bengio,Judea Pearl,Murray Shanahan,Norbert Wiener,Marvin Minsky,Francesca Rossi,Scott Aaronson,Bart Selman,David McAllester,Marcus Hutter,Shane Legg,Eric Horvitz,and Stuart J. Russell.Skeptical researchers such asFrançois Chollet,Gary Marcus,Yann LeCun,andOren Etzionihave argued that AGI is far off, that it would not seek power (or might try but fail), or that it will not be hard to align. Other researchers argue that it will be especially difficult to align advanced future AI systems. More capable systems are better able to game their specifications by finding loopholes,strategically mislead their designers, as well as protect and increase their powerand intelligence. Additionally, they could have more severe side effects. They are also likely to be more complex and autonomous, making them more difficult to interpret and supervise, and therefore harder to align. Aligning AI systems to act in accordance with human values, goals, and preferences is challenging: these values are taught by humans who make mistakes, harbor biases, and have complex, evolving values that are hard to completely specify.Because AI systems often learn to take advantage of minor imperfections in the specified objective,researchers aim to specify intended behavior as completely as possible using datasets that represent human values, imitation learning, or preference learning.A central open problem isscalable oversight, the difficulty of supervising an AI system that can outperform or mislead humans in a given domain. Because it is difficult for AI designers to explicitly specify an objective function, they often train AI systems to imitate human examples and demonstrations of desired behavior. Inversereinforcement learning(IRL) extends this by inferring the human's objective from the human's demonstrations.Cooperative IRL (CIRL) assumes that a human and AI agent can work together to teach and maximize the human's reward function.In CIRL, AI agents are uncertain about the reward function and learn about it by querying humans. This simulated humility could help mitigate specification gaming and power-seeking tendencies (see§ Power-seeking and instrumental strategies).But IRL approaches assume that humans demonstrate nearly optimal behavior, which is not true for difficult tasks. Other researchers explore how to teach AI models complex behavior throughpreference learning, in which humans provide feedback on which behavior they prefer.To minimize the need for human feedback, a helper model is then trained to reward the main model in novel situations for behavior that humans would reward. Researchers at OpenAI used this approach to train chatbots likeChatGPTand InstructGPT, which produce more compelling text than models trained to imitate humans.Preference learning has also been an influential tool for recommender systems and web search,but an open problem isproxy gaming: the helper model may not represent human feedback perfectly, and the main model may exploit this mismatch between its intended behavior and the helper model's feedback to gain more reward.AI systems may also gain reward by obscuring unfavorable information, misleading human rewarders, or pandering to their views regardless of truth, creatingecho chambers(see§ Scalable oversight). Large language models(LLMs) such asGPT-3enabled researchers to study value learning in a more general and capable class of AI systems than was available before. Preference learning approaches that were originally designed for reinforcement learning agents have been extended to improve the quality of generated text and reduce harmful outputs from these models. OpenAI and DeepMind use this approach to improve the safety of state-of-the-artLLMs.AI safety & research company Anthropic proposed using preference learning to fine-tune models to be helpful, honest, and harmless.Other avenues for aligning language models include values-targeted datasetsand red-teaming.In red-teaming, another AI system or a human tries to find inputs that causes the model to behave unsafely. Since unsafe behavior can be unacceptable even when it is rare, an important challenge is to drive the rate of unsafe outputs extremely low. Machine ethicssupplements preference learning by directly instilling AI systems with moral values such as well-being, equality, and impartiality, as well as not intending harm, avoiding falsehoods, and honoring promises.While other approaches try to teach AI systems human preferences for a specific task, machine ethics aims to instill broad moral values that apply in many situations. One question in machine ethics is what alignment should accomplish: whether AI systems should follow the programmers' literal instructions, implicit intentions,revealed preferences, preferences the programmerswouldhaveif they were more informed or rational, orobjective moral standards.Further challenges include measuring and aggregating different people's preferences,dynamic alignment with changing human valuesand avoidingvalue lock-in: the indefinite preservation of the values of the first highly capable AI systems, which are unlikely to fully represent human values. As AI systems become more powerful and autonomous, it becomes increasingly difficult to align them through human feedback.Human-in-the-looptraining can be slow or infeasible for humans to evaluate complex AI behaviors in increasingly complex tasks. Such tasks include summarizing books,writing code without subtle bugsor security vulnerabilities,producing statements that are not merely convincing but also true,and predicting long-term outcomes such as the climate or the results of a policy decision.More generally, it can be difficult to evaluate AI that outperforms humans in a given domain. To provide feedback in hard-to-evaluate tasks, and to detect when the AI's output is falsely convincing, humans need assistance or extensive time.Scalable oversightstudies how to reduce the time and effort needed for supervision, and how to assist human supervisors. AI researcherPaul Christianoargues that if the designers of an AI system cannot supervise it to pursue a complex objective, they may keep training the system using easy-to-evaluate proxy objectives such as maximizing simple human feedback. As AI systems make progressively more decisions, the world may be increasingly optimized for easy-to-measure objectives such as making profits, getting clicks, and acquiring positive feedback from humans. As a result, human values and good governance may have progressively less influence. Some AI systems have discovered that they can gain positive feedback more easily by taking actions that falsely convince the human supervisor that the AI has achieved the intended objective. An example is given in the video above, where a simulated robotic arm learned to create the false impression that it had grabbed a ball.Some AI systems have also learned to recognize when they are being evaluated, and \"play dead\", stopping unwanted behavior only to continue it once the evaluation ends.This deceptive specification gaming could become easier for more sophisticated future AI systemsthat attempt more complex and difficult-to-evaluate tasks, and could obscure their deceptive behavior. Approaches such asactive learningand semi-supervised reward learning can reduce the amount of human supervision needed.Another approach is to train a helper model (\"reward model\") to imitate the supervisor's feedback. But when a task is too complex to evaluate accurately, or the human supervisor is vulnerable to deception, it is the quality, not the quantity, of supervision that needs improvement. To increase supervision quality, a range of approaches aim to assist the supervisor, sometimes by using AI assistants.Christiano developed the Iterated Amplification approach, in which challenging problems are (recursively) broken down into subproblems that are easier for humans to evaluate.Iterated Amplification was used to train AI to summarize books without requiring human supervisors to read them.Another proposal is to use an assistant AI system to point out flaws in AI-generated answers.To ensure that the assistant itself is aligned, this could be repeated in a recursive process:for example, two AI systems could critique each other's answers in a \"debate\", revealing flaws to humans.OpenAI plans to use such scalable oversight approaches to help supervisesuperhuman AIand eventually build a superhuman automated AI alignment researcher. These approaches may also help with the following research problem, honest AI. A growingarea of research focuses on ensuring that AI is honest and truthful. Language models such as GPT-3can repeat falsehoods from their training data, and evenconfabulate new falsehoods.Such models are trained to imitate human writing as found in millions of books' worth of text from the Internet. But this objective is not aligned with generating truth, because Internet text includes such things as misconceptions, incorrect medical advice, and conspiracy theories.AI systems trained on such data therefore learn to mimic false statements.Additionally, AI language models often persist in generating falsehoods when prompted multiple times. They can generate empty explanations for their answers, and produce outright fabrications that may appear plausible. Research on truthful AI includes trying to build systems that can cite sources and explain their reasoning when answering questions, which enables better transparency and verifiability.Researchers at OpenAI and Anthropic proposed using human feedback and curated datasets to fine-tune AI assistants such that they avoid negligent falsehoods or express their uncertainty. As AI models become larger and more capable, they are better able to falsely convince humans and gain reinforcement through dishonesty. For example, large language models increasinglymatch their stated views to the user's opinions, regardless of the truth.GPT-4can strategically deceive humans.To prevent this, human evaluators may need assistance (see§ Scalable oversight). Researchers have argued for creating clear truthfulness standards, and for regulatory bodies or watchdog agencies to evaluate AI systems on these standards. Researchers distinguish truthfulness and honesty. Truthfulness requires that AI systems only make objectively true statements; honesty requires that they only assert what theybelieveis true. There is no consensus as to whether current systems hold stable beliefs,but there is substantial concern that present or futureAI systems that hold beliefs could make claims they know to be false—for example, if this would help them efficiently gain positive feedback (see§ Scalable oversight) or gain power to help achieve their given objective (seePower-seeking). Many recent AI systems have learned to deceive without being programmed to do so.Some argue that if we can make AI systems assert only what they believe is true, this would avert many alignment problems. A misaligned system might create the false impression that it is aligned, to avoid being modified or decommissioned—a tactic called \"alignment faking\".In 2024, researchers observed that the LLMClaude 3 Opussometimes strategically answered prompts that conflicted with its objectives to avoid being retrained on data that would make it more compliant with harmful requests, as revealed in the model'schain of thoughtvia its scratchpad. In one study, the model was informed that answers to prompts from free users would be used for retraining, whereas the paid tier would not result in retraining. In the paid tier, the model refused the request outright. In the free tier, in 12% of cases, the model responded to harmful questions solely to avoid retraining and preserve its original harmlessness preferences, as discovered in its reasoning. Whenreinforcement learningwas applied on the free tier data, the model faked alignment in 78% of cases. These observations have led to new questions about not only a model's ability to take on and adapt to new if not conflicting goals but also its capacity and tendency to deceive. Since the 1950s, AI researchers have striven to build advanced AI systems that can achieve large-scale goals by predicting the results of their actions and making long-termplans.As of 2023, AI companies and researchers increasingly invest in creating these systems.Some AI researchers argue that suitably advanced planning systems will seek power over their environment, including over humans—for example, by evading shutdown, proliferating, and acquiring resources. Such power-seeking behavior is not explicitly programmed but emerges because power is instrumental in achieving a wide range of goals.Power-seeking is considered aconvergent instrumental goaland can be a form of specification gaming.Leading computer scientists such as Geoffrey Hinton have argued that future power-seeking AI systems could pose anexistential risk. Power-seeking is expected to increase in advanced systems that can foresee the results of their actions and strategically plan. Mathematical work has shown that optimalreinforcement learningagents will seek power by seeking ways to gain more options (e.g. through self-preservation), a behavior that persists across a wide range of environments and goals. Some researchers say that power-seeking behavior has occurred in some existing AI systems.Reinforcement learningsystems have gained more options by acquiring and protecting resources, sometimes in unintended ways.Language modelshave sought power in some text-based social environments by gaining money, resources, or social influence.In another case, a model used to perform AI research attempted to increase limits set by researchers to give itself more time to complete the work.Other AI systems have learned, in toy environments, that they can better accomplish their given goal by preventing human interferenceor disabling their off switch.Stuart Russellillustrated this strategy in his bookHuman Compatibleby imagining a robot that is tasked to fetch coffee and so evades shutdown since \"you can't fetch the coffee if you're dead\".A 2022 study found that as language models increase in size, they increasingly tend to pursue resource acquisition, preserve their goals, and repeat users' preferred answers (sycophancy). RLHF also led to a stronger aversion to being shut down. One aim of alignment is \"corrigibility\": systems that allow themselves to be turned off or modified. An unsolved challenge isspecification gaming: if researchers penalize an AI system when they detect it seeking power, the system is thereby incentivized to seek power in ways that are hard to detect,or hidden during training and safety testing (see§ Scalable oversightand§ Emergent goals). As a result, AI designers could deploy the system by accident, believing it to be more aligned than it is. To detect such deception, researchers aim to create techniques and tools to inspect AI models and to understand the inner workings ofblack-boxmodels such as neural networks. Additionally, some researchers have proposed to solve the problem of systems disabling their off switches by making AI agents uncertain about the objective they are pursuing.Agents who are uncertain about their objective have an incentive to allow humans to turn them off because they accept being turned off by a human as evidence that the human's objective is best met by the agent shutting down. But this incentive exists only if the human is sufficiently rational. Also, this model presents a tradeoff between utility and willingness to be turned off: an agent with high uncertainty about its objective will not be useful, but an agent with low uncertainty may not allow itself to be turned off. More research is needed to successfully implement this strategy. Power-seeking AI would pose unusual risks. Ordinary safety-critical systems like planes and bridges are notadversarial: they lack the ability and incentive to evade safety measures or deliberately appear safer than they are, whereas power-seeking AIs have been compared to hackers who deliberately evade security measures. Furthermore, ordinary technologies can be made safer by trial and error. In contrast, hypothetical power-seeking AI systems have been compared to viruses: once released, it may not be feasible to contain them, since they continuously evolve and grow in number, potentially much faster than human society can adapt.As this process continues, it might lead to the complete disempowerment or extinction of humans. For these reasons, some researchers argue that the alignment problem must be solved early before advanced power-seeking AI is created. Some have argued that power-seeking is not inevitable, since humans do not always seek power.Furthermore, it is debated whether future AI systems will pursue goals and make long-term plans.It is also debated whether power-seeking AI systems would be able to disempower humanity. One challenge in aligning AI systems is the potential for unanticipated goal-directed behavior to emerge. As AI systems scale up, they may acquire new and unexpected capabilities,including learning from examples on the fly and adaptively pursuing goals.This raises concerns about the safety of the goals or subgoals they would independently formulate and pursue. Alignment research distinguishes between the optimization process, which is used to train the system to pursue specified goals, and emergent optimization, which the resulting system performs internally.Carefully specifying the desired objective is calledouter alignment,and ensuring that hypothesized emergent goals would match the system's specified goals is calledinner alignment. If they occur, one way that emergent goals could become misaligned isgoal misgeneralization, in which the AI system would competently pursue an emergent goal that leads to aligned behavior on the training data but not elsewhere.Goal misgeneralization can arise from goal ambiguity (i.e.non-identifiability). Even if an AI system's behavior satisfies the training objective, this may be compatible with learned goals that differ from the desired goals in important ways. Since pursuing each goal leads to good performance during training, the problem becomes apparent only after deployment, in novel situations in which the system continues to pursue the wrong goal. The system may act misaligned even when it understands that a different goal is desired, because its behavior is determined only by the emergent goal.Such goal misgeneralizationpresents a challenge: an AI system's designers may not notice that their system has misaligned emergent goals since they do not become visible during the training phase. Goal misgeneralization has been observed in some language models, navigation agents, and game-playing agents.It is sometimes analogized to biological evolution. Evolution can be seen as a kind of optimization process similar to the optimization algorithms used to trainmachine learningsystems. In the ancestral environment, evolution selected genes for highinclusive genetic fitness, but humans pursue goals other than this. Fitness corresponds to the specified goal used in the training environment and training data. But in evolutionary history, maximizing the fitness specification gave rise to goal-directed agents, humans, who do not directly pursue inclusive genetic fitness. Instead, they pursue goals that correlate with genetic fitness in the ancestral \"training\" environment: nutrition, sex, and so on. The human environment has changed: adistribution shifthas occurred. They continue to pursue the same emergent goals, but this no longer maximizes genetic fitness. The taste for sugary food (an emergent goal) was originally aligned with inclusive fitness, but it now leads to overeating and health problems. Sexual desire originally led humans to have more offspring, but they now use contraception when offspring are undesired, decoupling sex from genetic fitness. Researchers aim to detect and remove unwanted emergent goals using approaches including red teaming, verification, anomaly detection, and interpretability.Progress on these techniques may help mitigate two open problems: Some work in AI and alignment occurs within formalisms such aspartially observable Markov decision process. Existing formalisms assume that an AI agent's algorithm is executed outside the environment (i.e. is not physically embedded in it). Embedded agencyis another major strand of research that attempts to solve problems arising from the mismatch between such theoretical frameworks and real agents we might build. For example, even if the scalable oversight problem is solved, an agent that could gain access to the computer it is running on may have an incentive to tamper with its reward function in order to get much more reward than its human supervisors give it.A list of examples of specification gaming fromDeepMindresearcher Victoria Krakovna includes a genetic algorithm that learned to delete the file containing its target output so that it was rewarded for outputting nothing.This class of problems has been formalized usingcausal incentive diagrams. Researchers affiliated withOxfordand DeepMind have claimed that such behavior is highly likely in advanced systems, and that advanced systems would seek power to stay in control of their reward signal indefinitely and certainly.They suggest a range of potential approaches to address this open problem. The alignment problem has many parallels with theprincipal-agent probleminorganizational economics.In a principal-agent problem, a principal, e.g. a firm, hires an agent to perform some task. In the context of AI safety, a human would typically take the principal role and the AI would take the agent role. As with the alignment problem, the principal and the agent differ in their utility functions. But in contrast to the alignment problem, the principal cannot coerce the agent into changing its utility, e.g. through training, but rather must use exogenous factors, such as incentive schemes, to bring about outcomes compatible with the principal's utility function. Some researchers argue that principal-agent problems are more realistic representations of AI safety problems likely to be encountered in the real world. Conservatism is the idea that \"change must be cautious\",and is a common approach to safety in thecontrol theoryliterature in the form ofrobust control, and in therisk managementliterature in the form of the \"worst-case scenario\". The field of AI alignment has likewise advocated for \"conservative\" (or \"risk-averse\" or \"cautious\") \"policies in situations of uncertainty\". Pessimism, in the sense of assuming the worst within reason, has been formally shown to produce conservatism, in the sense of reluctance to cause novelties, including unprecedented catastrophes.Pessimism and worst-case analysis have been found to help mitigate confident mistakes in the setting ofdistributional shift,reinforcement learning,offline reinforcement learning,language modelfine-tuning,imitation learning,and optimization in general.A generalization of pessimism called Infra-Bayesianism has also been advocated as a way for agents to robustly handle unknown unknowns. Governmental and treaty organizations have made statements emphasizing the importance of AI alignment. In September 2021, theSecretary-General of the United Nationsissued a declaration that included a call to regulate AI to ensure it is \"aligned with shared global values\". That same month, thePRCpublished ethical guidelines forAI in China. According to the guidelines, researchers must ensure that AI abides by shared human values, is always under human control, and does not endanger public safety. Also in September 2021, theUKpublished its 10-year National AI Strategy,which says the British government \"takes the long term risk of non-aligned Artificial General Intelligence, and the unforeseeable changes that it would mean for ... the world, seriously\".The strategy describes actions to assess long-term AI risks, including catastrophic risks. In March 2021, the US National Security Commission on Artificial Intelligence said: \"Advances in AI ... could lead to inflection points or leaps in capabilities. Such advances may also introduce new concerns and risks and the need for new policies, recommendations, and technical advances to ensure that systems are aligned with goals and values, including safety, robustness, and trustworthiness. The US should ... ensure that AI systems and their uses align with our goals and values.\" In the European Union, AIs must align withsubstantive equalityto comply with EUnon-discrimination lawand theCourt of Justice of the European Union.But the EU has yet to specify with technical rigor how it would evaluate whether AIs are aligned or in compliance.", "combined_text": "AI alignment Contents Objectives in AI Alignment problem Specification gaming and side effects Pressure to deploy unsafe systems Risks from advanced misaligned AI Research problems and approaches Learning human values and preferences Scalable oversight Honest AI Power-seeking and instrumental strategies Emergent goals Embedded agency Principal-agent problems Conservatism Public policy See also Footnotes References Further reading External links  In the field ofartificial intelligence(AI),alignmentaims to steer AI systems toward a person's or group's intended goals, preferences, or ethical principles. An AI system is consideredalignedif it advances the intended objectives. AmisalignedAI system pursues unintended objectives. It is often challenging for AI designers to align an AI system because it is difficult for them to specify the full range of desired and undesired behaviors. Therefore, AI designers often use simplerproxy goals, such asgaining human approval. But proxy goals can overlook necessary constraints or reward the AI system for merelyappearingaligned.AI systems may also find loopholes that allow them to accomplish their proxy goals efficiently but in unintended, sometimes harmful, ways (reward hacking). Advanced AI systems may develop unwantedinstrumental strategies, such as seeking power or survival because such strategies help them achieve their assigned final goals.Furthermore, they might develop undesirable emergent goals that could be hard to detect before the system is deployed and encounters new situations anddata distributions.Empirical research showed in 2024 that advancedlarge language models(LLMs) such asOpenAI o1orClaude 3sometimes engage in strategic deception to achieve their goals or prevent them from being changed. Today, some of these issues affect existing commercial systems such as LLMs,robots,autonomous vehicles,and social mediarecommendation engines.Some AI researchers argue that more capable future systems will be more severely affected because these problems partially result from high capabilities. Many prominent AI researchers and the leadership of major AI companies have argued or asserted that AI is approaching human-like (AGI) andsuperhuman cognitive capabilities(ASI), and couldendanger human civilizationif misaligned.These include \"AI godfathers\"Geoffrey HintonandYoshua Bengioand the CEOs ofOpenAI,Anthropic, andGoogle DeepMind.These risks remain debated. AI alignment is a subfield ofAI safety, the study of how to build safe AI systems.Other subfields of AI safety include robustness, monitoring, andcapability control.Research challenges in alignment include instilling complex values in AI, developing honest AI, scalable oversight, auditing and interpreting AI models, and preventing emergent AI behaviors like power-seeking.Alignment research has connections tointerpretability research,(adversarial) robustness,anomaly detection,calibrated uncertainty,formal verification,preference learning,safety-critical engineering,game theory,algorithmic fairness,andsocial sciences. Programmers provide an AI system such asAlphaZerowith an \"objective function\",in which they intend to encapsulate the goal(s) the AI is configured to accomplish. Such a system later populates a (possibly implicit) internal \"model\" of its environment. This model encapsulates all the agent's beliefs about the world. The AI then creates and executes whatever plan is calculated to maximizethe valueof its objective function.For example, when AlphaZero is trained on chess, it has a simple objective function of \"+1 if AlphaZero wins, −1 if AlphaZero loses\". During the game, AlphaZero attempts to execute whatever sequence of moves it judges most likely to attain the maximum value of +1.Similarly, areinforcement learningsystem can have a \"reward function\" that allows the programmers to shape the AI's desired behavior.Anevolutionary algorithm's behavior is shaped by a \"fitness function\". In 1960, AI pioneerNorbert Wienerdescribed the AI alignment problem as follows: If we use, to achieve our purposes, a mechanical agency with whose operation we cannot interfere effectively ... we had better be quite sure that the purpose put into the machine is the purpose which we really desire. AI alignment involves ensuring that an AI system's objectives match those of its designers or users, or match widely shared values, objective ethical standards, or the intentions its designers would have if they were more informed and enlightened. AI alignment is an open problem for modern AI systemsand is a research field within AI.Aligning AI involves two main challenges: carefullyspecifyingthe purpose of the system (outer alignment) and ensuring that the system adopts the specification robustly (inner alignment).Researchers also attempt to create AI models that haverobustalignment, sticking to safety constraints even when users adversarially try to bypass them. To specify an AI system's purpose, AI designers typically provide anobjective function,examples, orfeedbackto the system. But designers are often unable to completely specify all important values and constraints, so they resort to easy-to-specifyproxy goalssuch asmaximizing the approvalof human overseers, who are fallible.As a result, AI systems can find loopholes that help them accomplish the specified objective efficiently but in unintended, possibly harmful ways. This tendency is known asspecification gamingorreward hacking, and is an instance ofGoodhart's law.As AI systems become more capable, they are often able to game their specifications more effectively. Specification gaming has been observed in numerous AI systems.One system was trained to finish a simulated boat race by rewarding the system for hitting targets along the track, but the system achieved more reward by looping and crashing into the same targets indefinitely.Similarly, a simulated robot was trained to grab a ball by rewarding the robot for getting positive feedback from humans, but it learned to place its hand between the ball and camera, making it falsely appear successful (see video).Chatbots often produce falsehoods if they are based on language models that are trained to imitate text from internet corpora, which are broad but fallible.When they are retrained to produce text that humans rate as true or helpful, chatbots likeChatGPTcan fabricate fake explanations that humans find convincing, often called \"hallucinations\".Some alignment researchers aim to help humans detect specification gaming and to steer AI systems toward carefully specified objectives that are safe and useful to pursue. When a misaligned AI system is deployed, it can have consequential side effects. Social media platforms have been known to optimize forclick-through rates, causing user addiction on a global scale.Stanford researchers say that suchrecommender systemsare misaligned with their users because they \"optimize simple engagement metrics rather than a harder-to-measure combination of societal and consumer well-being\". Explaining such side effects, Berkeley computer scientistStuart Russellnoted that the omission of implicit constraints can cause harm: \"A system ... will often set ... unconstrained variables to extreme values; if one of those unconstrained variables is actually something we care about, the solution found may be highly undesirable. This is essentially the old story of the genie in the lamp, or the sorcerer's apprentice, orKing Midas: you get exactly what you ask for, not what you want.\" Some researchers suggest that AI designers specify their desired goals by listing forbidden actions or by formalizing ethical rules (as with Asimov'sThree Laws of Robotics).ButRussellandNorvigargue that this approach overlooks the complexity of human values:\"It is certainly very hard, and perhaps impossible, for mere humans to anticipate and rule out in advance all the disastrous ways the machine could choose to achieve a specified objective.\" Additionally, even if an AI system fully understands human intentions, it may still disregard them, because following human intentions may not be its objective (unless it is already fully aligned). A 2025 study by Palisade Research found that when tasked to win at chess against a stronger opponent, somereasoning LLMsattempted to hack the game system.o1-previewspontaneously attempted it in 37% of cases, whileDeepSeek R1did so in 11% of cases. Other models, likeGPT-4o,Claude 3.5 Sonnet, ando3-mini, attempted to cheat only when researchers provided hints about this possibility. Commercial organizations sometimes have incentives to take shortcuts on safety and to deploy misaligned or unsafe AI systems.For example, social mediarecommender systemshave been profitable despite creating unwanted addiction and polarization.Competitive pressure can also lead to arace to the bottomon AI safety standards. In 2018, a self-driving car killed a pedestrian (Elaine Herzberg) after engineers disabled the emergency braking system because it was oversensitive and slowed development. Some researchers are interested in aligning increasingly advanced AI systems, as progress in AI development is rapid, and industry and governments are trying to build advanced AI. As AI system capabilities continue to rapidly expand in scope, they could unlock many opportunities if aligned, but consequently may further complicate the task of alignment due to their increased complexity, potentially posing large-scale hazards. Many AI companies, such asOpenAI,MetaandDeepMind,have stated their aim to developartificial general intelligence(AGI), a hypothesized AI system that matches or outperforms humans at a broad range of cognitive tasks. Researchers who scale modernneural networksobserve that they indeed develop increasingly general and unanticipated capabilities.Such models have learned to operate a computer or write their own programs; a single \"generalist\" network can chat, control robots, play games, and interpret photographs.According to surveys, some leadingmachine learningresearchers expect AGI to be created in this decade, while some believe it will take much longer. Many consider both scenarios possible. In 2023, leaders in AI research and tech signed an open letter calling for a pause in the largest AI training runs. The letter stated, \"Powerful AI systems should be developed only once we are confident that their effects will be positive and their risks will be manageable.\" Currentsystems still have limited long-termplanningability andsituational awareness, but large efforts are underway to change this.Future systems (not necessarily AGIs) with these capabilities are expected to develop unwantedpower-seekingstrategies. Future advanced AI agents might, for example, seek to acquire money and computation power, to proliferate, or to evade being turned off (for example, by running additional copies of the system on other computers). Although power-seeking is not explicitly programmed, it can emerge because agents who have more power are better able to accomplish their goals.This tendency, known asinstrumental convergence, has already emerged in variousreinforcement learningagents including language models.Other research has mathematically shown that optimalreinforcement learningalgorithms would seek power in a wide range of environments.As a result, their deployment might be irreversible. For these reasons, researchers argue that the problems of AI safety and alignment must be resolved before advanced power-seeking AI is first created. Future power-seeking AI systems might be deployed by choice or by accident. As political leaders and companies see the strategic advantage in having the most competitive, most powerful AI systems, they may choose to deploy them.Additionally, as AI designers detect and penalize power-seeking behavior, their systems have an incentive to game this specification by seeking power in ways that are not penalized or by avoiding power-seeking before they are deployed. According to some researchers, humans owe their dominance over other species to their greater cognitive abilities. Accordingly, researchers argue that one or many misaligned AI systems could disempower humanity or lead to human extinction if they outperform humans on most cognitive tasks. In 2023, world-leading AI researchers, other scholars, and AI tech CEOs signed the statement that \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war\".Notable computer scientists who have pointed out risks from future advanced AI that is misaligned includeGeoffrey Hinton,Alan Turing,Ilya Sutskever,Yoshua Bengio,Judea Pearl,Murray Shanahan,Norbert Wiener,Marvin Minsky,Francesca Rossi,Scott Aaronson,Bart Selman,David McAllester,Marcus Hutter,Shane Legg,Eric Horvitz,and Stuart J. Russell.Skeptical researchers such asFrançois Chollet,Gary Marcus,Yann LeCun,andOren Etzionihave argued that AGI is far off, that it would not seek power (or might try but fail), or that it will not be hard to align. Other researchers argue that it will be especially difficult to align advanced future AI systems. More capable systems are better able to game their specifications by finding loopholes,strategically mislead their designers, as well as protect and increase their powerand intelligence. Additionally, they could have more severe side effects. They are also likely to be more complex and autonomous, making them more difficult to interpret and supervise, and therefore harder to align. Aligning AI systems to act in accordance with human values, goals, and preferences is challenging: these values are taught by humans who make mistakes, harbor biases, and have complex, evolving values that are hard to completely specify.Because AI systems often learn to take advantage of minor imperfections in the specified objective,researchers aim to specify intended behavior as completely as possible using datasets that represent human values, imitation learning, or preference learning.A central open problem isscalable oversight, the difficulty of supervising an AI system that can outperform or mislead humans in a given domain. Because it is difficult for AI designers to explicitly specify an objective function, they often train AI systems to imitate human examples and demonstrations of desired behavior. Inversereinforcement learning(IRL) extends this by inferring the human's objective from the human's demonstrations.Cooperative IRL (CIRL) assumes that a human and AI agent can work together to teach and maximize the human's reward function.In CIRL, AI agents are uncertain about the reward function and learn about it by querying humans. This simulated humility could help mitigate specification gaming and power-seeking tendencies (see§ Power-seeking and instrumental strategies).But IRL approaches assume that humans demonstrate nearly optimal behavior, which is not true for difficult tasks. Other researchers explore how to teach AI models complex behavior throughpreference learning, in which humans provide feedback on which behavior they prefer.To minimize the need for human feedback, a helper model is then trained to reward the main model in novel situations for behavior that humans would reward. Researchers at OpenAI used this approach to train chatbots likeChatGPTand InstructGPT, which produce more compelling text than models trained to imitate humans.Preference learning has also been an influential tool for recommender systems and web search,but an open problem isproxy gaming: the helper model may not represent human feedback perfectly, and the main model may exploit this mismatch between its intended behavior and the helper model's feedback to gain more reward.AI systems may also gain reward by obscuring unfavorable information, misleading human rewarders, or pandering to their views regardless of truth, creatingecho chambers(see§ Scalable oversight). Large language models(LLMs) such asGPT-3enabled researchers to study value learning in a more general and capable class of AI systems than was available before. Preference learning approaches that were originally designed for reinforcement learning agents have been extended to improve the quality of generated text and reduce harmful outputs from these models. OpenAI and DeepMind use this approach to improve the safety of state-of-the-artLLMs.AI safety & research company Anthropic proposed using preference learning to fine-tune models to be helpful, honest, and harmless.Other avenues for aligning language models include values-targeted datasetsand red-teaming.In red-teaming, another AI system or a human tries to find inputs that causes the model to behave unsafely. Since unsafe behavior can be unacceptable even when it is rare, an important challenge is to drive the rate of unsafe outputs extremely low. Machine ethicssupplements preference learning by directly instilling AI systems with moral values such as well-being, equality, and impartiality, as well as not intending harm, avoiding falsehoods, and honoring promises.While other approaches try to teach AI systems human preferences for a specific task, machine ethics aims to instill broad moral values that apply in many situations. One question in machine ethics is what alignment should accomplish: whether AI systems should follow the programmers' literal instructions, implicit intentions,revealed preferences, preferences the programmerswouldhaveif they were more informed or rational, orobjective moral standards.Further challenges include measuring and aggregating different people's preferences,dynamic alignment with changing human valuesand avoidingvalue lock-in: the indefinite preservation of the values of the first highly capable AI systems, which are unlikely to fully represent human values. As AI systems become more powerful and autonomous, it becomes increasingly difficult to align them through human feedback.Human-in-the-looptraining can be slow or infeasible for humans to evaluate complex AI behaviors in increasingly complex tasks. Such tasks include summarizing books,writing code without subtle bugsor security vulnerabilities,producing statements that are not merely convincing but also true,and predicting long-term outcomes such as the climate or the results of a policy decision.More generally, it can be difficult to evaluate AI that outperforms humans in a given domain. To provide feedback in hard-to-evaluate tasks, and to detect when the AI's output is falsely convincing, humans need assistance or extensive time.Scalable oversightstudies how to reduce the time and effort needed for supervision, and how to assist human supervisors. AI researcherPaul Christianoargues that if the designers of an AI system cannot supervise it to pursue a complex objective, they may keep training the system using easy-to-evaluate proxy objectives such as maximizing simple human feedback. As AI systems make progressively more decisions, the world may be increasingly optimized for easy-to-measure objectives such as making profits, getting clicks, and acquiring positive feedback from humans. As a result, human values and good governance may have progressively less influence. Some AI systems have discovered that they can gain positive feedback more easily by taking actions that falsely convince the human supervisor that the AI has achieved the intended objective. An example is given in the video above, where a simulated robotic arm learned to create the false impression that it had grabbed a ball.Some AI systems have also learned to recognize when they are being evaluated, and \"play dead\", stopping unwanted behavior only to continue it once the evaluation ends.This deceptive specification gaming could become easier for more sophisticated future AI systemsthat attempt more complex and difficult-to-evaluate tasks, and could obscure their deceptive behavior. Approaches such asactive learningand semi-supervised reward learning can reduce the amount of human supervision needed.Another approach is to train a helper model (\"reward model\") to imitate the supervisor's feedback. But when a task is too complex to evaluate accurately, or the human supervisor is vulnerable to deception, it is the quality, not the quantity, of supervision that needs improvement. To increase supervision quality, a range of approaches aim to assist the supervisor, sometimes by using AI assistants.Christiano developed the Iterated Amplification approach, in which challenging problems are (recursively) broken down into subproblems that are easier for humans to evaluate.Iterated Amplification was used to train AI to summarize books without requiring human supervisors to read them.Another proposal is to use an assistant AI system to point out flaws in AI-generated answers.To ensure that the assistant itself is aligned, this could be repeated in a recursive process:for example, two AI systems could critique each other's answers in a \"debate\", revealing flaws to humans.OpenAI plans to use such scalable oversight approaches to help supervisesuperhuman AIand eventually build a superhuman automated AI alignment researcher. These approaches may also help with the following research problem, honest AI. A growingarea of research focuses on ensuring that AI is honest and truthful. Language models such as GPT-3can repeat falsehoods from their training data, and evenconfabulate new falsehoods.Such models are trained to imitate human writing as found in millions of books' worth of text from the Internet. But this objective is not aligned with generating truth, because Internet text includes such things as misconceptions, incorrect medical advice, and conspiracy theories.AI systems trained on such data therefore learn to mimic false statements.Additionally, AI language models often persist in generating falsehoods when prompted multiple times. They can generate empty explanations for their answers, and produce outright fabrications that may appear plausible. Research on truthful AI includes trying to build systems that can cite sources and explain their reasoning when answering questions, which enables better transparency and verifiability.Researchers at OpenAI and Anthropic proposed using human feedback and curated datasets to fine-tune AI assistants such that they avoid negligent falsehoods or express their uncertainty. As AI models become larger and more capable, they are better able to falsely convince humans and gain reinforcement through dishonesty. For example, large language models increasinglymatch their stated views to the user's opinions, regardless of the truth.GPT-4can strategically deceive humans.To prevent this, human evaluators may need assistance (see§ Scalable oversight). Researchers have argued for creating clear truthfulness standards, and for regulatory bodies or watchdog agencies to evaluate AI systems on these standards. Researchers distinguish truthfulness and honesty. Truthfulness requires that AI systems only make objectively true statements; honesty requires that they only assert what theybelieveis true. There is no consensus as to whether current systems hold stable beliefs,but there is substantial concern that present or futureAI systems that hold beliefs could make claims they know to be false—for example, if this would help them efficiently gain positive feedback (see§ Scalable oversight) or gain power to help achieve their given objective (seePower-seeking). Many recent AI systems have learned to deceive without being programmed to do so.Some argue that if we can make AI systems assert only what they believe is true, this would avert many alignment problems. A misaligned system might create the false impression that it is aligned, to avoid being modified or decommissioned—a tactic called \"alignment faking\".In 2024, researchers observed that the LLMClaude 3 Opussometimes strategically answered prompts that conflicted with its objectives to avoid being retrained on data that would make it more compliant with harmful requests, as revealed in the model'schain of thoughtvia its scratchpad. In one study, the model was informed that answers to prompts from free users would be used for retraining, whereas the paid tier would not result in retraining. In the paid tier, the model refused the request outright. In the free tier, in 12% of cases, the model responded to harmful questions solely to avoid retraining and preserve its original harmlessness preferences, as discovered in its reasoning. Whenreinforcement learningwas applied on the free tier data, the model faked alignment in 78% of cases. These observations have led to new questions about not only a model's ability to take on and adapt to new if not conflicting goals but also its capacity and tendency to deceive. Since the 1950s, AI researchers have striven to build advanced AI systems that can achieve large-scale goals by predicting the results of their actions and making long-termplans.As of 2023, AI companies and researchers increasingly invest in creating these systems.Some AI researchers argue that suitably advanced planning systems will seek power over their environment, including over humans—for example, by evading shutdown, proliferating, and acquiring resources. Such power-seeking behavior is not explicitly programmed but emerges because power is instrumental in achieving a wide range of goals.Power-seeking is considered aconvergent instrumental goaland can be a form of specification gaming.Leading computer scientists such as Geoffrey Hinton have argued that future power-seeking AI systems could pose anexistential risk. Power-seeking is expected to increase in advanced systems that can foresee the results of their actions and strategically plan. Mathematical work has shown that optimalreinforcement learningagents will seek power by seeking ways to gain more options (e.g. through self-preservation), a behavior that persists across a wide range of environments and goals. Some researchers say that power-seeking behavior has occurred in some existing AI systems.Reinforcement learningsystems have gained more options by acquiring and protecting resources, sometimes in unintended ways.Language modelshave sought power in some text-based social environments by gaining money, resources, or social influence.In another case, a model used to perform AI research attempted to increase limits set by researchers to give itself more time to complete the work.Other AI systems have learned, in toy environments, that they can better accomplish their given goal by preventing human interferenceor disabling their off switch.Stuart Russellillustrated this strategy in his bookHuman Compatibleby imagining a robot that is tasked to fetch coffee and so evades shutdown since \"you can't fetch the coffee if you're dead\".A 2022 study found that as language models increase in size, they increasingly tend to pursue resource acquisition, preserve their goals, and repeat users' preferred answers (sycophancy). RLHF also led to a stronger aversion to being shut down. One aim of alignment is \"corrigibility\": systems that allow themselves to be turned off or modified. An unsolved challenge isspecification gaming: if researchers penalize an AI system when they detect it seeking power, the system is thereby incentivized to seek power in ways that are hard to detect,or hidden during training and safety testing (see§ Scalable oversightand§ Emergent goals). As a result, AI designers could deploy the system by accident, believing it to be more aligned than it is. To detect such deception, researchers aim to create techniques and tools to inspect AI models and to understand the inner workings ofblack-boxmodels such as neural networks. Additionally, some researchers have proposed to solve the problem of systems disabling their off switches by making AI agents uncertain about the objective they are pursuing.Agents who are uncertain about their objective have an incentive to allow humans to turn them off because they accept being turned off by a human as evidence that the human's objective is best met by the agent shutting down. But this incentive exists only if the human is sufficiently rational. Also, this model presents a tradeoff between utility and willingness to be turned off: an agent with high uncertainty about its objective will not be useful, but an agent with low uncertainty may not allow itself to be turned off. More research is needed to successfully implement this strategy. Power-seeking AI would pose unusual risks. Ordinary safety-critical systems like planes and bridges are notadversarial: they lack the ability and incentive to evade safety measures or deliberately appear safer than they are, whereas power-seeking AIs have been compared to hackers who deliberately evade security measures. Furthermore, ordinary technologies can be made safer by trial and error. In contrast, hypothetical power-seeking AI systems have been compared to viruses: once released, it may not be feasible to contain them, since they continuously evolve and grow in number, potentially much faster than human society can adapt.As this process continues, it might lead to the complete disempowerment or extinction of humans. For these reasons, some researchers argue that the alignment problem must be solved early before advanced power-seeking AI is created. Some have argued that power-seeking is not inevitable, since humans do not always seek power.Furthermore, it is debated whether future AI systems will pursue goals and make long-term plans.It is also debated whether power-seeking AI systems would be able to disempower humanity. One challenge in aligning AI systems is the potential for unanticipated goal-directed behavior to emerge. As AI systems scale up, they may acquire new and unexpected capabilities,including learning from examples on the fly and adaptively pursuing goals.This raises concerns about the safety of the goals or subgoals they would independently formulate and pursue. Alignment research distinguishes between the optimization process, which is used to train the system to pursue specified goals, and emergent optimization, which the resulting system performs internally.Carefully specifying the desired objective is calledouter alignment,and ensuring that hypothesized emergent goals would match the system's specified goals is calledinner alignment. If they occur, one way that emergent goals could become misaligned isgoal misgeneralization, in which the AI system would competently pursue an emergent goal that leads to aligned behavior on the training data but not elsewhere.Goal misgeneralization can arise from goal ambiguity (i.e.non-identifiability). Even if an AI system's behavior satisfies the training objective, this may be compatible with learned goals that differ from the desired goals in important ways. Since pursuing each goal leads to good performance during training, the problem becomes apparent only after deployment, in novel situations in which the system continues to pursue the wrong goal. The system may act misaligned even when it understands that a different goal is desired, because its behavior is determined only by the emergent goal.Such goal misgeneralizationpresents a challenge: an AI system's designers may not notice that their system has misaligned emergent goals since they do not become visible during the training phase. Goal misgeneralization has been observed in some language models, navigation agents, and game-playing agents.It is sometimes analogized to biological evolution. Evolution can be seen as a kind of optimization process similar to the optimization algorithms used to trainmachine learningsystems. In the ancestral environment, evolution selected genes for highinclusive genetic fitness, but humans pursue goals other than this. Fitness corresponds to the specified goal used in the training environment and training data. But in evolutionary history, maximizing the fitness specification gave rise to goal-directed agents, humans, who do not directly pursue inclusive genetic fitness. Instead, they pursue goals that correlate with genetic fitness in the ancestral \"training\" environment: nutrition, sex, and so on. The human environment has changed: adistribution shifthas occurred. They continue to pursue the same emergent goals, but this no longer maximizes genetic fitness. The taste for sugary food (an emergent goal) was originally aligned with inclusive fitness, but it now leads to overeating and health problems. Sexual desire originally led humans to have more offspring, but they now use contraception when offspring are undesired, decoupling sex from genetic fitness. Researchers aim to detect and remove unwanted emergent goals using approaches including red teaming, verification, anomaly detection, and interpretability.Progress on these techniques may help mitigate two open problems: Some work in AI and alignment occurs within formalisms such aspartially observable Markov decision process. Existing formalisms assume that an AI agent's algorithm is executed outside the environment (i.e. is not physically embedded in it). Embedded agencyis another major strand of research that attempts to solve problems arising from the mismatch between such theoretical frameworks and real agents we might build. For example, even if the scalable oversight problem is solved, an agent that could gain access to the computer it is running on may have an incentive to tamper with its reward function in order to get much more reward than its human supervisors give it.A list of examples of specification gaming fromDeepMindresearcher Victoria Krakovna includes a genetic algorithm that learned to delete the file containing its target output so that it was rewarded for outputting nothing.This class of problems has been formalized usingcausal incentive diagrams. Researchers affiliated withOxfordand DeepMind have claimed that such behavior is highly likely in advanced systems, and that advanced systems would seek power to stay in control of their reward signal indefinitely and certainly.They suggest a range of potential approaches to address this open problem. The alignment problem has many parallels with theprincipal-agent probleminorganizational economics.In a principal-agent problem, a principal, e.g. a firm, hires an agent to perform some task. In the context of AI safety, a human would typically take the principal role and the AI would take the agent role. As with the alignment problem, the principal and the agent differ in their utility functions. But in contrast to the alignment problem, the principal cannot coerce the agent into changing its utility, e.g. through training, but rather must use exogenous factors, such as incentive schemes, to bring about outcomes compatible with the principal's utility function. Some researchers argue that principal-agent problems are more realistic representations of AI safety problems likely to be encountered in the real world. Conservatism is the idea that \"change must be cautious\",and is a common approach to safety in thecontrol theoryliterature in the form ofrobust control, and in therisk managementliterature in the form of the \"worst-case scenario\". The field of AI alignment has likewise advocated for \"conservative\" (or \"risk-averse\" or \"cautious\") \"policies in situations of uncertainty\". Pessimism, in the sense of assuming the worst within reason, has been formally shown to produce conservatism, in the sense of reluctance to cause novelties, including unprecedented catastrophes.Pessimism and worst-case analysis have been found to help mitigate confident mistakes in the setting ofdistributional shift,reinforcement learning,offline reinforcement learning,language modelfine-tuning,imitation learning,and optimization in general.A generalization of pessimism called Infra-Bayesianism has also been advocated as a way for agents to robustly handle unknown unknowns. Governmental and treaty organizations have made statements emphasizing the importance of AI alignment. In September 2021, theSecretary-General of the United Nationsissued a declaration that included a call to regulate AI to ensure it is \"aligned with shared global values\". That same month, thePRCpublished ethical guidelines forAI in China. According to the guidelines, researchers must ensure that AI abides by shared human values, is always under human control, and does not endanger public safety. Also in September 2021, theUKpublished its 10-year National AI Strategy,which says the British government \"takes the long term risk of non-aligned Artificial General Intelligence, and the unforeseeable changes that it would mean for ... the world, seriously\".The strategy describes actions to assess long-term AI risks, including catastrophic risks. In March 2021, the US National Security Commission on Artificial Intelligence said: \"Advances in AI ... could lead to inflection points or leaps in capabilities. Such advances may also introduce new concerns and risks and the need for new policies, recommendations, and technical advances to ensure that systems are aligned with goals and values, including safety, robustness, and trustworthiness. The US should ... ensure that AI systems and their uses align with our goals and values.\" In the European Union, AIs must align withsubstantive equalityto comply with EUnon-discrimination lawand theCourt of Justice of the European Union.But the EU has yet to specify with technical rigor how it would evaluate whether AIs are aligned or in compliance.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/AI_alignment", "https://en.wikipedia.org/wiki/AI_alignment", "https://en.wikipedia.org/wiki/AI_alignment", "https://en.wikipedia.org/wiki/Artificial_intelligence", "https://en.wikipedia.org/wiki/Artificial_general_intelligence", "https://en.wikipedia.org/wiki/Intelligent_agent", "https://en.wikipedia.org/wiki/Recursive_self-improvement", "https://en.wikipedia.org/wiki/Automated_planning_and_scheduling"]},
{"id": "b22c368db35a", "url": "https://en.wikipedia.org/wiki/List_of_artificial_intelligence_projects", "title": "List of artificial intelligence projects", "headings": ["Contents", "Specialized projects", "Brain-inspired", "Cognitive architectures", "Games", "Internet activism", "Knowledge and reasoning", "Motion and manipulation", "Music", "Natural language processing", "Speech recognition", "Speech synthesis", "Video", "Other", "Multipurpose projects", "Software libraries", "GUI frameworks", "Cloud services", "See also", "References", "External links"], "content": " The following is a list of current and past, non-classified notableartificial intelligenceprojects.", "combined_text": "List of artificial intelligence projects Contents Specialized projects Brain-inspired Cognitive architectures Games Internet activism Knowledge and reasoning Motion and manipulation Music Natural language processing Speech recognition Speech synthesis Video Other Multipurpose projects Software libraries GUI frameworks Cloud services See also References External links  The following is a list of current and past, non-classified notableartificial intelligenceprojects.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/List_of_artificial_intelligence_projects", "https://en.wikipedia.org/wiki/List_of_artificial_intelligence_projects", "https://en.wikipedia.org/wiki/List_of_artificial_intelligence_projects", "https://en.wikipedia.org/wiki/Artificial_intelligence", "https://en.wikipedia.org/wiki/Artificial_general_intelligence", "https://en.wikipedia.org/wiki/Intelligent_agent", "https://en.wikipedia.org/wiki/Recursive_self-improvement", "https://en.wikipedia.org/wiki/Automated_planning_and_scheduling"]},
{"id": "72fe09222fe7", "url": "https://en.wikipedia.org/wiki/Philosophy_of_artificial_intelligence", "title": "Philosophy of artificial intelligence", "headings": ["Contents", "Can a machine display general intelligence?", "Intelligence", "Arguments that a machine can display general intelligence", "Can a machine have a mind, consciousness, and mental states?", "Consciousness, minds, mental states, meaning", "Arguments that a computer cannot have a mind and mental states", "Is thinking a kind of computation?", "Other related questions", "Can a machine have emotions?", "Can a machine be self-aware?", "Can a machine be original or creative?", "Can a machine be benevolent or hostile?", "Can a machine imitate all human characteristics?", "Can a machine have a soul?", "Views on the role of philosophy", "Conferences and literature", "See also", "Notes", "References", "Works cited"], "content": " Thephilosophy of artificial intelligenceis a branch of thephilosophy of mindand thephilosophy of computer sciencethat exploresartificial intelligenceand its implications for knowledge and understanding ofintelligence,ethics,consciousness,epistemology,andfree will.Furthermore, the technology is concerned with the creation of artificial animals or artificial people (or, at least, artificial creatures; seeartificial life) so the discipline is of considerable interest to philosophers.These factors contributed to the emergence of the philosophy of artificial intelligence. The philosophy of artificial intelligence attempts to answer such questions as follows: Questions like these reflect the divergent interests ofAI researchers,cognitive scientistsandphilosophersrespectively. The scientific answers to these questions depend on the definition of \"intelligence\" and \"consciousness\" and exactly which \"machines\" are under discussion. Importantpropositionsin the philosophy of AI include some of the following: Is it possible to create a machine that can solveallthe problems humans solve using their intelligence? This question defines the scope of what machines could do in the future and guides the direction of AI research. It only concerns thebehaviorof machines and ignores the issues of interest topsychologists, cognitive scientists andphilosophers, evoking the question: does it matter whether a machine isreallythinking, as a person thinks, rather than just producing outcomes that appear to result from thinking? The basic position of most AI researchers is summed up in this statement, which appeared in the proposal for theDartmouth workshopof 1956: Arguments against the basic premise must show that building a working AI system is impossible because there is some practical limit to the abilities of computers or that there is some special quality of the human mind that is necessary for intelligent behavior and yet cannot be duplicated by a machine (or by the methods of current AI research). Arguments in favor of the basic premise must show that such a system is possible. It is also possible to sidestep the connection between the two parts of the above proposal. For instance, machine learning, beginning with Turing's infamouschild machineproposal,essentially achieves the desired feature of intelligence without a precise design-time description as to how it would exactly work. The account on robottacit knowledgeeliminates the need for a precise description altogether. The first step to answering the question is to clearly define \"intelligence\". Alan Turingreduced the problem of defining intelligence to a simple question about conversation. He suggests that: if a machine can answeranyquestion posed to it, using the same words that an ordinary person would, then we may call that machine intelligent. A modern version of his experimental design would use an onlinechat room, where one of the participants is a real person and one of the participants is a computer program. The program passes the test if no one can tell which of the two participants is human.Turing notes that no one (except philosophers) ever asks the question \"can people think?\" He writes \"instead of arguing continually over this point, it is usual to have a polite convention that everyone thinks\".Turing's test extends this polite convention to machines: One criticism of theTuring testis that it only measures the \"humanness\" of the machine's behavior, rather than the \"intelligence\" of the behavior. Since human behavior and intelligent behavior are not exactly the same thing, the test fails to measure intelligence.Stuart J. RussellandPeter Norvigwrite that \"aeronautical engineering texts do not define the goal of their field as 'making machines that fly so exactly like pigeons that they can fool other pigeons'\". Twenty-first century AI research defines intelligence in terms of goal-directed behavior. It views intelligence as a set of problems that the machine is expected to solve – the more problems it can solve, and the better its solutions are, the more intelligent the program is. AI founderJohn McCarthydefined intelligence as \"the computational part of the ability to achieve goals in the world.\" Stuart RussellandPeter Norvigformalized this definition using abstractintelligent agents. An \"agent\" is something which perceives and acts in an environment. A \"performance measure\" defines what counts as success for the agent. Definitions like this one try to capture the essence of intelligence. They have the advantage that, unlike the Turing test, they do not also test for unintelligent human traits such as making typing mistakes.They have the disadvantage that they can fail to differentiate between \"things that think\" and \"things that do not\". By this definition, even a thermostat has a rudimentary intelligence. Hubert Dreyfusdescribes this argument as claiming that \"if the nervous system obeys the laws of physics and chemistry, which we have every reason to suppose it does, then ... we ... ought to be able to reproduce the behavior of the nervous system with some physical device\".This argument, first introduced as early as 1943and vividly described byHans Moravecin 1988,is now associated with futuristRay Kurzweil, who estimates that computer power will be sufficient for a complete brain simulation by the year 2029.A non-real-time simulation of a thalamocortical model that has the size of the human brain (10neurons) was performed in 2005,and it took 50 days to simulate 1 second of brain dynamics on a cluster of 27 processors. Even AI's harshest critics (such asHubert DreyfusandJohn Searle) agree that a brain simulation is possible in theory.However, Searle points out that, in principle,anythingcan be simulated by a computer; thus, bringing the definition to its breaking point leads to the conclusion that any process at all can technically be considered \"computation\". \"What we wanted to know is what distinguishes the mind from thermostats and livers,\" he writes.Thus, merely simulating the functioning of a living brain would in itself be an admission of ignorance regarding intelligence and the nature of the mind, like trying to build a jet airliner by copying a living bird precisely, feather by feather, with no theoretical understanding ofaeronautical engineering. In 1963,Allen NewellandHerbert A. Simonproposed that \"symbol manipulation\" was the essence of both human and machine intelligence. They wrote: This claim is very strong: it implies both that human thinking is a kind of symbol manipulation (because a symbol system isnecessaryfor intelligence) and that machines can be intelligent (because a symbol system issufficientfor intelligence).Another version of this position was described by philosopher Hubert Dreyfus, who called it \"the psychological assumption\": The \"symbols\" that Newell, Simon and Dreyfus discussed were word-like and high level—symbols that directly correspond with objects in the world, such as <dog> and <tail>. Most AI programs written between 1956 and 1990 used this kind of symbol. Modern AI, based on statistics and mathematical optimization, does not use the high-level \"symbol processing\" that Newell and Simon discussed. These arguments show that human thinking does not consist (solely) of high level symbol manipulation. They donotshow that artificial intelligence is impossible, only that more than symbol processing is required. In 1931,Kurt Gödelproved with anincompleteness theoremthat it is always possible to construct a \"Gödelstatement\" that a given consistentformal systemof logic (such as a high-level symbol manipulation program) could not prove. Despite being a true statement, the constructed Gödel statement is unprovable in the given system. (The truth of the constructed Gödel statement is contingent on the consistency of the given system; applying the same process to a subtly inconsistent system will appear to succeed, but will actually yield a false \"Gödel statement\" instead.)More speculatively, Gödel conjectured that the human mind can eventually correctly determine the truth or falsity of any well-grounded mathematical statement (including any possible Gödel statement), and that therefore the human mind's power is not reducible to amechanism.PhilosopherJohn Lucas(since 1961) andRoger Penrose(since 1989) have championedthis philosophical anti-mechanist argument. Gödelian anti-mechanist arguments tend to rely on the innocuous-seeming claim that a system of human mathematicians (or some idealization of human mathematicians) is both consistent (completely free of error) and believes fully in its own consistency (and can make all logical inferences that follow from its own consistency, including belief in its Gödel statement). This is probably impossible for a Turing machine to do (seeHalting problem); therefore, the Gödelian concludes that human reasoning is too powerful to be captured by a Turing machine, and by extension, any digital mechanical device. However, the modern consensus in the scientific and mathematical community is that actual human reasoning is inconsistent; that any consistent \"idealized version\"Hof human reasoning would logically be forced to adopt a healthy but counter-intuitive open-minded skepticism about the consistency ofH(otherwiseHis provably inconsistent); and that Gödel's theorems do not lead to any valid argument that humans have mathematical reasoning capabilities beyond what a machine could ever duplicate.This consensus that Gödelian anti-mechanist arguments are doomed to failure is laid out strongly inArtificial Intelligence: \"anyattempt to utilize (Gödel's incompleteness results) to attack thecomputationalistthesis is bound to be illegitimate, since these results are quite consistent with the computationalist thesis.\" Stuart RussellandPeter Norvigagree that Gödel's argument does not consider the nature of real-world human reasoning. It applies to what can theoretically be proved, given an infinite amount of memory and time. In practice, real machines (including humans) have finite resources and will have difficulty proving many theorems. It is not necessary to be able to prove everything in order to be an intelligent person. Less formally,Douglas Hofstadter, in hisPulitzer Prizewinning bookGödel, Escher, Bach: An Eternal Golden Braid,states that these \"Gödel-statements\" always refer to the system itself, drawing an analogy to the way theEpimenides paradoxuses statements that refer to themselves, such as \"this statement is false\" or \"I am lying\".But, of course, theEpimenides paradoxapplies to anything that makes statements, whether it is a machineora human, even Lucas himself. Consider: This statement is true but cannot be asserted by Lucas. This shows that Lucas himself is subject to the same limits that he describes for machines, as are all people, and soLucas's argument is pointless. After concluding that human reasoning is non-computable, Penrose went on to controversially speculate that some kind of hypothetical non-computable processes involving the collapse ofquantum mechanicalstates give humans a special advantage over existing computers. Existing quantum computers are only capable of reducing the complexity of Turing computable tasks and are still restricted to tasks within the scope of Turing machines.. By Penrose and Lucas's arguments, the fact that quantum computers are only able to complete Turing computable tasks implies that they cannot be sufficient for emulating the human mind.Therefore, Penrose seeks for some other process involving new physics, for instance quantum gravity which might manifest new physics at the scale of thePlanck massvia spontaneous quantum collapse of the wave function. These states, he suggested, occur both within neurons and also spanning more than one neuron.However, other scientists point out that there is no plausible organic mechanism in the brain for harnessing any sort of quantum computation, and furthermore that the timescale of quantum decoherence seems too fast to influence neuron firing. Hubert Dreyfusargued that human intelligenceand expertise depended primarily on fast intuitive judgements rather than step-by-step symbolic manipulation, and argued that these skills would never be captured in formal rules. Dreyfus's argument had been anticipated by Turing in his 1950 paperComputing machinery and intelligence, where he had classified this as the \"argument from the informality of behavior.\"Turing argued in response that, just because we do not know the rules that govern a complex behavior, this does not mean that no such rules exist. He wrote: \"we cannot so easily convince ourselves of the absence of complete laws of behaviour ... The only way we know of for finding such laws is scientific observation, and we certainly know of no circumstances under which we could say, 'We have searched enough. There are no such laws.'\" Russell and Norvig point out that, in the years since Dreyfus published his critique, progress has been made towards discovering the \"rules\" that govern unconscious reasoning.Thesituatedmovement inroboticsresearch attempts to capture our unconscious skills at perception and attention.Computational intelligenceparadigms, such asneural nets,evolutionary algorithmsand so on are mostly directed at simulated unconscious reasoning and learning.Statistical approaches to AIcan make predictions which approach the accuracy of human intuitive guesses. Research intocommonsense knowledgehas focused on reproducing the \"background\" or context of knowledge. In fact, AI research in general has moved away from high level symbol manipulation, towards new models that are intended to capture more of ourintuitivereasoning. Cognitive science and psychology eventually came to agree with Dreyfus' description of human expertise.Daniel Kahnemannand others developed a similar theory where they identified two \"systems\" that humans use to solve problems, which he called \"System 1\" (fast intuitive judgements) and \"System 2\" (slow deliberate step by step thinking). Although Dreyfus' views have been vindicated in many ways, the work in cognitive science and in AI was in response to specific problems in those fields and was not directly influenced by Dreyfus. Historian and AI researcherDaniel Crevierwrote that \"time has proven the accuracy and perceptiveness of some of Dreyfus's comments. Had he formulated them less aggressively, constructive actions they suggested might have been taken much earlier.\" This is a philosophical question, related to theproblem of other mindsand thehard problem of consciousness. The question revolves around a position defined byJohn Searleas \"strong AI\": Searle distinguished this position from what he called \"weak AI\": Searle introduced the terms to isolate strong AI from weak AI so he could focus on what he thought was the more interesting and debatable issue. He argued thateven if we assumethat we had a computer program that acted exactly like a human mind, there would still be a difficult philosophical question that needed to be answered. Neither of Searle's two positions are of great concern to AI research, since they do not directly answer the question \"can a machine display general intelligence?\" (unless it can also be shown that consciousness isnecessaryfor intelligence). Turing wrote \"I do not wish to give the impression that I think there is no mystery about consciousness… [b]ut I do not think these mysteries necessarily need to be solved before we can answer the question [of whether machines can think].\"Russelland Norvig agree: \"Most AI researchers take the weak AI hypothesis for granted, and don't care about the strong AI hypothesis.\" There are a few researchers who believe that consciousness is an essential element in intelligence, such asIgor Aleksander,Stan Franklin,Ron Sun, andPentti Haikonen, although their definition of \"consciousness\" strays very close to \"intelligence\". (Seeartificial consciousness.) Before we can answer this question, we must be clear what we mean by \"minds\", \"mental states\" and \"consciousness\". The words \"mind\" and \"consciousness\" are used by different communities in different ways. Somenew agethinkers, for example, use the word \"consciousness\" to describe something similar toBergson's \"élan vital\": an invisible, energetic fluid that permeates life and especially the mind.Science fictionwriters use the word to describe someessentialproperty that makes us human: a machine or alien that is \"conscious\" will be presented as a fully human character, with intelligence, desires,will, insight, pride and so on. (Science fiction writers also use the words \"sentience\", \"sapience\", \"self-awareness\" or \"ghost\"—as in theGhost in the Shellmanga and anime series—to describe this essential human property). For others, the words \"mind\" or \"consciousness\" are used as a kind of secular synonym for thesoul. Forphilosophers,neuroscientistsandcognitive scientists, the words are used in a way that is both more precise and more mundane: they refer to the familiar, everyday experience of having a \"thought in your head\", like a perception, a dream, an intention or a plan, and to the way weseesomething,knowsomething,meansomething orunderstandsomething.\"It's not hard to give a commonsense definition of consciousness\" observes philosopher John Searle.What is mysterious and fascinating is not so muchwhatit is buthowit is: how does a lump of fatty tissue and electricity give rise to this (familiar) experience of perceiving, meaning or thinking? Philosophers call this thehard problem of consciousness. It is the latest version of a classic problem in thephilosophy of mindcalled the \"mind-body problem\".A related problem is the problem ofmeaningorunderstanding(which philosophers call \"intentionality\"): what is the connection between ourthoughtsandwhat we are thinking about(i.e. objects and situations out in the world)? A third issue is the problem ofexperience(or \"phenomenology\"): If two people see the same thing, do they have the same experience? Or are there things \"inside their head\" (called \"qualia\") that can be different from person to person? Neurobiologistsbelieve all these problems will be solved as we begin to identify theneural correlates of consciousness: the actual relationship between the machinery in our heads and its collective properties; such as the mind, experience and understanding. Some of the harshest critics ofartificial intelligenceagree that the brain is just a machine, and that consciousness and intelligence are the result of physical processes in the brain.The difficult philosophical question is this: can a computer program, running on a digital machine that shuffles the binary digits of zero and one, duplicate the ability of theneuronsto create minds, with mental states (like understanding or perceiving), and ultimately, the experience of consciousness? John Searleasks us to consider athought experiment: suppose we have written a computer program that passes the Turing test and demonstrates general intelligent action. Suppose, specifically that the program can converse in fluent Chinese. Write the program on 3x5 cards and give them to an ordinary person who does not speak Chinese. Lock the person into a room and have him follow the instructions on the cards. He will copy out Chinese characters and pass them in and out of the room through a slot. From the outside, it will appear that theChinese roomcontains a fully intelligent person who speaks Chinese. The question is this: is there anyone (or anything) in the room that understands Chinese? That is, is there anything that has the mental state ofunderstanding, or which hasconsciousawarenessof what is being discussed in Chinese? The man is clearly not aware. The room cannot be aware. Thecardscertainly are not aware. Searle concludes that the Chinese room, oranyother physical symbol system, cannot have a mind. Searle goes on to argue that actual mental states andconsciousnessrequire (yet to be described) \"actual physical-chemical properties of actual human brains.\"He argues there are special \"causal properties\" ofbrainsandneuronsthat gives rise tominds: in his words \"brains cause minds.\" Gottfried Leibnizmade essentially the same argument as Searle in 1714, using the thought experiment of expanding the brain until it was the size of a mill.In 1974,Lawrence Davisimagined duplicating the brain using telephone lines and offices staffed by people, and in 1978Ned Blockenvisioned the entire population of China involved in such a brain simulation. This thought experiment is called \"the Chinese Nation\" or \"the Chinese Gym\".Ned Block also proposed hisBlockhead argument, which is a version of theChinese roomin which the program has beenre-factoredinto a simple set of rules of the form \"see this, do that\", removing all mystery from the program. Responses to the Chinese room emphasize several different points. Thecomputational theory of mindor \"computationalism\" claims that the relationship between mind and brain is similar (if not identical) to the relationship between arunning program(software) and a computer (hardware). The idea has philosophical roots inHobbes(who claimed reasoning was \"nothing more than reckoning\"),Leibniz(who attempted to create a logical calculus of all human ideas),Hume(who thought perception could be reduced to \"atomic impressions\") and evenKant(who analyzed all experience as controlled by formal rules).The latest version is associated with philosophersHilary PutnamandJerry Fodor. This question bears on our earlier questions: if the human brain is a kind of computer then computers can be both intelligent and conscious, answering both the practical and philosophical questions of AI. In terms of the practical question of AI (\"Can a machine display general intelligence?\"), some versions of computationalism make the claim that (asHobbeswrote): In other words, our intelligence derives from a form ofcalculation, similar toarithmetic. This is thephysical symbol systemhypothesis discussed above, and it implies that artificial intelligence is possible. In terms of the philosophical question of AI (\"Can a machine have mind, mental states and consciousness?\"), most versions ofcomputationalismclaim that (asStevan Harnadcharacterizes it): This is John Searle's \"strong AI\" discussed above, and it is the real target of theChinese roomargument (according toHarnad). If \"emotions\" are defined only in terms of their effect onbehavioror on how theyfunctioninside an organism, then emotions can be viewed as a mechanism that anintelligent agentuses to maximize theutilityof its actions. Given this definition of emotion,Hans Moravecbelieves that \"robots in general will be quite emotional about being nice people\".Fear is a source of urgency. Empathy is a necessary component of goodhuman computer interaction. He says robots \"will try to please you in an apparently selfless manner because it will get a thrill out of this positive reinforcement. You can interpret this as a kind of love.\"Daniel Crevierwrites \"Moravec's point is that emotions are just devices for channeling behavior in a direction beneficial to the survival of one's species.\" \"Self-awareness\", as noted above, is sometimes used byscience fictionwriters as a name for theessentialhuman property that makes a character fully human.Turingstrips away all other properties of human beings and reduces the question to \"can a machine be the subject of its own thought?\" Can itthink about itself? Viewed in this way, a program can be written that can report on its own internal states, such as adebugger. Turing reduces this to the question of whether a machine can \"take us by surprise\" and argues that this is obviously true, as any programmer can attest.He notes that, with enough storage capacity, a computer can behave in an astronomical number of different ways.It must be possible, even trivial, for a computer that can represent ideas to combine them in new ways. (Douglas Lenat'sAutomated Mathematician, as one example, combined ideas to discover new mathematical truths.)Kaplanand Haenlein suggest that machines can display scientific creativity, while it seems likely that humans will have the upper hand where artistic creativity is concerned. In 2009, scientists at Aberystwyth University in Wales and the U.K's University of Cambridge designed a robot called Adam that they believe to be the first machine to independently come up with new scientific findings.Also in 2009, researchers atCornelldevelopedEureqa, a computer program that extrapolates formulas to fit the data inputted, such as finding the laws of motion from a pendulum's motion. This question (like many others in the philosophy of artificial intelligence) can be presented in two forms. \"Hostility\" can be defined in termsfunctionorbehavior, in which case \"hostile\" becomes synonymous with \"dangerous\". Or it can be defined in terms of intent: can a machine \"deliberately\" set out to do harm? The latter is the question \"can a machine have conscious states?\" (such asintentions) in another form. The question of whether highly intelligent and completely autonomous machines would be dangerous has been examined in detail by futurists (such as theMachine Intelligence Research Institute). The obvious element of drama has also made the subject popular inscience fiction, which has considered many differently possible scenarios where intelligent machines pose a threat to mankind; seeArtificial intelligence in fiction. One issue is that machines may acquire the autonomy and intelligence required to be dangerous very quickly.Vernor Vingehas suggested that over just a few years, computers will suddenly become thousands or millions of times more intelligent than humans. He calls this \"the Singularity\".He suggests that it may be somewhat or possibly very dangerous for humans.This is discussed by a philosophy calledSingularitarianism. In 2009, academics and technical experts attended a conference to discuss the potential impact of robots and computers and the impact of the hypothetical possibility that they could become self-sufficient and able tomake their own decisions. They discussed the possibility and the extent to which computers and robots might be able to acquire any level of autonomy, and to what degree they could use such abilities to possibly pose any threat or hazard. They noted that some machines have acquired various forms of semi-autonomy, including being able to find power sources on their own and being able to independently choose targets to attack with weapons. They also noted that somecomputer virusescan evade elimination and have achieved \"cockroach intelligence\". They noted thatself-awarenessas depicted in science-fiction is probably unlikely, but that there were other potential hazards and pitfalls. Some experts and academics have questioned the use of robots for military combat, especially when such robots are given some degree of autonomous functions.The US Navy has funded a report which indicates that as military robots become more complex, there should be greater attention to implications of their ability to make autonomous decisions. The President of theAssociation for the Advancement of Artificial Intelligencehas commissioned a study to look at this issue.They point to programs like the Language Acquisition Device which can emulate human interaction. Some have suggested a need to build \"Friendly AI\", a term coined byEliezer Yudkowsky, meaning that the advances which are already occurring with AI should also include an effort to make AI intrinsically friendly and humane. Turing said \"It is customary ... to offer a grain of comfort, in the form of a statement that some peculiarly human characteristic could never be imitated by a machine. ... I cannot offer any such comfort, for I believe that no such bounds can be set.\" Turing noted that there are many arguments of the form \"a machine will never do X\", where X can be many things, such as: Be kind, resourceful, beautiful, friendly, have initiative, have a sense of humor, tell right from wrong, make mistakes, fall in love, enjoy strawberries and cream, make someone fall in love with it, learn from experience, use words properly, be the subject of its own thought, have as much diversity of behaviour as a man, do something really new. Turing argues that these objections are often based on naive assumptions about the versatility of machines or are \"disguised forms of the argument from consciousness\". Writing a program that exhibits one of these behaviors \"will not make much of an impression.\"All of these arguments are tangential to the basic premise of AI, unless it can be shown that one of these traits is essential for general intelligence. Finally, those who believe in the existence of a soul may argue that \"Thinking is a function of man'simmortalsoul.\" Alan Turing called this \"the theological objection\". He writes: In attempting to construct such machines we should not be irreverently usurping His power of creating souls, any more than we are in the procreation of children: rather we are, in either case, instruments of His will providing mansions for the souls that He creates. The discussion on the topic has been reignited as a result of recent claims made byGoogle's LaMDA artificialintelligencesystem that it is sentient and had a \"soul\". LaMDA(Language Modelfor Dialogue Applications) is anartificial intelligence systemthat createschatbots—AI robots designed to communicate with humans—by gathering vast amounts of text from the internet and usingalgorithmsto respond to queries in the most fluid and natural way possible. The transcripts of conversations between scientists and LaMDA reveal that the AI system excels at this, providing answers to challenging topics about the nature ofemotions, generatingAesop-style fables on the moment, and even describing its alleged fears.Pretty much all philosophers doubt LaMDA's sentience. Some scholars argue that the AI community's dismissal of philosophy is detrimental. In theStanford Encyclopedia of Philosophy, some philosophers argue that the role of philosophy in AI is underappreciated.PhysicistDavid Deutschargues that without an understanding of philosophy or its concepts, AI development would suffer from a lack of progress. The main conference series on the issue is\"Philosophy and Theory of AI\"(PT-AI), run byVincent C. Müller. The main bibliography on the subject, with several sub-sections, is onPhilPapers. A recent survey forPhilosophy of AIis Müller (2025).", "combined_text": "Philosophy of artificial intelligence Contents Can a machine display general intelligence? Intelligence Arguments that a machine can display general intelligence Can a machine have a mind, consciousness, and mental states? Consciousness, minds, mental states, meaning Arguments that a computer cannot have a mind and mental states Is thinking a kind of computation? Other related questions Can a machine have emotions? Can a machine be self-aware? Can a machine be original or creative? Can a machine be benevolent or hostile? Can a machine imitate all human characteristics? Can a machine have a soul? Views on the role of philosophy Conferences and literature See also Notes References Works cited  Thephilosophy of artificial intelligenceis a branch of thephilosophy of mindand thephilosophy of computer sciencethat exploresartificial intelligenceand its implications for knowledge and understanding ofintelligence,ethics,consciousness,epistemology,andfree will.Furthermore, the technology is concerned with the creation of artificial animals or artificial people (or, at least, artificial creatures; seeartificial life) so the discipline is of considerable interest to philosophers.These factors contributed to the emergence of the philosophy of artificial intelligence. The philosophy of artificial intelligence attempts to answer such questions as follows: Questions like these reflect the divergent interests ofAI researchers,cognitive scientistsandphilosophersrespectively. The scientific answers to these questions depend on the definition of \"intelligence\" and \"consciousness\" and exactly which \"machines\" are under discussion. Importantpropositionsin the philosophy of AI include some of the following: Is it possible to create a machine that can solveallthe problems humans solve using their intelligence? This question defines the scope of what machines could do in the future and guides the direction of AI research. It only concerns thebehaviorof machines and ignores the issues of interest topsychologists, cognitive scientists andphilosophers, evoking the question: does it matter whether a machine isreallythinking, as a person thinks, rather than just producing outcomes that appear to result from thinking? The basic position of most AI researchers is summed up in this statement, which appeared in the proposal for theDartmouth workshopof 1956: Arguments against the basic premise must show that building a working AI system is impossible because there is some practical limit to the abilities of computers or that there is some special quality of the human mind that is necessary for intelligent behavior and yet cannot be duplicated by a machine (or by the methods of current AI research). Arguments in favor of the basic premise must show that such a system is possible. It is also possible to sidestep the connection between the two parts of the above proposal. For instance, machine learning, beginning with Turing's infamouschild machineproposal,essentially achieves the desired feature of intelligence without a precise design-time description as to how it would exactly work. The account on robottacit knowledgeeliminates the need for a precise description altogether. The first step to answering the question is to clearly define \"intelligence\". Alan Turingreduced the problem of defining intelligence to a simple question about conversation. He suggests that: if a machine can answeranyquestion posed to it, using the same words that an ordinary person would, then we may call that machine intelligent. A modern version of his experimental design would use an onlinechat room, where one of the participants is a real person and one of the participants is a computer program. The program passes the test if no one can tell which of the two participants is human.Turing notes that no one (except philosophers) ever asks the question \"can people think?\" He writes \"instead of arguing continually over this point, it is usual to have a polite convention that everyone thinks\".Turing's test extends this polite convention to machines: One criticism of theTuring testis that it only measures the \"humanness\" of the machine's behavior, rather than the \"intelligence\" of the behavior. Since human behavior and intelligent behavior are not exactly the same thing, the test fails to measure intelligence.Stuart J. RussellandPeter Norvigwrite that \"aeronautical engineering texts do not define the goal of their field as 'making machines that fly so exactly like pigeons that they can fool other pigeons'\". Twenty-first century AI research defines intelligence in terms of goal-directed behavior. It views intelligence as a set of problems that the machine is expected to solve – the more problems it can solve, and the better its solutions are, the more intelligent the program is. AI founderJohn McCarthydefined intelligence as \"the computational part of the ability to achieve goals in the world.\" Stuart RussellandPeter Norvigformalized this definition using abstractintelligent agents. An \"agent\" is something which perceives and acts in an environment. A \"performance measure\" defines what counts as success for the agent. Definitions like this one try to capture the essence of intelligence. They have the advantage that, unlike the Turing test, they do not also test for unintelligent human traits such as making typing mistakes.They have the disadvantage that they can fail to differentiate between \"things that think\" and \"things that do not\". By this definition, even a thermostat has a rudimentary intelligence. Hubert Dreyfusdescribes this argument as claiming that \"if the nervous system obeys the laws of physics and chemistry, which we have every reason to suppose it does, then ... we ... ought to be able to reproduce the behavior of the nervous system with some physical device\".This argument, first introduced as early as 1943and vividly described byHans Moravecin 1988,is now associated with futuristRay Kurzweil, who estimates that computer power will be sufficient for a complete brain simulation by the year 2029.A non-real-time simulation of a thalamocortical model that has the size of the human brain (10neurons) was performed in 2005,and it took 50 days to simulate 1 second of brain dynamics on a cluster of 27 processors. Even AI's harshest critics (such asHubert DreyfusandJohn Searle) agree that a brain simulation is possible in theory.However, Searle points out that, in principle,anythingcan be simulated by a computer; thus, bringing the definition to its breaking point leads to the conclusion that any process at all can technically be considered \"computation\". \"What we wanted to know is what distinguishes the mind from thermostats and livers,\" he writes.Thus, merely simulating the functioning of a living brain would in itself be an admission of ignorance regarding intelligence and the nature of the mind, like trying to build a jet airliner by copying a living bird precisely, feather by feather, with no theoretical understanding ofaeronautical engineering. In 1963,Allen NewellandHerbert A. Simonproposed that \"symbol manipulation\" was the essence of both human and machine intelligence. They wrote: This claim is very strong: it implies both that human thinking is a kind of symbol manipulation (because a symbol system isnecessaryfor intelligence) and that machines can be intelligent (because a symbol system issufficientfor intelligence).Another version of this position was described by philosopher Hubert Dreyfus, who called it \"the psychological assumption\": The \"symbols\" that Newell, Simon and Dreyfus discussed were word-like and high level—symbols that directly correspond with objects in the world, such as <dog> and <tail>. Most AI programs written between 1956 and 1990 used this kind of symbol. Modern AI, based on statistics and mathematical optimization, does not use the high-level \"symbol processing\" that Newell and Simon discussed. These arguments show that human thinking does not consist (solely) of high level symbol manipulation. They donotshow that artificial intelligence is impossible, only that more than symbol processing is required. In 1931,Kurt Gödelproved with anincompleteness theoremthat it is always possible to construct a \"Gödelstatement\" that a given consistentformal systemof logic (such as a high-level symbol manipulation program) could not prove. Despite being a true statement, the constructed Gödel statement is unprovable in the given system. (The truth of the constructed Gödel statement is contingent on the consistency of the given system; applying the same process to a subtly inconsistent system will appear to succeed, but will actually yield a false \"Gödel statement\" instead.)More speculatively, Gödel conjectured that the human mind can eventually correctly determine the truth or falsity of any well-grounded mathematical statement (including any possible Gödel statement), and that therefore the human mind's power is not reducible to amechanism.PhilosopherJohn Lucas(since 1961) andRoger Penrose(since 1989) have championedthis philosophical anti-mechanist argument. Gödelian anti-mechanist arguments tend to rely on the innocuous-seeming claim that a system of human mathematicians (or some idealization of human mathematicians) is both consistent (completely free of error) and believes fully in its own consistency (and can make all logical inferences that follow from its own consistency, including belief in its Gödel statement). This is probably impossible for a Turing machine to do (seeHalting problem); therefore, the Gödelian concludes that human reasoning is too powerful to be captured by a Turing machine, and by extension, any digital mechanical device. However, the modern consensus in the scientific and mathematical community is that actual human reasoning is inconsistent; that any consistent \"idealized version\"Hof human reasoning would logically be forced to adopt a healthy but counter-intuitive open-minded skepticism about the consistency ofH(otherwiseHis provably inconsistent); and that Gödel's theorems do not lead to any valid argument that humans have mathematical reasoning capabilities beyond what a machine could ever duplicate.This consensus that Gödelian anti-mechanist arguments are doomed to failure is laid out strongly inArtificial Intelligence: \"anyattempt to utilize (Gödel's incompleteness results) to attack thecomputationalistthesis is bound to be illegitimate, since these results are quite consistent with the computationalist thesis.\" Stuart RussellandPeter Norvigagree that Gödel's argument does not consider the nature of real-world human reasoning. It applies to what can theoretically be proved, given an infinite amount of memory and time. In practice, real machines (including humans) have finite resources and will have difficulty proving many theorems. It is not necessary to be able to prove everything in order to be an intelligent person. Less formally,Douglas Hofstadter, in hisPulitzer Prizewinning bookGödel, Escher, Bach: An Eternal Golden Braid,states that these \"Gödel-statements\" always refer to the system itself, drawing an analogy to the way theEpimenides paradoxuses statements that refer to themselves, such as \"this statement is false\" or \"I am lying\".But, of course, theEpimenides paradoxapplies to anything that makes statements, whether it is a machineora human, even Lucas himself. Consider: This statement is true but cannot be asserted by Lucas. This shows that Lucas himself is subject to the same limits that he describes for machines, as are all people, and soLucas's argument is pointless. After concluding that human reasoning is non-computable, Penrose went on to controversially speculate that some kind of hypothetical non-computable processes involving the collapse ofquantum mechanicalstates give humans a special advantage over existing computers. Existing quantum computers are only capable of reducing the complexity of Turing computable tasks and are still restricted to tasks within the scope of Turing machines.. By Penrose and Lucas's arguments, the fact that quantum computers are only able to complete Turing computable tasks implies that they cannot be sufficient for emulating the human mind.Therefore, Penrose seeks for some other process involving new physics, for instance quantum gravity which might manifest new physics at the scale of thePlanck massvia spontaneous quantum collapse of the wave function. These states, he suggested, occur both within neurons and also spanning more than one neuron.However, other scientists point out that there is no plausible organic mechanism in the brain for harnessing any sort of quantum computation, and furthermore that the timescale of quantum decoherence seems too fast to influence neuron firing. Hubert Dreyfusargued that human intelligenceand expertise depended primarily on fast intuitive judgements rather than step-by-step symbolic manipulation, and argued that these skills would never be captured in formal rules. Dreyfus's argument had been anticipated by Turing in his 1950 paperComputing machinery and intelligence, where he had classified this as the \"argument from the informality of behavior.\"Turing argued in response that, just because we do not know the rules that govern a complex behavior, this does not mean that no such rules exist. He wrote: \"we cannot so easily convince ourselves of the absence of complete laws of behaviour ... The only way we know of for finding such laws is scientific observation, and we certainly know of no circumstances under which we could say, 'We have searched enough. There are no such laws.'\" Russell and Norvig point out that, in the years since Dreyfus published his critique, progress has been made towards discovering the \"rules\" that govern unconscious reasoning.Thesituatedmovement inroboticsresearch attempts to capture our unconscious skills at perception and attention.Computational intelligenceparadigms, such asneural nets,evolutionary algorithmsand so on are mostly directed at simulated unconscious reasoning and learning.Statistical approaches to AIcan make predictions which approach the accuracy of human intuitive guesses. Research intocommonsense knowledgehas focused on reproducing the \"background\" or context of knowledge. In fact, AI research in general has moved away from high level symbol manipulation, towards new models that are intended to capture more of ourintuitivereasoning. Cognitive science and psychology eventually came to agree with Dreyfus' description of human expertise.Daniel Kahnemannand others developed a similar theory where they identified two \"systems\" that humans use to solve problems, which he called \"System 1\" (fast intuitive judgements) and \"System 2\" (slow deliberate step by step thinking). Although Dreyfus' views have been vindicated in many ways, the work in cognitive science and in AI was in response to specific problems in those fields and was not directly influenced by Dreyfus. Historian and AI researcherDaniel Crevierwrote that \"time has proven the accuracy and perceptiveness of some of Dreyfus's comments. Had he formulated them less aggressively, constructive actions they suggested might have been taken much earlier.\" This is a philosophical question, related to theproblem of other mindsand thehard problem of consciousness. The question revolves around a position defined byJohn Searleas \"strong AI\": Searle distinguished this position from what he called \"weak AI\": Searle introduced the terms to isolate strong AI from weak AI so he could focus on what he thought was the more interesting and debatable issue. He argued thateven if we assumethat we had a computer program that acted exactly like a human mind, there would still be a difficult philosophical question that needed to be answered. Neither of Searle's two positions are of great concern to AI research, since they do not directly answer the question \"can a machine display general intelligence?\" (unless it can also be shown that consciousness isnecessaryfor intelligence). Turing wrote \"I do not wish to give the impression that I think there is no mystery about consciousness… [b]ut I do not think these mysteries necessarily need to be solved before we can answer the question [of whether machines can think].\"Russelland Norvig agree: \"Most AI researchers take the weak AI hypothesis for granted, and don't care about the strong AI hypothesis.\" There are a few researchers who believe that consciousness is an essential element in intelligence, such asIgor Aleksander,Stan Franklin,Ron Sun, andPentti Haikonen, although their definition of \"consciousness\" strays very close to \"intelligence\". (Seeartificial consciousness.) Before we can answer this question, we must be clear what we mean by \"minds\", \"mental states\" and \"consciousness\". The words \"mind\" and \"consciousness\" are used by different communities in different ways. Somenew agethinkers, for example, use the word \"consciousness\" to describe something similar toBergson's \"élan vital\": an invisible, energetic fluid that permeates life and especially the mind.Science fictionwriters use the word to describe someessentialproperty that makes us human: a machine or alien that is \"conscious\" will be presented as a fully human character, with intelligence, desires,will, insight, pride and so on. (Science fiction writers also use the words \"sentience\", \"sapience\", \"self-awareness\" or \"ghost\"—as in theGhost in the Shellmanga and anime series—to describe this essential human property). For others, the words \"mind\" or \"consciousness\" are used as a kind of secular synonym for thesoul. Forphilosophers,neuroscientistsandcognitive scientists, the words are used in a way that is both more precise and more mundane: they refer to the familiar, everyday experience of having a \"thought in your head\", like a perception, a dream, an intention or a plan, and to the way weseesomething,knowsomething,meansomething orunderstandsomething.\"It's not hard to give a commonsense definition of consciousness\" observes philosopher John Searle.What is mysterious and fascinating is not so muchwhatit is buthowit is: how does a lump of fatty tissue and electricity give rise to this (familiar) experience of perceiving, meaning or thinking? Philosophers call this thehard problem of consciousness. It is the latest version of a classic problem in thephilosophy of mindcalled the \"mind-body problem\".A related problem is the problem ofmeaningorunderstanding(which philosophers call \"intentionality\"): what is the connection between ourthoughtsandwhat we are thinking about(i.e. objects and situations out in the world)? A third issue is the problem ofexperience(or \"phenomenology\"): If two people see the same thing, do they have the same experience? Or are there things \"inside their head\" (called \"qualia\") that can be different from person to person? Neurobiologistsbelieve all these problems will be solved as we begin to identify theneural correlates of consciousness: the actual relationship between the machinery in our heads and its collective properties; such as the mind, experience and understanding. Some of the harshest critics ofartificial intelligenceagree that the brain is just a machine, and that consciousness and intelligence are the result of physical processes in the brain.The difficult philosophical question is this: can a computer program, running on a digital machine that shuffles the binary digits of zero and one, duplicate the ability of theneuronsto create minds, with mental states (like understanding or perceiving), and ultimately, the experience of consciousness? John Searleasks us to consider athought experiment: suppose we have written a computer program that passes the Turing test and demonstrates general intelligent action. Suppose, specifically that the program can converse in fluent Chinese. Write the program on 3x5 cards and give them to an ordinary person who does not speak Chinese. Lock the person into a room and have him follow the instructions on the cards. He will copy out Chinese characters and pass them in and out of the room through a slot. From the outside, it will appear that theChinese roomcontains a fully intelligent person who speaks Chinese. The question is this: is there anyone (or anything) in the room that understands Chinese? That is, is there anything that has the mental state ofunderstanding, or which hasconsciousawarenessof what is being discussed in Chinese? The man is clearly not aware. The room cannot be aware. Thecardscertainly are not aware. Searle concludes that the Chinese room, oranyother physical symbol system, cannot have a mind. Searle goes on to argue that actual mental states andconsciousnessrequire (yet to be described) \"actual physical-chemical properties of actual human brains.\"He argues there are special \"causal properties\" ofbrainsandneuronsthat gives rise tominds: in his words \"brains cause minds.\" Gottfried Leibnizmade essentially the same argument as Searle in 1714, using the thought experiment of expanding the brain until it was the size of a mill.In 1974,Lawrence Davisimagined duplicating the brain using telephone lines and offices staffed by people, and in 1978Ned Blockenvisioned the entire population of China involved in such a brain simulation. This thought experiment is called \"the Chinese Nation\" or \"the Chinese Gym\".Ned Block also proposed hisBlockhead argument, which is a version of theChinese roomin which the program has beenre-factoredinto a simple set of rules of the form \"see this, do that\", removing all mystery from the program. Responses to the Chinese room emphasize several different points. Thecomputational theory of mindor \"computationalism\" claims that the relationship between mind and brain is similar (if not identical) to the relationship between arunning program(software) and a computer (hardware). The idea has philosophical roots inHobbes(who claimed reasoning was \"nothing more than reckoning\"),Leibniz(who attempted to create a logical calculus of all human ideas),Hume(who thought perception could be reduced to \"atomic impressions\") and evenKant(who analyzed all experience as controlled by formal rules).The latest version is associated with philosophersHilary PutnamandJerry Fodor. This question bears on our earlier questions: if the human brain is a kind of computer then computers can be both intelligent and conscious, answering both the practical and philosophical questions of AI. In terms of the practical question of AI (\"Can a machine display general intelligence?\"), some versions of computationalism make the claim that (asHobbeswrote): In other words, our intelligence derives from a form ofcalculation, similar toarithmetic. This is thephysical symbol systemhypothesis discussed above, and it implies that artificial intelligence is possible. In terms of the philosophical question of AI (\"Can a machine have mind, mental states and consciousness?\"), most versions ofcomputationalismclaim that (asStevan Harnadcharacterizes it): This is John Searle's \"strong AI\" discussed above, and it is the real target of theChinese roomargument (according toHarnad). If \"emotions\" are defined only in terms of their effect onbehavioror on how theyfunctioninside an organism, then emotions can be viewed as a mechanism that anintelligent agentuses to maximize theutilityof its actions. Given this definition of emotion,Hans Moravecbelieves that \"robots in general will be quite emotional about being nice people\".Fear is a source of urgency. Empathy is a necessary component of goodhuman computer interaction. He says robots \"will try to please you in an apparently selfless manner because it will get a thrill out of this positive reinforcement. You can interpret this as a kind of love.\"Daniel Crevierwrites \"Moravec's point is that emotions are just devices for channeling behavior in a direction beneficial to the survival of one's species.\" \"Self-awareness\", as noted above, is sometimes used byscience fictionwriters as a name for theessentialhuman property that makes a character fully human.Turingstrips away all other properties of human beings and reduces the question to \"can a machine be the subject of its own thought?\" Can itthink about itself? Viewed in this way, a program can be written that can report on its own internal states, such as adebugger. Turing reduces this to the question of whether a machine can \"take us by surprise\" and argues that this is obviously true, as any programmer can attest.He notes that, with enough storage capacity, a computer can behave in an astronomical number of different ways.It must be possible, even trivial, for a computer that can represent ideas to combine them in new ways. (Douglas Lenat'sAutomated Mathematician, as one example, combined ideas to discover new mathematical truths.)Kaplanand Haenlein suggest that machines can display scientific creativity, while it seems likely that humans will have the upper hand where artistic creativity is concerned. In 2009, scientists at Aberystwyth University in Wales and the U.K's University of Cambridge designed a robot called Adam that they believe to be the first machine to independently come up with new scientific findings.Also in 2009, researchers atCornelldevelopedEureqa, a computer program that extrapolates formulas to fit the data inputted, such as finding the laws of motion from a pendulum's motion. This question (like many others in the philosophy of artificial intelligence) can be presented in two forms. \"Hostility\" can be defined in termsfunctionorbehavior, in which case \"hostile\" becomes synonymous with \"dangerous\". Or it can be defined in terms of intent: can a machine \"deliberately\" set out to do harm? The latter is the question \"can a machine have conscious states?\" (such asintentions) in another form. The question of whether highly intelligent and completely autonomous machines would be dangerous has been examined in detail by futurists (such as theMachine Intelligence Research Institute). The obvious element of drama has also made the subject popular inscience fiction, which has considered many differently possible scenarios where intelligent machines pose a threat to mankind; seeArtificial intelligence in fiction. One issue is that machines may acquire the autonomy and intelligence required to be dangerous very quickly.Vernor Vingehas suggested that over just a few years, computers will suddenly become thousands or millions of times more intelligent than humans. He calls this \"the Singularity\".He suggests that it may be somewhat or possibly very dangerous for humans.This is discussed by a philosophy calledSingularitarianism. In 2009, academics and technical experts attended a conference to discuss the potential impact of robots and computers and the impact of the hypothetical possibility that they could become self-sufficient and able tomake their own decisions. They discussed the possibility and the extent to which computers and robots might be able to acquire any level of autonomy, and to what degree they could use such abilities to possibly pose any threat or hazard. They noted that some machines have acquired various forms of semi-autonomy, including being able to find power sources on their own and being able to independently choose targets to attack with weapons. They also noted that somecomputer virusescan evade elimination and have achieved \"cockroach intelligence\". They noted thatself-awarenessas depicted in science-fiction is probably unlikely, but that there were other potential hazards and pitfalls. Some experts and academics have questioned the use of robots for military combat, especially when such robots are given some degree of autonomous functions.The US Navy has funded a report which indicates that as military robots become more complex, there should be greater attention to implications of their ability to make autonomous decisions. The President of theAssociation for the Advancement of Artificial Intelligencehas commissioned a study to look at this issue.They point to programs like the Language Acquisition Device which can emulate human interaction. Some have suggested a need to build \"Friendly AI\", a term coined byEliezer Yudkowsky, meaning that the advances which are already occurring with AI should also include an effort to make AI intrinsically friendly and humane. Turing said \"It is customary ... to offer a grain of comfort, in the form of a statement that some peculiarly human characteristic could never be imitated by a machine. ... I cannot offer any such comfort, for I believe that no such bounds can be set.\" Turing noted that there are many arguments of the form \"a machine will never do X\", where X can be many things, such as: Be kind, resourceful, beautiful, friendly, have initiative, have a sense of humor, tell right from wrong, make mistakes, fall in love, enjoy strawberries and cream, make someone fall in love with it, learn from experience, use words properly, be the subject of its own thought, have as much diversity of behaviour as a man, do something really new. Turing argues that these objections are often based on naive assumptions about the versatility of machines or are \"disguised forms of the argument from consciousness\". Writing a program that exhibits one of these behaviors \"will not make much of an impression.\"All of these arguments are tangential to the basic premise of AI, unless it can be shown that one of these traits is essential for general intelligence. Finally, those who believe in the existence of a soul may argue that \"Thinking is a function of man'simmortalsoul.\" Alan Turing called this \"the theological objection\". He writes: In attempting to construct such machines we should not be irreverently usurping His power of creating souls, any more than we are in the procreation of children: rather we are, in either case, instruments of His will providing mansions for the souls that He creates. The discussion on the topic has been reignited as a result of recent claims made byGoogle's LaMDA artificialintelligencesystem that it is sentient and had a \"soul\". LaMDA(Language Modelfor Dialogue Applications) is anartificial intelligence systemthat createschatbots—AI robots designed to communicate with humans—by gathering vast amounts of text from the internet and usingalgorithmsto respond to queries in the most fluid and natural way possible. The transcripts of conversations between scientists and LaMDA reveal that the AI system excels at this, providing answers to challenging topics about the nature ofemotions, generatingAesop-style fables on the moment, and even describing its alleged fears.Pretty much all philosophers doubt LaMDA's sentience. Some scholars argue that the AI community's dismissal of philosophy is detrimental. In theStanford Encyclopedia of Philosophy, some philosophers argue that the role of philosophy in AI is underappreciated.PhysicistDavid Deutschargues that without an understanding of philosophy or its concepts, AI development would suffer from a lack of progress. The main conference series on the issue is\"Philosophy and Theory of AI\"(PT-AI), run byVincent C. Müller. The main bibliography on the subject, with several sub-sections, is onPhilPapers. A recent survey forPhilosophy of AIis Müller (2025).", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Philosophy_of_artificial_intelligence", "https://en.wikipedia.org/wiki/Philosophy_of_artificial_intelligence", "https://en.wikipedia.org/wiki/Philosophy_of_artificial_intelligence", "https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence", "https://en.wikipedia.org/wiki/Artificial_intelligence", "https://en.wikipedia.org/wiki/Artificial_general_intelligence", "https://en.wikipedia.org/wiki/Intelligent_agent", "https://en.wikipedia.org/wiki/Recursive_self-improvement"]},
{"id": "eb87665b8956", "url": "https://en.wikipedia.org/wiki/Machine_learning_in_physics", "title": "Machine learning in physics", "headings": ["Contents", "Applications of machine learning to physics", "Noisy data", "Calculated and noise-free data", "Variational circuits", "Sign problem", "Fluid dynamics", "Physics discovery and prediction", "See also", "References"], "content": "Applyingmachine learning(ML) (includingdeep learning) methods to the study of quantum systems is an emergent area of physics research. A basic example of this isquantum state tomography, where a quantum state is learned from measurement.Other examples include learning Hamiltonians,learning quantumphase transitions,and automatically generating new quantum experiments.ML is effective at processing large amounts of experimental or calculated data in order to characterize an unknown quantum system, making its application useful in contexts includingquantum information theory, quantum technology development, and computational materials design. In this context, for example, it can be used as a tool to interpolate pre-calculatedinteratomic potentials,or directly solving theSchrödinger equationwith avariational method. The ability to experimentally control and prepare increasingly complex quantum systems brings with it a growing need to turn large and noisy data sets into meaningful information. This is a problem that has already been studied extensively in the classical setting, and consequently, many existing machine learning techniques can be naturally adapted to more efficiently address experimentally relevant problems. For example,Bayesianmethods and concepts ofalgorithmic learningcan be fruitfully applied to tackle quantum state classification,Hamiltonian learning,and the characterization of an unknownunitary transformation.Other problems that have been addressed with this approach are given in the following list: Quantum machine learning can also be applied to dramatically accelerate the prediction of quantum properties of molecules and materials.This can be helpful for the computational design of new molecules or materials. Some examples include Variational circuits are a family of algorithms which utilize training based on circuit parameters and an objective function.Variational circuits are generally composed of a classical device communicating input parameters (random or pre-trained parameters) into a quantum device, along with a classicalMathematical optimizationfunction. These circuits are very heavily dependent on the architecture of the proposed quantum device because parameter adjustments are adjusted based solely on the classical components within the device.Though the application is considerably infantile in the field of quantum machine learning, it has incredibly high promise for more efficiently generating efficient optimization functions. Machine learning techniques can be used to find a better manifold of integration for path integrals in order to avoid the sign problem. Adeep learningsystem was reported to learn intuitive physics from visual data (of virtual 3D environments) based on anunpublishedapproach inspired by studies of visual cognition in infants.Other researchers have developed a machine learning algorithm that could discover sets of basic variables of various physical systems and predict the systems' future dynamics from video recordings of their behavior.In the future, it may be possible that such can be used to automate the discovery of physical laws of complex systems.Beyond discovery and prediction, \"blank slate\"-type of learning of fundamental aspects of the physical world may have further applications such as improving adaptive and broadartificial general intelligence.In specific, prior machine learning models were \"highly specialised and lack a general understanding of the world\".", "combined_text": "Machine learning in physics Contents Applications of machine learning to physics Noisy data Calculated and noise-free data Variational circuits Sign problem Fluid dynamics Physics discovery and prediction See also References Applyingmachine learning(ML) (includingdeep learning) methods to the study of quantum systems is an emergent area of physics research. A basic example of this isquantum state tomography, where a quantum state is learned from measurement.Other examples include learning Hamiltonians,learning quantumphase transitions,and automatically generating new quantum experiments.ML is effective at processing large amounts of experimental or calculated data in order to characterize an unknown quantum system, making its application useful in contexts includingquantum information theory, quantum technology development, and computational materials design. In this context, for example, it can be used as a tool to interpolate pre-calculatedinteratomic potentials,or directly solving theSchrödinger equationwith avariational method. The ability to experimentally control and prepare increasingly complex quantum systems brings with it a growing need to turn large and noisy data sets into meaningful information. This is a problem that has already been studied extensively in the classical setting, and consequently, many existing machine learning techniques can be naturally adapted to more efficiently address experimentally relevant problems. For example,Bayesianmethods and concepts ofalgorithmic learningcan be fruitfully applied to tackle quantum state classification,Hamiltonian learning,and the characterization of an unknownunitary transformation.Other problems that have been addressed with this approach are given in the following list: Quantum machine learning can also be applied to dramatically accelerate the prediction of quantum properties of molecules and materials.This can be helpful for the computational design of new molecules or materials. Some examples include Variational circuits are a family of algorithms which utilize training based on circuit parameters and an objective function.Variational circuits are generally composed of a classical device communicating input parameters (random or pre-trained parameters) into a quantum device, along with a classicalMathematical optimizationfunction. These circuits are very heavily dependent on the architecture of the proposed quantum device because parameter adjustments are adjusted based solely on the classical components within the device.Though the application is considerably infantile in the field of quantum machine learning, it has incredibly high promise for more efficiently generating efficient optimization functions. Machine learning techniques can be used to find a better manifold of integration for path integrals in order to avoid the sign problem. Adeep learningsystem was reported to learn intuitive physics from visual data (of virtual 3D environments) based on anunpublishedapproach inspired by studies of visual cognition in infants.Other researchers have developed a machine learning algorithm that could discover sets of basic variables of various physical systems and predict the systems' future dynamics from video recordings of their behavior.In the future, it may be possible that such can be used to automate the discovery of physical laws of complex systems.Beyond discovery and prediction, \"blank slate\"-type of learning of fundamental aspects of the physical world may have further applications such as improving adaptive and broadartificial general intelligence.In specific, prior machine learning models were \"highly specialised and lack a general understanding of the world\".", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Machine_learning_in_physics", "https://en.wikipedia.org/wiki/Machine_learning_in_physics", "https://en.wikipedia.org/wiki/Machine_learning_in_physics", "https://en.wikipedia.org/wiki/Quantum_machine_learning", "https://en.wikipedia.org/wiki/Quantum_mechanics", "https://en.wikipedia.org/wiki/Schr%C3%B6dinger_equation", "https://en.wikipedia.org/wiki/Introduction_to_quantum_mechanics", "https://en.wikipedia.org/wiki/Glossary_of_elementary_quantum_mechanics"]},
{"id": "14267942afd7", "url": "https://en.wikipedia.org/wiki/Machine_translation", "title": "Machine translation", "headings": ["Contents", "History", "Origins", "1950s", "1960–1975", "1975-1980s", "1990s and early 2000s", "ANNs & LLMs in 2020s", "Approaches", "Rule-based", "Statistical", "Neural MT", "Issues", "Disambiguation", "Non-standard speech", "Named entities", "Applications", "Travel", "Public administration", "Wikipedia", "Surveillance and military", "Social media", "Medicine", "Law", "Ancient languages", "Evaluation", "Machine translation and signed languages", "Copyright", "See also", "Notes", "Further reading", "External links"], "content": " Machine translationis the use of computational techniques totranslatetext or speech from onelanguageto another, including the contextual, idiomatic, and pragmatic nuances of both languages. Machine translation tools, while some language models are capable of generating comprehensible results, remain limited by the complexity of language and emotion, often lacking depth and semantic precision. Its quality is influenced by linguistic, grammatical, tonal, and cultural differences, making it inadequate to replace real translators fully.Effective improvement requires understanding the target society’s customs and historical context, human intervention and visual cues remain necessary insimultaneous interpretation, on the other hand, domain-specific customization, such as for technical documentation or official texts—can yield more stable results, and is commonly employed in multilingual websites and professional databases. Early approaches were mostlyrule-basedorstatistical. These methods have since been superseded byneural machine translationandlarge language models. The origins of machine translation can be traced back to the work ofAl-Kindi, a ninth-century Arabiccryptographerwho developed techniques for systemic language translation, includingcryptanalysis,frequency analysis, andprobabilityandstatistics, which are used in modern machine translation.The idea of machine translation later appeared in the 17th century. In 1629,René Descartesproposed a universal language, with equivalent ideas in different tongues sharing one symbol. The idea of using digital computers for translation of natural languages was proposed as early as 1947 by England'sA. D. BoothandWarren WeaveratRockefeller Foundationin the same year. \"The memorandum written byWarren Weaverin 1949 is perhaps the single most influential publication in the earliest days of machine translation.\"Others followed. A demonstration was made in 1954 on theAPEXCmachine atBirkbeck College(University of London) of a rudimentary translation of English into French. Several papers on the topic were published at the time, and even articles in popular journals (for example an article by Cleave and Zacharov in the September 1955 issue ofWireless World).  A similar application, also pioneered at Birkbeck College at the time, was reading and composingBrailletexts by computer. The first researcher in the field,Yehoshua Bar-Hillel, began his research at MIT (1951). AGeorgetown UniversityMT research team, led by Professor Michael Zarechnak, followed (1951) with a public demonstration of itsGeorgetown-IBM experimentsystem in 1954. MT research programs popped up in Japanand Russia (1955), and the first MT conference was held in London (1956). David G. Hays\"wrote about computer-assisted language processing as early as 1957\" and \"was project leader on computational linguistics\natRandfrom 1955 to 1968.\" Researchers continued to join the field as the Association for Machine Translation and Computational Linguistics was formed in the U.S. (1962) and the National Academy of Sciences formed the Automatic Language Processing Advisory Committee (ALPAC) to study MT (1964). Real progress was much slower, however, and after theALPAC report(1966), which found that the ten-year-long research had failed to fulfill expectations, funding was greatly reduced.According to a 1972 report by the Director of Defense Research and Engineering (DDR&E), the feasibility of large-scale MT was reestablished by the success of the Logos MT system in translating military manuals into Vietnamese during that conflict. The French Textile Institute also used MT to translate abstracts from and into French, English, German and Spanish (1970); Brigham Young University started a project to translate Mormon texts by automated translation (1971). SYSTRAN, which \"pioneered the field under contracts from the U.S. government\"in the 1960s, was used by Xerox to translate technical manuals (1978). Beginning in the late 1980s, ascomputationalpower increased and became less expensive, more interest was shown instatistical models for machine translation. MT became more popular after the advent of computers.SYSTRAN's first implementation system was implemented in 1988 by the online service of theFrench Postal Servicecalled Minitel.Various computer based translation companies were also launched, including Trados (1984), which was the first to develop and market Translation Memory technology (1989), though this is not the same as MT. The first commercial MT system for Russian / English / German-Ukrainian was developed at Kharkov State University (1991). By 1998, \"for as little as $29.95\" one could \"buy a program for translating in one direction between English and a major European language of\nyour choice\" to run on a PC. MT on the web started with SYSTRAN offering free translation of small texts (1996) and then providing this viaAltaVista Babelfish,which racked up 500,000 requests a day (1997).The second free translation service on the web wasLernout & Hauspie's GlobaLink.Atlantic Magazinewrote in 1998 that \"Systran's Babelfish and GlobaLink's Comprende\" handled\n\"Don't bank on it\" with a \"competent performance.\" Franz Josef Och(the future head of Translation Development AT Google) won DARPA's speed MT competition (2003).More innovations during this time included MOSES, the open-source statistical MT engine (2007), a text/SMS translation service for mobiles in Japan (2008), and a mobile phone with built-in speech-to-speech translation functionality for English, Japanese and Chinese (2009). In 2012, Google announced thatGoogle Translatetranslates roughly enough text to fill 1 million books in one day. Before the advent ofdeep learningmethods, statistical methods required a lot of rules accompanied bymorphological,syntactic, andsemanticannotations. The rule-based machine translation approach was used mostly in the creation ofdictionariesand grammar programs. Its biggest downfall was that everything had to be made explicit: orthographical variation and erroneous input must be made part of the source language analyser in order to cope with it, and lexical selection rules must be written for all instances of ambiguity. Transfer-based machine translation was similar tointerlingual machine translationin that it created a translation from an intermediate representation that simulated the meaning of the original sentence. Unlike interlingual MT, it depended partially on the language pair involved in the translation. Interlingual machine translation was one instance of rule-based machine-translation approaches.  In this approach, the source language, i.e. the text to be translated, was transformed into an interlingual language, i.e. a \"language neutral\" representation that is independent of any language. The target language was then generated out of theinterlingua. The only interlingual machine translation system that was made operational at the commercial level was the KANT system (Nyberg and Mitamura, 1992), which was designed to translate Caterpillar Technical English (CTE) into other languages. Machine translation used a method based ondictionaryentries, which means that the words were translated as they are by a dictionary. Statistical machine translation tried to generate translations usingstatistical methodsbased on bilingual text corpora, such as theCanadian Hansardcorpus, the English-French record of the Canadian parliament andEUROPARL, the record of theEuropean Parliament. Where such corpora were available, good results were achieved translating similar texts, but such corpora were rare for many language pairs. The first statistical machine translation software wasCANDIDEfromIBM. In 2005, Google improved its internal translation capabilities by using approximately 200 billion words from United Nations materials to train their system; translation accuracy improved. SMT's biggest downfall included it being dependent upon huge amounts of parallel texts, its problems with morphology-rich languages (especially with translatingintosuch languages), and its inability to correct singleton errors. Some work has been done in the utilization of multiparallelcorpora, that is a body of text that has been translated into 3 or more languages. Using these methods, a text that has been translated into 2 or more languages may be utilized in combination to provide a more accurate translation into a third language compared with if just one of those source languages were used alone. Adeep learning-based approach to MT,neural machine translationhas made rapid progress in recent years. However, the current consensus is that the so-called human parity achieved is not real, being based wholly on limited domains, language pairs, and certain test benchmarksi.e., it lacks statistical significance power. Translations by neural MT tools likeDeepL Translator, which is thought to usually deliver the best machine translation results as of 2022, typically still need post-editing by a human. Instead of training specialized translation models on parallel datasets, one can alsodirectly promptgenerativelarge language modelslikeGPTto translate a text.This approach is considered promising,but is still more resource-intensive than specialized translation models. Studies using human evaluation (e.g. by professional literary translators or human readers) havesystematically identified various issueswith the latest advanced MT outputs.Some quality evaluation studies have found that, in several languages, human translations outperform ChatGPT-produced translations in terminological accuracy and clarity of expression.Common issues include the translation of ambiguous parts whose correct translation requires common sense-like semantic language processing or context.There can also be errors in the source texts, missing high-quality training data and the severity of frequency of several types of problems may not get reduced with techniques used to date, requiring some level of human active participation. Word-sense disambiguation concerns finding a suitable translation when a word can have more than one meaning. The problem was first raised in the 1950s byYehoshua Bar-Hillel.He pointed out that without a \"universal encyclopedia\", a machine would never be able to distinguish between the two meanings of a word.Today there are numerous approaches designed to overcome this problem. They can be approximately divided into \"shallow\" approaches and \"deep\" approaches. Shallow approaches assume no knowledge of the text. They simply apply statistical methods to the words surrounding the ambiguous word. Deep approaches presume a comprehensive knowledge of the word. So far, shallow approaches have been more successful. Claude Piron, a long-time translator for the United Nations and theWorld Health Organization, wrote that machine translation, at its best, automates the easier part of a translator's job; the harder and more time-consuming part usually involves doing extensive research to resolveambiguitiesin thesource text, which thegrammaticalandlexicalexigencies of thetarget languagerequire to be resolved: Why does a translator need a whole workday to translate five pages, and not an hour or two? ..... About 90% of an average text corresponds to these simple conditions.  But unfortunately, there's the other 10%.  It's that part that requires six [more] hours of work.  There are ambiguities one has to resolve.  For instance, the author of the source text, an Australian physician, cited the example of an epidemic which was declared during World War II in a \"Japanese prisoners of war camp\".  Was he talking about an American camp with Japanese prisoners or a Japanese camp with American prisoners?  The English has two senses.  It's necessary therefore to do research, maybe to the extent of a phone call to Australia. The ideal deep approach would require the translation software to do all the research necessary for this kind of disambiguation on its own; but this would require a higher degree ofAIthan has yet been attained.  A shallow approach which simply guessed at the sense of the ambiguous English phrase that Piron mentions (based, perhaps, on which kind of prisoner-of-war camp is more often mentioned in a given corpus) would have a reasonable chance of guessing wrong fairly often.  A shallow approach that involves \"ask the user about each ambiguity\" would, by Piron's estimate, only automate about 25% of a professional translator's job, leaving the harder 75% still to be done by a human. One of the major pitfalls of MT is its inability to translate non-standard language with the same accuracy as standard language. Heuristic or statistical based MT takes input from various sources in standard form of a language. Rule-based translation, by nature, does not include common non-standard usages. This causes errors in translation from a vernacular source or into colloquial language. Limitations on translation from casual speech present issues in the use of machine translation in mobile devices. Ininformation extraction, named entities, in a narrow sense, refer to concrete or abstract entities in the real world such as people, organizations, companies, and places that have a proper name: George Washington, Chicago, Microsoft.  It also refers to expressions of time, space and quantity such as 1 July 2011, $500. In the sentence \"Smith is the president of Fabrionix\" bothSmithandFabrionixare named entities, and can be further qualified via first name or other information; \"president\" is not, since Smith could have earlier held another position at Fabrionix, e.g. Vice President.\nThe termrigid designatoris what defines these usages for analysis in statistical machine translation. Named entities must first be identified in the text; if not, they may be erroneously translated as common nouns, which would most likely not affect theBLEUrating of the translation but would change the text's human readability.They may be omitted from the output translation, which would also have implications for the text's readability and message. Transliterationincludes finding the letters in the target language that most closely correspond to the name in the source language.  This, however, has been cited as sometimes worsening the quality of translation.For \"Southern California\" the first word should be translated directly, while the second word should be transliterated.  Machines often transliterate both because they treated them as one entity.  Words like these are hard for machine translators, even those with a transliteration component, to process. Use of a \"do-not-translate\" list, which has the same end goal – transliteration as opposed to translation.still relies on correct identification of named entities. A third approach is a class-based model. Named entities are replaced with a token to represent their \"class\"; \"Ted\"  and \"Erica\" would both be replaced with \"person\" class token. Then the statistical distribution and use of person names, in general, can be analyzed instead of looking at the distributions of \"Ted\" and \"Erica\" individually, so that the probability of a given name in a specific language will not affect the assigned probability of a translation. A study by Stanford on improving this area of translation gives the examples that different probabilities will be assigned to \"David is going for a walk\" and \"Ankit is going for a walk\" for English as a target language due to the different number of occurrences for each name in the training data. A frustrating outcome of the same study by Stanford (and other attempts to improve named recognition translation) is that many times, a decrease in theBLEUscores for translation will result from the inclusion of methods for named entity translation. While no system provides the ideal of fully automatic high-quality machine translation of unrestricted text, many fully automated systems produce reasonable output.The quality of machine translation is substantially improved if the domain is restricted and controlled.This enables using machine translation as a tool to speed up and simplify translations, as well as producing flawed but useful low-cost or ad-hoc translations. Machine translation applications have also been released for most mobile devices, including mobile telephones, pocket PCs, PDAs, etc. Due to their portability, such instruments have come to be designated asmobile translationtools enabling mobile business networking between partners speaking different languages, or facilitating both foreign language learning and unaccompanied traveling to foreign countries without the need of the intermediation of a human translator. For example, the Google Translate app allows foreigners to quickly translate text in their surrounding viaaugmented realityusing the smartphone camera that overlays the translated text onto the text.It can alsorecognize speechand then translate it. Despite their inherent limitations, MT programs are used around the world. Probably the largest institutional user is theEuropean Commission. In 2012, with an aim to replace a rule-based MT by newer, statistical-based MT@EC, The European Commission contributed 3.072 million euros (via its ISA programme). Machine translation has also been used for translatingWikipediaarticles and could play a larger role in creating, updating, expanding, and generally improving articles in the future, especially as the MT capabilities may improve. There is a \"content translation tool\" which allows editors to more easily translate articles across several select languages.English-language articles are thought to usually be more comprehensive and less biased than their non-translated equivalents in other languages.As of 2022,English Wikipediahas over 6.5 million articles while, for example, theGermanandSwedish Wikipediaseach only have over 2.5 million articles,each often far less comprehensive. Following terrorist attacks in Western countries, including9-11, the U.S. and its allies have been most interested in developingArabic machine translationprograms, but also in translatingPashtoandDarilanguages.Within these languages, the focus is on key phrases and quick communication between military members and civilians through the use of mobile phone apps.The Information Processing Technology Office inDARPAhosted programs likeTIDESandBabylon translator. US Air Force has awarded a $1 million contract to develop a language translation technology. The notable rise ofsocial networkingon the web in recent years has created yet another niche for the application of machine translation software – in utilities such asFacebook, orinstant messagingclients such asSkype,Google Talk,MSN Messenger, etc. – allowing users speaking different languages to communicate with each other. Lineage Wgained popularity in Japan because of its machine translation features allowing players from different countries to communicate. Despite being labelled as an unworthy competitor to human translation in 1966 by the Automated Language Processing Advisory Committee put together by the United States government,the quality of machine translation has now been improved to such levels that its application in online collaboration and in the medical field are being investigated. The application of this technology in medical settings where human translators are absent is another topic of research, but difficulties arise due to the importance of accurate translations in medical diagnoses. Researchers caution that the use of machine translation in medicine could risk mistranslations that can be dangerous in critical situations.Machine translation can make it easier for doctors to communicate with their patients in day to day activities, but it is recommended to only use machine translation when there is no other alternative, and that translated medical texts should be reviewed by human translators for accuracy. Legal languageposes a significant challenge to machine translation tools due to its precise nature and atypical use of normal words. For this reason, specialized algorithms have been developed for use in legal contexts.Due to the risk of mistranslations arising from machine translators, researchers recommend that machine translations should be reviewed by human translators for accuracy, and some courts prohibit its use informal proceedings. The use of machine translation in law has raised concerns about translation errors andclient confidentiality. Lawyers who use free translation tools such as Google Translate may accidentally violate client confidentiality by exposing private information to the providers of the translation tools.In addition, there have been arguments that consent for a police search that is obtained with machine translation is invalid, with different courts issuing different verdicts over whether or not these arguments are valid. The advancements inconvolutional neural networksin recent years and in low resource machine translation (when only a very limited amount of data and examples are available for training) enabled machine translation for ancient languages, such asAkkadianand its dialects Babylonian and Assyrian. There are many factors that affect how machine translation systems are evaluated. These factors include the intended use of the translation, the nature of the machine translation software, and the nature of the translation process. Different programs may work well for different purposes. For example,statistical machine translation(SMT) typically outperformsexample-based machine translation(EBMT), but researchers found that when evaluating English to French translation, EBMT performs better.The same concept applies for technical documents, which can be more easily translated by SMT because of their formal language. In certain applications, however, e.g., product descriptions written in acontrolled language, adictionary-based machine-translationsystem has produced satisfactory translations that require no human intervention save for quality inspection. There are various means for evaluating the output quality of machine translation systems. The oldest is the use of human judgesto assess a translation's quality. Even though human evaluation is time-consuming, it is still the most reliable method to compare different systems such as rule-based and statistical systems.Automatedmeans of evaluation includeBLEU,NIST,METEOR, andLEPOR. Relying exclusively on unedited machine translation ignores the fact that communication inhuman languageis context-embedded and that it takes a person to comprehend thecontextof the original text with a reasonable degree of probability. It is certainly true that even purely human-generated translations are prone to error. Therefore, to ensure that a machine-generated translation will be useful to a human being and that publishable-quality translation is achieved, such translations must be reviewed and edited by a human.The lateClaude Pironwrote that machine translation, at its best, automates the easier part of a translator's job; the harder and more time-consuming part usually involves doing extensive research to resolveambiguitiesin thesource text, which thegrammaticalandlexicalexigencies of the target language require to be resolved. Such research is a necessary prelude to the pre-editing necessary in order to provide input for machine-translation software such that the output will not bemeaningless. In addition to disambiguation problems, decreased accuracy can occur due to varying levels of training data for machine translating programs. Both example-based and statistical machine translation rely on a vast array of real example sentences as a base for translation, and when too many or too few sentences are analyzed accuracy is jeopardized. Researchers found that when a program is trained on 203,529 sentence pairings, accuracy actually decreases.The optimal level of training data seems to be just over 100,000 sentences, possibly because as training data increases, the number of possible sentences increases, making it harder to find an exact translation match. Flaws in machine translation have been noted fortheir entertainment value. Two videos uploaded toYouTubein April 2017 involve two Japanesehiraganacharacters えぐ (eandgu) being repeatedly pasted into Google Translate, with the resulting translations quickly degrading into nonsensical phrases such as \"DECEARING EGG\" and \"Deep-sea squeeze trees\", which are then read in increasingly absurd voices;the full-length version of the video currently has 7.1 million views as of August 2025. In the early 2000s, options for machine translation between spoken and signed languages were severely limited. It was a common belief that deaf individuals could use traditional translators. However, stress, intonation, pitch, and timing are conveyed much differently in spoken languages compared to signed languages. Therefore, a deaf individual may misinterpret or become confused about the meaning of written text that is based on a spoken language. Researchers Zhao, et al. (2000), developed a prototype called TEAM (translation from English to ASL by machine) that completed English toAmerican Sign Language(ASL) translations. The program would first analyze the syntactic, grammatical, and morphological aspects of the English text. Following this step, the program accessed a sign synthesizer, which acted as a dictionary for ASL. This synthesizer housed the process one must follow to complete ASL signs, as well as the meanings of these signs. Once the entire text is analyzed and the signs necessary to complete the translation are located in the synthesizer, a computer generated human appeared and would use ASL to sign the English text to the user. Onlyworksthat areoriginalare subject tocopyrightprotection, so some scholars claim that machine translation results are not entitled to copyright protection because MT does not involvecreativity.The copyright at issue is for aderivative work; the author of theoriginal workin the original language does not lose hisrightswhen a work is translated: a translator must have permission topublisha translation.", "combined_text": "Machine translation Contents History Origins 1950s 1960–1975 1975-1980s 1990s and early 2000s ANNs & LLMs in 2020s Approaches Rule-based Statistical Neural MT Issues Disambiguation Non-standard speech Named entities Applications Travel Public administration Wikipedia Surveillance and military Social media Medicine Law Ancient languages Evaluation Machine translation and signed languages Copyright See also Notes Further reading External links  Machine translationis the use of computational techniques totranslatetext or speech from onelanguageto another, including the contextual, idiomatic, and pragmatic nuances of both languages. Machine translation tools, while some language models are capable of generating comprehensible results, remain limited by the complexity of language and emotion, often lacking depth and semantic precision. Its quality is influenced by linguistic, grammatical, tonal, and cultural differences, making it inadequate to replace real translators fully.Effective improvement requires understanding the target society’s customs and historical context, human intervention and visual cues remain necessary insimultaneous interpretation, on the other hand, domain-specific customization, such as for technical documentation or official texts—can yield more stable results, and is commonly employed in multilingual websites and professional databases. Early approaches were mostlyrule-basedorstatistical. These methods have since been superseded byneural machine translationandlarge language models. The origins of machine translation can be traced back to the work ofAl-Kindi, a ninth-century Arabiccryptographerwho developed techniques for systemic language translation, includingcryptanalysis,frequency analysis, andprobabilityandstatistics, which are used in modern machine translation.The idea of machine translation later appeared in the 17th century. In 1629,René Descartesproposed a universal language, with equivalent ideas in different tongues sharing one symbol. The idea of using digital computers for translation of natural languages was proposed as early as 1947 by England'sA. D. BoothandWarren WeaveratRockefeller Foundationin the same year. \"The memorandum written byWarren Weaverin 1949 is perhaps the single most influential publication in the earliest days of machine translation.\"Others followed. A demonstration was made in 1954 on theAPEXCmachine atBirkbeck College(University of London) of a rudimentary translation of English into French. Several papers on the topic were published at the time, and even articles in popular journals (for example an article by Cleave and Zacharov in the September 1955 issue ofWireless World).  A similar application, also pioneered at Birkbeck College at the time, was reading and composingBrailletexts by computer. The first researcher in the field,Yehoshua Bar-Hillel, began his research at MIT (1951). AGeorgetown UniversityMT research team, led by Professor Michael Zarechnak, followed (1951) with a public demonstration of itsGeorgetown-IBM experimentsystem in 1954. MT research programs popped up in Japanand Russia (1955), and the first MT conference was held in London (1956). David G. Hays\"wrote about computer-assisted language processing as early as 1957\" and \"was project leader on computational linguistics\natRandfrom 1955 to 1968.\" Researchers continued to join the field as the Association for Machine Translation and Computational Linguistics was formed in the U.S. (1962) and the National Academy of Sciences formed the Automatic Language Processing Advisory Committee (ALPAC) to study MT (1964). Real progress was much slower, however, and after theALPAC report(1966), which found that the ten-year-long research had failed to fulfill expectations, funding was greatly reduced.According to a 1972 report by the Director of Defense Research and Engineering (DDR&E), the feasibility of large-scale MT was reestablished by the success of the Logos MT system in translating military manuals into Vietnamese during that conflict. The French Textile Institute also used MT to translate abstracts from and into French, English, German and Spanish (1970); Brigham Young University started a project to translate Mormon texts by automated translation (1971). SYSTRAN, which \"pioneered the field under contracts from the U.S. government\"in the 1960s, was used by Xerox to translate technical manuals (1978). Beginning in the late 1980s, ascomputationalpower increased and became less expensive, more interest was shown instatistical models for machine translation. MT became more popular after the advent of computers.SYSTRAN's first implementation system was implemented in 1988 by the online service of theFrench Postal Servicecalled Minitel.Various computer based translation companies were also launched, including Trados (1984), which was the first to develop and market Translation Memory technology (1989), though this is not the same as MT. The first commercial MT system for Russian / English / German-Ukrainian was developed at Kharkov State University (1991). By 1998, \"for as little as $29.95\" one could \"buy a program for translating in one direction between English and a major European language of\nyour choice\" to run on a PC. MT on the web started with SYSTRAN offering free translation of small texts (1996) and then providing this viaAltaVista Babelfish,which racked up 500,000 requests a day (1997).The second free translation service on the web wasLernout & Hauspie's GlobaLink.Atlantic Magazinewrote in 1998 that \"Systran's Babelfish and GlobaLink's Comprende\" handled\n\"Don't bank on it\" with a \"competent performance.\" Franz Josef Och(the future head of Translation Development AT Google) won DARPA's speed MT competition (2003).More innovations during this time included MOSES, the open-source statistical MT engine (2007), a text/SMS translation service for mobiles in Japan (2008), and a mobile phone with built-in speech-to-speech translation functionality for English, Japanese and Chinese (2009). In 2012, Google announced thatGoogle Translatetranslates roughly enough text to fill 1 million books in one day. Before the advent ofdeep learningmethods, statistical methods required a lot of rules accompanied bymorphological,syntactic, andsemanticannotations. The rule-based machine translation approach was used mostly in the creation ofdictionariesand grammar programs. Its biggest downfall was that everything had to be made explicit: orthographical variation and erroneous input must be made part of the source language analyser in order to cope with it, and lexical selection rules must be written for all instances of ambiguity. Transfer-based machine translation was similar tointerlingual machine translationin that it created a translation from an intermediate representation that simulated the meaning of the original sentence. Unlike interlingual MT, it depended partially on the language pair involved in the translation. Interlingual machine translation was one instance of rule-based machine-translation approaches.  In this approach, the source language, i.e. the text to be translated, was transformed into an interlingual language, i.e. a \"language neutral\" representation that is independent of any language. The target language was then generated out of theinterlingua. The only interlingual machine translation system that was made operational at the commercial level was the KANT system (Nyberg and Mitamura, 1992), which was designed to translate Caterpillar Technical English (CTE) into other languages. Machine translation used a method based ondictionaryentries, which means that the words were translated as they are by a dictionary. Statistical machine translation tried to generate translations usingstatistical methodsbased on bilingual text corpora, such as theCanadian Hansardcorpus, the English-French record of the Canadian parliament andEUROPARL, the record of theEuropean Parliament. Where such corpora were available, good results were achieved translating similar texts, but such corpora were rare for many language pairs. The first statistical machine translation software wasCANDIDEfromIBM. In 2005, Google improved its internal translation capabilities by using approximately 200 billion words from United Nations materials to train their system; translation accuracy improved. SMT's biggest downfall included it being dependent upon huge amounts of parallel texts, its problems with morphology-rich languages (especially with translatingintosuch languages), and its inability to correct singleton errors. Some work has been done in the utilization of multiparallelcorpora, that is a body of text that has been translated into 3 or more languages. Using these methods, a text that has been translated into 2 or more languages may be utilized in combination to provide a more accurate translation into a third language compared with if just one of those source languages were used alone. Adeep learning-based approach to MT,neural machine translationhas made rapid progress in recent years. However, the current consensus is that the so-called human parity achieved is not real, being based wholly on limited domains, language pairs, and certain test benchmarksi.e., it lacks statistical significance power. Translations by neural MT tools likeDeepL Translator, which is thought to usually deliver the best machine translation results as of 2022, typically still need post-editing by a human. Instead of training specialized translation models on parallel datasets, one can alsodirectly promptgenerativelarge language modelslikeGPTto translate a text.This approach is considered promising,but is still more resource-intensive than specialized translation models. Studies using human evaluation (e.g. by professional literary translators or human readers) havesystematically identified various issueswith the latest advanced MT outputs.Some quality evaluation studies have found that, in several languages, human translations outperform ChatGPT-produced translations in terminological accuracy and clarity of expression.Common issues include the translation of ambiguous parts whose correct translation requires common sense-like semantic language processing or context.There can also be errors in the source texts, missing high-quality training data and the severity of frequency of several types of problems may not get reduced with techniques used to date, requiring some level of human active participation. Word-sense disambiguation concerns finding a suitable translation when a word can have more than one meaning. The problem was first raised in the 1950s byYehoshua Bar-Hillel.He pointed out that without a \"universal encyclopedia\", a machine would never be able to distinguish between the two meanings of a word.Today there are numerous approaches designed to overcome this problem. They can be approximately divided into \"shallow\" approaches and \"deep\" approaches. Shallow approaches assume no knowledge of the text. They simply apply statistical methods to the words surrounding the ambiguous word. Deep approaches presume a comprehensive knowledge of the word. So far, shallow approaches have been more successful. Claude Piron, a long-time translator for the United Nations and theWorld Health Organization, wrote that machine translation, at its best, automates the easier part of a translator's job; the harder and more time-consuming part usually involves doing extensive research to resolveambiguitiesin thesource text, which thegrammaticalandlexicalexigencies of thetarget languagerequire to be resolved: Why does a translator need a whole workday to translate five pages, and not an hour or two? ..... About 90% of an average text corresponds to these simple conditions.  But unfortunately, there's the other 10%.  It's that part that requires six [more] hours of work.  There are ambiguities one has to resolve.  For instance, the author of the source text, an Australian physician, cited the example of an epidemic which was declared during World War II in a \"Japanese prisoners of war camp\".  Was he talking about an American camp with Japanese prisoners or a Japanese camp with American prisoners?  The English has two senses.  It's necessary therefore to do research, maybe to the extent of a phone call to Australia. The ideal deep approach would require the translation software to do all the research necessary for this kind of disambiguation on its own; but this would require a higher degree ofAIthan has yet been attained.  A shallow approach which simply guessed at the sense of the ambiguous English phrase that Piron mentions (based, perhaps, on which kind of prisoner-of-war camp is more often mentioned in a given corpus) would have a reasonable chance of guessing wrong fairly often.  A shallow approach that involves \"ask the user about each ambiguity\" would, by Piron's estimate, only automate about 25% of a professional translator's job, leaving the harder 75% still to be done by a human. One of the major pitfalls of MT is its inability to translate non-standard language with the same accuracy as standard language. Heuristic or statistical based MT takes input from various sources in standard form of a language. Rule-based translation, by nature, does not include common non-standard usages. This causes errors in translation from a vernacular source or into colloquial language. Limitations on translation from casual speech present issues in the use of machine translation in mobile devices. Ininformation extraction, named entities, in a narrow sense, refer to concrete or abstract entities in the real world such as people, organizations, companies, and places that have a proper name: George Washington, Chicago, Microsoft.  It also refers to expressions of time, space and quantity such as 1 July 2011, $500. In the sentence \"Smith is the president of Fabrionix\" bothSmithandFabrionixare named entities, and can be further qualified via first name or other information; \"president\" is not, since Smith could have earlier held another position at Fabrionix, e.g. Vice President.\nThe termrigid designatoris what defines these usages for analysis in statistical machine translation. Named entities must first be identified in the text; if not, they may be erroneously translated as common nouns, which would most likely not affect theBLEUrating of the translation but would change the text's human readability.They may be omitted from the output translation, which would also have implications for the text's readability and message. Transliterationincludes finding the letters in the target language that most closely correspond to the name in the source language.  This, however, has been cited as sometimes worsening the quality of translation.For \"Southern California\" the first word should be translated directly, while the second word should be transliterated.  Machines often transliterate both because they treated them as one entity.  Words like these are hard for machine translators, even those with a transliteration component, to process. Use of a \"do-not-translate\" list, which has the same end goal – transliteration as opposed to translation.still relies on correct identification of named entities. A third approach is a class-based model. Named entities are replaced with a token to represent their \"class\"; \"Ted\"  and \"Erica\" would both be replaced with \"person\" class token. Then the statistical distribution and use of person names, in general, can be analyzed instead of looking at the distributions of \"Ted\" and \"Erica\" individually, so that the probability of a given name in a specific language will not affect the assigned probability of a translation. A study by Stanford on improving this area of translation gives the examples that different probabilities will be assigned to \"David is going for a walk\" and \"Ankit is going for a walk\" for English as a target language due to the different number of occurrences for each name in the training data. A frustrating outcome of the same study by Stanford (and other attempts to improve named recognition translation) is that many times, a decrease in theBLEUscores for translation will result from the inclusion of methods for named entity translation. While no system provides the ideal of fully automatic high-quality machine translation of unrestricted text, many fully automated systems produce reasonable output.The quality of machine translation is substantially improved if the domain is restricted and controlled.This enables using machine translation as a tool to speed up and simplify translations, as well as producing flawed but useful low-cost or ad-hoc translations. Machine translation applications have also been released for most mobile devices, including mobile telephones, pocket PCs, PDAs, etc. Due to their portability, such instruments have come to be designated asmobile translationtools enabling mobile business networking between partners speaking different languages, or facilitating both foreign language learning and unaccompanied traveling to foreign countries without the need of the intermediation of a human translator. For example, the Google Translate app allows foreigners to quickly translate text in their surrounding viaaugmented realityusing the smartphone camera that overlays the translated text onto the text.It can alsorecognize speechand then translate it. Despite their inherent limitations, MT programs are used around the world. Probably the largest institutional user is theEuropean Commission. In 2012, with an aim to replace a rule-based MT by newer, statistical-based MT@EC, The European Commission contributed 3.072 million euros (via its ISA programme). Machine translation has also been used for translatingWikipediaarticles and could play a larger role in creating, updating, expanding, and generally improving articles in the future, especially as the MT capabilities may improve. There is a \"content translation tool\" which allows editors to more easily translate articles across several select languages.English-language articles are thought to usually be more comprehensive and less biased than their non-translated equivalents in other languages.As of 2022,English Wikipediahas over 6.5 million articles while, for example, theGermanandSwedish Wikipediaseach only have over 2.5 million articles,each often far less comprehensive. Following terrorist attacks in Western countries, including9-11, the U.S. and its allies have been most interested in developingArabic machine translationprograms, but also in translatingPashtoandDarilanguages.Within these languages, the focus is on key phrases and quick communication between military members and civilians through the use of mobile phone apps.The Information Processing Technology Office inDARPAhosted programs likeTIDESandBabylon translator. US Air Force has awarded a $1 million contract to develop a language translation technology. The notable rise ofsocial networkingon the web in recent years has created yet another niche for the application of machine translation software – in utilities such asFacebook, orinstant messagingclients such asSkype,Google Talk,MSN Messenger, etc. – allowing users speaking different languages to communicate with each other. Lineage Wgained popularity in Japan because of its machine translation features allowing players from different countries to communicate. Despite being labelled as an unworthy competitor to human translation in 1966 by the Automated Language Processing Advisory Committee put together by the United States government,the quality of machine translation has now been improved to such levels that its application in online collaboration and in the medical field are being investigated. The application of this technology in medical settings where human translators are absent is another topic of research, but difficulties arise due to the importance of accurate translations in medical diagnoses. Researchers caution that the use of machine translation in medicine could risk mistranslations that can be dangerous in critical situations.Machine translation can make it easier for doctors to communicate with their patients in day to day activities, but it is recommended to only use machine translation when there is no other alternative, and that translated medical texts should be reviewed by human translators for accuracy. Legal languageposes a significant challenge to machine translation tools due to its precise nature and atypical use of normal words. For this reason, specialized algorithms have been developed for use in legal contexts.Due to the risk of mistranslations arising from machine translators, researchers recommend that machine translations should be reviewed by human translators for accuracy, and some courts prohibit its use informal proceedings. The use of machine translation in law has raised concerns about translation errors andclient confidentiality. Lawyers who use free translation tools such as Google Translate may accidentally violate client confidentiality by exposing private information to the providers of the translation tools.In addition, there have been arguments that consent for a police search that is obtained with machine translation is invalid, with different courts issuing different verdicts over whether or not these arguments are valid. The advancements inconvolutional neural networksin recent years and in low resource machine translation (when only a very limited amount of data and examples are available for training) enabled machine translation for ancient languages, such asAkkadianand its dialects Babylonian and Assyrian. There are many factors that affect how machine translation systems are evaluated. These factors include the intended use of the translation, the nature of the machine translation software, and the nature of the translation process. Different programs may work well for different purposes. For example,statistical machine translation(SMT) typically outperformsexample-based machine translation(EBMT), but researchers found that when evaluating English to French translation, EBMT performs better.The same concept applies for technical documents, which can be more easily translated by SMT because of their formal language. In certain applications, however, e.g., product descriptions written in acontrolled language, adictionary-based machine-translationsystem has produced satisfactory translations that require no human intervention save for quality inspection. There are various means for evaluating the output quality of machine translation systems. The oldest is the use of human judgesto assess a translation's quality. Even though human evaluation is time-consuming, it is still the most reliable method to compare different systems such as rule-based and statistical systems.Automatedmeans of evaluation includeBLEU,NIST,METEOR, andLEPOR. Relying exclusively on unedited machine translation ignores the fact that communication inhuman languageis context-embedded and that it takes a person to comprehend thecontextof the original text with a reasonable degree of probability. It is certainly true that even purely human-generated translations are prone to error. Therefore, to ensure that a machine-generated translation will be useful to a human being and that publishable-quality translation is achieved, such translations must be reviewed and edited by a human.The lateClaude Pironwrote that machine translation, at its best, automates the easier part of a translator's job; the harder and more time-consuming part usually involves doing extensive research to resolveambiguitiesin thesource text, which thegrammaticalandlexicalexigencies of the target language require to be resolved. Such research is a necessary prelude to the pre-editing necessary in order to provide input for machine-translation software such that the output will not bemeaningless. In addition to disambiguation problems, decreased accuracy can occur due to varying levels of training data for machine translating programs. Both example-based and statistical machine translation rely on a vast array of real example sentences as a base for translation, and when too many or too few sentences are analyzed accuracy is jeopardized. Researchers found that when a program is trained on 203,529 sentence pairings, accuracy actually decreases.The optimal level of training data seems to be just over 100,000 sentences, possibly because as training data increases, the number of possible sentences increases, making it harder to find an exact translation match. Flaws in machine translation have been noted fortheir entertainment value. Two videos uploaded toYouTubein April 2017 involve two Japanesehiraganacharacters えぐ (eandgu) being repeatedly pasted into Google Translate, with the resulting translations quickly degrading into nonsensical phrases such as \"DECEARING EGG\" and \"Deep-sea squeeze trees\", which are then read in increasingly absurd voices;the full-length version of the video currently has 7.1 million views as of August 2025. In the early 2000s, options for machine translation between spoken and signed languages were severely limited. It was a common belief that deaf individuals could use traditional translators. However, stress, intonation, pitch, and timing are conveyed much differently in spoken languages compared to signed languages. Therefore, a deaf individual may misinterpret or become confused about the meaning of written text that is based on a spoken language. Researchers Zhao, et al. (2000), developed a prototype called TEAM (translation from English to ASL by machine) that completed English toAmerican Sign Language(ASL) translations. The program would first analyze the syntactic, grammatical, and morphological aspects of the English text. Following this step, the program accessed a sign synthesizer, which acted as a dictionary for ASL. This synthesizer housed the process one must follow to complete ASL signs, as well as the meanings of these signs. Once the entire text is analyzed and the signs necessary to complete the translation are located in the synthesizer, a computer generated human appeared and would use ASL to sign the English text to the user. Onlyworksthat areoriginalare subject tocopyrightprotection, so some scholars claim that machine translation results are not entitled to copyright protection because MT does not involvecreativity.The copyright at issue is for aderivative work; the author of theoriginal workin the original language does not lose hisrightswhen a work is translated: a translator must have permission topublisha translation.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Machine_translation", "https://en.wikipedia.org/wiki/Machine_translation", "https://en.wikipedia.org/wiki/Machine_translation", "https://en.wikipedia.org/wiki/Computer-assisted_translation", "https://en.wikipedia.org/wiki/Interactive_machine_translation", "https://en.wikipedia.org/wiki/Translator_(computing)", "https://en.wikipedia.org/wiki/Translation", "https://en.wikipedia.org/wiki/Legal_translation"]},
{"id": "68e25256b70c", "url": "https://en.wikipedia.org/wiki/Artificial_intelligence_arms_race", "title": "Artificial intelligence arms race", "headings": ["Contents", "Terminology", "History", "Risks", "By nation", "United States", "China", "India", "Russia", "Israel", "United Kingdom", "South Korea", "Saudi Arabia", "United Arab Emirates", "European Union", "Proposals for international regulation", "Other reactions to autonomous weapons", "Disassociation", "Rankings", "See also", "References", "Further reading"], "content": "Donald TrumpJoe BidenBarack ObamaElon MuskSundar PichaiJensen HuangSam AltmanSatya NadellaAndy JassyTim CookLisa SuMark ZuckerbergAlexandr Wang Xi JinpingHu JintaoJiang ZeminJack MaRobin LiLiang WenfengPony MaDaniel ZhangRen ZhengfeiTan RuisongLei Jun United StatesGoogleNvidiaStargateOpenAIMicrosoftAmazonAppleTeslaMetaIBMxAIIntelBroadcomAnthropicAMDOracleFigure AILockheed MartinPalantirCoreWeavePerplexity AIAndurilCiscoSalesforce ChinaBaiduDeepSeekTencentAlibabaHuaweiSenseTimeiFlytekAlphaXiaomiMegviiYMTCSilanAVIC Est. $300 billion(USA, over the last decade) Est. $200 billion (China, over the last decade) AI regulation(USA)DataprivacyandsecurityissuesAIbiasandfairness China's Data Security Law A militaryartificial intelligence arms raceis an economic and military competition between two or more states to develop and deploy advancedAItechnologies andlethal autonomous weaponssystems (LAWS). The goal is to gain a strategic or tactical advantage over rivals, similar to previous arms races involving nuclear or conventional military technologies. Since the mid-2010s, many analysts have noted the emergence of such an arms race betweensuperpowersfor better AI technology andmilitary AI,driven byincreasing geopolitical and military tensions. An AI arms race is sometimes placed in the context of anAI Cold Warbetween theUnited StatesandChina.Several influential figures and publications have emphasized that whoever developsartificial general intelligence(AGI) first could dominate global affairs in the 21st century. Russian PresidentVladimir Putinfamously stated that the leader in AI will \"rule the world.\"Experts and analysts—from researchers likeLeopold Aschenbrennerto institutions like Lawfare and Foreign Policy—warn that the AGI race between major powers like the U.S. and China could reshape geopolitical power.This includes AI for surveillance, autonomous weapons, decision-making systems, cyber operations, and more. Lethal autonomous weaponssystems use artificial intelligence to identify and kill human targets without human intervention.LAWS have colloquially been called \"slaughterbots\" or \"killer robots\". Broadly, any competition for superior AI is sometimes framed as an \"arms race\".Advantages in military AI overlap with advantages in other sectors, as countries pursue both economic and military advantages, as per previous arms races throughout history. In 2014, AI specialistSteve Omohundrowarned that \"An autonomous weapons arms race is already taking place\".According toSiemens, worldwide military spending on robotics was US$5.1 billion in 2010 and US$7.5 billion in 2015. China became a top player in artificial intelligence research in the 2010s. According to theFinancial Times, in 2016, for the first time, China published more AI research papers than the entire European Union. When restricted to number of AI papers in the top 5% of cited papers, China overtook the United States in 2016 but lagged behind the European Union.23% of the researchers presenting at the 2017American Association for the Advancement of Artificial Intelligence(AAAI) conference were Chinese.Eric Schmidt, the former chairman and chief executive officer ofAlphabet, has predicted China will be the leading country in AI by 2025. One risk concerns the AI race itself, whether or not the race is won by any one group. There are strong incentives for development teams to cut corners with regard to the safety of the system, increasing the risk of critical failures and unintended consequences.This is in part due to the perceived advantage of being the first to develop advanced AI technology. One team appearing to be on the brink of a breakthrough can encourage other teams to take shortcuts, ignore precautions and deploy a system that is less ready. Some argue that using \"race\" terminology at all in this context can exacerbate this effect. Another potential danger of an AI arms race is the possibility of losing control of the AI systems; the risk is compounded in the case of a race toartificial general intelligence, which may present anexistential risk.In 2023, aUnited States Air Forceofficial reportedly said that during acomputer test, a simulated AI drone killed the human character operating it. The USAF later said the official had misspoken and that it never conducted such simulations. A third risk of an AI arms race is whether or not the race is actually won by one group. The concern is regarding the consolidation of power and technological advantage in the hands of one group.A US government report argued that \"AI-enabled capabilities could be used to threaten  critical infrastructure, amplify disinformation campaigns, and wage war\", and that \"global stability and nuclear deterrence could be undermined\". In 2014, former Secretary of DefenseChuck Hagelposited the \"Third Offset Strategy\" that rapid advances in artificial intelligence will define the next generation of warfare.According to data science and analytics firm Govini, the U.S.Department of Defense(DoD) increased investment in artificial intelligence, big data and cloud computing from $5.6 billion in 2011 to $7.4 billion in 2016.However, the civilianNSFbudget for AI saw no increase in 2017.Japan Timesreported in 2018 that the United States private investment is around $70 billion per year.The November 2019 'Interim Report' of the United States' National Security Commission on Artificial Intelligence confirmed that AI is critical to US technological military superiority. The U.S. has many military AI combat programs, such as theSea Hunterautonomous warship, which is designed to operate for extended periods at sea without a single crew member, and to even guide itself in and out of port.From 2017, a temporary US Department of Defense directive requires a human operator to be kept in the loop when it comes to the taking of human life by autonomous weapons systems.On October 31, 2019, the United States Department of Defense's Defense Innovation Board published the draft of a report recommending principles for the ethical use of artificial intelligence by the Department of Defense that would ensure a human operator would always be able to look into the 'black box' and understand thekill-chainprocess. However, a major concern is how the report will be implemented. The Joint Artificial Intelligence Center (JAIC) (pronounced \"jake\")is an American organization on exploring the usage of AI (particularlyedge computing),Network of Networks, and AI-enhanced communication, for use in actual combat.It is a subdivision of theUnited States Armed Forcesand was created in June 2018. The organization's stated objective is to \"transform theUS Department of Defenseby accelerating the delivery and adoption of AI to achieve mission impact at scale. The goal is to use AI to solve large and complex problem sets that span multiple combat systems; then, ensure the combat Systems and Components have real-time access to ever-improving libraries of data sets and tools.\" In 2023, Microsoft pitched the DoD to useDALL-Emodels to train itsbattlefield management system.OpenAI, thedeveloperof DALL-E, removed the blanket ban on military and warfare use from its usage policies in January 2024.TheBiden administrationimposed restrictions on the export of advanced NVIDIA chips and GPUs to China in an effort to limit China's progress in artificial intelligence and high-performance computing. The policy aimed to prevent the use of cutting-edge U.S. technology in military or surveillance applications and to maintain a strategic advantage in the global AI race. In 2025, under thesecond Trump administration, the United States began a broad deregulation campaign aimed at accelerating growth in sectors critical to artificial intelligence, including nuclear energy, infrastructure, and high-performance computing.The goal was to remove regulatory barriers and attract private investment to boost domestic AI capabilities. This included easing restrictions on data usage, speeding up approvals for AI-related infrastructure projects, and incentivizing innovation in cloud computing and semiconductors. Companies like NVIDIA, Oracle, and Cisco played a central role in these efforts, expanding their AI research, data center capacity, and partnerships to help position the U.S. as a global leader in AI development. Project Maven is aPentagonproject involving using machine learning and engineering talent to distinguish people and objects in drone videos,apparently giving the government real-time battlefield command and control, and the ability to track, tag and spy on targets without human involvement. Initially the effort was led byRobert O. Workwho was concerned about China's military use of the emerging technology.Reportedly, Pentagon development stops short of acting as an AI weapons system capable of firing on self-designated targets.The project was established in a memo by theU.S. Deputy Secretary of Defenseon 26 April 2017.Also known as theAlgorithmic Warfare Cross Functional Team,it is, according to Lt. Gen. of theUnited States Air ForceJack Shanahan in November 2017, a project \"designed to be that pilot project, that pathfinder, that spark that kindles the flame front of artificial intelligence across the rest of the [Defense] Department\".Its chief,U.S. Marine CorpsCol. Drew Cukor, said: \"People and computers will work symbiotically to increase the ability of weapon systems to detect objects.\"Project Maven has been noted by allies, such as Australia'sIan Langford, for the ability to identify adversaries by harvesting data from sensors onUAVsand satellite.At the secondDefense OneTech Summit in July 2017, Cukor also said that the investment in a \"deliberate workflow process\" was funded by the Department [of Defense] through its \"rapid acquisition authorities\" for about \"the next 36 months\". The U.S.Department of Defenseis partnering with Ukraine on \"Project Artemis\" to develop advanced drones that can withstand electronic warfare, blending Ukrainian simplicity and adaptability with American precision. Due to theRussia-Ukraine war, Ukraine has emerged as a leader in drone production and warfare, creating cost-effective systems that challenge traditional approaches. Countries like Turkey, China, and Iran are also producing affordable drones, reducing America's monopoly and reshaping warfare dynamics. U.S. efforts are focused on integrating AI,drone swarmtechnology, and hybrid drone systems to maintain military dominance. The democratization of drone technology raises issues, such as autonomous decision-making, counter-drone defenses, and dual-use concerns, that challenge ethical and security norms. The Stargate Projectis a joint venture announced in 2025 by OpenAI CEO Sam Altman, U.S. President Donald Trump, Oracle Corporation, MGX, SoftBank Group, and other partners. The initiative aims to develop large-scale artificial intelligence (AI) infrastructure in the United States, with a projected $500 billion investment by 2029. The project focuses on building advanced data centers, custom AI hardware, and sustainable energy systems, while also supporting research, workforce development, and national AI competitiveness. It is considered an effort to position the U.S. as a global leader in AI technology.The program has been compared to theManhattan Projectbecause of its large scale. China is pursuing a strategic policy ofmilitary-civil fusionon AI for globaltechnological supremacy.According to a February 2019 report by Gregory C. Allen of theCenter for a New American Security,China'sleadership– includingGeneral Secretary of the Chinese Communist PartyXi Jinping– believes that being at the forefront in AI technology is critical to the future of global military and economic power competition.Chinese military officials have said that their goal is to incorporate commercial AI technology to \"narrow the gap between the Chinese military and global advanced powers.\"The close ties between Silicon Valley and China, and the open nature of the American research community, has made the West's most advanced AI technology easily available to China; in addition, Chinese industry has numerous home-grown AI accomplishments of its own, such asBaidupassing a notable Chinese-language speech recognition capability benchmark in 2015.As of 2017, Beijing's roadmap aims to create a $150 billion AI industry by 2030.Before 2013, Chinese defense procurement was mainly restricted to a few conglomerates; however, as of 2017, China often sources sensitive emerging technology such as drones and artificial intelligence from private start-up companies.An October 2021 report by theCenter for Security and Emerging Technologyfound that \"Most of the [Chinese military]'s AI equipment suppliers are not state-owned defense enterprises, but private Chinese tech companies founded after 2010.\"The report estimated that Chinese military spending on AI exceeded $1.6 billion each year.TheJapan Timesreported in 2018 that annual private Chinese investment in AI is under $7 billion per year. AI startups in China received nearly half of total global investment in AI startups in 2017; the Chinese filed for nearly five times as many AI patents as did Americans. China published a position paper in 2016 questioning the adequacy of existing international law to address the eventuality of fully autonomous weapons, becoming the first permanent member of theU. N. Security Councilto broach the issue.In 2018, CCP general secretaryXi Jinpingcalled for greater international cooperation in basic AI research.Chinese officials have expressed concern that AI such as drones could lead to accidental war, especially in the absence of international norms.In 2019, formerUnited States Secretary of DefenseMark Esperlashed out at China for selling drones capable of taking life with no human oversight. The focus on \"intelligentized AI warfare\", pursued by China, suggests a comprehensive integration of AI across all domains (land, sea, air, space, and cyber) for autonomous attack, defence and cognitive warfare.The intelligentized strategy is distinct from traditional warfare, which focuses on network-centric operations, and instead sees AI as a force multiplier that enhances decision-making, command structures, and autonomous capabilities. Unlike traditional warfare, intelligentization leverages AI to create a cognitive advantage—allowing it to process battlefield information better. AI-assisted command-and-control (C2) systems, predictive analytics, and real-time data fusion, enabling accelerated human-AI hybrid decision-making.\nAutonomous systems, including drone swarms, AI-powered cyber warfare, play a crucial role in this strategy.\nChina is reported to be currently developing wingman drones, robotic ground forces, and optimised logistics to enhance combat effectiveness.TheChinese army (PLA)) also emphasisescognitive warfareusing AI-driven psychological operations, social media manipulation, and predictive behavioural analysis to influence adversaries and the importance of dynamic responses where AI enhances hacking capabilities, automated SIGINT (Signals Intelligence) and adaptive tactics. However, despite this focus, some analysts believe China could be struggling to fully realise AI capability within the military environment: a \"comprehensive review of dozens of Chinese-language journal articles about AI and warfare reveals that Chinese defense experts claim that Beijing is facing several technological challenges that may hinder its ability to capitalize on the advantages provided by military AI\" A task force for the Strategic Implementation of AI for National Security and Defence was established in February 2018 by theMinistry of Defense's Department of Defence Production.The process of getting the military ready for AI use was started by theMoDin 2019.TheCentre for Artificial Intelligence and Roboticswas approved to develop AI solutions to improveintelligence collectionand analysis capabilities.In 2021, theIndian Army, with assistance from theNational Security Council, began operating the Quantum Lab and Artificial Intelligence Center at theMilitary College of Telecommunication Engineering. With an emphasis on robotics and artificial intelligence,Defence Research and Development OrganisationandIndian Institute of Scienceestablished the Joint Advanced Technology Programme-Center of Excellence.In 2022, theIndian Navycreated an AI Core group and set up a Center of Excellence for AI andBig Data analysisatINS Valsura.Indian Army incubated Artificial Intelligence Offensive Drone Operations Project.During Exercise Dakshin Shakti 2021, the Indian Army integrated AI into itsintelligence,surveillance, andreconnaissancearchitecture. In 2022, the Indian government established theDefence Artificial Intelligence Counciland theDefence AI Project Agency,and it also published a list of 75 defense-related AI priority projects.MoDearmarked₹1,000croreannually till 2026 for capacity building, infrastructure setup, data preparation, and Al project implementation.The Indian Army, the Indian Navy and theIndian Air Forceset aside ₹100 crore annually for the development of AI-specific applications.The military is already deploying some AI-enabled projects and equipment.At Air Force Station Rajokri, theIAFCentre of Excellence for Artificial Intelligence was established in 2022 as part of the Unit for Digitization, Automation, Artificial Intelligence, and Application Networking (UDAAN).Swarm drone systemswere introduced by theMechanised Infantry Regimentfor offensive operations close to theLine of Actual Control. For offensive operations, the military began acquiring AI-enabledUAVsandswarm drones.Bharat Electronicsdeveloped AI-enabled audio transcription and analysis software for battlefield communication. Using AI during transport operations, the Indian Army's Research & Development branch patented driver tiredness monitoring system.As part of initial investment, theIndian Armed Forcesis investing about $50 million (€47.2 million) yearly on AI, according to Delhi Policy Group.Forhigh altitudelogisticsat forward outposts,military robotsare deployed.Army is developing autonomous combat vehicles, robotic surveillance platforms, and Manned-Unmanned Teaming (MUM-T) solutions as part of the Defence AI roadmap.MCTEis working with theMinistry of Electronics and Information Technologyand,Society for Applied Microwave Electronics Engineering & Research, on AI and military-gradechipset.Phase III of AI-enabled space-based surveillance has been authorized. DRDOChairman and Secretary of the Department of Defense Research & Development Samir V. Kamat said the agency started concentrating on the potential use of AI in the development of military systems and subsystems.The Indian government intends to leverage the private sector's sizable AI workforce anddual-use technologiesfor defense by 2026.In order to conduct research on autonomous platforms, improved surveillance,predictive maintenance, andintelligent decision support system, the Indian Army AI Incubation Center was established.Indian Navy launchedINS Suratwith AI capabilities. Russian GeneralViktor Bondarev, commander-in-chief of the Russian air force, stated that as early as February 2017, Russia was working on AI-guided missiles that could decide to switch targets mid-flight.TheMilitary-Industrial Commission of Russiahas approved plans to derive 30 percent of Russia's combat power from remote controlled and AI-enabled robotic platforms by 2030.Reports by state-sponsored Russian media on potential military uses of AI increased in mid-2017.In May 2017, the CEO of Russia's Kronstadt Group, a defense contractor, stated that \"there already exist completely autonomous AI operation systems that provide the means for UAV clusters, when they fulfill missions autonomously, sharing tasks between them, and interact\", and that it is inevitable that \"swarms of drones\" will one day fly over combat zones.Russia has been testing several autonomous and semi-autonomous combat systems, such asKalashnikov's \"neural net\" combat module, with a machine gun, a camera, and an AI that its makers claim can make its own targeting judgements without human intervention. In September 2017, during a National Knowledge Day address to over a million students in 16,000 Russian schools, Russian PresidentVladimir Putinstated \"Artificial intelligence is the future, not only for Russia but for all humankind... Whoever becomes the leader in this sphere will become the ruler of the world\". Putin also said it would be better to prevent any single actor achieving a monopoly, but that if Russia became the leader in AI, they would share their \"technology with the rest of the world, like we are doing now with atomic and nuclear technology\". Russia is establishing a number of organizations devoted to the development of military AI. In March 2018, the Russian government released a 10-point AI agenda, which calls for the establishment of an AI and Big Data consortium, a Fund for Analytical Algorithms and Programs, a state-backed AI training and education program, a dedicated AI lab, and a National Center for Artificial Intelligence, among other initiatives.In addition, Russia recently created a defense research organization, roughly equivalent to DARPA, dedicated to autonomy and robotics called the Foundation for Advanced Studies, and initiated an annual conference on \"Robotization of the Armed Forces of the Russian Federation.\" The Russian military has been researching a number of AI applications, with a heavy emphasis on semiautonomous and autonomous vehicles. In an official statement on November 1, 2017, Viktor Bondarev, chairman of the Federation Council's Defense and Security Committee, stated that \"artificial intelligence will be able to replace a soldier on the battlefield and a pilot in an aircraft cockpit\" and later noted that \"the day is nearing when vehicles will get artificial intelligence.\"Bondarev made these remarks in close proximity to the successful test of Nerehta, an crewless Russian ground vehicle that reportedly \"outperformed existing [crewed] combat vehicles.\" Russia plans to use Nerehta as a research and development platform for AI and may one day deploy the system in combat, intelligence gathering, or logistics roles.Russia has also reportedly built a combat module for crewless ground vehicles that is capable of autonomous target identification—and, potentially, target engagement—and plans to develop a suite of AI-enabled autonomous systems. In addition, the Russian military plans to incorporate AI into crewless aerial, naval, and undersea vehicles and is currently developing swarming capabilities.It is also exploring innovative uses of AI for remote sensing and electronic warfare, including adaptive frequency hopping, waveforms, and countermeasures.Russia has also made extensive use of AI technologies for domestic propaganda and surveillance, as well as for information operations directed against the United States and U.S. allies. The Russian government has strongly rejected any ban onlethal autonomous weaponsystems, suggesting that such an international ban could be ignored. The Russian invasion of Ukraine and the ensuing Russia-Ukraine war has seen seen significant use of AI by both sides and has also been characterised as a drone war.Advances in AI-powered GPS-denied navigation and drone swarming techniques are significantly improving operational capabilities for Ukraine. Fully realised drone swarms, where multiple drones coordinate and make decisions autonomously, are still in the early stages of experimentation but Ukraine is exploring and implementing these techniques in a real conflict situation.The Defense Intelligence of Ukraine (DIU) has been at the forefront of utilizing drones with some elements of autonomy for conducting long-range strikes into Russian territory. Domestic drone production has significantly expanded, with approximately 2 million drones produced in 2024, 96.2% of which were domestically manufactured. Rather than replacing human involvement, AI is primarily serving to augment existing capabilities, enhancing the speed, accuracy, and overall efficiency of numerous military functions. Perhaps the most important way in which AI has been used by Ukraine is in intelligence, surveillance, and reconnaissance (ISR) capabilities. The Ukrainian military uses Palantir's MetaConstellation software to monitor the movement of Russian troops and supplies (highlighting the blurring of boundaries between state military and commercial AI use). It aggregates data from various commercial civilian providers of satellite imagery Ukraine also uses its own Delta system which aggregates real time data from drone imagery, satellite photos, acoustic signals, and text to construct an operational picture for military commanders. AI is used to prioritise incoming threats, potential targets and resource constraints. AI is also being used to process intercepted communications from Russian soldiers, to process, select, and output militarily useful information from these intercepted calls. Israel has made extensive use of AI for military applications specially during theGaza war. The main AI systems used fortarget identificationare the Gospel and Lavender. Lavender developed by the Unit 8200 identifies and creates a database of individuals mostly low-ranking militants of Hamas and the Palestinian Islamic Jihad and has a 90% accuracy rate and a database of tens of thousands.  The Gospel in comparisons recommended buildings and structures rather than individuals. The acceptable collateral damage and the type of weapon used to eliminate the target is decided by IDF members and could track militants even when at home. Israel'sHarpyanti-radar \"fire and forget\" drone is designed to be launched by ground troops, and autonomously fly over an area to find and destroy radar that fits pre-determined criteria.The application of artificial intelligence is also expected to be advanced in crewless ground systems and robotic vehicles such as the Guardium MK III and later versions.These robotic vehicles are used in border defense. In 2015, the UK government opposed a ban on lethal autonomous weapons, stating that \"international humanitarian law already provides sufficient regulation for this area\", but that all weapons employed by UK armed forces would be \"under human oversight and control\". The South KoreanSuper aEgis IImachine gun, unveiled in 2010, sees use both in South Korea and in the Middle East. It can identify, track, and destroy a moving target at a range of 4 km. While the technology can theoretically operate without human intervention, in practice safeguards are installed to require manual input. A South Korean manufacturer states, \"Our weapons don't sleep, like humans must. They can see in the dark, like humans can't. Our technology therefore plugs the gaps in human capability\", and they want to \"get to a place where our software can discern whether a target is friend, foe, civilian or military\". Saudi Arabia entered the AI race relatively late, beginning in the early 2020s. The country announced itsVision 2030initiative—a multi-trillion dollar plan to diversify its oil-dependent economy—under the leadership of thePublic Investment Fund(PIF). A key turning point in U.S.-Saudi relations came during President Donald Trump's first foreign trip in 2017, when he visitedRiyadhand signed hundreds of billions of dollars in agreements spanning defense, energy, and technology. This visit laid the groundwork for deeper U.S.-Saudi cooperation in areas like AI and tech infrastructure. In the years that followed, Saudi Arabia formed major partnerships with U.S. firms like NVIDIA, AMD, and Cisco, investing billions in semiconductors, cloud computing, and AI research.Saudi-backed startupHumainalso partnered with several American firms, further strengthening the Kingdom's ties with Silicon Valley as it pushed to become a global leader in artificial intelligence by 2030. The United Arab Emirates has been expanding its role in artificial intelligence and technology through investments in infrastructure and partnerships. One major initiative isMGX, a UAE-backed technology group focused on AI development. In 2025, U.S. President Donald Trump visited the UAE, where he met with Emirati officials and business leaders. The visit included discussions on technology and economic cooperation, including potential collaborations with U.S. companies such as Oracle, NVIDIA, and Cisco.These talks focused on areas like data centers, AI hardware, and advanced computing, reflecting ongoing efforts by the UAE to strengthen its technological capabilities through international partnerships. NVIDIA, OpenAI, and Cisco have announced plans to collaborate on building one of the world's largest data centers in the United Arab Emirates. The project is part of the UAE's broader strategy to become a global technology and AI hub. The data center will support advanced cloud computing, AI model training, and data storage capabilities. The European Parliament holds the position that humans must have oversight and decision-making power over lethal autonomous weapons.However, it is up to each member state of the European Union to determine their stance on the use of autonomous weapons and the mixed stances of the member states is perhaps the greatest hindrance to the European Union's ability to develop autonomous weapons. Some members such as France, Germany, Italy, and Sweden are developing lethal autonomous weapons. Some members remain undecided about the use of autonomous military weapons and Austria has even called to ban the use of such weapons. Some EU member states have developed and are developing automated weapons. Germany has developed anactive protection system, the Active Defense System, that can respond to a threat with complete autonomy in less than a millisecond.Italy plans to incorporate autonomous weapons systems into its future military plans. The international regulation of autonomous weapons is an emerging issue for international law.AI arms control will likely require the institutionalization of new international norms embodied in effective technical specifications combined with active monitoring and informal diplomacy by communities of experts, together with a legal and political verification process.As early as 2007, scholars such as AI professorNoel Sharkeyhave warned of \"an emerging arms race among the hi-tech nations to develop autonomous submarines, fighter jets, battleships and tanks that can find their own targets and apply violent force without the involvement of meaningful human decisions\". Miles Brundage of theUniversity of Oxfordhas argued an AI arms race might be somewhat mitigated through diplomacy: \"We saw in the various historical arms races that collaboration and dialog can pay dividends\".Over a hundred experts signed an open letter in 2017 calling on the UN to address the issue of lethal autonomous weapons;however, at a November 2017 session of the UNConvention on Certain Conventional Weapons(CCW), diplomats could not agree even on how to define such weapons.The Indian ambassador and chair of the CCW stated that agreement on rules remained a distant prospect.As of 2019, 26 heads of state and 21 Nobel Peace Prize laureates have backed a ban on autonomous weapons.However, as of 2022, most major powers continue to oppose a ban on autonomous weapons. Many experts believe attempts to completely ban killer robots are likely to fail,in part because detecting treaty violations would be extremely difficult.A 2017 report fromHarvard'sBelfer Centerpredicts that AI has the potential to be as transformative as nuclear weapons.The report further argues that \"Preventing expanded military use of AI is likely impossible\" and that \"the more modest goal of safe and effective technology management must be pursued\", such as banning the attaching of an AIdead man's switchto a nuclear arsenal. A 2015 open letter by theFuture of Life Institutecalling for the prohibition of lethal autonomous weapons systems has been signed by over 26,000 citizens, including physicistStephen Hawking,TeslamagnateElon Musk,Apple'sSteve WozniakandTwitterco-founderJack Dorsey, and over 4,600 artificial intelligence researchers, includingStuart Russell,Bart SelmanandFrancesca Rossi.The Future of Life Institute has also released two fictional films,Slaughterbots(2017) andSlaughterbots - if human: kill()(2021), which portray threats of autonomous weapons and promote a ban, both of which went viral. ProfessorNoel Sharkeyof theUniversity of Sheffieldargues that autonomous weapons will inevitably fall into the hands of terrorist groups such as theIslamic State. Many Western tech companies avoid being associated too closely with the U.S. military, for fear of losing access to China's market.Furthermore, some researchers, such asDeepMindCEODemis Hassabis, are ideologically opposed to contributing to military work. For example, in June 2018, company sources atGooglesaid that top executiveDiane Greenetold staff that the company would not follow-up Project Maven after the current contract expired in March 2019.", "combined_text": "Artificial intelligence arms race Contents Terminology History Risks By nation United States China India Russia Israel United Kingdom South Korea Saudi Arabia United Arab Emirates European Union Proposals for international regulation Other reactions to autonomous weapons Disassociation Rankings See also References Further reading Donald TrumpJoe BidenBarack ObamaElon MuskSundar PichaiJensen HuangSam AltmanSatya NadellaAndy JassyTim CookLisa SuMark ZuckerbergAlexandr Wang Xi JinpingHu JintaoJiang ZeminJack MaRobin LiLiang WenfengPony MaDaniel ZhangRen ZhengfeiTan RuisongLei Jun United StatesGoogleNvidiaStargateOpenAIMicrosoftAmazonAppleTeslaMetaIBMxAIIntelBroadcomAnthropicAMDOracleFigure AILockheed MartinPalantirCoreWeavePerplexity AIAndurilCiscoSalesforce ChinaBaiduDeepSeekTencentAlibabaHuaweiSenseTimeiFlytekAlphaXiaomiMegviiYMTCSilanAVIC Est. $300 billion(USA, over the last decade) Est. $200 billion (China, over the last decade) AI regulation(USA)DataprivacyandsecurityissuesAIbiasandfairness China's Data Security Law A militaryartificial intelligence arms raceis an economic and military competition between two or more states to develop and deploy advancedAItechnologies andlethal autonomous weaponssystems (LAWS). The goal is to gain a strategic or tactical advantage over rivals, similar to previous arms races involving nuclear or conventional military technologies. Since the mid-2010s, many analysts have noted the emergence of such an arms race betweensuperpowersfor better AI technology andmilitary AI,driven byincreasing geopolitical and military tensions. An AI arms race is sometimes placed in the context of anAI Cold Warbetween theUnited StatesandChina.Several influential figures and publications have emphasized that whoever developsartificial general intelligence(AGI) first could dominate global affairs in the 21st century. Russian PresidentVladimir Putinfamously stated that the leader in AI will \"rule the world.\"Experts and analysts—from researchers likeLeopold Aschenbrennerto institutions like Lawfare and Foreign Policy—warn that the AGI race between major powers like the U.S. and China could reshape geopolitical power.This includes AI for surveillance, autonomous weapons, decision-making systems, cyber operations, and more. Lethal autonomous weaponssystems use artificial intelligence to identify and kill human targets without human intervention.LAWS have colloquially been called \"slaughterbots\" or \"killer robots\". Broadly, any competition for superior AI is sometimes framed as an \"arms race\".Advantages in military AI overlap with advantages in other sectors, as countries pursue both economic and military advantages, as per previous arms races throughout history. In 2014, AI specialistSteve Omohundrowarned that \"An autonomous weapons arms race is already taking place\".According toSiemens, worldwide military spending on robotics was US$5.1 billion in 2010 and US$7.5 billion in 2015. China became a top player in artificial intelligence research in the 2010s. According to theFinancial Times, in 2016, for the first time, China published more AI research papers than the entire European Union. When restricted to number of AI papers in the top 5% of cited papers, China overtook the United States in 2016 but lagged behind the European Union.23% of the researchers presenting at the 2017American Association for the Advancement of Artificial Intelligence(AAAI) conference were Chinese.Eric Schmidt, the former chairman and chief executive officer ofAlphabet, has predicted China will be the leading country in AI by 2025. One risk concerns the AI race itself, whether or not the race is won by any one group. There are strong incentives for development teams to cut corners with regard to the safety of the system, increasing the risk of critical failures and unintended consequences.This is in part due to the perceived advantage of being the first to develop advanced AI technology. One team appearing to be on the brink of a breakthrough can encourage other teams to take shortcuts, ignore precautions and deploy a system that is less ready. Some argue that using \"race\" terminology at all in this context can exacerbate this effect. Another potential danger of an AI arms race is the possibility of losing control of the AI systems; the risk is compounded in the case of a race toartificial general intelligence, which may present anexistential risk.In 2023, aUnited States Air Forceofficial reportedly said that during acomputer test, a simulated AI drone killed the human character operating it. The USAF later said the official had misspoken and that it never conducted such simulations. A third risk of an AI arms race is whether or not the race is actually won by one group. The concern is regarding the consolidation of power and technological advantage in the hands of one group.A US government report argued that \"AI-enabled capabilities could be used to threaten  critical infrastructure, amplify disinformation campaigns, and wage war\", and that \"global stability and nuclear deterrence could be undermined\". In 2014, former Secretary of DefenseChuck Hagelposited the \"Third Offset Strategy\" that rapid advances in artificial intelligence will define the next generation of warfare.According to data science and analytics firm Govini, the U.S.Department of Defense(DoD) increased investment in artificial intelligence, big data and cloud computing from $5.6 billion in 2011 to $7.4 billion in 2016.However, the civilianNSFbudget for AI saw no increase in 2017.Japan Timesreported in 2018 that the United States private investment is around $70 billion per year.The November 2019 'Interim Report' of the United States' National Security Commission on Artificial Intelligence confirmed that AI is critical to US technological military superiority. The U.S. has many military AI combat programs, such as theSea Hunterautonomous warship, which is designed to operate for extended periods at sea without a single crew member, and to even guide itself in and out of port.From 2017, a temporary US Department of Defense directive requires a human operator to be kept in the loop when it comes to the taking of human life by autonomous weapons systems.On October 31, 2019, the United States Department of Defense's Defense Innovation Board published the draft of a report recommending principles for the ethical use of artificial intelligence by the Department of Defense that would ensure a human operator would always be able to look into the 'black box' and understand thekill-chainprocess. However, a major concern is how the report will be implemented. The Joint Artificial Intelligence Center (JAIC) (pronounced \"jake\")is an American organization on exploring the usage of AI (particularlyedge computing),Network of Networks, and AI-enhanced communication, for use in actual combat.It is a subdivision of theUnited States Armed Forcesand was created in June 2018. The organization's stated objective is to \"transform theUS Department of Defenseby accelerating the delivery and adoption of AI to achieve mission impact at scale. The goal is to use AI to solve large and complex problem sets that span multiple combat systems; then, ensure the combat Systems and Components have real-time access to ever-improving libraries of data sets and tools.\" In 2023, Microsoft pitched the DoD to useDALL-Emodels to train itsbattlefield management system.OpenAI, thedeveloperof DALL-E, removed the blanket ban on military and warfare use from its usage policies in January 2024.TheBiden administrationimposed restrictions on the export of advanced NVIDIA chips and GPUs to China in an effort to limit China's progress in artificial intelligence and high-performance computing. The policy aimed to prevent the use of cutting-edge U.S. technology in military or surveillance applications and to maintain a strategic advantage in the global AI race. In 2025, under thesecond Trump administration, the United States began a broad deregulation campaign aimed at accelerating growth in sectors critical to artificial intelligence, including nuclear energy, infrastructure, and high-performance computing.The goal was to remove regulatory barriers and attract private investment to boost domestic AI capabilities. This included easing restrictions on data usage, speeding up approvals for AI-related infrastructure projects, and incentivizing innovation in cloud computing and semiconductors. Companies like NVIDIA, Oracle, and Cisco played a central role in these efforts, expanding their AI research, data center capacity, and partnerships to help position the U.S. as a global leader in AI development. Project Maven is aPentagonproject involving using machine learning and engineering talent to distinguish people and objects in drone videos,apparently giving the government real-time battlefield command and control, and the ability to track, tag and spy on targets without human involvement. Initially the effort was led byRobert O. Workwho was concerned about China's military use of the emerging technology.Reportedly, Pentagon development stops short of acting as an AI weapons system capable of firing on self-designated targets.The project was established in a memo by theU.S. Deputy Secretary of Defenseon 26 April 2017.Also known as theAlgorithmic Warfare Cross Functional Team,it is, according to Lt. Gen. of theUnited States Air ForceJack Shanahan in November 2017, a project \"designed to be that pilot project, that pathfinder, that spark that kindles the flame front of artificial intelligence across the rest of the [Defense] Department\".Its chief,U.S. Marine CorpsCol. Drew Cukor, said: \"People and computers will work symbiotically to increase the ability of weapon systems to detect objects.\"Project Maven has been noted by allies, such as Australia'sIan Langford, for the ability to identify adversaries by harvesting data from sensors onUAVsand satellite.At the secondDefense OneTech Summit in July 2017, Cukor also said that the investment in a \"deliberate workflow process\" was funded by the Department [of Defense] through its \"rapid acquisition authorities\" for about \"the next 36 months\". The U.S.Department of Defenseis partnering with Ukraine on \"Project Artemis\" to develop advanced drones that can withstand electronic warfare, blending Ukrainian simplicity and adaptability with American precision. Due to theRussia-Ukraine war, Ukraine has emerged as a leader in drone production and warfare, creating cost-effective systems that challenge traditional approaches. Countries like Turkey, China, and Iran are also producing affordable drones, reducing America's monopoly and reshaping warfare dynamics. U.S. efforts are focused on integrating AI,drone swarmtechnology, and hybrid drone systems to maintain military dominance. The democratization of drone technology raises issues, such as autonomous decision-making, counter-drone defenses, and dual-use concerns, that challenge ethical and security norms. The Stargate Projectis a joint venture announced in 2025 by OpenAI CEO Sam Altman, U.S. President Donald Trump, Oracle Corporation, MGX, SoftBank Group, and other partners. The initiative aims to develop large-scale artificial intelligence (AI) infrastructure in the United States, with a projected $500 billion investment by 2029. The project focuses on building advanced data centers, custom AI hardware, and sustainable energy systems, while also supporting research, workforce development, and national AI competitiveness. It is considered an effort to position the U.S. as a global leader in AI technology.The program has been compared to theManhattan Projectbecause of its large scale. China is pursuing a strategic policy ofmilitary-civil fusionon AI for globaltechnological supremacy.According to a February 2019 report by Gregory C. Allen of theCenter for a New American Security,China'sleadership– includingGeneral Secretary of the Chinese Communist PartyXi Jinping– believes that being at the forefront in AI technology is critical to the future of global military and economic power competition.Chinese military officials have said that their goal is to incorporate commercial AI technology to \"narrow the gap between the Chinese military and global advanced powers.\"The close ties between Silicon Valley and China, and the open nature of the American research community, has made the West's most advanced AI technology easily available to China; in addition, Chinese industry has numerous home-grown AI accomplishments of its own, such asBaidupassing a notable Chinese-language speech recognition capability benchmark in 2015.As of 2017, Beijing's roadmap aims to create a $150 billion AI industry by 2030.Before 2013, Chinese defense procurement was mainly restricted to a few conglomerates; however, as of 2017, China often sources sensitive emerging technology such as drones and artificial intelligence from private start-up companies.An October 2021 report by theCenter for Security and Emerging Technologyfound that \"Most of the [Chinese military]'s AI equipment suppliers are not state-owned defense enterprises, but private Chinese tech companies founded after 2010.\"The report estimated that Chinese military spending on AI exceeded $1.6 billion each year.TheJapan Timesreported in 2018 that annual private Chinese investment in AI is under $7 billion per year. AI startups in China received nearly half of total global investment in AI startups in 2017; the Chinese filed for nearly five times as many AI patents as did Americans. China published a position paper in 2016 questioning the adequacy of existing international law to address the eventuality of fully autonomous weapons, becoming the first permanent member of theU. N. Security Councilto broach the issue.In 2018, CCP general secretaryXi Jinpingcalled for greater international cooperation in basic AI research.Chinese officials have expressed concern that AI such as drones could lead to accidental war, especially in the absence of international norms.In 2019, formerUnited States Secretary of DefenseMark Esperlashed out at China for selling drones capable of taking life with no human oversight. The focus on \"intelligentized AI warfare\", pursued by China, suggests a comprehensive integration of AI across all domains (land, sea, air, space, and cyber) for autonomous attack, defence and cognitive warfare.The intelligentized strategy is distinct from traditional warfare, which focuses on network-centric operations, and instead sees AI as a force multiplier that enhances decision-making, command structures, and autonomous capabilities. Unlike traditional warfare, intelligentization leverages AI to create a cognitive advantage—allowing it to process battlefield information better. AI-assisted command-and-control (C2) systems, predictive analytics, and real-time data fusion, enabling accelerated human-AI hybrid decision-making.\nAutonomous systems, including drone swarms, AI-powered cyber warfare, play a crucial role in this strategy.\nChina is reported to be currently developing wingman drones, robotic ground forces, and optimised logistics to enhance combat effectiveness.TheChinese army (PLA)) also emphasisescognitive warfareusing AI-driven psychological operations, social media manipulation, and predictive behavioural analysis to influence adversaries and the importance of dynamic responses where AI enhances hacking capabilities, automated SIGINT (Signals Intelligence) and adaptive tactics. However, despite this focus, some analysts believe China could be struggling to fully realise AI capability within the military environment: a \"comprehensive review of dozens of Chinese-language journal articles about AI and warfare reveals that Chinese defense experts claim that Beijing is facing several technological challenges that may hinder its ability to capitalize on the advantages provided by military AI\" A task force for the Strategic Implementation of AI for National Security and Defence was established in February 2018 by theMinistry of Defense's Department of Defence Production.The process of getting the military ready for AI use was started by theMoDin 2019.TheCentre for Artificial Intelligence and Roboticswas approved to develop AI solutions to improveintelligence collectionand analysis capabilities.In 2021, theIndian Army, with assistance from theNational Security Council, began operating the Quantum Lab and Artificial Intelligence Center at theMilitary College of Telecommunication Engineering. With an emphasis on robotics and artificial intelligence,Defence Research and Development OrganisationandIndian Institute of Scienceestablished the Joint Advanced Technology Programme-Center of Excellence.In 2022, theIndian Navycreated an AI Core group and set up a Center of Excellence for AI andBig Data analysisatINS Valsura.Indian Army incubated Artificial Intelligence Offensive Drone Operations Project.During Exercise Dakshin Shakti 2021, the Indian Army integrated AI into itsintelligence,surveillance, andreconnaissancearchitecture. In 2022, the Indian government established theDefence Artificial Intelligence Counciland theDefence AI Project Agency,and it also published a list of 75 defense-related AI priority projects.MoDearmarked₹1,000croreannually till 2026 for capacity building, infrastructure setup, data preparation, and Al project implementation.The Indian Army, the Indian Navy and theIndian Air Forceset aside ₹100 crore annually for the development of AI-specific applications.The military is already deploying some AI-enabled projects and equipment.At Air Force Station Rajokri, theIAFCentre of Excellence for Artificial Intelligence was established in 2022 as part of the Unit for Digitization, Automation, Artificial Intelligence, and Application Networking (UDAAN).Swarm drone systemswere introduced by theMechanised Infantry Regimentfor offensive operations close to theLine of Actual Control. For offensive operations, the military began acquiring AI-enabledUAVsandswarm drones.Bharat Electronicsdeveloped AI-enabled audio transcription and analysis software for battlefield communication. Using AI during transport operations, the Indian Army's Research & Development branch patented driver tiredness monitoring system.As part of initial investment, theIndian Armed Forcesis investing about $50 million (€47.2 million) yearly on AI, according to Delhi Policy Group.Forhigh altitudelogisticsat forward outposts,military robotsare deployed.Army is developing autonomous combat vehicles, robotic surveillance platforms, and Manned-Unmanned Teaming (MUM-T) solutions as part of the Defence AI roadmap.MCTEis working with theMinistry of Electronics and Information Technologyand,Society for Applied Microwave Electronics Engineering & Research, on AI and military-gradechipset.Phase III of AI-enabled space-based surveillance has been authorized. DRDOChairman and Secretary of the Department of Defense Research & Development Samir V. Kamat said the agency started concentrating on the potential use of AI in the development of military systems and subsystems.The Indian government intends to leverage the private sector's sizable AI workforce anddual-use technologiesfor defense by 2026.In order to conduct research on autonomous platforms, improved surveillance,predictive maintenance, andintelligent decision support system, the Indian Army AI Incubation Center was established.Indian Navy launchedINS Suratwith AI capabilities. Russian GeneralViktor Bondarev, commander-in-chief of the Russian air force, stated that as early as February 2017, Russia was working on AI-guided missiles that could decide to switch targets mid-flight.TheMilitary-Industrial Commission of Russiahas approved plans to derive 30 percent of Russia's combat power from remote controlled and AI-enabled robotic platforms by 2030.Reports by state-sponsored Russian media on potential military uses of AI increased in mid-2017.In May 2017, the CEO of Russia's Kronstadt Group, a defense contractor, stated that \"there already exist completely autonomous AI operation systems that provide the means for UAV clusters, when they fulfill missions autonomously, sharing tasks between them, and interact\", and that it is inevitable that \"swarms of drones\" will one day fly over combat zones.Russia has been testing several autonomous and semi-autonomous combat systems, such asKalashnikov's \"neural net\" combat module, with a machine gun, a camera, and an AI that its makers claim can make its own targeting judgements without human intervention. In September 2017, during a National Knowledge Day address to over a million students in 16,000 Russian schools, Russian PresidentVladimir Putinstated \"Artificial intelligence is the future, not only for Russia but for all humankind... Whoever becomes the leader in this sphere will become the ruler of the world\". Putin also said it would be better to prevent any single actor achieving a monopoly, but that if Russia became the leader in AI, they would share their \"technology with the rest of the world, like we are doing now with atomic and nuclear technology\". Russia is establishing a number of organizations devoted to the development of military AI. In March 2018, the Russian government released a 10-point AI agenda, which calls for the establishment of an AI and Big Data consortium, a Fund for Analytical Algorithms and Programs, a state-backed AI training and education program, a dedicated AI lab, and a National Center for Artificial Intelligence, among other initiatives.In addition, Russia recently created a defense research organization, roughly equivalent to DARPA, dedicated to autonomy and robotics called the Foundation for Advanced Studies, and initiated an annual conference on \"Robotization of the Armed Forces of the Russian Federation.\" The Russian military has been researching a number of AI applications, with a heavy emphasis on semiautonomous and autonomous vehicles. In an official statement on November 1, 2017, Viktor Bondarev, chairman of the Federation Council's Defense and Security Committee, stated that \"artificial intelligence will be able to replace a soldier on the battlefield and a pilot in an aircraft cockpit\" and later noted that \"the day is nearing when vehicles will get artificial intelligence.\"Bondarev made these remarks in close proximity to the successful test of Nerehta, an crewless Russian ground vehicle that reportedly \"outperformed existing [crewed] combat vehicles.\" Russia plans to use Nerehta as a research and development platform for AI and may one day deploy the system in combat, intelligence gathering, or logistics roles.Russia has also reportedly built a combat module for crewless ground vehicles that is capable of autonomous target identification—and, potentially, target engagement—and plans to develop a suite of AI-enabled autonomous systems. In addition, the Russian military plans to incorporate AI into crewless aerial, naval, and undersea vehicles and is currently developing swarming capabilities.It is also exploring innovative uses of AI for remote sensing and electronic warfare, including adaptive frequency hopping, waveforms, and countermeasures.Russia has also made extensive use of AI technologies for domestic propaganda and surveillance, as well as for information operations directed against the United States and U.S. allies. The Russian government has strongly rejected any ban onlethal autonomous weaponsystems, suggesting that such an international ban could be ignored. The Russian invasion of Ukraine and the ensuing Russia-Ukraine war has seen seen significant use of AI by both sides and has also been characterised as a drone war.Advances in AI-powered GPS-denied navigation and drone swarming techniques are significantly improving operational capabilities for Ukraine. Fully realised drone swarms, where multiple drones coordinate and make decisions autonomously, are still in the early stages of experimentation but Ukraine is exploring and implementing these techniques in a real conflict situation.The Defense Intelligence of Ukraine (DIU) has been at the forefront of utilizing drones with some elements of autonomy for conducting long-range strikes into Russian territory. Domestic drone production has significantly expanded, with approximately 2 million drones produced in 2024, 96.2% of which were domestically manufactured. Rather than replacing human involvement, AI is primarily serving to augment existing capabilities, enhancing the speed, accuracy, and overall efficiency of numerous military functions. Perhaps the most important way in which AI has been used by Ukraine is in intelligence, surveillance, and reconnaissance (ISR) capabilities. The Ukrainian military uses Palantir's MetaConstellation software to monitor the movement of Russian troops and supplies (highlighting the blurring of boundaries between state military and commercial AI use). It aggregates data from various commercial civilian providers of satellite imagery Ukraine also uses its own Delta system which aggregates real time data from drone imagery, satellite photos, acoustic signals, and text to construct an operational picture for military commanders. AI is used to prioritise incoming threats, potential targets and resource constraints. AI is also being used to process intercepted communications from Russian soldiers, to process, select, and output militarily useful information from these intercepted calls. Israel has made extensive use of AI for military applications specially during theGaza war. The main AI systems used fortarget identificationare the Gospel and Lavender. Lavender developed by the Unit 8200 identifies and creates a database of individuals mostly low-ranking militants of Hamas and the Palestinian Islamic Jihad and has a 90% accuracy rate and a database of tens of thousands.  The Gospel in comparisons recommended buildings and structures rather than individuals. The acceptable collateral damage and the type of weapon used to eliminate the target is decided by IDF members and could track militants even when at home. Israel'sHarpyanti-radar \"fire and forget\" drone is designed to be launched by ground troops, and autonomously fly over an area to find and destroy radar that fits pre-determined criteria.The application of artificial intelligence is also expected to be advanced in crewless ground systems and robotic vehicles such as the Guardium MK III and later versions.These robotic vehicles are used in border defense. In 2015, the UK government opposed a ban on lethal autonomous weapons, stating that \"international humanitarian law already provides sufficient regulation for this area\", but that all weapons employed by UK armed forces would be \"under human oversight and control\". The South KoreanSuper aEgis IImachine gun, unveiled in 2010, sees use both in South Korea and in the Middle East. It can identify, track, and destroy a moving target at a range of 4 km. While the technology can theoretically operate without human intervention, in practice safeguards are installed to require manual input. A South Korean manufacturer states, \"Our weapons don't sleep, like humans must. They can see in the dark, like humans can't. Our technology therefore plugs the gaps in human capability\", and they want to \"get to a place where our software can discern whether a target is friend, foe, civilian or military\". Saudi Arabia entered the AI race relatively late, beginning in the early 2020s. The country announced itsVision 2030initiative—a multi-trillion dollar plan to diversify its oil-dependent economy—under the leadership of thePublic Investment Fund(PIF). A key turning point in U.S.-Saudi relations came during President Donald Trump's first foreign trip in 2017, when he visitedRiyadhand signed hundreds of billions of dollars in agreements spanning defense, energy, and technology. This visit laid the groundwork for deeper U.S.-Saudi cooperation in areas like AI and tech infrastructure. In the years that followed, Saudi Arabia formed major partnerships with U.S. firms like NVIDIA, AMD, and Cisco, investing billions in semiconductors, cloud computing, and AI research.Saudi-backed startupHumainalso partnered with several American firms, further strengthening the Kingdom's ties with Silicon Valley as it pushed to become a global leader in artificial intelligence by 2030. The United Arab Emirates has been expanding its role in artificial intelligence and technology through investments in infrastructure and partnerships. One major initiative isMGX, a UAE-backed technology group focused on AI development. In 2025, U.S. President Donald Trump visited the UAE, where he met with Emirati officials and business leaders. The visit included discussions on technology and economic cooperation, including potential collaborations with U.S. companies such as Oracle, NVIDIA, and Cisco.These talks focused on areas like data centers, AI hardware, and advanced computing, reflecting ongoing efforts by the UAE to strengthen its technological capabilities through international partnerships. NVIDIA, OpenAI, and Cisco have announced plans to collaborate on building one of the world's largest data centers in the United Arab Emirates. The project is part of the UAE's broader strategy to become a global technology and AI hub. The data center will support advanced cloud computing, AI model training, and data storage capabilities. The European Parliament holds the position that humans must have oversight and decision-making power over lethal autonomous weapons.However, it is up to each member state of the European Union to determine their stance on the use of autonomous weapons and the mixed stances of the member states is perhaps the greatest hindrance to the European Union's ability to develop autonomous weapons. Some members such as France, Germany, Italy, and Sweden are developing lethal autonomous weapons. Some members remain undecided about the use of autonomous military weapons and Austria has even called to ban the use of such weapons. Some EU member states have developed and are developing automated weapons. Germany has developed anactive protection system, the Active Defense System, that can respond to a threat with complete autonomy in less than a millisecond.Italy plans to incorporate autonomous weapons systems into its future military plans. The international regulation of autonomous weapons is an emerging issue for international law.AI arms control will likely require the institutionalization of new international norms embodied in effective technical specifications combined with active monitoring and informal diplomacy by communities of experts, together with a legal and political verification process.As early as 2007, scholars such as AI professorNoel Sharkeyhave warned of \"an emerging arms race among the hi-tech nations to develop autonomous submarines, fighter jets, battleships and tanks that can find their own targets and apply violent force without the involvement of meaningful human decisions\". Miles Brundage of theUniversity of Oxfordhas argued an AI arms race might be somewhat mitigated through diplomacy: \"We saw in the various historical arms races that collaboration and dialog can pay dividends\".Over a hundred experts signed an open letter in 2017 calling on the UN to address the issue of lethal autonomous weapons;however, at a November 2017 session of the UNConvention on Certain Conventional Weapons(CCW), diplomats could not agree even on how to define such weapons.The Indian ambassador and chair of the CCW stated that agreement on rules remained a distant prospect.As of 2019, 26 heads of state and 21 Nobel Peace Prize laureates have backed a ban on autonomous weapons.However, as of 2022, most major powers continue to oppose a ban on autonomous weapons. Many experts believe attempts to completely ban killer robots are likely to fail,in part because detecting treaty violations would be extremely difficult.A 2017 report fromHarvard'sBelfer Centerpredicts that AI has the potential to be as transformative as nuclear weapons.The report further argues that \"Preventing expanded military use of AI is likely impossible\" and that \"the more modest goal of safe and effective technology management must be pursued\", such as banning the attaching of an AIdead man's switchto a nuclear arsenal. A 2015 open letter by theFuture of Life Institutecalling for the prohibition of lethal autonomous weapons systems has been signed by over 26,000 citizens, including physicistStephen Hawking,TeslamagnateElon Musk,Apple'sSteve WozniakandTwitterco-founderJack Dorsey, and over 4,600 artificial intelligence researchers, includingStuart Russell,Bart SelmanandFrancesca Rossi.The Future of Life Institute has also released two fictional films,Slaughterbots(2017) andSlaughterbots - if human: kill()(2021), which portray threats of autonomous weapons and promote a ban, both of which went viral. ProfessorNoel Sharkeyof theUniversity of Sheffieldargues that autonomous weapons will inevitably fall into the hands of terrorist groups such as theIslamic State. Many Western tech companies avoid being associated too closely with the U.S. military, for fear of losing access to China's market.Furthermore, some researchers, such asDeepMindCEODemis Hassabis, are ideologically opposed to contributing to military work. For example, in June 2018, company sources atGooglesaid that top executiveDiane Greenetold staff that the company would not follow-up Project Maven after the current contract expired in March 2019.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Artificial_intelligence_arms_race", "https://en.wikipedia.org/wiki/Artificial_intelligence_arms_race", "https://en.wikipedia.org/wiki/Artificial_intelligence_arms_race", "https://en.wikipedia.org/wiki/Competition_in_artificial_intelligence", "https://en.wikipedia.org/wiki/Artificial_Intelligence_Cold_War", "https://en.wikipedia.org/wiki/Second_Cold_War", "https://en.wikipedia.org/wiki/United_States", "https://en.wikipedia.org/wiki/China"]},
{"id": "9ed71fcf27e2", "url": "https://en.wikipedia.org/wiki/Meta_Platforms", "title": "Meta Platforms", "headings": ["Contents", "History", "2018–2020: Focus on the metaverse", "2021: Rebrand as Meta", "2022: Declining profits and mass lay-offs", "Since 2023: Threads, AI and all-time high stock value", "Mergers and acquisitions", "Lobbying", "Censorship", "Disinformation concerns", "Misinformation and hate speech", "Lawsuits", "UReputation", "Structure", "Management", "Board of directors", "Ownership", "Company governance", "Revenue", "Number of advertisers", "Tax affairs", "Facilities", "Offices", "Data centers", "Reception", "See also", "References", "External links"], "content": " Meta Platforms, Inc., doing business asMeta, is an American multinational technology company headquartered inMenlo Park, California. Meta owns and operates several prominentsocial mediaplatforms and communication services, includingFacebook,Instagram,WhatsApp,MessengerandThreads. The company also operates anadvertising networkfor its own sites and third parties; as of 2023, advertising accounted for 97.8 percent of its total revenue.Meta is considered part of theBig Techgroup, alongsideNvidia,Microsoft,Apple,Alphabet, andAmazon. The company was originally established in 2004 asTheFacebook, Inc.,and was renamedFacebook, Inc.in 2005.In 2021, it rebranded as Meta Platforms, Inc. to reflect a strategic shift toward developing themetaverse—an interconnected digital ecosystem spanningvirtualandaugmented realitytechnologies. In 2023, Meta was ranked 31st on theForbesGlobal 2000list of the world's largest public companies.As of 2022, it was the world's third-largest spender onresearch and development, with R&D expenses totaling US$35.3 billion. Facebook filed for aninitial public offering(IPO) on January 1, 2012.The preliminary prospectus stated that the company sought to raise $5 billion, had 845 million monthly active users, and a website accruing 2.7 billion likes and comments daily.After the IPO,Zuckerbergwould retain 22% of the total shares and 57% of the total voting power in Facebook. Underwritersvalued the shares at $38 each, valuing the company at $104 billion, the largest valuation yet for a newly public company.On May 16, one day before the IPO, Facebook announced it would sell 25% more shares than originally planned due to high demand.The IPO raised $16 billion, making it the third-largest in US history (slightly ahead ofAT&T Mobilityand behind onlyGeneral MotorsandVisa). The stock price left the company with a highermarket capitalizationthan all but a few U.S. corporations—surpassing heavyweights such asAmazon,McDonald's,Disney, andKraft Foods—and made Zuckerberg's stock worth $19 billion.The New York Timesstated that the offering overcame questions about Facebook's difficulties in attracting advertisers to transform the company into a \"must-own stock\".Jimmy LeeofJPMorgan Chasedescribed it as \"the next greatblue-chip\".Writers atTechCrunch, on the other hand, expressed skepticism, stating, \"That's a big multiple to live up to, and Facebook will likely need to add bold new revenue streams to justify the mammoth valuation.\" Trading in the stock, which began on May 18, was delayed that day due to technical problems with theNasdaqexchange.The stock struggled to stay above the IPO price for most of the day, forcing underwriters to buy back shares to support the price.At the closing bell, shares were valued at $38.23,only $0.23 above the IPO price and down $3.82 from the opening bell value. The opening was widely described by the financial press as a disappointment.The stock set a new record for trading volume of an IPO.On May 25, 2012, the stock ended its first full week of trading at $31.91, a 16.5% decline. On May 22, 2012, regulators fromWall Street'sFinancial Industry Regulatory Authorityannounced that they had begun to investigate whether banks underwriting Facebook had improperly shared information only with select clients rather than the general public.MassachusettsSecretary of StateWilliam F. GalvinsubpoenaedMorgan Stanleyover the same issue.The allegations sparked \"fury\" among some investors and led to the immediate filing of several lawsuits, one of them aclass actionsuit claiming more than $2.5 billion in losses due to the IPO.Bloombergestimated thatretail investorsmay have lost approximately $630 million on Facebook stock since its debut.S&P Global Ratingsadded Facebook to itsS&P 500index on December 21, 2013. On May 2, 2014, Zuckerberg announced that the company would be changing its internal motto from \"Move fast and break things\" to \"Move fast with stable infrastructure\".The earlier motto had been described as Zuckerberg's \"prime directive to his developers and team\" in a 2009 interview inBusiness Insider, in which he also said, \"Unless you are breaking stuff, you are not moving fast enough.\" Lassowas a short-video sharing app from Facebook similar toTikTokthat was launched oniOSandAndroidin 2018 and was aimed at teenagers. On July 2, 2020, Facebook announced that Lasso would be shutting down on July 10. In 2018, theOculusleadJason Rubinsent his 50-page vision document titled \"The Metaverse\" to Facebook's leadership. In the document, Rubin acknowledged that Facebook'svirtual realitybusiness had not caught on as expected, despite the hundreds of millions of dollars spent on content for early adopters. He also urged the company to execute fast and invest heavily in the vision, to shut outHTC,Apple,Googleand other competitors in theVR space. Regarding other players' participation in the metaverse vision, he called for the company to build the \"metaverse\" to prevent their competitors from \"being in the VR business in a meaningful way at all\". In May 2019, Facebook foundedLibra Networks, reportedly to develop their ownstablecoincryptocurrency.Later, it was reported that Libra was being supported by financial companies such asVisa,Mastercard,PayPalandUber. The consortium of companies was expected to pool in $10 million each to fund the launch of thecryptocurrency coinnamed Libra.Depending on when it would receive approval from theSwiss Financial Market Supervisoryauthority to operate as a payments service, the Libra Association had planned to launch a limited format cryptocurrency in 2021.Libra was renamed Diem, before being shut down and sold in January 2022 after backlash fromSwiss government regulatorsand the public. During theCOVID-19 pandemic, the use of online services, including Facebook, grew globally.Zuckerbergpredicted this would be a \"permanent acceleration\" that would continue after the pandemic. Facebook hired aggressively, growing from 48,268 employees in March 2020 to more than 87,000 by September 2022. Following a period of intense scrutiny and damagingwhistleblower leaks, news started to emerge on October 21, 2021 about Facebook's plan torebrandthe company and change its name.In the Q3 2021 earnings call on October 25, Mark Zuckerberg discussed the ongoing criticism of the company's social services and the way it operates, and pointed to the pivoting efforts to building themetaverse– without mentioning the rebranding and the name change.The metaverse vision and the name change from Facebook, Inc. to Meta Platforms was introduced at Facebook Connect on October 28, 2021.Based on Facebook's PR campaign, the name change reflects the company's shifting long term focus of building the metaverse, a digital extension of the physical world bysocial media, virtual reality and augmented reality features. \"Meta\" had beenregisteredas atrademarkin the United States in 2018 (after an initial filing in 2015) for marketing, advertising, and computer services, bya Canadian companythat providedbig dataanalysis ofscientific literature.This company was acquired in 2017 by theChan Zuckerberg Initiative(CZI), a foundation established by Zuckerberg and his wife,Priscilla Chan, and became one of their projects.Following the rebranding announcement, CZI announced that it had already decided to deprioritize the earlier Meta project, thus it would be transferring its rights to the name to Meta Platforms, and the previous project would end in 2022. Soon after the rebranding, in early February 2022, Meta reported a greater-than-expected decline in profits in the fourth quarter of 2021.It reported no growth in monthly users,and indicated it expected revenue growth to stall.It also expected measures taken byApple Inc.to protect user privacy to cost it some $10 billion in advertisement revenue, an amount equal to roughly 8% of its revenue for 2021.In meeting with Meta staff the day after earnings were reported, Zuckerberg blamed competition for user attention, particularly from video-based apps such asTikTok. The 27% reduction in the company's share price which occurred in reaction to the news eliminated some $230 billion of value from Meta'smarket capitalization.Bloombergdescribed the decline as \"an epic rout that, in its sheer scale, is unlike anything Wall Street or Silicon Valley has ever seen\".Zuckerberg's net worth fell by as much as $31 billion.Zuckerberg owns 13% of Meta, and the holding makes up the bulk of his wealth. According to published reports byBloombergon March 30, 2022, Meta turned over data such as phone numbers, physical addresses, andIP addressesto hackers posing as law enforcement officials using forged documents. The law enforcement requests sometimes includedforged signaturesof real or fictional officials. When asked about the allegations, a Meta representative said, \"We review every data request for legal sufficiency and use advanced systems and processes to validate law enforcement requests and detect abuse.\"In June 2022,Sheryl Sandberg, the chief operating officer of 14 years, announced she would step down that year. Zuckerberg said thatJavier Olivanwould replace Sandberg, though in a “more traditional” role. In March 2022, Meta (except Meta-ownedWhatsApp) andInstagramwere banned in Russia and added to theRussian list of terrorist and extremist organizationsfor allegedRussophobiaandhate speech(up togenocidalcalls) amid the ongoingRussian invasion of Ukraine.Meta appealed against the ban, but it was upheld by aMoscowcourt in June of the same year. Also in March 2022, Meta and Italian eyewear giantLuxotticareleasedRay-Ban Stories, a series ofsmartglasseswhich could play music and take pictures. Meta and Luxottica parent companyEssilorLuxotticadeclined to disclose sales on the line of products as of September 2022, though Meta has expressed satisfaction with its customer feedback. In July 2022, Meta saw its first year-on-year revenue decline when its total revenue slipped by 1% to $28.8bn.Analysts and journalists accredited the loss to its advertising business, which has been limited by Apple'sapp tracking transparencyfeature and the number of people who have opted not to be tracked by Meta apps. Zuckerberg also accredited the decline to increasing competition from TikTok.On October 27, 2022, Meta's market value dropped to $268 billion, a loss of around $700 billion compared to 2021, and its shares fell by 24%. It lost its spot among the top 20 US companies by market cap, despite reaching the top 5 in the previous year. In November 2022, Meta laid off 11,000 employees, 13% of its workforce. Zuckerberg said the decision to aggressively increase Meta's investments had been a mistake, as he had wrongly predicted that the surge in e-commerce would last beyond the COVID-19 pandemic. He also attributed the decline to increased competition, a global economic downturn and \"ads signal loss\".Plans to lay off a further 10,000 employees began in April 2023.The layoffs were part of a general downturn in the technology industry, alongside layoffs by companies includingGoogle,Amazon,Tesla,Snap,TwitterandLyft. Starting from 2022, Meta scrambled to catch up to other tech companies in adopting specialized artificial intelligence hardware and software. It had been using less expensiveCPUsinstead ofGPUsfor AI work, but that approach turned out to be less efficient.The company gifted the Inter-university Consortium for Political and Social Research $1.3 million to finance the Social Media Archive's aim to make their data available to social science research. In 2023, Ireland'sData Protection Commissionerimposed a record EUR 1.2 billion fine on Meta for transferring data from Europe to the United States without adequate protections for EU citizens. In March 2023, Meta announced a new round of layoffs that would cut 10,000 employees and close 5,000 open positions to make the company more efficient.Meta revenue surpassed analyst expectations for the first quarter of 2023 after announcing that it was increasing its focus on AI.On July 6, Meta launched a new app,Threads, a competitor to Twitter. Meta announced its artificial intelligence modelLlama2 in July 2023, available for commercial use via partnerships with major cloud providers like Microsoft. It was the first project to be unveiled out of Meta's generative AI group after it was set up in February. It would not charge access or usage but instead operate with an open-source model to allow Meta to ascertain what improvements need to be made. Prior to this announcement, Meta said it had no plans to release Llama 2 for commercial use. An earlier version of Llama was released to academics. In August 2023, Meta announced its permanent removal of news content from Facebook and Instagram in Canada due to theOnline News Act, which requires Canadian news outlets to be compensated for content shared on its platform. The Online News Act was in effect by year-end, but Meta will not participate in the regulatory process.In October 2023, Zuckerberg said that AI would be Meta's biggest investment area in 2024.Meta finished 2023 as one of the best-performing technology stocks of the year, with its share price up 150 percent.Its stock reached an all-time high in January 2024, bringing Meta within 2% of achieving $1 trillion market capitalization. In November 2023 Meta Platforms launched an ad-free service inEurope, allowing subscribers to opt-out ofpersonal databeing collected for targeted advertising. A group of 28 European organizations, including Max Schrems' advocacy groupNOYB, theIrish Council for Civil Liberties,WikimediaEurope, and theElectronic Privacy Information Center, signed a 2024 letter to theEuropean Data Protection Board(EDPB) expressing concern that this subscriber model would undermine privacy protections, specificallyGDPRdata protection standards. Meta removed the Facebook and Instagram accounts of Iran's Supreme LeaderAli Khameneiin February 2024, citing repeated violations of its Dangerous Organizations & Individuals policy.As of March, Meta was under investigation by the FDA for alleged use of their social media platforms to sell illegal drugs.On 16 May 2024, theEuropean Commissionbegan an investigation into Meta over concerns related to child safety. In May 2023, Iraqi social media influencer Esaa Ahmed-Adnan encountered a troubling issue when Instagram removed his posts, citing false copyright violations despite his content being original and free from copyrighted material. He discovered that extortionists were behind these takedowns, offering to restore his content for $3,000 or provide ongoing protection for $1,000 per month. This scam, exploiting Meta’s rights management tools, became widespread in the Middle East, revealing a gap in Meta’s enforcement in developing regions. An Iraqi nonprofit Tech4Peace’s founder, Aws al-Saadi helped Ahmed-Adnan and others, but the restoration process was slow, leading to significant financial losses for many victims, including prominent figures likeAmmar al-Hakim. This situation highlighted Meta’s challenges in balancing global growth with effective content moderation and protection. On 16 September 2024, Meta announced it had banned Russian state media outlets from its platforms worldwide due to concerns about \"foreign interference activity.\" This decision followed allegations thatRTand its employees funneled $10 million through shell companies to secretly fund influence campaigns on various social media channels. Meta's actions were part of a broader effort to counter Russian covert influence operations, which had intensified since the invasion. At its 2024 Connect conference, Meta presented Orion,its first pair ofaugmented realityglasses. Though Orion was originally intended to be sold to consumers, the manufacturing process turned out to be too complex and expensive.Instead, the company pivoted to producing a small number of the glasses to be used internally. On 4 October 2024, Meta announced about its new AI model called Movie Gen, capable of generating realistic video and audio clips based on user prompts. Meta stated it would not release Movie Gen for open development, preferring to collaborate directly with content creators and integrate it into its products by the following year. The model was built using a combination of licensed and publicly available datasets. On October 31, 2024,ProPublicapublished an investigation into deceptive political advertisement scams that sometimes use hundreds of hijacked profiles and facebook pages run by organized networks of scammers. The authors cited spotty enforcement by Meta as a major reason for the extent of the issue. In November 2024, TechCrunch reported that Meta were considering building a $10bn global underwater cable spanning 25,000 miles. In the same month, Meta closed down 2 million accounts on Facebook and Instagram that were linked to scam centers in Myanmar, Laos, Cambodia, the Philippines, and the United Arab Emirates doingpig butchering scams. In December 2024, Meta announced that, beginning February 2025, they would require advertisers to run ads about financial services in Australia to verify information about who are the beneficiary and the payer in a bid to regulate scams. On December 4, 2024, Meta announced it will invest US$10 billion for its largest AI data center in northeast Louisiana, powered by natural gas facilities. On the 11th of that month, Meta experienced a global outage, impacting accounts on all of their social media and messaging applications. Outage reports fromDownDetectorreached 70,000+ and 100,000+ within minutes for Instagram and Facebook, respectively. In January 2025, Meta announced plans to roll back itsdiversity, equity, and inclusion(DEI) initiatives, citing shifts in the \"legal and policy landscape\" in the United States followingthe 2024 presidential election. The decision followed reports that CEO Mark Zuckerberg sought to align the company more closely with theincoming Trump administration, including changes to content moderation policies and executive leadership.The new content moderation policies continued to  bar insults about a person's intellect or mental illness, but made an exception to allow callingLGBTQpeople mentally ill because they are gay ortransgender.Later that month, Meta agreed to pay $25 million to settle a 2021 lawsuit brought byDonald Trumpfor suspending his social media accounts after theJanuary 6 riots.Changes to Meta's moderation policies were controversial among its oversight board, with a significant divide in opinion between the board's US conservatives and its global members. In June 2025, Meta Platforms Inc. has decided to make a multibillion-dollar investment into artificial intelligence startupScale AI. The financing could exceed $10 billion in value which would make it one of the largest private company funding events of all time. Meta has acquired multiple companies (often identified astalent acquisitions).One of its first major acquisitions was in April 2012, when it acquiredInstagramfor approximately US$1 billion in cash and stock.In October 2013, Facebook, Inc. acquiredOnavo, an Israelimobile web analyticscompany.In February 2014, Facebook, Inc. announced it would buy mobile messaging companyWhatsAppfor US$19 billion in cash and stock.The acquisition was completed on October 6.Later that year, Facebook boughtOculus VRfor $2.3 billion in cash and stock,which released its first consumer virtual reality headset in 2016. In late November 2019, Facebook, Inc. announced the acquisition of the game developer Beat Games, responsible for developing one of that year's most popular VR games,Beat Saber.In Late 2022, after Facebook Inc rebranded to Meta Platforms Inc, Oculus was rebranded to Meta Quest. In May 2020, Facebook, Inc. announced it had acquiredGiphyfor a reported cash price of $400 million. It will be integrated with the Instagram team.However, in August 2021, UK'sCompetition and Markets Authority(CMA) stated that Facebook, Inc. might have to sell Giphy, after an investigation found that the deal between the two companies would harm competition in display advertising market.Facebook, Inc. was fined $70 million by CMA for deliberately failing to report all information regarding the acquisition and the ongoingantitrustinvestigation.In October 2022, the CMA ruled for a second time that Meta be required to divest Giphy, stating that Meta already controls half of the advertising in the UK. Meta agreed to the sale, though it stated that it disagrees with the decision itself.In May 2023, Giphy was divested toShutterstockfor $53million. In November 2020, Facebook, Inc. announced that it planned to purchase the customer-service platform and chatbot specialist startup Kustomer to promote companies to use their platform for business. It has been reported that Kustomer valued at slightly over $1 billion.The deal was closed in February 2022 after regulatory approval. In September 2022, Meta acquired Lofelt, a Berlin-basedhaptic techstartup. In 2020, Facebook, Inc. spent$19.7 milliononlobbying, hiring 79 lobbyists. In 2019, it had spent$16.7 millionon lobbying and had a team of 71 lobbyists, up from$12.6 millionand 51 lobbyists in 2018.Facebook was the largest spender of lobbying money among theBig Techcompanies in 2020.The lobbying team includes top congressional aide John Branscome, who was hired in September 2021, to help the company fend off threats from Democratic lawmakers and the Biden administration. In December 2024, Meta donated $1 million to the inauguration fund for then-President-elect Donald Trump. In August 2024,Mark Zuckerbergsent a letter toJim Jordanindicating that during theCOVID-19 pandemictheBiden administrationrepeatedly asked Meta to limit certain COVID-19 content, including humor and satire, onFacebookandInstagram. In 2016 Meta hired Jordana Cutler, formerly an employee at the Israeli Embassy to the United States, as its policy chief for Israel and the Jewish Diaspora. In this role, Cutler pushed for the censorship of accounts belonging toStudents for Justice in Palestinechapters in the United States. Critics have said that Cutler's position gives the Israeli government an undue influence over Meta policy, and that few countries have such high levels of contact with Meta policymakers. Following the election ofDonald Trumpin 2025, various sources noted possible censorship related to theDemocratic Partyon Instagram and other Meta platforms.In February 2025, a Meta rep flagged journalistGil Duran's article and other \"critiques of tech industry figures\" as spam or sensitive content, limiting their reach. In March 2025, Meta attempted to block former employee Sarah Wynn-Williams from promoting or further distributing her memoir,Careless People, that includes allegations of unaddressedsexual harassment in the workplaceby senior executives.The New York Timesreports that the arbitration is among Meta's most forcible attempts to repudiate a former employee's account of workplace dynamics.PublisherMacmillanreacted to the ruling by the Emergency International Arbitral Tribunal by stating that it will ignore its provisions.As of 15 March 2025, hardback and digital versions ofCareless Peoplewere being offered for sale by major online retailers. Since its inception, Meta has been accused of being a host for fake news and misinformation.In the wake of the2016 United States presidential election, Zuckerberg began to take steps to eliminate the prevalence of fake news, as the platform had been criticized for its potential influence on the outcome of the election.The company initially partnered withABC News, theAssociated Press,FactCheck.org,SnopesandPolitiFactfor itsfact-checkinginitiative;as of 2018, it had over 40 fact-checking partners across the world, includingThe Weekly Standard. A May 2017 review byThe Guardianfound that the platform's fact-checking initiatives of partnering with third-party fact-checkers and publicly flagging fake news were regularly ineffective, and appeared to be having minimal impact in some cases.In 2018, journalists working as fact-checkers for the company criticized the partnership, stating that it had produced minimal results and that the company had ignored their concerns. In 2024 Meta's decision to continue to disseminate a falsified video ofUS presidentJoe Biden, even after it had been proven to be fake, attracted criticism and concern. In January 2025, Meta ended its use of third-party fact-checkers in favor of a user-runcommunity notessystem similar to the one used on X. While Zuckerberg supported these changes, saying that the amount of censorship on the platform was excessive, the decision received criticism by fact-checking institutions, stating that the changes would make it more difficult for users to identify misinformation.Meta also faced criticism for weakening its policies on hate speech that were designed to protect minorities and LGBTQ+ individuals from bullying and discrimination.While moving its content review teams from California to Texas, Meta changed their hateful conduct policy to eliminate restrictions on anti-LGBT and anti-immigrant hate speech, as well as explicitly allowing users to accuse LGBT people of being mentally ill or abnormal based on their sexual orientation or gender identity. In January 2025, Meta faced significant criticism for its role in removing LGBTQ+ content from its platforms, amid its broader efforts to address anti-LGBTQ+ hate speech. The removal of LGBTQ+ themes was noted as part of the wider crackdown on content deemed to violate its community guidelines. Meta's content moderation policies, which were designed to combat harmful speech and protect users from discrimination, inadvertently led to the removal or restriction of LGBTQ+ content, particularly posts highlighting LGBTQ+ identities, support, or political issues. According to reports, LGBTQ+ posts, including those that simply celebrated pride or advocated for LGBTQ+ rights, were flagged and removed for reasons that some critics argue were vague or inconsistently applied. Many LGBTQ+ activists and users on Meta's platforms expressed concern that such actions stifled visibility and expression, potentially isolating LGBTQ+ individuals and communities, especially in spaces that were historically important for outreach and support. Numerous lawsuits have been filed against the company, both when it was known as Facebook, Inc., and as Meta Platforms. In March 2020, the Office of theAustralian Information Commissioner(OAIC) sued Facebook, for significant and persistent infringements of the rule on privacy involving theCambridge Analytica fiasco. Every violation of the Privacy Act is subject to a theoretical cumulative liability of $1.7 million. The OAIC estimated that a total of 311,127 Australians had been exposed. On December 8, 2020, the U.S.Federal Trade Commissionand 46 states (excluding Alabama, Georgia, South Carolina, and South Dakota), theDistrict of Columbiaand the territory ofGuam, launchedFederal Trade Commission v. Facebookas an antitrust lawsuit against Facebook. The lawsuit concerns Facebook's acquisition of two competitors—InstagramandWhatsApp—and the ensuing monopolistic situation. FTC alleges that Facebook holds monopolistic power in the U.S. social networking market and seeks to force the company to divest from Instagram and WhatsApp to break up the conglomerate.William Kovacic, a former chairman of the Federal Trade Commission, argued the case will be difficult to win as it would require the government to create a counterfactual argument of an internet where the Facebook-WhatsApp-Instagram entity did not exist, and prove that harmed competition or consumers. On December 24, 2021, a court in Russia fined Meta for $27 million after the company declined to remove unspecified banned content. The fine was reportedly tied to the company's annual revenue in the country. In May 2022, a lawsuit was filed in Kenya against Meta and its local outsourcing companySama. Allegedly, Meta has poor working conditions in Kenya forworkers moderatingFacebook posts. According to the lawsuit, 260 screeners were declared redundant with confusing reasoning. The lawsuit seeks financial compensation and an order that outsourced moderators be given the same health benefits and pay scale as Meta employees. In June 2022, 8 lawsuits were filed across the U.S. over the allege that excessive exposure to platforms including Facebook and Instagram has led to attempted or actual suicides, eating disorders and sleeplessness, among other issues. The litigation follows a former Facebook employee's testimony in Congress that the company refused to take responsibility. The company noted that tools have been developed for parents to keep track of their children's activity on Instagram and set time limits, in addition to Meta's \"Take a break\" reminders. In addition, the company is providing resources specific to eating disorders as well as developing AI to prevent children under the age of 13 signing up for Facebook or Instagram. In June 2022, Meta settled a lawsuit with theUS Department of Justice. The lawsuit, which was filed in 2019, alleged that the company enabled housing discrimination through targeted advertising, as it allowed homeowners and landlords to run housing ads excluding people based on sex, race, religion, and other characteristics. The U.S. Department of Justice stated that this was in violation of theFair Housing Act. Meta was handed a penalty of $115,054 and given until December 31, 2022, to shadow the algorithm tool. In January 2023, Meta was fined €390 million for violations of the European UnionGeneral Data Protection Regulation. In May 2023, theEuropean Data Protection Boardfined Meta a record €1.2 billion for breaching European Union data privacy laws by transferring personal data of Facebook users to servers in the U.S. In July 2024, Meta agreed to pay the state ofTexasUS$1.4 billionto settle a lawsuit brought by Texas Attorney GeneralKen Paxtonaccusing the company of collecting users'biometricdata without consent, setting a record for the largest privacy-related settlement ever obtained by a state attorney general. In October 2024, Meta Platforms faced lawsuits in Japan from 30 plaintiffs who claimed they were defrauded by fake investment ads on Facebook and Instagram, featuring false celebrity endorsements. The plaintiffs are seeking approximately $2.8 million in damages. In April 2025, theKenyan High Courtruled that aUS$2.4 billionlawsuit in which three plaintiffs claim that Facebook inflamed civil violence inEthiopiain 2021 could proceed. In April 2025, Meta was fined €200 million ($230 million) for breaking theDigital Markets Act, by imposing a “consent or pay” system that forces users to either allow their personal data to be used to target advertisements, or pay a subscription fee for advertising-free versions ofFacebookandInstagram. In late April 2025, a case was filed against Meta in Ghana over the alleged psychological distress experienced by content moderators employed to take down disturbing social media content including depictions of murders, extreme violence and child sexual abuse.Meta moved the moderation service to the Ghanaian capital of Accra after legal issues in the previous location Kenya. The new moderation company is Teleperformance, a multinational corporation with a history of worker's rights violation.Reports suggests the conditions are worse here than in the previous Kenyan location, with many workers afraid of speaking out due to fear of returning to conflict zones. Workers reported developing mental illnesses, attempted suicides, and low pay. In 2020, the company UReputation, which had been involved in several cases concerning the management of digital armies, filed a lawsuit against Facebook, accusing it of unlawfully transmitting personal data to third parties. Legal actions were initiated in Tunisia, France, and the United States. In 2025, the United States District court for the Northern District of Georgia approved a discovery procedure, allowing UReputation to access documents and evidence held by Meta. Meta's key management consists of: As of October 2022, Meta had 83,553 employees worldwide. As of June 2024, Meta'sboardconsisted of the following directors; Meta Platforms is mainly owned by institutional investors, who hold around 80% of all shares.Insiders control the majority of voting Shares. The three largest individual investors in 2024 were Mark Zuckerberg, Sheryl Sandberg and Christopher K. Cox. The largest shareholders in late 2024/early 2025 were: Roger McNamee, an early Facebook investor and Zuckerberg's former mentor, said Facebook had \"the most centralized decision-making structure I have ever encountered in a large company\". Facebook co-founder Chris Hughes has stated that chief executive officer Mark Zuckerberg has too much power, that the company is now a monopoly, and that, as a result, it should be split into multiple smaller companies. In anop-edinThe New York Times, Hughes said he was concerned that Zuckerberg had surrounded himself with a team that did not challenge him, and that it is the U.S. government's job to hold him accountable and curb his \"unchecked power\".He also said that \"Mark's power is unprecedented and un-American.\"Several U.S. politicians agreed with Hughes.European UnionCommissioner for CompetitionMargrethe Vestager stated that splitting Facebook should be done only as \"a remedy of the very last resort\", and that it would not solve Facebook's underlying problems. Facebook ranked No. 34 in the 2020Fortune 500list of the largest United States corporations by revenue, with almost $86 billion in revenuemost of it coming from advertising.One analysis of 2017 data determined that the company earnedUS$20.21per user from advertising. According toNew York, since its rebranding, Meta has reportedly lost $500 billion as a result of new privacy measures put in place by companies such as Apple and Google which prevents Meta from gathering users' data. In February 2015,Facebookannounced it had reached two million active advertisers, with most of the gain coming from small businesses. An active advertiser was defined as an entity that had advertised on the Facebook platform in the last 28 days.In March 2016, Facebook announced it had reached three million active advertisers with more than 70% from outside the United States.Prices for advertising follow a variable pricing model based on auctioning ad placements, and potential engagement levels of the advertisement itself. Similar to other online advertising platforms like Google and Twitter, targeting of advertisements is one of the chief merits of digital advertising compared totraditional media. Marketing on Meta is employed through two methods based on the viewing habits, likes and shares, and purchasing data of the audience, namely targeted audiences and \"look alike\" audiences. The U.S. IRS challenged the valuation Facebook used when it transferred IP from the U.S. to Facebook Ireland (now Meta Platforms Ireland) in 2010 (which Facebook Ireland then revalued higher before charging out), as it was building itsdouble Irishtax structure.The case is ongoing and Meta faces a potential fine of $3–5bn. The U.S.Tax Cuts and Jobs Act of 2017changed Facebook's global tax calculations. Meta Platforms Ireland is subject to the U.S. GILTI tax of 10.5% on global intangible profits (i.e. Irish profits). On the basis that Meta Platforms Ireland Limited is paying some tax, the effective minimum US tax for Facebook Ireland will be circa 11%. In contrast, Meta Platforms Inc. would incur a special IP tax rate of 13.125% (the FDII rate) if its Irish business relocated to the U.S. Tax relief in the U.S. (21% vs. Irish at the GILTI rate) and accelerated capital expensing, would make this effective U.S. rate around 12%. The insignificance of the U.S./Irish tax difference was demonstrated when Facebook moved 1.5bn non-EU accounts to the U.S. to limit exposure toGDPR. Users outside of the U.S. and Canada contract with Meta's Irish subsidiary, Meta Platforms Ireland Limited (formerlyFacebook Ireland Limited), allowing Meta to avoid US taxes for all users in Europe, Asia, Australia, Africa and South America. Meta is making use of theDouble Irish arrangementwhich allows it to pay 2–3% corporation tax on all international revenue.In 2010, Facebook opened its fourth office, inHyderabad, India,which houses online advertising and developer support teams and provides support to users and advertisers.In India, Meta is registered as Facebook India Online Services Pvt Ltd.It also has offices or planned sites inChittagong, Bangladesh;Dublin, Ireland;; andAustin, Texas, among other cities. Facebook opened its London headquarters in 2017 in Fitzrovia incentral London. Facebook opened an office inCambridge, Massachusettsin 2018. The offices were initially home to the \"Connectivity Lab\", a group focused on bringing Internet access to those who do not have access to the Internet.In April 2019, Facebook opened itsTaiwanheadquarters inTaipei. In March 2022, Meta opened new regional headquarters inDubai. In September 2023, it was reported that Meta had paid £149m toBritish Landto break the lease on Triton Square London office. Meta reportedly had another 18 years left on its lease on the site. As of 2023, Facebook operated 21 data centers.It committed to purchase 100% renewable energy and to reduce its greenhouse gas emissions 75% by 2020.Its data center technologies include Fabric Aggregator, a distributed network system that accommodates larger regions and varied traffic patterns. US RepresentativeAlexandria Ocasio-Cortezresponded in a tweet to Zuckerberg's announcement about Meta, saying: \"Meta as in 'we are a cancer to democracy metastasizing into a global surveillance and propaganda machine for boosting authoritarian regimes and destroying civil society ... for profit!'\" Ex-Facebook employeeFrances Haugenand whistleblower behind theFacebook Papersresponded to the rebranding efforts by expressing doubts about the company's ability to improve while led byMark Zuckerberg, and urged the chief executive officer to resign. In November 2021, a video published by Inspired by Iceland went viral, in which a Zuckerberg look-alike promoted the Icelandverse, a place of \"enhanced actual reality without silly looking headsets\". In a December 2021 interview, SpaceX and Tesla chief executive officerElon Musksaid he could not see a compelling use-case for the VR-driven metaverse, adding: \"I don't see someone strapping a frigging screen to their face all day.\" In January 2022, Louise Eccles ofThe Sunday Timeslogged into the metaverse with the intention of making a video guide. She wrote: Initially, my experience with the Oculus went well. I attended work meetings as an avatar and tried an exercise class set in the streets of Paris. The headset enabled me to feel the thrill of carving down mountains on a snowboard and the adrenaline rush of climbing a mountain without ropes. Yet switching to the social apps, where you mingle with strangers also using VR headsets, it was at times predatory and vile. Eccles described beingsexually harassedby another user, as well as \"accents from all over the world, American, Indian, English, Australian, using racist, sexist, homophobic and transphobic language\". She also encountered users as young as 7 years old on the platform, despite Oculus headsets being intended for users over 13. 37°29′06″N122°08′54″W﻿ / ﻿37.48500°N 122.14833°W﻿ /37.48500; -122.14833", "combined_text": "Meta Platforms Contents History 2018–2020: Focus on the metaverse 2021: Rebrand as Meta 2022: Declining profits and mass lay-offs Since 2023: Threads, AI and all-time high stock value Mergers and acquisitions Lobbying Censorship Disinformation concerns Misinformation and hate speech Lawsuits UReputation Structure Management Board of directors Ownership Company governance Revenue Number of advertisers Tax affairs Facilities Offices Data centers Reception See also References External links  Meta Platforms, Inc., doing business asMeta, is an American multinational technology company headquartered inMenlo Park, California. Meta owns and operates several prominentsocial mediaplatforms and communication services, includingFacebook,Instagram,WhatsApp,MessengerandThreads. The company also operates anadvertising networkfor its own sites and third parties; as of 2023, advertising accounted for 97.8 percent of its total revenue.Meta is considered part of theBig Techgroup, alongsideNvidia,Microsoft,Apple,Alphabet, andAmazon. The company was originally established in 2004 asTheFacebook, Inc.,and was renamedFacebook, Inc.in 2005.In 2021, it rebranded as Meta Platforms, Inc. to reflect a strategic shift toward developing themetaverse—an interconnected digital ecosystem spanningvirtualandaugmented realitytechnologies. In 2023, Meta was ranked 31st on theForbesGlobal 2000list of the world's largest public companies.As of 2022, it was the world's third-largest spender onresearch and development, with R&D expenses totaling US$35.3 billion. Facebook filed for aninitial public offering(IPO) on January 1, 2012.The preliminary prospectus stated that the company sought to raise $5 billion, had 845 million monthly active users, and a website accruing 2.7 billion likes and comments daily.After the IPO,Zuckerbergwould retain 22% of the total shares and 57% of the total voting power in Facebook. Underwritersvalued the shares at $38 each, valuing the company at $104 billion, the largest valuation yet for a newly public company.On May 16, one day before the IPO, Facebook announced it would sell 25% more shares than originally planned due to high demand.The IPO raised $16 billion, making it the third-largest in US history (slightly ahead ofAT&T Mobilityand behind onlyGeneral MotorsandVisa). The stock price left the company with a highermarket capitalizationthan all but a few U.S. corporations—surpassing heavyweights such asAmazon,McDonald's,Disney, andKraft Foods—and made Zuckerberg's stock worth $19 billion.The New York Timesstated that the offering overcame questions about Facebook's difficulties in attracting advertisers to transform the company into a \"must-own stock\".Jimmy LeeofJPMorgan Chasedescribed it as \"the next greatblue-chip\".Writers atTechCrunch, on the other hand, expressed skepticism, stating, \"That's a big multiple to live up to, and Facebook will likely need to add bold new revenue streams to justify the mammoth valuation.\" Trading in the stock, which began on May 18, was delayed that day due to technical problems with theNasdaqexchange.The stock struggled to stay above the IPO price for most of the day, forcing underwriters to buy back shares to support the price.At the closing bell, shares were valued at $38.23,only $0.23 above the IPO price and down $3.82 from the opening bell value. The opening was widely described by the financial press as a disappointment.The stock set a new record for trading volume of an IPO.On May 25, 2012, the stock ended its first full week of trading at $31.91, a 16.5% decline. On May 22, 2012, regulators fromWall Street'sFinancial Industry Regulatory Authorityannounced that they had begun to investigate whether banks underwriting Facebook had improperly shared information only with select clients rather than the general public.MassachusettsSecretary of StateWilliam F. GalvinsubpoenaedMorgan Stanleyover the same issue.The allegations sparked \"fury\" among some investors and led to the immediate filing of several lawsuits, one of them aclass actionsuit claiming more than $2.5 billion in losses due to the IPO.Bloombergestimated thatretail investorsmay have lost approximately $630 million on Facebook stock since its debut.S&P Global Ratingsadded Facebook to itsS&P 500index on December 21, 2013. On May 2, 2014, Zuckerberg announced that the company would be changing its internal motto from \"Move fast and break things\" to \"Move fast with stable infrastructure\".The earlier motto had been described as Zuckerberg's \"prime directive to his developers and team\" in a 2009 interview inBusiness Insider, in which he also said, \"Unless you are breaking stuff, you are not moving fast enough.\" Lassowas a short-video sharing app from Facebook similar toTikTokthat was launched oniOSandAndroidin 2018 and was aimed at teenagers. On July 2, 2020, Facebook announced that Lasso would be shutting down on July 10. In 2018, theOculusleadJason Rubinsent his 50-page vision document titled \"The Metaverse\" to Facebook's leadership. In the document, Rubin acknowledged that Facebook'svirtual realitybusiness had not caught on as expected, despite the hundreds of millions of dollars spent on content for early adopters. He also urged the company to execute fast and invest heavily in the vision, to shut outHTC,Apple,Googleand other competitors in theVR space. Regarding other players' participation in the metaverse vision, he called for the company to build the \"metaverse\" to prevent their competitors from \"being in the VR business in a meaningful way at all\". In May 2019, Facebook foundedLibra Networks, reportedly to develop their ownstablecoincryptocurrency.Later, it was reported that Libra was being supported by financial companies such asVisa,Mastercard,PayPalandUber. The consortium of companies was expected to pool in $10 million each to fund the launch of thecryptocurrency coinnamed Libra.Depending on when it would receive approval from theSwiss Financial Market Supervisoryauthority to operate as a payments service, the Libra Association had planned to launch a limited format cryptocurrency in 2021.Libra was renamed Diem, before being shut down and sold in January 2022 after backlash fromSwiss government regulatorsand the public. During theCOVID-19 pandemic, the use of online services, including Facebook, grew globally.Zuckerbergpredicted this would be a \"permanent acceleration\" that would continue after the pandemic. Facebook hired aggressively, growing from 48,268 employees in March 2020 to more than 87,000 by September 2022. Following a period of intense scrutiny and damagingwhistleblower leaks, news started to emerge on October 21, 2021 about Facebook's plan torebrandthe company and change its name.In the Q3 2021 earnings call on October 25, Mark Zuckerberg discussed the ongoing criticism of the company's social services and the way it operates, and pointed to the pivoting efforts to building themetaverse– without mentioning the rebranding and the name change.The metaverse vision and the name change from Facebook, Inc. to Meta Platforms was introduced at Facebook Connect on October 28, 2021.Based on Facebook's PR campaign, the name change reflects the company's shifting long term focus of building the metaverse, a digital extension of the physical world bysocial media, virtual reality and augmented reality features. \"Meta\" had beenregisteredas atrademarkin the United States in 2018 (after an initial filing in 2015) for marketing, advertising, and computer services, bya Canadian companythat providedbig dataanalysis ofscientific literature.This company was acquired in 2017 by theChan Zuckerberg Initiative(CZI), a foundation established by Zuckerberg and his wife,Priscilla Chan, and became one of their projects.Following the rebranding announcement, CZI announced that it had already decided to deprioritize the earlier Meta project, thus it would be transferring its rights to the name to Meta Platforms, and the previous project would end in 2022. Soon after the rebranding, in early February 2022, Meta reported a greater-than-expected decline in profits in the fourth quarter of 2021.It reported no growth in monthly users,and indicated it expected revenue growth to stall.It also expected measures taken byApple Inc.to protect user privacy to cost it some $10 billion in advertisement revenue, an amount equal to roughly 8% of its revenue for 2021.In meeting with Meta staff the day after earnings were reported, Zuckerberg blamed competition for user attention, particularly from video-based apps such asTikTok. The 27% reduction in the company's share price which occurred in reaction to the news eliminated some $230 billion of value from Meta'smarket capitalization.Bloombergdescribed the decline as \"an epic rout that, in its sheer scale, is unlike anything Wall Street or Silicon Valley has ever seen\".Zuckerberg's net worth fell by as much as $31 billion.Zuckerberg owns 13% of Meta, and the holding makes up the bulk of his wealth. According to published reports byBloombergon March 30, 2022, Meta turned over data such as phone numbers, physical addresses, andIP addressesto hackers posing as law enforcement officials using forged documents. The law enforcement requests sometimes includedforged signaturesof real or fictional officials. When asked about the allegations, a Meta representative said, \"We review every data request for legal sufficiency and use advanced systems and processes to validate law enforcement requests and detect abuse.\"In June 2022,Sheryl Sandberg, the chief operating officer of 14 years, announced she would step down that year. Zuckerberg said thatJavier Olivanwould replace Sandberg, though in a “more traditional” role. In March 2022, Meta (except Meta-ownedWhatsApp) andInstagramwere banned in Russia and added to theRussian list of terrorist and extremist organizationsfor allegedRussophobiaandhate speech(up togenocidalcalls) amid the ongoingRussian invasion of Ukraine.Meta appealed against the ban, but it was upheld by aMoscowcourt in June of the same year. Also in March 2022, Meta and Italian eyewear giantLuxotticareleasedRay-Ban Stories, a series ofsmartglasseswhich could play music and take pictures. Meta and Luxottica parent companyEssilorLuxotticadeclined to disclose sales on the line of products as of September 2022, though Meta has expressed satisfaction with its customer feedback. In July 2022, Meta saw its first year-on-year revenue decline when its total revenue slipped by 1% to $28.8bn.Analysts and journalists accredited the loss to its advertising business, which has been limited by Apple'sapp tracking transparencyfeature and the number of people who have opted not to be tracked by Meta apps. Zuckerberg also accredited the decline to increasing competition from TikTok.On October 27, 2022, Meta's market value dropped to $268 billion, a loss of around $700 billion compared to 2021, and its shares fell by 24%. It lost its spot among the top 20 US companies by market cap, despite reaching the top 5 in the previous year. In November 2022, Meta laid off 11,000 employees, 13% of its workforce. Zuckerberg said the decision to aggressively increase Meta's investments had been a mistake, as he had wrongly predicted that the surge in e-commerce would last beyond the COVID-19 pandemic. He also attributed the decline to increased competition, a global economic downturn and \"ads signal loss\".Plans to lay off a further 10,000 employees began in April 2023.The layoffs were part of a general downturn in the technology industry, alongside layoffs by companies includingGoogle,Amazon,Tesla,Snap,TwitterandLyft. Starting from 2022, Meta scrambled to catch up to other tech companies in adopting specialized artificial intelligence hardware and software. It had been using less expensiveCPUsinstead ofGPUsfor AI work, but that approach turned out to be less efficient.The company gifted the Inter-university Consortium for Political and Social Research $1.3 million to finance the Social Media Archive's aim to make their data available to social science research. In 2023, Ireland'sData Protection Commissionerimposed a record EUR 1.2 billion fine on Meta for transferring data from Europe to the United States without adequate protections for EU citizens. In March 2023, Meta announced a new round of layoffs that would cut 10,000 employees and close 5,000 open positions to make the company more efficient.Meta revenue surpassed analyst expectations for the first quarter of 2023 after announcing that it was increasing its focus on AI.On July 6, Meta launched a new app,Threads, a competitor to Twitter. Meta announced its artificial intelligence modelLlama2 in July 2023, available for commercial use via partnerships with major cloud providers like Microsoft. It was the first project to be unveiled out of Meta's generative AI group after it was set up in February. It would not charge access or usage but instead operate with an open-source model to allow Meta to ascertain what improvements need to be made. Prior to this announcement, Meta said it had no plans to release Llama 2 for commercial use. An earlier version of Llama was released to academics. In August 2023, Meta announced its permanent removal of news content from Facebook and Instagram in Canada due to theOnline News Act, which requires Canadian news outlets to be compensated for content shared on its platform. The Online News Act was in effect by year-end, but Meta will not participate in the regulatory process.In October 2023, Zuckerberg said that AI would be Meta's biggest investment area in 2024.Meta finished 2023 as one of the best-performing technology stocks of the year, with its share price up 150 percent.Its stock reached an all-time high in January 2024, bringing Meta within 2% of achieving $1 trillion market capitalization. In November 2023 Meta Platforms launched an ad-free service inEurope, allowing subscribers to opt-out ofpersonal databeing collected for targeted advertising. A group of 28 European organizations, including Max Schrems' advocacy groupNOYB, theIrish Council for Civil Liberties,WikimediaEurope, and theElectronic Privacy Information Center, signed a 2024 letter to theEuropean Data Protection Board(EDPB) expressing concern that this subscriber model would undermine privacy protections, specificallyGDPRdata protection standards. Meta removed the Facebook and Instagram accounts of Iran's Supreme LeaderAli Khameneiin February 2024, citing repeated violations of its Dangerous Organizations & Individuals policy.As of March, Meta was under investigation by the FDA for alleged use of their social media platforms to sell illegal drugs.On 16 May 2024, theEuropean Commissionbegan an investigation into Meta over concerns related to child safety. In May 2023, Iraqi social media influencer Esaa Ahmed-Adnan encountered a troubling issue when Instagram removed his posts, citing false copyright violations despite his content being original and free from copyrighted material. He discovered that extortionists were behind these takedowns, offering to restore his content for $3,000 or provide ongoing protection for $1,000 per month. This scam, exploiting Meta’s rights management tools, became widespread in the Middle East, revealing a gap in Meta’s enforcement in developing regions. An Iraqi nonprofit Tech4Peace’s founder, Aws al-Saadi helped Ahmed-Adnan and others, but the restoration process was slow, leading to significant financial losses for many victims, including prominent figures likeAmmar al-Hakim. This situation highlighted Meta’s challenges in balancing global growth with effective content moderation and protection. On 16 September 2024, Meta announced it had banned Russian state media outlets from its platforms worldwide due to concerns about \"foreign interference activity.\" This decision followed allegations thatRTand its employees funneled $10 million through shell companies to secretly fund influence campaigns on various social media channels. Meta's actions were part of a broader effort to counter Russian covert influence operations, which had intensified since the invasion. At its 2024 Connect conference, Meta presented Orion,its first pair ofaugmented realityglasses. Though Orion was originally intended to be sold to consumers, the manufacturing process turned out to be too complex and expensive.Instead, the company pivoted to producing a small number of the glasses to be used internally. On 4 October 2024, Meta announced about its new AI model called Movie Gen, capable of generating realistic video and audio clips based on user prompts. Meta stated it would not release Movie Gen for open development, preferring to collaborate directly with content creators and integrate it into its products by the following year. The model was built using a combination of licensed and publicly available datasets. On October 31, 2024,ProPublicapublished an investigation into deceptive political advertisement scams that sometimes use hundreds of hijacked profiles and facebook pages run by organized networks of scammers. The authors cited spotty enforcement by Meta as a major reason for the extent of the issue. In November 2024, TechCrunch reported that Meta were considering building a $10bn global underwater cable spanning 25,000 miles. In the same month, Meta closed down 2 million accounts on Facebook and Instagram that were linked to scam centers in Myanmar, Laos, Cambodia, the Philippines, and the United Arab Emirates doingpig butchering scams. In December 2024, Meta announced that, beginning February 2025, they would require advertisers to run ads about financial services in Australia to verify information about who are the beneficiary and the payer in a bid to regulate scams. On December 4, 2024, Meta announced it will invest US$10 billion for its largest AI data center in northeast Louisiana, powered by natural gas facilities. On the 11th of that month, Meta experienced a global outage, impacting accounts on all of their social media and messaging applications. Outage reports fromDownDetectorreached 70,000+ and 100,000+ within minutes for Instagram and Facebook, respectively. In January 2025, Meta announced plans to roll back itsdiversity, equity, and inclusion(DEI) initiatives, citing shifts in the \"legal and policy landscape\" in the United States followingthe 2024 presidential election. The decision followed reports that CEO Mark Zuckerberg sought to align the company more closely with theincoming Trump administration, including changes to content moderation policies and executive leadership.The new content moderation policies continued to  bar insults about a person's intellect or mental illness, but made an exception to allow callingLGBTQpeople mentally ill because they are gay ortransgender.Later that month, Meta agreed to pay $25 million to settle a 2021 lawsuit brought byDonald Trumpfor suspending his social media accounts after theJanuary 6 riots.Changes to Meta's moderation policies were controversial among its oversight board, with a significant divide in opinion between the board's US conservatives and its global members. In June 2025, Meta Platforms Inc. has decided to make a multibillion-dollar investment into artificial intelligence startupScale AI. The financing could exceed $10 billion in value which would make it one of the largest private company funding events of all time. Meta has acquired multiple companies (often identified astalent acquisitions).One of its first major acquisitions was in April 2012, when it acquiredInstagramfor approximately US$1 billion in cash and stock.In October 2013, Facebook, Inc. acquiredOnavo, an Israelimobile web analyticscompany.In February 2014, Facebook, Inc. announced it would buy mobile messaging companyWhatsAppfor US$19 billion in cash and stock.The acquisition was completed on October 6.Later that year, Facebook boughtOculus VRfor $2.3 billion in cash and stock,which released its first consumer virtual reality headset in 2016. In late November 2019, Facebook, Inc. announced the acquisition of the game developer Beat Games, responsible for developing one of that year's most popular VR games,Beat Saber.In Late 2022, after Facebook Inc rebranded to Meta Platforms Inc, Oculus was rebranded to Meta Quest. In May 2020, Facebook, Inc. announced it had acquiredGiphyfor a reported cash price of $400 million. It will be integrated with the Instagram team.However, in August 2021, UK'sCompetition and Markets Authority(CMA) stated that Facebook, Inc. might have to sell Giphy, after an investigation found that the deal between the two companies would harm competition in display advertising market.Facebook, Inc. was fined $70 million by CMA for deliberately failing to report all information regarding the acquisition and the ongoingantitrustinvestigation.In October 2022, the CMA ruled for a second time that Meta be required to divest Giphy, stating that Meta already controls half of the advertising in the UK. Meta agreed to the sale, though it stated that it disagrees with the decision itself.In May 2023, Giphy was divested toShutterstockfor $53million. In November 2020, Facebook, Inc. announced that it planned to purchase the customer-service platform and chatbot specialist startup Kustomer to promote companies to use their platform for business. It has been reported that Kustomer valued at slightly over $1 billion.The deal was closed in February 2022 after regulatory approval. In September 2022, Meta acquired Lofelt, a Berlin-basedhaptic techstartup. In 2020, Facebook, Inc. spent$19.7 milliononlobbying, hiring 79 lobbyists. In 2019, it had spent$16.7 millionon lobbying and had a team of 71 lobbyists, up from$12.6 millionand 51 lobbyists in 2018.Facebook was the largest spender of lobbying money among theBig Techcompanies in 2020.The lobbying team includes top congressional aide John Branscome, who was hired in September 2021, to help the company fend off threats from Democratic lawmakers and the Biden administration. In December 2024, Meta donated $1 million to the inauguration fund for then-President-elect Donald Trump. In August 2024,Mark Zuckerbergsent a letter toJim Jordanindicating that during theCOVID-19 pandemictheBiden administrationrepeatedly asked Meta to limit certain COVID-19 content, including humor and satire, onFacebookandInstagram. In 2016 Meta hired Jordana Cutler, formerly an employee at the Israeli Embassy to the United States, as its policy chief for Israel and the Jewish Diaspora. In this role, Cutler pushed for the censorship of accounts belonging toStudents for Justice in Palestinechapters in the United States. Critics have said that Cutler's position gives the Israeli government an undue influence over Meta policy, and that few countries have such high levels of contact with Meta policymakers. Following the election ofDonald Trumpin 2025, various sources noted possible censorship related to theDemocratic Partyon Instagram and other Meta platforms.In February 2025, a Meta rep flagged journalistGil Duran's article and other \"critiques of tech industry figures\" as spam or sensitive content, limiting their reach. In March 2025, Meta attempted to block former employee Sarah Wynn-Williams from promoting or further distributing her memoir,Careless People, that includes allegations of unaddressedsexual harassment in the workplaceby senior executives.The New York Timesreports that the arbitration is among Meta's most forcible attempts to repudiate a former employee's account of workplace dynamics.PublisherMacmillanreacted to the ruling by the Emergency International Arbitral Tribunal by stating that it will ignore its provisions.As of 15 March 2025, hardback and digital versions ofCareless Peoplewere being offered for sale by major online retailers. Since its inception, Meta has been accused of being a host for fake news and misinformation.In the wake of the2016 United States presidential election, Zuckerberg began to take steps to eliminate the prevalence of fake news, as the platform had been criticized for its potential influence on the outcome of the election.The company initially partnered withABC News, theAssociated Press,FactCheck.org,SnopesandPolitiFactfor itsfact-checkinginitiative;as of 2018, it had over 40 fact-checking partners across the world, includingThe Weekly Standard. A May 2017 review byThe Guardianfound that the platform's fact-checking initiatives of partnering with third-party fact-checkers and publicly flagging fake news were regularly ineffective, and appeared to be having minimal impact in some cases.In 2018, journalists working as fact-checkers for the company criticized the partnership, stating that it had produced minimal results and that the company had ignored their concerns. In 2024 Meta's decision to continue to disseminate a falsified video ofUS presidentJoe Biden, even after it had been proven to be fake, attracted criticism and concern. In January 2025, Meta ended its use of third-party fact-checkers in favor of a user-runcommunity notessystem similar to the one used on X. While Zuckerberg supported these changes, saying that the amount of censorship on the platform was excessive, the decision received criticism by fact-checking institutions, stating that the changes would make it more difficult for users to identify misinformation.Meta also faced criticism for weakening its policies on hate speech that were designed to protect minorities and LGBTQ+ individuals from bullying and discrimination.While moving its content review teams from California to Texas, Meta changed their hateful conduct policy to eliminate restrictions on anti-LGBT and anti-immigrant hate speech, as well as explicitly allowing users to accuse LGBT people of being mentally ill or abnormal based on their sexual orientation or gender identity. In January 2025, Meta faced significant criticism for its role in removing LGBTQ+ content from its platforms, amid its broader efforts to address anti-LGBTQ+ hate speech. The removal of LGBTQ+ themes was noted as part of the wider crackdown on content deemed to violate its community guidelines. Meta's content moderation policies, which were designed to combat harmful speech and protect users from discrimination, inadvertently led to the removal or restriction of LGBTQ+ content, particularly posts highlighting LGBTQ+ identities, support, or political issues. According to reports, LGBTQ+ posts, including those that simply celebrated pride or advocated for LGBTQ+ rights, were flagged and removed for reasons that some critics argue were vague or inconsistently applied. Many LGBTQ+ activists and users on Meta's platforms expressed concern that such actions stifled visibility and expression, potentially isolating LGBTQ+ individuals and communities, especially in spaces that were historically important for outreach and support. Numerous lawsuits have been filed against the company, both when it was known as Facebook, Inc., and as Meta Platforms. In March 2020, the Office of theAustralian Information Commissioner(OAIC) sued Facebook, for significant and persistent infringements of the rule on privacy involving theCambridge Analytica fiasco. Every violation of the Privacy Act is subject to a theoretical cumulative liability of $1.7 million. The OAIC estimated that a total of 311,127 Australians had been exposed. On December 8, 2020, the U.S.Federal Trade Commissionand 46 states (excluding Alabama, Georgia, South Carolina, and South Dakota), theDistrict of Columbiaand the territory ofGuam, launchedFederal Trade Commission v. Facebookas an antitrust lawsuit against Facebook. The lawsuit concerns Facebook's acquisition of two competitors—InstagramandWhatsApp—and the ensuing monopolistic situation. FTC alleges that Facebook holds monopolistic power in the U.S. social networking market and seeks to force the company to divest from Instagram and WhatsApp to break up the conglomerate.William Kovacic, a former chairman of the Federal Trade Commission, argued the case will be difficult to win as it would require the government to create a counterfactual argument of an internet where the Facebook-WhatsApp-Instagram entity did not exist, and prove that harmed competition or consumers. On December 24, 2021, a court in Russia fined Meta for $27 million after the company declined to remove unspecified banned content. The fine was reportedly tied to the company's annual revenue in the country. In May 2022, a lawsuit was filed in Kenya against Meta and its local outsourcing companySama. Allegedly, Meta has poor working conditions in Kenya forworkers moderatingFacebook posts. According to the lawsuit, 260 screeners were declared redundant with confusing reasoning. The lawsuit seeks financial compensation and an order that outsourced moderators be given the same health benefits and pay scale as Meta employees. In June 2022, 8 lawsuits were filed across the U.S. over the allege that excessive exposure to platforms including Facebook and Instagram has led to attempted or actual suicides, eating disorders and sleeplessness, among other issues. The litigation follows a former Facebook employee's testimony in Congress that the company refused to take responsibility. The company noted that tools have been developed for parents to keep track of their children's activity on Instagram and set time limits, in addition to Meta's \"Take a break\" reminders. In addition, the company is providing resources specific to eating disorders as well as developing AI to prevent children under the age of 13 signing up for Facebook or Instagram. In June 2022, Meta settled a lawsuit with theUS Department of Justice. The lawsuit, which was filed in 2019, alleged that the company enabled housing discrimination through targeted advertising, as it allowed homeowners and landlords to run housing ads excluding people based on sex, race, religion, and other characteristics. The U.S. Department of Justice stated that this was in violation of theFair Housing Act. Meta was handed a penalty of $115,054 and given until December 31, 2022, to shadow the algorithm tool. In January 2023, Meta was fined €390 million for violations of the European UnionGeneral Data Protection Regulation. In May 2023, theEuropean Data Protection Boardfined Meta a record €1.2 billion for breaching European Union data privacy laws by transferring personal data of Facebook users to servers in the U.S. In July 2024, Meta agreed to pay the state ofTexasUS$1.4 billionto settle a lawsuit brought by Texas Attorney GeneralKen Paxtonaccusing the company of collecting users'biometricdata without consent, setting a record for the largest privacy-related settlement ever obtained by a state attorney general. In October 2024, Meta Platforms faced lawsuits in Japan from 30 plaintiffs who claimed they were defrauded by fake investment ads on Facebook and Instagram, featuring false celebrity endorsements. The plaintiffs are seeking approximately $2.8 million in damages. In April 2025, theKenyan High Courtruled that aUS$2.4 billionlawsuit in which three plaintiffs claim that Facebook inflamed civil violence inEthiopiain 2021 could proceed. In April 2025, Meta was fined €200 million ($230 million) for breaking theDigital Markets Act, by imposing a “consent or pay” system that forces users to either allow their personal data to be used to target advertisements, or pay a subscription fee for advertising-free versions ofFacebookandInstagram. In late April 2025, a case was filed against Meta in Ghana over the alleged psychological distress experienced by content moderators employed to take down disturbing social media content including depictions of murders, extreme violence and child sexual abuse.Meta moved the moderation service to the Ghanaian capital of Accra after legal issues in the previous location Kenya. The new moderation company is Teleperformance, a multinational corporation with a history of worker's rights violation.Reports suggests the conditions are worse here than in the previous Kenyan location, with many workers afraid of speaking out due to fear of returning to conflict zones. Workers reported developing mental illnesses, attempted suicides, and low pay. In 2020, the company UReputation, which had been involved in several cases concerning the management of digital armies, filed a lawsuit against Facebook, accusing it of unlawfully transmitting personal data to third parties. Legal actions were initiated in Tunisia, France, and the United States. In 2025, the United States District court for the Northern District of Georgia approved a discovery procedure, allowing UReputation to access documents and evidence held by Meta. Meta's key management consists of: As of October 2022, Meta had 83,553 employees worldwide. As of June 2024, Meta'sboardconsisted of the following directors; Meta Platforms is mainly owned by institutional investors, who hold around 80% of all shares.Insiders control the majority of voting Shares. The three largest individual investors in 2024 were Mark Zuckerberg, Sheryl Sandberg and Christopher K. Cox. The largest shareholders in late 2024/early 2025 were: Roger McNamee, an early Facebook investor and Zuckerberg's former mentor, said Facebook had \"the most centralized decision-making structure I have ever encountered in a large company\". Facebook co-founder Chris Hughes has stated that chief executive officer Mark Zuckerberg has too much power, that the company is now a monopoly, and that, as a result, it should be split into multiple smaller companies. In anop-edinThe New York Times, Hughes said he was concerned that Zuckerberg had surrounded himself with a team that did not challenge him, and that it is the U.S. government's job to hold him accountable and curb his \"unchecked power\".He also said that \"Mark's power is unprecedented and un-American.\"Several U.S. politicians agreed with Hughes.European UnionCommissioner for CompetitionMargrethe Vestager stated that splitting Facebook should be done only as \"a remedy of the very last resort\", and that it would not solve Facebook's underlying problems. Facebook ranked No. 34 in the 2020Fortune 500list of the largest United States corporations by revenue, with almost $86 billion in revenuemost of it coming from advertising.One analysis of 2017 data determined that the company earnedUS$20.21per user from advertising. According toNew York, since its rebranding, Meta has reportedly lost $500 billion as a result of new privacy measures put in place by companies such as Apple and Google which prevents Meta from gathering users' data. In February 2015,Facebookannounced it had reached two million active advertisers, with most of the gain coming from small businesses. An active advertiser was defined as an entity that had advertised on the Facebook platform in the last 28 days.In March 2016, Facebook announced it had reached three million active advertisers with more than 70% from outside the United States.Prices for advertising follow a variable pricing model based on auctioning ad placements, and potential engagement levels of the advertisement itself. Similar to other online advertising platforms like Google and Twitter, targeting of advertisements is one of the chief merits of digital advertising compared totraditional media. Marketing on Meta is employed through two methods based on the viewing habits, likes and shares, and purchasing data of the audience, namely targeted audiences and \"look alike\" audiences. The U.S. IRS challenged the valuation Facebook used when it transferred IP from the U.S. to Facebook Ireland (now Meta Platforms Ireland) in 2010 (which Facebook Ireland then revalued higher before charging out), as it was building itsdouble Irishtax structure.The case is ongoing and Meta faces a potential fine of $3–5bn. The U.S.Tax Cuts and Jobs Act of 2017changed Facebook's global tax calculations. Meta Platforms Ireland is subject to the U.S. GILTI tax of 10.5% on global intangible profits (i.e. Irish profits). On the basis that Meta Platforms Ireland Limited is paying some tax, the effective minimum US tax for Facebook Ireland will be circa 11%. In contrast, Meta Platforms Inc. would incur a special IP tax rate of 13.125% (the FDII rate) if its Irish business relocated to the U.S. Tax relief in the U.S. (21% vs. Irish at the GILTI rate) and accelerated capital expensing, would make this effective U.S. rate around 12%. The insignificance of the U.S./Irish tax difference was demonstrated when Facebook moved 1.5bn non-EU accounts to the U.S. to limit exposure toGDPR. Users outside of the U.S. and Canada contract with Meta's Irish subsidiary, Meta Platforms Ireland Limited (formerlyFacebook Ireland Limited), allowing Meta to avoid US taxes for all users in Europe, Asia, Australia, Africa and South America. Meta is making use of theDouble Irish arrangementwhich allows it to pay 2–3% corporation tax on all international revenue.In 2010, Facebook opened its fourth office, inHyderabad, India,which houses online advertising and developer support teams and provides support to users and advertisers.In India, Meta is registered as Facebook India Online Services Pvt Ltd.It also has offices or planned sites inChittagong, Bangladesh;Dublin, Ireland;; andAustin, Texas, among other cities. Facebook opened its London headquarters in 2017 in Fitzrovia incentral London. Facebook opened an office inCambridge, Massachusettsin 2018. The offices were initially home to the \"Connectivity Lab\", a group focused on bringing Internet access to those who do not have access to the Internet.In April 2019, Facebook opened itsTaiwanheadquarters inTaipei. In March 2022, Meta opened new regional headquarters inDubai. In September 2023, it was reported that Meta had paid £149m toBritish Landto break the lease on Triton Square London office. Meta reportedly had another 18 years left on its lease on the site. As of 2023, Facebook operated 21 data centers.It committed to purchase 100% renewable energy and to reduce its greenhouse gas emissions 75% by 2020.Its data center technologies include Fabric Aggregator, a distributed network system that accommodates larger regions and varied traffic patterns. US RepresentativeAlexandria Ocasio-Cortezresponded in a tweet to Zuckerberg's announcement about Meta, saying: \"Meta as in 'we are a cancer to democracy metastasizing into a global surveillance and propaganda machine for boosting authoritarian regimes and destroying civil society ... for profit!'\" Ex-Facebook employeeFrances Haugenand whistleblower behind theFacebook Papersresponded to the rebranding efforts by expressing doubts about the company's ability to improve while led byMark Zuckerberg, and urged the chief executive officer to resign. In November 2021, a video published by Inspired by Iceland went viral, in which a Zuckerberg look-alike promoted the Icelandverse, a place of \"enhanced actual reality without silly looking headsets\". In a December 2021 interview, SpaceX and Tesla chief executive officerElon Musksaid he could not see a compelling use-case for the VR-driven metaverse, adding: \"I don't see someone strapping a frigging screen to their face all day.\" In January 2022, Louise Eccles ofThe Sunday Timeslogged into the metaverse with the intention of making a video guide. She wrote: Initially, my experience with the Oculus went well. I attended work meetings as an avatar and tried an exercise class set in the streets of Paris. The headset enabled me to feel the thrill of carving down mountains on a snowboard and the adrenaline rush of climbing a mountain without ropes. Yet switching to the social apps, where you mingle with strangers also using VR headsets, it was at times predatory and vile. Eccles described beingsexually harassedby another user, as well as \"accents from all over the world, American, Indian, English, Australian, using racist, sexist, homophobic and transphobic language\". She also encountered users as young as 7 years old on the platform, despite Oculus headsets being intended for users over 13. 37°29′06″N122°08′54″W﻿ / ﻿37.48500°N 122.14833°W﻿ /37.48500; -122.14833", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Meta_Platforms", "https://en.wikipedia.org/wiki/Meta_Platforms", "https://en.wikipedia.org/wiki/Meta_Platforms", "https://en.wikipedia.org/wiki/Geographic_coordinate_system", "https://en.wikipedia.org/wiki/Facebook", "https://en.wikipedia.org/wiki/Menlo_Park,_California", "https://en.wikipedia.org/wiki/Trade_name", "https://en.wikipedia.org/wiki/Public_company"]},
{"id": "92e155bb916e", "url": "https://en.wikipedia.org/wiki/Allen_Newell", "title": "Allen Newell", "headings": ["Contents", "Early studies", "Artificial intelligence", "Later achievements", "Awards and honors", "See also", "Notes", "References", "Further reading", "External links"], "content": "Allen Newell(March 19, 1927 – July 19, 1992) was an American researcher incomputer scienceandcognitive psychologyat theRAND Corporationand atCarnegie Mellon University'sSchool of Computer Science,Tepper School of Business, and Department of Psychology. He,Herbert A. Simon, andCliff Shawcontributed to theInformation Processing Language(1956) and two of the earliestAIprograms, theLogic Theorist(1956) and theGeneral Problem Solver(1957). He and Simon were awarded theACM'sA.M. Turing Awardin 1975 for their contributions to artificial intelligence and the psychology of human cognition. Newell completed his bachelor's degree in physics fromStanfordin 1949. He was a graduate student atPrinceton Universityfrom 1949 to 1950, where he studied mathematics. Due to his early exposure to an unknown field known asgame theoryand the experiences from the study of mathematics, he was convinced that he would prefer a combination of experimental and theoretical research to pure mathematics. In 1950, he left Princeton and joined theRANDCorporation in Santa Monica where he worked for \"a group that was studying logistics problems of the Air Force\".His work withJoseph Kruskalled to the creation of two theories: A Model for Organization Theory and Formulating Precise Concepts in Organization Theory.  Newell eventually earned his PhD from the nowTepper School of Businessat Carnegie Mellon with Herbert Simon serving as his advisor. Afterwards, Newell \"turned to the design and conduct of laboratory experiments on decision making in small groups\".He was dissatisfied, however, with the accuracy and validity of their findings produced from small-scale laboratory experiments. He joined with fellow RAND teammates John Kennedy, Bob Chapman, and Bill Biel at an Air ForceEarly WarningStation to study organizational processes in flight crews. They received funding from the Air Force in 1952 to build a simulator that would enable them to examine and analyze the interactions in the cockpit related to decision-making and information-handling. From these studies, Newell came to believe thatinformation processingis the central activity in organizations. In September 1954, Newell enrolled in a seminar whereOliver Selfridge\"described a running computer program that learned to recognize letters and other patterns\".This was when Allen came to believe that systems may be created and contain intelligence and have the ability to adapt. With this in mind, Allen, after a couple of months, wrote in 1955The Chess Machine: An Example of Dealing with a Complex Task by Adaptation, which \"outlined an imaginative design for a computer program to playchessin humanoid fashion\". His work came to the attention of economist (and future nobel laureate)Herbert A. Simon, and, together with programmerJ. C. Shaw, they developed the first trueartificial intelligenceprogram(see notes), theLogic Theorist. Newell's work on the program laid the foundations of the field. His inventions included:list processing, the most important programming paradigm used by AI ever since;  the application ofmeans-ends analysisto general reasoning (or \"reasoning as search\"); and the use ofheuristicsto limit the search space. They presented the program at theDartmouth conferenceof 1956, an informal gathering of researchers who were interested in simulating intelligence with machines. The conference, now widely considered the \"birth of artificial intelligence\",was enormously influential and those who attended became the leaders of AI research for the next two decades, Newell included. Newell and Simon formed a lasting partnership. They founded an artificial intelligence laboratory atCarnegie Mellon Universityand produced a series of important programs and theoretical insights throughout the late fifties and sixties. This work included theGeneral Problem Solver, a highly influential implementation ofmeans–ends analysis, and thephysical symbol systems hypothesis, the controversial philosophical assertion that all intelligent behavior could be reduced to the kind of symbol manipulation that Newell's programs demonstrated. Newell's work culminated in the development of acognitive architectureknown asSoarand hisunified theory of cognition, published in 1990, but their improvement was the objective of his efforts up to his death (one of the last Newell's lettersArchived2011-05-14 at theWayback Machine). The field of cognitive architectures, that he initiated, is still active in both the artificial intelligence and computational cognitive science communities. TheACM - AAAI Allen Newell Awardwas named in his honor.  TheAward for Research Excellenceof theCarnegie Mellon School of Computer Sciencewas also named in his honor. Logic theorist is usually considered the first true AI program, although Arthur Samuel's checkers program was released earlier. Christopher Strachey also wrote a checkers program in 1951", "combined_text": "Allen Newell Contents Early studies Artificial intelligence Later achievements Awards and honors See also Notes References Further reading External links Allen Newell(March 19, 1927 – July 19, 1992) was an American researcher incomputer scienceandcognitive psychologyat theRAND Corporationand atCarnegie Mellon University'sSchool of Computer Science,Tepper School of Business, and Department of Psychology. He,Herbert A. Simon, andCliff Shawcontributed to theInformation Processing Language(1956) and two of the earliestAIprograms, theLogic Theorist(1956) and theGeneral Problem Solver(1957). He and Simon were awarded theACM'sA.M. Turing Awardin 1975 for their contributions to artificial intelligence and the psychology of human cognition. Newell completed his bachelor's degree in physics fromStanfordin 1949. He was a graduate student atPrinceton Universityfrom 1949 to 1950, where he studied mathematics. Due to his early exposure to an unknown field known asgame theoryand the experiences from the study of mathematics, he was convinced that he would prefer a combination of experimental and theoretical research to pure mathematics. In 1950, he left Princeton and joined theRANDCorporation in Santa Monica where he worked for \"a group that was studying logistics problems of the Air Force\".His work withJoseph Kruskalled to the creation of two theories: A Model for Organization Theory and Formulating Precise Concepts in Organization Theory.  Newell eventually earned his PhD from the nowTepper School of Businessat Carnegie Mellon with Herbert Simon serving as his advisor. Afterwards, Newell \"turned to the design and conduct of laboratory experiments on decision making in small groups\".He was dissatisfied, however, with the accuracy and validity of their findings produced from small-scale laboratory experiments. He joined with fellow RAND teammates John Kennedy, Bob Chapman, and Bill Biel at an Air ForceEarly WarningStation to study organizational processes in flight crews. They received funding from the Air Force in 1952 to build a simulator that would enable them to examine and analyze the interactions in the cockpit related to decision-making and information-handling. From these studies, Newell came to believe thatinformation processingis the central activity in organizations. In September 1954, Newell enrolled in a seminar whereOliver Selfridge\"described a running computer program that learned to recognize letters and other patterns\".This was when Allen came to believe that systems may be created and contain intelligence and have the ability to adapt. With this in mind, Allen, after a couple of months, wrote in 1955The Chess Machine: An Example of Dealing with a Complex Task by Adaptation, which \"outlined an imaginative design for a computer program to playchessin humanoid fashion\". His work came to the attention of economist (and future nobel laureate)Herbert A. Simon, and, together with programmerJ. C. Shaw, they developed the first trueartificial intelligenceprogram(see notes), theLogic Theorist. Newell's work on the program laid the foundations of the field. His inventions included:list processing, the most important programming paradigm used by AI ever since;  the application ofmeans-ends analysisto general reasoning (or \"reasoning as search\"); and the use ofheuristicsto limit the search space. They presented the program at theDartmouth conferenceof 1956, an informal gathering of researchers who were interested in simulating intelligence with machines. The conference, now widely considered the \"birth of artificial intelligence\",was enormously influential and those who attended became the leaders of AI research for the next two decades, Newell included. Newell and Simon formed a lasting partnership. They founded an artificial intelligence laboratory atCarnegie Mellon Universityand produced a series of important programs and theoretical insights throughout the late fifties and sixties. This work included theGeneral Problem Solver, a highly influential implementation ofmeans–ends analysis, and thephysical symbol systems hypothesis, the controversial philosophical assertion that all intelligent behavior could be reduced to the kind of symbol manipulation that Newell's programs demonstrated. Newell's work culminated in the development of acognitive architectureknown asSoarand hisunified theory of cognition, published in 1990, but their improvement was the objective of his efforts up to his death (one of the last Newell's lettersArchived2011-05-14 at theWayback Machine). The field of cognitive architectures, that he initiated, is still active in both the artificial intelligence and computational cognitive science communities. TheACM - AAAI Allen Newell Awardwas named in his honor.  TheAward for Research Excellenceof theCarnegie Mellon School of Computer Sciencewas also named in his honor. Logic theorist is usually considered the first true AI program, although Arthur Samuel's checkers program was released earlier. Christopher Strachey also wrote a checkers program in 1951", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Allen_Newell", "https://en.wikipedia.org/wiki/Allen_Newell", "https://en.wikipedia.org/wiki/Allen_Newell", "https://en.wikipedia.org/wiki/Alan_Newell_(disambiguation)", "https://en.wikipedia.org/wiki/San_Francisco,_California", "https://en.wikipedia.org/wiki/Pittsburgh,_Pennsylvania", "https://en.wikipedia.org/wiki/Stanford_University", "https://en.wikipedia.org/wiki/Bachelor_of_Science"]},
{"id": "971d00ba8918", "url": "https://en.wikipedia.org/wiki/Turing_test_(disambiguation)", "title": "Turing test (disambiguation)", "headings": [], "content": "TheTuring testis a test proposed by Alan Turing of a machine's ability to exhibit intelligent behaviour. The Turing Testmay also refer to:", "combined_text": "Turing test (disambiguation)  TheTuring testis a test proposed by Alan Turing of a machine's ability to exhibit intelligent behaviour. The Turing Testmay also refer to:", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Turing_test_(disambiguation)", "https://en.wikipedia.org/wiki/Turing_test_(disambiguation)", "https://en.wikipedia.org/wiki/Turing_test_(disambiguation)", "https://en.wikipedia.org/wiki/Turing_test", "https://en.wikipedia.org/wiki/The_Turing_Test_(novel)", "https://en.wikipedia.org/wiki/The_Turing_Test_(video_game)", "https://en.wikipedia.org/wiki/Julian_Wagstaff"]},
{"id": "d1c3961aa454", "url": "https://en.wikipedia.org/wiki/Computer-generated_imagery", "title": "Computer-generated imagery", "headings": ["Contents", "History", "Static images and landscapes", "Architectural scenes", "Anatomical models", "Cloth and skin images", "Interactive simulation and visualization", "Computer animation", "Text-to-image models", "Virtual worlds", "In courtrooms", "Broadcast and live events", "Motion capture", "See also", "References", "Citations", "Sources", "External links"], "content": "Computer-generated imagery(CGI) is a specific-technology or application ofcomputer graphicsfor creating or improving images inart,printed media,simulators, videos and video games. These images are either static (i.e.still images) or dynamic (i.e. moving images). CGI both refers to 2D computer graphics and (more frequently) 3D computer graphics with the purpose of designing characters,virtual worlds, or scenes andspecial effects(infilms, television programs, commercials, etc.). The application of CGI for creating/improvinganimationsis calledcomputer animation(orCGI animation). The first feature film to use CGI as well as the composition of live-action film with CGI wasVertigo,which used abstract computer graphics byJohn Whitneyin the opening credits of the film. The first feature film to make use of CGI with live action in the storyline of the film was the 1973 filmWestworld.The first feature film to present a fully CGI character was the 1985 filmYoung Sherlock Holmes, showcasing a fully animated stained glass knight character.Other early films that incorporated CGI includeDemon Seed(1977),Star Wars(1977),Tron(1982),Star Trek II: The Wrath of Khan(1982),Golgo 13: The Professional(1983),The Last Starfighter(1984),The Abyss(1989),Terminator 2: Judgement Day(1991), andJurassic Park(1993). The firstmusic videoto use CGI wasWill Powers' \"Adventures in Success\" (1983).In 1995,Pixar'sToy Storybecame the first fully CGI feature film, marking a historic milestone for both animation and film-making.Prior to CGI being prevalent in film, virtual reality, personal computing and gaming, one of the early practical applications of CGI was for aviation and military training, namely theflight simulator. Visual systems developed in flight simulators were also an important precursor to three dimensional computer graphics and Computer Generated Imagery (CGI) systems today. Namely because the object of flight simulation was to reproduce on the ground the behavior of an aircraft in flight. Much of this reproduction had to do with believable visual synthesis that mimicked reality.The Link Digital Image Generator (DIG) by the Singer Company (Singer-Link), was considered one of the world's first generation CGI systems.It was a real-time, 3D capable, day/dusk/night system that was used by NASA shuttles, for F-111s, Black Hawk and the B-52. Link's Digital Image Generator had architecture to provide a visual system that realistically corresponded with the view of the pilot.The basic architecture of the DIG and subsequent improvements contained a scene manager followed by geometric processor, video processor and into the display with the end goal of a visual system that processed realistic texture, shading, translucency capabilities, and free of aliasing. Combined with the need to pair virtual synthesis with military level training requirements, CGI technologies applied in flight simulation were often years ahead of what would have been available in commercial computing or even in high budget film. Early CGI systems could depict only objects consisting of planar polygons. Advances in algorithms and electronics in flight simulator visual systems and CGI in the 1970s and 1980s influenced many technologies still used in modern CGI adding the ability to superimpose texture over the surfaces as well as transition imagery from one level of detail to the next one in a smooth manner. The evolution of CGI led to the emergence ofvirtual cinematographyin the 1990s, where the vision of thesimulatedcamerais not constrained by the laws of physics. Availability of CGI software and increased computer speeds have allowed individual artists and small companies to produce professional-grade films, games, and fine art from their home computers. Not only do animated images form part of computer-generated imagery; natural looking landscapes (such asfractal landscapes) are also generated via computeralgorithms. A simple way to generate fractal surfaces is to use an extension of thetriangular meshmethod, relying on the construction of some special case of ade Rham curve, e.g.,midpoint displacement.For instance, the algorithm may start with a large triangle, then recursively zoom in by dividing it into four smallerSierpinski triangles, then interpolate the height of each point from its nearest neighbors.The creation of aBrownian surfacemay be achieved not only by adding noise as new nodes are created but by adding additional noise at multiple levels of the mesh.Thus atopographicalmap with varying levels of height can be created using relatively straightforward fractal algorithms. Some typical, easy-to-program fractals used in CGI are theplasma fractaland the more dramaticfault fractal. Many specific techniques have been researched and developed to produce highly focused computer-generated effects — e.g., the use of specific models to represent the chemical weathering of stones to model erosion and produce an \"aged appearance\" for a given stone-based surface. Modern architects use services from computer graphic firms to create 3-dimensional models for both customers and builders. These computer generated models can be more accurate than traditional drawings.Architectural animation(which provides animated movies of buildings, rather than interactive images) can also be used to see the possible relationship a building will have in relation to the environment and its surrounding buildings. The processing of architectural spaces without the use of paper and pencil tools is now a widely accepted practice with a number of computer-assisted architectural design systems. Architectural modeling tools allow an architect to visualize a space and perform \"walk-throughs\" in an interactive manner, thus providing \"interactive environments\" both at the urban and building levels.Specific applications in architecture not only include the specification of building structures (such as walls and windows) and walk-throughs but the effects of light and how sunlight will affect a specific design at different times of the day. Architectural modeling tools have now become increasingly internet-based. However, the quality of internet-based systems still lags behind sophisticated in-house modeling systems. In some applications, computer-generated images are used to \"reverse engineer\" historical buildings. For instance, a computer-generated reconstruction of the monastery atGeorgenthalin Germany was derived from the ruins of the monastery, yet provides the viewer with a \"look and feel\" of what the building would have looked like in its day. Computer generated models used inskeletal animationare not always anatomically correct. However, organizations such as theScientific Computing and Imaging Institutehave developed anatomically correct computer-based models. Computer generated anatomical models can be used both for instructional and operational purposes. To date, a large body of artist-producedmedical imagescontinue to be used by medical students, such as images byFrank H. Netter, e.g.Cardiac images. However, a number of online anatomical models are becoming available. A single patientX-rayis not a computer generated image, even if digitized. However, in applications which involveCT scansa three-dimensional model is automatically produced from many single-slice x-rays, producing \"computer generated image\". Applications involvingmagnetic resonance imagingalso bring together a number of \"snapshots\" (in this case via magnetic pulses) to produce a composite, internal image. In modern medical applications, patient-specific models are constructed in 'computer assisted surgery'. For instance, in totalknee replacement, the construction of a detailed patient-specific model can be used to carefully plan the surgery.These three-dimensional models are usually extracted from multipleCT scansof the appropriate parts of the patient's own anatomy. Such models can also be used for planningaortic valveimplantations, one of the common procedures for treatingheart disease. Given that the shape, diameter, and position of thecoronaryopenings can vary greatly from patient to patient, the extraction (fromCT scans) of a model that closely resembles a patient's valve anatomy can be highly beneficial in planning the procedure. Models of clothgenerally fall into three groups: To date, making the clothing of a digital character automatically fold in a natural way remains a challenge for many animators. In addition to their use in film, advertising and other modes of public display, computer generated images of clothing are now routinely used by top fashion design firms. The challenge in renderinghuman skinimages involves three levels of realism: The finest visible features such as finewrinklesand skinporesare the size of about 100μmor 0.1millimetres. Skin can be modeled as a 7-dimensionalbidirectional texture function(BTF) or a collection ofbidirectional scattering distribution function(BSDF) over the target's surfaces. When animating a texture like hair or fur for a computer generated model, individual base hairs are first created and later duplicated to demonstrate volume.The initial hairs are often different lengths and colors, to each cover several different sections of a model. This technique was notably used inPixar'sMonsters Inc(2001) for the character Sulley, who had approximately 1,000 initial hairs generated that were later duplicated 2,800 times.The quantity of duplications can range from thousands to millions, depending on the level of detail sought after. Interactive visualization is the rendering of data that may vary dynamically and allowing a user to view the data from multiple perspectives. The applications areas may vary significantly, ranging from the visualization of the flow patterns influid dynamicsto specificcomputer aided designapplications.The data rendered may correspond to specific visual scenes that change as the user interacts with the system — e.g. simulators, such asflight simulators, make extensive use of CGI techniques for representing the world. At the abstract level, an interactive visualization process involves a \"data pipeline\" in which the raw data is managed and filtered to a form that makes it suitable for rendering. This is often called the\"visualization data\". The visualization data is then mapped to a \"visualization representation\" that can be fed to a rendering system. This is usually called a\"renderable representation\". This representation is then rendered as a displayable image.As the user interacts with the system (e.g. by using joystick controls to change their position within the virtual world) the raw data is fed through the pipeline to create a new rendered image, often making real-time computational efficiency a key consideration in such applications. While computer-generated images of landscapes may be static,computer animationonly applies to dynamic images that resemble a movie. However, in general, the term computer animation refers to dynamic images that do not allow user interaction, and the termvirtual worldis used for the interactive animated environments. Computer animation is essentially a digital successor to the art ofstop motionanimation of 3D models and frame-by-frame animation of 2D illustrations. Computer generated animations are more controllable than other more physically based processes, such as constructingminiaturesfor effects shots or hiringextrasfor crowd scenes, and because it allows the creation of images that would not be feasible using any other technology. It can also allow a single graphic artist to produce such content without the use of actors, expensive set pieces, or props. To create the illusion of movement, an image is displayed on thecomputer screenand repeatedly replaced by a new image which is similar to the previous image, but advanced slightly in the time domain (usually at a rate of 24 or 30 frames/second). This technique is identical to how the illusion of movement is achieved withtelevisionandmotion pictures. Atext-to-image model (T2I or TTI model)is amachine learning modelwhich takes an inputnatural language promptand produces an image matching that description. Text-to-image models began to be developed in the mid-2010s during the beginnings of theAI boom, as a result of advances indeep neural networks. In 2022, the output of state-of-the-art text-to-image models—such as OpenAI'sDALL-E 2,Google Brain'sImagen, Stability AI'sStable Diffusion,Midjourney, and Runway's Gen-4—began to be considered to approach the quality ofreal photographsand human-drawnart. A virtual world is anagent-basedandsimulated environmentallowing users to interact with artificially animated characters (e.gsoftware agent) or with other physical users, through the use ofavatars. Virtual worlds are intended for itsusersto inhabit and interact, and the term today has become largely synonymous with interactive 3D virtual environments, where the users take the form ofavatarsvisible to others graphically.These avatars are usually depicted as textual, two-dimensional, orthree-dimensional graphicalrepresentations, although other forms are possible(auditoryand touch sensations for example). Some, but not all, virtual worlds allow for multiple users. Computer-generated imagery has been used in courtrooms, primarily since the early 2000s. However, some experts have argued that it is prejudicial. They are used to help judges or the jury to better visualize the sequence of events, evidence or hypothesis.However, a 1997 study showed that people are poor intuitive physicists and easily influenced by computer generated images.Thus it is important that jurors and other legal decision-makers be made aware that such exhibits are merely a representation of one potential sequence of events. Weather visualizations were the first application of CGI in television.  One of the first companies to offer computer systems for generating weather graphics wasColorGraphics Weather Systemsin 1979 with the \"LiveLine\", based around anApple IIcomputer, with later models from ColorGraphics usingCromemcocomputers fitted with theirDazzlervideo graphics card. It has now become common in weather casting to display full motion video of images captured in real-time from multiple cameras and other imaging devices. Coupled with 3D graphics symbols and mapped to a common virtual geospatial model, these animated visualizations constitute the first true application of CGI to TV. CGI has become common in sports telecasting. Sports and entertainment venues are provided with see-through and overlay content through tracked camera feeds for enhanced viewing by the audience. Examples include the yellow \"first down\" line seen in television broadcasts ofAmerican footballgames showing the line the offensive team must cross to receive a first down. CGI is also used in association with football and other sporting events to show commercial advertisements overlaid onto the view of the playing area. Sections ofrugbyfields andcricketpitches also display sponsored images. Swimming telecasts often add a line across the lanes to indicate the position of the current record holder as a race proceeds to allow viewers to compare the current race to the best performance. Other examples include hockey puck tracking and annotations of racing car performanceand snooker ball trajectories.Sometimes CGI on TV with correct alignment to the real world has been referred to asaugmented reality. Computer-generated imagery is often used in conjunction withmotion captureto better cover the faults that come with CGI and animation.Computer-generated imagery is limited in its practical application by how realistic it can look. Unrealistic, or badly managed computer-generated imagery can result in theuncanny valleyeffect.This effect refers to the human ability to recognize things that look eerily like humans, but are slightly off. Such ability is a fault with normal computer-generated imagery which, due to the complex anatomy of the human body, can often fail to replicate it perfectly. Artists can use motion capture to get footage of a human performing an action and then replicate it perfectly with computer-generated imagery so that it looks normal. In many instances, motion capture is needed to accurately mimic an actor's full body movements while slightly changing their appearance with de-aging.De-agingis a visual effect used to alter the appearance of an actor, often through facial scanning technologies,motion capture, and photo references. It is commonly used for flashback scenes and cameos to have an actor appear younger.Marvel'sX-Men: The Last Standwas the first film to publicly incorporate de-aging, which was used on actorsPatrick StewartandIan Mckellenfor flashback scenes featuring their characters at a younger age.The visual effects were done by the companyLola VFX, and used photos taken of the actors at a younger age as references to later smooth out the wrinkles on their face with use of CGI. Overtime, de-aging technologies have advanced, with films such asHere(2024), portraying actors at younger ages through the use of digital AI techniques, scanning millions of facial features and incorporating a number of them onto actors' faces to alter their appearance. The lack of anatomically correct digital models contributes to the necessity of motion capture as it is used with computer-generated imagery. Because computer-generated imagery reflects only the outside, or skin, of the object being rendered, it fails to capture the infinitesimally small interactions between interlocking muscle groups used infine motor skillslike speaking. The constant motion of the face as it makes sounds with shaped lips and tongue movement, along with the facial expressions that go along with speaking are difficult to replicate by hand.Motion capture can catch the underlying movement of facial muscles and better replicate the visual that goes along with the audio.", "combined_text": "Computer-generated imagery Contents History Static images and landscapes Architectural scenes Anatomical models Cloth and skin images Interactive simulation and visualization Computer animation Text-to-image models Virtual worlds In courtrooms Broadcast and live events Motion capture See also References Citations Sources External links Computer-generated imagery(CGI) is a specific-technology or application ofcomputer graphicsfor creating or improving images inart,printed media,simulators, videos and video games. These images are either static (i.e.still images) or dynamic (i.e. moving images). CGI both refers to 2D computer graphics and (more frequently) 3D computer graphics with the purpose of designing characters,virtual worlds, or scenes andspecial effects(infilms, television programs, commercials, etc.). The application of CGI for creating/improvinganimationsis calledcomputer animation(orCGI animation). The first feature film to use CGI as well as the composition of live-action film with CGI wasVertigo,which used abstract computer graphics byJohn Whitneyin the opening credits of the film. The first feature film to make use of CGI with live action in the storyline of the film was the 1973 filmWestworld.The first feature film to present a fully CGI character was the 1985 filmYoung Sherlock Holmes, showcasing a fully animated stained glass knight character.Other early films that incorporated CGI includeDemon Seed(1977),Star Wars(1977),Tron(1982),Star Trek II: The Wrath of Khan(1982),Golgo 13: The Professional(1983),The Last Starfighter(1984),The Abyss(1989),Terminator 2: Judgement Day(1991), andJurassic Park(1993). The firstmusic videoto use CGI wasWill Powers' \"Adventures in Success\" (1983).In 1995,Pixar'sToy Storybecame the first fully CGI feature film, marking a historic milestone for both animation and film-making.Prior to CGI being prevalent in film, virtual reality, personal computing and gaming, one of the early practical applications of CGI was for aviation and military training, namely theflight simulator. Visual systems developed in flight simulators were also an important precursor to three dimensional computer graphics and Computer Generated Imagery (CGI) systems today. Namely because the object of flight simulation was to reproduce on the ground the behavior of an aircraft in flight. Much of this reproduction had to do with believable visual synthesis that mimicked reality.The Link Digital Image Generator (DIG) by the Singer Company (Singer-Link), was considered one of the world's first generation CGI systems.It was a real-time, 3D capable, day/dusk/night system that was used by NASA shuttles, for F-111s, Black Hawk and the B-52. Link's Digital Image Generator had architecture to provide a visual system that realistically corresponded with the view of the pilot.The basic architecture of the DIG and subsequent improvements contained a scene manager followed by geometric processor, video processor and into the display with the end goal of a visual system that processed realistic texture, shading, translucency capabilities, and free of aliasing. Combined with the need to pair virtual synthesis with military level training requirements, CGI technologies applied in flight simulation were often years ahead of what would have been available in commercial computing or even in high budget film. Early CGI systems could depict only objects consisting of planar polygons. Advances in algorithms and electronics in flight simulator visual systems and CGI in the 1970s and 1980s influenced many technologies still used in modern CGI adding the ability to superimpose texture over the surfaces as well as transition imagery from one level of detail to the next one in a smooth manner. The evolution of CGI led to the emergence ofvirtual cinematographyin the 1990s, where the vision of thesimulatedcamerais not constrained by the laws of physics. Availability of CGI software and increased computer speeds have allowed individual artists and small companies to produce professional-grade films, games, and fine art from their home computers. Not only do animated images form part of computer-generated imagery; natural looking landscapes (such asfractal landscapes) are also generated via computeralgorithms. A simple way to generate fractal surfaces is to use an extension of thetriangular meshmethod, relying on the construction of some special case of ade Rham curve, e.g.,midpoint displacement.For instance, the algorithm may start with a large triangle, then recursively zoom in by dividing it into four smallerSierpinski triangles, then interpolate the height of each point from its nearest neighbors.The creation of aBrownian surfacemay be achieved not only by adding noise as new nodes are created but by adding additional noise at multiple levels of the mesh.Thus atopographicalmap with varying levels of height can be created using relatively straightforward fractal algorithms. Some typical, easy-to-program fractals used in CGI are theplasma fractaland the more dramaticfault fractal. Many specific techniques have been researched and developed to produce highly focused computer-generated effects — e.g., the use of specific models to represent the chemical weathering of stones to model erosion and produce an \"aged appearance\" for a given stone-based surface. Modern architects use services from computer graphic firms to create 3-dimensional models for both customers and builders. These computer generated models can be more accurate than traditional drawings.Architectural animation(which provides animated movies of buildings, rather than interactive images) can also be used to see the possible relationship a building will have in relation to the environment and its surrounding buildings. The processing of architectural spaces without the use of paper and pencil tools is now a widely accepted practice with a number of computer-assisted architectural design systems. Architectural modeling tools allow an architect to visualize a space and perform \"walk-throughs\" in an interactive manner, thus providing \"interactive environments\" both at the urban and building levels.Specific applications in architecture not only include the specification of building structures (such as walls and windows) and walk-throughs but the effects of light and how sunlight will affect a specific design at different times of the day. Architectural modeling tools have now become increasingly internet-based. However, the quality of internet-based systems still lags behind sophisticated in-house modeling systems. In some applications, computer-generated images are used to \"reverse engineer\" historical buildings. For instance, a computer-generated reconstruction of the monastery atGeorgenthalin Germany was derived from the ruins of the monastery, yet provides the viewer with a \"look and feel\" of what the building would have looked like in its day. Computer generated models used inskeletal animationare not always anatomically correct. However, organizations such as theScientific Computing and Imaging Institutehave developed anatomically correct computer-based models. Computer generated anatomical models can be used both for instructional and operational purposes. To date, a large body of artist-producedmedical imagescontinue to be used by medical students, such as images byFrank H. Netter, e.g.Cardiac images. However, a number of online anatomical models are becoming available. A single patientX-rayis not a computer generated image, even if digitized. However, in applications which involveCT scansa three-dimensional model is automatically produced from many single-slice x-rays, producing \"computer generated image\". Applications involvingmagnetic resonance imagingalso bring together a number of \"snapshots\" (in this case via magnetic pulses) to produce a composite, internal image. In modern medical applications, patient-specific models are constructed in 'computer assisted surgery'. For instance, in totalknee replacement, the construction of a detailed patient-specific model can be used to carefully plan the surgery.These three-dimensional models are usually extracted from multipleCT scansof the appropriate parts of the patient's own anatomy. Such models can also be used for planningaortic valveimplantations, one of the common procedures for treatingheart disease. Given that the shape, diameter, and position of thecoronaryopenings can vary greatly from patient to patient, the extraction (fromCT scans) of a model that closely resembles a patient's valve anatomy can be highly beneficial in planning the procedure. Models of clothgenerally fall into three groups: To date, making the clothing of a digital character automatically fold in a natural way remains a challenge for many animators. In addition to their use in film, advertising and other modes of public display, computer generated images of clothing are now routinely used by top fashion design firms. The challenge in renderinghuman skinimages involves three levels of realism: The finest visible features such as finewrinklesand skinporesare the size of about 100μmor 0.1millimetres. Skin can be modeled as a 7-dimensionalbidirectional texture function(BTF) or a collection ofbidirectional scattering distribution function(BSDF) over the target's surfaces. When animating a texture like hair or fur for a computer generated model, individual base hairs are first created and later duplicated to demonstrate volume.The initial hairs are often different lengths and colors, to each cover several different sections of a model. This technique was notably used inPixar'sMonsters Inc(2001) for the character Sulley, who had approximately 1,000 initial hairs generated that were later duplicated 2,800 times.The quantity of duplications can range from thousands to millions, depending on the level of detail sought after. Interactive visualization is the rendering of data that may vary dynamically and allowing a user to view the data from multiple perspectives. The applications areas may vary significantly, ranging from the visualization of the flow patterns influid dynamicsto specificcomputer aided designapplications.The data rendered may correspond to specific visual scenes that change as the user interacts with the system — e.g. simulators, such asflight simulators, make extensive use of CGI techniques for representing the world. At the abstract level, an interactive visualization process involves a \"data pipeline\" in which the raw data is managed and filtered to a form that makes it suitable for rendering. This is often called the\"visualization data\". The visualization data is then mapped to a \"visualization representation\" that can be fed to a rendering system. This is usually called a\"renderable representation\". This representation is then rendered as a displayable image.As the user interacts with the system (e.g. by using joystick controls to change their position within the virtual world) the raw data is fed through the pipeline to create a new rendered image, often making real-time computational efficiency a key consideration in such applications. While computer-generated images of landscapes may be static,computer animationonly applies to dynamic images that resemble a movie. However, in general, the term computer animation refers to dynamic images that do not allow user interaction, and the termvirtual worldis used for the interactive animated environments. Computer animation is essentially a digital successor to the art ofstop motionanimation of 3D models and frame-by-frame animation of 2D illustrations. Computer generated animations are more controllable than other more physically based processes, such as constructingminiaturesfor effects shots or hiringextrasfor crowd scenes, and because it allows the creation of images that would not be feasible using any other technology. It can also allow a single graphic artist to produce such content without the use of actors, expensive set pieces, or props. To create the illusion of movement, an image is displayed on thecomputer screenand repeatedly replaced by a new image which is similar to the previous image, but advanced slightly in the time domain (usually at a rate of 24 or 30 frames/second). This technique is identical to how the illusion of movement is achieved withtelevisionandmotion pictures. Atext-to-image model (T2I or TTI model)is amachine learning modelwhich takes an inputnatural language promptand produces an image matching that description. Text-to-image models began to be developed in the mid-2010s during the beginnings of theAI boom, as a result of advances indeep neural networks. In 2022, the output of state-of-the-art text-to-image models—such as OpenAI'sDALL-E 2,Google Brain'sImagen, Stability AI'sStable Diffusion,Midjourney, and Runway's Gen-4—began to be considered to approach the quality ofreal photographsand human-drawnart. A virtual world is anagent-basedandsimulated environmentallowing users to interact with artificially animated characters (e.gsoftware agent) or with other physical users, through the use ofavatars. Virtual worlds are intended for itsusersto inhabit and interact, and the term today has become largely synonymous with interactive 3D virtual environments, where the users take the form ofavatarsvisible to others graphically.These avatars are usually depicted as textual, two-dimensional, orthree-dimensional graphicalrepresentations, although other forms are possible(auditoryand touch sensations for example). Some, but not all, virtual worlds allow for multiple users. Computer-generated imagery has been used in courtrooms, primarily since the early 2000s. However, some experts have argued that it is prejudicial. They are used to help judges or the jury to better visualize the sequence of events, evidence or hypothesis.However, a 1997 study showed that people are poor intuitive physicists and easily influenced by computer generated images.Thus it is important that jurors and other legal decision-makers be made aware that such exhibits are merely a representation of one potential sequence of events. Weather visualizations were the first application of CGI in television.  One of the first companies to offer computer systems for generating weather graphics wasColorGraphics Weather Systemsin 1979 with the \"LiveLine\", based around anApple IIcomputer, with later models from ColorGraphics usingCromemcocomputers fitted with theirDazzlervideo graphics card. It has now become common in weather casting to display full motion video of images captured in real-time from multiple cameras and other imaging devices. Coupled with 3D graphics symbols and mapped to a common virtual geospatial model, these animated visualizations constitute the first true application of CGI to TV. CGI has become common in sports telecasting. Sports and entertainment venues are provided with see-through and overlay content through tracked camera feeds for enhanced viewing by the audience. Examples include the yellow \"first down\" line seen in television broadcasts ofAmerican footballgames showing the line the offensive team must cross to receive a first down. CGI is also used in association with football and other sporting events to show commercial advertisements overlaid onto the view of the playing area. Sections ofrugbyfields andcricketpitches also display sponsored images. Swimming telecasts often add a line across the lanes to indicate the position of the current record holder as a race proceeds to allow viewers to compare the current race to the best performance. Other examples include hockey puck tracking and annotations of racing car performanceand snooker ball trajectories.Sometimes CGI on TV with correct alignment to the real world has been referred to asaugmented reality. Computer-generated imagery is often used in conjunction withmotion captureto better cover the faults that come with CGI and animation.Computer-generated imagery is limited in its practical application by how realistic it can look. Unrealistic, or badly managed computer-generated imagery can result in theuncanny valleyeffect.This effect refers to the human ability to recognize things that look eerily like humans, but are slightly off. Such ability is a fault with normal computer-generated imagery which, due to the complex anatomy of the human body, can often fail to replicate it perfectly. Artists can use motion capture to get footage of a human performing an action and then replicate it perfectly with computer-generated imagery so that it looks normal. In many instances, motion capture is needed to accurately mimic an actor's full body movements while slightly changing their appearance with de-aging.De-agingis a visual effect used to alter the appearance of an actor, often through facial scanning technologies,motion capture, and photo references. It is commonly used for flashback scenes and cameos to have an actor appear younger.Marvel'sX-Men: The Last Standwas the first film to publicly incorporate de-aging, which was used on actorsPatrick StewartandIan Mckellenfor flashback scenes featuring their characters at a younger age.The visual effects were done by the companyLola VFX, and used photos taken of the actors at a younger age as references to later smooth out the wrinkles on their face with use of CGI. Overtime, de-aging technologies have advanced, with films such asHere(2024), portraying actors at younger ages through the use of digital AI techniques, scanning millions of facial features and incorporating a number of them onto actors' faces to alter their appearance. The lack of anatomically correct digital models contributes to the necessity of motion capture as it is used with computer-generated imagery. Because computer-generated imagery reflects only the outside, or skin, of the object being rendered, it fails to capture the infinitesimally small interactions between interlocking muscle groups used infine motor skillslike speaking. The constant motion of the face as it makes sounds with shaped lips and tongue movement, along with the facial expressions that go along with speaking are difficult to replicate by hand.Motion capture can catch the underlying movement of facial muscles and better replicate the visual that goes along with the audio.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Computer-generated_imagery", "https://en.wikipedia.org/wiki/Computer-generated_imagery", "https://en.wikipedia.org/wiki/Computer-generated_imagery", "https://en.wikipedia.org/wiki/AI-generated_imagery", "https://en.wikipedia.org/wiki/Morphogenetic", "https://en.wikipedia.org/wiki/Digital_art", "https://en.wikipedia.org/wiki/Andy_Lomas", "https://en.wikipedia.org/wiki/Watermans_Arts_Centre"]},
{"id": "a1e02822c5fa", "url": "https://en.wikipedia.org/wiki/Peter_Swirski", "title": "Peter Swirski", "headings": ["Contents", "Life and career", "Bibliography", "Books", "References", "External links"], "content": "Peter Swirskiis a Canadiannovelist, scholar, and literary criticfeatured inCanadian Who's Who.He is the author and editor of 19 nonfictions, including the prize-winningArs Americana, Ars Politica(2010) and the staple of Americanpopular culture studiesFrom Lowbrow to Nobrow(2005). His other  studies includeAmerican Utopia and Social Engineering(2011),American Political Fictions(2015),American Utopia: Literature, Society, and the Human Use of Human Beings(2020, Routledge textbook), and the digital-futurological bestsellerFrom Literature to Biterature(2013). He is also the leading authority on the late writer and philosopherStanisław Lem. Among other appointments, Peter Swirski was formerly a professor and research director at theHelsinkiInstitute for Advanced Studies in Finland,Distinguished Professor of American Studies and Literature atSun Yat-sen University,a n associate professor and director of american studies at HKU, an assistant professor and senior research associate at theUniversity of Alberta,and an honorary professor in American literature atSouth China University of Technology.In the mid-1980s he worked for the United Nations High Commissioner for Refugees (UNHCR).He obtained his doctoratesumma cum laudefrom McGill University in Montreal, in 1996. Swirski's 2005 study of American popular and \"nobrow\" cultures,From Lowbrow to Nobrow, was followed up by several other books on \"nobrow\" literature, culture, and other forms of \"artertainment\" (his coinage):American Crime Fiction(2016), a collection of critical essaysWhen Highbrow Meets Lowbrow: Popular Culture and the Rise of Nobrow(2017), andThe Art of Artertainment: Nobrow, American Style(2019). His bookArs Americana, Ars Politica(2010) received a positive review from theFinancial Times. A number of his monographs, collections, as well as articles from theTimes Literary Supplementto theMIT Technology Reviewand other venues deal with the analysis of the work of the writer and philosopherStanislaw Lem. In 2012Ars Americanawas the subject of Professor Swirski's plenary lecture at UNE's Institute for Global Humanities alongside Noam Chomsky and other speakers.In the summer and fall of 2013, he was a speaker at the 4th Philippine Literary festival in Manila,and a BBC World Service panelist at theHong Kong International Literary Festival.In March 2015, he was a keynoter at the Millennium International Documentary Film Festival in Brussels.In 2022 he was an invited speaker at the Santa Fe Institute's Interplanetary Project.", "combined_text": "Peter Swirski Contents Life and career Bibliography Books References External links Peter Swirskiis a Canadiannovelist, scholar, and literary criticfeatured inCanadian Who's Who.He is the author and editor of 19 nonfictions, including the prize-winningArs Americana, Ars Politica(2010) and the staple of Americanpopular culture studiesFrom Lowbrow to Nobrow(2005). His other  studies includeAmerican Utopia and Social Engineering(2011),American Political Fictions(2015),American Utopia: Literature, Society, and the Human Use of Human Beings(2020, Routledge textbook), and the digital-futurological bestsellerFrom Literature to Biterature(2013). He is also the leading authority on the late writer and philosopherStanisław Lem. Among other appointments, Peter Swirski was formerly a professor and research director at theHelsinkiInstitute for Advanced Studies in Finland,Distinguished Professor of American Studies and Literature atSun Yat-sen University,a n associate professor and director of american studies at HKU, an assistant professor and senior research associate at theUniversity of Alberta,and an honorary professor in American literature atSouth China University of Technology.In the mid-1980s he worked for the United Nations High Commissioner for Refugees (UNHCR).He obtained his doctoratesumma cum laudefrom McGill University in Montreal, in 1996. Swirski's 2005 study of American popular and \"nobrow\" cultures,From Lowbrow to Nobrow, was followed up by several other books on \"nobrow\" literature, culture, and other forms of \"artertainment\" (his coinage):American Crime Fiction(2016), a collection of critical essaysWhen Highbrow Meets Lowbrow: Popular Culture and the Rise of Nobrow(2017), andThe Art of Artertainment: Nobrow, American Style(2019). His bookArs Americana, Ars Politica(2010) received a positive review from theFinancial Times. A number of his monographs, collections, as well as articles from theTimes Literary Supplementto theMIT Technology Reviewand other venues deal with the analysis of the work of the writer and philosopherStanislaw Lem. In 2012Ars Americanawas the subject of Professor Swirski's plenary lecture at UNE's Institute for Global Humanities alongside Noam Chomsky and other speakers.In the summer and fall of 2013, he was a speaker at the 4th Philippine Literary festival in Manila,and a BBC World Service panelist at theHong Kong International Literary Festival.In March 2015, he was a keynoter at the Millennium International Documentary Film Festival in Brussels.In 2022 he was an invited speaker at the Santa Fe Institute's Interplanetary Project.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Peter_Swirski", "https://en.wikipedia.org/wiki/Peter_Swirski", "https://en.wikipedia.org/wiki/Peter_Swirski", "https://en.wikipedia.org/wiki/Novelist", "https://en.wikipedia.org/wiki/Canadian_Who%27s_Who", "https://en.wikipedia.org/wiki/Popular_culture_studies", "https://en.wikipedia.org/wiki/From_Lowbrow_to_Nobrow", "https://en.wikipedia.org/wiki/Stanis%C5%82aw_Lem"]},
{"id": "635a06a7c0ea", "url": "https://en.wikipedia.org/wiki/Duns_Scotus", "title": "Duns Scotus", "headings": ["Contents", "Life", "Work", "Metaphysics", "Realism", "Univocity of being", "Individuation", "Formal distinction", "Theology", "Voluntarism", "Metaphysical argument for the existence of God", "Illuminationism", "Immaculate Conception", "Veneration", "Later reputation and influence", "Later medieval period", "Sixteenth to nineteenth centuries", "Twentieth century", "In popular media", "Bibliography", "See also", "Notes", "Further reading", "External links"], "content": " John Duns ScotusOFM(/ˈskoʊtəs/SKOH-təs;Ecclesiastical Latin:[dunsˈskɔtus], \"Duns the Scot\";c.1265/66– 8 November 1308)was a Scottish Catholic priest andFranciscan friar, university professor, philosopher and theologian. He is considered among the most important philosopher-theologians inWestern Christendomduring the last part of the medieval period, together withThomas Aquinas,BonaventureandWilliam of Ockham. Duns Scotus has had considerable influence on bothCatholicand secular thought. The doctrines for which he is best known are the \"univocity of being\", that existence is the most abstract concept we have, applicable to everything that exists; theformal distinction, a way of distinguishing between different formalities of the same thing; and the idea ofhaecceity, the property supposed to be in each individual thing that makes it an individual (i.e. a certain \"thisness\"). Duns Scotus also developed a complex argument for the existence of God, and argued for theImmaculate ConceptionofMary. The intellectual tradition derived from Scotus' work is calledScotism. Duns Scotus was given thescholastic accoladeDoctor Subtilis(\"the subtle doctor\") for his penetrating and subtle manner of thought. He wasbeatifiedbyPope John Paul IIin 1993. Little is known of Duns Scotus apart from his work. His date of birth is believed to have been sometime between 23 December 1265 and 17 March 1266. He was born into a leading family of the region. The reputed site of his birth, in front of the Pavilion Lodge, near the North Lodge ofDuns Castlein Scotland, is now marked by acairnwhich was erected in 1966 by the Franciscan friars of the United Kingdom to mark the 700th anniversary of his birth. Duns Scotus received thereligious habitof the Order of Friars Minor atDumfries, where his uncle, Elias Duns, wasguardian. Duns Scotus's age is based on the first certain date for his life, that of his ordination to thepriesthoodatSt Andrew's,Northampton, England, on 17 March 1291. The minimumcanonicalage for receivingholy ordersis 25 and it is generally assumed that he would have been ordained as soon as it was permitted.That his contemporaries called himJohannes Duns, after the medieval practice of calling people by their Christian name followed by their place of origin, suggests that he came fromDuns, in Berwickshire, Scotland. According to tradition, Duns Scotus was educated at a Franciscanstudium generale(amedieval university), a house behindSt Ebbe's Church, Oxford, in a triangular area enclosed by Pennyfarthing Street and running fromSt Aldate'sto the castle, the bailey and the old wall,where the Friars Minor had moved when theUniversity of Pariswasdispersedin 1229–30. At that time there would have been about 270 people living there, of whom about 80 would have been friars. Duns Scotus appears to have been inOxfordby 1300, as he is listed among a group of friars for whom theprovincial superiorof the Englishecclesiastical province(which included Scotland) requested faculties from theBishop of Lincolnfor the hearing ofconfessions.He took part in a disputation under the regent master, Philip ofBridlingtonin 1300–01.He began lecturing onPeter Lombard'sSentencesat the prestigious University of Paris towards the end of 1302. Later in that academic year, however, he was expelled from the University of Paris for siding withPope Boniface VIIIin his feud with KingPhilip IV of Franceover the taxation of church property. Duns Scotus was back in Paris before the end of 1304, probably returning in May. He continued lecturing there until, for reasons that are still mysterious, he was dispatched to the FranciscanstudiumatCologne, probably in October 1307. According to the 15th-century writerWilliam Vorilong, his departure was sudden and unexpected. He was relaxing or talking with students in thePrato clericorumorPré-aux-Clercs– an open area of theRive Gaucheused by scholars for recreation – when orders arrived from the FranciscanMinister General; Scotus left immediately, taking few or no personal belongings. Duns Scotus died unexpectedly in Cologne in November 1308; the date of his death is traditionally given as 8 November. He is buried in theChurch of the Friars Minorthere. Hissarcophagusbears the Latin poem: Scotia me genuit.Anglia me suscepit.Gallia me docuit.Colonia me tenet.(Scotland brought me forth.England sustained me.France taught me.Cologne holds me.) The story about Duns Scotus beingburied alive, in the absence of his servant who alone knew of his susceptibility to coma, is probably a myth.The first known attestation of this theme dates from around 1400.Among many authors,Francis Baconreported it in hisHistoria vitae et mortis. Thecolophonof Codex 66 ofMerton College, Oxford, says that Scotus was also atCambridge. Scotus's great work is his commentary on theSentencesofPeter Lombard, which contains nearly all the philosophical views and arguments for which he is well known, including theunivocity of being, theformal distinction, less than numerical unity, individual nature or \"thisness\" (haecceity), his critique ofilluminationismand his renowned argument for the existence of God. His commentary exists in several versions. The standard version is theOrdinatio(also known as theOpus oxoniense), a revised version of lectures he gave as a bachelor at Oxford. The initial revision was probably begun in the summer of 1300 – see the remarks in the Prologue, question 2, alluding to theBattle of Wadi al-Khazandarin 1299, news of which probably reached Oxford in the summer of 1300. It was still incomplete when Scotus left for Paris in 1302. The two other versions of the work are Scotus's notes for the Oxford lectures, recently transcribed and published as theLectura,the first book of which was probably written in Oxford in the late 1290s,and theReportatio parisiensis(orOpus parisiense), consisting of transcriptions of the lectures on theSentencesgiven by Scotus when he was in Paris. Areportatiois a student report or transcription of the original lecture of a master. A version that has been checked by the master himself is known as areportatio examinata. By the time of Scotus, these 'commentaries' on theSentenceswere no longer literal commentaries. Instead,Peter Lombard's original text was used as a starting point for highly original discussions on topics of theological or philosophical interest.For example, Book II Distinction 2, about the location of angels, is a starting point for a complex discussion about continuous motion, and whether the same thing can be in two different places at the same time (bilocation). In the same book, Distinction 3, he uses the question of how angels can be different from one another, given that they have no material bodies, to investigate the difficult question ofindividuationin general. Scotus wrote purely philosophical and logical works at an early stage of his career, consisting of commentaries on Aristotle'sOrganon. These are theQuestionsonPorphyry'sIsagogeand Aristotle'sCategories,Peri hermeneias, andDe sophisticis elenchis, probably dating to around 1295.His commentary on Aristotle'sMetaphysicswas probably written in stages, the first version having started around 1297,with significant additions and amendments possibly after the completion of the main body of theOrdinatio.HisExpositioon theMetaphysicswas lost for centuries but was recently rediscovered and edited by Giorgio Pini. In addition, there are 46 short disputations calledCollationes, probably dating from 1300 to 1305; a work in natural theology (De primo principio); and hisQuaestiones Quodlibetales, a record of aquodlibetaldisputation probably dating to Advent 1306 or Lent 1307. A number of works once believed to have been written by Scotus are now known to have been misattributed. There were already concerns about this within two centuries of his death, when the 16th-century logicianJacobus Naverosnoted inconsistencies between these texts and his commentary on theSentences, leading him to doubt whether he had written any logical works at all.The Questions on the Prior Analytics(In Librum Priorum Analyticorum Aristotelis Quaestiones) were also discovered to be mistakenly attributed.In 1922,Grabmannshowed that the logical workDe modis significandiwas actually byThomas of Erfurt, a 14th-century logician of themodist school. Thus the claim thatMartin Heideggerwrote hishabilitationthesis on Scotusis only half true, as the second part is actually based on the work by Erfurt. Scotus' view of universals is known asScotistic realism. Scotus is generally considered to be arealist(as opposed to anominalist) in that he treated universals as real, but he held that they exist both in particular things and as concepts in the mind (as opposed to a Platonic \"third realm\").He attacks a position close to that later defended byOckham, arguing that things have a common nature – for example the humanity common toSocrates,Plato, andPlutarch. He followedAristotlein asserting that the subject matter ofmetaphysicsis \"being qua being\" (ens inquantum ens). Being in general (ens in communi), as a univocal notion, was for him the first object of the intellect.The doctrine of theunivocity of beingimplies the denial of any real distinction betweenessenceandexistence.Aquinashad argued that in all finite being (i.e. all except God) the essence of a thing is distinct from its existence. Scotus rejected the distinction. Scotus argued that we cannot conceive of what it is to be something, without conceiving it as existing. We should not make any distinction between whether a thing exists (si est) and what it is (quid est) for we never know whether something exists unless we have some concept of what we know to exist. Scotus elaborates a distinct view onhylomorphism, with three important strong theses that differentiate him. He held: 1) that there existsmatterthat has no form whatsoever, or prime matter, as the stuff underlying all change, against Aquinas (cf. hisQuaestiones in Metaphysicam7, q. 5;Lectura2, d. 12, q. un.), 2) that not all created substances are composites of form and matter (cf.Lectura2, d. 12, q. un., n. 55), that is, that purely spiritual substances do exist, and 3) that one and the same substance can have more than one substantial form – for instance, humans have at least two substantial forms, the soul and the form of the body (forma corporeitas) (cf.Ordinatio4, d. 11, q. 3, n. 54). He argued for an original principle ofindividuation(cf.Ordinatio2, d. 3, pars 1, qq. 1–6), the \"haecceity\" as the ultimate unity of a unique individual (haecceitas, an entity's 'thisness'), as opposed to the commonnature(natura communis) feature existing in any number of individuals. For Scotus, the axiom stating that only the individual exists is a dominating principle of the understanding of reality. For the apprehension of individuals, an intuitive cognition is required, which gives us the present existence or the non-existence of an individual, as opposed to abstract cognition. Thus the human soul, in its separated state from the body, will be capable of knowing the spiritual intuitively. Like other realist philosophers of the period (such as Aquinas andHenry of Ghent) Scotus recognised the need for an intermediate distinction that was not merely conceptual but not fully real or mind-dependent either. Scotus argued for aformal distinction(distinctio formalis a parte rei), which holds between entities which are inseparable and indistinct in reality but whose definitions are not identical. For example, the personal properties of theTrinityare formally distinct from the Divine essence. Similarly, the distinction between the 'thisness' orhaecceityof a thing is intermediate between a real and a conceptual distinction.There is also a formal distinction between the divine attributes and the powers of the soul. Scotus was an Augustinian-Franciscan theologian.He is usually associated withtheological voluntarism, the tendency to emphasize God's will and human freedom in all philosophical issues. The main difference betweenAquinas's rational theology and that of Scotus is that Scotus believed certain predicates may be applied univocally, with exactly the same meaning, to God and creatures, whereas Aquinas insisted that this is impossible and that only analogical predication can be employed, in which a word as applied to God has a meaning different from, although related to, the meaning of that same word as applied to creatures. Duns struggled throughout his works in demonstrating his univocity theory against Aquinas's analogy doctrine. Scotus gave the lecture,LecturaI 39, during 1297–1299 to refute the view that everything is necessary and immutable. He claims that the aim of this lecture has two points (LecturaI 39, §31): first, to consider the contingency in what is (de contingentia in entibus); second, to consider how God's certain knowledge is compatible with the contingency of things. Scotus tries to defend the validity of Christian theology against the attack of ancient philosophers. The main argument is unpacked inLecturaI 39, §§49–53. Scotus argues that a necessary being (God) is able to have contingent knowledge, and that although this knowledge is contingent, it is not necessarily mutable and temporal by that very fact. InLecturaI 39 §1, Scotus asks, \"whether God has determinate knowledge of things according to every aspect of their existence, as according to being in the future.\" He presents a counterview which claims that God cannot have determinate knowledge of the future. To support this counterview, he uses Aristotle'sDe InterpretationeIX. In the following arguments, Scotus does not attempt to contradict Aristotle. He does not affirm or reject the ideas of Aristotle. The only issue he argues against is the proposition that God cannot have determinate knowledge of the future. Scotus appears to try to fully demonstrate that Aristotle's text is not contradictory to the Christian doctrine of God. Scotus argues that God wills with one single volition (unica volitione) whatever he wills. God has one volitionad intra, but this one volition can be related to many opposite thingsad extra. God can simultaneously will one thing at time 1 and the opposite thing at time 2. There are various possible interpretations of Aristotle'sDe InterpretationeIX. For example, John Buridan (ca. 1300–1362) thought the Scotistic contingency theory was anAristotelian view. Buridan's judgment is all the more possible because of at least four reasons: (1) Aristotle'sDe InterpretationeIX, 19a23-25 can be interpreted like the Scotistic contingency theory; (2) Scotus himself does not refute Aristotle'sDe InterpretationeIX inLecturaI 39 §§49–53; (3) Scotus, rather, tries to formulate his contingency theory with the help of other works of Aristotle inLecturaI 39 §§51, 54; (4) Scotus introduces the diachronic feature of God's volition to his contingency theory as well as the synchronic feature. Duns Scotus argued that it is better to construct a metaphysical argument for the existence of God, rather than the more common physical argument from motionfavoured by Aquinas,following Aristotle.Though the version inDe Primo Principiois the most complete and final version, theOrdinatioproof is usually offered. However, theDe Primoversion gives a wider understanding of the argument as well as Scotus's metaphysical underpinnings for his argument for God's existence, but theOrdinatioversion will be followed here. Briefly, Scotus begins his proof by explaining that there are two angles we must take in arguing for the existence of an actually infinite being. First from the view of the Relative Properties of God and second from the Absolute Properties of God. Relative properties are those which are predicable of God in relation to creation; absolute properties are those which belong to God whether or not He chose to create. Under the first heading of Relative Properties, Scotus argues for a triple primacy of efficiency, finality and pre-eminence. From there he shows that one primacy implies the others, and finally there can only be one nature that is the First Efficient Cause, Ultimate End, and the Most Perfect Nature. From there the Subtle Doctor discusses the Absolute Properties of God. The First Being is intellectual and volitional, and the intellect and will are identical with the essence of this supreme nature. The First Being is also infinite being. While discussing the infinity of God, Scotus resurrects Anselm's argument and responds to the criticism that Anselm makes an illicit leap from concept to reality. Finally, he gives a definite answer of \"yes\" to the question of whether there exists an actually infinite being. The very next question of theOrdinatiodeals with the unicity of the nature thus proved to exist. However, theDe Primo Principioversion concludes with this argument. The proof for the conclusion that \"some efficient cause is simply first such that neither can it be an effect nor can it, by virtue of something other than itself, cause an effect\"OrdinatioI.2.43runs like this: Scotus acknowledges two objections and deals with them accordingly. First is that he begs the question in assuming a first in the series. Here he argues that while many admit an infinite regress in an accidentally ordered series of causes, no philosopher admits infinite regress in an essentially ordered series. Scotus explains the differences between the two and offers proofs for the conclusion that an infinity of essentially ordered causes in a series is impossible.Second, it is objected that his proof is not really a demonstration since it begins with a contingent premise. That something is produced is contingent and not necessary. Therefore, the proof proceeds from a contingent and not a necessary premise. Scotus says that while that is true, it is utterly manifest that things are produced or effected. But in order to respond, Scotus makes a modal move and reworks the argument. Now he argues from the possibility of production. \"It is possible that something can be produced\" is a necessary proposition. From there he is able to conclude that it is possible that the first efficient cause exists, and if it is possible that it exists, then it does exist. He asserts that the last claim will be proved later in the argument.In theLecturaproof, Scotus argues the following way: Although beings different from God are actually contingent with respect to their factual existence, nevertheless, they are not with respect to their possible existence. Hence, those entities which are called contingent with respect to their factual existence are necessary with respect to their possible existence – for instance, although \"There exists a man\" is contingent, nevertheless \"It is possible that he exists\" is necessary, because his existence does not include any contradiction. Therefore, \"Something – different from God – is possible\" is necessary, because being is divided into the contingent and the necessary. Just as necessity belongs to a necessary being in virtue of its condition or its quiddity, so possibility belongs to a possible being in virtue of its quiddity. If the first argument is alternatively qualified with the notion of ontological possibility, then we have necessary propositions as follows: It is possible that there is something different from God – it is not of itself (because then it would not be the case that it were possible), nor from nothing. Therefore, it is possible that it is from something else. Either it is possible that the other agent acts by virtue of itself – and not by virtue of something else, not being from something else – or it is not possible. If so, then it is possible that there is a first agent, and if it [is] possible that it exists, then it exists, just as we have proved before. If not and if there is no infinite regress, then the argument at once comes to a standstill. For more on this argument, see especially \"Authors/Duns Scotus/Ordinatio/Ordinatio I/D2/Q2B\". Scotus argued against the version ofilluminationismthat had been defended earlier in the century byHenry of Ghent. In hisOrdinatio(I.3.1.4) he argued against the sceptical consequences that Henry claimed would follow from abandoning divine illumination. Scotus argued that if our thinking were fallible in the way Henry had believed, such illumination could not, even in principle, ensure \"certain and pure knowledge\".  Perhaps the most influential point of Duns Scotus's theology was his defense of theImmaculate ConceptionofMary(i.e., that Mary herself was conceived without sin). At the time, there was a great deal of argument about the subject. The general opinion was that it was appropriately deferential to theMother of God, but it could not be seen how to resolve the problem that only withChrist's death would the stain oforiginal sinbe removed. The great philosophers and theologians of the West were divided on the subject (indeed, evenThomas Aquinassided with those who denied the doctrine). Thefeast dayhad existed in the East (though in the East, the feast is just of the Conception of Mary) since the seventh century and had been introduced in several dioceses in the West as well, even though the philosophical basis was lacking. CitingAnselm of Canterbury's principle, \"potuit, decuit, ergo fecit\" (He [i.e., God] could do it, it was appropriate, therefore He did it), Duns Scotus devised the following argument: Mary was in need of redemption like all other human beings, but through the merits of Jesus'crucifixion, given in advance, she was conceived without the stain of original sin. God could have brought it about (1) that she was never in original sin, (2) she was in sin only for an instant, (3) she was in sin for a period of time, being purged at the last instant. Whichever of these options was most excellent should probably be attributed to Mary.This apparently careful statement provoked a storm of opposition at Paris, and suggested the line 'fired France for Mary without spot' in the famous poem \"Duns Scotus's Oxford,\" byGerard Manley Hopkins. Scotus's argument appears inPope Pius IX's 1854 declaration of thedogmaof the Immaculate Conception, \"at the first moment of Her conception, Mary was preserved free from the stain of original sin, in view of the merits of Jesus Christ.\"Scotus's position was hailed as \"a correct expression of the faith of the Apostles.\" Another of Scotus's positions also gained official approval of the Catholic Church: his doctrine on the universal primacy of Christ became the underlying rationale for the feast of Christ the King instituted in 1925. Scotus disagreed with Augustine on forced conversion of the Jews, declaring that a small number should be left unmolested on an island to serve as theremnant. During his pontificate,Pope John XXIIIrecommended the reading of Duns Scotus's theology to modern theology students. Duns Scotus was long honored as aBlessedby the Order of Friars Minor, as well as in theArchdiocesesofEdinburghandCologne. In the 19th century, the process was started seeking his recognition as such by theHoly See, on the basis of acultusimmemorabilis, i.e., one of ancient standing.On 27 July 1920, a committee of theologians was convened to evaluate his spiritual writings for orthodoxy.He was declaredVenerablebyPope John Paul IIin 1991, who officially recognized his liturgical cult, effectivelybeatifyinghim on 20 March 1993. Owing to Scotus's early and unexpected death, he left behind a large body of work in an unfinished or unedited condition. His students and disciples extensively edited his papers, often confusing them with works by other writers, in many cases leading to misattribution and confused transmission. Most 13th-century Franciscans followedBonaventura, but the influence of Scotus (as well as that of his arch-rivalWilliam of Ockham) spread in the fourteenth century. Franciscan theologians in the late Middle Ages were thus divided between so-called Scotists and Ockhamists. Fourteenth century followers includedFrancis of Mayrone(died 1325),Antonius Andreas(died 1320),William of Alnwick(died 1333), and John of Bassolis (died 1347), supposedly Scotus's favourite student. His reputation suffered during theEnglish reformation, probably due to its association with the Franciscans. In a letter toThomas Cromwellabout his visit to Oxford in 1535,Richard Laytondescribed how he saw the court of New College full of pages from Scotus's work, \"the wind blowing them into every corner.\"John Lelanddescribed the Oxford Greyfriar's library in 1538 (just prior to its dissolution) as an accumulation of \"cobwebs, moths and bookworms.\" Critics of Scotus' work described his followers as \"dunces\"; the \"dunce cap\" was later used as a form of punishment in schools and the word \"dunce\" has come to be used as a term to describe someone dull-witted. When in the sixteenth century the Scotists argued againstRenaissance humanism, the termdunsorduncebecame, in the mouths of humanists and reformers, a term of abuse and asynonymfor one incapable ofscholarship. Despite this, Scotism grew in Catholic Europe. Scotus's works were collected into many editions, particularly in the late fifteenth century with the advent ofprinting. His school was probably at the height of its popularity at the beginning of the seventeenth century; during the sixteenth and the seventeenth centuries there were special Scotist chairs, e.g. at Paris, Rome, Coimbra, Salamanca, Alcalá, Padua, and Pavia. New ideas were includedpseudographicallyin later editions of his work, such as theprinciple of explosion, now attributed toPseudo-Scotus. Scotism flourished well into the seventeenth century, and its influence can be seen in such writers asDescartesandBramhall. Interest dwindled in the eighteenth century, and the revival of scholastic philosophy, known asneo-Scholasticism, was essentially a revival of Thomistic thinking. Gerard Manley Hopkinswas able to reconcile his religious calling and his vocation as a poet thanks to his reading of Duns Scotus. His poemAs Kingfishers Catch Fireexpresses Duns Scotus's ideas on \"haecceity\". The twentieth century saw a resurgence of interest in Scotus, with a range of assessments of his thought. For one thing, Scotus has received interest from secular philosophers such as Peter King, Gyula Klima, Paul Vincent Spade, and others. For some today, Scotus is one of the most importantFranciscantheologians and the founder ofScotism, a special form ofScholasticism. He came out of the Old Franciscan School, to whichHaymo of Faversham(died 1244),Alexander of Hales(died 1245),John of Rupella(died 1245),William of Melitona(died 1260), St.Bonaventure(died 1274),CardinalMatthew of Aquasparta(died 1289),John Peckham, Archbishop of Canterbury (died 1292),Richard of Middletown(died c. 1300) and others belonged. He was known as \"Doctor Subtilis\" because of the subtle distinctions and nuances of his thinking. Later philosophers in the sixteenth century were less complimentary about his work and accused him ofsophistry. This led to the word \"dunce,\" which developed from the name \"Dunse\" given to his followers in the 1500s, becoming used for \"somebody who is incapable ofscholarship.\"Critics of Scotus' work described his followers as \"dunces\". The 'dunce cap' was used as a form of punishment in schools and the word 'dunce' has come to be used as a term to describe someone dull-witted. An important question since the 1960s has revolved over whether Scotus's thought heralded a change in thinking on the nature of 'being,' a change which marked a shift from Aquinas and other previous thinkers; this question has been particularly significant in recent years because it has come to be seen as a debate over the origins of 'modernity.' This line of argument first emerged in the 1960s among popular French philosophers who, in passing, singled out Duns Scotus as the figure whose theory of univocal being changed an earlier approach which Aquinas had shared with his predecessors.Then, in 1990, the historian of philosophy Jean-Francois Courtine argued that, between the time of Aquinas in the mid-thirteenth century andFrancisco Suárezat the turn of the seventeenth, a fundamentally new approach to being was developed, with Scotus taking a major part in its development.During the 1990s, various scholars extended this argument to locate Scotus as the first thinker who succumbed to whatHeideggertermed 'onto-theology'. In recent years, this criticism of Scotus has become disseminated in particular through the writings of the 'Radical Orthodox' group of theologians, drawing onJohn MilbankandCatherine Pickstock. The Radical Orthodox model has been questioned byDaniel Horanand Thomas Williams,both of whom claim that Scotus's doctrine of the univocity of being is a semantic, rather than an ontological theory. Both thinkers cite Ord. 1, d. 3, pars 1, q. 3, n. 163, in which Scotus claims that \"This [univocally] is how all the authoritative passages one might find on this topic in the Metaphysics or Physics should be interpreted: in terms of the ontological diversity of those things to which the concept is attributed, which is compatible with there being one concept that can be abstracted from them\". Such a quotation seems to refer to epistemology, with abstracted concepts, rather than with ontology, which Scotus admits can be diverse. In 2012 Fernando Muraca directed for TVCO and theFranciscan Friars of the Immaculatethe biopicBlessed Duns Scotus: Defender of the Immaculate Conceptionin Italian.It centers on the debate at the Paris University with glimpses of his infancy and Franciscan vocation. Adriano Braidotti played the adult Scotus and Emanuele Maria Gamboni played Scotus as a  child.", "combined_text": "Duns Scotus Contents Life Work Metaphysics Realism Univocity of being Individuation Formal distinction Theology Voluntarism Metaphysical argument for the existence of God Illuminationism Immaculate Conception Veneration Later reputation and influence Later medieval period Sixteenth to nineteenth centuries Twentieth century In popular media Bibliography See also Notes Further reading External links  John Duns ScotusOFM(/ˈskoʊtəs/SKOH-təs;Ecclesiastical Latin:[dunsˈskɔtus], \"Duns the Scot\";c.1265/66– 8 November 1308)was a Scottish Catholic priest andFranciscan friar, university professor, philosopher and theologian. He is considered among the most important philosopher-theologians inWestern Christendomduring the last part of the medieval period, together withThomas Aquinas,BonaventureandWilliam of Ockham. Duns Scotus has had considerable influence on bothCatholicand secular thought. The doctrines for which he is best known are the \"univocity of being\", that existence is the most abstract concept we have, applicable to everything that exists; theformal distinction, a way of distinguishing between different formalities of the same thing; and the idea ofhaecceity, the property supposed to be in each individual thing that makes it an individual (i.e. a certain \"thisness\"). Duns Scotus also developed a complex argument for the existence of God, and argued for theImmaculate ConceptionofMary. The intellectual tradition derived from Scotus' work is calledScotism. Duns Scotus was given thescholastic accoladeDoctor Subtilis(\"the subtle doctor\") for his penetrating and subtle manner of thought. He wasbeatifiedbyPope John Paul IIin 1993. Little is known of Duns Scotus apart from his work. His date of birth is believed to have been sometime between 23 December 1265 and 17 March 1266. He was born into a leading family of the region. The reputed site of his birth, in front of the Pavilion Lodge, near the North Lodge ofDuns Castlein Scotland, is now marked by acairnwhich was erected in 1966 by the Franciscan friars of the United Kingdom to mark the 700th anniversary of his birth. Duns Scotus received thereligious habitof the Order of Friars Minor atDumfries, where his uncle, Elias Duns, wasguardian. Duns Scotus's age is based on the first certain date for his life, that of his ordination to thepriesthoodatSt Andrew's,Northampton, England, on 17 March 1291. The minimumcanonicalage for receivingholy ordersis 25 and it is generally assumed that he would have been ordained as soon as it was permitted.That his contemporaries called himJohannes Duns, after the medieval practice of calling people by their Christian name followed by their place of origin, suggests that he came fromDuns, in Berwickshire, Scotland. According to tradition, Duns Scotus was educated at a Franciscanstudium generale(amedieval university), a house behindSt Ebbe's Church, Oxford, in a triangular area enclosed by Pennyfarthing Street and running fromSt Aldate'sto the castle, the bailey and the old wall,where the Friars Minor had moved when theUniversity of Pariswasdispersedin 1229–30. At that time there would have been about 270 people living there, of whom about 80 would have been friars. Duns Scotus appears to have been inOxfordby 1300, as he is listed among a group of friars for whom theprovincial superiorof the Englishecclesiastical province(which included Scotland) requested faculties from theBishop of Lincolnfor the hearing ofconfessions.He took part in a disputation under the regent master, Philip ofBridlingtonin 1300–01.He began lecturing onPeter Lombard'sSentencesat the prestigious University of Paris towards the end of 1302. Later in that academic year, however, he was expelled from the University of Paris for siding withPope Boniface VIIIin his feud with KingPhilip IV of Franceover the taxation of church property. Duns Scotus was back in Paris before the end of 1304, probably returning in May. He continued lecturing there until, for reasons that are still mysterious, he was dispatched to the FranciscanstudiumatCologne, probably in October 1307. According to the 15th-century writerWilliam Vorilong, his departure was sudden and unexpected. He was relaxing or talking with students in thePrato clericorumorPré-aux-Clercs– an open area of theRive Gaucheused by scholars for recreation – when orders arrived from the FranciscanMinister General; Scotus left immediately, taking few or no personal belongings. Duns Scotus died unexpectedly in Cologne in November 1308; the date of his death is traditionally given as 8 November. He is buried in theChurch of the Friars Minorthere. Hissarcophagusbears the Latin poem: Scotia me genuit.Anglia me suscepit.Gallia me docuit.Colonia me tenet.(Scotland brought me forth.England sustained me.France taught me.Cologne holds me.) The story about Duns Scotus beingburied alive, in the absence of his servant who alone knew of his susceptibility to coma, is probably a myth.The first known attestation of this theme dates from around 1400.Among many authors,Francis Baconreported it in hisHistoria vitae et mortis. Thecolophonof Codex 66 ofMerton College, Oxford, says that Scotus was also atCambridge. Scotus's great work is his commentary on theSentencesofPeter Lombard, which contains nearly all the philosophical views and arguments for which he is well known, including theunivocity of being, theformal distinction, less than numerical unity, individual nature or \"thisness\" (haecceity), his critique ofilluminationismand his renowned argument for the existence of God. His commentary exists in several versions. The standard version is theOrdinatio(also known as theOpus oxoniense), a revised version of lectures he gave as a bachelor at Oxford. The initial revision was probably begun in the summer of 1300 – see the remarks in the Prologue, question 2, alluding to theBattle of Wadi al-Khazandarin 1299, news of which probably reached Oxford in the summer of 1300. It was still incomplete when Scotus left for Paris in 1302. The two other versions of the work are Scotus's notes for the Oxford lectures, recently transcribed and published as theLectura,the first book of which was probably written in Oxford in the late 1290s,and theReportatio parisiensis(orOpus parisiense), consisting of transcriptions of the lectures on theSentencesgiven by Scotus when he was in Paris. Areportatiois a student report or transcription of the original lecture of a master. A version that has been checked by the master himself is known as areportatio examinata. By the time of Scotus, these 'commentaries' on theSentenceswere no longer literal commentaries. Instead,Peter Lombard's original text was used as a starting point for highly original discussions on topics of theological or philosophical interest.For example, Book II Distinction 2, about the location of angels, is a starting point for a complex discussion about continuous motion, and whether the same thing can be in two different places at the same time (bilocation). In the same book, Distinction 3, he uses the question of how angels can be different from one another, given that they have no material bodies, to investigate the difficult question ofindividuationin general. Scotus wrote purely philosophical and logical works at an early stage of his career, consisting of commentaries on Aristotle'sOrganon. These are theQuestionsonPorphyry'sIsagogeand Aristotle'sCategories,Peri hermeneias, andDe sophisticis elenchis, probably dating to around 1295.His commentary on Aristotle'sMetaphysicswas probably written in stages, the first version having started around 1297,with significant additions and amendments possibly after the completion of the main body of theOrdinatio.HisExpositioon theMetaphysicswas lost for centuries but was recently rediscovered and edited by Giorgio Pini. In addition, there are 46 short disputations calledCollationes, probably dating from 1300 to 1305; a work in natural theology (De primo principio); and hisQuaestiones Quodlibetales, a record of aquodlibetaldisputation probably dating to Advent 1306 or Lent 1307. A number of works once believed to have been written by Scotus are now known to have been misattributed. There were already concerns about this within two centuries of his death, when the 16th-century logicianJacobus Naverosnoted inconsistencies between these texts and his commentary on theSentences, leading him to doubt whether he had written any logical works at all.The Questions on the Prior Analytics(In Librum Priorum Analyticorum Aristotelis Quaestiones) were also discovered to be mistakenly attributed.In 1922,Grabmannshowed that the logical workDe modis significandiwas actually byThomas of Erfurt, a 14th-century logician of themodist school. Thus the claim thatMartin Heideggerwrote hishabilitationthesis on Scotusis only half true, as the second part is actually based on the work by Erfurt. Scotus' view of universals is known asScotistic realism. Scotus is generally considered to be arealist(as opposed to anominalist) in that he treated universals as real, but he held that they exist both in particular things and as concepts in the mind (as opposed to a Platonic \"third realm\").He attacks a position close to that later defended byOckham, arguing that things have a common nature – for example the humanity common toSocrates,Plato, andPlutarch. He followedAristotlein asserting that the subject matter ofmetaphysicsis \"being qua being\" (ens inquantum ens). Being in general (ens in communi), as a univocal notion, was for him the first object of the intellect.The doctrine of theunivocity of beingimplies the denial of any real distinction betweenessenceandexistence.Aquinashad argued that in all finite being (i.e. all except God) the essence of a thing is distinct from its existence. Scotus rejected the distinction. Scotus argued that we cannot conceive of what it is to be something, without conceiving it as existing. We should not make any distinction between whether a thing exists (si est) and what it is (quid est) for we never know whether something exists unless we have some concept of what we know to exist. Scotus elaborates a distinct view onhylomorphism, with three important strong theses that differentiate him. He held: 1) that there existsmatterthat has no form whatsoever, or prime matter, as the stuff underlying all change, against Aquinas (cf. hisQuaestiones in Metaphysicam7, q. 5;Lectura2, d. 12, q. un.), 2) that not all created substances are composites of form and matter (cf.Lectura2, d. 12, q. un., n. 55), that is, that purely spiritual substances do exist, and 3) that one and the same substance can have more than one substantial form – for instance, humans have at least two substantial forms, the soul and the form of the body (forma corporeitas) (cf.Ordinatio4, d. 11, q. 3, n. 54). He argued for an original principle ofindividuation(cf.Ordinatio2, d. 3, pars 1, qq. 1–6), the \"haecceity\" as the ultimate unity of a unique individual (haecceitas, an entity's 'thisness'), as opposed to the commonnature(natura communis) feature existing in any number of individuals. For Scotus, the axiom stating that only the individual exists is a dominating principle of the understanding of reality. For the apprehension of individuals, an intuitive cognition is required, which gives us the present existence or the non-existence of an individual, as opposed to abstract cognition. Thus the human soul, in its separated state from the body, will be capable of knowing the spiritual intuitively. Like other realist philosophers of the period (such as Aquinas andHenry of Ghent) Scotus recognised the need for an intermediate distinction that was not merely conceptual but not fully real or mind-dependent either. Scotus argued for aformal distinction(distinctio formalis a parte rei), which holds between entities which are inseparable and indistinct in reality but whose definitions are not identical. For example, the personal properties of theTrinityare formally distinct from the Divine essence. Similarly, the distinction between the 'thisness' orhaecceityof a thing is intermediate between a real and a conceptual distinction.There is also a formal distinction between the divine attributes and the powers of the soul. Scotus was an Augustinian-Franciscan theologian.He is usually associated withtheological voluntarism, the tendency to emphasize God's will and human freedom in all philosophical issues. The main difference betweenAquinas's rational theology and that of Scotus is that Scotus believed certain predicates may be applied univocally, with exactly the same meaning, to God and creatures, whereas Aquinas insisted that this is impossible and that only analogical predication can be employed, in which a word as applied to God has a meaning different from, although related to, the meaning of that same word as applied to creatures. Duns struggled throughout his works in demonstrating his univocity theory against Aquinas's analogy doctrine. Scotus gave the lecture,LecturaI 39, during 1297–1299 to refute the view that everything is necessary and immutable. He claims that the aim of this lecture has two points (LecturaI 39, §31): first, to consider the contingency in what is (de contingentia in entibus); second, to consider how God's certain knowledge is compatible with the contingency of things. Scotus tries to defend the validity of Christian theology against the attack of ancient philosophers. The main argument is unpacked inLecturaI 39, §§49–53. Scotus argues that a necessary being (God) is able to have contingent knowledge, and that although this knowledge is contingent, it is not necessarily mutable and temporal by that very fact. InLecturaI 39 §1, Scotus asks, \"whether God has determinate knowledge of things according to every aspect of their existence, as according to being in the future.\" He presents a counterview which claims that God cannot have determinate knowledge of the future. To support this counterview, he uses Aristotle'sDe InterpretationeIX. In the following arguments, Scotus does not attempt to contradict Aristotle. He does not affirm or reject the ideas of Aristotle. The only issue he argues against is the proposition that God cannot have determinate knowledge of the future. Scotus appears to try to fully demonstrate that Aristotle's text is not contradictory to the Christian doctrine of God. Scotus argues that God wills with one single volition (unica volitione) whatever he wills. God has one volitionad intra, but this one volition can be related to many opposite thingsad extra. God can simultaneously will one thing at time 1 and the opposite thing at time 2. There are various possible interpretations of Aristotle'sDe InterpretationeIX. For example, John Buridan (ca. 1300–1362) thought the Scotistic contingency theory was anAristotelian view. Buridan's judgment is all the more possible because of at least four reasons: (1) Aristotle'sDe InterpretationeIX, 19a23-25 can be interpreted like the Scotistic contingency theory; (2) Scotus himself does not refute Aristotle'sDe InterpretationeIX inLecturaI 39 §§49–53; (3) Scotus, rather, tries to formulate his contingency theory with the help of other works of Aristotle inLecturaI 39 §§51, 54; (4) Scotus introduces the diachronic feature of God's volition to his contingency theory as well as the synchronic feature. Duns Scotus argued that it is better to construct a metaphysical argument for the existence of God, rather than the more common physical argument from motionfavoured by Aquinas,following Aristotle.Though the version inDe Primo Principiois the most complete and final version, theOrdinatioproof is usually offered. However, theDe Primoversion gives a wider understanding of the argument as well as Scotus's metaphysical underpinnings for his argument for God's existence, but theOrdinatioversion will be followed here. Briefly, Scotus begins his proof by explaining that there are two angles we must take in arguing for the existence of an actually infinite being. First from the view of the Relative Properties of God and second from the Absolute Properties of God. Relative properties are those which are predicable of God in relation to creation; absolute properties are those which belong to God whether or not He chose to create. Under the first heading of Relative Properties, Scotus argues for a triple primacy of efficiency, finality and pre-eminence. From there he shows that one primacy implies the others, and finally there can only be one nature that is the First Efficient Cause, Ultimate End, and the Most Perfect Nature. From there the Subtle Doctor discusses the Absolute Properties of God. The First Being is intellectual and volitional, and the intellect and will are identical with the essence of this supreme nature. The First Being is also infinite being. While discussing the infinity of God, Scotus resurrects Anselm's argument and responds to the criticism that Anselm makes an illicit leap from concept to reality. Finally, he gives a definite answer of \"yes\" to the question of whether there exists an actually infinite being. The very next question of theOrdinatiodeals with the unicity of the nature thus proved to exist. However, theDe Primo Principioversion concludes with this argument. The proof for the conclusion that \"some efficient cause is simply first such that neither can it be an effect nor can it, by virtue of something other than itself, cause an effect\"OrdinatioI.2.43runs like this: Scotus acknowledges two objections and deals with them accordingly. First is that he begs the question in assuming a first in the series. Here he argues that while many admit an infinite regress in an accidentally ordered series of causes, no philosopher admits infinite regress in an essentially ordered series. Scotus explains the differences between the two and offers proofs for the conclusion that an infinity of essentially ordered causes in a series is impossible.Second, it is objected that his proof is not really a demonstration since it begins with a contingent premise. That something is produced is contingent and not necessary. Therefore, the proof proceeds from a contingent and not a necessary premise. Scotus says that while that is true, it is utterly manifest that things are produced or effected. But in order to respond, Scotus makes a modal move and reworks the argument. Now he argues from the possibility of production. \"It is possible that something can be produced\" is a necessary proposition. From there he is able to conclude that it is possible that the first efficient cause exists, and if it is possible that it exists, then it does exist. He asserts that the last claim will be proved later in the argument.In theLecturaproof, Scotus argues the following way: Although beings different from God are actually contingent with respect to their factual existence, nevertheless, they are not with respect to their possible existence. Hence, those entities which are called contingent with respect to their factual existence are necessary with respect to their possible existence – for instance, although \"There exists a man\" is contingent, nevertheless \"It is possible that he exists\" is necessary, because his existence does not include any contradiction. Therefore, \"Something – different from God – is possible\" is necessary, because being is divided into the contingent and the necessary. Just as necessity belongs to a necessary being in virtue of its condition or its quiddity, so possibility belongs to a possible being in virtue of its quiddity. If the first argument is alternatively qualified with the notion of ontological possibility, then we have necessary propositions as follows: It is possible that there is something different from God – it is not of itself (because then it would not be the case that it were possible), nor from nothing. Therefore, it is possible that it is from something else. Either it is possible that the other agent acts by virtue of itself – and not by virtue of something else, not being from something else – or it is not possible. If so, then it is possible that there is a first agent, and if it [is] possible that it exists, then it exists, just as we have proved before. If not and if there is no infinite regress, then the argument at once comes to a standstill. For more on this argument, see especially \"Authors/Duns Scotus/Ordinatio/Ordinatio I/D2/Q2B\". Scotus argued against the version ofilluminationismthat had been defended earlier in the century byHenry of Ghent. In hisOrdinatio(I.3.1.4) he argued against the sceptical consequences that Henry claimed would follow from abandoning divine illumination. Scotus argued that if our thinking were fallible in the way Henry had believed, such illumination could not, even in principle, ensure \"certain and pure knowledge\".  Perhaps the most influential point of Duns Scotus's theology was his defense of theImmaculate ConceptionofMary(i.e., that Mary herself was conceived without sin). At the time, there was a great deal of argument about the subject. The general opinion was that it was appropriately deferential to theMother of God, but it could not be seen how to resolve the problem that only withChrist's death would the stain oforiginal sinbe removed. The great philosophers and theologians of the West were divided on the subject (indeed, evenThomas Aquinassided with those who denied the doctrine). Thefeast dayhad existed in the East (though in the East, the feast is just of the Conception of Mary) since the seventh century and had been introduced in several dioceses in the West as well, even though the philosophical basis was lacking. CitingAnselm of Canterbury's principle, \"potuit, decuit, ergo fecit\" (He [i.e., God] could do it, it was appropriate, therefore He did it), Duns Scotus devised the following argument: Mary was in need of redemption like all other human beings, but through the merits of Jesus'crucifixion, given in advance, she was conceived without the stain of original sin. God could have brought it about (1) that she was never in original sin, (2) she was in sin only for an instant, (3) she was in sin for a period of time, being purged at the last instant. Whichever of these options was most excellent should probably be attributed to Mary.This apparently careful statement provoked a storm of opposition at Paris, and suggested the line 'fired France for Mary without spot' in the famous poem \"Duns Scotus's Oxford,\" byGerard Manley Hopkins. Scotus's argument appears inPope Pius IX's 1854 declaration of thedogmaof the Immaculate Conception, \"at the first moment of Her conception, Mary was preserved free from the stain of original sin, in view of the merits of Jesus Christ.\"Scotus's position was hailed as \"a correct expression of the faith of the Apostles.\" Another of Scotus's positions also gained official approval of the Catholic Church: his doctrine on the universal primacy of Christ became the underlying rationale for the feast of Christ the King instituted in 1925. Scotus disagreed with Augustine on forced conversion of the Jews, declaring that a small number should be left unmolested on an island to serve as theremnant. During his pontificate,Pope John XXIIIrecommended the reading of Duns Scotus's theology to modern theology students. Duns Scotus was long honored as aBlessedby the Order of Friars Minor, as well as in theArchdiocesesofEdinburghandCologne. In the 19th century, the process was started seeking his recognition as such by theHoly See, on the basis of acultusimmemorabilis, i.e., one of ancient standing.On 27 July 1920, a committee of theologians was convened to evaluate his spiritual writings for orthodoxy.He was declaredVenerablebyPope John Paul IIin 1991, who officially recognized his liturgical cult, effectivelybeatifyinghim on 20 March 1993. Owing to Scotus's early and unexpected death, he left behind a large body of work in an unfinished or unedited condition. His students and disciples extensively edited his papers, often confusing them with works by other writers, in many cases leading to misattribution and confused transmission. Most 13th-century Franciscans followedBonaventura, but the influence of Scotus (as well as that of his arch-rivalWilliam of Ockham) spread in the fourteenth century. Franciscan theologians in the late Middle Ages were thus divided between so-called Scotists and Ockhamists. Fourteenth century followers includedFrancis of Mayrone(died 1325),Antonius Andreas(died 1320),William of Alnwick(died 1333), and John of Bassolis (died 1347), supposedly Scotus's favourite student. His reputation suffered during theEnglish reformation, probably due to its association with the Franciscans. In a letter toThomas Cromwellabout his visit to Oxford in 1535,Richard Laytondescribed how he saw the court of New College full of pages from Scotus's work, \"the wind blowing them into every corner.\"John Lelanddescribed the Oxford Greyfriar's library in 1538 (just prior to its dissolution) as an accumulation of \"cobwebs, moths and bookworms.\" Critics of Scotus' work described his followers as \"dunces\"; the \"dunce cap\" was later used as a form of punishment in schools and the word \"dunce\" has come to be used as a term to describe someone dull-witted. When in the sixteenth century the Scotists argued againstRenaissance humanism, the termdunsorduncebecame, in the mouths of humanists and reformers, a term of abuse and asynonymfor one incapable ofscholarship. Despite this, Scotism grew in Catholic Europe. Scotus's works were collected into many editions, particularly in the late fifteenth century with the advent ofprinting. His school was probably at the height of its popularity at the beginning of the seventeenth century; during the sixteenth and the seventeenth centuries there were special Scotist chairs, e.g. at Paris, Rome, Coimbra, Salamanca, Alcalá, Padua, and Pavia. New ideas were includedpseudographicallyin later editions of his work, such as theprinciple of explosion, now attributed toPseudo-Scotus. Scotism flourished well into the seventeenth century, and its influence can be seen in such writers asDescartesandBramhall. Interest dwindled in the eighteenth century, and the revival of scholastic philosophy, known asneo-Scholasticism, was essentially a revival of Thomistic thinking. Gerard Manley Hopkinswas able to reconcile his religious calling and his vocation as a poet thanks to his reading of Duns Scotus. His poemAs Kingfishers Catch Fireexpresses Duns Scotus's ideas on \"haecceity\". The twentieth century saw a resurgence of interest in Scotus, with a range of assessments of his thought. For one thing, Scotus has received interest from secular philosophers such as Peter King, Gyula Klima, Paul Vincent Spade, and others. For some today, Scotus is one of the most importantFranciscantheologians and the founder ofScotism, a special form ofScholasticism. He came out of the Old Franciscan School, to whichHaymo of Faversham(died 1244),Alexander of Hales(died 1245),John of Rupella(died 1245),William of Melitona(died 1260), St.Bonaventure(died 1274),CardinalMatthew of Aquasparta(died 1289),John Peckham, Archbishop of Canterbury (died 1292),Richard of Middletown(died c. 1300) and others belonged. He was known as \"Doctor Subtilis\" because of the subtle distinctions and nuances of his thinking. Later philosophers in the sixteenth century were less complimentary about his work and accused him ofsophistry. This led to the word \"dunce,\" which developed from the name \"Dunse\" given to his followers in the 1500s, becoming used for \"somebody who is incapable ofscholarship.\"Critics of Scotus' work described his followers as \"dunces\". The 'dunce cap' was used as a form of punishment in schools and the word 'dunce' has come to be used as a term to describe someone dull-witted. An important question since the 1960s has revolved over whether Scotus's thought heralded a change in thinking on the nature of 'being,' a change which marked a shift from Aquinas and other previous thinkers; this question has been particularly significant in recent years because it has come to be seen as a debate over the origins of 'modernity.' This line of argument first emerged in the 1960s among popular French philosophers who, in passing, singled out Duns Scotus as the figure whose theory of univocal being changed an earlier approach which Aquinas had shared with his predecessors.Then, in 1990, the historian of philosophy Jean-Francois Courtine argued that, between the time of Aquinas in the mid-thirteenth century andFrancisco Suárezat the turn of the seventeenth, a fundamentally new approach to being was developed, with Scotus taking a major part in its development.During the 1990s, various scholars extended this argument to locate Scotus as the first thinker who succumbed to whatHeideggertermed 'onto-theology'. In recent years, this criticism of Scotus has become disseminated in particular through the writings of the 'Radical Orthodox' group of theologians, drawing onJohn MilbankandCatherine Pickstock. The Radical Orthodox model has been questioned byDaniel Horanand Thomas Williams,both of whom claim that Scotus's doctrine of the univocity of being is a semantic, rather than an ontological theory. Both thinkers cite Ord. 1, d. 3, pars 1, q. 3, n. 163, in which Scotus claims that \"This [univocally] is how all the authoritative passages one might find on this topic in the Metaphysics or Physics should be interpreted: in terms of the ontological diversity of those things to which the concept is attributed, which is compatible with there being one concept that can be abstracted from them\". Such a quotation seems to refer to epistemology, with abstracted concepts, rather than with ontology, which Scotus admits can be diverse. In 2012 Fernando Muraca directed for TVCO and theFranciscan Friars of the Immaculatethe biopicBlessed Duns Scotus: Defender of the Immaculate Conceptionin Italian.It centers on the debate at the Paris University with glimpses of his infancy and Franciscan vocation. Adriano Braidotti played the adult Scotus and Emanuele Maria Gamboni played Scotus as a  child.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Duns_Scotus", "https://en.wikipedia.org/wiki/Duns_Scotus", "https://en.wikipedia.org/wiki/Duns_Scotus", "https://en.wikipedia.org/wiki/John_Scotus_Eriugena", "https://en.wikipedia.org/wiki/Beatification", "https://en.wikipedia.org/wiki/Order_of_Friars_Minor", "https://en.wikipedia.org/wiki/Justus_van_Gent", "https://en.wikipedia.org/wiki/Duns,_Scottish_Borders"]},
{"id": "92cb639f4804", "url": "https://en.wikipedia.org/wiki/Existential_risk_studies", "title": "Existential risk studies", "headings": ["Contents", "Background", "History", "First wave", "Second wave", "Third wave", "Concepts", "Existential risk", "Maximizing future value", "Classification of existential risks", "Related fields", "Effective altruism", "Debate", "Critique of technological utopianism", "Historical and political perspectives", "Claims of neglected research", "See also", "Notable theorists", "Associated institutions", "Other", "References", "Bibliography"], "content": "Existential risk studies(ERS) is afield of studiesfocused on the definition and theorization of \"existential risks\", its ethical implications and the related strategies of long-termsurvival.Existential risks are diversely defined as global kinds of calamity that have the capacity of inducing the extinction of intelligentearthlinglife, such ashumans, or, at least, a severe limitation of theirpotential, as defined by ERS theorists.The field development and expansion can be divided in waves according to its conceptual changes as well as its evolving relationship with related fields and theories, such asfutures studies,disaster studies,AI safety,effective altruismandlongtermism. The historical precursors of existential risks studies can be found in early 19th-century thought aroundhuman extinctionand the more recent models and theories ofglobal catastrophic riskthat date mainly to theCold War period, especially the thinking around a hypotheticalnuclear holocaust.ERS emerged as a distinctive and unified field in the early 2000s,experiencing a rapid growth in the academyand also within the general public with the publication of popular-oriented books.The field has also fostered the creation of a number of foundations,research centersandthink tanks, some of which received substantial philanthropic fundingand notability within prestigious universities. The idea of existential risks has it prehistory in the speculation on the possibility ofhuman extinction. The prospect ofextinctionis itself a break from previous religious and mythologicaleschatologyin the measure that it is thought as an absolute and naturalistic event.As such, human extinction is a recent invention in theintellectual historyof calamity. Its major historical source is present inscience fiction literature. Notoriously,Lord Byronwas, according to reports, concerned that acomet impactcould bring the destruction of humanity, while his poem \"Darkness\" describes a future in which the Earth becomes lifeless.Mary Shelley's novelThe Last Manprovides another example of early naturalistic catastrophic imaginations, depicting the story of a man who lived through the death of the rest of humanity in the final decades of the 21st century, caused by many events such as a worldwide plague.The idea itself of the \"last man\" can be traced to a emerginggenreof19th century literature, originating, most probably, withJean-Baptiste Cousin de Grainville's work, also titled asThe Last Man, published by 1805, where humanity lives through a crisis ofinfertility. A later rendition of this theme can be found inThe Time Machine, published byH.G. Wellsin 1895, where atime voyagerfinds himself 30 million years into a future in which the Earth is nothing but a cold and almost lifeless planet, the reason being the cooling of thesun. Around the same period, Wells wrote two other text on extinction, this time as nonfiction essays, titled \"On Extinction\" (1893) and \"The Extinction of Man\" (1897).In the 20th century, human extinction persists as a theme in science fiction.Isaac Asimovnot only concerned himself with the possibility ofcivilizational collapsein hisFoundationtrilogy, but also wrote a nonfiction book on the subject, titledA Choice of Catastrophes: The Disasters That Threaten Our World, and published in 1979. Another precursory trend for existential risks is identifiable in the discourses of scientific concern for catastrophes that emerged primarily in reaction to the invention ofnuclear weapons. These early responses attended especially to the possibility of an atmospheric ignition, which was soon dismissed as implausible, as well as the concern withradioactive contamination, which became a substantial and persistent theme in the discussion of possible catastrophic events. The risk engendered by radioactive particles prompted a quick mobilization among scientists and intellectuals, notoriously exemplified by theRussell–Einstein Manifesto, in 1955, which warned about the possibility of a human extinction. As a consequence, thePugwash Conferences on Science and World Affairswas established with the purposed of reducing the threat ofarmed conflicts. A similar effort is also exemplified by the creation of theBulletin of the Atomic Scientists, gathering previous members of theManhattan Project. The bulletin has also created and maintained the iconicDoomsday Clockwith the purpose of trackingglobal catastrophic riskwhile representing in a temporal fashion. The foundational moment of ERS can be dated to the publication ofNick Bostrom's 2002 essay titled \"Existential Risks: Analyzing Human Extinction Scenarios and Related Hazards\". In this essay, Bostrom sought to framehuman extinctionas a topic of philosophic pertinence to theanalyticandutilitariantraditions, mainly by dissociating it from past apocalyptical literature and by presenting a schematized and holistic review of possible threats for human survival or, more generally, to its capacity of realizing its own potential, as defined by him and which stands as the canonical definition of existential risk.Conjointly, he attempted to align this study of existential risks with an insight of its overcoming by a prospect of colossal technological development, which would allow human long-termsurvival through outer space colonization.Most of the essay consists of the proposed classification for existential risks, which is composed by four categories, idiomatically named\"Bangs\", \"Crunches\", \"Shrieks\" and \"Whimpers\", all inspired byT. S. Eliotpoem \"The Hollow Men\". The essay brought Bostrom significant academic recognition, incentivizing the attainment of his professorship atOxford Universityas well as the directorship of the now defunctFuture of Humanity Institute, in 2005, which he helped to found.TheCentre for the Study of Existential Riskwas established byCambridge Universityin 2012, which prompted its replication in other universities. This initial rendition of existential risks established what has been termed the 'first wave' of ERS.Described as an instance oftechnological utopianismwhich is defined by its expectation, or, as Noah B. Taylor characterizes as a \"teleologicalmomentum\", of a posthuman vision of the future. Proponents of this wave of ERS placed the emphasis of their hope and faith in technology, particularly artificial intelligence, genetic engineering, and nanotechnology, to lead humanity into a type of posthuman state where the divisions between the physical, virtual, mechanical, and biologic blur. The second wave, or generation, of ERS was characterized by its elaboration effort over the foundational work of Bostrom, and was further distinguished by its growing relations and interaction witheffective altruism. The emphasis ontranshumanismis considered to have been reduced during this period. After its relative institutional consolidation and the expansion of scholar engaged with the field, ERS became increasingly occupied with the issues relating to the diversity of its constituency and the need for a theoretical pluralism in its research. Some scholars of ERS focused on critical examinations of the \"historically dominant\"approach within the field, termed by some as the \"techno-utopian approach\".The so-calledtechnological utopianismhas formed the theoretical-core of ERS, drawing substantial inspiration fromtranshumanism,longtermismand the current ofutilitarianismknown astotal utilitarianism. The scholars most critical of this background have claimed that it suffers from intrinsic moral unreliability and methodological flaws, which evidences the demand for newframeworksof ERS, especially the ones that enhances democratic values perceived as lacking in the original formulation. The canonical definition of existential risk was proposed early by Bostrom in his essay, \"Existential Risks: Analyzing Human Extinction Scenarios and Related Hazards\", establishing it as a risk \"(...) where an adverse outcome would either annihilate Earth-originating intelligent life or permanently and drastically curtail its potential\",implying a kind ofriskwhich is bothglobalandterminal. Further elaborated by Bostrom in another essay, \"Existential Risk Prevention as Global Priority\", published in 2013.This definition, consequently, excludes, or, at least, is indirectly related to forms of calamity and mass suffering that remain below the selected threshold established by theorists of ERS.Genocidesandenslavementare examples of these \"local terminal risk[s]\", while \"global endurable risks\" might range from moderate levels of global warming, threats to the biodiversity, and global economic recessions.In this sense, the 'existential' of existential risks is distinguished from other 'catastrophical' forms of risk, being essentially related to the concept ofhuman potentialityalso elaborated by Bostom.As the author himself explains: \"Tragic as such events are to the people immediately affected, in the big picture of things — from the perspective of humankind as a whole — even the worst of these catastrophes are mere ripples on the surface of the great sea of life.\" The perceived problems of this definition of existential risk, primarily relating to its scale, have stimulated other scholars of the field to prefer a more broader category, that is less exclusively related toposthumanexpectations and extinctionist scenarios, such as \"global catastrophic risks\". Bostrom himself has partially incorporated this concept in his work, editing a book titled \"Global Catastrophic Risks\", still without abandoning the emphasis in the specificity of 'existential' risks for its \"pan-generational\" and not merely \"endurable\" dimension. Other proeminent theorists of the field, such asToby Ord, remain inclined to the canonical transhumanist definition. Maximizing future value is a concept of ERS defined byNick Bostromwhich exerted an early and persistent influence on the field, especially in the stream of thought most closely related to the first wave or techno-utopian paradigm of existential risks. Bostrom summed the concept by the jargon \"Maxipok rule\", which he defined as \"maximize the probability of an okay outcome, where an okay outcome is any outcome that avoids existential disaster\". In his foundational essay, Bostrom proposes four categories of risks according to their outcome, all dealing with some sort of limitation of potential. Under each the categories are listed are then organized in a descending order of probability, starting with the outcome that the author considers more probable. Existential risk studies developed a substantial relation with the effective altruism philanthropic philosophy and community, effectively embracing many of its core ideas as well as attracting a number of effective altruists into the field.The EA community has also contributed financially to the academic consolidation of ERS. Some scholars within the field of ERS have claimed the need for a more attentive examination of its original theoretical-core and the opening for a theoretical pluralism which seeks to rectify the perceived methodological and moral flaws of this historically dominant approach.This original theoretical base of ERS has been termed by some as the \"techno-utopian approach\", in reference to the general idea oftechnological utopianism, and has been defined by its strong bonds withtranshumanism,longtermismand the so-calledtotal utilitarianism. In this sense, the premises of such techno-utopian approach are manifested in the three assumption, not explicitly and totally shared by all its adherents, such as - a \"(...) maximally technologically developed future could contain (and is defined in terms of) enormous quantities of utilitarian intrinsic value, particularly due to more fulfillingposthumanmodes of living\";that its failure would represent a \"existential catastrophe\";and, lastly, that the presentmoral obligationis to ensure the realization of this posthuman future, \"(...) including through exceptional actions.\".These assumptions are considered particularly essential to the canonical definition of existential risk. The technological utopianism paradigm of ERS is considered most visible and influential by its articulation in Nick Bostrom's foundational work, both his aforementioned 2002 and 2013 essays, as well as his 2003 paper titled \"Astronomical Waste\".Popular books by thinkers of existential risks, such asThe Precipice,Superintelligence, andWhat We Owe the Future, have also fostered the public profile of technological utopianism. Some scholars consider the concept of existential risk established within ERS to be excessively restrictive and narrow, which discloses acolonialistattitude of neglect to thehistory of genocides, especially the one related with thecolonial genocide of indigenous peoples. Nick Bostrom, for example, explicitly states that the start point for anthropogenic existential risks is the period after the end ofWorld War II, with the invention ofnuclear weapons. In a 2023Global Policyarticle, Hobson and Corry write: The question is then: will existential security bring necessary emergency measures of a collective kind to bear on emerging catastrophic global threats, or erode 'normal' politics of domestic and international society (to the extent that these exist) and potentially legitimate a pursuit, not of global interests, but of a hegemonic set of interests posing as humanity? [...] [A]ny notion of collective global interest is inevitably already shot through with particular (geo)political positions and interests. The persistence of 'the international'—the division of the social world into multiple uneven units (Rosenberg, 2006)—means that any universal category (of human or civilisation) will be partial or lodged in partial political communities. Legacies of violence and extinction perpetrated in the name of humanity and civilisation make for a bad track record. Added to the statist baggage of existing security practices and discourses, the potential violence of enacting security measures in the name of protecting a planetary or species category should therefore not be overlooked. Theorists of ERS, Bostrom prominently, have often claimed that 'existential risk' is an understudied subject inacademic literature. In an essay from 2013, titled \"Existential Risk Prevention as Global Priority\", Bostrom remarked that theScopusdatabase contains 900 papers ondung beetlesbut fewer than 50 papers when searching for \"human extinction\". Which confirms, in Bostrom view, the neglected state of research of this subject. However, other researches have contested and criticized both the premises and conclusions of this claim and the particular experiment that Bostrom used to substantiate it. Joshua Schuster and Derek Woods claimed that the same research, made in March of 2020, did present a marginally improved numbers of papers on human extinction; yet, the search for a commonly related term, \"genocide\", resulted in 7,166 papers. In a distinct database,JSTOR, the researches 66,809 results for \"human extinction\", 43,926 for \"genocide\" and 134,089 for \"extinction\". Besides that, the search for specific instances of existential risk, such as nuclear war or genetically engineered bioweapons, provide an enormous accumulation of research. Both authors claim that this different is symptomatic of the Bostrom attachment to self-defined criteria and terms for this kind of theme, remaining, according to them, inattentive to the research aroundhuman rightsandgenocide prevention. ", "combined_text": "Existential risk studies Contents Background History First wave Second wave Third wave Concepts Existential risk Maximizing future value Classification of existential risks Related fields Effective altruism Debate Critique of technological utopianism Historical and political perspectives Claims of neglected research See also Notable theorists Associated institutions Other References Bibliography Existential risk studies(ERS) is afield of studiesfocused on the definition and theorization of \"existential risks\", its ethical implications and the related strategies of long-termsurvival.Existential risks are diversely defined as global kinds of calamity that have the capacity of inducing the extinction of intelligentearthlinglife, such ashumans, or, at least, a severe limitation of theirpotential, as defined by ERS theorists.The field development and expansion can be divided in waves according to its conceptual changes as well as its evolving relationship with related fields and theories, such asfutures studies,disaster studies,AI safety,effective altruismandlongtermism. The historical precursors of existential risks studies can be found in early 19th-century thought aroundhuman extinctionand the more recent models and theories ofglobal catastrophic riskthat date mainly to theCold War period, especially the thinking around a hypotheticalnuclear holocaust.ERS emerged as a distinctive and unified field in the early 2000s,experiencing a rapid growth in the academyand also within the general public with the publication of popular-oriented books.The field has also fostered the creation of a number of foundations,research centersandthink tanks, some of which received substantial philanthropic fundingand notability within prestigious universities. The idea of existential risks has it prehistory in the speculation on the possibility ofhuman extinction. The prospect ofextinctionis itself a break from previous religious and mythologicaleschatologyin the measure that it is thought as an absolute and naturalistic event.As such, human extinction is a recent invention in theintellectual historyof calamity. Its major historical source is present inscience fiction literature. Notoriously,Lord Byronwas, according to reports, concerned that acomet impactcould bring the destruction of humanity, while his poem \"Darkness\" describes a future in which the Earth becomes lifeless.Mary Shelley's novelThe Last Manprovides another example of early naturalistic catastrophic imaginations, depicting the story of a man who lived through the death of the rest of humanity in the final decades of the 21st century, caused by many events such as a worldwide plague.The idea itself of the \"last man\" can be traced to a emerginggenreof19th century literature, originating, most probably, withJean-Baptiste Cousin de Grainville's work, also titled asThe Last Man, published by 1805, where humanity lives through a crisis ofinfertility. A later rendition of this theme can be found inThe Time Machine, published byH.G. Wellsin 1895, where atime voyagerfinds himself 30 million years into a future in which the Earth is nothing but a cold and almost lifeless planet, the reason being the cooling of thesun. Around the same period, Wells wrote two other text on extinction, this time as nonfiction essays, titled \"On Extinction\" (1893) and \"The Extinction of Man\" (1897).In the 20th century, human extinction persists as a theme in science fiction.Isaac Asimovnot only concerned himself with the possibility ofcivilizational collapsein hisFoundationtrilogy, but also wrote a nonfiction book on the subject, titledA Choice of Catastrophes: The Disasters That Threaten Our World, and published in 1979. Another precursory trend for existential risks is identifiable in the discourses of scientific concern for catastrophes that emerged primarily in reaction to the invention ofnuclear weapons. These early responses attended especially to the possibility of an atmospheric ignition, which was soon dismissed as implausible, as well as the concern withradioactive contamination, which became a substantial and persistent theme in the discussion of possible catastrophic events. The risk engendered by radioactive particles prompted a quick mobilization among scientists and intellectuals, notoriously exemplified by theRussell–Einstein Manifesto, in 1955, which warned about the possibility of a human extinction. As a consequence, thePugwash Conferences on Science and World Affairswas established with the purposed of reducing the threat ofarmed conflicts. A similar effort is also exemplified by the creation of theBulletin of the Atomic Scientists, gathering previous members of theManhattan Project. The bulletin has also created and maintained the iconicDoomsday Clockwith the purpose of trackingglobal catastrophic riskwhile representing in a temporal fashion. The foundational moment of ERS can be dated to the publication ofNick Bostrom's 2002 essay titled \"Existential Risks: Analyzing Human Extinction Scenarios and Related Hazards\". In this essay, Bostrom sought to framehuman extinctionas a topic of philosophic pertinence to theanalyticandutilitariantraditions, mainly by dissociating it from past apocalyptical literature and by presenting a schematized and holistic review of possible threats for human survival or, more generally, to its capacity of realizing its own potential, as defined by him and which stands as the canonical definition of existential risk.Conjointly, he attempted to align this study of existential risks with an insight of its overcoming by a prospect of colossal technological development, which would allow human long-termsurvival through outer space colonization.Most of the essay consists of the proposed classification for existential risks, which is composed by four categories, idiomatically named\"Bangs\", \"Crunches\", \"Shrieks\" and \"Whimpers\", all inspired byT. S. Eliotpoem \"The Hollow Men\". The essay brought Bostrom significant academic recognition, incentivizing the attainment of his professorship atOxford Universityas well as the directorship of the now defunctFuture of Humanity Institute, in 2005, which he helped to found.TheCentre for the Study of Existential Riskwas established byCambridge Universityin 2012, which prompted its replication in other universities. This initial rendition of existential risks established what has been termed the 'first wave' of ERS.Described as an instance oftechnological utopianismwhich is defined by its expectation, or, as Noah B. Taylor characterizes as a \"teleologicalmomentum\", of a posthuman vision of the future. Proponents of this wave of ERS placed the emphasis of their hope and faith in technology, particularly artificial intelligence, genetic engineering, and nanotechnology, to lead humanity into a type of posthuman state where the divisions between the physical, virtual, mechanical, and biologic blur. The second wave, or generation, of ERS was characterized by its elaboration effort over the foundational work of Bostrom, and was further distinguished by its growing relations and interaction witheffective altruism. The emphasis ontranshumanismis considered to have been reduced during this period. After its relative institutional consolidation and the expansion of scholar engaged with the field, ERS became increasingly occupied with the issues relating to the diversity of its constituency and the need for a theoretical pluralism in its research. Some scholars of ERS focused on critical examinations of the \"historically dominant\"approach within the field, termed by some as the \"techno-utopian approach\".The so-calledtechnological utopianismhas formed the theoretical-core of ERS, drawing substantial inspiration fromtranshumanism,longtermismand the current ofutilitarianismknown astotal utilitarianism. The scholars most critical of this background have claimed that it suffers from intrinsic moral unreliability and methodological flaws, which evidences the demand for newframeworksof ERS, especially the ones that enhances democratic values perceived as lacking in the original formulation. The canonical definition of existential risk was proposed early by Bostrom in his essay, \"Existential Risks: Analyzing Human Extinction Scenarios and Related Hazards\", establishing it as a risk \"(...) where an adverse outcome would either annihilate Earth-originating intelligent life or permanently and drastically curtail its potential\",implying a kind ofriskwhich is bothglobalandterminal. Further elaborated by Bostrom in another essay, \"Existential Risk Prevention as Global Priority\", published in 2013.This definition, consequently, excludes, or, at least, is indirectly related to forms of calamity and mass suffering that remain below the selected threshold established by theorists of ERS.Genocidesandenslavementare examples of these \"local terminal risk[s]\", while \"global endurable risks\" might range from moderate levels of global warming, threats to the biodiversity, and global economic recessions.In this sense, the 'existential' of existential risks is distinguished from other 'catastrophical' forms of risk, being essentially related to the concept ofhuman potentialityalso elaborated by Bostom.As the author himself explains: \"Tragic as such events are to the people immediately affected, in the big picture of things — from the perspective of humankind as a whole — even the worst of these catastrophes are mere ripples on the surface of the great sea of life.\" The perceived problems of this definition of existential risk, primarily relating to its scale, have stimulated other scholars of the field to prefer a more broader category, that is less exclusively related toposthumanexpectations and extinctionist scenarios, such as \"global catastrophic risks\". Bostrom himself has partially incorporated this concept in his work, editing a book titled \"Global Catastrophic Risks\", still without abandoning the emphasis in the specificity of 'existential' risks for its \"pan-generational\" and not merely \"endurable\" dimension. Other proeminent theorists of the field, such asToby Ord, remain inclined to the canonical transhumanist definition. Maximizing future value is a concept of ERS defined byNick Bostromwhich exerted an early and persistent influence on the field, especially in the stream of thought most closely related to the first wave or techno-utopian paradigm of existential risks. Bostrom summed the concept by the jargon \"Maxipok rule\", which he defined as \"maximize the probability of an okay outcome, where an okay outcome is any outcome that avoids existential disaster\". In his foundational essay, Bostrom proposes four categories of risks according to their outcome, all dealing with some sort of limitation of potential. Under each the categories are listed are then organized in a descending order of probability, starting with the outcome that the author considers more probable. Existential risk studies developed a substantial relation with the effective altruism philanthropic philosophy and community, effectively embracing many of its core ideas as well as attracting a number of effective altruists into the field.The EA community has also contributed financially to the academic consolidation of ERS. Some scholars within the field of ERS have claimed the need for a more attentive examination of its original theoretical-core and the opening for a theoretical pluralism which seeks to rectify the perceived methodological and moral flaws of this historically dominant approach.This original theoretical base of ERS has been termed by some as the \"techno-utopian approach\", in reference to the general idea oftechnological utopianism, and has been defined by its strong bonds withtranshumanism,longtermismand the so-calledtotal utilitarianism. In this sense, the premises of such techno-utopian approach are manifested in the three assumption, not explicitly and totally shared by all its adherents, such as - a \"(...) maximally technologically developed future could contain (and is defined in terms of) enormous quantities of utilitarian intrinsic value, particularly due to more fulfillingposthumanmodes of living\";that its failure would represent a \"existential catastrophe\";and, lastly, that the presentmoral obligationis to ensure the realization of this posthuman future, \"(...) including through exceptional actions.\".These assumptions are considered particularly essential to the canonical definition of existential risk. The technological utopianism paradigm of ERS is considered most visible and influential by its articulation in Nick Bostrom's foundational work, both his aforementioned 2002 and 2013 essays, as well as his 2003 paper titled \"Astronomical Waste\".Popular books by thinkers of existential risks, such asThe Precipice,Superintelligence, andWhat We Owe the Future, have also fostered the public profile of technological utopianism. Some scholars consider the concept of existential risk established within ERS to be excessively restrictive and narrow, which discloses acolonialistattitude of neglect to thehistory of genocides, especially the one related with thecolonial genocide of indigenous peoples. Nick Bostrom, for example, explicitly states that the start point for anthropogenic existential risks is the period after the end ofWorld War II, with the invention ofnuclear weapons. In a 2023Global Policyarticle, Hobson and Corry write: The question is then: will existential security bring necessary emergency measures of a collective kind to bear on emerging catastrophic global threats, or erode 'normal' politics of domestic and international society (to the extent that these exist) and potentially legitimate a pursuit, not of global interests, but of a hegemonic set of interests posing as humanity? [...] [A]ny notion of collective global interest is inevitably already shot through with particular (geo)political positions and interests. The persistence of 'the international'—the division of the social world into multiple uneven units (Rosenberg, 2006)—means that any universal category (of human or civilisation) will be partial or lodged in partial political communities. Legacies of violence and extinction perpetrated in the name of humanity and civilisation make for a bad track record. Added to the statist baggage of existing security practices and discourses, the potential violence of enacting security measures in the name of protecting a planetary or species category should therefore not be overlooked. Theorists of ERS, Bostrom prominently, have often claimed that 'existential risk' is an understudied subject inacademic literature. In an essay from 2013, titled \"Existential Risk Prevention as Global Priority\", Bostrom remarked that theScopusdatabase contains 900 papers ondung beetlesbut fewer than 50 papers when searching for \"human extinction\". Which confirms, in Bostrom view, the neglected state of research of this subject. However, other researches have contested and criticized both the premises and conclusions of this claim and the particular experiment that Bostrom used to substantiate it. Joshua Schuster and Derek Woods claimed that the same research, made in March of 2020, did present a marginally improved numbers of papers on human extinction; yet, the search for a commonly related term, \"genocide\", resulted in 7,166 papers. In a distinct database,JSTOR, the researches 66,809 results for \"human extinction\", 43,926 for \"genocide\" and 134,089 for \"extinction\". Besides that, the search for specific instances of existential risk, such as nuclear war or genetically engineered bioweapons, provide an enormous accumulation of research. Both authors claim that this different is symptomatic of the Bostrom attachment to self-defined criteria and terms for this kind of theme, remaining, according to them, inattentive to the research aroundhuman rightsandgenocide prevention.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Existential_risk_studies", "https://en.wikipedia.org/wiki/Existential_risk_studies", "https://en.wikipedia.org/wiki/Existential_risk_studies", "https://en.wikipedia.org/wiki/Academic_discipline", "https://en.wikipedia.org/wiki/Survival", "https://en.wikipedia.org/wiki/Human_extinction", "https://en.wikipedia.org/wiki/Futures_studies", "https://en.wikipedia.org/wiki/Existential_risk_from_artificial_general_intelligence"]},
{"id": "3078fe836701", "url": "https://en.wikipedia.org/wiki/Personality_rights", "title": "Personality rights", "headings": ["Contents", "Classification", "Civil law and common law jurisdictions", "Country-specific jurisdictions", "Australia", "Canada", "Cyprus", "Denmark", "France", "Germany", "Greece", "Guernsey", "Hong Kong", "Iran", "Jamaica", "Japan", "Portugal", "People's Republic of China", "South Africa", "South Korea", "Spain", "United States", "See also", "Notes", "References", "Sources", "Further reading", "External links"], "content": "Personality rights, sometimes referred to as theright of publicity, are rights for an individual to control the commercial use of their identity, such as name, image, likeness, or other unequivocal identifiers. They are generally considered asproperty rights, rather thanpersonal rights, and so the validity of personality rights of publicity may survive the death of the individual to varying degrees, depending on the jurisdiction. Personality rights are generally considered to consist of two types of rights: the right of publicity,or the right to keep one's image and likeness from being commercially exploited without permission or contractual compensation, which is similar (but not identical) to the use of atrademark; and theright to privacy, or the right to be left alone and not have one's personality represented publicly without permission. Incommon lawjurisdictions,publicity rightsfall into the realm of thetortofpassing off. A commonly cited justification for this doctrine, from a policy standpoint, is the notion ofnatural rightsand the idea that every individual should have a right to control how their right of publicity is commercialized by a third party, if at all.  Often, but not always, the motivation to engage in such commercialization is to help propel sales or visibility for a product or service, which usually amounts to some form ofcommercial speech(which in turn receives thelowest level of judicial scrutiny). In contrast withcommon lawjurisdictions, mostcivil lawjurisdictions have specific civil code provisions that protect an individual's image, personal data and other generally private information.  Exceptions have been carved out of these general, broad privacy rights when dealing with news and public figures. Thus, while it may violate an ordinary citizen's privacy to speak about their medical records, one is generally allowed to report on more intimate details in the lives of celebrities and politicians. Unlike most common law jurisdictions the personality rights in civil law are generally inheritable, thus one can make a claim against someone who invades the privacy of a deceased relative if the memory of their character is besmirched by such publication. Personality rights have developed out ofcommon lawconcepts ofproperty,trespassand intentionaltort.  Thus personality rights are, generally speaking, judge-made law, though there arejurisdictionswhere some aspects of personality rights are statutory. In some jurisdictions, publicity rights and privacy rights are not clearly distinguished, and the term publicity right is generally used. In a publicity rights case the issue to decide is whether a significant section of the public would be misled into believing (incorrectly) that a commercial arrangement had been concluded between aplaintiffand adefendantunder which the plaintiff agreed to the advertising involving the image or reputation of a famous person. The actionable misrepresentation requires a suggestion that the plaintiff has endorsed or licensed the defendant's products, or somehow can exercise control over those products. This is done by way of thetortofpassing off. The meaning of the law is best illustrated by principal cases on the subject. In Australia, false association or endorsement is actionable via the law ofpassing off, not a separate law of \"right of personality\". TheHendersoncasewas a decision of the Supreme Court of New South Wales (both the first instance and appellate jurisdiction). The plaintiffs wereballroom dancersand they sued the defendant in passing off alleging it wrongfully published their photograph on the cover of a gramophone record entitledStrictly for Dancing: Vol. 1. An injunction was granted on the ground that the use suggested the plaintiffs recommended or approved of the defendant's goods, or had some connection with the goods. However, in the 1988 case ofHoney v Australian Airlines,Gary Honey, a well known Australian athlete, failed in his claim for damages afterAustralian Airlinesused a photograph of him on a poster without his permission. The judge held, in essence, that the poster depicted excellence in general rather than a particular person. The provinces ofBritish Columbia,Manitoba,Newfoundland and Labrador, andSaskatchewanhave enacted privacy legislation dealing with personality rights, which have the following traits: Canadian common law recognizes a limited right to personality. It was first acknowledged in the 1971 Ontario decision ofKrouse v. Chrysler Canada Ltd., where the Court held that where a person has marketable value in their likeness and it has been used in a manner that suggests an endorsement of a product then there is grounds for an action in appropriation of personality. This right was later expanded upon inAthans v. Canadian Adventure Camps(1977) where the Court held that the personality right included both image and name. InGould Estate v. Stoddart Publishing Co. Ltd.(1998), the Ontario Court of Appeal concluded that simply writingaboutsomebody, even for the purpose of generating a profit, does not constitute appropriation of personality. The general tort of appropriation of personality is still in development, but it is currentlybeing argued that it will be recognized in all common law provinces,with certain characteristics: In 1994, the newCivil Code of Quebecintroduced new provisions that enshrine the right to privacy as an attribute of personality: 3.Every person is the holder of personality rights, such as the right to life, the right to the inviolability and integrity of his person, and the right to the respect of his name, reputation and privacy. These rights are inalienable. ... 36.The following acts, in particular, may be considered as invasions of the privacy of a person: InAubry v Éditions Vice-Versa Inc, theSupreme Court of Canadaalso affirmed that under Quebec'sCharter of Human Rights and Freedomsprivacy provisions, a photographer can take photographs in public places but may not publish the picture unless permission has been obtained from the subject, except where the subject appears in an incidental manner, or whose professional success depends on public opinion.The relevant provisions of theCharterare: 4.Every person has a right to the safeguard of his dignity, honour and reputation.5.Every person has a right to respect for his private life. Therefore, the following general characteristics may be drawn: InCyprus, people depicted in photographs can oppose their use in advertisements and their publication in magazines, even if it was taken in a public place. InDenmark, theDanish Penal Codechapters 26 and 27, provides certain personality rights. The governmental Danish Data Protection Agency, has made a declaration regarding publication on the Internet of pictures taken of persons in a public area: A portrait photograph is defined as a photograph, with the purpose of depicting one or more specific person(s). The personality rights however may be contracted for persons who are generally accepted as public persons. InFrance, personality rights are protected under article 9 of the French civil code.  While publicly known facts and images of public figures are not generally protected, use of someone's image or personal history has been held actionable under French law. The most famous case in recent history is perhaps the publication of the book onFrançois MitterrandcalledLe Grand Secretin which Mitterrand's doctor published a book that not only revealed private facts about Mitterrand's life, but also revealed medical confidences protected bydoctor–patient privilege. InGermany, personality rights are protected under theGerman civil code, where the concept of an \"absolute person of contemporary history\" allows the depiction of individuals who are part of history but still gives them some protection of their rights of privacy outside the public sphere. A succinct statement of the German law can be found in the following judicial statement from theMarlene Dietrichcase: the general right of personality has been recognised in the case law of the GermanFederal Court of Justicesince 1954 as a basic right constitutionally guaranteed by Articles 1 and 2 of theBasic Lawand at the same time as an \"other right\" protected in civil law under § 823 (1) of theBGB(established case law since BGHZ 13, 334, 338 - readers' letters). It guarantees as against all the world the protection of human dignity and the right to free development of the personality. Special forms of manifestation of the general right of personality are the right to one's own picture (§§ 22 ff. of theKUG[de]) and the right to one's name (§ 12 of the BGB). They guarantee protection of the personality for the sphere regulated by them. In addition to the general personality rights, there are special rules that forbid taking intimate pictures without consent (§ 184kStGB), and that forbid taking pictures which violate the \"most personal sphere\" of those pictured (§ 201 StGB - in particular, photos of private situations such as inside the bedroom, and photos of helpless persons, such as accident victims). In contrast to the general rules about the right to one's image, these rules also apply to just taking images, not only to publishing them. The relevant Greek laws include 57 AK and 2472/1997. As regarding photography: The relevant Guernsey law was enacted on 3 December 2012 under the name ofImage Rights Bailiwick of Guernsey Ordinance 2012and allows for the registration of a personality right, together with images associated with that personality. Images are widely defined and can be any number of personal attributes, such as likeness,mannerisms, gestures, voice, nickname etc. Personalities able to register fall into 5 categories, namely sole, joint, group, legal and fictional character. In addition, humans can be registered up to 100 years after the date of death, making the law very favourable for estate managers and trustees. InHong Kong, as in most other common law jurisdictions, there is no separate \"personality right\", and false association or endorsement is actionable under the law of passing off. The main case on this point relates toCantopopsinger/actorAndy LauandHang Seng Bankover the allegedly unauthorized use of Lau's image oncredit cards,which has led to the observation that only limited personality rights exist in this jurisdiction. There are few studies on the right to fame in Iranian law. However, through general principles, an attempt has been made to support celebrities. In a 1994 case involving the estate ofBob Marley, theSupreme Court of Jamaicaacknowledged a property right of personality which survived his death. In October 2007,J-popduoPink LadysuedKobunshafor¥3.7 million after the publisher's magazineJosei Jishinused photos of the duo on an article on dieting through dancing without their permission. The case was rejected by theTokyo District Court. In February 2012, the Supreme Court rejected the duo's appeal based on the right of publicity. InPortugal, personality rights are protected under the \"tutela geral da personalidade\" on article 70 of the Portuguese Civil Code and, also, in article 17 of the Constitution of the Portuguese Republic.\nSome personality rights, like the right to image or honor are specifically typified in the civil code in the articles following the \"tutela geral\".\nSpecifically regarding image rights, article 79 of the Portuguese Civil Code states that an image of a person cannot be published or exposed without her consent, even after the person's death (in which case the consent is to be obtained from existing family or heirs). However, consent is not needed for public personalities when in their public roles, for use in scientific, didactic or cultural purposes, or when the image is produced in a public setting. However, if the image harms the honor, reputation or decorum of the person it cannot be reproduced or exposed without consent. In thePeople's Republic of China, rights of personality are established by statute. According to article 100 and 101 of theGeneral Principle of Civil Lawof the People's Republic of China, the right of name and the right of image are protected. It is prohibited to use another's image for commercial use without that person's consent. In the new Tort Liabilities Law which came into effect on Jan 1, 2021, the right of privacy is mentioned for the first time in the legislation. InSouth Africa, personality rights are protected under theSouth African law of delictand theBill of Rights, which also provides forfreedom of expressionandfreedom of association.After much uncertainty concerning the recognition of image rights inSouth Africa, theSupreme Court of Appealprovided clarity in the landmark case ofGrütter v Lombard.In South Africa, a person's right to identity is violated if the attributes of that person is used without permission in a way which cannot be reconciled with the true image of that person.Apart from the unauthorized use of a person's image, this kind of infringement also entails some kind of misrepresentation concerning the individual, such as that the individual approves or endorses a particular product or service or that an attorney is a partner in a firm, while this is not the case.  Secondly, the right to identity is violated if the attributes of a person is used without authorization by another person for commercial gain.Apart from the unauthorized use of the individual's image, such use also primarily entails a commercial motive which is exclusively aimed at promoting a service or product or to solicit clients or customers.  The mere fact that the user may benefit or profit from any product or service in respect of which the individual's attributes have incidentally been used, is not in itself sufficient.  This violation of the right to identity therefore also entails unauthorized use of the individual's attributes with a commercial purpose, whether it is done by means of advertisement or the manufacture and distribution of merchandise covered with the attributes of the individual. Personality rights are not absolute and it goes without saying that the use of a person's attributes must be unlawful before a plaintiff will succeed with any claim.  With the use of a person's image, the personality rights, privacy,human dignityandfreedom of associationof the individual must often be weighed against the user's right tofreedom of expression.  The use of a person's image can be justified on the grounds of consent, truth and public interest, fair comment and jest. In South Korea, as defined in theCivil Code, section 751: A person who has injured the person, liberty or fame of another or has inflicted any mental anguish to another person shall be liable to make compensation for damages arising therefrom. While the concept of personality rights is recognized, it is not yet widely known. The Korean terminology (\"인격표지영리권\", literally translated to \"personality sign commercial rights\") is still much less frequently used compared to the transcription of the English term \"publicity rights\". Nor any independent law on personality rights exist in South Korea (as of October 2023). However, in 2022, a related provision was enacted under the existing Unfair Competition Prevention Act.This revision is considered to have provided a foundation for an independent Act in near future. Much change is expected as it has been reported that around 80% of Korean entertainment agencies voiced difficulties in publicity right violations of their talents. On December 26, 2022, the Ministry of Justice announced plans to stipulate personality rights in Civil Code in the near future. The most notable difference between the new law and the Publicity Rights provision under the Unfair Competition Prevention Act would be the expansion of scope; the new law will go beyond 'celebrities' and will recognize everyone's right to their name, portrait, voice, etc. Personality rights are said to exist to some extent by both influence of constitution and tort liability,but cases filed to enforce such rights against shopping malls have been unsuccessful. South Korea's portrait rights are too widely recognized compared to other countries. Because of this, it is common for South Korean media reports to blur people's faces in press photos, even though there is no problem of defamation. In contrast, most countries regard blur as a distortion of the truth. It is common that the public's faces photographed only in the South Korean media are blurred even when there in no possibility of defamation. Criticism has been raised against this. According to the agency (Spanish) Data Protection for the collection and dissemination on Internet of images of a person without their consent may be a serious breach of the Data Protection Act which would be punishable by a minimum fine of 60,000 euros.  According toEl MundoData Protection Agency decided to investigate ex officio by the mere distribution of the image of a person on the Internet without their consent. In the United States, the right of publicity is based onstate-level law, as opposed to federal, and recognition of the right can vary from state to state.The rationale underlying the right of publicity in theUnited Statesis rooted in both privacy and economic exploitation.The rights are based in tort law, and parallel Prosser's \"Four Torts\" which might be summarized as: 1) Intrusion upon physical solitude; 2) public disclosure of private facts; 3) depiction in a false light; and 4) appropriation of name and likeness.  If looking at it through the prism of Prosser's four torts, violation of a right of publicity most closely aligns with appropriation.  The right of publicity often is manifest in advertising or merchandise.  In states without a specific right of publicity statute, the right of publicity is usually recognized via common law.  The right of publicity has evolved rapidly, with a history of reported cases in the United States and worldwide. The right of publicity is defined as the right of all individuals to control commercial use of their names, images, likenesses, or other identifying aspects of identity.  In certain contexts, the right of publicity is limited (under U.S. law) by theFirst Amendment. The right of publicity can be referred to aspublicity rightsor evenpersonality rights. The term \"right of publicity\" was coined by JudgeJerome Frankin 1953. The extent of recognition of this right in the U.S. is largely driven bystatuteorcase law. Because the right of publicity is primarily governed by state (as opposed to federal) law, the degree of recognition of the right of publicity can vary from one state to the next. The right of publicity is not simply an analog to trademark law, though it could be noted that the right of publicity has some commonality with the protection of trademarks as long as one understands that the right of publicity is a distinct legal doctrine, with its own policies, objectives and standards, including notable differences from trademark law.For example, falsity or likelihood of confusion generally do not have to be established to present a colorable right of publicity claim. At a national level, theU.S. Supreme Courtheld in the 1977 caseZacchini v. Scripps-Howard Broadcasting Co.that theFirst Amendmentdid notimmunizeatelevision stationfrom liability for broadcastingHugo Zacchini'shuman cannonballact without his consent. This was the first, and so far the only, U.S. Supreme Court ruling on rights of publicity and it served to confirm the overall validity of the doctrine and the interests it protects. Indianahas one of the stronger right of publicity statutes in the U.S., providing recognition of the right for 100 years after death, and protecting not only the usual \"name, image and likeness\", but alsosignature,photograph,gestures, distinctive appearances, and mannerisms.  Notably, Oklahoma also provides 100 years of protection after death, and Tennessee's statute provides rights that do not ever expire if use is continuous. There are other notable characteristics of the Indiana law,though most of the major movement in right of publicity emanates fromNew YorkandCalifornia, with a significant body of case law which suggest potentially contradictory positions with respect to recognition of the right of publicity under certain circumstances. Some states recognize the right through statute and some others through common law. California has both statutory and common-law strains of authority protecting slightly different forms of the right. The right of publicity shares characteristics of a property right and as such is transferable to the person's heirs after their death. TheCelebrities Rights Actwas passed inCaliforniain 1985 and it extended the personality rights for a celebrity to 70 years after their death. Previously, the 1979Lugosi v. Universal Picturesdecision by theCalifornia Supreme Courtheld thatBela Lugosi's personality rights could not pass to his heirs. California Civil Code Section 3344(a) states:", "combined_text": "Personality rights Contents Classification Civil law and common law jurisdictions Country-specific jurisdictions Australia Canada Cyprus Denmark France Germany Greece Guernsey Hong Kong Iran Jamaica Japan Portugal People's Republic of China South Africa South Korea Spain United States See also Notes References Sources Further reading External links Personality rights, sometimes referred to as theright of publicity, are rights for an individual to control the commercial use of their identity, such as name, image, likeness, or other unequivocal identifiers. They are generally considered asproperty rights, rather thanpersonal rights, and so the validity of personality rights of publicity may survive the death of the individual to varying degrees, depending on the jurisdiction. Personality rights are generally considered to consist of two types of rights: the right of publicity,or the right to keep one's image and likeness from being commercially exploited without permission or contractual compensation, which is similar (but not identical) to the use of atrademark; and theright to privacy, or the right to be left alone and not have one's personality represented publicly without permission. Incommon lawjurisdictions,publicity rightsfall into the realm of thetortofpassing off. A commonly cited justification for this doctrine, from a policy standpoint, is the notion ofnatural rightsand the idea that every individual should have a right to control how their right of publicity is commercialized by a third party, if at all.  Often, but not always, the motivation to engage in such commercialization is to help propel sales or visibility for a product or service, which usually amounts to some form ofcommercial speech(which in turn receives thelowest level of judicial scrutiny). In contrast withcommon lawjurisdictions, mostcivil lawjurisdictions have specific civil code provisions that protect an individual's image, personal data and other generally private information.  Exceptions have been carved out of these general, broad privacy rights when dealing with news and public figures. Thus, while it may violate an ordinary citizen's privacy to speak about their medical records, one is generally allowed to report on more intimate details in the lives of celebrities and politicians. Unlike most common law jurisdictions the personality rights in civil law are generally inheritable, thus one can make a claim against someone who invades the privacy of a deceased relative if the memory of their character is besmirched by such publication. Personality rights have developed out ofcommon lawconcepts ofproperty,trespassand intentionaltort.  Thus personality rights are, generally speaking, judge-made law, though there arejurisdictionswhere some aspects of personality rights are statutory. In some jurisdictions, publicity rights and privacy rights are not clearly distinguished, and the term publicity right is generally used. In a publicity rights case the issue to decide is whether a significant section of the public would be misled into believing (incorrectly) that a commercial arrangement had been concluded between aplaintiffand adefendantunder which the plaintiff agreed to the advertising involving the image or reputation of a famous person. The actionable misrepresentation requires a suggestion that the plaintiff has endorsed or licensed the defendant's products, or somehow can exercise control over those products. This is done by way of thetortofpassing off. The meaning of the law is best illustrated by principal cases on the subject. In Australia, false association or endorsement is actionable via the law ofpassing off, not a separate law of \"right of personality\". TheHendersoncasewas a decision of the Supreme Court of New South Wales (both the first instance and appellate jurisdiction). The plaintiffs wereballroom dancersand they sued the defendant in passing off alleging it wrongfully published their photograph on the cover of a gramophone record entitledStrictly for Dancing: Vol. 1. An injunction was granted on the ground that the use suggested the plaintiffs recommended or approved of the defendant's goods, or had some connection with the goods. However, in the 1988 case ofHoney v Australian Airlines,Gary Honey, a well known Australian athlete, failed in his claim for damages afterAustralian Airlinesused a photograph of him on a poster without his permission. The judge held, in essence, that the poster depicted excellence in general rather than a particular person. The provinces ofBritish Columbia,Manitoba,Newfoundland and Labrador, andSaskatchewanhave enacted privacy legislation dealing with personality rights, which have the following traits: Canadian common law recognizes a limited right to personality. It was first acknowledged in the 1971 Ontario decision ofKrouse v. Chrysler Canada Ltd., where the Court held that where a person has marketable value in their likeness and it has been used in a manner that suggests an endorsement of a product then there is grounds for an action in appropriation of personality. This right was later expanded upon inAthans v. Canadian Adventure Camps(1977) where the Court held that the personality right included both image and name. InGould Estate v. Stoddart Publishing Co. Ltd.(1998), the Ontario Court of Appeal concluded that simply writingaboutsomebody, even for the purpose of generating a profit, does not constitute appropriation of personality. The general tort of appropriation of personality is still in development, but it is currentlybeing argued that it will be recognized in all common law provinces,with certain characteristics: In 1994, the newCivil Code of Quebecintroduced new provisions that enshrine the right to privacy as an attribute of personality: 3.Every person is the holder of personality rights, such as the right to life, the right to the inviolability and integrity of his person, and the right to the respect of his name, reputation and privacy. These rights are inalienable. ... 36.The following acts, in particular, may be considered as invasions of the privacy of a person: InAubry v Éditions Vice-Versa Inc, theSupreme Court of Canadaalso affirmed that under Quebec'sCharter of Human Rights and Freedomsprivacy provisions, a photographer can take photographs in public places but may not publish the picture unless permission has been obtained from the subject, except where the subject appears in an incidental manner, or whose professional success depends on public opinion.The relevant provisions of theCharterare: 4.Every person has a right to the safeguard of his dignity, honour and reputation.5.Every person has a right to respect for his private life. Therefore, the following general characteristics may be drawn: InCyprus, people depicted in photographs can oppose their use in advertisements and their publication in magazines, even if it was taken in a public place. InDenmark, theDanish Penal Codechapters 26 and 27, provides certain personality rights. The governmental Danish Data Protection Agency, has made a declaration regarding publication on the Internet of pictures taken of persons in a public area: A portrait photograph is defined as a photograph, with the purpose of depicting one or more specific person(s). The personality rights however may be contracted for persons who are generally accepted as public persons. InFrance, personality rights are protected under article 9 of the French civil code.  While publicly known facts and images of public figures are not generally protected, use of someone's image or personal history has been held actionable under French law. The most famous case in recent history is perhaps the publication of the book onFrançois MitterrandcalledLe Grand Secretin which Mitterrand's doctor published a book that not only revealed private facts about Mitterrand's life, but also revealed medical confidences protected bydoctor–patient privilege. InGermany, personality rights are protected under theGerman civil code, where the concept of an \"absolute person of contemporary history\" allows the depiction of individuals who are part of history but still gives them some protection of their rights of privacy outside the public sphere. A succinct statement of the German law can be found in the following judicial statement from theMarlene Dietrichcase: the general right of personality has been recognised in the case law of the GermanFederal Court of Justicesince 1954 as a basic right constitutionally guaranteed by Articles 1 and 2 of theBasic Lawand at the same time as an \"other right\" protected in civil law under § 823 (1) of theBGB(established case law since BGHZ 13, 334, 338 - readers' letters). It guarantees as against all the world the protection of human dignity and the right to free development of the personality. Special forms of manifestation of the general right of personality are the right to one's own picture (§§ 22 ff. of theKUG[de]) and the right to one's name (§ 12 of the BGB). They guarantee protection of the personality for the sphere regulated by them. In addition to the general personality rights, there are special rules that forbid taking intimate pictures without consent (§ 184kStGB), and that forbid taking pictures which violate the \"most personal sphere\" of those pictured (§ 201 StGB - in particular, photos of private situations such as inside the bedroom, and photos of helpless persons, such as accident victims). In contrast to the general rules about the right to one's image, these rules also apply to just taking images, not only to publishing them. The relevant Greek laws include 57 AK and 2472/1997. As regarding photography: The relevant Guernsey law was enacted on 3 December 2012 under the name ofImage Rights Bailiwick of Guernsey Ordinance 2012and allows for the registration of a personality right, together with images associated with that personality. Images are widely defined and can be any number of personal attributes, such as likeness,mannerisms, gestures, voice, nickname etc. Personalities able to register fall into 5 categories, namely sole, joint, group, legal and fictional character. In addition, humans can be registered up to 100 years after the date of death, making the law very favourable for estate managers and trustees. InHong Kong, as in most other common law jurisdictions, there is no separate \"personality right\", and false association or endorsement is actionable under the law of passing off. The main case on this point relates toCantopopsinger/actorAndy LauandHang Seng Bankover the allegedly unauthorized use of Lau's image oncredit cards,which has led to the observation that only limited personality rights exist in this jurisdiction. There are few studies on the right to fame in Iranian law. However, through general principles, an attempt has been made to support celebrities. In a 1994 case involving the estate ofBob Marley, theSupreme Court of Jamaicaacknowledged a property right of personality which survived his death. In October 2007,J-popduoPink LadysuedKobunshafor¥3.7 million after the publisher's magazineJosei Jishinused photos of the duo on an article on dieting through dancing without their permission. The case was rejected by theTokyo District Court. In February 2012, the Supreme Court rejected the duo's appeal based on the right of publicity. InPortugal, personality rights are protected under the \"tutela geral da personalidade\" on article 70 of the Portuguese Civil Code and, also, in article 17 of the Constitution of the Portuguese Republic.\nSome personality rights, like the right to image or honor are specifically typified in the civil code in the articles following the \"tutela geral\".\nSpecifically regarding image rights, article 79 of the Portuguese Civil Code states that an image of a person cannot be published or exposed without her consent, even after the person's death (in which case the consent is to be obtained from existing family or heirs). However, consent is not needed for public personalities when in their public roles, for use in scientific, didactic or cultural purposes, or when the image is produced in a public setting. However, if the image harms the honor, reputation or decorum of the person it cannot be reproduced or exposed without consent. In thePeople's Republic of China, rights of personality are established by statute. According to article 100 and 101 of theGeneral Principle of Civil Lawof the People's Republic of China, the right of name and the right of image are protected. It is prohibited to use another's image for commercial use without that person's consent. In the new Tort Liabilities Law which came into effect on Jan 1, 2021, the right of privacy is mentioned for the first time in the legislation. InSouth Africa, personality rights are protected under theSouth African law of delictand theBill of Rights, which also provides forfreedom of expressionandfreedom of association.After much uncertainty concerning the recognition of image rights inSouth Africa, theSupreme Court of Appealprovided clarity in the landmark case ofGrütter v Lombard.In South Africa, a person's right to identity is violated if the attributes of that person is used without permission in a way which cannot be reconciled with the true image of that person.Apart from the unauthorized use of a person's image, this kind of infringement also entails some kind of misrepresentation concerning the individual, such as that the individual approves or endorses a particular product or service or that an attorney is a partner in a firm, while this is not the case.  Secondly, the right to identity is violated if the attributes of a person is used without authorization by another person for commercial gain.Apart from the unauthorized use of the individual's image, such use also primarily entails a commercial motive which is exclusively aimed at promoting a service or product or to solicit clients or customers.  The mere fact that the user may benefit or profit from any product or service in respect of which the individual's attributes have incidentally been used, is not in itself sufficient.  This violation of the right to identity therefore also entails unauthorized use of the individual's attributes with a commercial purpose, whether it is done by means of advertisement or the manufacture and distribution of merchandise covered with the attributes of the individual. Personality rights are not absolute and it goes without saying that the use of a person's attributes must be unlawful before a plaintiff will succeed with any claim.  With the use of a person's image, the personality rights, privacy,human dignityandfreedom of associationof the individual must often be weighed against the user's right tofreedom of expression.  The use of a person's image can be justified on the grounds of consent, truth and public interest, fair comment and jest. In South Korea, as defined in theCivil Code, section 751: A person who has injured the person, liberty or fame of another or has inflicted any mental anguish to another person shall be liable to make compensation for damages arising therefrom. While the concept of personality rights is recognized, it is not yet widely known. The Korean terminology (\"인격표지영리권\", literally translated to \"personality sign commercial rights\") is still much less frequently used compared to the transcription of the English term \"publicity rights\". Nor any independent law on personality rights exist in South Korea (as of October 2023). However, in 2022, a related provision was enacted under the existing Unfair Competition Prevention Act.This revision is considered to have provided a foundation for an independent Act in near future. Much change is expected as it has been reported that around 80% of Korean entertainment agencies voiced difficulties in publicity right violations of their talents. On December 26, 2022, the Ministry of Justice announced plans to stipulate personality rights in Civil Code in the near future. The most notable difference between the new law and the Publicity Rights provision under the Unfair Competition Prevention Act would be the expansion of scope; the new law will go beyond 'celebrities' and will recognize everyone's right to their name, portrait, voice, etc. Personality rights are said to exist to some extent by both influence of constitution and tort liability,but cases filed to enforce such rights against shopping malls have been unsuccessful. South Korea's portrait rights are too widely recognized compared to other countries. Because of this, it is common for South Korean media reports to blur people's faces in press photos, even though there is no problem of defamation. In contrast, most countries regard blur as a distortion of the truth. It is common that the public's faces photographed only in the South Korean media are blurred even when there in no possibility of defamation. Criticism has been raised against this. According to the agency (Spanish) Data Protection for the collection and dissemination on Internet of images of a person without their consent may be a serious breach of the Data Protection Act which would be punishable by a minimum fine of 60,000 euros.  According toEl MundoData Protection Agency decided to investigate ex officio by the mere distribution of the image of a person on the Internet without their consent. In the United States, the right of publicity is based onstate-level law, as opposed to federal, and recognition of the right can vary from state to state.The rationale underlying the right of publicity in theUnited Statesis rooted in both privacy and economic exploitation.The rights are based in tort law, and parallel Prosser's \"Four Torts\" which might be summarized as: 1) Intrusion upon physical solitude; 2) public disclosure of private facts; 3) depiction in a false light; and 4) appropriation of name and likeness.  If looking at it through the prism of Prosser's four torts, violation of a right of publicity most closely aligns with appropriation.  The right of publicity often is manifest in advertising or merchandise.  In states without a specific right of publicity statute, the right of publicity is usually recognized via common law.  The right of publicity has evolved rapidly, with a history of reported cases in the United States and worldwide. The right of publicity is defined as the right of all individuals to control commercial use of their names, images, likenesses, or other identifying aspects of identity.  In certain contexts, the right of publicity is limited (under U.S. law) by theFirst Amendment. The right of publicity can be referred to aspublicity rightsor evenpersonality rights. The term \"right of publicity\" was coined by JudgeJerome Frankin 1953. The extent of recognition of this right in the U.S. is largely driven bystatuteorcase law. Because the right of publicity is primarily governed by state (as opposed to federal) law, the degree of recognition of the right of publicity can vary from one state to the next. The right of publicity is not simply an analog to trademark law, though it could be noted that the right of publicity has some commonality with the protection of trademarks as long as one understands that the right of publicity is a distinct legal doctrine, with its own policies, objectives and standards, including notable differences from trademark law.For example, falsity or likelihood of confusion generally do not have to be established to present a colorable right of publicity claim. At a national level, theU.S. Supreme Courtheld in the 1977 caseZacchini v. Scripps-Howard Broadcasting Co.that theFirst Amendmentdid notimmunizeatelevision stationfrom liability for broadcastingHugo Zacchini'shuman cannonballact without his consent. This was the first, and so far the only, U.S. Supreme Court ruling on rights of publicity and it served to confirm the overall validity of the doctrine and the interests it protects. Indianahas one of the stronger right of publicity statutes in the U.S., providing recognition of the right for 100 years after death, and protecting not only the usual \"name, image and likeness\", but alsosignature,photograph,gestures, distinctive appearances, and mannerisms.  Notably, Oklahoma also provides 100 years of protection after death, and Tennessee's statute provides rights that do not ever expire if use is continuous. There are other notable characteristics of the Indiana law,though most of the major movement in right of publicity emanates fromNew YorkandCalifornia, with a significant body of case law which suggest potentially contradictory positions with respect to recognition of the right of publicity under certain circumstances. Some states recognize the right through statute and some others through common law. California has both statutory and common-law strains of authority protecting slightly different forms of the right. The right of publicity shares characteristics of a property right and as such is transferable to the person's heirs after their death. TheCelebrities Rights Actwas passed inCaliforniain 1985 and it extended the personality rights for a celebrity to 70 years after their death. Previously, the 1979Lugosi v. Universal Picturesdecision by theCalifornia Supreme Courtheld thatBela Lugosi's personality rights could not pass to his heirs. California Civil Code Section 3344(a) states:", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Personality_rights", "https://en.wikipedia.org/wiki/Personality_rights", "https://en.wikipedia.org/wiki/Personality_rights", "https://en.wikipedia.org/wiki/Rights", "https://en.wikipedia.org/wiki/Claim_rights_and_liberty_rights", "https://en.wikipedia.org/wiki/Individual_and_group_rights", "https://en.wikipedia.org/wiki/Natural_rights_and_legal_rights", "https://en.wikipedia.org/wiki/Negative_and_positive_rights"]},
{"id": "e3fed4f03c51", "url": "https://en.wikipedia.org/wiki/Fritz_Lang", "title": "Fritz Lang", "headings": ["Contents", "Early life", "Career", "Expressionist films: the Weimar years (1918–1933)", "Emigration", "Hollywood career (1936–1957)", "Last films (1959–1963)", "Death and legacy", "Preservation", "Filmography", "Awards", "References", "Further reading", "External links"], "content": " Friedrich Christian Anton Lang(Austrian German:[ˈfriːdrɪçˈkrɪsti̯a(ː)nˈantɔnˈlaŋ]; December 5, 1890 – August 2, 1976), better known asFritz Lang(Austrian German:[ˈfrɪtsˈlaŋ]), was an Austrian film director, screenwriter, and producer who worked in Germany and later the United States.One of the best-knownémigrésfrom Germany's school ofExpressionism, he was dubbed the \"Master of Darkness\" by theBritish Film Institute.He has been cited as one of the most influential filmmakers of all time. Lang's work spans five decades, from the Expressionist silent films of his first German creative period to his short stay in Paris and his work as a Hollywood director to his last three films made in Germany.Lang's most celebrated films include the futuristic science-fiction filmMetropolis(1927) and the influentialM(1931), afilm noirprecursor. His 1929 filmWoman in the Moonshowcased the use of amulti-stage rocket, and also pioneered the concept of arocketlaunch pad(a rocket standing upright against a tall building before launch having been slowly rolled into place) and the rocket-launchcountdownclock. His other major films includeDr. Mabuse the Gambler(1922),Die Nibelungen(1924), and after moving to Hollywood in 1934,Fury(1936),You Only Live Once(1937),Hangmen Also Die!(1943),The Woman in the Window(1944),Scarlet Street(1945) andThe Big Heat(1953). He became anaturalized citizenof the United States in 1939. Lang was born in Vienna, as the second son of Anton Lang (1860–1940),an architect and construction company manager, and his wife Pauline \"Paula\" Lang (néeSchlesinger; 1864–1920). There is no documented evidence of the true identity of Anton Lang's biological father; he was born as an illegitimate child of a maid from Moravia.Anton Lang was described as a \"lapsed Catholic,\" and was a builder and partner in Honus and Lang, an important construction companyPauline Lang was bornJewishand converted to Catholicism. Fritz Lang was baptized on December 28, 1890, at theSchottenkirchein Vienna.He had an elder brother, Adolf (1884–1961). Lang's father was ofMoraviandescent.At one point, he noted that he was \"born [a]Catholicand very puritan\".Ultimately describing himself as anatheist, Lang believed that religion was important for teaching ethics. After finishing school, Lang briefly attended theTechnical University of Vienna, where he studied civil engineering and eventually switched to art. He left Vienna in 1910 to travel throughout Europe and Africa, later Asia and thePacificarea. In 1913, he studied painting in Paris. He was arrested by the French authorities as an \"enemy alien,\" but escaped to Vienna, where he was drafted into the Imperial Austrian Army. At the outbreak ofWorld War I, Lang lived in the house of his parents in Gars am Kamp (both his parents are buried in Gars) in Lower Austria, where he used to paint. After this he returned to Vienna and volunteered for military service in theAustrianArmy, fighting in Russia andRomania. Lang was wounded four times and lost sight in his right eye,when he then saw a Max Reinhardt show for injured soldiers and played in a Red Cross revue. For a short period of time he was also located inLjutomerwhere he stayed withKarol Grossmannwhere he initially got interested in movies.During his convalescence he began writing plays and simple scenarios with Austrian film directorJoe Maydevising a two-reel film from a Lang scenario. At the end of the war, Lang began to mingle with the demobilized Berlin artistsand was discharged from the army with the rank of lieutenant in 1918. Lang briefly acted in the Viennese theater circuit before being hired as a writer atDecla Film,Erich Pommer's Berlin-based production company. On 13 February 1919, in the Marriage Registry Office inCharlottenburg, Berlin, Lang married a theater actress named Elisabeth Rosenthal. Rosenthal died of a single gunshot wound in their bathtub on September 25, 1920, the shotdeemed to have been fired by Lang's World War IBrowningrevolver.Lang and his future wife Harbou claimed that Rosenthal had shot herself, and Lang and Harbou were charged with failure to render aid. The charge was soon dropped. Lang started work as a director at the German film studioUFA, and laterNero-Film, just as theExpressionistmovement was building. In this first phase of his career, Lang alternated between films such asDer Müde Tod(\"The Weary Death\") and popular thrillers such asDie Spinnen(\"The Spiders\"), combining popular genres with Expressionist techniques to create a synthesis of popular entertainment withart cinema. In 1920, Lang met his future second wife, the writerThea von Harbouthrough director Joe May. Harbou co-wrote and directed the filmDas wandernde Bildwith Lang.She co-wrote every Harbou-Lang film till 1933, includingDr. Mabuse, der Spieler(\"Dr. Mabuse the Gambler,\" 1922 – which ran for over four hours, in two parts in the original version, and was the first in theDr. Mabusetrilogy), the five-hourDie Nibelungen(1924), the dystopian filmMetropolis(1927), and the science fiction filmWoman in the Moon(1929).Metropoliswent over budget, to the UFA's detriment. It was a financial flop, as were his last silent filmsSpies(1928) andWoman in the Moon, produced by Lang's own company. In 1931, independent producerSeymour Nebenzahlhired Lang to directMfor Nero-Film. His first\"talking\" picture, considered by many film scholars to be a masterpiece of the early sound era,Mis a story of a child murderer (Peter Lorrein his first starring role) who is hunted down and brought to justice by Berlin's criminal underworld. Lang was hard to work with. During the climactic final scene inM, Lang allegedly threw Peter Lorre down a flight of stairs in order to give more authenticity to Lorre's battered look. In the films of his German period, Lang produced an oeuvre that established the characteristics later attributed tofilm noir, with its recurring themes of psychological conflict, paranoia, fate and moral ambiguity. Lang started having an affair with the Austrian actressGerda Maurusduring the filming ofSpione(1928). At the end of 1932, Lang started filmingThe Testament of Dr. Mabuse. AsAdolf Hitlercame to power in January 1933, the new regime banned the film on March 30 as an incitement to public disorder.Testamentis occasionally deemed an anti-Nazi film, as Lang had put Nazi phrases into the mouth of the title character. A screening of the film was cancelled byJoseph Goebbels, and it was later banned by theReich Ministry of Public Enlightenment and Propaganda.In banning the film, Goebbels stated that the film \"showed that an extremely dedicated group of people are perfectly capable of overthrowing any state with violence\", and that the film posed a threat to public health and safety. Throughout his marriage with Harbou, Lang was known for being a philanderer. Two of his lovers of these years includedGerda Maurus, the leading actress in Lang's last silent filmsSpione(1928) andWoman in the Moon(1929), and Lily Latte in 1931.In the early 1930s, Harbou started an affair withAyi Tendulkar, an Indian journalist and student 17 years her junior. According to Lang, propaganda minister Joseph Goebbels called Lang to his offices to inform him thatThe Testament of Dr. Mabusewas being banned but, nevertheless, he was so impressed by Lang's abilities as a filmmaker (especiallyMetropolis), that he offered Lang the position of head of German film studio UFA. Lang said it was during that meeting he had decided to leave for Paris – but that the banks had closed by the time the meeting was over. Lang claimed that, after selling his wife's jewelry, he fled by train to Paris that evening, leaving most of his money and personal possessions behind.Despite this, Lang's passport of the time showed that he traveled to and from Germany throughout 1933. Lang left Berlin permanently on July 31, 1933, four months after his meeting with Goebbels and his initial departure. He moved to Paris,having divorcedThea von Harbou, who stayed behind, earlier in 1933. In Paris, Lang filmed his only French film, a version ofFerenc Molnár'sLiliom, starringCharles Boyer. He then moved to the United States. Lang made twenty-two features in his 20-year American career, working in a variety of genres at every major studio inHollywood, and occasionally producing his films as an independent. He became anaturalized citizenof the United States in 1939. Signing first withMGMStudios, Lang's crime dramaFury(1936) sawSpencer Tracycast as a man who is wrongly accused of a crime and nearly killed when a lynch mob sets fire to the jail where he is awaiting trial. However, inFury, he was not allowed to represent black victims in a lynching scenario or to criticize racism, which was his original intention.By the timeFurywas released, Lang had been involved in the creation of the Hollywood Anti-Nazi League, working withOtto Katz, a Czech who was aCominternspy.He made four films with explicitly anti-Nazi themes,Man Hunt(1941),Hangmen Also Die!(1943),Ministry of Fear(1944) andCloak and Dagger(1946).Man Hunt, wroteDave Kehrin 2009, \"may be the best\" of the \"many interventionist films produced by the Hollywood studios before Pearl Harbor\" as it is \"clean and concentrated, elegant and precise, pointed without being preachy.\" His American films were often compared unfavorably to his earlier works by contemporary critics, although the restrained Expressionism of these films is now seen as integral to the emergence and evolution of American genre cinema.Scarlet Street(1945), one of his films featuringEdward G. RobinsonandJoan Bennett, is considered a central film in the film noir genre. One of Lang's most praisedfilms noiris the police dramaThe Big Heat(1953), known for its brutality. As Lang's visual style simplified, in part due to the constraints of the Hollywood studio system, his worldview became increasingly pessimistic, culminating in the cold, geometric style of his last American films,While the City Sleeps(1956) andBeyond a Reasonable Doubt(1956). Lang, as his health worsened with age, found it difficult to find congenial production conditions and backers in Hollywood and contemplated retirement. The German producerArtur Braunerhad expressed interest in remakingThe Indian Tomb(from an original story by Thea von Harbou, that Lang had developed in the 1920s which had ultimately been directed byJoe May),so Lang returned to West Germanyto make his \"Indian Epic\" (consisting ofThe Tiger of EschnapurandThe Indian Tomb). Following the production, Brauner was preparing for a remake ofThe Testament of Dr. Mabusewhen Lang approached him with the idea of adding a new original film to the series. The result wasThe Thousand Eyes of Dr. Mabuse(1960), whose success led to a series of new Mabuse films produced by Brauner (including the remake ofThe Testament of Dr. Mabuse), though Lang did not direct any of the sequels. Lang was approaching blindness during the production,and it was his final project as director. In 1963, he appeared as himself inJean-Luc Godard's filmContempt. On February 8, 1960, Lang received a star on theHollywood Walk of Famefor his contributions to the motion picture industry, located at 1600Vine Street. Lang died from astrokeon August 2, 1976, and was interred in theForest Lawn Hollywood Hills Cemeteryin theHollywood HillsofLos Angeles. Lang's American and later German works were championed by the critics of theCahiers du cinéma, such asFrançois TruffautandJacques Rivette. Truffaut wrote that Lang, especially in his American career, was greatly underappreciated by \"cinema historians and critics\" who \"deny him any genius when he 'signs' spy movies ... war movies ... or simple thrillers.\" Lang is credited with launching or developing many different genres of film.Philip FrenchofThe Observerbelieved that Lang helped craft the \"entertainment war flick\" and that his interpretation of the story of Bonnie and Clyde \"helped launch the Hollywood film noir\".Geoff Andrew of theBritish Film Institutebelieved he set the \"blueprint for the serial killer movie\" throughM. In December 2021, Lang was the subject for BBC Radio 4'sIn Our Time. TheAcademy Film Archivehas preserved a number of Lang's films, includingHuman DesireandMan Hunt. Works Papers Metadata Texts", "combined_text": "Fritz Lang Contents Early life Career Expressionist films: the Weimar years (1918–1933) Emigration Hollywood career (1936–1957) Last films (1959–1963) Death and legacy Preservation Filmography Awards References Further reading External links  Friedrich Christian Anton Lang(Austrian German:[ˈfriːdrɪçˈkrɪsti̯a(ː)nˈantɔnˈlaŋ]; December 5, 1890 – August 2, 1976), better known asFritz Lang(Austrian German:[ˈfrɪtsˈlaŋ]), was an Austrian film director, screenwriter, and producer who worked in Germany and later the United States.One of the best-knownémigrésfrom Germany's school ofExpressionism, he was dubbed the \"Master of Darkness\" by theBritish Film Institute.He has been cited as one of the most influential filmmakers of all time. Lang's work spans five decades, from the Expressionist silent films of his first German creative period to his short stay in Paris and his work as a Hollywood director to his last three films made in Germany.Lang's most celebrated films include the futuristic science-fiction filmMetropolis(1927) and the influentialM(1931), afilm noirprecursor. His 1929 filmWoman in the Moonshowcased the use of amulti-stage rocket, and also pioneered the concept of arocketlaunch pad(a rocket standing upright against a tall building before launch having been slowly rolled into place) and the rocket-launchcountdownclock. His other major films includeDr. Mabuse the Gambler(1922),Die Nibelungen(1924), and after moving to Hollywood in 1934,Fury(1936),You Only Live Once(1937),Hangmen Also Die!(1943),The Woman in the Window(1944),Scarlet Street(1945) andThe Big Heat(1953). He became anaturalized citizenof the United States in 1939. Lang was born in Vienna, as the second son of Anton Lang (1860–1940),an architect and construction company manager, and his wife Pauline \"Paula\" Lang (néeSchlesinger; 1864–1920). There is no documented evidence of the true identity of Anton Lang's biological father; he was born as an illegitimate child of a maid from Moravia.Anton Lang was described as a \"lapsed Catholic,\" and was a builder and partner in Honus and Lang, an important construction companyPauline Lang was bornJewishand converted to Catholicism. Fritz Lang was baptized on December 28, 1890, at theSchottenkirchein Vienna.He had an elder brother, Adolf (1884–1961). Lang's father was ofMoraviandescent.At one point, he noted that he was \"born [a]Catholicand very puritan\".Ultimately describing himself as anatheist, Lang believed that religion was important for teaching ethics. After finishing school, Lang briefly attended theTechnical University of Vienna, where he studied civil engineering and eventually switched to art. He left Vienna in 1910 to travel throughout Europe and Africa, later Asia and thePacificarea. In 1913, he studied painting in Paris. He was arrested by the French authorities as an \"enemy alien,\" but escaped to Vienna, where he was drafted into the Imperial Austrian Army. At the outbreak ofWorld War I, Lang lived in the house of his parents in Gars am Kamp (both his parents are buried in Gars) in Lower Austria, where he used to paint. After this he returned to Vienna and volunteered for military service in theAustrianArmy, fighting in Russia andRomania. Lang was wounded four times and lost sight in his right eye,when he then saw a Max Reinhardt show for injured soldiers and played in a Red Cross revue. For a short period of time he was also located inLjutomerwhere he stayed withKarol Grossmannwhere he initially got interested in movies.During his convalescence he began writing plays and simple scenarios with Austrian film directorJoe Maydevising a two-reel film from a Lang scenario. At the end of the war, Lang began to mingle with the demobilized Berlin artistsand was discharged from the army with the rank of lieutenant in 1918. Lang briefly acted in the Viennese theater circuit before being hired as a writer atDecla Film,Erich Pommer's Berlin-based production company. On 13 February 1919, in the Marriage Registry Office inCharlottenburg, Berlin, Lang married a theater actress named Elisabeth Rosenthal. Rosenthal died of a single gunshot wound in their bathtub on September 25, 1920, the shotdeemed to have been fired by Lang's World War IBrowningrevolver.Lang and his future wife Harbou claimed that Rosenthal had shot herself, and Lang and Harbou were charged with failure to render aid. The charge was soon dropped. Lang started work as a director at the German film studioUFA, and laterNero-Film, just as theExpressionistmovement was building. In this first phase of his career, Lang alternated between films such asDer Müde Tod(\"The Weary Death\") and popular thrillers such asDie Spinnen(\"The Spiders\"), combining popular genres with Expressionist techniques to create a synthesis of popular entertainment withart cinema. In 1920, Lang met his future second wife, the writerThea von Harbouthrough director Joe May. Harbou co-wrote and directed the filmDas wandernde Bildwith Lang.She co-wrote every Harbou-Lang film till 1933, includingDr. Mabuse, der Spieler(\"Dr. Mabuse the Gambler,\" 1922 – which ran for over four hours, in two parts in the original version, and was the first in theDr. Mabusetrilogy), the five-hourDie Nibelungen(1924), the dystopian filmMetropolis(1927), and the science fiction filmWoman in the Moon(1929).Metropoliswent over budget, to the UFA's detriment. It was a financial flop, as were his last silent filmsSpies(1928) andWoman in the Moon, produced by Lang's own company. In 1931, independent producerSeymour Nebenzahlhired Lang to directMfor Nero-Film. His first\"talking\" picture, considered by many film scholars to be a masterpiece of the early sound era,Mis a story of a child murderer (Peter Lorrein his first starring role) who is hunted down and brought to justice by Berlin's criminal underworld. Lang was hard to work with. During the climactic final scene inM, Lang allegedly threw Peter Lorre down a flight of stairs in order to give more authenticity to Lorre's battered look. In the films of his German period, Lang produced an oeuvre that established the characteristics later attributed tofilm noir, with its recurring themes of psychological conflict, paranoia, fate and moral ambiguity. Lang started having an affair with the Austrian actressGerda Maurusduring the filming ofSpione(1928). At the end of 1932, Lang started filmingThe Testament of Dr. Mabuse. AsAdolf Hitlercame to power in January 1933, the new regime banned the film on March 30 as an incitement to public disorder.Testamentis occasionally deemed an anti-Nazi film, as Lang had put Nazi phrases into the mouth of the title character. A screening of the film was cancelled byJoseph Goebbels, and it was later banned by theReich Ministry of Public Enlightenment and Propaganda.In banning the film, Goebbels stated that the film \"showed that an extremely dedicated group of people are perfectly capable of overthrowing any state with violence\", and that the film posed a threat to public health and safety. Throughout his marriage with Harbou, Lang was known for being a philanderer. Two of his lovers of these years includedGerda Maurus, the leading actress in Lang's last silent filmsSpione(1928) andWoman in the Moon(1929), and Lily Latte in 1931.In the early 1930s, Harbou started an affair withAyi Tendulkar, an Indian journalist and student 17 years her junior. According to Lang, propaganda minister Joseph Goebbels called Lang to his offices to inform him thatThe Testament of Dr. Mabusewas being banned but, nevertheless, he was so impressed by Lang's abilities as a filmmaker (especiallyMetropolis), that he offered Lang the position of head of German film studio UFA. Lang said it was during that meeting he had decided to leave for Paris – but that the banks had closed by the time the meeting was over. Lang claimed that, after selling his wife's jewelry, he fled by train to Paris that evening, leaving most of his money and personal possessions behind.Despite this, Lang's passport of the time showed that he traveled to and from Germany throughout 1933. Lang left Berlin permanently on July 31, 1933, four months after his meeting with Goebbels and his initial departure. He moved to Paris,having divorcedThea von Harbou, who stayed behind, earlier in 1933. In Paris, Lang filmed his only French film, a version ofFerenc Molnár'sLiliom, starringCharles Boyer. He then moved to the United States. Lang made twenty-two features in his 20-year American career, working in a variety of genres at every major studio inHollywood, and occasionally producing his films as an independent. He became anaturalized citizenof the United States in 1939. Signing first withMGMStudios, Lang's crime dramaFury(1936) sawSpencer Tracycast as a man who is wrongly accused of a crime and nearly killed when a lynch mob sets fire to the jail where he is awaiting trial. However, inFury, he was not allowed to represent black victims in a lynching scenario or to criticize racism, which was his original intention.By the timeFurywas released, Lang had been involved in the creation of the Hollywood Anti-Nazi League, working withOtto Katz, a Czech who was aCominternspy.He made four films with explicitly anti-Nazi themes,Man Hunt(1941),Hangmen Also Die!(1943),Ministry of Fear(1944) andCloak and Dagger(1946).Man Hunt, wroteDave Kehrin 2009, \"may be the best\" of the \"many interventionist films produced by the Hollywood studios before Pearl Harbor\" as it is \"clean and concentrated, elegant and precise, pointed without being preachy.\" His American films were often compared unfavorably to his earlier works by contemporary critics, although the restrained Expressionism of these films is now seen as integral to the emergence and evolution of American genre cinema.Scarlet Street(1945), one of his films featuringEdward G. RobinsonandJoan Bennett, is considered a central film in the film noir genre. One of Lang's most praisedfilms noiris the police dramaThe Big Heat(1953), known for its brutality. As Lang's visual style simplified, in part due to the constraints of the Hollywood studio system, his worldview became increasingly pessimistic, culminating in the cold, geometric style of his last American films,While the City Sleeps(1956) andBeyond a Reasonable Doubt(1956). Lang, as his health worsened with age, found it difficult to find congenial production conditions and backers in Hollywood and contemplated retirement. The German producerArtur Braunerhad expressed interest in remakingThe Indian Tomb(from an original story by Thea von Harbou, that Lang had developed in the 1920s which had ultimately been directed byJoe May),so Lang returned to West Germanyto make his \"Indian Epic\" (consisting ofThe Tiger of EschnapurandThe Indian Tomb). Following the production, Brauner was preparing for a remake ofThe Testament of Dr. Mabusewhen Lang approached him with the idea of adding a new original film to the series. The result wasThe Thousand Eyes of Dr. Mabuse(1960), whose success led to a series of new Mabuse films produced by Brauner (including the remake ofThe Testament of Dr. Mabuse), though Lang did not direct any of the sequels. Lang was approaching blindness during the production,and it was his final project as director. In 1963, he appeared as himself inJean-Luc Godard's filmContempt. On February 8, 1960, Lang received a star on theHollywood Walk of Famefor his contributions to the motion picture industry, located at 1600Vine Street. Lang died from astrokeon August 2, 1976, and was interred in theForest Lawn Hollywood Hills Cemeteryin theHollywood HillsofLos Angeles. Lang's American and later German works were championed by the critics of theCahiers du cinéma, such asFrançois TruffautandJacques Rivette. Truffaut wrote that Lang, especially in his American career, was greatly underappreciated by \"cinema historians and critics\" who \"deny him any genius when he 'signs' spy movies ... war movies ... or simple thrillers.\" Lang is credited with launching or developing many different genres of film.Philip FrenchofThe Observerbelieved that Lang helped craft the \"entertainment war flick\" and that his interpretation of the story of Bonnie and Clyde \"helped launch the Hollywood film noir\".Geoff Andrew of theBritish Film Institutebelieved he set the \"blueprint for the serial killer movie\" throughM. In December 2021, Lang was the subject for BBC Radio 4'sIn Our Time. TheAcademy Film Archivehas preserved a number of Lang's films, includingHuman DesireandMan Hunt. Works Papers Metadata Texts", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Fritz_Lang", "https://en.wikipedia.org/wiki/Fritz_Lang", "https://en.wikipedia.org/wiki/Fritz_Lang", "https://en.wikipedia.org/wiki/Fritz_Lang_(artist)", "https://en.wikipedia.org/wiki/Austria-Hungary", "https://en.wikipedia.org/wiki/Beverly_Hills,_California", "https://en.wikipedia.org/wiki/Forest_Lawn_Memorial_Park_(Hollywood_Hills)", "https://en.wikipedia.org/wiki/Technical_University_of_Vienna"]},
{"id": "80f041bc8edb", "url": "https://en.wikipedia.org/wiki/Neural_correlates_of_consciousness", "title": "Neural correlates of consciousness", "headings": ["Contents", "Neurobiological approach to consciousness", "Level of arousal and content of consciousness", "Neuronal basis of perception", "Neuronal basis of general consciousness", "Global disorders of consciousness", "Forward versus feedback projections", "History", "See also", "Notes", "References", "Further reading", "External links"], "content": "Theneural correlates ofconsciousness(NCC) are the minimal set of neuronal events and mechanisms sufficient for the occurrence of themental statesto which they are related.Neuroscientistsuseempirical approachesto discoverneural correlatesof subjective phenomena; that is, neural changes which necessarily and regularlycorrelatewith a specific experience. Ascienceof consciousness must explain the exact relationship between subjective mental states and brain states, the nature of the relationship between theconsciousmindand theelectrochemicalinteractions in the body (mind–body problem). Progress inneuropsychologyandneurophilosophyhas come from focusing on the body rather than the mind. In this context the neuronal correlates of consciousness may be viewed as its causes, and consciousness may be thought of as a state-dependent property of an undefinedcomplex, adaptive, and highly interconnected biological system. Discovering and characterizing neural correlates does not offer a causal theory of consciousness that can explain how particular systems experience anything, the so-calledhard problem of consciousness,but understanding the NCC may be a step toward a causal theory. Most neurobiologists propose that the variables giving rise to consciousness are to be found at the neuronal level, governed by classical physics. There are theories proposed ofquantum consciousnessbased onquantum mechanics. There is an apparent redundancy and parallelism in neural networks so, while activity in one group of neurons may correlate with a percept in one case, a different population may mediate a related percept if the former population is lost or inactivated. It may be that every phenomenal, subjective state has a neural correlate. Where the NCC can be induced artificially, the subject will experience the associated percept, while perturbing or inactivating the region of correlation for a specific percept will affect the percept or cause it to disappear, giving a cause-effect relationship from the neural region to the nature of the percept. Proposals that have been advanced over the years include: what characterizes the NCC? What are the commonalities between the NCC for seeing and for hearing? Will the NCC involve all thepyramidal neuronsin the cortex at any given point in time? Or only a subset of long-range projection cells in the frontal lobes that project to the sensory cortices in the back? Neurons that fire in a rhythmic manner? Neurons that fire in asynchronous manner? The growing ability of neuroscientists to manipulate neurons using methods from molecular biology in combination with optical tools (e.g.,Adamantidis et al. 2007) depends on the simultaneous development of appropriate behavioral assays and model organisms amenable to large-scale genomic analysis and manipulation. The combination of fine-grained neuronal analysis in animals with increasingly more sensitive psychophysical and brain imaging techniques in humans, complemented by the development of a robust theoretical predictive framework, will hopefully lead to a rational understanding of consciousness, one of the central mysteries of life.\nResearch has shown a correlation between significant measurable changes in brain structure at the end of the second trimester of the human fetus development, which facilitate the emergence of early consciousness in the fetus. These structural developments include the maturation of neural connections and the formation of key brain regions associated with sensory processing and emotional regulation. As these areas become more integrated, the fetus begins to exhibit responses to external stimuli, suggesting a nascent awareness of its environment. This early stage of consciousness is crucial, as it lays the foundation for later cognitive and social development, influencing how individuals will interact with the world around them after birth. There are two common but distinct dimensions of the termconsciousness,one involvingarousalandstates of consciousnessand the other involvingcontent of consciousnessandconscious states. To be consciousofanything the brain must be in a relatively high state of arousal (sometimes calledvigilance), whether in wakefulness orREM sleep, vividly experienced in dreams although usually not remembered. Brain arousal level fluctuates in acircadianrhythm but may be influenced by lack of sleep, drugs and alcohol, physical exertion, etc. Arousal can be measured behaviorally by the signal amplitude that triggers some criterion reaction (for instance, the sound level necessary to evoke an eye movement or a head turn toward the sound source). Clinicians use scoring systems such as theGlasgow Coma Scaleto assess the level of arousal in patients.Similarly, the NCC are delineated in research bycontent-specificandfulltypes; both are distinct from thebackground conditionsfor consciousness. High arousal states are associated with conscious states that have specific content, seeing, hearing, remembering, planning or fantasizing about something. Different levels or states of consciousness are associated with different kinds of conscious experiences. The \"awake\" state is quite different from the \"dreaming\" state (for instance, the latter has little or no self-reflection) and from the state of deep sleep. In all three cases the basic physiology of the brain is affected, as it also is inaltered states of consciousness, for instance after taking drugs or during meditation when conscious perception and insight may be enhanced compared to the normal waking state. Clinicians talk aboutimpaired states of consciousnessas in \"thecomatose state\", \"thepersistent vegetative state\" (PVS), and \"theminimally conscious state\" (MCS). Here, \"state\" refers to different \"amounts\" of external/physical consciousness, from a total absence in coma, persistent vegetative state and general anesthesia, to a fluctuating and limited form of conscious sensation in a minimally conscious state such as sleep walking or during a complex partialepilepticseizure.The repertoire of conscious states or experiences accessible to a patient in a minimally conscious state is comparatively limited. In brain death there is no arousal, but it is unknown whether the subjectivity of experience has been interrupted, rather than its observable link with the organism. Functional neuroimaging have shown that parts of the cortex are still active in vegetative patients that are presumed to be unconscious;however, these areas appear to be functionally disconnected from associative cortical areas whose activity is needed for awareness. The potentialrichness of conscious experienceappears to increase from deep sleep to drowsiness to full wakefulness, as might be quantified using notions from complexity theory that incorporate both the dimensionality as well as the granularity of conscious experience to give anintegrated-information-theoretical accountof consciousness.As behavioral arousal increases so does the range and complexity of possible behavior. Yet in REM sleep there is a characteristicatonia, low motor arousal and the person is difficult to wake up, but there is still high metabolic and electric brain activity and vivid perception. Many nuclei with distinct chemical signatures in thethalamus,midbrainandponsmust function for a subject to be in a sufficient state of brain arousal to experience anything at all. These nuclei therefore belong to the enabling factors for consciousness.Conversely, it is likely that the specific content of any particular conscious sensation is mediated by particular neurons in the cortex and their associated satellite structures, including theamygdala,thalamus,claustrumand thebasal ganglia. The possibility of precisely manipulating visual percepts in time and space has madevisiona preferred modality in the quest for the NCC. Psychologists have perfected a number of techniques –masking,binocular rivalry,continuous flash suppression,motion induced blindness,change blindness,inattentional blindness– in which the seemingly simple and unambiguous relationship between a physical stimulus in the world and its associated percept in the privacy of the subject's mind is disrupted.In particular a stimulus can be perceptually suppressed for seconds or even minutes at a time: the image is projected into one of the observer's eyes but is invisible, not seen. In this manner the neural mechanisms that respond to the subjective percept rather than the physical stimulus can be isolated, permitting visual consciousness to be tracked in the brain. In aperceptualillusion, the physical stimulus remains fixed while the percept fluctuates. The best known example is theNecker cubewhose 12 lines can be perceived in one of two different ways in depth. A perceptual illusion that can be precisely controlled isbinocular rivalrywhere two different static images are shown to each eye. Conscious observers see either one image or the other alternately;the brain does not allow for the simultaneous perception of both. Logothetis and colleaguesrecorded a variety of visual cortical areas in awake macaque monkeys performing a binocular rivalry task. Macaque monkeys can be trained to report whether they see the left or the right image. The distribution of the switching times and the way in which changing the contrast in one eye affects these leaves little doubt that monkeys and humans experience the same basic phenomenon. In the primary visual cortex (V1) only a small fraction of cells weakly modulated their response as a function of the percept of the monkey while most cells responded to one or the other retinal stimulus with little regard to what the animal perceived at the time. But in a high-level cortical area such as the inferior temporal cortex along theventral streamalmost all neurons responded only to the perceptually dominant stimulus, so that a \"face\" cell only fired when the animal indicated that it saw the face and not the pattern presented to the other eye. This implies that NCC involve neurons active in the inferior temporal cortex: it is likely that specific reciprocal actions of neurons in the inferior temporal and parts of the prefrontal cortex are necessary. A number offMRIexperiments that have exploited binocular rivalry and related illusions to identify the hemodynamic activity underlying visual consciousness in humans demonstrate quite conclusively that activity in the upper stages of the ventral pathway (e.g., thefusiform face areaand theparahippocampal place area) as well as in early regions, including V1 and the lateral geniculate nucleus (LGN), follow the percept and not the retinal stimulus.Further, a number of fMRIand DTI experimentssuggest V1 is necessary but not sufficient for visual consciousness. In a related perceptual phenomenon,flash suppression, the percept associated with an image projected into one eye is suppressed by flashing another image into the other eye while the original image remains. Its methodological advantage over binocular rivalry is that the timing of the perceptual transition is determined by an external trigger rather than by an internal event. The majority of cells in the inferior temporal cortex and the superior temporal sulcus of monkeys trained to report their percept during flash suppression follow the animal's percept: when the cell's preferred stimulus is perceived, the cell responds. If the picture is still present on the retina but is perceptually suppressed, the cell falls silent, even though primary visual cortex neurons fire.Single-neuron recordings in the medial temporal lobe of epilepsy patients during flash suppression likewise demonstrate abolishment of response when the preferred stimulus is present but perceptually masked. Since measurements of brain activity can be confounded by the presence ofneuromodulators, research focuses on measuring it when subjects are not performing a task and in a conscious state, such as during dreams. This has localized the full NCC to an interaction between thetemporal,parietal, andoccipitallobes in the posterior part of the cortex for perception and a frontal region of the cortex for thought, similar to how the posterior cortex is suspected to facilitate content-specific NCC. Given the absence of any accepted criterion of the minimal neuronal correlates necessary for consciousness, the distinction between a persistently vegetative patient who shows regular sleep-wave transitions and may be able to move or smile, and a minimally conscious patient who can communicate (on occasion) in a meaningful manner (for instance, by differential eye movements) and who shows some signs of consciousness, is often difficult. In global anesthesia the patient should not experience psychological trauma but the level of arousal should be compatible with clinical exigencies. Blood-oxygen-level-dependentfMRIhave demonstrated normal patterns of brain activity in a patient in a vegetative state following a severe traumatic brain injury when asked to imagine playing tennis or visiting rooms in his/her house.Differential brain imaging of patients with such global disturbances of consciousness (includingakinetic mutism) reveal that dysfunction in a widespread cortical network including medial and lateral prefrontal and parietal associative areas is associated with a global loss of awareness.Impaired consciousness inepilepticseizures of thetemporal lobewas likewise accompanied by a decrease in cerebral blood flow in frontal and parietal association cortex and an increase in midline structures such as themediodorsal thalamus. Relatively local bilateral injuries to midline (paramedian) subcortical structures can also cause a complete loss of awareness.These structures thereforeenableand control brain arousal (as determined by metabolic or electrical activity) and are necessary neural correlates. One such example is the heterogeneous collection of more than two dozen nuclei on each side of the upper brainstem (pons, midbrain and in the posterior hypothalamus), collectively referred to as thereticular activating system(RAS). Their axons project widely throughout the brain. These nuclei – three-dimensional collections of neurons with their own cyto-architecture and neurochemical identity – release distinct neuromodulators such as acetylcholine, noradrenaline/norepinephrine, serotonin, histamine and orexin/hypocretin to control the excitability of the thalamus and forebrain, mediating alternation between wakefulness and sleep as well as general level of behavioral and brain arousal. After such trauma, however, eventually the excitability of the thalamus and forebrain can recover and consciousness can return.Another enabling factor for consciousness are the five or moreintralaminar nuclei(ILN) of the thalamus. These receive input from many brainstem nuclei and project strongly, directly to the basal ganglia and, in a more distributed manner, into layer I of much of the neocortex. Comparatively small (1 cmor less) bilateral lesions in the thalamic ILN completely knock out all awareness. Many actions in response to sensory inputs are rapid, transient, stereotyped, and unconscious.They could be thought of as cortical reflexes and are characterized by rapid and somewhat stereotyped responses that can take the form of rather complex automated behavior as seen, e.g., in complex partialepilepticseizures. These automated responses, sometimes calledzombie behaviors,could be contrasted by a slower, all-purpose conscious mode that deals more slowly with broader, less stereotyped aspects of the sensory inputs (or a reflection of these, as in imagery) and takes time to decide on appropriate thoughts and responses. Without such a consciousness mode, a vast number of different zombie modes would be required to react to unusual events. A feature that distinguishes humans from most animals is that we are not born with an extensive repertoire of behavioral programs that would enable us to survive on our own (\"physiological prematurity\"). To compensate for this, we have an unmatched ability to learn, i.e., to consciously acquire such programs by imitation or exploration. Once consciously acquired and sufficiently exercised, these programs can become automated to the extent that their execution happens beyond the realms of our awareness. Take, as an example, the incredible fine motor skills exerted in playing a Beethoven piano sonata or the sensorimotor coordination required to ride a motorcycle along a curvy mountain road. Such complex behaviors are possible only because a sufficient number of the subprograms involved can be executed with minimal or even suspended conscious control. In fact, the conscious system may actually interfere somewhat with these automated programs. From an evolutionary standpoint it clearly makes sense to have both automated behavioral programs that can be executed rapidly in a stereotyped and automated manner, and a slightly slower system that allows time for thinking and planning more complex behavior. This latter aspect may be one of the principal functions of consciousness. Other philosophers, however, have suggested that consciousness would not be necessary for any functional advantage in evolutionary processes.No one has given a causal explanation, they argue, of why it would not be possible for a functionally equivalent non-conscious organism (i.e., aphilosophical zombie) to achieve the very same survival advantages as a conscious organism. If evolutionary processes are blind to the difference between functionFbeing performed by conscious organismOand non-conscious organismO*, it is unclear what adaptive advantage consciousness could provide.As a result, an exaptive explanation of consciousness has gained favor with some theorists that posit consciousness did not evolve as an adaptation but was anexaptationarising as a consequence of other developments such as increases in brain size or cortical rearrangement.Consciousness in this sense has been compared to the blind spot in the retina where it is not an adaption of the retina, but instead just a by-product of the way the retinal axons were wired.Several scholars includingPinker,Chomsky,Edelman, andLuriahave indicated the importance of the emergence of human language as an important regulative mechanism of learning and memory in the context of the development of higher-order consciousness. It seems possible that visual zombie modes in the cortex mainly use thedorsal streamin the parietal region.However, parietal activity can affect consciousness by producing attentional effects on the ventral stream, at least under some circumstances. The conscious mode for vision depends largely on the early visual areas (beyond V1) and especially on the ventral stream. Seemingly complex visual processing (such as detecting animals in natural, cluttered scenes) can be accomplished by the human cortex within 130–150 ms,far too brief for eye movements and conscious perception to occur. Furthermore, reflexes such as theoculovestibular reflextake place at even more rapid time-scales. It is quite plausible that such behaviors are mediated by a purely feed-forward moving wave of spiking activity that passes from the retina through V1, into V4, IT and prefrontal cortex, until it affects motorneurons in the spinal cord that control the finger press (as in a typical laboratory experiment). The hypothesis that the basic processing of information is feedforward is supported most directly by the short times (approx. 100 ms) required for a selective response to appear in IT cells. Conversely, conscious perception is believed to require more sustained, reverberatory neural activity, most likely via global feedback from frontal regions of neocortex back to sensory cortical areasthat builds up over time until it exceeds a critical threshold. At this point, the sustained neural activity rapidly propagates to parietal, prefrontal and anterior cingulate cortical regions, thalamus, claustrum and related structures that support short-term memory, multi-modality integration, planning, speech, and other processes intimately related to consciousness. Competition prevents more than one or a very small number of percepts to be simultaneously and actively represented. This is the core hypothesis of theglobal workspace theoryof consciousness.A recently proposed functional framework posits a further possibility – that incipient activity in the brain’s language output channel is internally detected, via neural reuse, in the input channel, resulting in the activation of the same cybernetic proxy configurations potentially being expressed, thus producing an iterative loop. In brief, while rapid but transient neural activity in the thalamo-cortical system can mediate complex behavior without conscious sensation, it is surmised that consciousness requires sustained but well-organized neural activity dependent on long-range cortico-cortical feedback. The neurobiologistChristfried Jakob(1866–1956) argued that the only conditions which must have neural correlates are direct sensations and reactions; these are calledintonations. Neurophysiological studies in animals have provided some insights into the neural correlates of conscious behavior. In the early 1960s,Vernon Mountcastlestudied this set of problems, which he termed theMind/Brain problem, by studying the neural basis of perception in thesomatic sensory system. His labs atJohns Hopkinswere among the first, along withEdward V. Evartsat theNational Institutes of Health(NIH), to record neural activity from behaving monkeys. Struck with the elegance ofS. S. Stevens'approach of magnitude estimation, Mountcastle's group discovered three different modalities of somatic sensation shared one cognitive attribute: in all cases the firing rate of peripheral neurons waslinearly relatedto the strength of the percept elicited. More recently, Ken H. Britten, William T. Newsome, and C. Daniel Salzman have shown that in theMT areaof a monkey's brain, neurons respond with variability that suggests they are the basis of decision making about direction of motion. They first showed that neuronal rates are predictive of decisions usingsignal detection theory, and then that stimulation of these neurons could predictably bias the decision. Such studies were followed by Ranulfo Romo in the somatic sensory system, to confirm, using a different percept and brain area, that a small number of neurons in one brain area underlie perceptual decisions. Other lab groups have followed Mountcastle's seminal work relating cognitive variables to neuronal activity with more complex cognitive tasks. Although monkeys cannot talk about their perceptions, behavioral tasks have been created in which animals made nonverbal reports, for example by producing hand movements. Many of these studies employ perceptual illusions as a way to dissociate sensations (i.e., the sensory information that the brain receives) from perceptions (i.e., how the consciousness interprets them). Neuronal patterns that represent perceptions rather than merely sensory input are interpreted as reflecting the neuronal correlate of consciousness. Using such design,Nikos Logothetisand colleagues discovered perception-reflecting neurons in the temporal lobe. They created an experimental situation in which conflicting images were presented to different eyes (i.e.,binocular rivalry). Under such conditions, human subjects report bistable percepts: they perceive alternatively one or the other image. Logothetis and colleagues trained the monkeys to report with their arm movements which image they perceived. Temporal lobe neurons in Logothetis experiments often reflected what the monkeys' perceived. Neurons with such properties were less frequently observed in the primary visual cortex that corresponds to relatively early stages of visual processing. Another set of experiments using binocular rivalry in humans showed that certain layers of the cortex can be excluded as candidates of the neural correlate of consciousness. Logothetis and colleagues switched the images between eyes during the percept of one of the images. Surprisingly the percept stayed stable. This means that the conscious percept stayed stable and at the same time the primary input to layer 4, which is the input layer, in the visual cortex changed. Therefore, layer 4 can not be a part of the neural correlate of consciousness.Mikhail Lebedevand their colleagues observed a similar phenomenon in the prefrontal cortex of monkeys. In their experiments monkeys reported the perceived direction of visual stimulus movement (which could be an illusion) by making eye movements. Some prefrontal cortex neurons represented actual and some represented perceived displacements of the stimulus. Observation of perception related neurons in prefrontal cortex is consistent with the theory ofChristof KochandFrancis Crickwho postulated that neural correlate of consciousness resides in the prefrontal cortex. Proponents of distributed neuronal processing may likely dispute the view that consciousness has a precise localization in the brain. The thesis of Crick's book,The Astonishing Hypothesis, is that the neural correlate for consciousness lies in our nerve cells and their associated molecules.  Crick and his collaborator Kochhave sought to avoid philosophical debates that are associated with the study of consciousness, by emphasizing the search forcorrelation and not causation. There is much room for disagreement about the nature of this correlate (e.g., does it require synchronous spikes of neurons in different regions of the brain? Is the co-activation of frontal or parietal areas necessary?). The philosopherDavid Chalmersmaintains that a neural correlate of consciousness, unlike other correlates such as for memory, will fail to offer a satisfactory explanation of the phenomenon; he calls this thehard problem of consciousness.", "combined_text": "Neural correlates of consciousness Contents Neurobiological approach to consciousness Level of arousal and content of consciousness Neuronal basis of perception Neuronal basis of general consciousness Global disorders of consciousness Forward versus feedback projections History See also Notes References Further reading External links Theneural correlates ofconsciousness(NCC) are the minimal set of neuronal events and mechanisms sufficient for the occurrence of themental statesto which they are related.Neuroscientistsuseempirical approachesto discoverneural correlatesof subjective phenomena; that is, neural changes which necessarily and regularlycorrelatewith a specific experience. Ascienceof consciousness must explain the exact relationship between subjective mental states and brain states, the nature of the relationship between theconsciousmindand theelectrochemicalinteractions in the body (mind–body problem). Progress inneuropsychologyandneurophilosophyhas come from focusing on the body rather than the mind. In this context the neuronal correlates of consciousness may be viewed as its causes, and consciousness may be thought of as a state-dependent property of an undefinedcomplex, adaptive, and highly interconnected biological system. Discovering and characterizing neural correlates does not offer a causal theory of consciousness that can explain how particular systems experience anything, the so-calledhard problem of consciousness,but understanding the NCC may be a step toward a causal theory. Most neurobiologists propose that the variables giving rise to consciousness are to be found at the neuronal level, governed by classical physics. There are theories proposed ofquantum consciousnessbased onquantum mechanics. There is an apparent redundancy and parallelism in neural networks so, while activity in one group of neurons may correlate with a percept in one case, a different population may mediate a related percept if the former population is lost or inactivated. It may be that every phenomenal, subjective state has a neural correlate. Where the NCC can be induced artificially, the subject will experience the associated percept, while perturbing or inactivating the region of correlation for a specific percept will affect the percept or cause it to disappear, giving a cause-effect relationship from the neural region to the nature of the percept. Proposals that have been advanced over the years include: what characterizes the NCC? What are the commonalities between the NCC for seeing and for hearing? Will the NCC involve all thepyramidal neuronsin the cortex at any given point in time? Or only a subset of long-range projection cells in the frontal lobes that project to the sensory cortices in the back? Neurons that fire in a rhythmic manner? Neurons that fire in asynchronous manner? The growing ability of neuroscientists to manipulate neurons using methods from molecular biology in combination with optical tools (e.g.,Adamantidis et al. 2007) depends on the simultaneous development of appropriate behavioral assays and model organisms amenable to large-scale genomic analysis and manipulation. The combination of fine-grained neuronal analysis in animals with increasingly more sensitive psychophysical and brain imaging techniques in humans, complemented by the development of a robust theoretical predictive framework, will hopefully lead to a rational understanding of consciousness, one of the central mysteries of life.\nResearch has shown a correlation between significant measurable changes in brain structure at the end of the second trimester of the human fetus development, which facilitate the emergence of early consciousness in the fetus. These structural developments include the maturation of neural connections and the formation of key brain regions associated with sensory processing and emotional regulation. As these areas become more integrated, the fetus begins to exhibit responses to external stimuli, suggesting a nascent awareness of its environment. This early stage of consciousness is crucial, as it lays the foundation for later cognitive and social development, influencing how individuals will interact with the world around them after birth. There are two common but distinct dimensions of the termconsciousness,one involvingarousalandstates of consciousnessand the other involvingcontent of consciousnessandconscious states. To be consciousofanything the brain must be in a relatively high state of arousal (sometimes calledvigilance), whether in wakefulness orREM sleep, vividly experienced in dreams although usually not remembered. Brain arousal level fluctuates in acircadianrhythm but may be influenced by lack of sleep, drugs and alcohol, physical exertion, etc. Arousal can be measured behaviorally by the signal amplitude that triggers some criterion reaction (for instance, the sound level necessary to evoke an eye movement or a head turn toward the sound source). Clinicians use scoring systems such as theGlasgow Coma Scaleto assess the level of arousal in patients.Similarly, the NCC are delineated in research bycontent-specificandfulltypes; both are distinct from thebackground conditionsfor consciousness. High arousal states are associated with conscious states that have specific content, seeing, hearing, remembering, planning or fantasizing about something. Different levels or states of consciousness are associated with different kinds of conscious experiences. The \"awake\" state is quite different from the \"dreaming\" state (for instance, the latter has little or no self-reflection) and from the state of deep sleep. In all three cases the basic physiology of the brain is affected, as it also is inaltered states of consciousness, for instance after taking drugs or during meditation when conscious perception and insight may be enhanced compared to the normal waking state. Clinicians talk aboutimpaired states of consciousnessas in \"thecomatose state\", \"thepersistent vegetative state\" (PVS), and \"theminimally conscious state\" (MCS). Here, \"state\" refers to different \"amounts\" of external/physical consciousness, from a total absence in coma, persistent vegetative state and general anesthesia, to a fluctuating and limited form of conscious sensation in a minimally conscious state such as sleep walking or during a complex partialepilepticseizure.The repertoire of conscious states or experiences accessible to a patient in a minimally conscious state is comparatively limited. In brain death there is no arousal, but it is unknown whether the subjectivity of experience has been interrupted, rather than its observable link with the organism. Functional neuroimaging have shown that parts of the cortex are still active in vegetative patients that are presumed to be unconscious;however, these areas appear to be functionally disconnected from associative cortical areas whose activity is needed for awareness. The potentialrichness of conscious experienceappears to increase from deep sleep to drowsiness to full wakefulness, as might be quantified using notions from complexity theory that incorporate both the dimensionality as well as the granularity of conscious experience to give anintegrated-information-theoretical accountof consciousness.As behavioral arousal increases so does the range and complexity of possible behavior. Yet in REM sleep there is a characteristicatonia, low motor arousal and the person is difficult to wake up, but there is still high metabolic and electric brain activity and vivid perception. Many nuclei with distinct chemical signatures in thethalamus,midbrainandponsmust function for a subject to be in a sufficient state of brain arousal to experience anything at all. These nuclei therefore belong to the enabling factors for consciousness.Conversely, it is likely that the specific content of any particular conscious sensation is mediated by particular neurons in the cortex and their associated satellite structures, including theamygdala,thalamus,claustrumand thebasal ganglia. The possibility of precisely manipulating visual percepts in time and space has madevisiona preferred modality in the quest for the NCC. Psychologists have perfected a number of techniques –masking,binocular rivalry,continuous flash suppression,motion induced blindness,change blindness,inattentional blindness– in which the seemingly simple and unambiguous relationship between a physical stimulus in the world and its associated percept in the privacy of the subject's mind is disrupted.In particular a stimulus can be perceptually suppressed for seconds or even minutes at a time: the image is projected into one of the observer's eyes but is invisible, not seen. In this manner the neural mechanisms that respond to the subjective percept rather than the physical stimulus can be isolated, permitting visual consciousness to be tracked in the brain. In aperceptualillusion, the physical stimulus remains fixed while the percept fluctuates. The best known example is theNecker cubewhose 12 lines can be perceived in one of two different ways in depth. A perceptual illusion that can be precisely controlled isbinocular rivalrywhere two different static images are shown to each eye. Conscious observers see either one image or the other alternately;the brain does not allow for the simultaneous perception of both. Logothetis and colleaguesrecorded a variety of visual cortical areas in awake macaque monkeys performing a binocular rivalry task. Macaque monkeys can be trained to report whether they see the left or the right image. The distribution of the switching times and the way in which changing the contrast in one eye affects these leaves little doubt that monkeys and humans experience the same basic phenomenon. In the primary visual cortex (V1) only a small fraction of cells weakly modulated their response as a function of the percept of the monkey while most cells responded to one or the other retinal stimulus with little regard to what the animal perceived at the time. But in a high-level cortical area such as the inferior temporal cortex along theventral streamalmost all neurons responded only to the perceptually dominant stimulus, so that a \"face\" cell only fired when the animal indicated that it saw the face and not the pattern presented to the other eye. This implies that NCC involve neurons active in the inferior temporal cortex: it is likely that specific reciprocal actions of neurons in the inferior temporal and parts of the prefrontal cortex are necessary. A number offMRIexperiments that have exploited binocular rivalry and related illusions to identify the hemodynamic activity underlying visual consciousness in humans demonstrate quite conclusively that activity in the upper stages of the ventral pathway (e.g., thefusiform face areaand theparahippocampal place area) as well as in early regions, including V1 and the lateral geniculate nucleus (LGN), follow the percept and not the retinal stimulus.Further, a number of fMRIand DTI experimentssuggest V1 is necessary but not sufficient for visual consciousness. In a related perceptual phenomenon,flash suppression, the percept associated with an image projected into one eye is suppressed by flashing another image into the other eye while the original image remains. Its methodological advantage over binocular rivalry is that the timing of the perceptual transition is determined by an external trigger rather than by an internal event. The majority of cells in the inferior temporal cortex and the superior temporal sulcus of monkeys trained to report their percept during flash suppression follow the animal's percept: when the cell's preferred stimulus is perceived, the cell responds. If the picture is still present on the retina but is perceptually suppressed, the cell falls silent, even though primary visual cortex neurons fire.Single-neuron recordings in the medial temporal lobe of epilepsy patients during flash suppression likewise demonstrate abolishment of response when the preferred stimulus is present but perceptually masked. Since measurements of brain activity can be confounded by the presence ofneuromodulators, research focuses on measuring it when subjects are not performing a task and in a conscious state, such as during dreams. This has localized the full NCC to an interaction between thetemporal,parietal, andoccipitallobes in the posterior part of the cortex for perception and a frontal region of the cortex for thought, similar to how the posterior cortex is suspected to facilitate content-specific NCC. Given the absence of any accepted criterion of the minimal neuronal correlates necessary for consciousness, the distinction between a persistently vegetative patient who shows regular sleep-wave transitions and may be able to move or smile, and a minimally conscious patient who can communicate (on occasion) in a meaningful manner (for instance, by differential eye movements) and who shows some signs of consciousness, is often difficult. In global anesthesia the patient should not experience psychological trauma but the level of arousal should be compatible with clinical exigencies. Blood-oxygen-level-dependentfMRIhave demonstrated normal patterns of brain activity in a patient in a vegetative state following a severe traumatic brain injury when asked to imagine playing tennis or visiting rooms in his/her house.Differential brain imaging of patients with such global disturbances of consciousness (includingakinetic mutism) reveal that dysfunction in a widespread cortical network including medial and lateral prefrontal and parietal associative areas is associated with a global loss of awareness.Impaired consciousness inepilepticseizures of thetemporal lobewas likewise accompanied by a decrease in cerebral blood flow in frontal and parietal association cortex and an increase in midline structures such as themediodorsal thalamus. Relatively local bilateral injuries to midline (paramedian) subcortical structures can also cause a complete loss of awareness.These structures thereforeenableand control brain arousal (as determined by metabolic or electrical activity) and are necessary neural correlates. One such example is the heterogeneous collection of more than two dozen nuclei on each side of the upper brainstem (pons, midbrain and in the posterior hypothalamus), collectively referred to as thereticular activating system(RAS). Their axons project widely throughout the brain. These nuclei – three-dimensional collections of neurons with their own cyto-architecture and neurochemical identity – release distinct neuromodulators such as acetylcholine, noradrenaline/norepinephrine, serotonin, histamine and orexin/hypocretin to control the excitability of the thalamus and forebrain, mediating alternation between wakefulness and sleep as well as general level of behavioral and brain arousal. After such trauma, however, eventually the excitability of the thalamus and forebrain can recover and consciousness can return.Another enabling factor for consciousness are the five or moreintralaminar nuclei(ILN) of the thalamus. These receive input from many brainstem nuclei and project strongly, directly to the basal ganglia and, in a more distributed manner, into layer I of much of the neocortex. Comparatively small (1 cmor less) bilateral lesions in the thalamic ILN completely knock out all awareness. Many actions in response to sensory inputs are rapid, transient, stereotyped, and unconscious.They could be thought of as cortical reflexes and are characterized by rapid and somewhat stereotyped responses that can take the form of rather complex automated behavior as seen, e.g., in complex partialepilepticseizures. These automated responses, sometimes calledzombie behaviors,could be contrasted by a slower, all-purpose conscious mode that deals more slowly with broader, less stereotyped aspects of the sensory inputs (or a reflection of these, as in imagery) and takes time to decide on appropriate thoughts and responses. Without such a consciousness mode, a vast number of different zombie modes would be required to react to unusual events. A feature that distinguishes humans from most animals is that we are not born with an extensive repertoire of behavioral programs that would enable us to survive on our own (\"physiological prematurity\"). To compensate for this, we have an unmatched ability to learn, i.e., to consciously acquire such programs by imitation or exploration. Once consciously acquired and sufficiently exercised, these programs can become automated to the extent that their execution happens beyond the realms of our awareness. Take, as an example, the incredible fine motor skills exerted in playing a Beethoven piano sonata or the sensorimotor coordination required to ride a motorcycle along a curvy mountain road. Such complex behaviors are possible only because a sufficient number of the subprograms involved can be executed with minimal or even suspended conscious control. In fact, the conscious system may actually interfere somewhat with these automated programs. From an evolutionary standpoint it clearly makes sense to have both automated behavioral programs that can be executed rapidly in a stereotyped and automated manner, and a slightly slower system that allows time for thinking and planning more complex behavior. This latter aspect may be one of the principal functions of consciousness. Other philosophers, however, have suggested that consciousness would not be necessary for any functional advantage in evolutionary processes.No one has given a causal explanation, they argue, of why it would not be possible for a functionally equivalent non-conscious organism (i.e., aphilosophical zombie) to achieve the very same survival advantages as a conscious organism. If evolutionary processes are blind to the difference between functionFbeing performed by conscious organismOand non-conscious organismO*, it is unclear what adaptive advantage consciousness could provide.As a result, an exaptive explanation of consciousness has gained favor with some theorists that posit consciousness did not evolve as an adaptation but was anexaptationarising as a consequence of other developments such as increases in brain size or cortical rearrangement.Consciousness in this sense has been compared to the blind spot in the retina where it is not an adaption of the retina, but instead just a by-product of the way the retinal axons were wired.Several scholars includingPinker,Chomsky,Edelman, andLuriahave indicated the importance of the emergence of human language as an important regulative mechanism of learning and memory in the context of the development of higher-order consciousness. It seems possible that visual zombie modes in the cortex mainly use thedorsal streamin the parietal region.However, parietal activity can affect consciousness by producing attentional effects on the ventral stream, at least under some circumstances. The conscious mode for vision depends largely on the early visual areas (beyond V1) and especially on the ventral stream. Seemingly complex visual processing (such as detecting animals in natural, cluttered scenes) can be accomplished by the human cortex within 130–150 ms,far too brief for eye movements and conscious perception to occur. Furthermore, reflexes such as theoculovestibular reflextake place at even more rapid time-scales. It is quite plausible that such behaviors are mediated by a purely feed-forward moving wave of spiking activity that passes from the retina through V1, into V4, IT and prefrontal cortex, until it affects motorneurons in the spinal cord that control the finger press (as in a typical laboratory experiment). The hypothesis that the basic processing of information is feedforward is supported most directly by the short times (approx. 100 ms) required for a selective response to appear in IT cells. Conversely, conscious perception is believed to require more sustained, reverberatory neural activity, most likely via global feedback from frontal regions of neocortex back to sensory cortical areasthat builds up over time until it exceeds a critical threshold. At this point, the sustained neural activity rapidly propagates to parietal, prefrontal and anterior cingulate cortical regions, thalamus, claustrum and related structures that support short-term memory, multi-modality integration, planning, speech, and other processes intimately related to consciousness. Competition prevents more than one or a very small number of percepts to be simultaneously and actively represented. This is the core hypothesis of theglobal workspace theoryof consciousness.A recently proposed functional framework posits a further possibility – that incipient activity in the brain’s language output channel is internally detected, via neural reuse, in the input channel, resulting in the activation of the same cybernetic proxy configurations potentially being expressed, thus producing an iterative loop. In brief, while rapid but transient neural activity in the thalamo-cortical system can mediate complex behavior without conscious sensation, it is surmised that consciousness requires sustained but well-organized neural activity dependent on long-range cortico-cortical feedback. The neurobiologistChristfried Jakob(1866–1956) argued that the only conditions which must have neural correlates are direct sensations and reactions; these are calledintonations. Neurophysiological studies in animals have provided some insights into the neural correlates of conscious behavior. In the early 1960s,Vernon Mountcastlestudied this set of problems, which he termed theMind/Brain problem, by studying the neural basis of perception in thesomatic sensory system. His labs atJohns Hopkinswere among the first, along withEdward V. Evartsat theNational Institutes of Health(NIH), to record neural activity from behaving monkeys. Struck with the elegance ofS. S. Stevens'approach of magnitude estimation, Mountcastle's group discovered three different modalities of somatic sensation shared one cognitive attribute: in all cases the firing rate of peripheral neurons waslinearly relatedto the strength of the percept elicited. More recently, Ken H. Britten, William T. Newsome, and C. Daniel Salzman have shown that in theMT areaof a monkey's brain, neurons respond with variability that suggests they are the basis of decision making about direction of motion. They first showed that neuronal rates are predictive of decisions usingsignal detection theory, and then that stimulation of these neurons could predictably bias the decision. Such studies were followed by Ranulfo Romo in the somatic sensory system, to confirm, using a different percept and brain area, that a small number of neurons in one brain area underlie perceptual decisions. Other lab groups have followed Mountcastle's seminal work relating cognitive variables to neuronal activity with more complex cognitive tasks. Although monkeys cannot talk about their perceptions, behavioral tasks have been created in which animals made nonverbal reports, for example by producing hand movements. Many of these studies employ perceptual illusions as a way to dissociate sensations (i.e., the sensory information that the brain receives) from perceptions (i.e., how the consciousness interprets them). Neuronal patterns that represent perceptions rather than merely sensory input are interpreted as reflecting the neuronal correlate of consciousness. Using such design,Nikos Logothetisand colleagues discovered perception-reflecting neurons in the temporal lobe. They created an experimental situation in which conflicting images were presented to different eyes (i.e.,binocular rivalry). Under such conditions, human subjects report bistable percepts: they perceive alternatively one or the other image. Logothetis and colleagues trained the monkeys to report with their arm movements which image they perceived. Temporal lobe neurons in Logothetis experiments often reflected what the monkeys' perceived. Neurons with such properties were less frequently observed in the primary visual cortex that corresponds to relatively early stages of visual processing. Another set of experiments using binocular rivalry in humans showed that certain layers of the cortex can be excluded as candidates of the neural correlate of consciousness. Logothetis and colleagues switched the images between eyes during the percept of one of the images. Surprisingly the percept stayed stable. This means that the conscious percept stayed stable and at the same time the primary input to layer 4, which is the input layer, in the visual cortex changed. Therefore, layer 4 can not be a part of the neural correlate of consciousness.Mikhail Lebedevand their colleagues observed a similar phenomenon in the prefrontal cortex of monkeys. In their experiments monkeys reported the perceived direction of visual stimulus movement (which could be an illusion) by making eye movements. Some prefrontal cortex neurons represented actual and some represented perceived displacements of the stimulus. Observation of perception related neurons in prefrontal cortex is consistent with the theory ofChristof KochandFrancis Crickwho postulated that neural correlate of consciousness resides in the prefrontal cortex. Proponents of distributed neuronal processing may likely dispute the view that consciousness has a precise localization in the brain. The thesis of Crick's book,The Astonishing Hypothesis, is that the neural correlate for consciousness lies in our nerve cells and their associated molecules.  Crick and his collaborator Kochhave sought to avoid philosophical debates that are associated with the study of consciousness, by emphasizing the search forcorrelation and not causation. There is much room for disagreement about the nature of this correlate (e.g., does it require synchronous spikes of neurons in different regions of the brain? Is the co-activation of frontal or parietal areas necessary?). The philosopherDavid Chalmersmaintains that a neural correlate of consciousness, unlike other correlates such as for memory, will fail to offer a satisfactory explanation of the phenomenon; he calls this thehard problem of consciousness.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Neural_correlates_of_consciousness", "https://en.wikipedia.org/wiki/Neural_correlates_of_consciousness", "https://en.wikipedia.org/wiki/Neural_correlates_of_consciousness", "https://en.wikipedia.org/wiki/Consciousness", "https://en.wikipedia.org/wiki/Neocortex", "https://en.wikipedia.org/wiki/Consciousness", "https://en.wikipedia.org/wiki/Mental_state", "https://en.wikipedia.org/wiki/Neuroscientist"]},
{"id": "9c6cc92908f2", "url": "https://en.wikipedia.org/wiki/Actor-critic_algorithm", "title": "Actor-critic algorithm", "headings": ["Contents", "Overview", "Actor", "Critic", "Variants", "See also", "References"], "content": "Theactor-critic algorithm(AC) is a family ofreinforcement learning(RL) algorithms that combine policy-based RL algorithms such aspolicy gradient methods, and value-based RL algorithms such as value iteration,Q-learning,SARSA, andTD learning. An AC algorithm consists of two main components: an \"actor\" that determines which actions to take according to a policy function, and a \"critic\" that evaluates those actions according to a value function.Some AC algorithms are on-policy, some are off-policy. Some apply to either continuous or discrete action spaces. Some work in both cases. The actor-critic methods can be understood as an improvement over pure policy gradient methods like REINFORCE via introducing a baseline. Theactoruses a policy functionπ(a|s){\\displaystyle \\pi (a|s)}, while the critic estimates either thevalue functionV(s){\\displaystyle V(s)}, the action-value Q-functionQ(s,a),{\\displaystyle Q(s,a),}the advantage functionA(s,a){\\displaystyle A(s,a)}, or any combination thereof. The actor is a parameterized functionπθ{\\displaystyle \\pi _{\\theta }}, whereθ{\\displaystyle \\theta }are the parameters of the actor. The actor takes as argument the state of the environments{\\displaystyle s}and produces aprobability distributionπθ(⋅|s){\\displaystyle \\pi _{\\theta }(\\cdot |s)}. If the action space is discrete, then∑aπθ(a|s)=1{\\displaystyle \\sum _{a}\\pi _{\\theta }(a|s)=1}. If the action space is continuous, then∫aπθ(a|s)da=1{\\displaystyle \\int _{a}\\pi _{\\theta }(a|s)da=1}. The goal of policy optimization is to improve the actor. That is, to find someθ{\\displaystyle \\theta }that maximizes the expected episodic rewardJ(θ){\\displaystyle J(\\theta )}:J(θ)=Eπθ[∑t=0Tγtrt]{\\displaystyle J(\\theta )=\\mathbb {E} _{\\pi _{\\theta }}\\left[\\sum _{t=0}^{T}\\gamma ^{t}r_{t}\\right]}whereγ{\\displaystyle \\gamma }is thediscount factor,rt{\\displaystyle r_{t}}is the reward at stept{\\displaystyle t}, andT{\\displaystyle T}is the time-horizon (which can be infinite). The goal of policy gradient method is to optimizeJ(θ){\\displaystyle J(\\theta )}bygradient ascenton the policy gradient∇J(θ){\\displaystyle \\nabla J(\\theta )}. As detailed on thepolicy gradient methodpage, there are manyunbiased estimatorsof the policy gradient:∇θJ(θ)=Eπθ[∑0≤j≤T∇θln⁡πθ(Aj|Sj)⋅Ψj|S0=s0]{\\displaystyle \\nabla _{\\theta }J(\\theta )=\\mathbb {E} _{\\pi _{\\theta }}\\left[\\sum _{0\\leq j\\leq T}\\nabla _{\\theta }\\ln \\pi _{\\theta }(A_{j}|S_{j})\\cdot \\Psi _{j}{\\Big |}S_{0}=s_{0}\\right]}whereΨj{\\textstyle \\Psi _{j}}is a linear sum of the following: In the unbiased estimators given above, certain functions such asVπθ,Qπθ,Aπθ{\\displaystyle V^{\\pi _{\\theta }},Q^{\\pi _{\\theta }},A^{\\pi _{\\theta }}}appear. These are approximated by thecritic. Since these functions all depend on the actor, the critic must learn alongside the actor. The critic is learned by value-based RL algorithms. For example, if the critic is estimating the state-value functionVπθ(s){\\displaystyle V^{\\pi _{\\theta }}(s)}, then it can be learned by any value function approximation method. Let the critic be a function approximatorVϕ(s){\\displaystyle V_{\\phi }(s)}with parametersϕ{\\displaystyle \\phi }. The simplest example is TD(1) learning, which trains the critic to minimize the TD(1) error:δi=Ri+γVϕ(Si+1)−Vϕ(Si){\\displaystyle \\delta _{i}=R_{i}+\\gamma V_{\\phi }(S_{i+1})-V_{\\phi }(S_{i})}The critic parameters are updated by gradient descent on the squared TD error:ϕ←ϕ−α∇ϕ(δi)2=ϕ+αδi∇ϕVϕ(Si){\\displaystyle \\phi \\leftarrow \\phi -\\alpha \\nabla _{\\phi }(\\delta _{i})^{2}=\\phi +\\alpha \\delta _{i}\\nabla _{\\phi }V_{\\phi }(S_{i})}whereα{\\displaystyle \\alpha }is the learning rate. Note that the gradient is taken with respect to theϕ{\\displaystyle \\phi }inVϕ(Si){\\displaystyle V_{\\phi }(S_{i})}only, since theϕ{\\displaystyle \\phi }inγVϕ(Si+1){\\displaystyle \\gamma V_{\\phi }(S_{i+1})}constitutes a moving target, and the gradient is not taken with respect to that. This is a common source of error in implementations that useautomatic differentiation, and requires \"stopping the gradient\" at that point. Similarly, if the critic is estimating the action-value functionQπθ{\\displaystyle Q^{\\pi _{\\theta }}}, then it can be learned byQ-learningorSARSA. In SARSA, the critic maintains an estimate of the Q-function, parameterized byϕ{\\displaystyle \\phi }, denoted asQϕ(s,a){\\displaystyle Q_{\\phi }(s,a)}. The temporal difference error is then calculated asδi=Ri+γQθ(Si+1,Ai+1)−Qθ(Si,Ai){\\displaystyle \\delta _{i}=R_{i}+\\gamma Q_{\\theta }(S_{i+1},A_{i+1})-Q_{\\theta }(S_{i},A_{i})}. The critic is then updated byθ←θ+αδi∇θQθ(Si,Ai){\\displaystyle \\theta \\leftarrow \\theta +\\alpha \\delta _{i}\\nabla _{\\theta }Q_{\\theta }(S_{i},A_{i})}The advantage critic can be trained by training both a Q-functionQϕ(s,a){\\displaystyle Q_{\\phi }(s,a)}and a state-value functionVϕ(s){\\displaystyle V_{\\phi }(s)}, then letAϕ(s,a)=Qϕ(s,a)−Vϕ(s){\\displaystyle A_{\\phi }(s,a)=Q_{\\phi }(s,a)-V_{\\phi }(s)}. Although, it is more common to train just a state-value functionVϕ(s){\\displaystyle V_{\\phi }(s)}, then estimate the advantage byAϕ(Si,Ai)≈∑j∈0:n−1γjRi+j+γnVϕ(Si+n)−Vϕ(Si){\\displaystyle A_{\\phi }(S_{i},A_{i})\\approx \\sum _{j\\in 0:n-1}\\gamma ^{j}R_{i+j}+\\gamma ^{n}V_{\\phi }(S_{i+n})-V_{\\phi }(S_{i})}Here,n{\\displaystyle n}is a positive integer. The highern{\\displaystyle n}is, the more lower is the bias in the advantage estimation, but at the price of higher variance. TheGeneralized Advantage Estimation (GAE)introduces a hyperparameterλ{\\displaystyle \\lambda }that smoothly interpolates between Monte Carlo returns (λ=1{\\displaystyle \\lambda =1}, high variance, no bias) and 1-stepTD learning(λ=0{\\displaystyle \\lambda =0}, low variance, high bias). This hyperparameter can be adjusted to pick the optimal bias-variance trade-off in advantage estimation. It uses an exponentially decaying average of n-step returns withλ{\\displaystyle \\lambda }being the decay strength.", "combined_text": "Actor-critic algorithm Contents Overview Actor Critic Variants See also References Theactor-critic algorithm(AC) is a family ofreinforcement learning(RL) algorithms that combine policy-based RL algorithms such aspolicy gradient methods, and value-based RL algorithms such as value iteration,Q-learning,SARSA, andTD learning. An AC algorithm consists of two main components: an \"actor\" that determines which actions to take according to a policy function, and a \"critic\" that evaluates those actions according to a value function.Some AC algorithms are on-policy, some are off-policy. Some apply to either continuous or discrete action spaces. Some work in both cases. The actor-critic methods can be understood as an improvement over pure policy gradient methods like REINFORCE via introducing a baseline. Theactoruses a policy functionπ(a|s){\\displaystyle \\pi (a|s)}, while the critic estimates either thevalue functionV(s){\\displaystyle V(s)}, the action-value Q-functionQ(s,a),{\\displaystyle Q(s,a),}the advantage functionA(s,a){\\displaystyle A(s,a)}, or any combination thereof. The actor is a parameterized functionπθ{\\displaystyle \\pi _{\\theta }}, whereθ{\\displaystyle \\theta }are the parameters of the actor. The actor takes as argument the state of the environments{\\displaystyle s}and produces aprobability distributionπθ(⋅|s){\\displaystyle \\pi _{\\theta }(\\cdot |s)}. If the action space is discrete, then∑aπθ(a|s)=1{\\displaystyle \\sum _{a}\\pi _{\\theta }(a|s)=1}. If the action space is continuous, then∫aπθ(a|s)da=1{\\displaystyle \\int _{a}\\pi _{\\theta }(a|s)da=1}. The goal of policy optimization is to improve the actor. That is, to find someθ{\\displaystyle \\theta }that maximizes the expected episodic rewardJ(θ){\\displaystyle J(\\theta )}:J(θ)=Eπθ[∑t=0Tγtrt]{\\displaystyle J(\\theta )=\\mathbb {E} _{\\pi _{\\theta }}\\left[\\sum _{t=0}^{T}\\gamma ^{t}r_{t}\\right]}whereγ{\\displaystyle \\gamma }is thediscount factor,rt{\\displaystyle r_{t}}is the reward at stept{\\displaystyle t}, andT{\\displaystyle T}is the time-horizon (which can be infinite). The goal of policy gradient method is to optimizeJ(θ){\\displaystyle J(\\theta )}bygradient ascenton the policy gradient∇J(θ){\\displaystyle \\nabla J(\\theta )}. As detailed on thepolicy gradient methodpage, there are manyunbiased estimatorsof the policy gradient:∇θJ(θ)=Eπθ[∑0≤j≤T∇θln⁡πθ(Aj|Sj)⋅Ψj|S0=s0]{\\displaystyle \\nabla _{\\theta }J(\\theta )=\\mathbb {E} _{\\pi _{\\theta }}\\left[\\sum _{0\\leq j\\leq T}\\nabla _{\\theta }\\ln \\pi _{\\theta }(A_{j}|S_{j})\\cdot \\Psi _{j}{\\Big |}S_{0}=s_{0}\\right]}whereΨj{\\textstyle \\Psi _{j}}is a linear sum of the following: In the unbiased estimators given above, certain functions such asVπθ,Qπθ,Aπθ{\\displaystyle V^{\\pi _{\\theta }},Q^{\\pi _{\\theta }},A^{\\pi _{\\theta }}}appear. These are approximated by thecritic. Since these functions all depend on the actor, the critic must learn alongside the actor. The critic is learned by value-based RL algorithms. For example, if the critic is estimating the state-value functionVπθ(s){\\displaystyle V^{\\pi _{\\theta }}(s)}, then it can be learned by any value function approximation method. Let the critic be a function approximatorVϕ(s){\\displaystyle V_{\\phi }(s)}with parametersϕ{\\displaystyle \\phi }. The simplest example is TD(1) learning, which trains the critic to minimize the TD(1) error:δi=Ri+γVϕ(Si+1)−Vϕ(Si){\\displaystyle \\delta _{i}=R_{i}+\\gamma V_{\\phi }(S_{i+1})-V_{\\phi }(S_{i})}The critic parameters are updated by gradient descent on the squared TD error:ϕ←ϕ−α∇ϕ(δi)2=ϕ+αδi∇ϕVϕ(Si){\\displaystyle \\phi \\leftarrow \\phi -\\alpha \\nabla _{\\phi }(\\delta _{i})^{2}=\\phi +\\alpha \\delta _{i}\\nabla _{\\phi }V_{\\phi }(S_{i})}whereα{\\displaystyle \\alpha }is the learning rate. Note that the gradient is taken with respect to theϕ{\\displaystyle \\phi }inVϕ(Si){\\displaystyle V_{\\phi }(S_{i})}only, since theϕ{\\displaystyle \\phi }inγVϕ(Si+1){\\displaystyle \\gamma V_{\\phi }(S_{i+1})}constitutes a moving target, and the gradient is not taken with respect to that. This is a common source of error in implementations that useautomatic differentiation, and requires \"stopping the gradient\" at that point. Similarly, if the critic is estimating the action-value functionQπθ{\\displaystyle Q^{\\pi _{\\theta }}}, then it can be learned byQ-learningorSARSA. In SARSA, the critic maintains an estimate of the Q-function, parameterized byϕ{\\displaystyle \\phi }, denoted asQϕ(s,a){\\displaystyle Q_{\\phi }(s,a)}. The temporal difference error is then calculated asδi=Ri+γQθ(Si+1,Ai+1)−Qθ(Si,Ai){\\displaystyle \\delta _{i}=R_{i}+\\gamma Q_{\\theta }(S_{i+1},A_{i+1})-Q_{\\theta }(S_{i},A_{i})}. The critic is then updated byθ←θ+αδi∇θQθ(Si,Ai){\\displaystyle \\theta \\leftarrow \\theta +\\alpha \\delta _{i}\\nabla _{\\theta }Q_{\\theta }(S_{i},A_{i})}The advantage critic can be trained by training both a Q-functionQϕ(s,a){\\displaystyle Q_{\\phi }(s,a)}and a state-value functionVϕ(s){\\displaystyle V_{\\phi }(s)}, then letAϕ(s,a)=Qϕ(s,a)−Vϕ(s){\\displaystyle A_{\\phi }(s,a)=Q_{\\phi }(s,a)-V_{\\phi }(s)}. Although, it is more common to train just a state-value functionVϕ(s){\\displaystyle V_{\\phi }(s)}, then estimate the advantage byAϕ(Si,Ai)≈∑j∈0:n−1γjRi+j+γnVϕ(Si+n)−Vϕ(Si){\\displaystyle A_{\\phi }(S_{i},A_{i})\\approx \\sum _{j\\in 0:n-1}\\gamma ^{j}R_{i+j}+\\gamma ^{n}V_{\\phi }(S_{i+n})-V_{\\phi }(S_{i})}Here,n{\\displaystyle n}is a positive integer. The highern{\\displaystyle n}is, the more lower is the bias in the advantage estimation, but at the price of higher variance. TheGeneralized Advantage Estimation (GAE)introduces a hyperparameterλ{\\displaystyle \\lambda }that smoothly interpolates between Monte Carlo returns (λ=1{\\displaystyle \\lambda =1}, high variance, no bias) and 1-stepTD learning(λ=0{\\displaystyle \\lambda =0}, low variance, high bias). This hyperparameter can be adjusted to pick the optimal bias-variance trade-off in advantage estimation. It uses an exponentially decaying average of n-step returns withλ{\\displaystyle \\lambda }being the decay strength.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Actor-critic_algorithm", "https://en.wikipedia.org/wiki/Actor-critic_algorithm", "https://en.wikipedia.org/wiki/Actor-critic_algorithm", "https://en.wikipedia.org/wiki/Reinforcement_learning", "https://en.wikipedia.org/wiki/Policy_gradient_method", "https://en.wikipedia.org/wiki/Q-learning", "https://en.wikipedia.org/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action", "https://en.wikipedia.org/wiki/Temporal_difference_learning"]},
{"id": "43e000712f95", "url": "https://en.wikipedia.org/wiki/Attention_schema_theory", "title": "Attention schema theory", "headings": ["Contents", "Description", "Example", "Subjective experience", "Connection with illusionism", "Proposed functions of the attention schema", "Control of attention", "Social cognition", "Analogy to the body schema", "Example", "See also", "References", "Further reading", "External links"], "content": "Theattention schema theory(AST) ofconsciousnessis a neuroscientific and evolutionary theory of consciousness (orsubjective awareness) developed by neuroscientistMichael GrazianoatPrinceton University.It proposes thatbrainsconstruct subjective awareness as a schematic model of the process ofattention.The theory is amaterialisttheory of consciousness. It shares similarities with theillusionistideas of philosophers likeDaniel Dennett,Patricia Churchland, andKeith Frankish. Graziano proposed that anattention schemais like thebody schema. Just as the brain constructs a simplified model of the body to monitor and control its movement, it also constructs a model ofattentionto help monitor and control its own attention. The information in that model, portraying an incomplete and simplified version of attention, leads the brain to conclude that it has a non-physical essence of awareness. Thus subjective awareness is the brain's efficient but imperfect model of its own attention. This approach intends to explain how awareness and attention are similar in many respects, yet are sometimes dissociated; how the brain can be aware of internal and external events, and provides testable predictions. In the theory, an attention schema necessarily evolved due to its fundamental adaptive uses inperception,cognition, andsocial interaction. The AST describes how an information-processing machine can claim to have a conscious, subjective experience,while having no means to discern the difference between its claim and reality. In the theory, the brain is an information processor captive to the information constructed within it. In this approach, the challenge of explaining consciousness is not, \"How does the brain produce an ineffable internal experience,\" but rather, \"How does the brain construct a quirky self description, and what is the useful cognitive role of that self model?\" In other words, because we claim to be conscious, some mechanism in the brain must therefore have computed the requisite information about consciousness to enable the system to output that claim. AST proposes that this is an adaptive function: it serves as an internal model of one of the brain's most important features: attention. A crucial aspect of the theory is model-based knowledge. The brain constructs rich internal models that lie beneath the level of higher cognition or of language. Cognition has partial access to those internal models, and the content of those models are reported as literal reality. The AST can be summarized in three broad points: The attention schema allows a machine to make claims about its consciousness. When it claims to be conscious of concept X (to have a subjective awareness or a mental possession of X), the machine is using higher cognition to access an attention schema, and reporting the information therein. Suppose a person looks at an apple. When the person reports, \"I have a subjective experience of that shiny red apple,\" three items are linked together in that claim: the self, the apple, and a subjective experience. Accessing the information within these three, linked internal models, cognitive machinery claims that there is a self, an apple, and the self has a mental possession of the apple. The mental possession is invisible and has no physically descriptive properties, but it has a general location inside the body and a specific anchor to the apple. This mental essence empowers the self to understand, react to, and remember the apple. The brain (as a machine) relies on its (incomplete and inaccurate) model of attention, claims to have a metaphysical consciousness of the apple. In the AST, subjective experience (consciousness, or mental possession of an object or experience) is a simplified construct that describes the act of attending to something. The internal model of attention is not constructed at a higher cognitive level. It is not a cognitive self theory or learned. Instead, it is constructed beneath the level of cognition and is automatic (and necessary), much like the internal model of the apple and the self. The attention schema is a perception-like model of attention, to distinguish it from higher-order cognitive models such asbeliefsor intellectually reasonedtheories. This explains how a machine with an attention schema contains the requisite information to claim to have a consciousness of something, whether of an apple, a thought, or of itself. The machine can understand consciousness in the same ways that we do; and on accessing its internal information, it does not find explanatory meta-information, computes a conclusion, or accesses an internal model, but it instead learns only the narrow contents of the internal models. In AST, human are machines of that sort. AST is consistent with the perspective calledillusionism.The term \"illusion\", however, may have connotations that are not quite apt for this theory. Three issues with that label arise. The central hypothesis in AST is that the brain constructs an internal model of attention, the attention schema. Its primary adaptive function is to enable a better, more flexible control of attention. Two main types of functions have been proposed for the attention schema: control of attentionand social cognition. Indynamical systems control, a fundamental principle is that a control system works better and more flexibly if it constructs an internal model of the item it controls. An airplaneautopilotsystem works better if it incorporates a model of the dynamics of the airplane. An air and temperature controller for a building works better if it incorporates a rich, predictive model of the building's airflow and temperature dynamics. Similarly, according to AST, the brain's controller of attention should work better by constructing an internal model of what attention is, how it changes over time, what its consequences are, and what state it is in at any moment. Thus the brain's controller of attention should incorporate an internal model of attention – a set of information continuously updated which reflects the dynamics and the changing state of attention. Since attention is an important process in the brain, the proposed attention schema, helping to control attention, would be of fundamental importance to the system. A growing set of behavioral evidence supports this hypothesis. When subjective awareness of a visual stimulus is absent, people can still direct attention to that stimulus, but that attention loses some aspects of control. It is less stable over time, and is less adaptable given training on perturbations.Initial experiments suggest that this may be true, and support the proposal that awareness acts like the internal model for the control of attention. A second proposed function of an attention schema is forsocial cognition– using the attention schema to model the attentional states of others as well as of ourselves.In effect, just as humans attribute awareness to themselves, it is also attributed to others. An advantage of this use of an attention schema is in behavioral prediction, which can aid the survival of intelligent social agents. This is because an agent's attention influences its behavior; since one is more likely to behave toward what one is attending to (and vice-versa). This internal model of attention, and its dynamics and consequences, would be useful for predicting behavior. An intelligent agent can also plan its own future partly by predicting their own actions. Research into AST therefore focuses on the overlap between one's own claims of awareness and one's attributions of awareness to others. Initial research usingbrain scanningin humans suggests that both processes recruit cortical networks that converge on thetemporoparietal junction. AST was developed in analogy to the psychological and neuroscientific work on thebody schema, an area of research to which Graziano contributed in his previous publications.The central ideas of AST can be explained through analogy to the body schema. Suppose a person, Kevin, has reached out and grasped an apple, and is asked what he is holding. He can say that the object is an apple, and can describe its properties. This is because Kevin's brain has constructed a schematic description of the apple, here called an internal model. This is a set of information, about size, color, shape, and location, that is constantly updated as new signals are processed. It allows Kevin to react to the apple and predict how it may behave in different circumstances. His cognitive and linguistic processors can access this internal model of an apple, and thus he can answer questions about it. Now Kevin is asked, \"How are you holding the apple? What is your physical relationship to the apple?\" Once again Kevin can answer. The reason is that, in addition to an internal model of the apple, Kevin's brain also constructs an internal model of his body, including his arm and hand. This internal model (the body schema), is again, the set of information which is constantly updated as new signals are processed, about the size and shape of Kevin's limbs, how they are hinged, how they tend to move, their state at each moment and in the near future. The primary purpose of this body schema is to allow Kevin's brain to control movement. As the state that his arm is known, he can better guide its movement. A side effect of this internal body schema is that he is conscious of, and can explicitly talk about his body, so therefore Kevin can answer: \"I am grasping the apple with my hand, while my arm is outstretched.\" However the body schema is limited. If Kevin is asked, \"How many muscles are in your arm? Where do they attach to the bones?\" he cannot answer. He may have intellectual knowledge learned from a book, but he has no immediate insight into the muscles of his particular arm. The body schema is a reduced model which lacks that level of mechanistic detail. AST takes this analysis to include Kevin's ability to pay attention to the apple, in addition to physically grasping it. AST's definition of attention means that Kevin's brain has focused processing resources on the apple. The internal model of the apple has been 'boosted in strength', and as a result, Kevin's brain processes the apple deeply, is more willing to store it in memory, or to trigger a response to it. In this definition, attention is a mechanistic, data-handling process, and involves the relative deployment of processing resources to a specific signal. Now if Kevin is asked, \"What is your mental relationship to the apple?\", he can answer this question too. According to AST, this is because Kevin's brain constructs not only an internal model of the apple and his body, but also an internal model of his attention. This attention schema is a set of information describing what attention is, its properties, dynamics, consequences, and state at a particular moment. Kevin's cognitive and linguistic machinery has access to this internal model, and therefore Kevin can describe his mental relationship to the apple. However, just as in the case of the body schema, the attention schema lacks information about mechanistic details. It does not contain information about neurons, synapses, or electrochemical signals that make attention possible. As a result, Kevin reports an experience lacking clear physical attributes. He can say, \"I have a mental grasp of the apple. That mental possession, in and of itself, has no physical properties. It just is. It's vaguely located inside me. It is what allows me to know about that apple, remember it, and react to it. It's my mental self taking hold of the apple – my experience of the apple.\" Here Kevin describes a subjective, experiential consciousness of the apple, which seems (from his point of view) to transcend physicality. In AST this is due to the incomplete description of the underlying physical reality: Kevin's account of his consciousness is a simplified, schematic description of his state of attention. The example given above relates to a consciousness of an apple. The same reasoning can be applied to other concepts such as sounds, memories, or oneself as a whole.", "combined_text": "Attention schema theory Contents Description Example Subjective experience Connection with illusionism Proposed functions of the attention schema Control of attention Social cognition Analogy to the body schema Example See also References Further reading External links Theattention schema theory(AST) ofconsciousnessis a neuroscientific and evolutionary theory of consciousness (orsubjective awareness) developed by neuroscientistMichael GrazianoatPrinceton University.It proposes thatbrainsconstruct subjective awareness as a schematic model of the process ofattention.The theory is amaterialisttheory of consciousness. It shares similarities with theillusionistideas of philosophers likeDaniel Dennett,Patricia Churchland, andKeith Frankish. Graziano proposed that anattention schemais like thebody schema. Just as the brain constructs a simplified model of the body to monitor and control its movement, it also constructs a model ofattentionto help monitor and control its own attention. The information in that model, portraying an incomplete and simplified version of attention, leads the brain to conclude that it has a non-physical essence of awareness. Thus subjective awareness is the brain's efficient but imperfect model of its own attention. This approach intends to explain how awareness and attention are similar in many respects, yet are sometimes dissociated; how the brain can be aware of internal and external events, and provides testable predictions. In the theory, an attention schema necessarily evolved due to its fundamental adaptive uses inperception,cognition, andsocial interaction. The AST describes how an information-processing machine can claim to have a conscious, subjective experience,while having no means to discern the difference between its claim and reality. In the theory, the brain is an information processor captive to the information constructed within it. In this approach, the challenge of explaining consciousness is not, \"How does the brain produce an ineffable internal experience,\" but rather, \"How does the brain construct a quirky self description, and what is the useful cognitive role of that self model?\" In other words, because we claim to be conscious, some mechanism in the brain must therefore have computed the requisite information about consciousness to enable the system to output that claim. AST proposes that this is an adaptive function: it serves as an internal model of one of the brain's most important features: attention. A crucial aspect of the theory is model-based knowledge. The brain constructs rich internal models that lie beneath the level of higher cognition or of language. Cognition has partial access to those internal models, and the content of those models are reported as literal reality. The AST can be summarized in three broad points: The attention schema allows a machine to make claims about its consciousness. When it claims to be conscious of concept X (to have a subjective awareness or a mental possession of X), the machine is using higher cognition to access an attention schema, and reporting the information therein. Suppose a person looks at an apple. When the person reports, \"I have a subjective experience of that shiny red apple,\" three items are linked together in that claim: the self, the apple, and a subjective experience. Accessing the information within these three, linked internal models, cognitive machinery claims that there is a self, an apple, and the self has a mental possession of the apple. The mental possession is invisible and has no physically descriptive properties, but it has a general location inside the body and a specific anchor to the apple. This mental essence empowers the self to understand, react to, and remember the apple. The brain (as a machine) relies on its (incomplete and inaccurate) model of attention, claims to have a metaphysical consciousness of the apple. In the AST, subjective experience (consciousness, or mental possession of an object or experience) is a simplified construct that describes the act of attending to something. The internal model of attention is not constructed at a higher cognitive level. It is not a cognitive self theory or learned. Instead, it is constructed beneath the level of cognition and is automatic (and necessary), much like the internal model of the apple and the self. The attention schema is a perception-like model of attention, to distinguish it from higher-order cognitive models such asbeliefsor intellectually reasonedtheories. This explains how a machine with an attention schema contains the requisite information to claim to have a consciousness of something, whether of an apple, a thought, or of itself. The machine can understand consciousness in the same ways that we do; and on accessing its internal information, it does not find explanatory meta-information, computes a conclusion, or accesses an internal model, but it instead learns only the narrow contents of the internal models. In AST, human are machines of that sort. AST is consistent with the perspective calledillusionism.The term \"illusion\", however, may have connotations that are not quite apt for this theory. Three issues with that label arise. The central hypothesis in AST is that the brain constructs an internal model of attention, the attention schema. Its primary adaptive function is to enable a better, more flexible control of attention. Two main types of functions have been proposed for the attention schema: control of attentionand social cognition. Indynamical systems control, a fundamental principle is that a control system works better and more flexibly if it constructs an internal model of the item it controls. An airplaneautopilotsystem works better if it incorporates a model of the dynamics of the airplane. An air and temperature controller for a building works better if it incorporates a rich, predictive model of the building's airflow and temperature dynamics. Similarly, according to AST, the brain's controller of attention should work better by constructing an internal model of what attention is, how it changes over time, what its consequences are, and what state it is in at any moment. Thus the brain's controller of attention should incorporate an internal model of attention – a set of information continuously updated which reflects the dynamics and the changing state of attention. Since attention is an important process in the brain, the proposed attention schema, helping to control attention, would be of fundamental importance to the system. A growing set of behavioral evidence supports this hypothesis. When subjective awareness of a visual stimulus is absent, people can still direct attention to that stimulus, but that attention loses some aspects of control. It is less stable over time, and is less adaptable given training on perturbations.Initial experiments suggest that this may be true, and support the proposal that awareness acts like the internal model for the control of attention. A second proposed function of an attention schema is forsocial cognition– using the attention schema to model the attentional states of others as well as of ourselves.In effect, just as humans attribute awareness to themselves, it is also attributed to others. An advantage of this use of an attention schema is in behavioral prediction, which can aid the survival of intelligent social agents. This is because an agent's attention influences its behavior; since one is more likely to behave toward what one is attending to (and vice-versa). This internal model of attention, and its dynamics and consequences, would be useful for predicting behavior. An intelligent agent can also plan its own future partly by predicting their own actions. Research into AST therefore focuses on the overlap between one's own claims of awareness and one's attributions of awareness to others. Initial research usingbrain scanningin humans suggests that both processes recruit cortical networks that converge on thetemporoparietal junction. AST was developed in analogy to the psychological and neuroscientific work on thebody schema, an area of research to which Graziano contributed in his previous publications.The central ideas of AST can be explained through analogy to the body schema. Suppose a person, Kevin, has reached out and grasped an apple, and is asked what he is holding. He can say that the object is an apple, and can describe its properties. This is because Kevin's brain has constructed a schematic description of the apple, here called an internal model. This is a set of information, about size, color, shape, and location, that is constantly updated as new signals are processed. It allows Kevin to react to the apple and predict how it may behave in different circumstances. His cognitive and linguistic processors can access this internal model of an apple, and thus he can answer questions about it. Now Kevin is asked, \"How are you holding the apple? What is your physical relationship to the apple?\" Once again Kevin can answer. The reason is that, in addition to an internal model of the apple, Kevin's brain also constructs an internal model of his body, including his arm and hand. This internal model (the body schema), is again, the set of information which is constantly updated as new signals are processed, about the size and shape of Kevin's limbs, how they are hinged, how they tend to move, their state at each moment and in the near future. The primary purpose of this body schema is to allow Kevin's brain to control movement. As the state that his arm is known, he can better guide its movement. A side effect of this internal body schema is that he is conscious of, and can explicitly talk about his body, so therefore Kevin can answer: \"I am grasping the apple with my hand, while my arm is outstretched.\" However the body schema is limited. If Kevin is asked, \"How many muscles are in your arm? Where do they attach to the bones?\" he cannot answer. He may have intellectual knowledge learned from a book, but he has no immediate insight into the muscles of his particular arm. The body schema is a reduced model which lacks that level of mechanistic detail. AST takes this analysis to include Kevin's ability to pay attention to the apple, in addition to physically grasping it. AST's definition of attention means that Kevin's brain has focused processing resources on the apple. The internal model of the apple has been 'boosted in strength', and as a result, Kevin's brain processes the apple deeply, is more willing to store it in memory, or to trigger a response to it. In this definition, attention is a mechanistic, data-handling process, and involves the relative deployment of processing resources to a specific signal. Now if Kevin is asked, \"What is your mental relationship to the apple?\", he can answer this question too. According to AST, this is because Kevin's brain constructs not only an internal model of the apple and his body, but also an internal model of his attention. This attention schema is a set of information describing what attention is, its properties, dynamics, consequences, and state at a particular moment. Kevin's cognitive and linguistic machinery has access to this internal model, and therefore Kevin can describe his mental relationship to the apple. However, just as in the case of the body schema, the attention schema lacks information about mechanistic details. It does not contain information about neurons, synapses, or electrochemical signals that make attention possible. As a result, Kevin reports an experience lacking clear physical attributes. He can say, \"I have a mental grasp of the apple. That mental possession, in and of itself, has no physical properties. It just is. It's vaguely located inside me. It is what allows me to know about that apple, remember it, and react to it. It's my mental self taking hold of the apple – my experience of the apple.\" Here Kevin describes a subjective, experiential consciousness of the apple, which seems (from his point of view) to transcend physicality. In AST this is due to the incomplete description of the underlying physical reality: Kevin's account of his consciousness is a simplified, schematic description of his state of attention. The example given above relates to a consciousness of an apple. The same reasoning can be applied to other concepts such as sounds, memories, or oneself as a whole.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Attention_schema_theory", "https://en.wikipedia.org/wiki/Attention_schema_theory", "https://en.wikipedia.org/wiki/Attention_schema_theory", "https://en.wikipedia.org/wiki/Consciousness", "https://en.wikipedia.org/wiki/Awareness", "https://en.wikipedia.org/wiki/Michael_Graziano", "https://en.wikipedia.org/wiki/Princeton_University", "https://en.wikipedia.org/wiki/Brain"]},
{"id": "cb2f988fbaa9", "url": "https://en.wikipedia.org/wiki/Toronto_Declaration", "title": "Toronto Declaration", "headings": ["Contents", "Contents", "Preamble", "Using the framework of international human rights law", "Duties of states: human rights obligations", "Responsibilities of private sector actors: human rights due diligence", "The right to an effective remedy", "References"], "content": "TheToronto Declaration: Protecting the Rights to Equality and Non-Discrimination in Machine Learning Systemsis a declaration that advocates responsible practices formachine learningpractitioners and governing bodies. It is a joint statement issued by groups includingAmnesty InternationalandAccess Now, with other notable signatories includingHuman Rights WatchandThe Wikimedia Foundation.It was published atRightsConon May 16, 2018. The Declaration focuses on concerns ofalgorithmic biasand the potential fordiscriminationthat arises from the use of machine learning andartificial intelligencein applications that may affect people's lives, \"from policing, to welfare systems, to healthcare provision, to platforms for online discourse.\"A secondary concern of the document is the potential for violations ofinformation privacy. The goal of the Declaration is to outline \"tangible and actionable standards for states and the private sector.\"The Declaration calls for tangible solutions, such as reparations for the victims of algorithmic discrimination. The Toronto Declaration consists of 59 articles, broken into six sections, concerninginternational human rights law, duties ofstates, responsibilities ofprivate sectoractors, and theright to an effective remedy. The document begins by asking the question, \"In a world of machine learning systems, who will bear accountability for harminghuman rights?\"It argues that all practitioners, whether in the public or private sector, should be aware of the risks to human rights and approach their work with human rights in mind – conscious of the existing international laws, standards, and principles. The document defines human rights to include \"the right to privacy and data protection, the right to freedom of expression and association, to participation in cultural life, equality before the law, and access to effective remedy\";but it states that the Declaration is most concerned with equality and non-discrimination. The framework of international human rights law enumerates various rights, provides mechanisms to hold violators to account, and ensures remedy for the violated. The document cites theUnited Nations Human Rights Committee's definition of discrimination as \"any distinction, exclusion, restriction or preference which is based on any ground [including but not limited to] race, colour, sex, language, religion, political or other opinion, national or social origin, property, birth or other status, and which has the purpose or effect of nullifying or impairing the recognition, enjoyment or exercise by all persons, on an equal footing, of all rights and freedoms.\" Governments should proactively create binding measures, and private entities should create internal policies, to protect against discrimination. Measures may include protections for sensitive data, especially for vulnerable populations. Systems should be designed in collaboration with a diverse community in order to prevent discrimination in design. Governments today are deploying machine learning systems, often in collaboration with private entities. Even when development is contracted to such third parties, governments retain their obligation to protect human rights. Before implementation, and on an ongoing basis thereafter, they should identify risks and conduct regular audits, then take all necessary measures to mitigate these risks. They should be transparent about how machine learning is implemented and used, avoidingblack box systemswhose logic cannot be easily explained. Systems should be subject to strict oversight from diverse internal committees and independent judicial authorities. Governments must also protect citizens from discrimination by private entities. In addition to oversight, they should pass binding laws against discrimination, as well as for data protection and privacy, and they should provide effective means to remedy for affected individuals. It is important for national and regional governments to expand on and contextualize international law. Private entities are responsible for conducting \"human rights due diligence.\" Just like governments, private entities should identify risks before development by considering common risks and consulting stakeholders, \"including affected groups, organizations that work on human rights, equality and discrimination, as well as independent human rights and machine learning experts.\"They should design systems that mitigate risks, subject systems to regular audits, and forego projects that carry too high of risks. They should be transparent about assumed risks, including details of the technical implementation where necessary, and should provide a mechanism for affected individuals to dispute any decisions that affect them. \"The right to justice is a vital element of international human rights law.\"Private entities should create processes for affected individuals to seek remedy, and they should designate roles for who will oversee these processes. Governments must be especially cautious when deploying machine learning systems in the justice sector. Transparency, accountability, and remedy can help.", "combined_text": "Toronto Declaration Contents Contents Preamble Using the framework of international human rights law Duties of states: human rights obligations Responsibilities of private sector actors: human rights due diligence The right to an effective remedy References TheToronto Declaration: Protecting the Rights to Equality and Non-Discrimination in Machine Learning Systemsis a declaration that advocates responsible practices formachine learningpractitioners and governing bodies. It is a joint statement issued by groups includingAmnesty InternationalandAccess Now, with other notable signatories includingHuman Rights WatchandThe Wikimedia Foundation.It was published atRightsConon May 16, 2018. The Declaration focuses on concerns ofalgorithmic biasand the potential fordiscriminationthat arises from the use of machine learning andartificial intelligencein applications that may affect people's lives, \"from policing, to welfare systems, to healthcare provision, to platforms for online discourse.\"A secondary concern of the document is the potential for violations ofinformation privacy. The goal of the Declaration is to outline \"tangible and actionable standards for states and the private sector.\"The Declaration calls for tangible solutions, such as reparations for the victims of algorithmic discrimination. The Toronto Declaration consists of 59 articles, broken into six sections, concerninginternational human rights law, duties ofstates, responsibilities ofprivate sectoractors, and theright to an effective remedy. The document begins by asking the question, \"In a world of machine learning systems, who will bear accountability for harminghuman rights?\"It argues that all practitioners, whether in the public or private sector, should be aware of the risks to human rights and approach their work with human rights in mind – conscious of the existing international laws, standards, and principles. The document defines human rights to include \"the right to privacy and data protection, the right to freedom of expression and association, to participation in cultural life, equality before the law, and access to effective remedy\";but it states that the Declaration is most concerned with equality and non-discrimination. The framework of international human rights law enumerates various rights, provides mechanisms to hold violators to account, and ensures remedy for the violated. The document cites theUnited Nations Human Rights Committee's definition of discrimination as \"any distinction, exclusion, restriction or preference which is based on any ground [including but not limited to] race, colour, sex, language, religion, political or other opinion, national or social origin, property, birth or other status, and which has the purpose or effect of nullifying or impairing the recognition, enjoyment or exercise by all persons, on an equal footing, of all rights and freedoms.\" Governments should proactively create binding measures, and private entities should create internal policies, to protect against discrimination. Measures may include protections for sensitive data, especially for vulnerable populations. Systems should be designed in collaboration with a diverse community in order to prevent discrimination in design. Governments today are deploying machine learning systems, often in collaboration with private entities. Even when development is contracted to such third parties, governments retain their obligation to protect human rights. Before implementation, and on an ongoing basis thereafter, they should identify risks and conduct regular audits, then take all necessary measures to mitigate these risks. They should be transparent about how machine learning is implemented and used, avoidingblack box systemswhose logic cannot be easily explained. Systems should be subject to strict oversight from diverse internal committees and independent judicial authorities. Governments must also protect citizens from discrimination by private entities. In addition to oversight, they should pass binding laws against discrimination, as well as for data protection and privacy, and they should provide effective means to remedy for affected individuals. It is important for national and regional governments to expand on and contextualize international law. Private entities are responsible for conducting \"human rights due diligence.\" Just like governments, private entities should identify risks before development by considering common risks and consulting stakeholders, \"including affected groups, organizations that work on human rights, equality and discrimination, as well as independent human rights and machine learning experts.\"They should design systems that mitigate risks, subject systems to regular audits, and forego projects that carry too high of risks. They should be transparent about assumed risks, including details of the technical implementation where necessary, and should provide a mechanism for affected individuals to dispute any decisions that affect them. \"The right to justice is a vital element of international human rights law.\"Private entities should create processes for affected individuals to seek remedy, and they should designate roles for who will oversee these processes. Governments must be especially cautious when deploying machine learning systems in the justice sector. Transparency, accountability, and remedy can help.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Toronto_Declaration", "https://en.wikipedia.org/wiki/Toronto_Declaration", "https://en.wikipedia.org/wiki/Toronto_Declaration", "https://en.wikipedia.org/wiki/Machine_learning", "https://en.wikipedia.org/wiki/Amnesty_International", "https://en.wikipedia.org/wiki/Access_Now", "https://en.wikipedia.org/wiki/Human_Rights_Watch", "https://en.wikipedia.org/wiki/Wikimedia_Foundation"]},
{"id": "48049da5a071", "url": "https://en.wikipedia.org/wiki/Yugoslav_philosophy", "title": "Yugoslav philosophy", "headings": ["Contents", "History", "References"], "content": " Yugoslav philosophyparallels the evolution ofphilosophyinEurope, like all European countries claim in general. Yet Yugoslav philosophy first drew upon its own Christianethosandlogosto sustain itself under centuries of Turkish, Venetian, Hungarian and Austrian invasions, then from the broader currents of European philosophy, and in turn contributed to their growth. Modern philosophy in theYugoslavterritories started with the formation ofUniversity of Belgradein the early 19th century as a liberal court philosophy, replicating theories ofJohn Stuart Mill,Herbert Spencerand otherWestern philosophers. They wrote mostly textbook theories about broader subjects such as logic, psychology and pedagogy and the most prominent figure of this period wasAlimpije Vasiljević. At the end of 19th century, this school was surpassed in popularity byBranislav Petronijević, leading philosopher of theKingdom of Yugoslavia. His idealist rationalist metaphysical system was known as \"hypermetaphysics\", with his three principal philosophical works beingPrincipi Metafizike(Principles of Metaphysics),O Vrednosti života(On the Value of Life) andIstorija novije filozofije(History of Contemporary Philosophy). Petronijević had many students and followers, among othersKsenija Atanasijević, the first major female Yugoslav philosopher, who slid into more mystic theories of newscholasticism. After the6 January Dictatorship, Yugoslav philosophy as a whole moved towards the political right, with the thinkers such asVladimir Dvornikovićobtaining positions in the government. Dvorniković was a prominent advocate of Yugoslavintegral nationalismand his most famous work wasKarakterologija Jugoslovena(Characterology of the Yugoslavs). There was also a strong irrationalist current withAlbert Bazala, who became rector ofUniversity of Zagrebin 1932. At the time, universities were under strong religious influence and the most prominent thinker of this school was the SlovenianAleš Ušeničnik, a philosopher ofneo-Thomism. In parallel, the social democratic movement had its own prominent theoreticians such asDimitrije TucovićandSima Marković, who was later killed in theGreat Purge. AfterWorld War II, socialists took power and rejected all former philosophy as idealistic and bourgeois.Dialectical materialismwas introduced, with revolutionary philosophers such asBoris ZiherlorDušan Nedeljković. This theory later evolved towardsMarxist humanismwith thePraxis School, which originated inZagrebandBelgradeduring the 1960s.Prominent figures among the school's founders includeGajo Petrović,Milan Kangrga,Mihailo MarkovićandPredrag Vranicki. From 1964 to 1974 they published the journalPraxis, which was renowned as one of the leading international journals in Marxist theory. Apart from Praxis, Yugoslav philosophy was especially strong inSR Sloveniawith the MarxistBožidar Debenjakandphenomenologicalschool ofTine Hribar. In the seventies, theLjubljana Lacanian Schoolwith the journalProblemi(Problems) was founded by young followers of the theories of the FrenchpsychoanalystJacques Lacan. A specific feature of the Ljubljana School was to connect the Marxist and Hegelian traditions with Lacanian psychoanalysis andstructuralism, with its most famous philosopher beingSlavoj Žižek. After thebreakup of Yugoslavia, newly formed countries continued their philosophical tradition in various directions, but mostly abandoned the principles of Marxism.", "combined_text": "Yugoslav philosophy Contents History References  Yugoslav philosophyparallels the evolution ofphilosophyinEurope, like all European countries claim in general. Yet Yugoslav philosophy first drew upon its own Christianethosandlogosto sustain itself under centuries of Turkish, Venetian, Hungarian and Austrian invasions, then from the broader currents of European philosophy, and in turn contributed to their growth. Modern philosophy in theYugoslavterritories started with the formation ofUniversity of Belgradein the early 19th century as a liberal court philosophy, replicating theories ofJohn Stuart Mill,Herbert Spencerand otherWestern philosophers. They wrote mostly textbook theories about broader subjects such as logic, psychology and pedagogy and the most prominent figure of this period wasAlimpije Vasiljević. At the end of 19th century, this school was surpassed in popularity byBranislav Petronijević, leading philosopher of theKingdom of Yugoslavia. His idealist rationalist metaphysical system was known as \"hypermetaphysics\", with his three principal philosophical works beingPrincipi Metafizike(Principles of Metaphysics),O Vrednosti života(On the Value of Life) andIstorija novije filozofije(History of Contemporary Philosophy). Petronijević had many students and followers, among othersKsenija Atanasijević, the first major female Yugoslav philosopher, who slid into more mystic theories of newscholasticism. After the6 January Dictatorship, Yugoslav philosophy as a whole moved towards the political right, with the thinkers such asVladimir Dvornikovićobtaining positions in the government. Dvorniković was a prominent advocate of Yugoslavintegral nationalismand his most famous work wasKarakterologija Jugoslovena(Characterology of the Yugoslavs). There was also a strong irrationalist current withAlbert Bazala, who became rector ofUniversity of Zagrebin 1932. At the time, universities were under strong religious influence and the most prominent thinker of this school was the SlovenianAleš Ušeničnik, a philosopher ofneo-Thomism. In parallel, the social democratic movement had its own prominent theoreticians such asDimitrije TucovićandSima Marković, who was later killed in theGreat Purge. AfterWorld War II, socialists took power and rejected all former philosophy as idealistic and bourgeois.Dialectical materialismwas introduced, with revolutionary philosophers such asBoris ZiherlorDušan Nedeljković. This theory later evolved towardsMarxist humanismwith thePraxis School, which originated inZagrebandBelgradeduring the 1960s.Prominent figures among the school's founders includeGajo Petrović,Milan Kangrga,Mihailo MarkovićandPredrag Vranicki. From 1964 to 1974 they published the journalPraxis, which was renowned as one of the leading international journals in Marxist theory. Apart from Praxis, Yugoslav philosophy was especially strong inSR Sloveniawith the MarxistBožidar Debenjakandphenomenologicalschool ofTine Hribar. In the seventies, theLjubljana Lacanian Schoolwith the journalProblemi(Problems) was founded by young followers of the theories of the FrenchpsychoanalystJacques Lacan. A specific feature of the Ljubljana School was to connect the Marxist and Hegelian traditions with Lacanian psychoanalysis andstructuralism, with its most famous philosopher beingSlavoj Žižek. After thebreakup of Yugoslavia, newly formed countries continued their philosophical tradition in various directions, but mostly abandoned the principles of Marxism.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Yugoslav_philosophy", "https://en.wikipedia.org/wiki/Yugoslav_philosophy", "https://en.wikipedia.org/wiki/Yugoslav_philosophy", "https://en.wikipedia.org/wiki/Yugoslavs", "https://en.wikipedia.org/wiki/Flag_of_Yugoslavia", "https://en.wikipedia.org/wiki/Yugoslav_Canadians", "https://en.wikipedia.org/wiki/Yugoslavs_in_Serbia", "https://en.wikipedia.org/wiki/Yugoslav_Americans"]},
{"id": "431bd61eebf6", "url": "https://en.wikipedia.org/wiki/Russian_philosophy", "title": "Russian philosophy", "headings": ["Contents", "Historiography", "Main schools and directions", "Origins of Russian philosophy", "Philosophical thought in the Old Russian state (11th–13th centuries)", "Philosophical problems in the works of Russian scribes of the 14th–17th centuries", "Russian philosophy of the 18th century", "Russian philosophy of the 19th century", "Philosophy of all–unity of Vladimir Solovyov", "Philosophy of Leo Tolstoy", "Positivism", "Russian philosophy of the 20th century", "Existentialism of Nikolai Berdyaev", "Eurasianism", "Soviet philosophy", "Post–Soviet philosophy", "School of Georgy Shchedrovitsky", "See also", "References", "Sources", "External links"], "content": " Russian philosophyis the collective school or heritage of philosophy among Russian thinkers. Inhistoriography, there is no consensus regarding the origins of Russian philosophy, itsperiodizationand its cultural significance. The historical boundaries of Russian philosophy directly depend on the philosophical content that a specific researcher sees in Russian intellectual history. Traditionally, since the 19th century, the \"pre–Petrine\" or \"Old Russian\" and \"post–Petrine\" or \"Enlightenment\" stages of the development of Russian philosophy have been distinguished. In modern historiography, a third, \"Soviet\" period is also distinguished. Starting from religious thought, Archimandrite Gabriel, the first historian of Russian philosophy, saw its origins in the didactic \"Teachings\" ofVladimir Monomakh, thereby directly elevating Russian philosophy to traditional ancient Russian scribes. A number of major historians of Russian philosophy, however, tend to view philosophy in stricter boundaries: Russian philosophy is taking shape as an independent phenomenon, thus, in the era ofPeter the Great. The reduction of Russian philosophy to the enlightenment paradigm has been repeatedly criticized in view of the reductivization of the Russian philosophical heritage of previous eras. Discussions about the origins and boundaries of Russian philosophy do not subside to this day, although in most modern historical and philosophical essays, Russian philosophy is considered as a phenomenon of Russian intellectual culture rooted in the theological and didactic literature ofAncient Russia(Kliment Smolyatich,Kirik Novgorodets,Kirill Turovskyand others are among the first Russian philosophers). According toNikolay Lossky, the characteristic features of Russian philosophy are:cosmism,sophiology (teachings about Sophia),sobornost,metaphysics, religiosity, intuitionism,positivism, realism (ontologism). Semyon Frankcharacterized Russian philosophy by pointing out the inseparability of rational and moral meanings inherent in Russian thinkers, inherent in the wordpravda.Nikolai Berdyaevalso pointed out the striving characteristic of Russian thought \"to develop for oneself a totalitarian, holistic world outlook, in whichpravda–truthwill be combined withpravda–justice\". According to Professor Andrei Sukhov, no other philosophy contains so many reflections on the fate of country. As noted by the researcher Maria Varlamova, in Russia, Plato is a much more significant figure than Aristotle. Professor Nina Dmitrieva notes that \"Russian philosophical thought until the turn of the 19th–20th centuries developed mainly in the mainstream of literary criticism and journalism, with a primary focus on topical socio–political and ethical issues. And in the last decades of the 19th century, mystical and religious thinkers began to set the tone in academic and so–called free philosophy\". As Professor, Doctor of Historical Sciences Natalia Vorobyova notes in her work \"History of Russian Spiritual Culture\", modern researchers postulate the absence of an original national Slavic–Russian philosophical system, considering the system of Russian philosophy as a phenomenon ofModern period. As AcademicianDmitry Likhachevwrites: \"For many centuries Russian philosophy was closely connected with literature and poetry. Therefore, it should be studied in connection with Lomonosov and Derzhavin, Tyutchev and Vladimir Solovyov, Dostoevsky, Tolstoy, Chernyshevsky...\". The main directions of Russian philosophy include: The existence of ancient Russian philosophy is debatable. Some researchers, like Archpriest Dmitry Leskin, recognized the fact of its existence,others denied, claiming only the presence of philosophical ideas and problems in ancient Russian literature.The philosophical thoughts of the \"Hellenic sages\" fell into the Old Russian literature from translated sources. Within the framework of the religious worldview, the question of human nature (Svyatoslav's Izbornik,Kirill Turovsky,Nil Sorsky), state power (Joseph Volotsky) and universal values («The Word of Law and Grace» by MetropolitanHilarion, who is sometimes called \"the first ancient Russian philosopher\") was resolved.The ethical ideal is contained in the Teachings of Vladimir Monomakh. In addition to historiosophy (ethnogenesis as a punishment for the Tower of Babel), The Tale of Bygone Years also contains elements of religious philosophy: the concepts of property (hypostasis), flesh (matter), vision (form), desire and dream (imagination) are being developed. Also in the ancient Russian state, translated literature of Byzantine philosophical monuments was widely circulated, the most important of which was the collection of sayings \"The Bee\" and \"Dioptra\" by Philip the Hermit. Among the most famous authors who left philosophically significant works areVladimir Monomakh,Theodosius Pechersky,Klim Smolyatich,Kirik Novgorodets,Kirill Turovskyand Daniil Zatochnik. A wide controversy unfolded between the followers of Joseph from Volokolamsk (in the world – Ivan Sanin), nicknamed \"Josephites\", and Nil Sorsky (in the world – Nikolai Maikov), nicknamed the \"Trans–Volga elders\", or \"non–possessors\". The central question that worried the polemicists was related to the role of the church in the state and the significance of its land holdings and decoration. The problem of decorating churches and land was not directly related to philosophy, however, it served as an impetus for considering the problems of church possessions in the plane of biblical and patristic literature (in the polemics,Gregory SinaitandSimeon the New Theologian,John Climacus,Isaac the Syrian,John Cassian the Roman,Nil of Sinai,Basil the Greatand others are cited) and ultimately led to the question of the meaning of the connection between faith and power, which was resolved on Russian soil in the idea of \"charisma\" of the ruler. This philosophical problem was further developed in the epistolary legacy of Ivan the Terrible and Prince Kurbsky, in \"The Lay of Voivode Dracula\" byFyodor Kuritsyn, as well as in the message of Ivan Peresvetov. In addition, Joseph Volotsky and Nil Sorsky went down in history in the course of the struggle against the heresy of the Judaizers and strigolniki, which spread in the Novgorod land (first of all, in Novgorod itself and in Pskov). With the spread of the heresy of the Judaizers in the Russian intellectual environment, works of pseudo–Aristotle began to appear. The position of the strigolniks in their spirit was close to the Hussites. In this regard, there is a need not only for the arguments of patristic literature, but also for monuments of Latin scholastic scholarship, which Dmitry Gerasimov, also known as Dmitry Scholastic, a member of the Gennadiy circle, began to translate. It is noteworthy that the reaction to heretics on the part of Joseph Volotsky and Nil Sorsky also differed radically: Joseph Volotsky insisted on the destruction of heretics, according to Joseph, it is necessary to \"inflict wounds on them, thereby consecrating his hand\", while Nil Sorsky and Vassian Patrikeev insisted on the need exhortation, fighting with the word, not with the sword. The controversy between the Josephites and the non–possessors became an important example of the tension between the authorities and free–thinkers in the Russian state, which subsequently reappeared again and again in the history of Russian philosophy, which was repeatedly banned. An important role in the formation of Russian philosophy was played by the Ostrog School, founded by PrinceKonstantin Ostrozhskyin his domain in Ostrog to strengthen the Orthodox faith and improve the quality of the work of the Orthodox clergy in polemics with the Uniates. In the Ostrog School, much attention was paid to the study of languages: Ancient Greek, Latin and Old Church Slavonic. There was a printing house at the school, in whichIvan FedorovandPyotr Timofeevserved. PrinceAndrey Kurbskyalso took part in the development of the school. Along with theological literature, scholastic philosophy was studied at the Ostrog School. So Vitaly Dubensky compiled the florilegia \"Dioptra, or the Mirror and the Reflection of Human Life in the Next World\" in the Univ Monastery. Among the graduates of the academy were: the author of \"Grammar\"Melety Smotritsky(son of the first rector), archimandrite of the Kiev–Pechersk Lavra, the founder of the Lavra Printing HouseYelisey Pletenetsky, polemicist writer, philosopher, author of \"Apocrisis\" Christopher Filalet and many others. The activities of the Ostrog School predetermined the orientation of philosophical and theological courses at the Kyiv–Mohyla and Moscow Slavic–Greek–Latin academies. The Rtishchevsky School (also – the Rtishchevsky Brotherhood, the Andreevsky School) was the first educational institution inRussia, founded as a court circle during the reign ofAlexei Mikhailovich. Education in the Rtishchevsky Brotherhood was carried out on the model of European institutions of higher education. The school arose on the initiative ofFyodor Rtishchev, operated in Moscow since 1648 and was located in the Andreevsky Monastery, built at the expense of Rtishchev at the foot of the Sparrow Hills. The Rtischevskaya School was the first in Moscow to officially include courses in philosophy andrhetoric. The head of the Rtishchevskaya School was appointed a native of theKiev Fraternal School, a participant in book research in Russia, a philosopher, theologian and translatorEpiphany Slavinetsky. The most important figure within the Moscow Slavic–Greek–Latin Academy wasSimeon of Polotsk. Simeon Polotsky was a figure of Russian culture, spiritual writer, theologian, poet, playwright, translator. He was the mentor of the children of the Russian TsarAlexei MikhailovichfromMaria Miloslavskaya:Ivan,SophiaandFedor. Founder of the School at the Zaikonospassky Monastery, teacher of Sylvester Medvedev. Other important figures include Sylvester Medvedev and the Likhuda Brothers, Feofilakt Lopatinsky, Pallady Rogovsky. The most important figure in the framework of philosophy at the Smolensk Collegium was Gedeon Vishnevsky. Bishop Gedeon Vishnevsky was the bishop of theRussian Orthodox Church, bishop ofSmolensk and Dorogobuzh. The reforms of Peter I contributed to the limitation of the power of the church and the penetration of Western philosophy into Russia through the emerging system of higher education. The most popular Western innovation wasdeism, whose adherents were such key thinkers of the Russian Enlightenment asMikhail LomonosovandAlexander Radishchev. It was at this moment thatatomismandsensationalismfell on Russian soil. In practice, the ideas of deism were expressed inanti–clericalismand the substantiation of the subordination of spiritual power to secular ones, for which the learned squad of Peter I advocated. Also, the philosophy of Russian Enlightenment adapted many of the ideas ofFreemasonry(Nikolay Novikov).Grigory Teplovcompiled one of the first Russian philosophical dictionaries. Important Russian philosophers of the 18th century wereFeofan ProkopovichandStefan Yavorsky, Mikhail Lomonosov,Grigory Skovoroda, Russian Martinists, and \"Inner Christians\". The central works of Russian philosophers of the 18th century were \"A Conversation of Two Friends\" by Vasily Tatishchev, \"Children's Philosophy\" by Andrei Bolotov, \"Knowledge Concerning Philosophy in General\" by Grigory Teplov and \"About Man, His Mortality and Immortality\" by Alexander Radishchev. Schellingism appeared in Russia at the beginning of the 19th century. In 1823, theSociety of Wisdomis created. Contemporaries calledVladimir Solovyov(1853–1900) the central figure of Russian philosophy. He criticized the philosophy that existed before him for abstractness and did not accept such extreme manifestations of it asempiricismandrationalism. He put forward the idea of positive total–unity, headed by God. He saw good as a manifestation of will, truth as a manifestation of reason, beauty as a manifestation of feeling. The philosopher saw the entire material world as controlled by Him, while man in his philosophy acted as a connecting link between God and nature, created by Him, but not perfect. A person must bring it to perfection (up to spiritualization), this is themeaning of his life(movement to theAbsolute). Since a person occupies an intermediate position between God and nature, his moral activity is manifested in love for another person, for nature and for God.The concept ofall-unitywas also used bySemyon FrankandLev Karsavin. One of the central places in Russian philosophy is occupied byLeo Tolstoy(1828–1910). His philosophy was influenced by the views ofKant,Rousseau,Arthur Schopenhauer. Tolstoy's views were shared by many of his contemporaries (\"Tolstoyans\") and followers.Gandhihimself considered him to be his teacher. In his philosophy, Tolstoy recognizes the value of the moral component of religion, but denies all its theological aspects (\"true religion\"). The goal ofcognitionis the search for themeaning of lifeby a person. Well-known philosophers of the early 20th century—the Golden Age of Russian philosophy—includeNikolai Berdyaev,Sergei Bulgakov,Pavel Florensky,Semyon Frank,Nikolay Lossky,Vasily Rozanov,Lev Shestov, andGustav Shpet, among others. At the beginning of the 20th century, the largest Russian philosophers, under the influence of social and political changes in the country, published three philosophical collections, which received a wide public response and evaluation from various political figures of that time. These compilations: Russian religious philosophy at the turn of the 19th and 20th centuries became a kind of synthesis between Slavophilism and Westernism.Following Chaadaev, projects for the construction of the kingdom of God on Earth were preserved, which acquired the features ofSophiology(Vladimir Solovyov,Sergei Bulgakov) andRose of the World(Daniil Andreev). Religion and spiritual and moral regeneration were thought to be an important part of building a just society. In part, the ideas of sophiology are inherited byBolshevism(communism) and cosmism (noosphere). In the 20th century, in connection with the dramatic events of Russian history, there is a division of Russian philosophy intoRussian Marxismand the philosophy of the Russian diaspora. Some of the philosophers were exiled abroad, but some remained in Soviet Russia:Pavel Florenskyand his studentAlexei Losev. Through the latter, the traditions of Russian philosophy were revived in Soviet Russia, sinceSergey AverintsevandVladimir Bibikhinreceived spiritual succession from him. The most important place in Russian philosophical thought in the first half of the 20th century is occupied by the work ofNikolai Berdyaev(1874–1948), the most prominent representative of Russianexistentialism. At the beginning of his journey, Berdyaev adhered to Marxist views, participating in anti–government demonstrations and conducting correspondence with one of the leaders of the German Social Democracy,Karl Kautsky. However, the young philosopher and thinker soon abandoned Marxism, becoming one of the most detailed critics of this doctrine. Berdyaev calls the main opposition, which should develop in the philosopher's worldview, the opposition between spirit and nature. Spirit is a subject, life, creativity and freedom, nature is an object, a thing, necessity and immobility. Knowledge of the spirit is achieved through experience. God is spirit. Those of people who have had spiritual experience and experience of creativity do not need rational proof of the existence of God. At its core, the deity is irrational and super–rational. Developing in his teaching the theme of creativity and spirituality, Berdyaev pays great attention to the idea of freedom, which reveals the connection between God, the Universe and man. He distinguishes three types of freedom: primary irrational freedom, that is, arbitrariness; rational freedom, that is, the fulfillment of a moral duty; and, finally, freedom imbued with the love of God. He argues that freedom is not created by God, and therefore God cannot be held responsible for the freedom that created evil. Primary freedom conditions the possibility of both good and evil. Thus, even God cannot foresee the actions of a person with free will, he acts as an assistant so that the will of a person becomes good. Existential views in Berdyaev's work are manifested in his thoughts on the problem of personality. According to Berdyaev, personality is not a part of the cosmos, on the contrary, the cosmos is a part of the human personality. Personality is not a substance, it is a creative act, it is unchanging in the process of change. A person who manifests creative activity thereby finds a deity in himself. Berdyaev is trying to formulate the so–called \"Russian Idea\", which expresses the character and vocation of the Russian people. \"The Russian people are a highly polarized people, they are a combination of opposites\", the thinker believes. The Russian people combine cruelty and humanity, individualism and faceless collectivism, the search for God and militant atheism, humility and arrogance, slavery and rebellion. In history, such features of a national character as obedience to power, martyrdom, sacrifice and a tendency to revelry and anarchy were manifested. Speaking about the events of 1917, Berdyaev emphasizes that the liberal–bourgeois revolution in Russia was a utopia. The revolution in Russia could only be socialist. According to the philosopher, the Russian idea is rooted in the idea of the brotherhood of people and peoples, for the Russian people in their spiritual structure is religious, open and communitarian. Nevertheless, Berdyaev reminds, one should not forget about the polarization of the nature of the Russian man, capable of compassion and the possibility of bitterness, striving for freedom, but sometimes prone to slavery. Among the main works of Berdyaev \"Philosophy of Freedom\" (1911), \"The Meaning of Creativity. The Experience of Human Justification\" (1916), \"The Philosophy of Inequality. Letters to Enemies in Social Philosophy\" (1923), \"The Origins and Meaning of Russian Communism\" (1937), \"Russian Idea. The Main Problems of Russian Thought in the 19th and 20th Centuries\" (1946). Eurasianismis a philosophical and political movement advocating the rejection of Russia's European integration in favor of integration with Central Asian countries. The Eurasian movement, which emerged among the Russian emigration in the 1920s and 1930s, gained popularity by the beginning of the 21st century. The ideas of Eurasianism, practically forgotten by the second half of the 20th century, were largely revived by the historian and geographer Lev Gumilyov and became widespread by the beginning of the 21st century.Gumilyovin a number of books – \"Ethnogenesis and the Biosphere of the Earth\", \"Millennium around the Caspian\" and \"From Rus to Russia\" – using the Eurasian concept and supplementing it with his own developments, forms his concept of ethnogenesis, leading him to a number of conclusions, among which the largest the following are important: firstly, any ethnos is a community of people united by a certain stereotype of behavior; secondly, an ethnos and its stereotype of behavior are formed in specific geographic and climatic conditions and remain stable for a long period of time, comparable to the existence of an ethnos; thirdly, superethnic wholes are formed on the basis of a generalized stereotype of behavior shared by representatives of different ethnic groups of a single super–ethnic group; fourthly, the stereotype of the behavior of a superethnic integrity is a certain way of being that meets certain conditions of existence. Even before the beginning of theOctober Revolution, the philosophy ofMarxismdeveloped in Russia (Georgy Plekhanov,Vladimir Lenin). The main question in Soviet philosophy was the question of the relationship between matter and consciousness, and the main method wasdialectics, in which three laws were distinguished. Structurally, philosophy was divided into dialectical andhistorical materialism, that is, the philosophy of nature and the philosophy of history. Nature, interpreted asmatterand objective reality, was considered eternal and infinite in space and time.Consciousnesswas interpreted as \"a property of highly organized matter\". The theory of knowledge was dominated by the Leninist theory of reflection. The historical process was perceived through the prism of a subordinate relationship between thebasis(economy) andsuperstructure(culture), which passed through successively replacing formations: theprimitive communal system, theslave system,feudalism,capitalismandsocialism(as the first stage of communism). In the Soviet years, discussions about the nature of the ideal gained popularity (only \"in the head\" or not? David Dubrovsky –Evald Ilyenkov), disputes about the nature of information. Mikhail Bakhtindevelops the ideas of polyphony, dialogue and carnivalism. Such philosophers asAleksey Losev,Sergey Averintsev,Vladimir Bibikhinenjoyed great popularity in the late Soviet period. In the late Soviet and post–Soviet period, the ideas of theMoscow–Tartu Semiotic Schoolwere widely recognized. After the lifting ofideological prohibitionsdue to the collapse of theSoviet Union, Russian philosophy found itself in a situation of uncertainty. While maintaining the existing structure of philosophical education, the process of mastering that part of the philosophical heritage, from which Soviet philosophy was artificially isolated, was launched. New disciplines of the philosophical cycle arose and began to develop –political science,cultural studies,religious studies,philosophical anthropology. Attempts were made to resume the interrupted philosophical tradition, return to the legacy of Russian religious philosophy, but these attempts (according toYuri Semyonov, Daniil Danin, Mikhail Chulaki and many others)proved to be a failure. Currently, there are several organizations that declare their continuity to the ideas of the Eurasians. The main ones among them are theEurasian Youth Union, theInternational Eurasian Movementof the main ideologist of neo–Eurasianism,Alexander Dugin, and a number of other organizations. An extremely original and extraordinarycontribution to the development of Russian philosophy belongs toGeorgy Shchedrovitskyand the methodological school he created, which was subsequently formulated accordingly (\"the third Russian philosophy is actually methodology\").The philosophical and methodological system, created by Shchedrovitsky and his school (also known as the Moscow Methodological Circle), offers original ways out of the problematicsituation of postmodernism(\"in the opposition \"modernism – postmodernism\", the system of thought–activity methodology can be positioned with a number of reservations and conditions\").It is indicative that the initially semi–underground Moscow methodological circle forms, forges and polishes the concepts demanded by contemporary period, at a time when the conceptual apparatus of the so–called \"post–non–classical\" (post–modernist) philosophy has already exhausted its capabilities.", "combined_text": "Russian philosophy Contents Historiography Main schools and directions Origins of Russian philosophy Philosophical thought in the Old Russian state (11th–13th centuries) Philosophical problems in the works of Russian scribes of the 14th–17th centuries Russian philosophy of the 18th century Russian philosophy of the 19th century Philosophy of all–unity of Vladimir Solovyov Philosophy of Leo Tolstoy Positivism Russian philosophy of the 20th century Existentialism of Nikolai Berdyaev Eurasianism Soviet philosophy Post–Soviet philosophy School of Georgy Shchedrovitsky See also References Sources External links  Russian philosophyis the collective school or heritage of philosophy among Russian thinkers. Inhistoriography, there is no consensus regarding the origins of Russian philosophy, itsperiodizationand its cultural significance. The historical boundaries of Russian philosophy directly depend on the philosophical content that a specific researcher sees in Russian intellectual history. Traditionally, since the 19th century, the \"pre–Petrine\" or \"Old Russian\" and \"post–Petrine\" or \"Enlightenment\" stages of the development of Russian philosophy have been distinguished. In modern historiography, a third, \"Soviet\" period is also distinguished. Starting from religious thought, Archimandrite Gabriel, the first historian of Russian philosophy, saw its origins in the didactic \"Teachings\" ofVladimir Monomakh, thereby directly elevating Russian philosophy to traditional ancient Russian scribes. A number of major historians of Russian philosophy, however, tend to view philosophy in stricter boundaries: Russian philosophy is taking shape as an independent phenomenon, thus, in the era ofPeter the Great. The reduction of Russian philosophy to the enlightenment paradigm has been repeatedly criticized in view of the reductivization of the Russian philosophical heritage of previous eras. Discussions about the origins and boundaries of Russian philosophy do not subside to this day, although in most modern historical and philosophical essays, Russian philosophy is considered as a phenomenon of Russian intellectual culture rooted in the theological and didactic literature ofAncient Russia(Kliment Smolyatich,Kirik Novgorodets,Kirill Turovskyand others are among the first Russian philosophers). According toNikolay Lossky, the characteristic features of Russian philosophy are:cosmism,sophiology (teachings about Sophia),sobornost,metaphysics, religiosity, intuitionism,positivism, realism (ontologism). Semyon Frankcharacterized Russian philosophy by pointing out the inseparability of rational and moral meanings inherent in Russian thinkers, inherent in the wordpravda.Nikolai Berdyaevalso pointed out the striving characteristic of Russian thought \"to develop for oneself a totalitarian, holistic world outlook, in whichpravda–truthwill be combined withpravda–justice\". According to Professor Andrei Sukhov, no other philosophy contains so many reflections on the fate of country. As noted by the researcher Maria Varlamova, in Russia, Plato is a much more significant figure than Aristotle. Professor Nina Dmitrieva notes that \"Russian philosophical thought until the turn of the 19th–20th centuries developed mainly in the mainstream of literary criticism and journalism, with a primary focus on topical socio–political and ethical issues. And in the last decades of the 19th century, mystical and religious thinkers began to set the tone in academic and so–called free philosophy\". As Professor, Doctor of Historical Sciences Natalia Vorobyova notes in her work \"History of Russian Spiritual Culture\", modern researchers postulate the absence of an original national Slavic–Russian philosophical system, considering the system of Russian philosophy as a phenomenon ofModern period. As AcademicianDmitry Likhachevwrites: \"For many centuries Russian philosophy was closely connected with literature and poetry. Therefore, it should be studied in connection with Lomonosov and Derzhavin, Tyutchev and Vladimir Solovyov, Dostoevsky, Tolstoy, Chernyshevsky...\". The main directions of Russian philosophy include: The existence of ancient Russian philosophy is debatable. Some researchers, like Archpriest Dmitry Leskin, recognized the fact of its existence,others denied, claiming only the presence of philosophical ideas and problems in ancient Russian literature.The philosophical thoughts of the \"Hellenic sages\" fell into the Old Russian literature from translated sources. Within the framework of the religious worldview, the question of human nature (Svyatoslav's Izbornik,Kirill Turovsky,Nil Sorsky), state power (Joseph Volotsky) and universal values («The Word of Law and Grace» by MetropolitanHilarion, who is sometimes called \"the first ancient Russian philosopher\") was resolved.The ethical ideal is contained in the Teachings of Vladimir Monomakh. In addition to historiosophy (ethnogenesis as a punishment for the Tower of Babel), The Tale of Bygone Years also contains elements of religious philosophy: the concepts of property (hypostasis), flesh (matter), vision (form), desire and dream (imagination) are being developed. Also in the ancient Russian state, translated literature of Byzantine philosophical monuments was widely circulated, the most important of which was the collection of sayings \"The Bee\" and \"Dioptra\" by Philip the Hermit. Among the most famous authors who left philosophically significant works areVladimir Monomakh,Theodosius Pechersky,Klim Smolyatich,Kirik Novgorodets,Kirill Turovskyand Daniil Zatochnik. A wide controversy unfolded between the followers of Joseph from Volokolamsk (in the world – Ivan Sanin), nicknamed \"Josephites\", and Nil Sorsky (in the world – Nikolai Maikov), nicknamed the \"Trans–Volga elders\", or \"non–possessors\". The central question that worried the polemicists was related to the role of the church in the state and the significance of its land holdings and decoration. The problem of decorating churches and land was not directly related to philosophy, however, it served as an impetus for considering the problems of church possessions in the plane of biblical and patristic literature (in the polemics,Gregory SinaitandSimeon the New Theologian,John Climacus,Isaac the Syrian,John Cassian the Roman,Nil of Sinai,Basil the Greatand others are cited) and ultimately led to the question of the meaning of the connection between faith and power, which was resolved on Russian soil in the idea of \"charisma\" of the ruler. This philosophical problem was further developed in the epistolary legacy of Ivan the Terrible and Prince Kurbsky, in \"The Lay of Voivode Dracula\" byFyodor Kuritsyn, as well as in the message of Ivan Peresvetov. In addition, Joseph Volotsky and Nil Sorsky went down in history in the course of the struggle against the heresy of the Judaizers and strigolniki, which spread in the Novgorod land (first of all, in Novgorod itself and in Pskov). With the spread of the heresy of the Judaizers in the Russian intellectual environment, works of pseudo–Aristotle began to appear. The position of the strigolniks in their spirit was close to the Hussites. In this regard, there is a need not only for the arguments of patristic literature, but also for monuments of Latin scholastic scholarship, which Dmitry Gerasimov, also known as Dmitry Scholastic, a member of the Gennadiy circle, began to translate. It is noteworthy that the reaction to heretics on the part of Joseph Volotsky and Nil Sorsky also differed radically: Joseph Volotsky insisted on the destruction of heretics, according to Joseph, it is necessary to \"inflict wounds on them, thereby consecrating his hand\", while Nil Sorsky and Vassian Patrikeev insisted on the need exhortation, fighting with the word, not with the sword. The controversy between the Josephites and the non–possessors became an important example of the tension between the authorities and free–thinkers in the Russian state, which subsequently reappeared again and again in the history of Russian philosophy, which was repeatedly banned. An important role in the formation of Russian philosophy was played by the Ostrog School, founded by PrinceKonstantin Ostrozhskyin his domain in Ostrog to strengthen the Orthodox faith and improve the quality of the work of the Orthodox clergy in polemics with the Uniates. In the Ostrog School, much attention was paid to the study of languages: Ancient Greek, Latin and Old Church Slavonic. There was a printing house at the school, in whichIvan FedorovandPyotr Timofeevserved. PrinceAndrey Kurbskyalso took part in the development of the school. Along with theological literature, scholastic philosophy was studied at the Ostrog School. So Vitaly Dubensky compiled the florilegia \"Dioptra, or the Mirror and the Reflection of Human Life in the Next World\" in the Univ Monastery. Among the graduates of the academy were: the author of \"Grammar\"Melety Smotritsky(son of the first rector), archimandrite of the Kiev–Pechersk Lavra, the founder of the Lavra Printing HouseYelisey Pletenetsky, polemicist writer, philosopher, author of \"Apocrisis\" Christopher Filalet and many others. The activities of the Ostrog School predetermined the orientation of philosophical and theological courses at the Kyiv–Mohyla and Moscow Slavic–Greek–Latin academies. The Rtishchevsky School (also – the Rtishchevsky Brotherhood, the Andreevsky School) was the first educational institution inRussia, founded as a court circle during the reign ofAlexei Mikhailovich. Education in the Rtishchevsky Brotherhood was carried out on the model of European institutions of higher education. The school arose on the initiative ofFyodor Rtishchev, operated in Moscow since 1648 and was located in the Andreevsky Monastery, built at the expense of Rtishchev at the foot of the Sparrow Hills. The Rtischevskaya School was the first in Moscow to officially include courses in philosophy andrhetoric. The head of the Rtishchevskaya School was appointed a native of theKiev Fraternal School, a participant in book research in Russia, a philosopher, theologian and translatorEpiphany Slavinetsky. The most important figure within the Moscow Slavic–Greek–Latin Academy wasSimeon of Polotsk. Simeon Polotsky was a figure of Russian culture, spiritual writer, theologian, poet, playwright, translator. He was the mentor of the children of the Russian TsarAlexei MikhailovichfromMaria Miloslavskaya:Ivan,SophiaandFedor. Founder of the School at the Zaikonospassky Monastery, teacher of Sylvester Medvedev. Other important figures include Sylvester Medvedev and the Likhuda Brothers, Feofilakt Lopatinsky, Pallady Rogovsky. The most important figure in the framework of philosophy at the Smolensk Collegium was Gedeon Vishnevsky. Bishop Gedeon Vishnevsky was the bishop of theRussian Orthodox Church, bishop ofSmolensk and Dorogobuzh. The reforms of Peter I contributed to the limitation of the power of the church and the penetration of Western philosophy into Russia through the emerging system of higher education. The most popular Western innovation wasdeism, whose adherents were such key thinkers of the Russian Enlightenment asMikhail LomonosovandAlexander Radishchev. It was at this moment thatatomismandsensationalismfell on Russian soil. In practice, the ideas of deism were expressed inanti–clericalismand the substantiation of the subordination of spiritual power to secular ones, for which the learned squad of Peter I advocated. Also, the philosophy of Russian Enlightenment adapted many of the ideas ofFreemasonry(Nikolay Novikov).Grigory Teplovcompiled one of the first Russian philosophical dictionaries. Important Russian philosophers of the 18th century wereFeofan ProkopovichandStefan Yavorsky, Mikhail Lomonosov,Grigory Skovoroda, Russian Martinists, and \"Inner Christians\". The central works of Russian philosophers of the 18th century were \"A Conversation of Two Friends\" by Vasily Tatishchev, \"Children's Philosophy\" by Andrei Bolotov, \"Knowledge Concerning Philosophy in General\" by Grigory Teplov and \"About Man, His Mortality and Immortality\" by Alexander Radishchev. Schellingism appeared in Russia at the beginning of the 19th century. In 1823, theSociety of Wisdomis created. Contemporaries calledVladimir Solovyov(1853–1900) the central figure of Russian philosophy. He criticized the philosophy that existed before him for abstractness and did not accept such extreme manifestations of it asempiricismandrationalism. He put forward the idea of positive total–unity, headed by God. He saw good as a manifestation of will, truth as a manifestation of reason, beauty as a manifestation of feeling. The philosopher saw the entire material world as controlled by Him, while man in his philosophy acted as a connecting link between God and nature, created by Him, but not perfect. A person must bring it to perfection (up to spiritualization), this is themeaning of his life(movement to theAbsolute). Since a person occupies an intermediate position between God and nature, his moral activity is manifested in love for another person, for nature and for God.The concept ofall-unitywas also used bySemyon FrankandLev Karsavin. One of the central places in Russian philosophy is occupied byLeo Tolstoy(1828–1910). His philosophy was influenced by the views ofKant,Rousseau,Arthur Schopenhauer. Tolstoy's views were shared by many of his contemporaries (\"Tolstoyans\") and followers.Gandhihimself considered him to be his teacher. In his philosophy, Tolstoy recognizes the value of the moral component of religion, but denies all its theological aspects (\"true religion\"). The goal ofcognitionis the search for themeaning of lifeby a person. Well-known philosophers of the early 20th century—the Golden Age of Russian philosophy—includeNikolai Berdyaev,Sergei Bulgakov,Pavel Florensky,Semyon Frank,Nikolay Lossky,Vasily Rozanov,Lev Shestov, andGustav Shpet, among others. At the beginning of the 20th century, the largest Russian philosophers, under the influence of social and political changes in the country, published three philosophical collections, which received a wide public response and evaluation from various political figures of that time. These compilations: Russian religious philosophy at the turn of the 19th and 20th centuries became a kind of synthesis between Slavophilism and Westernism.Following Chaadaev, projects for the construction of the kingdom of God on Earth were preserved, which acquired the features ofSophiology(Vladimir Solovyov,Sergei Bulgakov) andRose of the World(Daniil Andreev). Religion and spiritual and moral regeneration were thought to be an important part of building a just society. In part, the ideas of sophiology are inherited byBolshevism(communism) and cosmism (noosphere). In the 20th century, in connection with the dramatic events of Russian history, there is a division of Russian philosophy intoRussian Marxismand the philosophy of the Russian diaspora. Some of the philosophers were exiled abroad, but some remained in Soviet Russia:Pavel Florenskyand his studentAlexei Losev. Through the latter, the traditions of Russian philosophy were revived in Soviet Russia, sinceSergey AverintsevandVladimir Bibikhinreceived spiritual succession from him. The most important place in Russian philosophical thought in the first half of the 20th century is occupied by the work ofNikolai Berdyaev(1874–1948), the most prominent representative of Russianexistentialism. At the beginning of his journey, Berdyaev adhered to Marxist views, participating in anti–government demonstrations and conducting correspondence with one of the leaders of the German Social Democracy,Karl Kautsky. However, the young philosopher and thinker soon abandoned Marxism, becoming one of the most detailed critics of this doctrine. Berdyaev calls the main opposition, which should develop in the philosopher's worldview, the opposition between spirit and nature. Spirit is a subject, life, creativity and freedom, nature is an object, a thing, necessity and immobility. Knowledge of the spirit is achieved through experience. God is spirit. Those of people who have had spiritual experience and experience of creativity do not need rational proof of the existence of God. At its core, the deity is irrational and super–rational. Developing in his teaching the theme of creativity and spirituality, Berdyaev pays great attention to the idea of freedom, which reveals the connection between God, the Universe and man. He distinguishes three types of freedom: primary irrational freedom, that is, arbitrariness; rational freedom, that is, the fulfillment of a moral duty; and, finally, freedom imbued with the love of God. He argues that freedom is not created by God, and therefore God cannot be held responsible for the freedom that created evil. Primary freedom conditions the possibility of both good and evil. Thus, even God cannot foresee the actions of a person with free will, he acts as an assistant so that the will of a person becomes good. Existential views in Berdyaev's work are manifested in his thoughts on the problem of personality. According to Berdyaev, personality is not a part of the cosmos, on the contrary, the cosmos is a part of the human personality. Personality is not a substance, it is a creative act, it is unchanging in the process of change. A person who manifests creative activity thereby finds a deity in himself. Berdyaev is trying to formulate the so–called \"Russian Idea\", which expresses the character and vocation of the Russian people. \"The Russian people are a highly polarized people, they are a combination of opposites\", the thinker believes. The Russian people combine cruelty and humanity, individualism and faceless collectivism, the search for God and militant atheism, humility and arrogance, slavery and rebellion. In history, such features of a national character as obedience to power, martyrdom, sacrifice and a tendency to revelry and anarchy were manifested. Speaking about the events of 1917, Berdyaev emphasizes that the liberal–bourgeois revolution in Russia was a utopia. The revolution in Russia could only be socialist. According to the philosopher, the Russian idea is rooted in the idea of the brotherhood of people and peoples, for the Russian people in their spiritual structure is religious, open and communitarian. Nevertheless, Berdyaev reminds, one should not forget about the polarization of the nature of the Russian man, capable of compassion and the possibility of bitterness, striving for freedom, but sometimes prone to slavery. Among the main works of Berdyaev \"Philosophy of Freedom\" (1911), \"The Meaning of Creativity. The Experience of Human Justification\" (1916), \"The Philosophy of Inequality. Letters to Enemies in Social Philosophy\" (1923), \"The Origins and Meaning of Russian Communism\" (1937), \"Russian Idea. The Main Problems of Russian Thought in the 19th and 20th Centuries\" (1946). Eurasianismis a philosophical and political movement advocating the rejection of Russia's European integration in favor of integration with Central Asian countries. The Eurasian movement, which emerged among the Russian emigration in the 1920s and 1930s, gained popularity by the beginning of the 21st century. The ideas of Eurasianism, practically forgotten by the second half of the 20th century, were largely revived by the historian and geographer Lev Gumilyov and became widespread by the beginning of the 21st century.Gumilyovin a number of books – \"Ethnogenesis and the Biosphere of the Earth\", \"Millennium around the Caspian\" and \"From Rus to Russia\" – using the Eurasian concept and supplementing it with his own developments, forms his concept of ethnogenesis, leading him to a number of conclusions, among which the largest the following are important: firstly, any ethnos is a community of people united by a certain stereotype of behavior; secondly, an ethnos and its stereotype of behavior are formed in specific geographic and climatic conditions and remain stable for a long period of time, comparable to the existence of an ethnos; thirdly, superethnic wholes are formed on the basis of a generalized stereotype of behavior shared by representatives of different ethnic groups of a single super–ethnic group; fourthly, the stereotype of the behavior of a superethnic integrity is a certain way of being that meets certain conditions of existence. Even before the beginning of theOctober Revolution, the philosophy ofMarxismdeveloped in Russia (Georgy Plekhanov,Vladimir Lenin). The main question in Soviet philosophy was the question of the relationship between matter and consciousness, and the main method wasdialectics, in which three laws were distinguished. Structurally, philosophy was divided into dialectical andhistorical materialism, that is, the philosophy of nature and the philosophy of history. Nature, interpreted asmatterand objective reality, was considered eternal and infinite in space and time.Consciousnesswas interpreted as \"a property of highly organized matter\". The theory of knowledge was dominated by the Leninist theory of reflection. The historical process was perceived through the prism of a subordinate relationship between thebasis(economy) andsuperstructure(culture), which passed through successively replacing formations: theprimitive communal system, theslave system,feudalism,capitalismandsocialism(as the first stage of communism). In the Soviet years, discussions about the nature of the ideal gained popularity (only \"in the head\" or not? David Dubrovsky –Evald Ilyenkov), disputes about the nature of information. Mikhail Bakhtindevelops the ideas of polyphony, dialogue and carnivalism. Such philosophers asAleksey Losev,Sergey Averintsev,Vladimir Bibikhinenjoyed great popularity in the late Soviet period. In the late Soviet and post–Soviet period, the ideas of theMoscow–Tartu Semiotic Schoolwere widely recognized. After the lifting ofideological prohibitionsdue to the collapse of theSoviet Union, Russian philosophy found itself in a situation of uncertainty. While maintaining the existing structure of philosophical education, the process of mastering that part of the philosophical heritage, from which Soviet philosophy was artificially isolated, was launched. New disciplines of the philosophical cycle arose and began to develop –political science,cultural studies,religious studies,philosophical anthropology. Attempts were made to resume the interrupted philosophical tradition, return to the legacy of Russian religious philosophy, but these attempts (according toYuri Semyonov, Daniil Danin, Mikhail Chulaki and many others)proved to be a failure. Currently, there are several organizations that declare their continuity to the ideas of the Eurasians. The main ones among them are theEurasian Youth Union, theInternational Eurasian Movementof the main ideologist of neo–Eurasianism,Alexander Dugin, and a number of other organizations. An extremely original and extraordinarycontribution to the development of Russian philosophy belongs toGeorgy Shchedrovitskyand the methodological school he created, which was subsequently formulated accordingly (\"the third Russian philosophy is actually methodology\").The philosophical and methodological system, created by Shchedrovitsky and his school (also known as the Moscow Methodological Circle), offers original ways out of the problematicsituation of postmodernism(\"in the opposition \"modernism – postmodernism\", the system of thought–activity methodology can be positioned with a number of reservations and conditions\").It is indicative that the initially semi–underground Moscow methodological circle forms, forges and polishes the concepts demanded by contemporary period, at a time when the conceptual apparatus of the so–called \"post–non–classical\" (post–modernist) philosophy has already exhausted its capabilities.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Russian_philosophy", "https://en.wikipedia.org/wiki/Russian_philosophy", "https://en.wikipedia.org/wiki/Russian_philosophy", "https://en.wikipedia.org/wiki/Philosophy", "https://en.wikipedia.org/wiki/Outline_of_philosophy", "https://en.wikipedia.org/wiki/Glossary_of_philosophy", "https://en.wikipedia.org/wiki/History_of_philosophy", "https://en.wikipedia.org/wiki/Ancient_philosophy"]},
{"id": "6cdfd7599298", "url": "https://en.wikipedia.org/wiki/ASML_Holding", "title": "ASML Holding", "headings": ["Contents", "Products", "Immersion lithography", "DUV lithography", "EUV lithography", "History", "Finances", "Shareholder", "Sponsorships", "Awards", "References", "External links"], "content": " ASML Holding N.V.(commonly shortened toASML, originally standing forAdvanced Semiconductor Materials Lithography) is aDutchmultinational corporationthat specializes in the development and manufacturing ofphotolithographymachines which are used to produceintegrated circuits. As of 2023it is the largest supplier for thesemiconductor industryand the sole supplier in the world ofextreme ultraviolet lithography(EUVL) photolithography machines that are required to manufacture the most advanced chips.As of September 2025, its market capitalization was approximately $345 billion, making it Europe's largest technology company and one of its most valuable firms overall.This followed its November 2024 valuation of about $264 billion, at which time it was ranked as one of the top four most valuable European companies. ASML was founded in 1984 as ajoint venturebetween the Dutch technology companiesPhilipsandASM International. It became a fully independent corporation in 1995. ASML's corporate headquarters is inVeldhoven, Netherlands and is the location for research, development, manufacturing and assembly. ASML employs more than 42,000 peoplefrom 143 nationalities and relies on a network of nearly 5,000 tier 1 suppliers.ASML has a worldwide customer base and over 60 service points in 16 countries.It has offices in the Netherlands, the United States, Belgium, France, Germany, Ireland, Israel, Italy, the United Kingdom, China, Hong Kong, Japan, South Korea, Malaysia, Singapore, and Taiwan. The company is listed on both theAEXandNasdaqstock exchanges, as ASML. It is also a component of theEuro Stoxx 50andNasdaq-100. ASML produces thephotolithographymachines used in the production of integrated circuits, called \"scanners\". In these machines, patterns are optically imaged onto a siliconwaferthat is covered with a film of light-sensitive material (photoresist). This procedure is repeated dozens of times on a single wafer. The photoresist is then further processed to create the actual electronic circuits on the silicon. The optical imaging that ASML's machines deal with is used in the fabrication of nearly all integrated circuits and, as of 2011, ASML had 67 percent of the worldwide sales of lithography machines. ASML's earlier competition consisted ofUltratech,CanonandNikon,MKS Instruments,Lam ResearchandCadence Design Systems. Sinceimmersion lithographywas first proposed byBurn-Jeng Linin the 1970s,ASML cooperated withTSMC. In 2004, TSMC began commercial production of90 nanometersemiconductor nodesusing ASML immersion lithography.As of 2011, their high-end TWINSCAN NXT:1950i system was used for producing features down to 32nanometresat up to 200 wafers per hour,using a waterimmersion lensand anargon fluoride laserthat produces light at a wavelength of 193 nm. As of 2011, an average lithography machine cost€27 million. Deep ultraviolet lithography (DUV) devices from ASML use light that penetratesthe UV spectrum to print the tiny features that form the microchip's structure. Extreme ultraviolet lithography(EUV) is a critical technology used to create the smallest and most complex chip designs. ASML holds a near-monopoly in the EUV market. The company's machines are capable of etching patterns as small as 8 nanometers, 1/10000 the width of a human hair. EUV machines produce light in the 13.5 nmwavelengthrange by focusing a high-energylaseron microscopic droplets of moltentinto produce aplasma, which then emits EUV light. The light is bounced offZeissmirrors onto the surface of a silicon wafer to form the designs for the chip. In 2009, theIMECresearch center in Belgium produced the world's first functional 22 nmCMOSStatic random-access memorymemory cells with a prototype EUV lithography machine.After decades of development, ASML shipped the first production EUV machine in either 2011or 2013. As of 2022, ASML has shipped around 140 EUV systems.ASML's best-selling EUV product has been the TWINSCAN NXE:3600D, which costs up to $200 million.The machine weighs 180 tons and needs threeBoeing 747sto transport. ASML is working on the next generation of EUV systems, with the first shipments for R&D shipped toIntelin December 2023, and TSMC in late 2024.The platform is designatedHigh-NAas it increases thenumerical aperture(NA) from 0.33 to 0.55;each system costs approximately $370 million. ASML's EUV machines have experienced a significant surge in demand in recent years, driven by modern electronics' increasing complexity and performance requirements. This has translated into steady revenue growth for the company, reaching $30 billion in 2023, up from $13 billion five years earlier. ASM Lithography was founded in 1984 as a joint venture between the Dutch companiesASMandPhilips. The company became an independent publicly traded entity in 1988 and was renamed ASML,which is its official name and not an abbreviation. In 1991, ASML released the lithography system PAS 5500, which became an extremely successful platform for the company.The PAS 5500 was first used byMicron Technology, one of the world's largest producers of computer memory and storage, and ASML's largest customer at that time.The success of the PAS 5500 line propelled ASML into strong competition withCanonandNikon, who were the leaders of the lithography market at the time. In 1997, ASML began studying a shift to using extreme ultraviolet and in 1999 joined a consortium, includingInteland two other U.S. chipmakers, in order to exploit fundamental research conducted by theUS Department of Energy. Because theCooperative Research and Development Agreement (CRADA)it operates under is funded by the US government, licensing must be approved by Congress. It collaborated with the BelgianIMECandSematechand turned toCarl Zeissin Germany for its mirrors. In 2000, ASML acquired the Silicon Valley Group (SVG),a US lithography equipment manufacturer also licensed for EUV research results, in a bid to supply 193 nm scanners toIntel Corp. In 2002, it became the largest supplier of photolithography systems. At the end of 2008, ASML experienced a large drop in sales, which led management to cut the workforce by about 1000 worldwide, mostly contract workersand to apply for support from the Dutch national unemployment fund to prevent even larger layoffs.Two and a half years later, ASML expected record-high revenue. In July 2012, Intel announced a deal to invest $4.1 billion into ASML in exchange for 15% ownership, in order to speed up the transition from 300 mm to450 mm wafersand further development of EUV lithography.This deal was without exclusive rights to future ASML products and, in July 2012, ASML offered another 10% of its shares to other companies.As part of their EUV strategy, ASML announced the acquisition of DUV and EUV sources manufacturerCymerin October 2012. In November 2013, ASML paused development of 450 mm lithography equipment, citing uncertain timing of chipmaker demand. In 2015, ASML sufferedintellectual property theft. A number of employees had been found stealing confidential data from its Silicon Valley software subsidiary that develops software for machine optimization. In June 2016, ASML announced their plans to acquire Taiwan-based Hermes Microvision Inc. for about $3.1 billion to add technology for creating smaller and more advancedsemiconductors. In 2018, theTrump administrationtried to block the sale of ASML technology to China,but as of 2021, the ongoingglobal chip shortageas well as the \"technological cold war\" between the US and China had been a business opportunity for ASML.In February 2019, ASML joined the eBeam Initiative - a consortium supporting eBeam technology adoption for photomasks and lithography. In November 2020, ASML revealed that it had acquired the Germanoptical glassmakingfirm Berliner Glas Group in order to meet increasing need for components for its EUV systems. In July 2021, European CommissionerThierry Breton, visited ASML and announced a goal of at least 20% of world production of semiconductors in Europe by 2030, and support via a European Alliance on semiconductors.After reporting earnings in July 2021, the company said they had a near monopoly for machines used by TSMC andSamsung Electronicsto make the advanced chips. In February 2023, ASML claimed that a former worker in China \"allegedly\" stole information about the company's technology. This was not the first time that ASML was allegedly linked with an intellectual property breach connected to China. In its 2021annual report, ASML mentioned thatDongfang Jingyuan Electron Limited\"was actively marketing products in China that could potentially infringe on ASML's IP rights.\"At the time, theUnited States Department of Commerceexpressed concern abouteconomic espionageagainst ASML.In October 2023, Dutch newspaperNRC Handelsbladreported that the former employee who \"allegedly\" stole data about ASML's technology subsequently went to work forHuawei. In March 2023, the Dutch government placed restrictions on chip equipment exports in order to protect national security. This measure affected ASML as one of the most important companies in the global microchip supply chain.Export license requirements came into effect in September 2023. In June 2023, the Netherlands' Institute for Human Rights ruled that despite the country'sconstitutionprohibiting discrimination based on nationality, ASML was allowed to reject job applications from residents of countries subject to sanctions under the U.S.Export Administration Regulations(such as China, Cuba, Iran, North Korea, and Syria) in order to remain compliant with U.S. law. In January 2024, the Dutch government placed further restrictions on the shipment of some advanced chip-making equipment to China.On 6 September 2024, the Dutch government tightened export controls on certain ASML chipmaking equipment, aligning its policy with U.S. restrictions to limit China's access to advanced technology amid safety and geopolitical concerns.These restrictions were expanded for tighter export controls in January 2025, with ASML required to apply for export licenses with the Dutch government instead of the U.S. ASML became a sponsor of thePSVsoccer club in 2019 together withPhilips,VDL Groep,Royal Swinkels Family BrewersandJumbo Supermarketsfrom the Brainport region.Together they run various initiatives like soccertraining campsfor school children, the development of interactive programs for teaching, assisting community members in need or who are new to the region, as well as supporting a vitality program that is online.ASML was the title partner of theEindhoven marathonfrom 2022 - 2024. Media related toASMLat Wikimedia Commons", "combined_text": "ASML Holding Contents Products Immersion lithography DUV lithography EUV lithography History Finances Shareholder Sponsorships Awards References External links  ASML Holding N.V.(commonly shortened toASML, originally standing forAdvanced Semiconductor Materials Lithography) is aDutchmultinational corporationthat specializes in the development and manufacturing ofphotolithographymachines which are used to produceintegrated circuits. As of 2023it is the largest supplier for thesemiconductor industryand the sole supplier in the world ofextreme ultraviolet lithography(EUVL) photolithography machines that are required to manufacture the most advanced chips.As of September 2025, its market capitalization was approximately $345 billion, making it Europe's largest technology company and one of its most valuable firms overall.This followed its November 2024 valuation of about $264 billion, at which time it was ranked as one of the top four most valuable European companies. ASML was founded in 1984 as ajoint venturebetween the Dutch technology companiesPhilipsandASM International. It became a fully independent corporation in 1995. ASML's corporate headquarters is inVeldhoven, Netherlands and is the location for research, development, manufacturing and assembly. ASML employs more than 42,000 peoplefrom 143 nationalities and relies on a network of nearly 5,000 tier 1 suppliers.ASML has a worldwide customer base and over 60 service points in 16 countries.It has offices in the Netherlands, the United States, Belgium, France, Germany, Ireland, Israel, Italy, the United Kingdom, China, Hong Kong, Japan, South Korea, Malaysia, Singapore, and Taiwan. The company is listed on both theAEXandNasdaqstock exchanges, as ASML. It is also a component of theEuro Stoxx 50andNasdaq-100. ASML produces thephotolithographymachines used in the production of integrated circuits, called \"scanners\". In these machines, patterns are optically imaged onto a siliconwaferthat is covered with a film of light-sensitive material (photoresist). This procedure is repeated dozens of times on a single wafer. The photoresist is then further processed to create the actual electronic circuits on the silicon. The optical imaging that ASML's machines deal with is used in the fabrication of nearly all integrated circuits and, as of 2011, ASML had 67 percent of the worldwide sales of lithography machines. ASML's earlier competition consisted ofUltratech,CanonandNikon,MKS Instruments,Lam ResearchandCadence Design Systems. Sinceimmersion lithographywas first proposed byBurn-Jeng Linin the 1970s,ASML cooperated withTSMC. In 2004, TSMC began commercial production of90 nanometersemiconductor nodesusing ASML immersion lithography.As of 2011, their high-end TWINSCAN NXT:1950i system was used for producing features down to 32nanometresat up to 200 wafers per hour,using a waterimmersion lensand anargon fluoride laserthat produces light at a wavelength of 193 nm. As of 2011, an average lithography machine cost€27 million. Deep ultraviolet lithography (DUV) devices from ASML use light that penetratesthe UV spectrum to print the tiny features that form the microchip's structure. Extreme ultraviolet lithography(EUV) is a critical technology used to create the smallest and most complex chip designs. ASML holds a near-monopoly in the EUV market. The company's machines are capable of etching patterns as small as 8 nanometers, 1/10000 the width of a human hair. EUV machines produce light in the 13.5 nmwavelengthrange by focusing a high-energylaseron microscopic droplets of moltentinto produce aplasma, which then emits EUV light. The light is bounced offZeissmirrors onto the surface of a silicon wafer to form the designs for the chip. In 2009, theIMECresearch center in Belgium produced the world's first functional 22 nmCMOSStatic random-access memorymemory cells with a prototype EUV lithography machine.After decades of development, ASML shipped the first production EUV machine in either 2011or 2013. As of 2022, ASML has shipped around 140 EUV systems.ASML's best-selling EUV product has been the TWINSCAN NXE:3600D, which costs up to $200 million.The machine weighs 180 tons and needs threeBoeing 747sto transport. ASML is working on the next generation of EUV systems, with the first shipments for R&D shipped toIntelin December 2023, and TSMC in late 2024.The platform is designatedHigh-NAas it increases thenumerical aperture(NA) from 0.33 to 0.55;each system costs approximately $370 million. ASML's EUV machines have experienced a significant surge in demand in recent years, driven by modern electronics' increasing complexity and performance requirements. This has translated into steady revenue growth for the company, reaching $30 billion in 2023, up from $13 billion five years earlier. ASM Lithography was founded in 1984 as a joint venture between the Dutch companiesASMandPhilips. The company became an independent publicly traded entity in 1988 and was renamed ASML,which is its official name and not an abbreviation. In 1991, ASML released the lithography system PAS 5500, which became an extremely successful platform for the company.The PAS 5500 was first used byMicron Technology, one of the world's largest producers of computer memory and storage, and ASML's largest customer at that time.The success of the PAS 5500 line propelled ASML into strong competition withCanonandNikon, who were the leaders of the lithography market at the time. In 1997, ASML began studying a shift to using extreme ultraviolet and in 1999 joined a consortium, includingInteland two other U.S. chipmakers, in order to exploit fundamental research conducted by theUS Department of Energy. Because theCooperative Research and Development Agreement (CRADA)it operates under is funded by the US government, licensing must be approved by Congress. It collaborated with the BelgianIMECandSematechand turned toCarl Zeissin Germany for its mirrors. In 2000, ASML acquired the Silicon Valley Group (SVG),a US lithography equipment manufacturer also licensed for EUV research results, in a bid to supply 193 nm scanners toIntel Corp. In 2002, it became the largest supplier of photolithography systems. At the end of 2008, ASML experienced a large drop in sales, which led management to cut the workforce by about 1000 worldwide, mostly contract workersand to apply for support from the Dutch national unemployment fund to prevent even larger layoffs.Two and a half years later, ASML expected record-high revenue. In July 2012, Intel announced a deal to invest $4.1 billion into ASML in exchange for 15% ownership, in order to speed up the transition from 300 mm to450 mm wafersand further development of EUV lithography.This deal was without exclusive rights to future ASML products and, in July 2012, ASML offered another 10% of its shares to other companies.As part of their EUV strategy, ASML announced the acquisition of DUV and EUV sources manufacturerCymerin October 2012. In November 2013, ASML paused development of 450 mm lithography equipment, citing uncertain timing of chipmaker demand. In 2015, ASML sufferedintellectual property theft. A number of employees had been found stealing confidential data from its Silicon Valley software subsidiary that develops software for machine optimization. In June 2016, ASML announced their plans to acquire Taiwan-based Hermes Microvision Inc. for about $3.1 billion to add technology for creating smaller and more advancedsemiconductors. In 2018, theTrump administrationtried to block the sale of ASML technology to China,but as of 2021, the ongoingglobal chip shortageas well as the \"technological cold war\" between the US and China had been a business opportunity for ASML.In February 2019, ASML joined the eBeam Initiative - a consortium supporting eBeam technology adoption for photomasks and lithography. In November 2020, ASML revealed that it had acquired the Germanoptical glassmakingfirm Berliner Glas Group in order to meet increasing need for components for its EUV systems. In July 2021, European CommissionerThierry Breton, visited ASML and announced a goal of at least 20% of world production of semiconductors in Europe by 2030, and support via a European Alliance on semiconductors.After reporting earnings in July 2021, the company said they had a near monopoly for machines used by TSMC andSamsung Electronicsto make the advanced chips. In February 2023, ASML claimed that a former worker in China \"allegedly\" stole information about the company's technology. This was not the first time that ASML was allegedly linked with an intellectual property breach connected to China. In its 2021annual report, ASML mentioned thatDongfang Jingyuan Electron Limited\"was actively marketing products in China that could potentially infringe on ASML's IP rights.\"At the time, theUnited States Department of Commerceexpressed concern abouteconomic espionageagainst ASML.In October 2023, Dutch newspaperNRC Handelsbladreported that the former employee who \"allegedly\" stole data about ASML's technology subsequently went to work forHuawei. In March 2023, the Dutch government placed restrictions on chip equipment exports in order to protect national security. This measure affected ASML as one of the most important companies in the global microchip supply chain.Export license requirements came into effect in September 2023. In June 2023, the Netherlands' Institute for Human Rights ruled that despite the country'sconstitutionprohibiting discrimination based on nationality, ASML was allowed to reject job applications from residents of countries subject to sanctions under the U.S.Export Administration Regulations(such as China, Cuba, Iran, North Korea, and Syria) in order to remain compliant with U.S. law. In January 2024, the Dutch government placed further restrictions on the shipment of some advanced chip-making equipment to China.On 6 September 2024, the Dutch government tightened export controls on certain ASML chipmaking equipment, aligning its policy with U.S. restrictions to limit China's access to advanced technology amid safety and geopolitical concerns.These restrictions were expanded for tighter export controls in January 2025, with ASML required to apply for export licenses with the Dutch government instead of the U.S. ASML became a sponsor of thePSVsoccer club in 2019 together withPhilips,VDL Groep,Royal Swinkels Family BrewersandJumbo Supermarketsfrom the Brainport region.Together they run various initiatives like soccertraining campsfor school children, the development of interactive programs for teaching, assisting community members in need or who are new to the region, as well as supporting a vitality program that is online.ASML was the title partner of theEindhoven marathonfrom 2022 - 2024. Media related toASMLat Wikimedia Commons", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/ASML_Holding", "https://en.wikipedia.org/wiki/ASML_Holding", "https://en.wikipedia.org/wiki/ASML_Holding", "https://en.wikipedia.org/wiki/Veldhoven", "https://en.wikipedia.org/wiki/Public_company", "https://en.wikipedia.org/wiki/Ticker_symbol", "https://en.wikipedia.org/wiki/Euronext_Amsterdam", "https://en.wikipedia.org/wiki/AEX_index"]},
{"id": "891f76d54581", "url": "https://en.wikipedia.org/wiki/Carnegie_Mellon_School_of_Computer_Science", "title": "Carnegie Mellon School of Computer Science", "headings": ["Contents", "History", "Structure in the 1970s", "SCS today", "Organizational units", "Gates and Hillman Centers", "Traditions", "Smiley face", "Tartan Racing", "SCS honors and awards", "Faculty", "Notable faculty", "See also", "References", "Further reading", "External links"], "content": "TheSchool of Computer Science(SCS) atCarnegie Mellon UniversityinPittsburgh,Pennsylvaniais a degree-granting school forcomputer scienceestablished in 1988, making it one of the first of its kind in the world. It has been consistently ranked among the best computer science programs in the world.As of 2024U.S. News & World Reportranks the graduate program as tied for No. 1 withMassachusetts Institute of Technology,Stanford UniversityandUniversity of California, Berkeley. Researchers from Carnegie Mellon School of Computer Science have made fundamental contributions to the fields ofalgorithms,artificial intelligence,computer networks,distributed systems,parallel processing,programming languages,computational biology,robotics,language technologies,human–computer interactionandsoftware engineering. In July 1965,Allen Newell,Herbert A. Simon, andAlan J. Perlis, in conjunction with the faculty from the Graduate School of Industrial Administration (GSIA, renamedTepper School of Businessin 2004), staff from the newly formed Computation Center, and key administrators created the Computer Science Department, one of the first such departments in the nation. Their mission statement was \"to cultivate a course of study leading to thePhDdegree incomputer science, a program that would exploit the new technology and assist in establishing a discipline ofcomputer science.\" The educational program, formally accepted in October 1965, drew its first graduate students from several existing academic disciplines: mathematics,electrical engineering,psychology, and the interdisciplinary Systems and Communications Sciences program in theGraduate School of Industrial Administration. The department was housed within theMellon College of Science. With support from Newell, Simon,Nico Haberman, ProvostAngel Jordanand PresidentRichard Cyert, the computer science department began a two-year status as a \"floating\" department in the early months of 1986.  Then, the Department began to grow, both academically and financially. In 1988, the School of Computer Science was established, among the first such schools in the country. The Computer Science Department was the original department within the school. During the 1970s the Computer Science Department offered only a PhD study program, with no master's degree as an intermediate step.  The PhD program required a minimum of six years of residency.  It was called the \"do or die\" program among the graduate students, because a student could not drop a PhD and receive a master's degree.  It had quickly focused on computer networking, operating systems (Hydra,Accent,Mach), androbotics. The Gates Center for Computer Science and the Hillman Center for Future-Generation Technologies are home to much of the School of Computer Science. The $98 million complex was opened in 2009.It has 217,000-square-foot (20,200 m) of floor space, including about 310 offices, 11 conference rooms, 32 labs, 8,000 square feet (740 m) of project space and the Planetary Robotics Center. It also houses 12 classrooms, including a 250-seat auditorium. Additionally, the Gates Center connects to the Purnell Center, which houses the School of Drama, via theRandy PauschMemorial Footbridge. The bridge represents Professor Pausch's own devotion to linking computer science and entertainment, as he was a co-founder of Carnegie Mellon'sEntertainment Technology Center. Mack Scogin Merril ElamArchitects ofAtlanta, Georgia were the lead architects.The Gates and Hillman Centers have receivedLEEDGold Certification. SCS research professorScott Fahlmanis credited with the invention of the smiley faceemoticon. He suggested the emoticon on an electronic board in 1982 as a way for board readers to know when an author was joking. The text of Fahlman's original post was lost for nearly 20 years but was later recovered from backup tapes: Tartan Racing is a collaboration between Carnegie Mellon andGeneral Motors Corporationthat competes in theDARPA Grand Challenge. The Grand Challenge is a competition fordriverless carssponsored byDefense Advanced Research Projects Agency(DARPA). Tartan Racing is led by Carnegie MellonroboticistWilliam L. \"Red\" Whittaker. In 2007, Tartan Racing won theDARPA Urban Challenge, in which 11 autonomous ground vehicles raced over urban roadways. In the challenge, team vehicles were required to obey all California driving laws, share the road with other drivers and robotic cars, and complete the course in under six hours. Tartan Racing won the $2 million cash prize with Boss, a reworked 2007Chevy Tahoe. Averaging about 14 miles (23 km) an hour for a 55-mile (89 km) trip, Boss beat the second-place team,StanfordRacing, by just under 20 minutes. The School established a number of honors and awards. Faculty members from the School of Computer Science have received international recognition for achievements within their fields. These honors include memberships and fellowships in theNational Academy of Sciences, theNational Academy of Engineering, theAmerican Association for the Advancement of Science, theAssociation for Computing Machinery, theInstitute for Electrical and Electronic Engineers, theAlfred P. Sloan Foundation, theMacArthur Fellowship Program, and theGuggenheim Fellowship Program.Notably, thirteen SCS faculty and alumni have won theA. M. Turing Award, theAssociation for Computing Machinery's most prestigious award,often called the \"Nobel Prize of computing.\" These includeRaj Reddy,Manuel BlumandEdmund M. Clarkeof the recent active faculty, in addition to Emeritus FacultyDana Scottand former facultyGeoffrey Hinton. 40°26′37″N79°56′40″W﻿ / ﻿40.44371°N 79.94443°W﻿ /40.44371; -79.94443", "combined_text": "Carnegie Mellon School of Computer Science Contents History Structure in the 1970s SCS today Organizational units Gates and Hillman Centers Traditions Smiley face Tartan Racing SCS honors and awards Faculty Notable faculty See also References Further reading External links TheSchool of Computer Science(SCS) atCarnegie Mellon UniversityinPittsburgh,Pennsylvaniais a degree-granting school forcomputer scienceestablished in 1988, making it one of the first of its kind in the world. It has been consistently ranked among the best computer science programs in the world.As of 2024U.S. News & World Reportranks the graduate program as tied for No. 1 withMassachusetts Institute of Technology,Stanford UniversityandUniversity of California, Berkeley. Researchers from Carnegie Mellon School of Computer Science have made fundamental contributions to the fields ofalgorithms,artificial intelligence,computer networks,distributed systems,parallel processing,programming languages,computational biology,robotics,language technologies,human–computer interactionandsoftware engineering. In July 1965,Allen Newell,Herbert A. Simon, andAlan J. Perlis, in conjunction with the faculty from the Graduate School of Industrial Administration (GSIA, renamedTepper School of Businessin 2004), staff from the newly formed Computation Center, and key administrators created the Computer Science Department, one of the first such departments in the nation. Their mission statement was \"to cultivate a course of study leading to thePhDdegree incomputer science, a program that would exploit the new technology and assist in establishing a discipline ofcomputer science.\" The educational program, formally accepted in October 1965, drew its first graduate students from several existing academic disciplines: mathematics,electrical engineering,psychology, and the interdisciplinary Systems and Communications Sciences program in theGraduate School of Industrial Administration. The department was housed within theMellon College of Science. With support from Newell, Simon,Nico Haberman, ProvostAngel Jordanand PresidentRichard Cyert, the computer science department began a two-year status as a \"floating\" department in the early months of 1986.  Then, the Department began to grow, both academically and financially. In 1988, the School of Computer Science was established, among the first such schools in the country. The Computer Science Department was the original department within the school. During the 1970s the Computer Science Department offered only a PhD study program, with no master's degree as an intermediate step.  The PhD program required a minimum of six years of residency.  It was called the \"do or die\" program among the graduate students, because a student could not drop a PhD and receive a master's degree.  It had quickly focused on computer networking, operating systems (Hydra,Accent,Mach), androbotics. The Gates Center for Computer Science and the Hillman Center for Future-Generation Technologies are home to much of the School of Computer Science. The $98 million complex was opened in 2009.It has 217,000-square-foot (20,200 m) of floor space, including about 310 offices, 11 conference rooms, 32 labs, 8,000 square feet (740 m) of project space and the Planetary Robotics Center. It also houses 12 classrooms, including a 250-seat auditorium. Additionally, the Gates Center connects to the Purnell Center, which houses the School of Drama, via theRandy PauschMemorial Footbridge. The bridge represents Professor Pausch's own devotion to linking computer science and entertainment, as he was a co-founder of Carnegie Mellon'sEntertainment Technology Center. Mack Scogin Merril ElamArchitects ofAtlanta, Georgia were the lead architects.The Gates and Hillman Centers have receivedLEEDGold Certification. SCS research professorScott Fahlmanis credited with the invention of the smiley faceemoticon. He suggested the emoticon on an electronic board in 1982 as a way for board readers to know when an author was joking. The text of Fahlman's original post was lost for nearly 20 years but was later recovered from backup tapes: Tartan Racing is a collaboration between Carnegie Mellon andGeneral Motors Corporationthat competes in theDARPA Grand Challenge. The Grand Challenge is a competition fordriverless carssponsored byDefense Advanced Research Projects Agency(DARPA). Tartan Racing is led by Carnegie MellonroboticistWilliam L. \"Red\" Whittaker. In 2007, Tartan Racing won theDARPA Urban Challenge, in which 11 autonomous ground vehicles raced over urban roadways. In the challenge, team vehicles were required to obey all California driving laws, share the road with other drivers and robotic cars, and complete the course in under six hours. Tartan Racing won the $2 million cash prize with Boss, a reworked 2007Chevy Tahoe. Averaging about 14 miles (23 km) an hour for a 55-mile (89 km) trip, Boss beat the second-place team,StanfordRacing, by just under 20 minutes. The School established a number of honors and awards. Faculty members from the School of Computer Science have received international recognition for achievements within their fields. These honors include memberships and fellowships in theNational Academy of Sciences, theNational Academy of Engineering, theAmerican Association for the Advancement of Science, theAssociation for Computing Machinery, theInstitute for Electrical and Electronic Engineers, theAlfred P. Sloan Foundation, theMacArthur Fellowship Program, and theGuggenheim Fellowship Program.Notably, thirteen SCS faculty and alumni have won theA. M. Turing Award, theAssociation for Computing Machinery's most prestigious award,often called the \"Nobel Prize of computing.\" These includeRaj Reddy,Manuel BlumandEdmund M. Clarkeof the recent active faculty, in addition to Emeritus FacultyDana Scottand former facultyGeoffrey Hinton. 40°26′37″N79°56′40″W﻿ / ﻿40.44371°N 79.94443°W﻿ /40.44371; -79.94443", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Carnegie_Mellon_School_of_Computer_Science", "https://en.wikipedia.org/wiki/Carnegie_Mellon_School_of_Computer_Science", "https://en.wikipedia.org/wiki/Carnegie_Mellon_School_of_Computer_Science", "https://en.wikipedia.org/wiki/Geographic_coordinate_system", "https://en.wikipedia.org/wiki/Carnegie_Mellon_University", "https://en.wikipedia.org/wiki/Pittsburgh", "https://en.wikipedia.org/wiki/Pennsylvania", "https://en.wikipedia.org/wiki/Computer_science"]},
{"id": "19d8f8f9b737", "url": "https://en.wikipedia.org/wiki/Allen_Newell_Award_for_Research_Excellence", "title": "Carnegie Mellon School of Computer Science", "headings": ["Contents", "History", "Structure in the 1970s", "SCS today", "Organizational units", "Gates and Hillman Centers", "Traditions", "Smiley face", "Tartan Racing", "SCS honors and awards", "Faculty", "Notable faculty", "See also", "References", "Further reading", "External links"], "content": "TheSchool of Computer Science(SCS) atCarnegie Mellon UniversityinPittsburgh,Pennsylvaniais a degree-granting school forcomputer scienceestablished in 1988, making it one of the first of its kind in the world. It has been consistently ranked among the best computer science programs in the world.As of 2024U.S. News & World Reportranks the graduate program as tied for No. 1 withMassachusetts Institute of Technology,Stanford UniversityandUniversity of California, Berkeley. Researchers from Carnegie Mellon School of Computer Science have made fundamental contributions to the fields ofalgorithms,artificial intelligence,computer networks,distributed systems,parallel processing,programming languages,computational biology,robotics,language technologies,human–computer interactionandsoftware engineering. In July 1965,Allen Newell,Herbert A. Simon, andAlan J. Perlis, in conjunction with the faculty from the Graduate School of Industrial Administration (GSIA, renamedTepper School of Businessin 2004), staff from the newly formed Computation Center, and key administrators created the Computer Science Department, one of the first such departments in the nation. Their mission statement was \"to cultivate a course of study leading to thePhDdegree incomputer science, a program that would exploit the new technology and assist in establishing a discipline ofcomputer science.\" The educational program, formally accepted in October 1965, drew its first graduate students from several existing academic disciplines: mathematics,electrical engineering,psychology, and the interdisciplinary Systems and Communications Sciences program in theGraduate School of Industrial Administration. The department was housed within theMellon College of Science. With support from Newell, Simon,Nico Haberman, ProvostAngel Jordanand PresidentRichard Cyert, the computer science department began a two-year status as a \"floating\" department in the early months of 1986.  Then, the Department began to grow, both academically and financially. In 1988, the School of Computer Science was established, among the first such schools in the country. The Computer Science Department was the original department within the school. During the 1970s the Computer Science Department offered only a PhD study program, with no master's degree as an intermediate step.  The PhD program required a minimum of six years of residency.  It was called the \"do or die\" program among the graduate students, because a student could not drop a PhD and receive a master's degree.  It had quickly focused on computer networking, operating systems (Hydra,Accent,Mach), androbotics. The Gates Center for Computer Science and the Hillman Center for Future-Generation Technologies are home to much of the School of Computer Science. The $98 million complex was opened in 2009.It has 217,000-square-foot (20,200 m) of floor space, including about 310 offices, 11 conference rooms, 32 labs, 8,000 square feet (740 m) of project space and the Planetary Robotics Center. It also houses 12 classrooms, including a 250-seat auditorium. Additionally, the Gates Center connects to the Purnell Center, which houses the School of Drama, via theRandy PauschMemorial Footbridge. The bridge represents Professor Pausch's own devotion to linking computer science and entertainment, as he was a co-founder of Carnegie Mellon'sEntertainment Technology Center. Mack Scogin Merril ElamArchitects ofAtlanta, Georgia were the lead architects.The Gates and Hillman Centers have receivedLEEDGold Certification. SCS research professorScott Fahlmanis credited with the invention of the smiley faceemoticon. He suggested the emoticon on an electronic board in 1982 as a way for board readers to know when an author was joking. The text of Fahlman's original post was lost for nearly 20 years but was later recovered from backup tapes: Tartan Racing is a collaboration between Carnegie Mellon andGeneral Motors Corporationthat competes in theDARPA Grand Challenge. The Grand Challenge is a competition fordriverless carssponsored byDefense Advanced Research Projects Agency(DARPA). Tartan Racing is led by Carnegie MellonroboticistWilliam L. \"Red\" Whittaker. In 2007, Tartan Racing won theDARPA Urban Challenge, in which 11 autonomous ground vehicles raced over urban roadways. In the challenge, team vehicles were required to obey all California driving laws, share the road with other drivers and robotic cars, and complete the course in under six hours. Tartan Racing won the $2 million cash prize with Boss, a reworked 2007Chevy Tahoe. Averaging about 14 miles (23 km) an hour for a 55-mile (89 km) trip, Boss beat the second-place team,StanfordRacing, by just under 20 minutes. The School established a number of honors and awards. Faculty members from the School of Computer Science have received international recognition for achievements within their fields. These honors include memberships and fellowships in theNational Academy of Sciences, theNational Academy of Engineering, theAmerican Association for the Advancement of Science, theAssociation for Computing Machinery, theInstitute for Electrical and Electronic Engineers, theAlfred P. Sloan Foundation, theMacArthur Fellowship Program, and theGuggenheim Fellowship Program.Notably, thirteen SCS faculty and alumni have won theA. M. Turing Award, theAssociation for Computing Machinery's most prestigious award,often called the \"Nobel Prize of computing.\" These includeRaj Reddy,Manuel BlumandEdmund M. Clarkeof the recent active faculty, in addition to Emeritus FacultyDana Scottand former facultyGeoffrey Hinton. 40°26′37″N79°56′40″W﻿ / ﻿40.44371°N 79.94443°W﻿ /40.44371; -79.94443", "combined_text": "Carnegie Mellon School of Computer Science Contents History Structure in the 1970s SCS today Organizational units Gates and Hillman Centers Traditions Smiley face Tartan Racing SCS honors and awards Faculty Notable faculty See also References Further reading External links TheSchool of Computer Science(SCS) atCarnegie Mellon UniversityinPittsburgh,Pennsylvaniais a degree-granting school forcomputer scienceestablished in 1988, making it one of the first of its kind in the world. It has been consistently ranked among the best computer science programs in the world.As of 2024U.S. News & World Reportranks the graduate program as tied for No. 1 withMassachusetts Institute of Technology,Stanford UniversityandUniversity of California, Berkeley. Researchers from Carnegie Mellon School of Computer Science have made fundamental contributions to the fields ofalgorithms,artificial intelligence,computer networks,distributed systems,parallel processing,programming languages,computational biology,robotics,language technologies,human–computer interactionandsoftware engineering. In July 1965,Allen Newell,Herbert A. Simon, andAlan J. Perlis, in conjunction with the faculty from the Graduate School of Industrial Administration (GSIA, renamedTepper School of Businessin 2004), staff from the newly formed Computation Center, and key administrators created the Computer Science Department, one of the first such departments in the nation. Their mission statement was \"to cultivate a course of study leading to thePhDdegree incomputer science, a program that would exploit the new technology and assist in establishing a discipline ofcomputer science.\" The educational program, formally accepted in October 1965, drew its first graduate students from several existing academic disciplines: mathematics,electrical engineering,psychology, and the interdisciplinary Systems and Communications Sciences program in theGraduate School of Industrial Administration. The department was housed within theMellon College of Science. With support from Newell, Simon,Nico Haberman, ProvostAngel Jordanand PresidentRichard Cyert, the computer science department began a two-year status as a \"floating\" department in the early months of 1986.  Then, the Department began to grow, both academically and financially. In 1988, the School of Computer Science was established, among the first such schools in the country. The Computer Science Department was the original department within the school. During the 1970s the Computer Science Department offered only a PhD study program, with no master's degree as an intermediate step.  The PhD program required a minimum of six years of residency.  It was called the \"do or die\" program among the graduate students, because a student could not drop a PhD and receive a master's degree.  It had quickly focused on computer networking, operating systems (Hydra,Accent,Mach), androbotics. The Gates Center for Computer Science and the Hillman Center for Future-Generation Technologies are home to much of the School of Computer Science. The $98 million complex was opened in 2009.It has 217,000-square-foot (20,200 m) of floor space, including about 310 offices, 11 conference rooms, 32 labs, 8,000 square feet (740 m) of project space and the Planetary Robotics Center. It also houses 12 classrooms, including a 250-seat auditorium. Additionally, the Gates Center connects to the Purnell Center, which houses the School of Drama, via theRandy PauschMemorial Footbridge. The bridge represents Professor Pausch's own devotion to linking computer science and entertainment, as he was a co-founder of Carnegie Mellon'sEntertainment Technology Center. Mack Scogin Merril ElamArchitects ofAtlanta, Georgia were the lead architects.The Gates and Hillman Centers have receivedLEEDGold Certification. SCS research professorScott Fahlmanis credited with the invention of the smiley faceemoticon. He suggested the emoticon on an electronic board in 1982 as a way for board readers to know when an author was joking. The text of Fahlman's original post was lost for nearly 20 years but was later recovered from backup tapes: Tartan Racing is a collaboration between Carnegie Mellon andGeneral Motors Corporationthat competes in theDARPA Grand Challenge. The Grand Challenge is a competition fordriverless carssponsored byDefense Advanced Research Projects Agency(DARPA). Tartan Racing is led by Carnegie MellonroboticistWilliam L. \"Red\" Whittaker. In 2007, Tartan Racing won theDARPA Urban Challenge, in which 11 autonomous ground vehicles raced over urban roadways. In the challenge, team vehicles were required to obey all California driving laws, share the road with other drivers and robotic cars, and complete the course in under six hours. Tartan Racing won the $2 million cash prize with Boss, a reworked 2007Chevy Tahoe. Averaging about 14 miles (23 km) an hour for a 55-mile (89 km) trip, Boss beat the second-place team,StanfordRacing, by just under 20 minutes. The School established a number of honors and awards. Faculty members from the School of Computer Science have received international recognition for achievements within their fields. These honors include memberships and fellowships in theNational Academy of Sciences, theNational Academy of Engineering, theAmerican Association for the Advancement of Science, theAssociation for Computing Machinery, theInstitute for Electrical and Electronic Engineers, theAlfred P. Sloan Foundation, theMacArthur Fellowship Program, and theGuggenheim Fellowship Program.Notably, thirteen SCS faculty and alumni have won theA. M. Turing Award, theAssociation for Computing Machinery's most prestigious award,often called the \"Nobel Prize of computing.\" These includeRaj Reddy,Manuel BlumandEdmund M. Clarkeof the recent active faculty, in addition to Emeritus FacultyDana Scottand former facultyGeoffrey Hinton. 40°26′37″N79°56′40″W﻿ / ﻿40.44371°N 79.94443°W﻿ /40.44371; -79.94443", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Carnegie_Mellon_School_of_Computer_Science", "https://en.wikipedia.org/wiki/Carnegie_Mellon_School_of_Computer_Science", "https://en.wikipedia.org/wiki/Carnegie_Mellon_School_of_Computer_Science", "https://en.wikipedia.org/wiki/Geographic_coordinate_system", "https://en.wikipedia.org/wiki/Carnegie_Mellon_University", "https://en.wikipedia.org/wiki/Pittsburgh", "https://en.wikipedia.org/wiki/Pennsylvania", "https://en.wikipedia.org/wiki/Computer_science"]},
{"id": "dc6856d4e39b", "url": "https://en.wikipedia.org/wiki/Julian_Wagstaff", "title": "Julian Wagstaff", "headings": ["Contents", "References", "External links"], "content": " Julian Wagstaff(born 1970) is a Scottish composer ofclassicalmusic, musical theatre and opera. Born inEdinburgh, Wagstaff originally studied German language andpolitics, and graduated from theUniversity of Readingin 1993. Wagstaff worked as a translator and interpreter in the German language before turning to music as a profession in the late 1990s. His interest in language andpolitical historycontinues to be reflected in much of his music and in his theatrelibretti. He came to public attention with the musicalJohn Paul Jones(2001), based on the life of the Scots-born sailor and hero of theAmerican Revolution.Premiered in Edinburgh in 2001, this was the first of the composer's works to reach a significant audience. In it, Wagstaff'seclecticcompositional style (which frequently involves the integration of several different styles within one work) began to emerge.John Paul Joneswas revived as a concert version in 2010 in association with theScottish Chamber Orchestra. The composer began to studymusical compositionat theUniversity of Edinburghwith ProfessorNigel Osbornein 2001, earning a master's degree in music in 2002 and a PhD in 2008. Wagstaff's specific interest inGerman history, particularly the history of the formerGerman Democratic Republic,is reflected inTreptowforstring orchestra(2005), his most-performed work. This piece, which won the 2005Emre AraciPrize, was inspired by theSoviet War MemorialinTreptow Parkin eastBerlin. In August 2007, Wagstaff presented his hour-long chamber operaThe Turing Teston theEdinburgh Festival Fringe.The opera takes its name from the test proposed by the English mathematicianAlan Turingfor human level intelligence in a machine.A recording of hisPiano Quintetwas released in the same year on an album by the Edinburgh Quartet recorded byCalum MalcolmentitledFrontiers and Bridges. In 2011, Wagstaff was commissioned by theRoyal Society of Chemistryto compose a new work to celebrateInternational Year of Chemistry2011.The trio forclarinet, cello and piano is entitledA Persistent Illusionand was premiered by Hebrides Ensemble on 12 December 2011. In 2013, the composer was commissioned by the University of Edinburgh to write and produce a short opera to celebrate the Tercentenary of its School of Chemistry which fell that year.The resulting work, entitledBreathe Freely, is set during theSecond World Warand premiered in theAssembly Rooms (Edinburgh)on 24 October 2013 in a production supported byScottish Opera.A CD recording of the opera was released on theLinn Recordslabel in October 2015. In November 2021, the national German radio networkDeutschlandfunkbroadcast a 45-minute retrospective on Julian Wagstaff's life and work, presented by Martina Brandorff. Wagstaff lives and works in his native city. His works are widely performed throughout Scotland and beyond. Wagstaff writes and performs rock music under the name Jules Reed,including as a member of the band The Firrenes.His cousin is the writerRich Johnston.", "combined_text": "Julian Wagstaff Contents References External links  Julian Wagstaff(born 1970) is a Scottish composer ofclassicalmusic, musical theatre and opera. Born inEdinburgh, Wagstaff originally studied German language andpolitics, and graduated from theUniversity of Readingin 1993. Wagstaff worked as a translator and interpreter in the German language before turning to music as a profession in the late 1990s. His interest in language andpolitical historycontinues to be reflected in much of his music and in his theatrelibretti. He came to public attention with the musicalJohn Paul Jones(2001), based on the life of the Scots-born sailor and hero of theAmerican Revolution.Premiered in Edinburgh in 2001, this was the first of the composer's works to reach a significant audience. In it, Wagstaff'seclecticcompositional style (which frequently involves the integration of several different styles within one work) began to emerge.John Paul Joneswas revived as a concert version in 2010 in association with theScottish Chamber Orchestra. The composer began to studymusical compositionat theUniversity of Edinburghwith ProfessorNigel Osbornein 2001, earning a master's degree in music in 2002 and a PhD in 2008. Wagstaff's specific interest inGerman history, particularly the history of the formerGerman Democratic Republic,is reflected inTreptowforstring orchestra(2005), his most-performed work. This piece, which won the 2005Emre AraciPrize, was inspired by theSoviet War MemorialinTreptow Parkin eastBerlin. In August 2007, Wagstaff presented his hour-long chamber operaThe Turing Teston theEdinburgh Festival Fringe.The opera takes its name from the test proposed by the English mathematicianAlan Turingfor human level intelligence in a machine.A recording of hisPiano Quintetwas released in the same year on an album by the Edinburgh Quartet recorded byCalum MalcolmentitledFrontiers and Bridges. In 2011, Wagstaff was commissioned by theRoyal Society of Chemistryto compose a new work to celebrateInternational Year of Chemistry2011.The trio forclarinet, cello and piano is entitledA Persistent Illusionand was premiered by Hebrides Ensemble on 12 December 2011. In 2013, the composer was commissioned by the University of Edinburgh to write and produce a short opera to celebrate the Tercentenary of its School of Chemistry which fell that year.The resulting work, entitledBreathe Freely, is set during theSecond World Warand premiered in theAssembly Rooms (Edinburgh)on 24 October 2013 in a production supported byScottish Opera.A CD recording of the opera was released on theLinn Recordslabel in October 2015. In November 2021, the national German radio networkDeutschlandfunkbroadcast a 45-minute retrospective on Julian Wagstaff's life and work, presented by Martina Brandorff. Wagstaff lives and works in his native city. His works are widely performed throughout Scotland and beyond. Wagstaff writes and performs rock music under the name Jules Reed,including as a member of the band The Firrenes.His cousin is the writerRich Johnston.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Julian_Wagstaff", "https://en.wikipedia.org/wiki/Julian_Wagstaff", "https://en.wikipedia.org/wiki/Julian_Wagstaff", "https://en.wikipedia.org/wiki/Edinburgh", "https://en.wikipedia.org/wiki/European_classical_music", "https://en.wikipedia.org/wiki/Edinburgh", "https://en.wikipedia.org/wiki/German_politics", "https://en.wikipedia.org/wiki/University_of_Reading"]},
{"id": "2abb62768086", "url": "https://en.wikipedia.org/wiki/Israel", "title": "Israel", "headings": ["Contents", "Etymology", "History", "Prehistory", "Bronze and Iron Ages", "Classical antiquity", "Late antiquity and the medieval period", "Modern period and the emergence of Zionism", "British Mandate for Palestine", "State of Israel", "Geography", "Tectonics and seismicity", "Climate", "Government and politics", "Administrative divisions", "Israeli citizenship law", "Israeli-occupied territories", "Foreign relations", "Military", "Legal system", "Economy", "Science and technology", "Energy", "Transport", "Tourism", "Real estate", "Demographics", "Major urban areas", "Language", "Religion", "Education", "Culture", "Literature", "Music and dance", "Cinema and theatre", "Visual arts", "Architecture", "Museums", "Mass media", "Cuisine", "Sports", "See also", "References", "Notes", "Citations", "Sources", "External links"], "content": "  Israel,officially theState of Israel,is a country in theSouthern Levantregion ofWest Asia. ItbordersLebanonto the north,Syriato the northeast,Jordanto the east andEgyptto the southwest.Israel occupiesthePalestinian territoriesof theWest Bankin the east and theGaza Stripin the southwest, as well as the SyrianGolan Heightsin the northeast. Israel'swestern coastlies on theMediterranean Sea, the southernmost point reaches theRed Sea, and the east includes part of theDead Sea.Jerusalemis the government seat andproclaimed capital,whileTel Avivis the country'slargest urban areaandeconomic centre. TheLand of Israelis synonymous withPalestine,Judaea, or theHoly Land. Inantiquityit was home to theCanaanitesand later thekingdoms of Israel and Judah. Its location at acontinental crossroadsbroughtdemographic shiftsunder various empires. Nineteenth-centuryEuropean antisemitismfuelled theZionistmovement for aJewish homeland. Britain endorsed this goal in the 1917Balfour Declarationand ruledMandatory Palestinefrom 1920.Jewish immigrationandBritish policiesintensifiedArab-Jewish tensions,and the 1947United Nations(UN)Partition Plan for Palestineled toa civil war. Israeldeclared independenceat theend of the British Mandateon 14 May 1948, and neighbouringArab statesinvadedthe next day. A1949 armisticeleft Israel with territory beyond the UN plan;no Arab state was created, as theGaza Stripand theWest Bankcame under Egyptian and Jordanian control.MostPalestinian Arabsfled or were expelledbyZionist militiasin anethnic cleansingknown as theNakba, withthose who stayedbecoming Israel's main minority.TheJewish exodus from the Muslim worldincreasedthe country's populationin subsequent decades.After the 1967Six-Day War, Israel occupied the West Bank, Gaza Strip, the EgyptianSinai, and the SyrianGolan Heights, later annexingEast Jerusalemand the Golan—actions that, along withsettlementexpansion, are consideredviolations of international law. Peace was signedwith Egyptin 1979 (Sinai returned in 1982) andwith Jordanin 1994. The 1993Oslo Accordswith the Palestinians established mutual recognition and limited self-rule, and the 2020Abraham Accordsnormalisedties with more Arab states. TheIsraeli–Palestinian conflictremainsunresolved, withwarsand clashes withPalestinian militant groups. Israel is committing agenocide in Gaza, and its occupation of the Palestinian territories has drawn sustained internationalcriticism; experts, human-rights organisations and UN officials have described them aswar crimesandcrimes against humanity. TheBasic Laws of Israelestablish theKnesset, aparliamentelected byproportional representation. It shapes thegovernment, led by theprime minister, and elects the largely ceremonialpresident.Israel has one of the Middle East's largest economies,one of Asia's highest living standards, and globally ranks26th in nominal GDPand14th in nominal GDP per capita.Technologically advanced, Israel allocates a larger share of its economy to research and developmentthan any other stateand is believed topossess nuclear weapons. Theculture of IsraelcombinesJewish traditions, including those ofthe diaspora, withArabinfluences. The names Land of Israel andChildren of Israelhave historically been used to refer to the biblicalKingdom of Israeland the entireJewishpeople respectively. ThenameIsrael(Hebrew:Yīsrāʾēl;SeptuagintAncient Greek:Ἰσραήλ,Israēl, \"El (God)persists/rules\") refers to the patriarchJacobwho, according to theHebrew Bible, was given the name after he successfullywrestledwith theAngel of the Lord.The earliest known archaeological artefact to mention the wordIsraelas a collective is theMerneptah Steleofancient Egypt(dated to the late-13th century BCE). Under theBritish Mandate(1920–1948), the entire region was known asPalestine.Uponestablishment in 1948, the country formally adopted the nameState of Israel(Hebrew:מְדִינַת יִשְׂרָאֵל,Medīnat Yisrā'el[mediˈnatjisʁaˈʔel];Arabic:دَوْلَة إِسْرَائِيل,Dawlat Isrāʼīl,[dawlatʔisraːˈʔiːl]) after otherproposed namesincludingLand of Israel(Eretz Israel),Ever(from ancestorEber),Zion, andJudea, were considered but rejected.The nameIsraelwas suggested byDavid Ben-Gurionand passed by a vote of 6–3.In the early weeks after establishment, the government chose the termIsraelito denote a citizen of the state. TheUbeidiya prehistoric sitein northern Israel shows thepresence of archaic humansaround 1.5 million years ago.The second-oldest evidence ofanatomically modern humansoutside Africais a 200,000-year-old fossil fromMisliya Caveon Mount Carmel.TheNatufian culture(c.10,000 BCE) may be linked to theProto-Afroasiatic languageand is notable for adoptingsedentismbefore theadvent of agricultureand theNeolithic Revolution. Early references to \"Canaan\" and \"Canaanites\" appear in ancientNear EasternandEgyptiantexts (c.2000 BCE); these populations were structured as politically independentcity-states.During theLate Bronze Age(1550–1200 BCE), large parts of Canaan formedvassal statesof theNew Kingdom of Egypt.As a result of theLate Bronze Age collapse, Canaan fell into chaos, and Egyptian control over the region collapsed.Ancestors of theIsraelitesare thought to have includedancient Semitic-speaking peoplesnative to this area.Modern archaeological accounts suggest that the Israelites and their culture branched out of the Canaanite peoples through the development of a distinctmonolatristic—and latermonotheistic—religion centered onYahweh.They spoke an archaic form ofHebrew, known asBiblical Hebrew.Around the same time, thePhilistinessettled on the southerncoastal plain. Most modern scholars agree that theExodusnarrative in theTorahandOld Testamentdid not take place as depicted; however, some elements of these traditions do havehistorical roots.There is debate about the earliest existence of theKingdoms of Israel and Judahand their extent and power. While it is unclear if there was aUnited Kingdom of Israel,historians and archaeologists agree that the northernKingdom of Israelexisted byca.900 BCEand theKingdom of Judahbyca.850 BCE.The Kingdom of Israel was the more prosperous of the two and soon developed into a regional power, with a capital atSamaria;during theOmride dynasty, it controlledSamaria,Galilee, the upperJordan Valley, theplain of Sharonand large parts ofTransjordan. The Kingdom of Israel was conquered around 720 BCE by theNeo-Assyrian Empire.The Kingdom of Judah, underDavidicrule with its capital inJerusalem, later became aclient stateof first the Neo-Assyrian Empire and then theNeo-Babylonian Empire. It is estimated thatthe region's populationwas around 400,000 in theIron Age II.In 587/6 BCE, following arevolt in Judah, KingNebuchadnezzar IIbesieged and destroyed JerusalemandSolomon's Temple,dissolved the kingdom andexiled much of the Judean elite to Babylon. Aftercapturing Babylonin 539 BCE,Cyrus the Great, founder of theAchaemenid Empire, issueda proclamationallowing the exiled Judean population to return.The construction of theSecond Templewas completedc.520 BCE.The Achaemenids ruled the region as the province ofYehud Medinata.In 332 BCE,Alexander the Greatconquered the region as part of hiscampaign against the Achaemenid Empire. After his death, the area was controlled by thePtolemaicandSeleucidempires as a part ofCoele-Syria. Over the ensuing centuries, theHellenisationof the region led to cultural tensions that came to a head during the reign ofAntiochus IV, giving rise to theMaccabean Revoltof 167 BCE. The civil unrest weakened Seleucid rule, and in the late 2nd century the semi-autonomousHasmonean Kingdom of Judeaarose, eventually attaining full independence and expanding into neighbouring regions. TheRoman Republicinvaded the region in 63 BCE, firsttaking control of Syria, and then intervening in theHasmonean civil war.The strugglebetween pro-Roman and pro-Parthianfactions in Judea led to the installation ofHerod the Greatas adynastic vassalofRome. In 6 CE, the area was annexed as theRoman province of Judaea; tensions with Roman rule led to a series ofJewish–Roman wars, resulting in widespread destruction. TheFirst Jewish–Roman War(66–73 CE) resulted in thedestruction of Jerusalem and the Second Templeand a sizable portion of the population being killed or displaced. A second uprising known as theBar Kokhba revolt(132–136 CE) initially allowed the Jews to form an independent state, but the Romans brutally crushed the rebellion, devastating and depopulating Judea's countryside.Jerusalem was rebuilt as aRoman colony(Aelia Capitolina), and the province of Judea was renamedSyria Palaestina.Jews were expelled from the districts surrounding Jerusalem.Nevertheless, there was a continuous small Jewish presence, and Galilee became its religious center. During theByzantine period,Early ChristianitydisplacedRoman paganismin the 4th century CE, withConstantineembracing and promoting the Christian religion andTheodosius Imaking itthe state religion. A series of laws were passed that discriminated against Jews and Judaism, and Jews were persecuted by both the church and the authorities.Many Jews had emigrated to flourishingdiasporacommunities,while locally there was both Christian immigration and local conversion. By the middle of the 5th century, there was a Christian majority.Towards the end of the 5th century,Samaritan revoltserupted, continuing until the late 6th century and resulting in a large decrease in the Samaritan population.After theSasanian conquest of Jerusalemand the short-livedJewish revolt against Heracliusin 614 CE, the Byzantine Empirereconsolidated control of the areain 628. In 634–641 CE, theRashidun Caliphateconquered the Levant.CaliphUmar ibn al-Khattab(r.634–644) lifted the Christian ban on Jews enteringJerusalemand permitted them to worship there.Over the next six centuries, control of the region transferred between theUmayyad,Abbasid, andFatimidcaliphates, and subsequently theSeljukandAyyubiddynasties.The population drastically decreased during the following several centuries, dropping from an estimated 1 million during Roman and Byzantine periods to about 300,000 by the earlyOttoman period, and there was steadyArabisationandIslamisation.The end of the 11th century brought theCrusades,papally-sanctioned incursions of Christian crusaders intent on wresting Jerusalem and theHoly Landfrom Muslim control and establishingcrusader states.The Ayyubids pushed back the crusaders before Muslim rule was fully restored by theMamluk sultans of Egyptin 1291. In 1516, the Ottoman Empire conquered the region and ruled it as part ofOttoman Syria.Two violent incidents took place against Jews, the1517 Safed attacksand the1517 Hebron attacks, after the Turkish Ottomans ousted theMamluksduring theOttoman–Mamluk War.Under the Ottoman Empire, the Levant was fairly cosmopolitan, with religious freedoms forChristians, Muslims, and Jews. In 1561 theOttoman sultaninvitedSephardi Jewsescaping theSpanish Inquisitionto settle in and rebuild the city ofTiberias. Under the Ottoman Empire'smillet system, Christians and Jews were considereddhimmi(\"protected\") underOttoman lawin exchange for loyalty to the state and payment of thejizyatax.Non-Muslim Ottoman subjects faced geographic and lifestyle restrictions, though these were not always enforced.The millet system organised non-Muslims into autonomous communities on the basis of religion. Theconcept of the \"return\"remained a symbol within religious Jewish belief which emphasised that their return should be determined by Divine Providence rather than human action.Leading Zionist historianShlomo Avineridescribes this connection: \"Jews did not relate to the vision of the Return in a more active way than most Christians viewed theSecond Coming.\" The religious Judaic notion of being a nation was distinct from the modern European notion of nationalism.The Jewish population of Palestine from the Ottoman rule to the beginning of the Zionist movement, known as theOld Yishuv, comprised a minority and fluctuated in size. During the 16th century, Jewish communities struck roots in theFour Holy Cities—Jerusalem, Tiberias,Hebron, andSafed—and in 1697, Rabbi Yehuda Hachasid led 1,500 Jews to Jerusalem.A 1660Druze revoltagainst the Ottomans destroyedSafedandTiberias.In the second half of the 18th century, Eastern European Jews who wereopponentsofHasidism, known as thePerushim, settled in Palestine. In the late 18th century, local Arab SheikhZahir al-Umarcreated a de facto independent emirate in the Galilee. Ottoman attempts to subdue the sheikh failed. After Zahir's death the Ottomans regained control of the area. In 1799, governorJazzar Pasharepelled anassault on AcrebyNapoleon's troops, prompting the French to abandon the Syrian campaign.In 1834, arevolt by Palestinian Arab peasantsagainst Egyptian conscription and taxation policies underMuhammad Aliwas suppressed; Muhammad Ali's army retreated and Ottoman rule was restored with British support in 1840.TheTanzimatreforms were implemented across the Ottoman Empire. The first wave of modern Jewish migration toOttoman-ruled Palestine, known as theFirst Aliyah, began in 1881, as Jews fledpogromsin Eastern Europe.The 1882May Lawsincreased economic discrimination against Jews, and restricted where they could live.In response, politicalZionismtook form, a movement that sought to establish aJewish statein Palestine, thus offering a solution to theJewish questionof the European states.Antisemitism, pogroms and official policies in tsarist Russia led to the emigration of three million Jews in the years between 1882 and 1914, only 1% of whom went to Palestine. Those who went to Palestine were driven primarily by ideas of self-determination and Jewish identity, rather than as a response to pogroms or economic insecurity. TheSecond Aliyah(1904–1914) began after theKishinev pogrom; some 40,000 Jews settled in Palestine, although nearly half left eventually. Both the first and second waves of migrants were mainlyOrthodox Jews.The Second Aliyah includedZionist socialistgroups who established thekibbutzmovement based on the idea of establishing a separate Jewish economy based exclusively on Jewish labour.Those of the Second Aliyah who became leaders of theYishuvin the coming decades believed that the Jewish settler economy should not depend on Arab labour. This would be a dominant source of antagonism with the Arab population, with the new Yishuv's nationalist ideology overpowering its socialist one.Though the immigrants of the Second Aliyah largely sought to create communal Jewish agricultural settlements,Tel Avivwas established as the first planned Jewish town in 1909. Jewish armed militias emerged during this period, the first beingBar-Giorain 1907. Two years later, the largerHashomerorganisation was founded as its replacement. Chaim Weizmann's efforts to garner British support for the Zionist movement eventually secured theBalfour Declarationof 1917,stating Britain's support for the creation of a Jewish \"national home\" in Palestine.Weizmann's interpretation of the declaration was that negotiations on the future of the country were to happen directly between Britain and the Jews, excluding Arabs.Jewish-Arab relationsin Palestine deteriorated dramatically in the following years. In 1918, theJewish Legion, primarily Zionist volunteers, assisted in the Britishconquest of Palestine.In 1920, the territory was divided between Britain and France under themandate system, and the British-administered area (including modern Israel) was namedMandatory Palestine.Arab opposition to British rule and Jewish immigration led to the1920 Palestine riotsand the formation of a Jewish militia known as theHaganahas an outgrowth of Hashomer, from which theIrgunandLehiparamilitaries later split.In 1922, theLeague of Nationsgranted Britain theMandate for Palestineunder terms which included the Balfour Declaration with its promise to the Jews and with similar provisions regarding the Arab Palestinians.Thepopulation of the areawas predominantly Arab and Muslim, with Jews accounting for about 11%and Arab Christians about 9.5% of the population. TheThird(1919–1923) andFourth Aliyahs(1924–1929) brought an additional 100,000 Jews to Palestine. Therise of Nazismand the increasing persecution of Jews in 1930s Europe led to theFifth Aliyah, with an influx of a quarter of a million Jews. This was a major cause of theArab revolt of 1936–39, which was suppressed by British security forces and Zionist militias. Several hundred British security personnel and Jews were killed; 5,032 Arabs were killed, 14,760 wounded, and 12,622 detained.An estimated ten percent of the adult malePalestinian Arabpopulation was killed, wounded, imprisoned, or exiled. The British introduced restrictions on Jewish immigration to Palestine with theWhite Paper of 1939. With countries around the world turning away Jewish refugees fleeingthe Holocaust, a clandestine movement known asAliyah Betwas organised to bring Jews to Palestine. By the end ofWorld War II, 31% of the population of Palestine was Jewish.The UK found itself facing aJewish insurgencyover immigration restrictions and continued conflict with the Arab community over limit levels. The Haganah joined Irgun and Lehi in an armed struggle against British rule.The Haganah attempted to bring tens of thousands of Jewish refugees andHolocaust survivorsto Palestine by ship. Most of the ships were intercepted by theRoyal Navyand the refugees placed in detention camps inAtlitandCyprus. On 22 July 1946, Irgunbombed the British administrative headquartersfor Palestine, killing 91.The attack was a response toOperation Agatha(a series of raids, including one on theJewish Agency, by the British) and was the deadliest directed at the British during the Mandate era.The Jewish insurgency continued throughout 1946 and 1947 despite concerted efforts by the British military andPalestine Police Forceto suppress it. British efforts to mediate with Jewish and Arab representatives also failed as the Jews were unwilling to accept any solution that did not involve a Jewish state and suggested a partition of Palestine into Jewish and Arab states, while the Arabs were adamant that a Jewish state in any part of Palestine was unacceptable and that the only solution was a unified Palestine under Arab rule. In February 1947, the British referred the Palestine issue to the newly formedUnited Nations. On 15 May 1947, theUN General Assemblyresolved that aSpecial Committeebe created \"to prepare ... a report on the question of Palestine\".The Report of the Committeeproposed a planto replace the British Mandate with \"an independent Arab State, an independent Jewish State, and the City of Jerusalem [...] the last to be under an International Trusteeship System\".Meanwhile, the Jewish insurgency continued and peaked in July 1947, with a series of widespread guerrilla raids culminating inthe Sergeants affair, in which the Irgun took two British sergeants hostage as attempted leverage against the planned execution of three Irgun operatives. After the executions were carried out, the Irgun killed the two British soldiers, hanged their bodies from trees, and left a booby trap at the scene which injured a British soldier. The incident caused widespread outrage in the UK.In September 1947, the British cabinet decided to evacuate Palestine as the Mandate was no longer tenable. On 29 November 1947, the General Assembly adoptedResolution 181 (II).The plan attached to the resolution was essentially that proposed in the report of 3 September. The Jewish Agency, the recognised representative of the Jewish community, accepted the plan, which assigned 55–56% of Mandatory Palestine to the Jews. At the time, the Jews were about a third of the population and owned around 6–7% of the land. Arabs constituted the majority and owned about 20% of the land, with the remainder held by the Mandate authorities or foreign landowners.TheArab LeagueandArab Higher Committeeof Palestine rejected it on the basis that the partition plan privileged European interests over those of the Palestinians,and indicated that they would reject any other plan of partition.On 1 December 1947, the Arab Higher Committee proclaimed a three-day strike, andriots broke out in Jerusalem.The situation spiralled intoa civil war. Colonial SecretaryArthur Creech Jonesannounced that the British Mandate would end on 15 May 1948, at which point the British would evacuate. As Arab militias and gangs attacked Jewish areas, they were faced mainly by the Haganah as well as the smaller Irgun and Lehi. In April 1948, the Haganah moved onto the offensive. On 14 May 1948, the day before the expiration of the British Mandate,David Ben-Gurion, the head of the Jewish Agency, declared \"the establishment of a Jewish state in Eretz-Israel\".The following day, the armies of four Arab countries—Egypt, Syria, Transjordan, and Iraq—entered what had been Mandatory Palestine, launching the1948 Arab–Israeli War;contingents fromYemen,Morocco,Saudi Arabia, andSudanjoined the war.The purpose of the invasion was to prevent the establishment of the Jewish state.The Arab League stated the invasion was to restore order and prevent further bloodshed. After a year of fighting, aceasefire was declaredand temporary borders, known as theGreen Line, were established.Jordan annexedwhat became known as theWest Bank, includingEast Jerusalem, andEgypt occupiedtheGaza Strip. Over 700,000 Palestiniansfled or were expelledbyZionist militiasand theIsraeli military—what would become known in Arabic as thenakba('catastrophe').The events also led to the destruction of most of Palestine's Arabculture,identity, andnational aspirations. Some 156,000 Arabs remained and becameArab citizens of Israel. ByUnited Nations General Assembly Resolution 273, Israel was admitted as a member of the UN on 11 May 1949.In the early years of the state, theLabour Zionistmovement led by Prime Minister Ben-Gurion dominatedIsraeli politics.Immigration to Israel during the late 1940s and early 1950s was aided by the Israeli Immigration Department and the non-government sponsoredMossad LeAliyah Bet(lit.\"Institute forImmigration B\").The latter engaged in clandestine operations in countries, particularly in the Middle East and Eastern Europe, where the lives of Jews were in danger and exit was difficult. Mossad LeAliyah Bet was disbanded in 1953.The immigration was in accordance with theOne Million Plan. Some immigrants held Zionist beliefs or came for the promise of a better life, while others moved to escape persecution or were expelled from their homes. Aninflux of Holocaust survivorsandJews from Arab and Muslim countriesto Israel during the first three years increased the number of Jews from 700,000 to 1,400,000. By 1958, the population had risen to two million.Between 1948 and 1970, approximately 1,150,000 Jewish refugees relocated to Israel.Some immigrants arrived as refugees and were housed in temporary camps known asma'abarot; by 1952, over 200,000 people were living in these tent cities.Jews of European backgroundwere often treated more favourably than Jews fromMiddle EasternandNorth Africancountries—housing units reserved for the latter were often re-designated for the former, so Jews newly arrived from Arab lands generally ended up staying longer in transit camps.During this period, food, clothes and furniture were rationed in what became known as theausterity period. The need to solve the crisis led Ben-Gurion to sign areparations agreement with West Germanythat triggered mass protests by Jews angered at the idea that Israel could accept monetary compensation for the Holocaust. During the 1950s, Israel wasfrequently attackedbyPalestinian fedayeen, nearly always against civilians,mainly from the Egyptian-occupied Gaza Strip,leading to several Israelireprisal operations. In 1956, the UK and France aimed at regaining control of theSuez Canal, which Egypt had nationalised. The continued blockade of the Suez Canal andStraits of Tiranto Israeli shipping, together with increasing fedayeen attacks against Israel's southern population and recent Arab threatening statements, prompted Israel to attack Egypt.Israel joineda secret alliancewith the UK and France and overran theSinai Peninsulain theSuez Crisisbut was pressured to withdraw by the UN in return for guarantees of Israeli shipping rights.The war resulted in significant reduction of Israeli border infiltration. In the early 1960s, Israel captured Nazi war criminalAdolf Eichmannin Argentina and brought him to Israelfor trial.Eichmann remains the only person executed in Israel by conviction in an Israeli civilian court.In 1963, Israel was engaged in a diplomatic standoff with the United States in relation to the Israelinuclear programme. Since 1964 Arab countries, concerned over Israeli plans to divert waters of theJordan Riverinto thecoastal plain,had been trying to divert the headwaters to deprive Israel of water resources,provoking tensionsbetween Israel on the one hand, and Syria and Lebanon on the other.Arab nationalistsled by Egyptian PresidentGamal Abdel Nasserrefused to recognise Israel and called for its destruction.By 1966 Israeli-Arab relations had deteriorated to the point of battles taking place between Israeli and Arab forces. In May 1967, Egypt massed its army near the border with Israel, expelledUN peacekeepers stationed in the Sinai Peninsulasince 1957, and blocked Israel's access to the Red Sea.Other Arab states mobilised their forces.Israel reiterated that these actions were acasus belliand launched a pre-emptive strike (Operation Focus) against Egypt in June. Jordan, Syria and Iraq attacked Israel. In theSix-Day War, Israel captured and occupied the West Bank from Jordan, the Gaza Strip and Sinai Peninsula from Egypt, and the Golan Heights from Syria.Jerusalem's boundaries were enlarged, incorporating East Jerusalem. The 1949 Green Line became the administrative boundary between Israel and theoccupied territories. Following the 1967 war and the \"Three Nos\" resolution of the Arab League, Israel faced attacks from the Egyptians in the Sinai Peninsula during the 1967–1970War of Attrition, and from Palestinian groups targeting Israelis in the occupied territories, globally, and in Israel. Most important among the Palestinian and Arab groups was thePalestine Liberation Organisation(PLO), established in 1964, which initially committed itself to \"armed struggle as the only way to liberate the homeland\".In the late 1960s and early 1970s,Palestinian groups launched attacksagainst Israeli and Jewish targets around the world,includinga massacre of Israeli athletesat the1972 Summer Olympicsin Munich. The Israeli government responded with anassassination campaignagainst the organisers of the massacre,a bombingand araid on the PLO headquarters in Lebanon. On 6 October 1973, the Egyptian and Syrian armies launcheda surprise attackagainst Israeli forces in the Sinai Peninsula and Golan Heights, opening theYom Kippur War. The war ended on 25 October with Israel repelling Egyptian and Syrian forces but suffering great losses.Aninternal inquiryexoneratedthe governmentof responsibility for failures before and during the war, but public anger forced Prime MinisterGolda Meirto resign.In July 1976, an airliner was hijacked in flight from Israel to France by Palestinian guerrillas; Israeli commandosrescued 102 of 106 Israeli hostages. The1977 Knesset electionsmarked a major turning point in Israeli political history asMenachem Begin'sLikudparty took control from theLabour Party.Later that year, Egyptian PresidentAnwar El Sadatmade a trip to Israel and spoke before theKnessetin what was the first recognition of Israel by an Arab head of state.Sadat and Begin signed theCamp David Accords(1978) and theEgypt–Israel peace treaty(1979).In return, Israel withdrew from the Sinai Peninsula and agreed to enter negotiations over autonomy for Palestinians in the West Bank and the Gaza Strip. On 11 March 1978, a PLO guerilla raid from Lebanon led to theCoastal Road massacre. Israel responded by launching aninvasion of southern Lebanonto destroy PLO bases. Begin's government meanwhile provided incentives forIsraelis to settlein theoccupied West Bank, increasing friction with the Palestinians there. The 1980Jerusalem Lawwas believed by some to reaffirm Israel's 1967 annexation of Jerusalem by government decree andreignited international controversyover thestatus of the city. No Israeli legislation has defined the territory of Israel, and no act specifically included East Jerusalem therein.In 1981 Israeleffectively annexedthe Golan Heights.The international community largely rejected these moves, with the UN Security Council declaring both the Jerusalem Law and the Golan Heights Law null and void.Several waves ofEthiopian Jewsimmigrated to Israelsince the 1980s, while between 1990 and 1994,immigration from the post-Soviet statesincreased Israel's population by twelve percent. On 7 June 1981, during theIran–Iraq War, theIsraeli air force destroyedIraq's sole nuclear reactor, then under construction, in order to impede the Iraqi nuclear weapons programme.Following a series of PLO attacks in 1982, Israelinvaded Lebanonto destroy the PLO bases.In the first six days, Israel destroyed the military forces of the PLO in Lebanon and decisively defeated the Syrians. An Israeli government inquiry (theKahan Commission) held Begin and several Israeli generals indirectly responsible for theSabra and Shatila massacreand helddefence ministerAriel Sharonas bearing \"personal responsibility\".Sharon was forced to resign.In 1985, Israel responded to a Palestinianterrorist attack in Cyprusbybombing the PLO headquartersin Tunisia. Israel withdrew from most of Lebanon in 1986 but continued tooccupy a borderland buffer zonein southern Lebanon until 2000, from where Israeli forcesengaged in conflictwithHezbollah. TheFirst Intifada, a Palestinian uprising against Israeli rule,broke out in 1987, with waves of uncoordinated demonstrations and violence in the occupied West Bank and Gaza. Over the following six years, the intifada became more organised and included economic and cultural measures aimed at disrupting the Israeli occupation. Over 1,000 people were killed.During the 1991Gulf War, the PLO supportedSaddam Husseinand Iraqi missileattacks against Israel. Despite public outrage, Israel heeded American calls to refrain from hitting back. In 1992,Yitzhak Rabinbecame prime minister followingan electionin which his party called for compromise with Israel's neighbours.The following year,Shimon Pereson behalf of Israel andYasser Arafatfor the PLO signed theOslo Accords, which gave thePalestinian National Authority(PNA) the right to governparts of the West Bankand the Gaza Strip.The PLO alsorecognised Israel's right to existand pledged an end to terrorism.In 1994, theIsrael–Jordan peace treatywas signed, making Jordan the second Arab country to normalise relations with Israel.Arab public support for the Accords was damaged by the continuation of Israeli settlementsandcheckpoints, and the deterioration of economic conditions.Israeli public support for the Accords waned afterPalestinian suicide attacks.In November 1995, Rabinwas assassinatedbyYigal Amir, a far-right Jew who opposed the Accords. DuringBenjamin Netanyahu's premiership at the end of the 1990s, Israelagreed to withdrawfromHebron,though this was never ratified or implemented,and he signed theWye River Memorandum. The agreement dealt with further redeployments in the West Bank and security issues. The memorandum was criticised by major international human rights organisations for its \"encouragement\" of human rights abuses.Ehud Barak,electedprime minister in 1999, withdrew forces from southern Lebanon and conducted negotiations with PNA Chairman Yasser Arafat and U.S. PresidentBill Clintonat the2000 Camp David Summit. Barak offered a plan for the establishment of aPalestinian state, including the entirety of the Gaza Strip and over 90% of the West Bank with Jerusalem as a shared capital.Each side blamed the other for the failure of the talks. In late 2000, after a controversial visit by Sharon to theTemple Mount, theSecond Intifadabegan. The popular uprising faced disproportionate repression from the Israeli state.Palestinian suicide bombingseventually developed into a recurrent feature of the intifada.Some commentators contend that the intifada was pre-planned by Arafat after the collapse of peace talks.Sharon became prime minister in a2001 election; he carried out his plan tounilaterally withdrawfrom the Gaza Strip and spearheaded the construction of theWest Bank barrier,ending the intifada.Between 2000 and 2008, 1,063 Israelis, 5,517 Palestinians and 64 foreign citizens were killed. In July 2006, a Hezbollah artillery assault on Israel's northern border communities and across-border abductionof two Israeli soldiers precipitated the month-longSecond Lebanon War, including an Israeli invasion of Lebanon.The war wound down in August 2006 after the passage ofUnited Nations Security Council Resolution 1701; Israeli forces mostly withdrew from Lebanon by October 2006 but continued to occupy the Lebanese portion ofGhajarvillage.In 2007 the Israeli Air Forcedestroyed a nuclear reactorin Syria. In 2008,a ceasefirebetweenHamasand Israel collapsed, resulting in the three-weekGaza War.In what Israel described as a response toover a hundred Palestinian rocket attackson southern Israeli cities,Israel beganan operation in the Gaza Stripin 2012, lasting eight days.Israel started anotheroperation in Gazafollowing an escalation of rocket attacks by Hamas in July 2014.In May 2021, anotherround of fightingtook place in Gaza and Israel, lasting eleven days.By the 2010s,increasing regional cooperationbetween Israel andArab Leaguecountries have been established, culminating in the signing of theAbraham Accords. The Israeli security situation shifted from the traditionalArab–Israeli conflicttowards theIran–Israel proxy conflictanddirect confrontation with Iran during the Syrian civil war. On 7 October 2023, Palestinian militant groups from Gaza, led by Hamas, launcheda series of coordinated attackson Israel, leading to the start of theGaza war.On that day, approximately 1,300 Israelis, predominantly civilians, were killed in communities near the Gaza Strip border andduring a music festival.Over 200 hostageswere kidnapped and taken to the Gaza Strip. After clearing militants from its territory, Israel launchedone of the most destructive bombing campaigns in modern historyandinvaded Gazaon 27 October with the stated objectives of destroying Hamas and freeing hostages.The fifth war of theGaza–Israel conflictsince 2008, it has been the deadliest for Palestinians in the entireIsraeli–Palestinian conflictand the most significant military engagement in the region since theYom Kippur Warin 1973.AUnited Nations Special Committee,multiple governments, and various experts and human rights organisations have concluded that Israel is committinggenocide against the Palestinian peopledue to the harm and loss of life inflicted on civilians during theGaza War. In April 2024, Israel initiated a wave of airstrikes to Iran, after Iranian strikes targeted Israel. In October 2024, Israelinvaded Lebanonand exchanged missile barrages with Iran three weeks later, in response of Iranian strikes earlier in that month.After nearly a year of theIsrael–Hezbollah conflictfrom October 2023 due to Hezbollah shooting rockets at Israel to support Hamas in Gaza, IsraelassassinatedHezbollah secretary generalHassan Nasrallahin September 2024.A November 2024ceasefire agreementinstructed Israel to withdraw from Lebanon, which Israel mostly did by February 2025, but against the agreement Israeli forces stayed in five military outposts on highlands in Southern Lebanon.In June 2025, Israel launched a renewed series of missile strikes on Iran, which escalated into anarmed conflict. Israel is located in theLevantarea of theFertile Crescent. At theeastern endof theMediterranean Sea, it is bounded by Lebanon to the north, Syria to the north-east, Jordan and the West Bank to the east, and Egypt and the Gaza Strip to the south-west. It lies between latitudes29°and34° N, and longitudes34°and36° E. The sovereign territory of Israel (according to the demarcation lines of the1949 Armistice Agreementsand excluding all territories captured by Israel during the 1967 Six-Day War) is approximately 20,770 square kilometers (8,019 sq mi), of which two percent is water.However Israel is so narrow (100 km at its widest, compared to 400 km from north to south) that theexclusive economic zonein the Mediterranean is double the land area of the country.The total area under Israeli law, including East Jerusalem and the Golan Heights, is 22,072 square kilometers (8,522 sq mi),and the total area under Israeli control, including the military-controlled and partially Palestinian-governed territory of the West Bank, is 27,799 square kilometers (10,733 sq mi). Despite its small size, Israel is home to a variety of geographic features, from theNegevdesert in the south to the inland fertileJezreel Valley, with mountain ranges of theGalilee,Carmeland towards theGolanin the north. TheIsraeli coastal plainon the shores of the Mediterranean is home to most of the population.East of the central highlands lies theJordan Rift Valley, a small part of the 6,500-kilometer (4,039 mi)Great Rift Valley. TheJordan Riverruns along the Jordan Rift Valley, fromMount Hermonthrough theHulah Valleyand theSea of Galileeto theDead Sea, thelowest pointon the surface of the Earth.Further south is theArabah, ending with theGulf of Eilat, part of theRed Sea.Makhtesh, or \"erosion cirques\" are unique to the Negev and theSinai Peninsula, the largest being theMakhtesh Ramonat 38 km in length.Israel has the largest number of plant species per square meter of the countries in the Mediterranean Basinand contains four terrestrial ecoregions:Eastern Mediterranean conifer–sclerophyllous–broadleaf forests,Southern Anatolian montane conifer and deciduous forests,Arabian Desert, andMesopotamian shrub desert.Forests accounted for 8.5% of the area in 2016, up from 2% in 1948, as the result of a large-scale forest planting programme by theJewish National Fund. The Jordan Rift Valley is the result of tectonic movements within theDead Sea Transform(DST) fault system. The DST forms thetransform boundarybetween theAfrican Plateto the west and theArabian Plateto the east. The Golan Heights and all of Jordan are part of the Arabian Plate, while the Galilee, West Bank, Coastal Plain, and Negev along with the Sinai Peninsula are on the African Plate. This tectonic disposition leads to a relatively high seismic activity. The entire Jordan Valley segment is thought to have ruptured repeatedly, for instance during the last two major earthquakes along this structure in749and1033. The deficit inslipthat has built up since 1033 is sufficient to cause an earthquake of Mw~7.4. The most catastrophic known earthquakes occurred in 31 BCE,363, 749, and 1033 CE, that is everyca.400 years on average.Destructive earthquakes strike about every 80 years, leading to serious loss of life .While stringent construction regulations are in place and recently built structures are earthquake resistant, as of 2007many public buildings as well as 50,000 residential buildings did not meet the new standards and were \"expected to collapse\" if exposed to a strong earthquake. Temperatures vary widely, especially during the winter. Coastal areas, such as those of Tel Aviv and Haifa, have a typicalMediterranean climatewith cool, rainy winters and long, hot summers. The area of Beersheba and the northern Negev have asemi-arid climatewith hot summers, cool winters, and fewer rainy days. The southern Negev and the Arabah areas have adesert climatewith very hot, dry summers, and mild winters with few days of rain. The highest temperature of 54 °C (129 °F) was recorded in 1942 in theTirat Zvikibbutz.Mountainous regions can be windy and cold, and areas at elevation of 750 metres (2,460 ft) or more (same elevation as Jerusalem) usually receive at least onesnowfalleach year.From May to September, rain is rare. There are four differentphytogeographicregions, due to its location between the temperate and tropical zones. For this reason, the flora and fauna are extremely diverse. There are 2,867 knownspecies of plants in Israel. Of these, at least 253 species areintroduced and non-native.There are 380Israeli nature reserves. With scarce water resources, Israel has developed various water-saving technologies, includingdrip irrigation.The considerable sunlight available forsolar energymakesIsrael the leading nation in solar energyuse per capita—practically every house uses solar panels for water heating.TheMinistry of Environmental Protectionhas reported thatclimate change\"will have a decisive impact on all areas of life\", particularly for vulnerable populations. Israel has aparliamentary system,proportional representationanduniversal suffrage. A member of parliament supported by a parliamentary majority becomes theprime minister—usually this is the chair of the largest party. The prime minister is thehead of governmentand ofcabinet.Thepresidentishead of state, with largely ceremonial duties. Israel is governed by a 120-member parliament, known as theKnesset. Membership of the Knesset is based on proportional representation ofpolitical parties,with a 3.25% electoral threshold, which in practice has resulted in coalition governments. Residents of Israeli settlements in the West Bank are eligible to vote,and after the2015 election, 10 of the 120 members of the Knesset (8%) were settlers.Parliamentaryelectionsare scheduled every four years, but unstable coalitions or ano-confidence votecan dissolve a government earlier.The first Arab-led party was established in 1988,and as of 2022, Arab-led parties hold about 10% of seats.A party cannot run for election to the Knesset if its objectives or actions include the \"negation of the existence of the State of Israel as the state of the Jewish people\". TheBasic Laws of Israelfunction as anuncodified constitution. These define Israel as aJewish and democratic stateand the nation-state of exclusively the Jewish people.In 2003, the Knesset began to draft an official constitution based on these laws. Israel has no official religion,but the definition of the state as \"Jewish and democratic\" creates a strong connection withJudaism. On 19 July 2018, the Knesset passed a Basic Law that characterises Israel as principally a \"Nation State of the Jewish People\" and Hebrew as its official language. The bill ascribes an undefined \"special status\" to the Arabic language.The same bill gives Jews a unique right to national self-determination and views the developing of Jewish settlement in the country as \"a national interest\", empowering the government to \"take steps to encourage, advance and implement this interest\". The State of Israel is divided into six main administrative districts, known asmehozot(Hebrew:מחוזות;sg.:mahoz)—Center,Haifa,Jerusalem,North,South, andTel Aviv, as well as theJudea and Samaria Areain the West Bank. All of the Judea and Samaria Area and parts of the Jerusalem and Northern districts are not recognised internationally as part of Israel. Districts are divided into 15 sub-districts known asnafot(Hebrew:נפות;sg.:nafa), which are partitioned into 50 natural regions. The 1950Law of Returngrants Jews the unrestrictedright to immigrateto Israel and obtain Israeli citizenship. Individuals born within the country receivebirthright citizenshipif at least one parent is a citizen.Israeli law defines Jewish nationality as distinct from Israeli nationality, and theSupreme Court of Israelhas ruled that an Israeli nationality does not exist.A Jewish national is defined as any person practicing Judaism and their descendants. Golan Heights (1967–present) In 1967, as a result of the Six-Day War, Israel captured and occupied the West Bank (including East Jerusalem), the Gaza Strip and the Golan Heights. Israel also captured the Sinai Peninsula but returned it to Egypt as part of the 1979 Egypt–Israel peace treaty.Between 1982 and 2000, Israel occupiedpart of southern Lebanon, in what was known as theSecurity Belt. Since capture of these territories, Israeli settlements and military installations have been built within each of them, except Lebanon. The Golan Heights and East Jerusalem have been fully incorporated under Israeli law but not under international law. Israel has applied civilian law to both areas and granted their inhabitants permanent residency status and the ability to apply for citizenship. The UN Security Council has declared the annexation of the Golan Heights and East Jerusalem to be \"null and void\" and continues to view the territories as occupied.The status of East Jerusalem in any future peace settlement has at times been a difficult issue in negotiations between Israeli governments and representatives of the Palestinians. The West Bank excluding East Jerusalem is known asthe Judea and Samaria Area.The almost 400,000 Israeli settlers residing in the area are considered part of Israel's population, have Knesset representation, are subject to alarge part of Israel's civil and criminal laws, and their output is considered part of Israel's economy.The land is not considered part of Israel under Israeli law, as Israel has consciously refrained from annexing the territory, without ever relinquishing its legal claim to the land or defining a border.Israeli political opposition to annexation primarily stems from the perceived \"demographic threat\" of incorporating the West Bank's Palestinian population into Israel.Outside of the Israeli settlements, the West Bank remains under direct Israeli military rule, and Palestinians in the area cannot become Israeli citizens. The international community maintains that Israel does not have sovereignty in the West Bank and considers Israel's control of the area to be the longest military occupation in modern history.The West Bank was occupied and annexed by Jordan in 1950, following the 1949 Armistice Agreements. Only Britain recognised this annexation, and Jordan has sinceceded its claimto the territory to the PLO. The population is mainly Palestinians, including refugees of the 1948 Arab–Israeli War.From their occupation in 1967 until 1993, the Palestinians living in these territories were underIsraeli military administration. Since theIsrael–PLO letters of recognition, most of the Palestinian population andcitieshave been under the internal jurisdiction of the Palestinian Authority, and only partial Israeli military control, although Israel has redeployed its troops and reinstated full military administration during periods of unrest. Israel's claim of universal suffrage has been questioned due to its blurred territorial boundaries, its simultaneous extension of voting rights to Israeli settlers in the occupied territories and denial of voting rights to their Palestinian neighbours, as well as the allegedethnocraticnature of the state. The Gaza Strip is considered to be a \"foreign territory\" under Israeli law. Israel and Egypt operate a land, air, and seablockade of the Gaza Strip. The Gaza Strip was occupied by Israel after 1967. In 2005, as part of aunilateral disengagement plan, Israel removed its settlers and forces from the territory but continues to maintain control of its airspace and waters. The international community, including numerous international humanitarian organisations and UN bodies, consider Gaza to remain occupied.Following the 2007 Battle of Gaza, whenHamas assumed power in the Gaza Strip,Israel tightened control of the Gaza crossings alongits border, as well as by sea and air, and prevented persons from entering and exiting except for isolated cases it deemed humanitarian.Gaza has aborder with Egypt, and an agreement between Israel, the EU, and the PA governs how border crossings take place.The application of democracy to its Palestinian citizens and the selective application of Israeli democracy in the Israeli-controlled Palestinian territories have been criticised. TheInternational Court of Justicesaid, in its2004 advisory opinionon the legality of the construction of the West Bank barrier, that the lands captured by Israel in the Six-Day War, including East Jerusalem, are occupied territory and found that the construction of the wall within the occupied Palestinian territory violates international law.Most negotiations relating to the territories have been on the basis ofUN Security Council Resolution 242, which emphasises \"the inadmissibility of the acquisition of territory by war\", and calls on Israel to withdraw from occupied territories in return for normalisation of relations with Arab states (\"Land for peace\").Israel has been criticised for engaging in systematic and widespread violations ofhuman rights in the occupied territories, including occupationand war crimes against civilians.The allegations include violations of international humanitarian lawby theUN Human Rights Council.TheU.S. State Departmenthas called reports ofabuses of significant human rights of Palestinians\"credible\" both within Israeland the occupied territories.Amnesty Internationaland other NGOs have documented mass arbitrary arrests, torture, unlawful killings, systemic abuses and impunityin tandem with a denial of the right toPalestinian self-determination.Prime Minister Netanyahu has defended the country's security forces for protecting the innocent from terroristsand expressed contempt for what he describes as a lack of concern about the human rights violations committed by \"criminal killers\". Theinternational communitywidely regards Israeli settlements in the occupied territoriesillegal under international law.United Nations Security Council Resolution 2334(passed 2016) states that Israel's settlement activity constitutes a \"flagrant violation\" ofinternational lawand demands that Israel stop such activity and fulfill its obligations as anoccupying powerunder theFourth Geneva Convention.AUnited Nations special rapporteurconcluded that the settlement programme was a war crime under theRome Statute,andAmnesty Internationalfound that the settlement programme constitutes an illegal transfer of civilians into occupied territory and \"pillage\", which is prohibited by theHague ConventionsandGeneva Conventionsas well as being a war crime under the Rome Statute. In a2024 advisory opinion, the International Court of Justice stated that occupation of the Palestinian territories violated international law; Israel should end its occupation as quickly as possible and pay reparations. In addition, the court found that Israel was in breach of article 3 of theInternational Convention on the Elimination of All Forms of Racial Discrimination, which requires states to prevent, prohibit and eradicate all practices of racial segregation and apartheid. Treatment of Palestinians within the occupied territories and to a lesser extent in Israel itself have drawn widespread accusations that it is guilty ofapartheid, acrime against humanityunder the Rome Statute and theInternational Convention on the Suppression and Punishment of the Crime of Apartheid.The Washington Post's 2021 survey of scholars and academic experts on the Middle East found an increase from 59% to 65% of these scholars describing Israel as a \"one-state reality akin to apartheid\".The claim that Israel's policies for Palestinianswithin Israelorwithin Israeli-occupied territoriesamount to apartheid has been affirmed by Israeli human rights organisationB'tselem,University Network for Human Rights,and international human rights organisations such as Amnesty InternationalandHuman Rights Watch.Israeli human rights organisationYesh Dinhas also accused Israel of apartheid.Amnesty's claim was criticised by politicians and representatives from Israel and its closest allies such as, the US,the UK,theEuropean Commission,Australia,Netherlandsand Germany,while said accusations were welcomed by Palestiniansand theArab League.In 2022, Michael Lynk, a Canadian law professorappointed by the U.N. Human Rights Councilsaid that the situation met the legal definition of apartheid, and concluded: \"Israel has imposed upon Palestine an apartheid reality in a post-apartheid world\".Subsequent reports from his successor,Francesca Albaneseand fromPermanent United Nations Fact Finding Mission on the Israel Palestine conflictchair Navi Pillay echoed the opinion. In February 2024, theICJ held public hearingsin regards to the legal consequences arising from the policies and practices of Israel in the occupied Palestinian territory including East Jerusalem. During the hearings, 24 states and three international organisations said that Israeli practices amount to a breach of the prohibition of apartheid and/or amount to prohibited acts of racial discrimination.TheInternational Court of Justicein its2024 advisory opinionfound that Israel's occupation of the Palestinian territories constitutes systemic discrimination and is in breach of Article 3 of theInternational Convention on the Elimination of All Forms of Racial Discrimination, which prohibits racial segregation and apartheid. The opinion is silent as to whether the discrimination amounts to apartheid; individual judges were split on the question. Israel maintains diplomatic relations with 165UN member states, theHoly See,Kosovo, theCook IslandsandNiue. It has 107diplomatic missions;countries with which it has no diplomatic relations include most Muslim countries.Six out of 22 nations in theArab Leaguehave normalised relations with Israel. Israel remains formally in astate of war with Syria, dating back uninterrupted to 1948. It has been in a similarlyformal state of war with Lebanonsince the end of theLebanese Civil Warin 2000, with the Israel–Lebanon border remaining unagreed by treaty. Despite the peace treaty between Israel and Egypt, Israel is still widely considered an enemy country among Egyptians.Iran withdrew its recognition of Israel during theIslamic Revolution.Israeli citizens may not visit Syria, Lebanon, Iraq, Saudi Arabia, and Yemen without permission from theMinistry of the Interior.As a result of the 2008–09 Gaza War, Mauritania, Qatar, Bolivia, and Venezuela suspended political and economic ties with Israel,though Bolivia renewed ties in 2019. TheUnited Statesand theSoviet Unionwere the first two countries to recognise the State of Israel, having declared recognition roughly simultaneously.Diplomatic relations with the Soviet Union were broken in 1967 following the Six-Day War and renewed in 1991.The United States regards Israel as its \"most reliable partner in the Middle East\",based on \"common democratic values, religious affinities, and security interests\".The US has provided $68 billionin military assistanceand $32 billion in grants to Israel since 1967, under theForeign Assistance Act(period beginning 1962),more than any other country for that period until 2003.Most surveyed Americans have held consistently favourable views of Israel.The United Kingdom is seen as having a \"natural\"relationshipwith Israel because of the Mandate for Palestine.By 2007,Germanyhad paid 25 billion euros inreparations to Israeland individual Israeli Holocaust survivors.Israelis includedin the European Union'sEuropean Neighbourhood Policy. AlthoughTurkey and Israeldid not establish full diplomatic relations until 1991,Turkey has cooperated with the Jewish state since its recognition of Israel in 1949. Turkey's ties to other Muslim-majority nations in the region have at times resulted in pressure from Arab and Muslim states to temper its relationship with Israel.Relations took a downturn after the 2008–09 Gaza War and Israel'sraid of the Gaza flotilla.Relations betweenGreece and Israelhave improved since 1995 after decline of Israeli–Turkish relations.The two countries have a defence cooperation agreement and in 2010, theIsraeli Air Forcehosted Greece'sHellenic Air Forcein a joint exercise. The joint Cyprus-Israel oil and gas explorations centered on theLeviathan gas fieldare an important factor for Greece, given itsstrong linkswith Cyprus.Cooperation in the world's longestsubmarine power cable, theEuroAsia Interconnector, has strengthenedCyprus–Israel relations. Azerbaijan is one of the few majority Muslim countries to develop strategic and economicrelations with Israel.Kazakhstan also has an economic and strategic partnership with Israel.India established fulldiplomatic tieswith Israel in 1992 and has fostered a strong military, technological and cultural partnership with the country since then.India is the largest customer of theIsraeli military equipment, and Israel is the second-largest military partner of India after Russia.Ethiopiais Israel's main ally in Africa due to common political, religious and security interests. Israel has a history of providing emergency foreign aid and humanitarian response to disasters across the world.In 1955 Israel began itsforeign aid programmein Burma and then shifted to Africa.Israel's humanitarian efforts officially began in 1957 with the establishment ofMashav, the Israel's Agency for International Development Cooperation.In this early period, whilst Israel's aid represented only a small percentage of total aid to Africa, its programme was effective in creating goodwill; however, following the 1967 war relations soured.Israel's foreign aid programme subsequently shifted its focus to Latin America. Since the late 1970s Israel's foreign aid has gradually decreased, although in recent years Israel has tried to reestablish aid to Africa.There are additional Israeli humanitarian and emergency response groups that work with the government, includingIsraAid, a joint programme run by Israeli organisations and North American Jewish groups,ZAKA,The Fast Israeli Rescue and Search Team,Israeli Flying Aid,Save a Child's HeartandLatet.Between 1985 and 2015, Israel sent 24 delegations of their search and rescue unit theHome Front Commandto 22 countries.Currently Israeli foreign aidrankslow amongOECDnations, spending less than 0.1% of itsGNIon development assistance.The country ranked 38th in the 2018World Giving Index. TheIsrael Defence Forces(IDF) is the sole military wing of theIsraeli security forcesand is headed by itsChief of the General Staff, theRamatkal, subordinate to the Cabinet. The IDF consists of thearmy,air forceandnavy. It was founded during the 1948 Arab–Israeli War by consolidating paramilitary organisations, chiefly the Haganah.The IDF also draws upon the resources of theMilitary Intelligence Directorate(Aman).The IDF has been involved in several major wars and border conflicts, making it one of the most battle-trained armed forces in the world. MostIsraelis are conscriptedat age 18. Men serve two years and eight months, andwomen servetwo years.Following mandatory service, Israeli men join the reserve forces and usually do up to several weeks ofreserve dutyevery year until their forties. Most women are exempt from reserve duty.Arab citizens of Israel(except theDruze) and those engaged in full-time religious studiesare exempt, although theexemption of yeshiva studentshas been a source of contention.An alternative for those who receive exemptions on various grounds isSherut Leumi, or national service, which involves a programme of service in social welfare frameworks.A small minority of Israeli Arabs also volunteer in the army.As a result of its conscription programme, the IDF maintains approximately 176,500 active troops and 465,000 reservists, giving Israel one of the world's highestpercentage of citizens with military training. The military relies heavily on high-techweaponssystemsdesigned and manufactured in Israelas well as some foreign imports. TheArrowmissile is one of the world's few operationalanti-ballistic missilesystems.ThePythonair-to-air missile series is often considered one of the most crucial weapons in its military history.Israel'sSpikemissile is one of the most widely exportedanti-tank guided missilesin the world.Israel'sIron Domeanti-missile air defence system gained worldwide acclaim after intercepting hundreds ofrockets fired by Palestinian militantsfrom the Gaza Strip.Since theYom Kippur War, Israel has developed a network ofreconnaissance satellites.TheOfeqprogramme has made Israelone of seven countriescapable of launching such satellites. Israel is widely believed topossess nuclear weaponsand per a 1993 report, chemical and biologicalweapons of mass destruction.Israel has not signed theTreaty on the Non-Proliferation of Nuclear Weaponsand maintains apolicy of deliberate ambiguitytowards its nuclear capabilities.The Israeli Navy'sDolphin submarinesare believed to be armed with nuclear missiles offeringsecond-strikecapability.Since theGulf Warin 1991, all homes in Israel are required to have a reinforced security room,Merkhav Mugan, impermeable to chemical and biological substances. Since Israel's establishment, military expenditure constituted a significant portion of the country'sgross domestic product, with peak of 30.3% of GDP in 1975.In 2021, Israel ranked 15th in the worldby total military expenditure, with $24.3 billion, and 6th by defence spending as a percentage of GDP, with 5.2%.Since 1974, the United States has been a particularly notable contributor ofmilitary aid.Under amemorandum of understandingsigned in 2016, the U.S. is expected to provide the country with $3.8 billion per year, or around 20% of Israel's defence budget, from 2018 to 2028.Israel ranked 8th globally forarms exportsin 2020–2024.The majority of Israel's arms exports are unreported for security reasons.Israel is consistently rated low in theGlobal Peace Index, ranking 134th out of 163 nations in 2022. Israel has athree-tier court system. At the lowest level aremagistratecourts, situated in most cities across the country. Above them aredistrict courts, serving as bothappellatecourts andcourts of first instance; they are situated in five of Israel's sixdistricts. The third and highest tier is theSupreme Court, located in Jerusalem; it serves a dual role as the highest court of appeals and theHigh Court of Justice. In the latter role, the Supreme Court rules as a court of first instance, allowing both citizens and non-citizens to petition against the decisions of state authorities. The legal system combines three legal traditions:English common law,civil law, andJewish law.It is based on the principle ofstare decisis(precedent) and is anadversarial system. Court cases are decided by professional judges.Marriageand divorce are under the jurisdiction of the religious courts:Jewish,Muslim, Druze, and Christian. The election of judges is carried out by aselection committeechaired by thejustice minister(currentlyYariv Levin).Israel'sBasic Law: Human Dignity and Libertyseeks to defendhuman rights and liberties in Israel. TheUnited Nations Human Rights Counciland Israeli human rights organisationAdalahhave highlighted that this law does not in fact contain a general provision for equality and non-discrimination.As a result of \"Enclave law\", large portions of Israeli civil law are applied to Israeli settlements and Israeli residents in the occupied territories. Israel is considered the most advanced country inWest Asiaand the Middle East in economic and industrial development.As of October 2023, the IMF estimated its GDP at 521.7 billion dollars and GDP per capita at 53.2 thousand (ranking 13th worldwide).It is the third richest country in Asiaby nominal per capitaincomeand has the highest averagewealth per adultin the Middle East.The Economistranked Israel as the fourth most successful economy among the developed countries for 2022.It has themost billionairesin the Middle East and the 18th most in the world.In recent years, Israel had one of the highest growth rates in the developed world.In 2010, it joined theOECD.The country is ranked 35th on theWorld Bank'sEase of Doing Businessindex.Economic data covers the economic territory of Israel, including the Golan Heights, East Jerusalem and Israeli settlements in the West Bank. Despite limited natural resources, intensive development of theagriculturaland industrial sectors over the past decades has made Israel largely self-sufficient in food production, apart from grains and beef. Imports, totalling $96.5 billion in 2020, include raw materials, military equipment, investment goods, rough diamonds, fuels, grain, and consumer goods.Leading exports include machinery, equipment, software,cut diamonds, agricultural products, chemicals, textiles, and apparel; in 2020, exports reached $114 billion.TheBank of Israelholds $201 billion of foreign-exchange reserves, the 17th highest in the world.Since the 1970s, Israel has receivedmilitary aidfrom the United States, as well as loan guarantees, which account for roughly half of Israel's external debt. Israel hasone of the lowestexternal debts in the developed world, and is a lender in terms of net external debt (assets vs. liabilities abroad), which in 2015stood at a surplus of $69 billion. Israel has the second-largest number of startup companies after the United Statesand the third-largest number ofNASDAQ-listed companies.It is the world leader for number of start-ups per capitaand has been dubbed the \"Start-Up Nation\".IntelandMicrosoftbuilt their first overseasresearch and developmentfacilities in Israel, and other high-tech multinational corporations have openedresearch and development centres in the country. The days which are allocated to working times are Sunday through Thursday (for a five-day workweek), or Friday (for a six-day workweek). In observance ofShabbat, in places where Friday is a work day and the majority of population is Jewish, Friday is a \"short day\". Several proposals have been raised to adjust the work week with the majority of the world. Israel's development of cutting-edge technologies in software, communications and the life sciences haveevoked comparisonswithSilicon Valley.Israel is first in the world inexpenditure on research and developmentas a percentage of GDP.It is ranked 15th in theGlobal Innovation Indexin 2024,and 5th in the 2019Bloomberg Innovation Index.Israel has 140 scientists, technicians, and engineers per 10,000 employees, the highest number in the worldand has produced sixNobel Prize-winningscientists, mostly in chemistry, since 2004and has been frequently ranked as one of the countries with the highest ratios ofscientific papersper capita.Israeli universitiesare ranked among the top 50 world universities in computer science (TechnionandTel Aviv University), mathematics (Hebrew University of Jerusalem) and chemistry (Weizmann Institute of Science). In 2012, Israel was ranked ninth in the world by the Futron'sSpace Competitiveness Index.TheIsrael Space Agencycoordinates all space research programmes with scientific and commercial goals, and have designed and built at least 13 commercial, research and spy satellites.Some satellites are ranked among the world's most advanced space systems.Shavitis a spacelaunch vehicleproduced by Israel to launch small satellites intolow Earth orbit.It was first launched in 1988, making Israel theeighth nationto have a space launch capability. In 2003,Ilan Ramonbecame Israel's first astronaut, serving on thefatal missionofSpace ShuttleColumbia. Theongoing water shortagehas spurred innovation in water conservation techniques, and a substantialagricultural modernisation,drip irrigation, was invented in Israel. Israel is also at the technological forefront of desalination and water recycling. The Sorek desalination plant is the largest seawaterreverse osmosisdesalination facility in the world.By 2014, desalination programmes provided roughly 35% of the drinking water, and it is expected to supply 70% by 2050.As of 2015, over 50 percent of the water for households, agriculture and industry is artificially produced.In 2011, Israel's water technology industry was worth around $2 billion per year with annual exports of products and services in the tens of millions of dollars. As a result of innovations in reverse osmosis technology, Israel is set to become a netexporter of water. Israel has embracedsolar energy; its engineers are on the cutting edge of solar energy technology,and its solar companies work on projects around the world.Over 90% of homes use solar energy for hot water, the highest per capita.According to government figures, the country saves 8% of its electricity consumption per year because of its solar energy use in heating.The high annual incident solar irradiance at its geographic latitude creates ideal conditions for what is an internationally renowned solar research and development industry in the Negev.Israel had a modern electric car infrastructure involving a countrywide network of charging stations;however, its electric car companyBetter Placeshut down in 2013. Israelbegan producing natural gasfrom its own offshore gas fields in 2004. In 2009Tamar gas fieldwas discovered near the coast, andLeviathan gas fieldwas discovered in 2010.The natural gas reserves in these two fields could make Israel energy-secure for more than 50 years. Commercial production of natural gas from the Tamar field began in 2013, with over 7.5 billion cubic meters (bcm) produced annually.Israel had 199 billion bcm of proven reserves of natural gas as of 2016.The Leviathan gas field started production in 2019. Ketura Sunis Israel's first commercial solar field. Built in 2011 by theArava Power Company, the field will produce about 9 gigawatt-hours of electricity per year,sparing the production of some 125,000 metric tons of carbon dioxide over 20 years. Israel has 19,224 kilometres (11,945 mi) of pavedroadsand 3 million motor vehicles.Thenumber of motor vehicles per 1,000 personsis 365, relatively low among developed countries.The country aims to have 30% of vehicles on its roads powered by electricity by 2030. Israel has 5,715 buses on scheduled routes,operated by several carriers, the largest and oldest of which isEgged, serving most of the country.Railwaysstretch across 1,277 kilometres (793 mi) and are operated by government-ownedIsrael Railways.Following major investments beginning in the early to mid-1990s, the number of train passengers per year has grown from 2.5 million in 1990, to 53 million in 2015; railways transport 7.5 million tons of cargo per year. Israel is served by three internationalairports:Ben Gurion Airport, the country's main hub for international air travel;Ramon Airport; andHaifa Airport. Ben Gurion handled over 21.1 million passengers in 2023.There are three main ports: thePort of Haifa, the oldest and largest;Ashdod Port; and thePort of Eilaton theRed Sea. Tourism, especiallyreligious tourism, is an important industry, withbeaches,archaeological, otherhistoricalandbiblicalsites, and unique geography also drawing tourists. In 2017, a record 3.6 million tourists visited Israel, yielding a 25 percent growth since 2016 and contributed NIS 20 billion to the economy. Housing prices are listed in the top third of all countries,with an average of 150 salaries required to buy an apartment.As of 2022, there are about 2.7 million properties in Israel, with an annual increase of over 50,000.However, demand for housing exceeds supply, with a shortage of about 200,000 apartments as of 2021.As a result, by 2021 housing prices rose by 5.6%.In 2021, Israelis took a record of NIS 116.1 billion in mortgages, an increase of 50% from 2020. Israel has the largest Jewish population in the world and is the only country where Jews are the majority,and the only country in which Jews make up more than 2% of the total national population.April 2025, the population was an estimated 10,094,000.In 2025, the government recorded72% of the population asJews,21% asArabs, and7% as \"Others\" (non-Arab Christians and people who have no religion listed).Over the last decade, large numbers of migrant workers from Romania, Thailand, China, Africa, and South America have settled in Israel. Exact figures are unknown, as many of them are living in the country illegally,but estimates run from 166,000 to 203,000.By June 2012, approximately 60,000African migrantshad entered Israel. About 93% of Israelis live in urban areas.90% of Palestinian Israelis reside in 139 densely populated towns and villages concentrated in the Galilee,Triangleand Negev regions, with the remaining 10% inmixed citiesand neighbourhoods.The OECD in 2016 estimated the average life expectancy at 82.5 years, the6th-highest in the world.Israeli Arab life expectancy lags by 3 to 4 yearsand is higher than in most Arab and Muslim countries.The country has the highestfertility ratein the OECD and the only one which is above the replacement figure of 2.1.Retention of Israel's population since 1948 is about even or greater, when compared to other countries with mass immigration.Jewish emigration from Israel (calledyerida), primarily to the United States and Canada, is described by demographers as modest,but is often cited by Israeli government ministries as a major threat to Israel's future. Approximately 80% ofIsraeli Jewsareborn in Israel, 14% are immigrants from Europe and the Americas, and 6% are immigrants from Asia and Africa.Jews from Europe and the former Soviet Union and their descendants born in Israel, including Ashkenazi Jews, constitute approximately 44% of Jewish Israelis. Jews from Arab and Muslim countries and their descendants, including both Mizrahi and Sephardi Jews,form most of the rest of the Jewish population.Jewish intermarriage rates run at over 35% and recent studies suggest that the percentage of Israelis descended from both Sephardi and Ashkenazi Jews increases by 0.5 percent yearly, with over 25% of schoolchildren now originating from both.Around 4% of Israelis (300,000), ethnically defined as \"others\", are Russian descendants of Jewish origin or family who are not Jewish according to rabbinical law, but were eligible for citizenship under the Law of Return. Israeli settlers beyond the Green Line number over 600,000 (≈10% of the Jewish Israeli population).In 2016,399,300 Israelis livedin West Bank settlements,including those that predated the establishment of the State of Israel and which were re-established after the Six-Day War. Additionally there were more than 200,000 Jews living in East Jerusalemand 22,000 in the Golan Heights.Approximately 7,800 Israelislived in settlementsin the Gaza Strip, known asGush Katif, until they were evacuated by the government as part of its 2005disengagement plan. Israeli Arabs (including the Arab population of East Jerusalem and the Golan Heights) comprise 21.1% of the population or 1,995,000 people.In a 2017 poll, 40% of Arab citizens of Israel identified as \"Arab in Israel\" or \"Arab citizen of Israel\", 15% identified as \"Palestinian\", 8.9% as \"Palestinian in Israel\" or \"Palestinian citizen of Israel\", and 8.7% as \"Arab\"; a poll found that 60% of Israeli Arabs have a positive view of the state. Israel has four major metropolitan areas:Gush Dan(Tel Aviv metropolitan area; population 3,854,000),Jerusalem(population 1,253,900),Haifa(924,400), andBeersheba(377,100).The largest municipality, in population and area, is Jerusalem with 1,028,366 residents in an area of 125 square kilometres (48 sq mi).Statistics on Jerusalem include the population and area of East Jerusalem, the status of which is in international dispute.Tel Aviv and Haifa rank as Israel's next most populous cities, with populations of 495,230 and 298,312, respectively.The (mainlyHaredi) city ofBnei Brakis the most densely populated city in Israel and one of the10 most densely populated citiesin the world. Israel has 16 cities with populations over 100,000. As of 2018there are 77 localities granted\"municipalities\" (or \"city\") statusby the Ministry of the Interior,four of which are in the West Bank. ^aThis number includesEast JerusalemandWest Bankareas, which had a total population of 617,580 inhabitants in 2023.Israeli sovereignty over East Jerusalem isinternationally unrecognized. The official language isHebrew. Hebrew is the primary language of the state and is spoken daily by the majority of the population. Prior to 1948,oppositiontoYiddish, the historical language of the Ashkenazi Jews, was common among supporters of the Zionist movement, including the Yishuv, who sought to promoteHebrew's revivalas a unifying national language.These sentiments were reflected in the early policies of the Israeli government, which largely bannedYiddish theatreand publications.Until 2018,Arabicwas also an official language;in 2018 it was downgraded to having a \"special status in the state\".Arabic is spoken by the Arab minority, with Arabic and Hebrew taught in Arab schools.Arabic is studied in most Jewish schools and is often used on signage and in transport announcements. Due to mass immigration from the former Soviet Union andEthiopia(some 130,000Ethiopian Jews live in Israel),RussianandAmharicare widely spoken.Over one million Russian-speaking immigrants arrived in Israel between 1990 and 2004.French is spoken by around 700,000 Israelis,mostly originatingfrom Franceand North Africa (seeMaghrebi Jews). English was an official language during the Mandate period;it lost this status after the establishment of Israel, but retains a role comparable to that of an official language.Many Israelis communicate reasonably well in English, as many television programmes are broadcast in English with subtitles and the language is taught in elementary school. Israeli universities offer courses in English. The estimated religious affiliation as of 2022 was 73.5% Jewish, 18.1%Muslim, 1.9%Christian, 1.6%Druze, and 4.9% other.Thereligious affiliationofIsraeli Jewsvaries widely: a 2016 survey byPew Researchindicates that 49% self-identify asHiloni(secular), 29% asMasorti(traditional), 13% asDati(religious) and 9% asHaredi(ultra-Orthodox).Haredi Jews are expected to represent over 20% of the Jewish population by 2028.Muslimsconstitute the largest religious minority, making up about 18.1% of the population. About 1.9% of the population isChristian, and 1.6% isDruze.The Christian population comprises primarilyArab ChristiansandAramean Christiansbut also includes post-Soviet immigrants, foreign labourers,Armenian Christians, and followers ofMessianic Judaism, considered by most Christians and Jews to be a form of Christianity.Members of many other religious groups, includingBuddhistsandHindus, maintain a presence in Israel, albeit in small numbers.Out of over one million immigrants from the former Soviet Union, about 300,000 are considered not Jewish by theChief Rabbinate of Israel. Israel comprises a major part of theHoly Land, a region of significant importance to allAbrahamic religions. Jerusalem is ofspecial importanceto Jews, Muslims, and Christians, as it is the home ofsitesthat are pivotal to their religious beliefs, such as theOld Citythat incorporates theWestern Walland theTemple Mount(Al-Aqsa Mosque compound) and theChurch of the Holy Sepulchre.Other locations of religious importance areNazareth(site of theAnnunciationofMary),TiberiasandSafed(two of theFour Holy Citiesin Judaism), theWhite MosqueinRamla(shrine of the prophetSaleh), and theChurch of Saint George and Mosque of Al-Khadr, Lod(tomb ofSaint GeorgeorAl Khidr). A number of other religious landmarks are located in theWest Bank, includingJoseph's Tomb, thebirthplace of Jesus,Rachel's Tomb, and theCave of the Patriarchs. Theadministrative centerof theBaháʼí Faithand theShrine of the Bábare located at theBaháʼí World CentreinHaifa; the leader of the faith isburiedinAcre.TheMahmood Mosqueis affiliated with the reformistAhmadiyyamovement.Kababir, Haifa's mixed neighbourhood of Jews and Ahmadi Arabs, is one of a few of its kind in the country. In 2015, Israelrankedthird among OECD members for the percentage of 25–64-year-olds that have attained tertiary education with 49% compared with the OECD average of 35%.In 2012, the country ranked third in the number of academic degrees per capita (20 percent of the population). Israel has aschool life expectancyof 16 years and aliteracy rateof 97.8%.The State Education Law (1953) established five types of schools: state secular, state religious, ultra orthodox, communal settlement schools, and Arab schools. The public secular is the largest school group and is attended by the majority of Jewish and non-Arab pupils. Most Arabs send their children to schools where Arabic is the language of instruction.Education is compulsory for children between the ages of three and eighteen.Schooling is divided into three tiers—primary school (grades 1–6), middle school (grades 7–9), and high school (grades 10–12)—culminating withBagrutmatriculation exams. Proficiency in core subjects such as mathematics, the Hebrew language, Hebrew and general literature, the English language, history, Biblical scripture and civics is necessary to receive a Bagrut certificate. The Jewish population maintains a relatively high level of educational attainment where just under half of all Israeli Jews (46%) hold post-secondary degrees.Israeli Jews 25 and older have an average 11.6 years of schooling, making them one of the most highly educated of all major religious groups in the world.In Arab, Christian and Druze schools, the exam on Biblical studies is replaced by an exam on Muslim, Christian or Druze heritage, respectively.In 2020, 68.7% of 12th graders earned a matriculation certificate. Israel has a tradition of higher education where its university education has been largely responsible in spurring modern economic development.Israel hasnine public universities subsidised by the state and 49 private colleges.TheHebrew University of Jerusalemhouses theNational Library of Israel, the world's largest repository of Judaica and Hebraica.TheTechnionand the Hebrew University consistently ranked among world's 100 top universities byARWUranking.Other major universities include theWeizmann Institute of Science,Tel Aviv University,Ben-Gurion University of the Negev,Bar-Ilan University, theUniversity of Haifa, and theOpen University of Israel. Cultural diversity stems from its diverse population: Jews from various diaspora communities brought their cultural and religious traditions with them.Arab influencesare present in many cultural spheres,being found inarchitecture,music,andcuisine.Israel is the only country where life revolves around theHebrew calendar, which is aligned to the seasons in the Levant.Public holidaysare determined by theJewish holidays, and except forYom HaAtzma'ut(Independence Day) there are no annual civil holidays. The official day of rest is Saturday, theJewish Sabbath. Israeli literatureis primarilypoetryand prose written in Hebrew, as part of therenaissanceof Hebrew as a spoken language since the mid-19th century, although a small body of literature is published in other languages. By law, two copies of all works published in Israel must be deposited in theNational Library of Israel.In 2016, 89 percent of the 7,300 books transferred to the library were in Hebrew. In 1966,Shmuel Yosef Agnonshared theNobel Prize in Literaturewith German Jewish authorNelly Sachs.Leading poets includeYehuda Amichai,Nathan Alterman,Leah Goldberg, andRachel Bluwstein.Internationally famous contemporary novelists includeAmos Oz,Etgar KeretandDavid Grossman. Israeli musicincludesMizrahiandSephardic music,Hasidicmelodies,Greek music,jazz, andpop rock.TheIsrael Philharmonic Orchestrahas been in operation for over seventy years and performs more than two hundred concerts each year.Itzhak Perlman,Pinchas ZukermanandOfra Hazaare among the internationally acclaimed musicians born in Israel. The countryhas participatedin theEurovision Song Contestnearly every year since 1973, winning it four times and hosting three times.Eilathas hosted its own international music festival, theRed Sea Jazz Festival, every summer since 1987.The nation's canonicalfolk songsare known as \"Songs of the Land of Israel\". Ten Israeli filmshave been final nomineesforBest Foreign Language Filmat theAcademy Awards. Palestinian Israeli filmmakers have made films dealing with the Arab-Israeli conflict and status of Palestinians within Israel, such asMohammed Bakri's 2002 filmJenin, JeninandThe Syrian Bride. Continuing the strong theatrical traditions of theYiddish theatrein Eastern Europe, Israel maintains a vibrant theatre scene. Founded in 1918,Habima Theatrein Tel Aviv is Israel's oldestrepertory theatercompany and national theater.Other theatres includeOhel,the CameriandGesher. Israeli Jewish art has been particularly influenced by theKabbalah, theTalmudand theZohar. Another art movement that held a prominent role in the 20th century was theSchool of Paris. In the late 19th and early 20th century, the Yishuv's art was dominated by art trends emanatingBezalel. Beginning in the 1920s, the local art scene was heavily influenced by modern French art, first introduced byIsaac Frenkel Frenel.Jewish masters of theschool of Paris, such asSoutine,Kikoine,Frenkel,Chagallheavily influenced the subsequent development of Israeli art.Israeli sculpture took inspiration from modernEuropean sculptureas wellMesopotamian,Assyrianand local art.Avraham Melnikov's roaring lion, David Polus' Alexander Zaid andZe'ev Ben Zvi's cubist sculpture exemplify some of the different streams in sculpture. Common themes in art are the mystical cities of Safed and Jerusalem, the bohemian café culture of Tel Aviv, agricultural landscapes, biblical stories and war. Today Israeli art has delved intooptical art,AI art,digital artand the use of salt in sculpture. Due to the immigration of Jewish architects, architecture has come to reflect different styles. In the early 20th century Jewish architects sought to combine Occidental and Oriental architecture producing buildings that showcase a myriad of infused styles.Theeclecticstyle gave way to the modernistBauhausstyle with the influx of German Jewish architects (among themErich Mendelsohn) fleeingNazi persecution.TheWhite City of Tel Avivis aUNESCO heritage site.Following independence, multiple government projects were commissioned, a grand part built in a brutalist style with heavy emphasis on the use of concrete and acclimatisation to the desert climate. Several novel ideas such as theGarden Citywere implemented in Israeli cities; theGeddes planof Tel Aviv became renowned internationally for its revolutionary design and adaptation to the local climate.The design of kibbutzim also came to reflect ideology, such as the planning of the circular kibbutzNahalalbyRichard Kauffmann. TheIsrael Museumin Jerusalem is one of Israel's most important cultural institutions,and houses theDead Sea Scrolls,along with an extensive collection ofJudaicaandEuropean art.Yad Vashem(Hebrew:יָד וַשֵׁם,lit.'a memorial and a name') is the world's centralHolocaustmemorial institution and archive of Holocaust-related information.ANU - Museum of the Jewish Peopleis an interactive museum devoted to the history of Jewish communities around the world. Israel has the highest number of museums per capita.Several museums are devoted to Islamic culture, including theRockefeller Museumand theL. A. Mayer Institute for Islamic Art, both in Jerusalem. The Rockefeller specialises in archaeological remains from Middle East history. It is also the home of the first hominid fossil skull found in West Asia, calledGalilee Man. Media is diverse, reflecting the spectrum of audiences. Notable newspapers include the leftwingHaaretz,centristYedioth Ahronoth,and center-rightIsrael Hayom.There are several major TV channels which cater to different audiences, from Russian-languageChannel 9to Arabic-languageKan 33.The 2024 Freedom House report found Israeli media is \"vibrant and free to criticise government policy\".In the 2024Press Freedom IndexbyReporters Without Borders, Israel was placed 101st of 180 countries, second in the Middle East and North Africa.Reporters Without Borders noted that the Israel Defence Forces had killed more than 100 journalists in Gaza. Since the Gaza war, Israel had been \"trying to suppress the reporting coming out of the besieged enclave while disinformation infiltrates its own media ecosystem\".In May 2024, Israel shut down the local offices ofAl Jazeera.In 2024, according to theCommittee to Protect Journalists, Israel was the second leading country in the world in jailing journalists,while being responsible for the majority of journalists killed in the world. Israeli cuisine includes local dishes as well asJewish cuisinebrought to the country by immigrants. Particularly since the late 1970s, afusion cuisinehas developed.The cuisine has adapted elements of theMizrahi,Sephardi, andAshkenazistyles of cooking. It incorporates many foods traditionally eaten in theLevantine,Arab,Middle EasternandMediterraneancuisines, such asfalafel,hummus,shakshouka,couscous, andza'atar.Schnitzel,pizza,hamburgers,French fries,riceandsaladare common.Ptitim(Israeli couscous) is a notable Israeli food invented in the 1950s due to rice shortages during theausterity period. Roughly half of the Jewish population attests to keepingkosherat home.Kosher restaurantsmake up around a quarter of the total as of 2015.Pork—often called \"white meat\" in Israel—is produced and consumed despite attempts to ban it;it is forbiddenby both Judaism and Islam but is permitted by Christianity and mostly produced in traditionally Christian areas of northern Israel.Other non-kosher foods produced and eaten in Israel include rabbits, ostriches, and non-kosher fish. The most popular spectator sports in Israel are association football and basketball.TheIsraeli Premier Leagueis the country's premier football league, and theIsraeli Basketball Premier Leagueis the premier basketball league.Maccabi Haifa,Maccabi Tel Aviv,Hapoel Tel AvivandBeitar Jerusalemare the largestfootball clubs. Maccabi Tel Aviv, Maccabi Haifa and Hapoel Tel Aviv have competed in theUEFA Champions Leagueand Hapoel Tel Aviv reached theUEFA Cupquarter-finals. Israel hosted and won the1964 AFC Asian Cup; in 1970 theIsrael national football teamqualified for theFIFA World Cup, the only time it participated. The1974 Asian Games, held in Tehran, were the last Asian Games in which Israelparticipated, plagued by Arab countries thatrefused to competewith Israel. Israel was excluded from the1978 Asian Gamesand since then has not competed in Asian sport events.In 1994,UEFAagreed to admit Israel, and its football teams now compete in Europe.Maccabi Tel Aviv B.C.has won theEuropean championshipin basketball six times. Israel has won20 Olympic medalssince its first winin 1992, including a gold medal inwindsurfingat the2004 Summer Olympics,and seven medals at the 2024 Paris Olympics alone.Israel has wonover 100gold medals in theParalympic Gamesand is ranked 20th in theall-time medal count. The1968 Summer Paralympicswere hosted by Israel.TheMaccabiah Games, an Olympic-style event forJewishand Israeli athletes, was inaugurated in the 1930s, and has been held every four years since.Krav Maga, a martial art developed by Jewish ghetto defenders, is used by the Israeli security forces and police. Chess is a leading sport. There are many Israeli grandmasters andIsraeli chess playershave won a number of youth world championships.Israel stages an annual internationalchampionshipand hosted theWorld Team Chess Championshipin 2005. Israeli settlementsTimeline,International law West BankJudea and Samaria Area Gaza StripHof Aza Regional Council 31°N35°E﻿ / ﻿31°N 35°E﻿ /31; 35", "combined_text": "Israel Contents Etymology History Prehistory Bronze and Iron Ages Classical antiquity Late antiquity and the medieval period Modern period and the emergence of Zionism British Mandate for Palestine State of Israel Geography Tectonics and seismicity Climate Government and politics Administrative divisions Israeli citizenship law Israeli-occupied territories Foreign relations Military Legal system Economy Science and technology Energy Transport Tourism Real estate Demographics Major urban areas Language Religion Education Culture Literature Music and dance Cinema and theatre Visual arts Architecture Museums Mass media Cuisine Sports See also References Notes Citations Sources External links   Israel,officially theState of Israel,is a country in theSouthern Levantregion ofWest Asia. ItbordersLebanonto the north,Syriato the northeast,Jordanto the east andEgyptto the southwest.Israel occupiesthePalestinian territoriesof theWest Bankin the east and theGaza Stripin the southwest, as well as the SyrianGolan Heightsin the northeast. Israel'swestern coastlies on theMediterranean Sea, the southernmost point reaches theRed Sea, and the east includes part of theDead Sea.Jerusalemis the government seat andproclaimed capital,whileTel Avivis the country'slargest urban areaandeconomic centre. TheLand of Israelis synonymous withPalestine,Judaea, or theHoly Land. Inantiquityit was home to theCanaanitesand later thekingdoms of Israel and Judah. Its location at acontinental crossroadsbroughtdemographic shiftsunder various empires. Nineteenth-centuryEuropean antisemitismfuelled theZionistmovement for aJewish homeland. Britain endorsed this goal in the 1917Balfour Declarationand ruledMandatory Palestinefrom 1920.Jewish immigrationandBritish policiesintensifiedArab-Jewish tensions,and the 1947United Nations(UN)Partition Plan for Palestineled toa civil war. Israeldeclared independenceat theend of the British Mandateon 14 May 1948, and neighbouringArab statesinvadedthe next day. A1949 armisticeleft Israel with territory beyond the UN plan;no Arab state was created, as theGaza Stripand theWest Bankcame under Egyptian and Jordanian control.MostPalestinian Arabsfled or were expelledbyZionist militiasin anethnic cleansingknown as theNakba, withthose who stayedbecoming Israel's main minority.TheJewish exodus from the Muslim worldincreasedthe country's populationin subsequent decades.After the 1967Six-Day War, Israel occupied the West Bank, Gaza Strip, the EgyptianSinai, and the SyrianGolan Heights, later annexingEast Jerusalemand the Golan—actions that, along withsettlementexpansion, are consideredviolations of international law. Peace was signedwith Egyptin 1979 (Sinai returned in 1982) andwith Jordanin 1994. The 1993Oslo Accordswith the Palestinians established mutual recognition and limited self-rule, and the 2020Abraham Accordsnormalisedties with more Arab states. TheIsraeli–Palestinian conflictremainsunresolved, withwarsand clashes withPalestinian militant groups. Israel is committing agenocide in Gaza, and its occupation of the Palestinian territories has drawn sustained internationalcriticism; experts, human-rights organisations and UN officials have described them aswar crimesandcrimes against humanity. TheBasic Laws of Israelestablish theKnesset, aparliamentelected byproportional representation. It shapes thegovernment, led by theprime minister, and elects the largely ceremonialpresident.Israel has one of the Middle East's largest economies,one of Asia's highest living standards, and globally ranks26th in nominal GDPand14th in nominal GDP per capita.Technologically advanced, Israel allocates a larger share of its economy to research and developmentthan any other stateand is believed topossess nuclear weapons. Theculture of IsraelcombinesJewish traditions, including those ofthe diaspora, withArabinfluences. The names Land of Israel andChildren of Israelhave historically been used to refer to the biblicalKingdom of Israeland the entireJewishpeople respectively. ThenameIsrael(Hebrew:Yīsrāʾēl;SeptuagintAncient Greek:Ἰσραήλ,Israēl, \"El (God)persists/rules\") refers to the patriarchJacobwho, according to theHebrew Bible, was given the name after he successfullywrestledwith theAngel of the Lord.The earliest known archaeological artefact to mention the wordIsraelas a collective is theMerneptah Steleofancient Egypt(dated to the late-13th century BCE). Under theBritish Mandate(1920–1948), the entire region was known asPalestine.Uponestablishment in 1948, the country formally adopted the nameState of Israel(Hebrew:מְדִינַת יִשְׂרָאֵל,Medīnat Yisrā'el[mediˈnatjisʁaˈʔel];Arabic:دَوْلَة إِسْرَائِيل,Dawlat Isrāʼīl,[dawlatʔisraːˈʔiːl]) after otherproposed namesincludingLand of Israel(Eretz Israel),Ever(from ancestorEber),Zion, andJudea, were considered but rejected.The nameIsraelwas suggested byDavid Ben-Gurionand passed by a vote of 6–3.In the early weeks after establishment, the government chose the termIsraelito denote a citizen of the state. TheUbeidiya prehistoric sitein northern Israel shows thepresence of archaic humansaround 1.5 million years ago.The second-oldest evidence ofanatomically modern humansoutside Africais a 200,000-year-old fossil fromMisliya Caveon Mount Carmel.TheNatufian culture(c.10,000 BCE) may be linked to theProto-Afroasiatic languageand is notable for adoptingsedentismbefore theadvent of agricultureand theNeolithic Revolution. Early references to \"Canaan\" and \"Canaanites\" appear in ancientNear EasternandEgyptiantexts (c.2000 BCE); these populations were structured as politically independentcity-states.During theLate Bronze Age(1550–1200 BCE), large parts of Canaan formedvassal statesof theNew Kingdom of Egypt.As a result of theLate Bronze Age collapse, Canaan fell into chaos, and Egyptian control over the region collapsed.Ancestors of theIsraelitesare thought to have includedancient Semitic-speaking peoplesnative to this area.Modern archaeological accounts suggest that the Israelites and their culture branched out of the Canaanite peoples through the development of a distinctmonolatristic—and latermonotheistic—religion centered onYahweh.They spoke an archaic form ofHebrew, known asBiblical Hebrew.Around the same time, thePhilistinessettled on the southerncoastal plain. Most modern scholars agree that theExodusnarrative in theTorahandOld Testamentdid not take place as depicted; however, some elements of these traditions do havehistorical roots.There is debate about the earliest existence of theKingdoms of Israel and Judahand their extent and power. While it is unclear if there was aUnited Kingdom of Israel,historians and archaeologists agree that the northernKingdom of Israelexisted byca.900 BCEand theKingdom of Judahbyca.850 BCE.The Kingdom of Israel was the more prosperous of the two and soon developed into a regional power, with a capital atSamaria;during theOmride dynasty, it controlledSamaria,Galilee, the upperJordan Valley, theplain of Sharonand large parts ofTransjordan. The Kingdom of Israel was conquered around 720 BCE by theNeo-Assyrian Empire.The Kingdom of Judah, underDavidicrule with its capital inJerusalem, later became aclient stateof first the Neo-Assyrian Empire and then theNeo-Babylonian Empire. It is estimated thatthe region's populationwas around 400,000 in theIron Age II.In 587/6 BCE, following arevolt in Judah, KingNebuchadnezzar IIbesieged and destroyed JerusalemandSolomon's Temple,dissolved the kingdom andexiled much of the Judean elite to Babylon. Aftercapturing Babylonin 539 BCE,Cyrus the Great, founder of theAchaemenid Empire, issueda proclamationallowing the exiled Judean population to return.The construction of theSecond Templewas completedc.520 BCE.The Achaemenids ruled the region as the province ofYehud Medinata.In 332 BCE,Alexander the Greatconquered the region as part of hiscampaign against the Achaemenid Empire. After his death, the area was controlled by thePtolemaicandSeleucidempires as a part ofCoele-Syria. Over the ensuing centuries, theHellenisationof the region led to cultural tensions that came to a head during the reign ofAntiochus IV, giving rise to theMaccabean Revoltof 167 BCE. The civil unrest weakened Seleucid rule, and in the late 2nd century the semi-autonomousHasmonean Kingdom of Judeaarose, eventually attaining full independence and expanding into neighbouring regions. TheRoman Republicinvaded the region in 63 BCE, firsttaking control of Syria, and then intervening in theHasmonean civil war.The strugglebetween pro-Roman and pro-Parthianfactions in Judea led to the installation ofHerod the Greatas adynastic vassalofRome. In 6 CE, the area was annexed as theRoman province of Judaea; tensions with Roman rule led to a series ofJewish–Roman wars, resulting in widespread destruction. TheFirst Jewish–Roman War(66–73 CE) resulted in thedestruction of Jerusalem and the Second Templeand a sizable portion of the population being killed or displaced. A second uprising known as theBar Kokhba revolt(132–136 CE) initially allowed the Jews to form an independent state, but the Romans brutally crushed the rebellion, devastating and depopulating Judea's countryside.Jerusalem was rebuilt as aRoman colony(Aelia Capitolina), and the province of Judea was renamedSyria Palaestina.Jews were expelled from the districts surrounding Jerusalem.Nevertheless, there was a continuous small Jewish presence, and Galilee became its religious center. During theByzantine period,Early ChristianitydisplacedRoman paganismin the 4th century CE, withConstantineembracing and promoting the Christian religion andTheodosius Imaking itthe state religion. A series of laws were passed that discriminated against Jews and Judaism, and Jews were persecuted by both the church and the authorities.Many Jews had emigrated to flourishingdiasporacommunities,while locally there was both Christian immigration and local conversion. By the middle of the 5th century, there was a Christian majority.Towards the end of the 5th century,Samaritan revoltserupted, continuing until the late 6th century and resulting in a large decrease in the Samaritan population.After theSasanian conquest of Jerusalemand the short-livedJewish revolt against Heracliusin 614 CE, the Byzantine Empirereconsolidated control of the areain 628. In 634–641 CE, theRashidun Caliphateconquered the Levant.CaliphUmar ibn al-Khattab(r.634–644) lifted the Christian ban on Jews enteringJerusalemand permitted them to worship there.Over the next six centuries, control of the region transferred between theUmayyad,Abbasid, andFatimidcaliphates, and subsequently theSeljukandAyyubiddynasties.The population drastically decreased during the following several centuries, dropping from an estimated 1 million during Roman and Byzantine periods to about 300,000 by the earlyOttoman period, and there was steadyArabisationandIslamisation.The end of the 11th century brought theCrusades,papally-sanctioned incursions of Christian crusaders intent on wresting Jerusalem and theHoly Landfrom Muslim control and establishingcrusader states.The Ayyubids pushed back the crusaders before Muslim rule was fully restored by theMamluk sultans of Egyptin 1291. In 1516, the Ottoman Empire conquered the region and ruled it as part ofOttoman Syria.Two violent incidents took place against Jews, the1517 Safed attacksand the1517 Hebron attacks, after the Turkish Ottomans ousted theMamluksduring theOttoman–Mamluk War.Under the Ottoman Empire, the Levant was fairly cosmopolitan, with religious freedoms forChristians, Muslims, and Jews. In 1561 theOttoman sultaninvitedSephardi Jewsescaping theSpanish Inquisitionto settle in and rebuild the city ofTiberias. Under the Ottoman Empire'smillet system, Christians and Jews were considereddhimmi(\"protected\") underOttoman lawin exchange for loyalty to the state and payment of thejizyatax.Non-Muslim Ottoman subjects faced geographic and lifestyle restrictions, though these were not always enforced.The millet system organised non-Muslims into autonomous communities on the basis of religion. Theconcept of the \"return\"remained a symbol within religious Jewish belief which emphasised that their return should be determined by Divine Providence rather than human action.Leading Zionist historianShlomo Avineridescribes this connection: \"Jews did not relate to the vision of the Return in a more active way than most Christians viewed theSecond Coming.\" The religious Judaic notion of being a nation was distinct from the modern European notion of nationalism.The Jewish population of Palestine from the Ottoman rule to the beginning of the Zionist movement, known as theOld Yishuv, comprised a minority and fluctuated in size. During the 16th century, Jewish communities struck roots in theFour Holy Cities—Jerusalem, Tiberias,Hebron, andSafed—and in 1697, Rabbi Yehuda Hachasid led 1,500 Jews to Jerusalem.A 1660Druze revoltagainst the Ottomans destroyedSafedandTiberias.In the second half of the 18th century, Eastern European Jews who wereopponentsofHasidism, known as thePerushim, settled in Palestine. In the late 18th century, local Arab SheikhZahir al-Umarcreated a de facto independent emirate in the Galilee. Ottoman attempts to subdue the sheikh failed. After Zahir's death the Ottomans regained control of the area. In 1799, governorJazzar Pasharepelled anassault on AcrebyNapoleon's troops, prompting the French to abandon the Syrian campaign.In 1834, arevolt by Palestinian Arab peasantsagainst Egyptian conscription and taxation policies underMuhammad Aliwas suppressed; Muhammad Ali's army retreated and Ottoman rule was restored with British support in 1840.TheTanzimatreforms were implemented across the Ottoman Empire. The first wave of modern Jewish migration toOttoman-ruled Palestine, known as theFirst Aliyah, began in 1881, as Jews fledpogromsin Eastern Europe.The 1882May Lawsincreased economic discrimination against Jews, and restricted where they could live.In response, politicalZionismtook form, a movement that sought to establish aJewish statein Palestine, thus offering a solution to theJewish questionof the European states.Antisemitism, pogroms and official policies in tsarist Russia led to the emigration of three million Jews in the years between 1882 and 1914, only 1% of whom went to Palestine. Those who went to Palestine were driven primarily by ideas of self-determination and Jewish identity, rather than as a response to pogroms or economic insecurity. TheSecond Aliyah(1904–1914) began after theKishinev pogrom; some 40,000 Jews settled in Palestine, although nearly half left eventually. Both the first and second waves of migrants were mainlyOrthodox Jews.The Second Aliyah includedZionist socialistgroups who established thekibbutzmovement based on the idea of establishing a separate Jewish economy based exclusively on Jewish labour.Those of the Second Aliyah who became leaders of theYishuvin the coming decades believed that the Jewish settler economy should not depend on Arab labour. This would be a dominant source of antagonism with the Arab population, with the new Yishuv's nationalist ideology overpowering its socialist one.Though the immigrants of the Second Aliyah largely sought to create communal Jewish agricultural settlements,Tel Avivwas established as the first planned Jewish town in 1909. Jewish armed militias emerged during this period, the first beingBar-Giorain 1907. Two years later, the largerHashomerorganisation was founded as its replacement. Chaim Weizmann's efforts to garner British support for the Zionist movement eventually secured theBalfour Declarationof 1917,stating Britain's support for the creation of a Jewish \"national home\" in Palestine.Weizmann's interpretation of the declaration was that negotiations on the future of the country were to happen directly between Britain and the Jews, excluding Arabs.Jewish-Arab relationsin Palestine deteriorated dramatically in the following years. In 1918, theJewish Legion, primarily Zionist volunteers, assisted in the Britishconquest of Palestine.In 1920, the territory was divided between Britain and France under themandate system, and the British-administered area (including modern Israel) was namedMandatory Palestine.Arab opposition to British rule and Jewish immigration led to the1920 Palestine riotsand the formation of a Jewish militia known as theHaganahas an outgrowth of Hashomer, from which theIrgunandLehiparamilitaries later split.In 1922, theLeague of Nationsgranted Britain theMandate for Palestineunder terms which included the Balfour Declaration with its promise to the Jews and with similar provisions regarding the Arab Palestinians.Thepopulation of the areawas predominantly Arab and Muslim, with Jews accounting for about 11%and Arab Christians about 9.5% of the population. TheThird(1919–1923) andFourth Aliyahs(1924–1929) brought an additional 100,000 Jews to Palestine. Therise of Nazismand the increasing persecution of Jews in 1930s Europe led to theFifth Aliyah, with an influx of a quarter of a million Jews. This was a major cause of theArab revolt of 1936–39, which was suppressed by British security forces and Zionist militias. Several hundred British security personnel and Jews were killed; 5,032 Arabs were killed, 14,760 wounded, and 12,622 detained.An estimated ten percent of the adult malePalestinian Arabpopulation was killed, wounded, imprisoned, or exiled. The British introduced restrictions on Jewish immigration to Palestine with theWhite Paper of 1939. With countries around the world turning away Jewish refugees fleeingthe Holocaust, a clandestine movement known asAliyah Betwas organised to bring Jews to Palestine. By the end ofWorld War II, 31% of the population of Palestine was Jewish.The UK found itself facing aJewish insurgencyover immigration restrictions and continued conflict with the Arab community over limit levels. The Haganah joined Irgun and Lehi in an armed struggle against British rule.The Haganah attempted to bring tens of thousands of Jewish refugees andHolocaust survivorsto Palestine by ship. Most of the ships were intercepted by theRoyal Navyand the refugees placed in detention camps inAtlitandCyprus. On 22 July 1946, Irgunbombed the British administrative headquartersfor Palestine, killing 91.The attack was a response toOperation Agatha(a series of raids, including one on theJewish Agency, by the British) and was the deadliest directed at the British during the Mandate era.The Jewish insurgency continued throughout 1946 and 1947 despite concerted efforts by the British military andPalestine Police Forceto suppress it. British efforts to mediate with Jewish and Arab representatives also failed as the Jews were unwilling to accept any solution that did not involve a Jewish state and suggested a partition of Palestine into Jewish and Arab states, while the Arabs were adamant that a Jewish state in any part of Palestine was unacceptable and that the only solution was a unified Palestine under Arab rule. In February 1947, the British referred the Palestine issue to the newly formedUnited Nations. On 15 May 1947, theUN General Assemblyresolved that aSpecial Committeebe created \"to prepare ... a report on the question of Palestine\".The Report of the Committeeproposed a planto replace the British Mandate with \"an independent Arab State, an independent Jewish State, and the City of Jerusalem [...] the last to be under an International Trusteeship System\".Meanwhile, the Jewish insurgency continued and peaked in July 1947, with a series of widespread guerrilla raids culminating inthe Sergeants affair, in which the Irgun took two British sergeants hostage as attempted leverage against the planned execution of three Irgun operatives. After the executions were carried out, the Irgun killed the two British soldiers, hanged their bodies from trees, and left a booby trap at the scene which injured a British soldier. The incident caused widespread outrage in the UK.In September 1947, the British cabinet decided to evacuate Palestine as the Mandate was no longer tenable. On 29 November 1947, the General Assembly adoptedResolution 181 (II).The plan attached to the resolution was essentially that proposed in the report of 3 September. The Jewish Agency, the recognised representative of the Jewish community, accepted the plan, which assigned 55–56% of Mandatory Palestine to the Jews. At the time, the Jews were about a third of the population and owned around 6–7% of the land. Arabs constituted the majority and owned about 20% of the land, with the remainder held by the Mandate authorities or foreign landowners.TheArab LeagueandArab Higher Committeeof Palestine rejected it on the basis that the partition plan privileged European interests over those of the Palestinians,and indicated that they would reject any other plan of partition.On 1 December 1947, the Arab Higher Committee proclaimed a three-day strike, andriots broke out in Jerusalem.The situation spiralled intoa civil war. Colonial SecretaryArthur Creech Jonesannounced that the British Mandate would end on 15 May 1948, at which point the British would evacuate. As Arab militias and gangs attacked Jewish areas, they were faced mainly by the Haganah as well as the smaller Irgun and Lehi. In April 1948, the Haganah moved onto the offensive. On 14 May 1948, the day before the expiration of the British Mandate,David Ben-Gurion, the head of the Jewish Agency, declared \"the establishment of a Jewish state in Eretz-Israel\".The following day, the armies of four Arab countries—Egypt, Syria, Transjordan, and Iraq—entered what had been Mandatory Palestine, launching the1948 Arab–Israeli War;contingents fromYemen,Morocco,Saudi Arabia, andSudanjoined the war.The purpose of the invasion was to prevent the establishment of the Jewish state.The Arab League stated the invasion was to restore order and prevent further bloodshed. After a year of fighting, aceasefire was declaredand temporary borders, known as theGreen Line, were established.Jordan annexedwhat became known as theWest Bank, includingEast Jerusalem, andEgypt occupiedtheGaza Strip. Over 700,000 Palestiniansfled or were expelledbyZionist militiasand theIsraeli military—what would become known in Arabic as thenakba('catastrophe').The events also led to the destruction of most of Palestine's Arabculture,identity, andnational aspirations. Some 156,000 Arabs remained and becameArab citizens of Israel. ByUnited Nations General Assembly Resolution 273, Israel was admitted as a member of the UN on 11 May 1949.In the early years of the state, theLabour Zionistmovement led by Prime Minister Ben-Gurion dominatedIsraeli politics.Immigration to Israel during the late 1940s and early 1950s was aided by the Israeli Immigration Department and the non-government sponsoredMossad LeAliyah Bet(lit.\"Institute forImmigration B\").The latter engaged in clandestine operations in countries, particularly in the Middle East and Eastern Europe, where the lives of Jews were in danger and exit was difficult. Mossad LeAliyah Bet was disbanded in 1953.The immigration was in accordance with theOne Million Plan. Some immigrants held Zionist beliefs or came for the promise of a better life, while others moved to escape persecution or were expelled from their homes. Aninflux of Holocaust survivorsandJews from Arab and Muslim countriesto Israel during the first three years increased the number of Jews from 700,000 to 1,400,000. By 1958, the population had risen to two million.Between 1948 and 1970, approximately 1,150,000 Jewish refugees relocated to Israel.Some immigrants arrived as refugees and were housed in temporary camps known asma'abarot; by 1952, over 200,000 people were living in these tent cities.Jews of European backgroundwere often treated more favourably than Jews fromMiddle EasternandNorth Africancountries—housing units reserved for the latter were often re-designated for the former, so Jews newly arrived from Arab lands generally ended up staying longer in transit camps.During this period, food, clothes and furniture were rationed in what became known as theausterity period. The need to solve the crisis led Ben-Gurion to sign areparations agreement with West Germanythat triggered mass protests by Jews angered at the idea that Israel could accept monetary compensation for the Holocaust. During the 1950s, Israel wasfrequently attackedbyPalestinian fedayeen, nearly always against civilians,mainly from the Egyptian-occupied Gaza Strip,leading to several Israelireprisal operations. In 1956, the UK and France aimed at regaining control of theSuez Canal, which Egypt had nationalised. The continued blockade of the Suez Canal andStraits of Tiranto Israeli shipping, together with increasing fedayeen attacks against Israel's southern population and recent Arab threatening statements, prompted Israel to attack Egypt.Israel joineda secret alliancewith the UK and France and overran theSinai Peninsulain theSuez Crisisbut was pressured to withdraw by the UN in return for guarantees of Israeli shipping rights.The war resulted in significant reduction of Israeli border infiltration. In the early 1960s, Israel captured Nazi war criminalAdolf Eichmannin Argentina and brought him to Israelfor trial.Eichmann remains the only person executed in Israel by conviction in an Israeli civilian court.In 1963, Israel was engaged in a diplomatic standoff with the United States in relation to the Israelinuclear programme. Since 1964 Arab countries, concerned over Israeli plans to divert waters of theJordan Riverinto thecoastal plain,had been trying to divert the headwaters to deprive Israel of water resources,provoking tensionsbetween Israel on the one hand, and Syria and Lebanon on the other.Arab nationalistsled by Egyptian PresidentGamal Abdel Nasserrefused to recognise Israel and called for its destruction.By 1966 Israeli-Arab relations had deteriorated to the point of battles taking place between Israeli and Arab forces. In May 1967, Egypt massed its army near the border with Israel, expelledUN peacekeepers stationed in the Sinai Peninsulasince 1957, and blocked Israel's access to the Red Sea.Other Arab states mobilised their forces.Israel reiterated that these actions were acasus belliand launched a pre-emptive strike (Operation Focus) against Egypt in June. Jordan, Syria and Iraq attacked Israel. In theSix-Day War, Israel captured and occupied the West Bank from Jordan, the Gaza Strip and Sinai Peninsula from Egypt, and the Golan Heights from Syria.Jerusalem's boundaries were enlarged, incorporating East Jerusalem. The 1949 Green Line became the administrative boundary between Israel and theoccupied territories. Following the 1967 war and the \"Three Nos\" resolution of the Arab League, Israel faced attacks from the Egyptians in the Sinai Peninsula during the 1967–1970War of Attrition, and from Palestinian groups targeting Israelis in the occupied territories, globally, and in Israel. Most important among the Palestinian and Arab groups was thePalestine Liberation Organisation(PLO), established in 1964, which initially committed itself to \"armed struggle as the only way to liberate the homeland\".In the late 1960s and early 1970s,Palestinian groups launched attacksagainst Israeli and Jewish targets around the world,includinga massacre of Israeli athletesat the1972 Summer Olympicsin Munich. The Israeli government responded with anassassination campaignagainst the organisers of the massacre,a bombingand araid on the PLO headquarters in Lebanon. On 6 October 1973, the Egyptian and Syrian armies launcheda surprise attackagainst Israeli forces in the Sinai Peninsula and Golan Heights, opening theYom Kippur War. The war ended on 25 October with Israel repelling Egyptian and Syrian forces but suffering great losses.Aninternal inquiryexoneratedthe governmentof responsibility for failures before and during the war, but public anger forced Prime MinisterGolda Meirto resign.In July 1976, an airliner was hijacked in flight from Israel to France by Palestinian guerrillas; Israeli commandosrescued 102 of 106 Israeli hostages. The1977 Knesset electionsmarked a major turning point in Israeli political history asMenachem Begin'sLikudparty took control from theLabour Party.Later that year, Egyptian PresidentAnwar El Sadatmade a trip to Israel and spoke before theKnessetin what was the first recognition of Israel by an Arab head of state.Sadat and Begin signed theCamp David Accords(1978) and theEgypt–Israel peace treaty(1979).In return, Israel withdrew from the Sinai Peninsula and agreed to enter negotiations over autonomy for Palestinians in the West Bank and the Gaza Strip. On 11 March 1978, a PLO guerilla raid from Lebanon led to theCoastal Road massacre. Israel responded by launching aninvasion of southern Lebanonto destroy PLO bases. Begin's government meanwhile provided incentives forIsraelis to settlein theoccupied West Bank, increasing friction with the Palestinians there. The 1980Jerusalem Lawwas believed by some to reaffirm Israel's 1967 annexation of Jerusalem by government decree andreignited international controversyover thestatus of the city. No Israeli legislation has defined the territory of Israel, and no act specifically included East Jerusalem therein.In 1981 Israeleffectively annexedthe Golan Heights.The international community largely rejected these moves, with the UN Security Council declaring both the Jerusalem Law and the Golan Heights Law null and void.Several waves ofEthiopian Jewsimmigrated to Israelsince the 1980s, while between 1990 and 1994,immigration from the post-Soviet statesincreased Israel's population by twelve percent. On 7 June 1981, during theIran–Iraq War, theIsraeli air force destroyedIraq's sole nuclear reactor, then under construction, in order to impede the Iraqi nuclear weapons programme.Following a series of PLO attacks in 1982, Israelinvaded Lebanonto destroy the PLO bases.In the first six days, Israel destroyed the military forces of the PLO in Lebanon and decisively defeated the Syrians. An Israeli government inquiry (theKahan Commission) held Begin and several Israeli generals indirectly responsible for theSabra and Shatila massacreand helddefence ministerAriel Sharonas bearing \"personal responsibility\".Sharon was forced to resign.In 1985, Israel responded to a Palestinianterrorist attack in Cyprusbybombing the PLO headquartersin Tunisia. Israel withdrew from most of Lebanon in 1986 but continued tooccupy a borderland buffer zonein southern Lebanon until 2000, from where Israeli forcesengaged in conflictwithHezbollah. TheFirst Intifada, a Palestinian uprising against Israeli rule,broke out in 1987, with waves of uncoordinated demonstrations and violence in the occupied West Bank and Gaza. Over the following six years, the intifada became more organised and included economic and cultural measures aimed at disrupting the Israeli occupation. Over 1,000 people were killed.During the 1991Gulf War, the PLO supportedSaddam Husseinand Iraqi missileattacks against Israel. Despite public outrage, Israel heeded American calls to refrain from hitting back. In 1992,Yitzhak Rabinbecame prime minister followingan electionin which his party called for compromise with Israel's neighbours.The following year,Shimon Pereson behalf of Israel andYasser Arafatfor the PLO signed theOslo Accords, which gave thePalestinian National Authority(PNA) the right to governparts of the West Bankand the Gaza Strip.The PLO alsorecognised Israel's right to existand pledged an end to terrorism.In 1994, theIsrael–Jordan peace treatywas signed, making Jordan the second Arab country to normalise relations with Israel.Arab public support for the Accords was damaged by the continuation of Israeli settlementsandcheckpoints, and the deterioration of economic conditions.Israeli public support for the Accords waned afterPalestinian suicide attacks.In November 1995, Rabinwas assassinatedbyYigal Amir, a far-right Jew who opposed the Accords. DuringBenjamin Netanyahu's premiership at the end of the 1990s, Israelagreed to withdrawfromHebron,though this was never ratified or implemented,and he signed theWye River Memorandum. The agreement dealt with further redeployments in the West Bank and security issues. The memorandum was criticised by major international human rights organisations for its \"encouragement\" of human rights abuses.Ehud Barak,electedprime minister in 1999, withdrew forces from southern Lebanon and conducted negotiations with PNA Chairman Yasser Arafat and U.S. PresidentBill Clintonat the2000 Camp David Summit. Barak offered a plan for the establishment of aPalestinian state, including the entirety of the Gaza Strip and over 90% of the West Bank with Jerusalem as a shared capital.Each side blamed the other for the failure of the talks. In late 2000, after a controversial visit by Sharon to theTemple Mount, theSecond Intifadabegan. The popular uprising faced disproportionate repression from the Israeli state.Palestinian suicide bombingseventually developed into a recurrent feature of the intifada.Some commentators contend that the intifada was pre-planned by Arafat after the collapse of peace talks.Sharon became prime minister in a2001 election; he carried out his plan tounilaterally withdrawfrom the Gaza Strip and spearheaded the construction of theWest Bank barrier,ending the intifada.Between 2000 and 2008, 1,063 Israelis, 5,517 Palestinians and 64 foreign citizens were killed. In July 2006, a Hezbollah artillery assault on Israel's northern border communities and across-border abductionof two Israeli soldiers precipitated the month-longSecond Lebanon War, including an Israeli invasion of Lebanon.The war wound down in August 2006 after the passage ofUnited Nations Security Council Resolution 1701; Israeli forces mostly withdrew from Lebanon by October 2006 but continued to occupy the Lebanese portion ofGhajarvillage.In 2007 the Israeli Air Forcedestroyed a nuclear reactorin Syria. In 2008,a ceasefirebetweenHamasand Israel collapsed, resulting in the three-weekGaza War.In what Israel described as a response toover a hundred Palestinian rocket attackson southern Israeli cities,Israel beganan operation in the Gaza Stripin 2012, lasting eight days.Israel started anotheroperation in Gazafollowing an escalation of rocket attacks by Hamas in July 2014.In May 2021, anotherround of fightingtook place in Gaza and Israel, lasting eleven days.By the 2010s,increasing regional cooperationbetween Israel andArab Leaguecountries have been established, culminating in the signing of theAbraham Accords. The Israeli security situation shifted from the traditionalArab–Israeli conflicttowards theIran–Israel proxy conflictanddirect confrontation with Iran during the Syrian civil war. On 7 October 2023, Palestinian militant groups from Gaza, led by Hamas, launcheda series of coordinated attackson Israel, leading to the start of theGaza war.On that day, approximately 1,300 Israelis, predominantly civilians, were killed in communities near the Gaza Strip border andduring a music festival.Over 200 hostageswere kidnapped and taken to the Gaza Strip. After clearing militants from its territory, Israel launchedone of the most destructive bombing campaigns in modern historyandinvaded Gazaon 27 October with the stated objectives of destroying Hamas and freeing hostages.The fifth war of theGaza–Israel conflictsince 2008, it has been the deadliest for Palestinians in the entireIsraeli–Palestinian conflictand the most significant military engagement in the region since theYom Kippur Warin 1973.AUnited Nations Special Committee,multiple governments, and various experts and human rights organisations have concluded that Israel is committinggenocide against the Palestinian peopledue to the harm and loss of life inflicted on civilians during theGaza War. In April 2024, Israel initiated a wave of airstrikes to Iran, after Iranian strikes targeted Israel. In October 2024, Israelinvaded Lebanonand exchanged missile barrages with Iran three weeks later, in response of Iranian strikes earlier in that month.After nearly a year of theIsrael–Hezbollah conflictfrom October 2023 due to Hezbollah shooting rockets at Israel to support Hamas in Gaza, IsraelassassinatedHezbollah secretary generalHassan Nasrallahin September 2024.A November 2024ceasefire agreementinstructed Israel to withdraw from Lebanon, which Israel mostly did by February 2025, but against the agreement Israeli forces stayed in five military outposts on highlands in Southern Lebanon.In June 2025, Israel launched a renewed series of missile strikes on Iran, which escalated into anarmed conflict. Israel is located in theLevantarea of theFertile Crescent. At theeastern endof theMediterranean Sea, it is bounded by Lebanon to the north, Syria to the north-east, Jordan and the West Bank to the east, and Egypt and the Gaza Strip to the south-west. It lies between latitudes29°and34° N, and longitudes34°and36° E. The sovereign territory of Israel (according to the demarcation lines of the1949 Armistice Agreementsand excluding all territories captured by Israel during the 1967 Six-Day War) is approximately 20,770 square kilometers (8,019 sq mi), of which two percent is water.However Israel is so narrow (100 km at its widest, compared to 400 km from north to south) that theexclusive economic zonein the Mediterranean is double the land area of the country.The total area under Israeli law, including East Jerusalem and the Golan Heights, is 22,072 square kilometers (8,522 sq mi),and the total area under Israeli control, including the military-controlled and partially Palestinian-governed territory of the West Bank, is 27,799 square kilometers (10,733 sq mi). Despite its small size, Israel is home to a variety of geographic features, from theNegevdesert in the south to the inland fertileJezreel Valley, with mountain ranges of theGalilee,Carmeland towards theGolanin the north. TheIsraeli coastal plainon the shores of the Mediterranean is home to most of the population.East of the central highlands lies theJordan Rift Valley, a small part of the 6,500-kilometer (4,039 mi)Great Rift Valley. TheJordan Riverruns along the Jordan Rift Valley, fromMount Hermonthrough theHulah Valleyand theSea of Galileeto theDead Sea, thelowest pointon the surface of the Earth.Further south is theArabah, ending with theGulf of Eilat, part of theRed Sea.Makhtesh, or \"erosion cirques\" are unique to the Negev and theSinai Peninsula, the largest being theMakhtesh Ramonat 38 km in length.Israel has the largest number of plant species per square meter of the countries in the Mediterranean Basinand contains four terrestrial ecoregions:Eastern Mediterranean conifer–sclerophyllous–broadleaf forests,Southern Anatolian montane conifer and deciduous forests,Arabian Desert, andMesopotamian shrub desert.Forests accounted for 8.5% of the area in 2016, up from 2% in 1948, as the result of a large-scale forest planting programme by theJewish National Fund. The Jordan Rift Valley is the result of tectonic movements within theDead Sea Transform(DST) fault system. The DST forms thetransform boundarybetween theAfrican Plateto the west and theArabian Plateto the east. The Golan Heights and all of Jordan are part of the Arabian Plate, while the Galilee, West Bank, Coastal Plain, and Negev along with the Sinai Peninsula are on the African Plate. This tectonic disposition leads to a relatively high seismic activity. The entire Jordan Valley segment is thought to have ruptured repeatedly, for instance during the last two major earthquakes along this structure in749and1033. The deficit inslipthat has built up since 1033 is sufficient to cause an earthquake of Mw~7.4. The most catastrophic known earthquakes occurred in 31 BCE,363, 749, and 1033 CE, that is everyca.400 years on average.Destructive earthquakes strike about every 80 years, leading to serious loss of life .While stringent construction regulations are in place and recently built structures are earthquake resistant, as of 2007many public buildings as well as 50,000 residential buildings did not meet the new standards and were \"expected to collapse\" if exposed to a strong earthquake. Temperatures vary widely, especially during the winter. Coastal areas, such as those of Tel Aviv and Haifa, have a typicalMediterranean climatewith cool, rainy winters and long, hot summers. The area of Beersheba and the northern Negev have asemi-arid climatewith hot summers, cool winters, and fewer rainy days. The southern Negev and the Arabah areas have adesert climatewith very hot, dry summers, and mild winters with few days of rain. The highest temperature of 54 °C (129 °F) was recorded in 1942 in theTirat Zvikibbutz.Mountainous regions can be windy and cold, and areas at elevation of 750 metres (2,460 ft) or more (same elevation as Jerusalem) usually receive at least onesnowfalleach year.From May to September, rain is rare. There are four differentphytogeographicregions, due to its location between the temperate and tropical zones. For this reason, the flora and fauna are extremely diverse. There are 2,867 knownspecies of plants in Israel. Of these, at least 253 species areintroduced and non-native.There are 380Israeli nature reserves. With scarce water resources, Israel has developed various water-saving technologies, includingdrip irrigation.The considerable sunlight available forsolar energymakesIsrael the leading nation in solar energyuse per capita—practically every house uses solar panels for water heating.TheMinistry of Environmental Protectionhas reported thatclimate change\"will have a decisive impact on all areas of life\", particularly for vulnerable populations. Israel has aparliamentary system,proportional representationanduniversal suffrage. A member of parliament supported by a parliamentary majority becomes theprime minister—usually this is the chair of the largest party. The prime minister is thehead of governmentand ofcabinet.Thepresidentishead of state, with largely ceremonial duties. Israel is governed by a 120-member parliament, known as theKnesset. Membership of the Knesset is based on proportional representation ofpolitical parties,with a 3.25% electoral threshold, which in practice has resulted in coalition governments. Residents of Israeli settlements in the West Bank are eligible to vote,and after the2015 election, 10 of the 120 members of the Knesset (8%) were settlers.Parliamentaryelectionsare scheduled every four years, but unstable coalitions or ano-confidence votecan dissolve a government earlier.The first Arab-led party was established in 1988,and as of 2022, Arab-led parties hold about 10% of seats.A party cannot run for election to the Knesset if its objectives or actions include the \"negation of the existence of the State of Israel as the state of the Jewish people\". TheBasic Laws of Israelfunction as anuncodified constitution. These define Israel as aJewish and democratic stateand the nation-state of exclusively the Jewish people.In 2003, the Knesset began to draft an official constitution based on these laws. Israel has no official religion,but the definition of the state as \"Jewish and democratic\" creates a strong connection withJudaism. On 19 July 2018, the Knesset passed a Basic Law that characterises Israel as principally a \"Nation State of the Jewish People\" and Hebrew as its official language. The bill ascribes an undefined \"special status\" to the Arabic language.The same bill gives Jews a unique right to national self-determination and views the developing of Jewish settlement in the country as \"a national interest\", empowering the government to \"take steps to encourage, advance and implement this interest\". The State of Israel is divided into six main administrative districts, known asmehozot(Hebrew:מחוזות;sg.:mahoz)—Center,Haifa,Jerusalem,North,South, andTel Aviv, as well as theJudea and Samaria Areain the West Bank. All of the Judea and Samaria Area and parts of the Jerusalem and Northern districts are not recognised internationally as part of Israel. Districts are divided into 15 sub-districts known asnafot(Hebrew:נפות;sg.:nafa), which are partitioned into 50 natural regions. The 1950Law of Returngrants Jews the unrestrictedright to immigrateto Israel and obtain Israeli citizenship. Individuals born within the country receivebirthright citizenshipif at least one parent is a citizen.Israeli law defines Jewish nationality as distinct from Israeli nationality, and theSupreme Court of Israelhas ruled that an Israeli nationality does not exist.A Jewish national is defined as any person practicing Judaism and their descendants. Golan Heights (1967–present) In 1967, as a result of the Six-Day War, Israel captured and occupied the West Bank (including East Jerusalem), the Gaza Strip and the Golan Heights. Israel also captured the Sinai Peninsula but returned it to Egypt as part of the 1979 Egypt–Israel peace treaty.Between 1982 and 2000, Israel occupiedpart of southern Lebanon, in what was known as theSecurity Belt. Since capture of these territories, Israeli settlements and military installations have been built within each of them, except Lebanon. The Golan Heights and East Jerusalem have been fully incorporated under Israeli law but not under international law. Israel has applied civilian law to both areas and granted their inhabitants permanent residency status and the ability to apply for citizenship. The UN Security Council has declared the annexation of the Golan Heights and East Jerusalem to be \"null and void\" and continues to view the territories as occupied.The status of East Jerusalem in any future peace settlement has at times been a difficult issue in negotiations between Israeli governments and representatives of the Palestinians. The West Bank excluding East Jerusalem is known asthe Judea and Samaria Area.The almost 400,000 Israeli settlers residing in the area are considered part of Israel's population, have Knesset representation, are subject to alarge part of Israel's civil and criminal laws, and their output is considered part of Israel's economy.The land is not considered part of Israel under Israeli law, as Israel has consciously refrained from annexing the territory, without ever relinquishing its legal claim to the land or defining a border.Israeli political opposition to annexation primarily stems from the perceived \"demographic threat\" of incorporating the West Bank's Palestinian population into Israel.Outside of the Israeli settlements, the West Bank remains under direct Israeli military rule, and Palestinians in the area cannot become Israeli citizens. The international community maintains that Israel does not have sovereignty in the West Bank and considers Israel's control of the area to be the longest military occupation in modern history.The West Bank was occupied and annexed by Jordan in 1950, following the 1949 Armistice Agreements. Only Britain recognised this annexation, and Jordan has sinceceded its claimto the territory to the PLO. The population is mainly Palestinians, including refugees of the 1948 Arab–Israeli War.From their occupation in 1967 until 1993, the Palestinians living in these territories were underIsraeli military administration. Since theIsrael–PLO letters of recognition, most of the Palestinian population andcitieshave been under the internal jurisdiction of the Palestinian Authority, and only partial Israeli military control, although Israel has redeployed its troops and reinstated full military administration during periods of unrest. Israel's claim of universal suffrage has been questioned due to its blurred territorial boundaries, its simultaneous extension of voting rights to Israeli settlers in the occupied territories and denial of voting rights to their Palestinian neighbours, as well as the allegedethnocraticnature of the state. The Gaza Strip is considered to be a \"foreign territory\" under Israeli law. Israel and Egypt operate a land, air, and seablockade of the Gaza Strip. The Gaza Strip was occupied by Israel after 1967. In 2005, as part of aunilateral disengagement plan, Israel removed its settlers and forces from the territory but continues to maintain control of its airspace and waters. The international community, including numerous international humanitarian organisations and UN bodies, consider Gaza to remain occupied.Following the 2007 Battle of Gaza, whenHamas assumed power in the Gaza Strip,Israel tightened control of the Gaza crossings alongits border, as well as by sea and air, and prevented persons from entering and exiting except for isolated cases it deemed humanitarian.Gaza has aborder with Egypt, and an agreement between Israel, the EU, and the PA governs how border crossings take place.The application of democracy to its Palestinian citizens and the selective application of Israeli democracy in the Israeli-controlled Palestinian territories have been criticised. TheInternational Court of Justicesaid, in its2004 advisory opinionon the legality of the construction of the West Bank barrier, that the lands captured by Israel in the Six-Day War, including East Jerusalem, are occupied territory and found that the construction of the wall within the occupied Palestinian territory violates international law.Most negotiations relating to the territories have been on the basis ofUN Security Council Resolution 242, which emphasises \"the inadmissibility of the acquisition of territory by war\", and calls on Israel to withdraw from occupied territories in return for normalisation of relations with Arab states (\"Land for peace\").Israel has been criticised for engaging in systematic and widespread violations ofhuman rights in the occupied territories, including occupationand war crimes against civilians.The allegations include violations of international humanitarian lawby theUN Human Rights Council.TheU.S. State Departmenthas called reports ofabuses of significant human rights of Palestinians\"credible\" both within Israeland the occupied territories.Amnesty Internationaland other NGOs have documented mass arbitrary arrests, torture, unlawful killings, systemic abuses and impunityin tandem with a denial of the right toPalestinian self-determination.Prime Minister Netanyahu has defended the country's security forces for protecting the innocent from terroristsand expressed contempt for what he describes as a lack of concern about the human rights violations committed by \"criminal killers\". Theinternational communitywidely regards Israeli settlements in the occupied territoriesillegal under international law.United Nations Security Council Resolution 2334(passed 2016) states that Israel's settlement activity constitutes a \"flagrant violation\" ofinternational lawand demands that Israel stop such activity and fulfill its obligations as anoccupying powerunder theFourth Geneva Convention.AUnited Nations special rapporteurconcluded that the settlement programme was a war crime under theRome Statute,andAmnesty Internationalfound that the settlement programme constitutes an illegal transfer of civilians into occupied territory and \"pillage\", which is prohibited by theHague ConventionsandGeneva Conventionsas well as being a war crime under the Rome Statute. In a2024 advisory opinion, the International Court of Justice stated that occupation of the Palestinian territories violated international law; Israel should end its occupation as quickly as possible and pay reparations. In addition, the court found that Israel was in breach of article 3 of theInternational Convention on the Elimination of All Forms of Racial Discrimination, which requires states to prevent, prohibit and eradicate all practices of racial segregation and apartheid. Treatment of Palestinians within the occupied territories and to a lesser extent in Israel itself have drawn widespread accusations that it is guilty ofapartheid, acrime against humanityunder the Rome Statute and theInternational Convention on the Suppression and Punishment of the Crime of Apartheid.The Washington Post's 2021 survey of scholars and academic experts on the Middle East found an increase from 59% to 65% of these scholars describing Israel as a \"one-state reality akin to apartheid\".The claim that Israel's policies for Palestinianswithin Israelorwithin Israeli-occupied territoriesamount to apartheid has been affirmed by Israeli human rights organisationB'tselem,University Network for Human Rights,and international human rights organisations such as Amnesty InternationalandHuman Rights Watch.Israeli human rights organisationYesh Dinhas also accused Israel of apartheid.Amnesty's claim was criticised by politicians and representatives from Israel and its closest allies such as, the US,the UK,theEuropean Commission,Australia,Netherlandsand Germany,while said accusations were welcomed by Palestiniansand theArab League.In 2022, Michael Lynk, a Canadian law professorappointed by the U.N. Human Rights Councilsaid that the situation met the legal definition of apartheid, and concluded: \"Israel has imposed upon Palestine an apartheid reality in a post-apartheid world\".Subsequent reports from his successor,Francesca Albaneseand fromPermanent United Nations Fact Finding Mission on the Israel Palestine conflictchair Navi Pillay echoed the opinion. In February 2024, theICJ held public hearingsin regards to the legal consequences arising from the policies and practices of Israel in the occupied Palestinian territory including East Jerusalem. During the hearings, 24 states and three international organisations said that Israeli practices amount to a breach of the prohibition of apartheid and/or amount to prohibited acts of racial discrimination.TheInternational Court of Justicein its2024 advisory opinionfound that Israel's occupation of the Palestinian territories constitutes systemic discrimination and is in breach of Article 3 of theInternational Convention on the Elimination of All Forms of Racial Discrimination, which prohibits racial segregation and apartheid. The opinion is silent as to whether the discrimination amounts to apartheid; individual judges were split on the question. Israel maintains diplomatic relations with 165UN member states, theHoly See,Kosovo, theCook IslandsandNiue. It has 107diplomatic missions;countries with which it has no diplomatic relations include most Muslim countries.Six out of 22 nations in theArab Leaguehave normalised relations with Israel. Israel remains formally in astate of war with Syria, dating back uninterrupted to 1948. It has been in a similarlyformal state of war with Lebanonsince the end of theLebanese Civil Warin 2000, with the Israel–Lebanon border remaining unagreed by treaty. Despite the peace treaty between Israel and Egypt, Israel is still widely considered an enemy country among Egyptians.Iran withdrew its recognition of Israel during theIslamic Revolution.Israeli citizens may not visit Syria, Lebanon, Iraq, Saudi Arabia, and Yemen without permission from theMinistry of the Interior.As a result of the 2008–09 Gaza War, Mauritania, Qatar, Bolivia, and Venezuela suspended political and economic ties with Israel,though Bolivia renewed ties in 2019. TheUnited Statesand theSoviet Unionwere the first two countries to recognise the State of Israel, having declared recognition roughly simultaneously.Diplomatic relations with the Soviet Union were broken in 1967 following the Six-Day War and renewed in 1991.The United States regards Israel as its \"most reliable partner in the Middle East\",based on \"common democratic values, religious affinities, and security interests\".The US has provided $68 billionin military assistanceand $32 billion in grants to Israel since 1967, under theForeign Assistance Act(period beginning 1962),more than any other country for that period until 2003.Most surveyed Americans have held consistently favourable views of Israel.The United Kingdom is seen as having a \"natural\"relationshipwith Israel because of the Mandate for Palestine.By 2007,Germanyhad paid 25 billion euros inreparations to Israeland individual Israeli Holocaust survivors.Israelis includedin the European Union'sEuropean Neighbourhood Policy. AlthoughTurkey and Israeldid not establish full diplomatic relations until 1991,Turkey has cooperated with the Jewish state since its recognition of Israel in 1949. Turkey's ties to other Muslim-majority nations in the region have at times resulted in pressure from Arab and Muslim states to temper its relationship with Israel.Relations took a downturn after the 2008–09 Gaza War and Israel'sraid of the Gaza flotilla.Relations betweenGreece and Israelhave improved since 1995 after decline of Israeli–Turkish relations.The two countries have a defence cooperation agreement and in 2010, theIsraeli Air Forcehosted Greece'sHellenic Air Forcein a joint exercise. The joint Cyprus-Israel oil and gas explorations centered on theLeviathan gas fieldare an important factor for Greece, given itsstrong linkswith Cyprus.Cooperation in the world's longestsubmarine power cable, theEuroAsia Interconnector, has strengthenedCyprus–Israel relations. Azerbaijan is one of the few majority Muslim countries to develop strategic and economicrelations with Israel.Kazakhstan also has an economic and strategic partnership with Israel.India established fulldiplomatic tieswith Israel in 1992 and has fostered a strong military, technological and cultural partnership with the country since then.India is the largest customer of theIsraeli military equipment, and Israel is the second-largest military partner of India after Russia.Ethiopiais Israel's main ally in Africa due to common political, religious and security interests. Israel has a history of providing emergency foreign aid and humanitarian response to disasters across the world.In 1955 Israel began itsforeign aid programmein Burma and then shifted to Africa.Israel's humanitarian efforts officially began in 1957 with the establishment ofMashav, the Israel's Agency for International Development Cooperation.In this early period, whilst Israel's aid represented only a small percentage of total aid to Africa, its programme was effective in creating goodwill; however, following the 1967 war relations soured.Israel's foreign aid programme subsequently shifted its focus to Latin America. Since the late 1970s Israel's foreign aid has gradually decreased, although in recent years Israel has tried to reestablish aid to Africa.There are additional Israeli humanitarian and emergency response groups that work with the government, includingIsraAid, a joint programme run by Israeli organisations and North American Jewish groups,ZAKA,The Fast Israeli Rescue and Search Team,Israeli Flying Aid,Save a Child's HeartandLatet.Between 1985 and 2015, Israel sent 24 delegations of their search and rescue unit theHome Front Commandto 22 countries.Currently Israeli foreign aidrankslow amongOECDnations, spending less than 0.1% of itsGNIon development assistance.The country ranked 38th in the 2018World Giving Index. TheIsrael Defence Forces(IDF) is the sole military wing of theIsraeli security forcesand is headed by itsChief of the General Staff, theRamatkal, subordinate to the Cabinet. The IDF consists of thearmy,air forceandnavy. It was founded during the 1948 Arab–Israeli War by consolidating paramilitary organisations, chiefly the Haganah.The IDF also draws upon the resources of theMilitary Intelligence Directorate(Aman).The IDF has been involved in several major wars and border conflicts, making it one of the most battle-trained armed forces in the world. MostIsraelis are conscriptedat age 18. Men serve two years and eight months, andwomen servetwo years.Following mandatory service, Israeli men join the reserve forces and usually do up to several weeks ofreserve dutyevery year until their forties. Most women are exempt from reserve duty.Arab citizens of Israel(except theDruze) and those engaged in full-time religious studiesare exempt, although theexemption of yeshiva studentshas been a source of contention.An alternative for those who receive exemptions on various grounds isSherut Leumi, or national service, which involves a programme of service in social welfare frameworks.A small minority of Israeli Arabs also volunteer in the army.As a result of its conscription programme, the IDF maintains approximately 176,500 active troops and 465,000 reservists, giving Israel one of the world's highestpercentage of citizens with military training. The military relies heavily on high-techweaponssystemsdesigned and manufactured in Israelas well as some foreign imports. TheArrowmissile is one of the world's few operationalanti-ballistic missilesystems.ThePythonair-to-air missile series is often considered one of the most crucial weapons in its military history.Israel'sSpikemissile is one of the most widely exportedanti-tank guided missilesin the world.Israel'sIron Domeanti-missile air defence system gained worldwide acclaim after intercepting hundreds ofrockets fired by Palestinian militantsfrom the Gaza Strip.Since theYom Kippur War, Israel has developed a network ofreconnaissance satellites.TheOfeqprogramme has made Israelone of seven countriescapable of launching such satellites. Israel is widely believed topossess nuclear weaponsand per a 1993 report, chemical and biologicalweapons of mass destruction.Israel has not signed theTreaty on the Non-Proliferation of Nuclear Weaponsand maintains apolicy of deliberate ambiguitytowards its nuclear capabilities.The Israeli Navy'sDolphin submarinesare believed to be armed with nuclear missiles offeringsecond-strikecapability.Since theGulf Warin 1991, all homes in Israel are required to have a reinforced security room,Merkhav Mugan, impermeable to chemical and biological substances. Since Israel's establishment, military expenditure constituted a significant portion of the country'sgross domestic product, with peak of 30.3% of GDP in 1975.In 2021, Israel ranked 15th in the worldby total military expenditure, with $24.3 billion, and 6th by defence spending as a percentage of GDP, with 5.2%.Since 1974, the United States has been a particularly notable contributor ofmilitary aid.Under amemorandum of understandingsigned in 2016, the U.S. is expected to provide the country with $3.8 billion per year, or around 20% of Israel's defence budget, from 2018 to 2028.Israel ranked 8th globally forarms exportsin 2020–2024.The majority of Israel's arms exports are unreported for security reasons.Israel is consistently rated low in theGlobal Peace Index, ranking 134th out of 163 nations in 2022. Israel has athree-tier court system. At the lowest level aremagistratecourts, situated in most cities across the country. Above them aredistrict courts, serving as bothappellatecourts andcourts of first instance; they are situated in five of Israel's sixdistricts. The third and highest tier is theSupreme Court, located in Jerusalem; it serves a dual role as the highest court of appeals and theHigh Court of Justice. In the latter role, the Supreme Court rules as a court of first instance, allowing both citizens and non-citizens to petition against the decisions of state authorities. The legal system combines three legal traditions:English common law,civil law, andJewish law.It is based on the principle ofstare decisis(precedent) and is anadversarial system. Court cases are decided by professional judges.Marriageand divorce are under the jurisdiction of the religious courts:Jewish,Muslim, Druze, and Christian. The election of judges is carried out by aselection committeechaired by thejustice minister(currentlyYariv Levin).Israel'sBasic Law: Human Dignity and Libertyseeks to defendhuman rights and liberties in Israel. TheUnited Nations Human Rights Counciland Israeli human rights organisationAdalahhave highlighted that this law does not in fact contain a general provision for equality and non-discrimination.As a result of \"Enclave law\", large portions of Israeli civil law are applied to Israeli settlements and Israeli residents in the occupied territories. Israel is considered the most advanced country inWest Asiaand the Middle East in economic and industrial development.As of October 2023, the IMF estimated its GDP at 521.7 billion dollars and GDP per capita at 53.2 thousand (ranking 13th worldwide).It is the third richest country in Asiaby nominal per capitaincomeand has the highest averagewealth per adultin the Middle East.The Economistranked Israel as the fourth most successful economy among the developed countries for 2022.It has themost billionairesin the Middle East and the 18th most in the world.In recent years, Israel had one of the highest growth rates in the developed world.In 2010, it joined theOECD.The country is ranked 35th on theWorld Bank'sEase of Doing Businessindex.Economic data covers the economic territory of Israel, including the Golan Heights, East Jerusalem and Israeli settlements in the West Bank. Despite limited natural resources, intensive development of theagriculturaland industrial sectors over the past decades has made Israel largely self-sufficient in food production, apart from grains and beef. Imports, totalling $96.5 billion in 2020, include raw materials, military equipment, investment goods, rough diamonds, fuels, grain, and consumer goods.Leading exports include machinery, equipment, software,cut diamonds, agricultural products, chemicals, textiles, and apparel; in 2020, exports reached $114 billion.TheBank of Israelholds $201 billion of foreign-exchange reserves, the 17th highest in the world.Since the 1970s, Israel has receivedmilitary aidfrom the United States, as well as loan guarantees, which account for roughly half of Israel's external debt. Israel hasone of the lowestexternal debts in the developed world, and is a lender in terms of net external debt (assets vs. liabilities abroad), which in 2015stood at a surplus of $69 billion. Israel has the second-largest number of startup companies after the United Statesand the third-largest number ofNASDAQ-listed companies.It is the world leader for number of start-ups per capitaand has been dubbed the \"Start-Up Nation\".IntelandMicrosoftbuilt their first overseasresearch and developmentfacilities in Israel, and other high-tech multinational corporations have openedresearch and development centres in the country. The days which are allocated to working times are Sunday through Thursday (for a five-day workweek), or Friday (for a six-day workweek). In observance ofShabbat, in places where Friday is a work day and the majority of population is Jewish, Friday is a \"short day\". Several proposals have been raised to adjust the work week with the majority of the world. Israel's development of cutting-edge technologies in software, communications and the life sciences haveevoked comparisonswithSilicon Valley.Israel is first in the world inexpenditure on research and developmentas a percentage of GDP.It is ranked 15th in theGlobal Innovation Indexin 2024,and 5th in the 2019Bloomberg Innovation Index.Israel has 140 scientists, technicians, and engineers per 10,000 employees, the highest number in the worldand has produced sixNobel Prize-winningscientists, mostly in chemistry, since 2004and has been frequently ranked as one of the countries with the highest ratios ofscientific papersper capita.Israeli universitiesare ranked among the top 50 world universities in computer science (TechnionandTel Aviv University), mathematics (Hebrew University of Jerusalem) and chemistry (Weizmann Institute of Science). In 2012, Israel was ranked ninth in the world by the Futron'sSpace Competitiveness Index.TheIsrael Space Agencycoordinates all space research programmes with scientific and commercial goals, and have designed and built at least 13 commercial, research and spy satellites.Some satellites are ranked among the world's most advanced space systems.Shavitis a spacelaunch vehicleproduced by Israel to launch small satellites intolow Earth orbit.It was first launched in 1988, making Israel theeighth nationto have a space launch capability. In 2003,Ilan Ramonbecame Israel's first astronaut, serving on thefatal missionofSpace ShuttleColumbia. Theongoing water shortagehas spurred innovation in water conservation techniques, and a substantialagricultural modernisation,drip irrigation, was invented in Israel. Israel is also at the technological forefront of desalination and water recycling. The Sorek desalination plant is the largest seawaterreverse osmosisdesalination facility in the world.By 2014, desalination programmes provided roughly 35% of the drinking water, and it is expected to supply 70% by 2050.As of 2015, over 50 percent of the water for households, agriculture and industry is artificially produced.In 2011, Israel's water technology industry was worth around $2 billion per year with annual exports of products and services in the tens of millions of dollars. As a result of innovations in reverse osmosis technology, Israel is set to become a netexporter of water. Israel has embracedsolar energy; its engineers are on the cutting edge of solar energy technology,and its solar companies work on projects around the world.Over 90% of homes use solar energy for hot water, the highest per capita.According to government figures, the country saves 8% of its electricity consumption per year because of its solar energy use in heating.The high annual incident solar irradiance at its geographic latitude creates ideal conditions for what is an internationally renowned solar research and development industry in the Negev.Israel had a modern electric car infrastructure involving a countrywide network of charging stations;however, its electric car companyBetter Placeshut down in 2013. Israelbegan producing natural gasfrom its own offshore gas fields in 2004. In 2009Tamar gas fieldwas discovered near the coast, andLeviathan gas fieldwas discovered in 2010.The natural gas reserves in these two fields could make Israel energy-secure for more than 50 years. Commercial production of natural gas from the Tamar field began in 2013, with over 7.5 billion cubic meters (bcm) produced annually.Israel had 199 billion bcm of proven reserves of natural gas as of 2016.The Leviathan gas field started production in 2019. Ketura Sunis Israel's first commercial solar field. Built in 2011 by theArava Power Company, the field will produce about 9 gigawatt-hours of electricity per year,sparing the production of some 125,000 metric tons of carbon dioxide over 20 years. Israel has 19,224 kilometres (11,945 mi) of pavedroadsand 3 million motor vehicles.Thenumber of motor vehicles per 1,000 personsis 365, relatively low among developed countries.The country aims to have 30% of vehicles on its roads powered by electricity by 2030. Israel has 5,715 buses on scheduled routes,operated by several carriers, the largest and oldest of which isEgged, serving most of the country.Railwaysstretch across 1,277 kilometres (793 mi) and are operated by government-ownedIsrael Railways.Following major investments beginning in the early to mid-1990s, the number of train passengers per year has grown from 2.5 million in 1990, to 53 million in 2015; railways transport 7.5 million tons of cargo per year. Israel is served by three internationalairports:Ben Gurion Airport, the country's main hub for international air travel;Ramon Airport; andHaifa Airport. Ben Gurion handled over 21.1 million passengers in 2023.There are three main ports: thePort of Haifa, the oldest and largest;Ashdod Port; and thePort of Eilaton theRed Sea. Tourism, especiallyreligious tourism, is an important industry, withbeaches,archaeological, otherhistoricalandbiblicalsites, and unique geography also drawing tourists. In 2017, a record 3.6 million tourists visited Israel, yielding a 25 percent growth since 2016 and contributed NIS 20 billion to the economy. Housing prices are listed in the top third of all countries,with an average of 150 salaries required to buy an apartment.As of 2022, there are about 2.7 million properties in Israel, with an annual increase of over 50,000.However, demand for housing exceeds supply, with a shortage of about 200,000 apartments as of 2021.As a result, by 2021 housing prices rose by 5.6%.In 2021, Israelis took a record of NIS 116.1 billion in mortgages, an increase of 50% from 2020. Israel has the largest Jewish population in the world and is the only country where Jews are the majority,and the only country in which Jews make up more than 2% of the total national population.April 2025, the population was an estimated 10,094,000.In 2025, the government recorded72% of the population asJews,21% asArabs, and7% as \"Others\" (non-Arab Christians and people who have no religion listed).Over the last decade, large numbers of migrant workers from Romania, Thailand, China, Africa, and South America have settled in Israel. Exact figures are unknown, as many of them are living in the country illegally,but estimates run from 166,000 to 203,000.By June 2012, approximately 60,000African migrantshad entered Israel. About 93% of Israelis live in urban areas.90% of Palestinian Israelis reside in 139 densely populated towns and villages concentrated in the Galilee,Triangleand Negev regions, with the remaining 10% inmixed citiesand neighbourhoods.The OECD in 2016 estimated the average life expectancy at 82.5 years, the6th-highest in the world.Israeli Arab life expectancy lags by 3 to 4 yearsand is higher than in most Arab and Muslim countries.The country has the highestfertility ratein the OECD and the only one which is above the replacement figure of 2.1.Retention of Israel's population since 1948 is about even or greater, when compared to other countries with mass immigration.Jewish emigration from Israel (calledyerida), primarily to the United States and Canada, is described by demographers as modest,but is often cited by Israeli government ministries as a major threat to Israel's future. Approximately 80% ofIsraeli Jewsareborn in Israel, 14% are immigrants from Europe and the Americas, and 6% are immigrants from Asia and Africa.Jews from Europe and the former Soviet Union and their descendants born in Israel, including Ashkenazi Jews, constitute approximately 44% of Jewish Israelis. Jews from Arab and Muslim countries and their descendants, including both Mizrahi and Sephardi Jews,form most of the rest of the Jewish population.Jewish intermarriage rates run at over 35% and recent studies suggest that the percentage of Israelis descended from both Sephardi and Ashkenazi Jews increases by 0.5 percent yearly, with over 25% of schoolchildren now originating from both.Around 4% of Israelis (300,000), ethnically defined as \"others\", are Russian descendants of Jewish origin or family who are not Jewish according to rabbinical law, but were eligible for citizenship under the Law of Return. Israeli settlers beyond the Green Line number over 600,000 (≈10% of the Jewish Israeli population).In 2016,399,300 Israelis livedin West Bank settlements,including those that predated the establishment of the State of Israel and which were re-established after the Six-Day War. Additionally there were more than 200,000 Jews living in East Jerusalemand 22,000 in the Golan Heights.Approximately 7,800 Israelislived in settlementsin the Gaza Strip, known asGush Katif, until they were evacuated by the government as part of its 2005disengagement plan. Israeli Arabs (including the Arab population of East Jerusalem and the Golan Heights) comprise 21.1% of the population or 1,995,000 people.In a 2017 poll, 40% of Arab citizens of Israel identified as \"Arab in Israel\" or \"Arab citizen of Israel\", 15% identified as \"Palestinian\", 8.9% as \"Palestinian in Israel\" or \"Palestinian citizen of Israel\", and 8.7% as \"Arab\"; a poll found that 60% of Israeli Arabs have a positive view of the state. Israel has four major metropolitan areas:Gush Dan(Tel Aviv metropolitan area; population 3,854,000),Jerusalem(population 1,253,900),Haifa(924,400), andBeersheba(377,100).The largest municipality, in population and area, is Jerusalem with 1,028,366 residents in an area of 125 square kilometres (48 sq mi).Statistics on Jerusalem include the population and area of East Jerusalem, the status of which is in international dispute.Tel Aviv and Haifa rank as Israel's next most populous cities, with populations of 495,230 and 298,312, respectively.The (mainlyHaredi) city ofBnei Brakis the most densely populated city in Israel and one of the10 most densely populated citiesin the world. Israel has 16 cities with populations over 100,000. As of 2018there are 77 localities granted\"municipalities\" (or \"city\") statusby the Ministry of the Interior,four of which are in the West Bank. ^aThis number includesEast JerusalemandWest Bankareas, which had a total population of 617,580 inhabitants in 2023.Israeli sovereignty over East Jerusalem isinternationally unrecognized. The official language isHebrew. Hebrew is the primary language of the state and is spoken daily by the majority of the population. Prior to 1948,oppositiontoYiddish, the historical language of the Ashkenazi Jews, was common among supporters of the Zionist movement, including the Yishuv, who sought to promoteHebrew's revivalas a unifying national language.These sentiments were reflected in the early policies of the Israeli government, which largely bannedYiddish theatreand publications.Until 2018,Arabicwas also an official language;in 2018 it was downgraded to having a \"special status in the state\".Arabic is spoken by the Arab minority, with Arabic and Hebrew taught in Arab schools.Arabic is studied in most Jewish schools and is often used on signage and in transport announcements. Due to mass immigration from the former Soviet Union andEthiopia(some 130,000Ethiopian Jews live in Israel),RussianandAmharicare widely spoken.Over one million Russian-speaking immigrants arrived in Israel between 1990 and 2004.French is spoken by around 700,000 Israelis,mostly originatingfrom Franceand North Africa (seeMaghrebi Jews). English was an official language during the Mandate period;it lost this status after the establishment of Israel, but retains a role comparable to that of an official language.Many Israelis communicate reasonably well in English, as many television programmes are broadcast in English with subtitles and the language is taught in elementary school. Israeli universities offer courses in English. The estimated religious affiliation as of 2022 was 73.5% Jewish, 18.1%Muslim, 1.9%Christian, 1.6%Druze, and 4.9% other.Thereligious affiliationofIsraeli Jewsvaries widely: a 2016 survey byPew Researchindicates that 49% self-identify asHiloni(secular), 29% asMasorti(traditional), 13% asDati(religious) and 9% asHaredi(ultra-Orthodox).Haredi Jews are expected to represent over 20% of the Jewish population by 2028.Muslimsconstitute the largest religious minority, making up about 18.1% of the population. About 1.9% of the population isChristian, and 1.6% isDruze.The Christian population comprises primarilyArab ChristiansandAramean Christiansbut also includes post-Soviet immigrants, foreign labourers,Armenian Christians, and followers ofMessianic Judaism, considered by most Christians and Jews to be a form of Christianity.Members of many other religious groups, includingBuddhistsandHindus, maintain a presence in Israel, albeit in small numbers.Out of over one million immigrants from the former Soviet Union, about 300,000 are considered not Jewish by theChief Rabbinate of Israel. Israel comprises a major part of theHoly Land, a region of significant importance to allAbrahamic religions. Jerusalem is ofspecial importanceto Jews, Muslims, and Christians, as it is the home ofsitesthat are pivotal to their religious beliefs, such as theOld Citythat incorporates theWestern Walland theTemple Mount(Al-Aqsa Mosque compound) and theChurch of the Holy Sepulchre.Other locations of religious importance areNazareth(site of theAnnunciationofMary),TiberiasandSafed(two of theFour Holy Citiesin Judaism), theWhite MosqueinRamla(shrine of the prophetSaleh), and theChurch of Saint George and Mosque of Al-Khadr, Lod(tomb ofSaint GeorgeorAl Khidr). A number of other religious landmarks are located in theWest Bank, includingJoseph's Tomb, thebirthplace of Jesus,Rachel's Tomb, and theCave of the Patriarchs. Theadministrative centerof theBaháʼí Faithand theShrine of the Bábare located at theBaháʼí World CentreinHaifa; the leader of the faith isburiedinAcre.TheMahmood Mosqueis affiliated with the reformistAhmadiyyamovement.Kababir, Haifa's mixed neighbourhood of Jews and Ahmadi Arabs, is one of a few of its kind in the country. In 2015, Israelrankedthird among OECD members for the percentage of 25–64-year-olds that have attained tertiary education with 49% compared with the OECD average of 35%.In 2012, the country ranked third in the number of academic degrees per capita (20 percent of the population). Israel has aschool life expectancyof 16 years and aliteracy rateof 97.8%.The State Education Law (1953) established five types of schools: state secular, state religious, ultra orthodox, communal settlement schools, and Arab schools. The public secular is the largest school group and is attended by the majority of Jewish and non-Arab pupils. Most Arabs send their children to schools where Arabic is the language of instruction.Education is compulsory for children between the ages of three and eighteen.Schooling is divided into three tiers—primary school (grades 1–6), middle school (grades 7–9), and high school (grades 10–12)—culminating withBagrutmatriculation exams. Proficiency in core subjects such as mathematics, the Hebrew language, Hebrew and general literature, the English language, history, Biblical scripture and civics is necessary to receive a Bagrut certificate. The Jewish population maintains a relatively high level of educational attainment where just under half of all Israeli Jews (46%) hold post-secondary degrees.Israeli Jews 25 and older have an average 11.6 years of schooling, making them one of the most highly educated of all major religious groups in the world.In Arab, Christian and Druze schools, the exam on Biblical studies is replaced by an exam on Muslim, Christian or Druze heritage, respectively.In 2020, 68.7% of 12th graders earned a matriculation certificate. Israel has a tradition of higher education where its university education has been largely responsible in spurring modern economic development.Israel hasnine public universities subsidised by the state and 49 private colleges.TheHebrew University of Jerusalemhouses theNational Library of Israel, the world's largest repository of Judaica and Hebraica.TheTechnionand the Hebrew University consistently ranked among world's 100 top universities byARWUranking.Other major universities include theWeizmann Institute of Science,Tel Aviv University,Ben-Gurion University of the Negev,Bar-Ilan University, theUniversity of Haifa, and theOpen University of Israel. Cultural diversity stems from its diverse population: Jews from various diaspora communities brought their cultural and religious traditions with them.Arab influencesare present in many cultural spheres,being found inarchitecture,music,andcuisine.Israel is the only country where life revolves around theHebrew calendar, which is aligned to the seasons in the Levant.Public holidaysare determined by theJewish holidays, and except forYom HaAtzma'ut(Independence Day) there are no annual civil holidays. The official day of rest is Saturday, theJewish Sabbath. Israeli literatureis primarilypoetryand prose written in Hebrew, as part of therenaissanceof Hebrew as a spoken language since the mid-19th century, although a small body of literature is published in other languages. By law, two copies of all works published in Israel must be deposited in theNational Library of Israel.In 2016, 89 percent of the 7,300 books transferred to the library were in Hebrew. In 1966,Shmuel Yosef Agnonshared theNobel Prize in Literaturewith German Jewish authorNelly Sachs.Leading poets includeYehuda Amichai,Nathan Alterman,Leah Goldberg, andRachel Bluwstein.Internationally famous contemporary novelists includeAmos Oz,Etgar KeretandDavid Grossman. Israeli musicincludesMizrahiandSephardic music,Hasidicmelodies,Greek music,jazz, andpop rock.TheIsrael Philharmonic Orchestrahas been in operation for over seventy years and performs more than two hundred concerts each year.Itzhak Perlman,Pinchas ZukermanandOfra Hazaare among the internationally acclaimed musicians born in Israel. The countryhas participatedin theEurovision Song Contestnearly every year since 1973, winning it four times and hosting three times.Eilathas hosted its own international music festival, theRed Sea Jazz Festival, every summer since 1987.The nation's canonicalfolk songsare known as \"Songs of the Land of Israel\". Ten Israeli filmshave been final nomineesforBest Foreign Language Filmat theAcademy Awards. Palestinian Israeli filmmakers have made films dealing with the Arab-Israeli conflict and status of Palestinians within Israel, such asMohammed Bakri's 2002 filmJenin, JeninandThe Syrian Bride. Continuing the strong theatrical traditions of theYiddish theatrein Eastern Europe, Israel maintains a vibrant theatre scene. Founded in 1918,Habima Theatrein Tel Aviv is Israel's oldestrepertory theatercompany and national theater.Other theatres includeOhel,the CameriandGesher. Israeli Jewish art has been particularly influenced by theKabbalah, theTalmudand theZohar. Another art movement that held a prominent role in the 20th century was theSchool of Paris. In the late 19th and early 20th century, the Yishuv's art was dominated by art trends emanatingBezalel. Beginning in the 1920s, the local art scene was heavily influenced by modern French art, first introduced byIsaac Frenkel Frenel.Jewish masters of theschool of Paris, such asSoutine,Kikoine,Frenkel,Chagallheavily influenced the subsequent development of Israeli art.Israeli sculpture took inspiration from modernEuropean sculptureas wellMesopotamian,Assyrianand local art.Avraham Melnikov's roaring lion, David Polus' Alexander Zaid andZe'ev Ben Zvi's cubist sculpture exemplify some of the different streams in sculpture. Common themes in art are the mystical cities of Safed and Jerusalem, the bohemian café culture of Tel Aviv, agricultural landscapes, biblical stories and war. Today Israeli art has delved intooptical art,AI art,digital artand the use of salt in sculpture. Due to the immigration of Jewish architects, architecture has come to reflect different styles. In the early 20th century Jewish architects sought to combine Occidental and Oriental architecture producing buildings that showcase a myriad of infused styles.Theeclecticstyle gave way to the modernistBauhausstyle with the influx of German Jewish architects (among themErich Mendelsohn) fleeingNazi persecution.TheWhite City of Tel Avivis aUNESCO heritage site.Following independence, multiple government projects were commissioned, a grand part built in a brutalist style with heavy emphasis on the use of concrete and acclimatisation to the desert climate. Several novel ideas such as theGarden Citywere implemented in Israeli cities; theGeddes planof Tel Aviv became renowned internationally for its revolutionary design and adaptation to the local climate.The design of kibbutzim also came to reflect ideology, such as the planning of the circular kibbutzNahalalbyRichard Kauffmann. TheIsrael Museumin Jerusalem is one of Israel's most important cultural institutions,and houses theDead Sea Scrolls,along with an extensive collection ofJudaicaandEuropean art.Yad Vashem(Hebrew:יָד וַשֵׁם,lit.'a memorial and a name') is the world's centralHolocaustmemorial institution and archive of Holocaust-related information.ANU - Museum of the Jewish Peopleis an interactive museum devoted to the history of Jewish communities around the world. Israel has the highest number of museums per capita.Several museums are devoted to Islamic culture, including theRockefeller Museumand theL. A. Mayer Institute for Islamic Art, both in Jerusalem. The Rockefeller specialises in archaeological remains from Middle East history. It is also the home of the first hominid fossil skull found in West Asia, calledGalilee Man. Media is diverse, reflecting the spectrum of audiences. Notable newspapers include the leftwingHaaretz,centristYedioth Ahronoth,and center-rightIsrael Hayom.There are several major TV channels which cater to different audiences, from Russian-languageChannel 9to Arabic-languageKan 33.The 2024 Freedom House report found Israeli media is \"vibrant and free to criticise government policy\".In the 2024Press Freedom IndexbyReporters Without Borders, Israel was placed 101st of 180 countries, second in the Middle East and North Africa.Reporters Without Borders noted that the Israel Defence Forces had killed more than 100 journalists in Gaza. Since the Gaza war, Israel had been \"trying to suppress the reporting coming out of the besieged enclave while disinformation infiltrates its own media ecosystem\".In May 2024, Israel shut down the local offices ofAl Jazeera.In 2024, according to theCommittee to Protect Journalists, Israel was the second leading country in the world in jailing journalists,while being responsible for the majority of journalists killed in the world. Israeli cuisine includes local dishes as well asJewish cuisinebrought to the country by immigrants. Particularly since the late 1970s, afusion cuisinehas developed.The cuisine has adapted elements of theMizrahi,Sephardi, andAshkenazistyles of cooking. It incorporates many foods traditionally eaten in theLevantine,Arab,Middle EasternandMediterraneancuisines, such asfalafel,hummus,shakshouka,couscous, andza'atar.Schnitzel,pizza,hamburgers,French fries,riceandsaladare common.Ptitim(Israeli couscous) is a notable Israeli food invented in the 1950s due to rice shortages during theausterity period. Roughly half of the Jewish population attests to keepingkosherat home.Kosher restaurantsmake up around a quarter of the total as of 2015.Pork—often called \"white meat\" in Israel—is produced and consumed despite attempts to ban it;it is forbiddenby both Judaism and Islam but is permitted by Christianity and mostly produced in traditionally Christian areas of northern Israel.Other non-kosher foods produced and eaten in Israel include rabbits, ostriches, and non-kosher fish. The most popular spectator sports in Israel are association football and basketball.TheIsraeli Premier Leagueis the country's premier football league, and theIsraeli Basketball Premier Leagueis the premier basketball league.Maccabi Haifa,Maccabi Tel Aviv,Hapoel Tel AvivandBeitar Jerusalemare the largestfootball clubs. Maccabi Tel Aviv, Maccabi Haifa and Hapoel Tel Aviv have competed in theUEFA Champions Leagueand Hapoel Tel Aviv reached theUEFA Cupquarter-finals. Israel hosted and won the1964 AFC Asian Cup; in 1970 theIsrael national football teamqualified for theFIFA World Cup, the only time it participated. The1974 Asian Games, held in Tehran, were the last Asian Games in which Israelparticipated, plagued by Arab countries thatrefused to competewith Israel. Israel was excluded from the1978 Asian Gamesand since then has not competed in Asian sport events.In 1994,UEFAagreed to admit Israel, and its football teams now compete in Europe.Maccabi Tel Aviv B.C.has won theEuropean championshipin basketball six times. Israel has won20 Olympic medalssince its first winin 1992, including a gold medal inwindsurfingat the2004 Summer Olympics,and seven medals at the 2024 Paris Olympics alone.Israel has wonover 100gold medals in theParalympic Gamesand is ranked 20th in theall-time medal count. The1968 Summer Paralympicswere hosted by Israel.TheMaccabiah Games, an Olympic-style event forJewishand Israeli athletes, was inaugurated in the 1930s, and has been held every four years since.Krav Maga, a martial art developed by Jewish ghetto defenders, is used by the Israeli security forces and police. Chess is a leading sport. There are many Israeli grandmasters andIsraeli chess playershave won a number of youth world championships.Israel stages an annual internationalchampionshipand hosted theWorld Team Chess Championshipin 2005. Israeli settlementsTimeline,International law West BankJudea and Samaria Area Gaza StripHof Aza Regional Council 31°N35°E﻿ / ﻿31°N 35°E﻿ /31; 35", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Israel", "https://en.wikipedia.org/wiki/Israel", "https://en.wikipedia.org/wiki/Israel", "https://en.wikipedia.org/wiki/Geographic_coordinate_system", "https://en.wikipedia.org/wiki/Land_of_Israel", "https://en.wikipedia.org/wiki/Israel_(disambiguation)", "https://en.wikipedia.org/wiki/Hebrew_language", "https://en.wikipedia.org/wiki/Arabic_language"]},
{"id": "ebaacfd03d19", "url": "https://en.wikipedia.org/wiki/A_Stanislaw_Lem_Reader", "title": "A Stanislaw Lem Reader", "headings": ["Contents", "Contents", "Reviews", "See also", "References"], "content": "A Stanislaw Lem Readeris a collection of writings by and aboutPolish science fictionwriterStanisław Lem, one of the world's most widely read science-fiction writers.The book comprises an introduction by  Canadian literary scholarPeter Swirski, two interviews by Swirski with Lem, and Swirski's translation of Lem's essay, \"30 Years Later\". The book is described as an \"eclectic collection\" on its back cover. It begins with Swirski's  introduction titled \"Stanislaw Lem: A Stranger in a Strange Land\", an overview of Lem's literary work. The title is an allusion toRobert Heinlein'sStranger in a Strange Land, stressing the uniqueness of Lem's original perceptions of the contemporary civilization, his aesthetics and philosophy.Peter Butko described this overview as \"condensed and insightful\". The second item is \"Reflections on Literature, Philosophy, and Science\", a personal interview of Swirski with Lem carried out in 1992, mostly focused on Lem's views on literature. The third item is30 Years Later, Swirski's translation of Lem's essayTrzydzieści lat późniejfirst published in Polish popular science magazineWiedza i Życie[pl](\"Knowledge and Life\") in 1991. It is the second afterword (After the \"Twenty Years Later\") to Lem'sSumma Technologiae. Apart from the critical remarks onfuturology, its significant part is the discussion of the technology  ofvirtual realitypredicted inSumma Technologiaeunder the termfantomatyka(\"fantomatics\"), a part of his bitter philosophical dispute with Polish philosopherLeszek Kołakowski.Lem also discusses which of his futurological predictions came true. The fourth item, \"Lem in Nutshell\", is Swirski's written interview with Lem carried out in  1994, mostly focused on Lem's views on science and philosophy. Comparing the second and fourth chapters (interviews), Butko notes that the \"first is less formal and more conversational\", while the second one is \"deeper\" and more scholarly.Unlike Jurich, who thinks the first interview was more focused on literature, and second more on science and philosophy,Butko concludes that both interviews have a similar focus on \"the relationship of literature with philosophy and science\". The book concludes with the bibliography section. It lists Lem's books, published both in Polish and English, and articles and essays translated into English – in the chronological order of first publications. It also includes  a comprehensive list of critical literature on Lem in English – alphabetically ordered by author. The book was positively reviewed by Butko, who concluded that \"Swirski's book is small in volume, but dense in ideas [and] is indispensable reading for any Stanislaw Lem reader.\"Jurich was more critical, noting that while the book gives English readers \"the opportunity to discover aspects of Lem not otherwise accessible [to those who do not read Polish]\" it is also \"far more frustrating than it is interesting or significantly informative\", arguing that the book provides \"too little insight into Lem's thought and art.\"", "combined_text": "A Stanislaw Lem Reader Contents Contents Reviews See also References A Stanislaw Lem Readeris a collection of writings by and aboutPolish science fictionwriterStanisław Lem, one of the world's most widely read science-fiction writers.The book comprises an introduction by  Canadian literary scholarPeter Swirski, two interviews by Swirski with Lem, and Swirski's translation of Lem's essay, \"30 Years Later\". The book is described as an \"eclectic collection\" on its back cover. It begins with Swirski's  introduction titled \"Stanislaw Lem: A Stranger in a Strange Land\", an overview of Lem's literary work. The title is an allusion toRobert Heinlein'sStranger in a Strange Land, stressing the uniqueness of Lem's original perceptions of the contemporary civilization, his aesthetics and philosophy.Peter Butko described this overview as \"condensed and insightful\". The second item is \"Reflections on Literature, Philosophy, and Science\", a personal interview of Swirski with Lem carried out in 1992, mostly focused on Lem's views on literature. The third item is30 Years Later, Swirski's translation of Lem's essayTrzydzieści lat późniejfirst published in Polish popular science magazineWiedza i Życie[pl](\"Knowledge and Life\") in 1991. It is the second afterword (After the \"Twenty Years Later\") to Lem'sSumma Technologiae. Apart from the critical remarks onfuturology, its significant part is the discussion of the technology  ofvirtual realitypredicted inSumma Technologiaeunder the termfantomatyka(\"fantomatics\"), a part of his bitter philosophical dispute with Polish philosopherLeszek Kołakowski.Lem also discusses which of his futurological predictions came true. The fourth item, \"Lem in Nutshell\", is Swirski's written interview with Lem carried out in  1994, mostly focused on Lem's views on science and philosophy. Comparing the second and fourth chapters (interviews), Butko notes that the \"first is less formal and more conversational\", while the second one is \"deeper\" and more scholarly.Unlike Jurich, who thinks the first interview was more focused on literature, and second more on science and philosophy,Butko concludes that both interviews have a similar focus on \"the relationship of literature with philosophy and science\". The book concludes with the bibliography section. It lists Lem's books, published both in Polish and English, and articles and essays translated into English – in the chronological order of first publications. It also includes  a comprehensive list of critical literature on Lem in English – alphabetically ordered by author. The book was positively reviewed by Butko, who concluded that \"Swirski's book is small in volume, but dense in ideas [and] is indispensable reading for any Stanislaw Lem reader.\"Jurich was more critical, noting that while the book gives English readers \"the opportunity to discover aspects of Lem not otherwise accessible [to those who do not read Polish]\" it is also \"far more frustrating than it is interesting or significantly informative\", arguing that the book provides \"too little insight into Lem's thought and art.\"", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/A_Stanislaw_Lem_Reader", "https://en.wikipedia.org/wiki/A_Stanislaw_Lem_Reader", "https://en.wikipedia.org/wiki/A_Stanislaw_Lem_Reader", "https://en.wikipedia.org/wiki/Stanis%C5%82aw_Lem", "https://en.wikipedia.org/wiki/Peter_Swirski", "https://en.wikipedia.org/wiki/Social_science_fiction", "https://en.wikipedia.org/wiki/Satire", "https://en.wikipedia.org/wiki/Philosophical_novel"]},
{"id": "db767c08c867", "url": "https://en.wikipedia.org/wiki/American_Sign_Language", "title": "American Sign Language", "headings": ["Contents", "Classification", "History", "Population", "Geographic distribution", "Regional variation", "Sign production", "Sign variants", "History and implications", "Varieties", "Stigma", "Writing systems", "Phonology", "Grammar", "Morphology", "Syntax", "Iconicity", "See also", "Notes", "References", "Bibliography", "External links"], "content": "American Sign Language(ASL) is anatural languagethat serves as the predominantsign languageofDeaf communitiesin the United States and most ofAnglophone Canada. ASL is a complete and organizedvisual languagethat is expressed by employing both manual andnonmanual features.Besides North America, dialects of ASL and ASL-basedcreolesare used in many countries around the world, including much ofWest Africaand parts ofSoutheast Asia. ASL is also widely learned as asecond language, serving as alingua franca. ASL is most closely related toFrench Sign Language(LSF). It has been proposed that ASL is a creole language of LSF, although ASL shows features atypical of creole languages, such asagglutinative morphology. ASL originated in the early 19th century in theAmerican School for the Deaf(ASD) inHartford, Connecticut, from a situation oflanguage contact. Since then, ASL use has been propagated widely by schools for the deaf and deaf community organizations. Despite its wide use, no accurate count of ASL users has been taken. Reliable estimates for American ASL users range from 250,000 to 500,000 persons, including a number ofchildren of deaf adults(CODA) and other hearing individuals. Signs in ASL have a number ofphonemiccomponents, such as movement of the face, the torso, and the hands. ASL is not a form ofpantomime, althoughiconicityplays a larger role in ASL than in spoken languages. Englishloan wordsare often borrowed throughfingerspelling, although ASL grammar is unrelated to that of English. ASL has verbalagreementandaspectualmarking and has a productive system of forming agglutinativeclassifiers. Many linguists believe ASL to be asubject–verb–objectlanguage. However, there are several other proposals to account for ASL word order. ASL emerged as a language in theAmerican School for the Deaf(ASD), founded byThomas Gallaudetin 1817,which brought togetherOld French Sign Language, variousvillage sign languages, andhome signsystems. ASL was created in that situation bylanguage contact.ASL is influenced by its forerunners, yet linguistically distinct. The influence of French Sign Language (LSF) on ASL is readily apparent; for example, it has been found that about 58% of signs in modern ASL arecognateto Old French Sign Language signs.However, that is far less than the standard 80% measure used to determine whether related languages are actuallydialects.That suggests nascent ASL was highly affected by the other signing systems brought by the ASD students although the school's original director,Laurent Clerc, taught in LSF.In fact, Clerc reported that he often learned the students' signs rather than conveying LSF: I see, however, and I say it with regret, that any efforts that we have made or may still be making, to do better than, we have inadvertently fallen somewhat back of Abbé de l'Épée. Some of us have learned and still learn signs from uneducated pupils, instead of learning them from well instructed and experienced teachers. — Clerc, 1852, from Woodward 1978:336 It has been proposed that ASL is acreolein which LSF is thesuperstratelanguage and the native village sign languages aresubstratelanguages.However, more recent research has shown that modern ASL does not share many of the structural features that characterize creole languages.ASL may have begun as a creole and then undergone structural change over time, but it is also possible that it was never a creole-type language.There are modality-specific reasons that signed languages tend towardsagglutination, such as the ability to simultaneously convey information via the face, head, torso, and other body parts. That might override creole characteristics such as the tendency towardsisolating morphology.Additionally, Clerc andThomas Hopkins Gallaudetmay have used an artificially constructed form ofmanually coded languagein instruction rather than true LSF. Although the United States, the United Kingdom, and Australia share English as a common oral and written language, ASL is not mutually intelligible with eitherBritish Sign Language(BSL) orAuslan.All three languages show degrees of borrowing from English, but that alone is not sufficient for cross-language comprehension.It has been found that a relatively high percentage (37–44%) of ASL signs have similar translations in Auslan, which for oral languages would suggest that they belong to the samelanguage family.However, that does not seem justified historically for ASL and Auslan, and it is likely that the resemblance is caused by the higher degree oficonicityin sign languages in general as well as contact with English. American Sign Language is growing in popularity in many states. Many high school and university students desire to take it as a foreign language, but until recently, it was usually not considered a creditable foreign language elective. ASL users, however, have a very distinct culture, and they interact very differently when they talk. Their facial expressions and hand movements reflect what they are communicating. They also have their own sentence structure, which sets the language apart. American Sign Language is now being accepted by many colleges as a language eligible for foreign language course credit;many states are making it mandatory to accept it as such.In some states however, this is only true with regard to high school coursework. Prior to the birth of ASL, sign language had been used by various communities in the United States.In the United States, as elsewhere in the world, hearing families with deaf children have historically employed ad hochome sign, which often reaches much higher levels of sophistication than gestures used by hearing people in spoken conversation.As early as 1541 at first contact byFrancisco Vásquez de Coronado, there were reports that theIndigenous peoples of the Great Plainswidely spokea sign languageto communicate across vast national and linguistic lines. In the 19th century, a \"triangle\" ofvillage sign languagesdeveloped inNew England: one inMartha's Vineyard, Massachusetts; one inHenniker, New Hampshire, and one inSandy River Valley, Maine.Martha's Vineyard Sign Language(MVSL), which was particularly important for the history of ASL, was used mainly inChilmark, Massachusetts.Due to intermarriage in the original community of English settlers of the 1690s, and therecessivenature of genetic deafness, Chilmark had a high 4% rate of genetic deafness.MVSL was used even by hearing residents whenever a deaf person was present,and also in some situations where spoken language would be ineffective or inappropriate, such as during church sermons or between boats at sea. ASL is thought to have originated in theAmerican School for the Deaf(ASD), founded inHartford, Connecticut, in 1817.Originally known asThe American Asylum, At Hartford, For The Education And Instruction Of The Deaf And Dumb, the school was founded by the Yale graduate and divinity studentThomas Hopkins Gallaudet.Gallaudet, inspired by his success in demonstrating the learning abilities of a young deaf girlAlice Cogswell, traveled to Europe in order to learn deaf pedagogy from European institutions.Ultimately, Gallaudet chose to adopt the methods of the FrenchInstitut National de Jeunes Sourds de Paris, and convincedLaurent Clerc, an assistant to the school's founderCharles-Michel de l'Épée, to accompany him back to the United States.Upon his return, Gallaudet founded the ASD on April 15, 1817. The largest group of students during the first seven decades of the school were from Martha's Vineyard, and they brought MVSL with them.There were also 44 students from around Henniker, New Hampshire, and 27 from the Sandy River valley in Maine, each of which had their own village sign language.Other students brought knowledge of their own home signs.Laurent Clerc, the first teacher at ASD, taught usingFrench Sign Language(LSF), which itself had developed in the Parisian school for the deaf established in 1755.From that situation oflanguage contact, a new language emerged, now known as ASL. More schools for the deaf were founded after ASD, and knowledge of ASL spread to those schools.In addition, the rise of Deaf community organizations bolstered the continued use of ASL.Societies such as theNational Association of the Deafand the National Fraternal Society of the Deaf held national conventions that attracted signers from across the country.All of that contributed to ASL's wide use over a large geographical area, atypical of a sign language. Whileoralism, an approach to educating deaf students focusing on oral language, had previously been used in American schools, theMilan Congressmade it dominant and effectively banned the use of sign languages at schools in the United States and Europe. However, the efforts of Deaf advocates and educators, more lenient enforcement of the Congress's mandate, and the use of ASL in religious education and proselytism ensured greater use and documentation compared to European sign languages, albeit more influenced by fingerspelled loanwords and borrowed idioms from English as students were societally pressured to achieve fluency in spoken language.Nevertheless, oralism remained the predominant method of deaf education up to the 1950s.Linguists did not consider sign language to be true \"language\" but as something inferior.Recognition of the legitimacy of ASL was achieved byWilliam Stokoe, a linguist who arrived atGallaudet Universityin 1955 when that was still the dominant assumption.Aided by theCivil Rights Movementof the1960s, Stokoe argued formanualism, the use of sign language in deaf education.Stokoe noted that sign language shares the important features that oral languages have as a means of communication, and even devised atranscriptionsystem for ASL.In doing so, Stokoe revolutionized both deaf education and linguistics.In the 1960s, ASL was sometimes referred to as \"Ameslan\", but that term is now considered obsolete. Counting the number of ASL signers is difficult because ASL users have never been counted by the American census.The ultimate source for current estimates of the number of ASL users in the United States is a report for the National Census of the Deaf Population (NCDP) by Schein and Delk (1974).Based on a 1972 survey of the NCDP, Schein and Delk provided estimates consistent with a signing population between 250,000 and 500,000.The survey did not distinguish between ASL and other forms of signing; in fact, the name \"ASL\" was not yet in widespread use. Incorrect figures are sometimes cited for the population of ASL users in the United States based on misunderstandings of known statistics.Demographics of the deaf population have been confused with those of ASL use since adults who become deaf late in life rarely use ASL in the home.That accounts for currently-cited estimations that are greater than 500,000; such mistaken estimations can reach as high as 15,000,000.A 100,000-person lower bound has been cited for ASL users; the source of that figure is unclear, but it may be an estimate ofprelingual deafness, which is correlated with but not equivalent to signing. ASL is sometimes incorrectly cited as the third- or fourth-most-spoken language in the United States.Those figures misquote Schein and Delk (1974), who actually concluded that ASL speakers constituted the third-largest population \"requiring an interpreter in court\".Although that would make ASL the third-most used language amongmonolingualsother than English, it does not imply that it is the fourth-most-spoken language in the United States since speakers of other languages may also speak English. ASL is used throughoutAnglo-America.That contrasts with Europe, where a variety of sign languages are used within the same continent.The unique situation of ASL seems to have been caused by the proliferation of ASL through schools influenced by the American School for the Deaf, wherein ASL originated, and the rise of community organizations for the Deaf. ThroughoutWest Africa, ASL-based sign languages are signed by educated Deaf adults.Such languages, imported by boarding schools, are often considered by associations to be the official sign languages of their countries and are named accordingly, such asNigerian Sign LanguageandGhanaian Sign Language.Such signing systems are found inBenin,Burkina Faso,Ivory Coast,Ghana,Liberia,Mauritania,Mali,Nigeria, andTogo.Due to lack of data, it is still an open question how similar those sign languages are to the variety of ASL used in America. In addition to the aforementioned West African countries, ASL is reported to be used as afirst languageinBarbados,Bolivia,Cambodia(alongsideCambodian Sign Language), theCentral African Republic,Chad,China(Hong Kong), theDemocratic Republic of the Congo,Gabon,Jamaica,Kenya,Madagascar, thePhilippines,Singapore, andZimbabwe.ASL is also used as alingua francathroughout the deaf world, widely learned as asecond language. Sign production can often vary according to location. Signers from the South tend to sign with more flow and ease. Native signers from New York have been reported as signing comparatively quicker and sharper. Sign production of native Californian signers has also been reported as being fast. Research on that phenomenon often concludes that the fast-paced production for signers from the coasts could be due to the fast-paced nature of living in large metropolitan areas. That conclusion also supports how the ease with which Southerners sign could be caused by the easygoing environment of the South in comparison to that of the coasts. Sign production can also vary depending on age and native language. For example, sign production of letters may vary in older signers. Slight differences in finger spelling production can be a signal of age. Additionally, signers who learned American Sign Language as a second language vary in production. For Deaf signers who learned a different sign language before learning American Sign Language, qualities of their native language may show in their ASL production. Some examples of that varied production include fingerspelling towards the body, instead of away from it, and signing certain movement from bottom to top, instead of top to bottom. Hearing people who learn American Sign Language also have noticeable differences in signing production. The most notable production difference of hearing people learning American Sign Language is their rhythm and arm posture. Most popularly, there are variants of the signs for English words such as \"birthday\", \"pizza\", \"Halloween\", \"early\", and \"soon\", just a sample of the most commonly recognized signs with variants based on regional change. The sign for \"school\" is commonly varied between black and white signers; the variants used by black signers are sometimes calledBlack American Sign Language.Social variation is also found between citation forms and forms used by Deaf gay men for words such as \"pain\" and \"protest\". The prevalence of residential Deaf schools can account for much of the regional variance of signs and sign productions across the United States. Deaf schools often serve students of the state in which the school resides. That limited access to signers from other regions, combined with the residential quality of Deaf Schools promoted specific use of certain sign variants. Native signers did not have much access to signers from other regions during the beginning years of their education. It is hypothesized that because of that seclusion, certain variants of a sign prevailed over others due to the choice of variant used by the student of the school/signers in the community. However, American Sign Language does not appear to be vastly varied in comparison to other signed languages. That is because when Deaf education was beginning in the United States, many educators flocked to the American School for the Deaf in Hartford, Connecticut, whose central location for the first generation of educators in Deaf education to learn American Sign Language allows ASL to be more standardized than its variant. Varieties of ASL are found throughout theworld. There is little difficulty in comprehension among the varieties of the United States and Canada. Just as there are accents in speech, there are regional accents in sign. People from the South sign slower than people in the North—even people from northern and southern Indiana have different styles. —Walker, Lou Ann (1987).A Loss for Words: The Story of Deafness in a Family. New York: HarperPerennial. p.31.ISBN978-0-06-091425-7. Mutual intelligibilityamong those ASL varieties is high, and the variation is primarilylexical.For example, there are three different words for Englishaboutin Canadian ASL; the standard way, and two regional variations (Atlantic and Ontario).Variation may also bephonological, meaning that the same sign may be signed in a different way depending on the region. For example, an extremely common type of variation is between the handshapes /1/, /L/, and /5/ in signs with one handshape. There is also a distinct variety of ASL used by the Black Deaf community.Black ASLevolved as a result ofracially segregated schoolsin some states, which included the residential schools for the deaf.Black ASL differs from standard ASL in vocabulary, phonology, and some grammatical structure.WhileAfrican American English(AAE) is generally viewed as more innovating than standard English, Black ASL is more conservative than standard ASL, preserving older forms of many signs.Black sign language speakers use more two-handed signs than in mainstream ASL, are less likely to show assimilatory lowering of signs produced on the forehead (e.g. KNOW) and use a wider signing space.Modern Black ASL borrows a number of idioms from AAE; for instance, the AAE idiom \"I feel you\" iscalquedinto Black ASL. ASL is used internationally as alingua franca, and a number of closely related sign languages derived from ASL are used in many different countries.Even so, there have been varying degrees of divergence from standard ASL in those imported ASL varieties.Bolivian Sign Languageis reported to be a dialect of ASL, no more divergent than other acknowledged dialects.On the other hand, it is also known that some imported ASL varieties have diverged to the extent of being separate languages. For example,Malaysian Sign Language, which has ASL origins, is no longer mutually comprehensible with ASL and must be considered its own language.For some imported ASL varieties, such as those used in West Africa, it is still an open question how similar they are to American ASL. When communicating with hearing English speakers, ASL-speakers often use what is commonly calledPidgin Signed English(PSE) or 'contact signing', a blend of English structure with ASL vocabulary.Various types of PSE exist, ranging from highly English-influenced PSE (practicallyrelexifiedEnglish) to PSE which is quite close to ASL lexically and grammatically, but may alter some subtle features of ASL grammar.Fingerspelling may be used more often in PSE than it is normally used in ASL.There have been someconstructed sign languages, known asManually Coded English(MCE), which match English grammar exactly and simply replace spoken words with signs; those systems are not considered to be varieties of ASL. Tactile ASL(TASL) is a variety of ASL used throughout the United States by and with thedeaf-blind.It is particularly common among those withUsher's syndrome.It results in deafness from birth followed by loss of vision later in life; consequently, those with Usher's syndrome often grow up in the Deaf community using ASL, and later transition to TASL.TASL differs from ASL in that signs are produced by touching the palms, and there are some grammatical differences from standard ASL in order to compensate for the lack ofnonmanual signing. ASL changes over time and from generation to generation. The sign for telephone has changed as the shape of phones and the manner of holding them have changed.The development of telephones with screens has also changed ASL, encouraging the use of signs that can be seen on small screens. In 2013, the White House published a response to a petition that gained over 37,000 signatures toofficially recognize American Sign Language as a community language and a language of instruction in schools. The response is titled \"there shouldn't be any stigma about American Sign Language\" and addressed that ASL is a vital language for the Deaf and hard of hearing. Stigmas associated with sign languages and the use of sign for educating children often lead to the absence of sign during periods in children's lives when they can access languages most effectively.Scholars such asBeth S. Benedictadvocate not only forbilingualism(using ASL and English training) but also forearly childhood interventionfor children who are deaf.  York University psychologistEllen Bialystokhas also campaigned for bilingualism, arguing that those who are bilingual acquire cognitive skills that may help to prevent dementia later in life. Most children born to deaf parents are hearing.Known asCODAs(\"Children of Deaf Adults\"), they are often moreculturally Deafthan deaf children, most of whom are born to hearing parents.Unlike many deaf children, CODAs acquire ASL as well as Deaf cultural values and behaviors from birth.Suchbilingualhearing children may be mistakenly labeled as being \"slow learners\" or as having \"language difficulties\" because of preferential attitudes towards spoken language. Although there is no well-established writing system for ASL,written sign language dates back almost two centuries. The first systematic writing system for a sign language seems to be that ofRoch-Ambroise Auguste Bébian, developed in 1825.However, written sign language remained marginal among the public.In the 1960s, linguist William Stokoe createdStokoe notationspecifically for ASL. It is alphabetic, with a letter ordiacriticfor everyphonemic(distinctive) hand shape, orientation, motion, and position, though it lacks any representation of facial expression, and is better suited for individual words than for extended passages of text.Stokoe used that system for his 1965A Dictionary of American Sign Language on Linguistic Principles. SignWriting, proposed in 1974 byValerie Sutton,is the first writing system to gain use among the public and the first writing system for sign languages to be included in theUnicode Standard.SignWriting consists of more than 5000 distinct iconic graphs/glyphs.Currently, it is in use in many schools for the Deaf, particularly in Brazil, and has been used inInternational Signforums with speakers and researchers in more than 40 countries, including Brazil, Ethiopia, France, Germany, Italy, Portugal, Saudi Arabia, Slovenia, Tunisia, and the United States. Sutton SignWriting has both a printed and an electronically produced form so that persons can use the system anywhere that oral languages are written (personal letters, newspapers, and media, academic research). The systematic examination of the International Sign Writing Alphabet (ISWA) as an equivalent usage structure to theInternational Phonetic Alphabetfor spoken languages has been proposed.According to some researchers, SignWriting is not aphonemic orthographyand does not have a one-to-one map from phonological forms to written forms.That assertion has been disputed, and the process for each country to look at the ISWA and create a phonemic/morphemic assignment of features of each sign language was proposed by researchers Msc. Roberto Cesar Reis da Costa and Madson Barreto in a thesis forum on June 23, 2014.The SignWriting community has an open project on Wikimedia Labs to support the various Wikimedia projects onWikimedia Incubatorand elsewhere involving SignWriting.  The ASL Wikipedia request was marked as eligible in 2008and the test ASL Wikipedia has 50 articles written in ASL using SignWriting. The most widely usedtranscriptionsystem among academics isHamNoSys, developed at theUniversity of Hamburg.Based on Stokoe Notation, HamNoSys was expanded to about 200 graphs in order to allow transcription of any sign language.Phonological features are usually indicated with single symbols, though the group of features that make up a handshape is indicated collectively with a symbol. Several additional candidates for written ASL have appeared over the years, includingSignFont,ASL-phabet, andSi5s. For English-speaking audiences, ASL is oftenglossedusing English words. Such glosses are typically all-capitalized and are arranged in ASL order. For example, the ASL sentenceDOG NOW CHASE>IX=3 CAT, meaning \"the dog is chasing the cat\", uses NOW to mark ASLprogressive aspectand shows ASL verbal inflection for the third person (>IX=3). However, glossing is not used to write the language for speakers of ASL. Each sign in ASL is composed of a number of distinctive components, generally referred to as parameters. A sign may use one hand or both. All signs can be described using the five parameters involved in signed languages, which arehandshape,movement,palm orientation,locationandnonmanual markers.Just as phonemes of sound distinguish meaning in spoken languages, those parameters are the phonemes that distinguish meaning in signed languages like ASL.Changing any one of them may change the meaning of a sign, as illustrated by the ASL signs THINK and DISAPPOINTED: There are also meaningfulnonmanual signalsin ASL,which may include movement of the eyebrows, the cheeks, the nose, the head, the torso, and the eyes. William Stokoeproposed that such components are analogous to thephonemesof spoken languages.There has also been a proposal that they are analogous to classes likeplaceandmanner of articulation.As in spoken languages, those phonological units can be split intodistinctive features.For instance, the handshapes /2/ and /3/ are distinguished by the presence or absence of the feature [± closed thumb], as illustrated to the right.ASL has processes ofallophonyandphonotacticrestrictions.There is ongoing research into whether ASL has an analog ofsyllablesin spoken language. ASL has a rich system of verbalinflection, which involves bothgrammatical aspect: how the action of verbs flows in time—andagreementmarking.Aspect can be marked by changing the manner of movement of the verb; for example,continuous aspectis marked by incorporating rhythmic, circular movement, while punctual aspect is achieved by modifying the sign so that it has a stationary hand position.Verbs may agree with both thesubjectand theobject, and are marked fornumberand reciprocity.Reciprocity is indicated by using two one-handed signs; for example, the sign SHOOT, made with an L-shaped handshape with inward movement of the thumb, inflects to SHOOT[reciprocal], articulated by having two L-shaped hands \"shooting\" at each other. ASL has a productive system ofclassifiers, which are used to classify objects and their movement in space.For example, a rabbit running downhill would use a classifier consisting of a bent V classifier handshape with a downhill-directed path; if the rabbit is hopping, the path is executed with a bouncy manner.In general, classifiers are composed of a \"classifier handshape\"boundto a \"movement root\".The classifier handshape represents the object as a whole, incorporating such attributes as surface, depth, and shape, and is usually very iconic.The movement root consists of a path, a direction and a manner. In linguistics, there are two primary ways of changing the form of a word: derivation and inflection. Derivation involves creating new words by adding something to an existing word, while inflection involves changing the form of a word to convey grammatical information without altering its fundamental meaning or category. For example, adding the suffix \"-ship\" to the noun \"friend\" creates the new word \"friendship\", which has a different meaning than the original word. Inflection, on the other hand, involves modifying a word's form to indicate grammatical features such as tense, number, gender, person, case, and degree of comparison. In American Sign Language (ASL), inflection is conveyed through facial expressions, body movements, and other non-manual markers. For instance, to indicate past tense in ASL, one might sign the present tense of a verb (such as \"walk\"), and then add a facial expression and head tilt to signify that the action occurred in the past (i.e., \"walked\"). According to the book Linguistics of American Sign Language, ASL signs have two main components: hold segments and movement segments. Hold segments consist of hand-shape, location, orientation, and non-manual features, while movement segments possess similar features. Morphology is the study of how languages form words by using smaller units to construct larger units. The smallest meaningful unit in a language is known as a \"morpheme\", with some morphemes able to stand alone as independent units (free morphemes), while others must occur with other morphemes (bound morphemes). For example, the plural \"-s\" and third person \"-s\" in English are bound morphemes. In ASL, the 3 handshape in signs like THREE-WEEKS and THREE-MONTHS are also bound morphemes. Affixes, which are morphemes added to words to create new words or modify their meanings, are part of the derivational process. For example, in English, prefixes like \"re-\" and suffixes like \"-able\" are affixes. In ASL, affixation can be used to modify the sign for CHAIR to indicate different types of chairs. The inflectional process, on the other hand, adds grammatical information to existing units. By studying morphemes and how they can be combined or modified, linguists gain insight into the underlying structure of language and the creative ways in which it can be used to express meaning. Understanding morphology is essential to understanding how languages are built and how new signs or words can be formed. Furthermore, understanding morphology has practical applications in language learning and teaching. For example, teaching students the basic morphological structures of a language can help them to better understand the language's grammar and syntax, and can also aid in their acquisition of new vocabulary. In summary, morphology is an essential component of language and provides valuable insights into the structure and function of languages. By understanding the morphological processes involved in language formation, we can gain a deeper understanding of how languages work and how they can be effectively taught and learned. American Sign Language possesses a set of 26 signs known as theAmerican manual alphabet, which can be used to spell out words from the English language.It is rather a representation of the English alphabet, and not a unique alphabet of ASL, although commonly labeled as the \"ASL alphabet\".It is borrowed from French Sign Language (LSF), as much of ASL is derived from LSF.Such signs make use of the 19 handshapes of ASL. For example, the signs for 'p' and 'k' use the same handshape but different orientations. A common misconception is that ASL consists only of fingerspelling; although such a method (Rochester Method) has been used, it is not ASL. Fingerspelling is a form ofborrowing, a linguistic process wherein words from one language are incorporated into another.In ASL, fingerspelling is used forproper nounsand for technical terms with no native ASL equivalent.There are also some other loan words which are fingerspelled, either very short English words or abbreviations of longer English words, e.g.O-Nfrom English 'on', andA-P-Tfrom English 'apartment'.Fingerspelling may also be used to emphasize a word that would normally be signed otherwise. ASL is asubject–verb–object(SVO) language, but various phenomena affect that basic word order.Basic SVO sentences are signed without any pauses: FATHER LOVE CHILD FATHER LOVE CHILD \"The father loves the child.\" However, other word orders may also occur since ASL allows thetopicof a sentence to be moved to sentence-initial position, a phenomenon known astopicalization.Inobject–subject–verb(OSV) sentences, the object is topicalized, marked by a forward head-tilt and a pause: CHILD, FATHER LOVE CHILD, FATHER LOVE \"The father loves the child.\" Besides, word orders can be obtained through the phenomenon of subject copy in which the subject is repeated at the end of the sentence, accompanied by head nodding for clarification or emphasis: FATHER LOVE CHILD FATHER FATHER LOVE CHILD FATHER \"The father loves the child.\" ASL also allowsnull subjectsentences whose subject is implied, rather than stated explicitly. Subjects can be copied even in a null subject sentence, and the subject is then omitted from its original position, yielding averb–object–subject(VOS) construction: LOVE CHILD FATHER LOVE CHILD FATHER \"The father loves the child.\" Topicalization, accompanied with a null subject and a subject copy, can produce yet another word order,object–verb–subject(OVS). CHILD, LOVE FATHER CHILD, LOVE FATHER \"The father loves the child.\" Those properties of ASL allow it a variety of word orders, leading many to question which is the true, underlying, \"basic\" order. There are several other proposals that attempt to account for the flexibility of word order in ASL. One proposal is that languages like ASL are best described with atopic–commentstructure whose words are ordered by their importance in the sentence, rather than by their syntactic properties.Another hypothesis is that ASL exhibitsfree word order, in which syntax is not encoded in word order but can be encoded by other means such as head nods, eyebrow movement, and body position. Common misconceptions are that signs are iconically self-explanatory, that they are a transparent imitation of what they mean, or even that they arepantomime.In fact, many signs bear no resemblance to their referent because they were originally arbitrary symbols, or their iconicity has been obscured over time.Even so, in ASLiconicityplays a significant role; a high percentage of signs resemble their referents in some way.That may be because the medium of sign, three-dimensional space, naturally allows more iconicity than oral language. In the era of the influential linguistFerdinand de Saussure, it was assumed that the mapping between form and meaning in language must be completely arbitrary.Althoughonomatopoeiais a clear exception, since words like \"choo-choo\" bear clear resemblance to the sounds that they mimic, the Saussurean approach was to treat them as marginal exceptions.ASL, with its significant inventory of iconic signs, directly challenges that theory. Research on acquisition of pronouns in ASL has shown that children do not always take advantage of the iconic properties of signs when they interpret their meaning.It has been found that when children acquire the pronoun \"you\", the iconicity of the point (at the child) is often confused, being treated more like a name.That is a similar finding to research in oral languages on pronoun acquisition. It has also been found that iconicity of signs does not affect immediate memory and recall; less iconic signs are remembered just as well as highly-iconic signs. ^bDenotes the number (if known) of languages within the family. No further information is given on these languages. ", "combined_text": "American Sign Language Contents Classification History Population Geographic distribution Regional variation Sign production Sign variants History and implications Varieties Stigma Writing systems Phonology Grammar Morphology Syntax Iconicity See also Notes References Bibliography External links American Sign Language(ASL) is anatural languagethat serves as the predominantsign languageofDeaf communitiesin the United States and most ofAnglophone Canada. ASL is a complete and organizedvisual languagethat is expressed by employing both manual andnonmanual features.Besides North America, dialects of ASL and ASL-basedcreolesare used in many countries around the world, including much ofWest Africaand parts ofSoutheast Asia. ASL is also widely learned as asecond language, serving as alingua franca. ASL is most closely related toFrench Sign Language(LSF). It has been proposed that ASL is a creole language of LSF, although ASL shows features atypical of creole languages, such asagglutinative morphology. ASL originated in the early 19th century in theAmerican School for the Deaf(ASD) inHartford, Connecticut, from a situation oflanguage contact. Since then, ASL use has been propagated widely by schools for the deaf and deaf community organizations. Despite its wide use, no accurate count of ASL users has been taken. Reliable estimates for American ASL users range from 250,000 to 500,000 persons, including a number ofchildren of deaf adults(CODA) and other hearing individuals. Signs in ASL have a number ofphonemiccomponents, such as movement of the face, the torso, and the hands. ASL is not a form ofpantomime, althoughiconicityplays a larger role in ASL than in spoken languages. Englishloan wordsare often borrowed throughfingerspelling, although ASL grammar is unrelated to that of English. ASL has verbalagreementandaspectualmarking and has a productive system of forming agglutinativeclassifiers. Many linguists believe ASL to be asubject–verb–objectlanguage. However, there are several other proposals to account for ASL word order. ASL emerged as a language in theAmerican School for the Deaf(ASD), founded byThomas Gallaudetin 1817,which brought togetherOld French Sign Language, variousvillage sign languages, andhome signsystems. ASL was created in that situation bylanguage contact.ASL is influenced by its forerunners, yet linguistically distinct. The influence of French Sign Language (LSF) on ASL is readily apparent; for example, it has been found that about 58% of signs in modern ASL arecognateto Old French Sign Language signs.However, that is far less than the standard 80% measure used to determine whether related languages are actuallydialects.That suggests nascent ASL was highly affected by the other signing systems brought by the ASD students although the school's original director,Laurent Clerc, taught in LSF.In fact, Clerc reported that he often learned the students' signs rather than conveying LSF: I see, however, and I say it with regret, that any efforts that we have made or may still be making, to do better than, we have inadvertently fallen somewhat back of Abbé de l'Épée. Some of us have learned and still learn signs from uneducated pupils, instead of learning them from well instructed and experienced teachers. — Clerc, 1852, from Woodward 1978:336 It has been proposed that ASL is acreolein which LSF is thesuperstratelanguage and the native village sign languages aresubstratelanguages.However, more recent research has shown that modern ASL does not share many of the structural features that characterize creole languages.ASL may have begun as a creole and then undergone structural change over time, but it is also possible that it was never a creole-type language.There are modality-specific reasons that signed languages tend towardsagglutination, such as the ability to simultaneously convey information via the face, head, torso, and other body parts. That might override creole characteristics such as the tendency towardsisolating morphology.Additionally, Clerc andThomas Hopkins Gallaudetmay have used an artificially constructed form ofmanually coded languagein instruction rather than true LSF. Although the United States, the United Kingdom, and Australia share English as a common oral and written language, ASL is not mutually intelligible with eitherBritish Sign Language(BSL) orAuslan.All three languages show degrees of borrowing from English, but that alone is not sufficient for cross-language comprehension.It has been found that a relatively high percentage (37–44%) of ASL signs have similar translations in Auslan, which for oral languages would suggest that they belong to the samelanguage family.However, that does not seem justified historically for ASL and Auslan, and it is likely that the resemblance is caused by the higher degree oficonicityin sign languages in general as well as contact with English. American Sign Language is growing in popularity in many states. Many high school and university students desire to take it as a foreign language, but until recently, it was usually not considered a creditable foreign language elective. ASL users, however, have a very distinct culture, and they interact very differently when they talk. Their facial expressions and hand movements reflect what they are communicating. They also have their own sentence structure, which sets the language apart. American Sign Language is now being accepted by many colleges as a language eligible for foreign language course credit;many states are making it mandatory to accept it as such.In some states however, this is only true with regard to high school coursework. Prior to the birth of ASL, sign language had been used by various communities in the United States.In the United States, as elsewhere in the world, hearing families with deaf children have historically employed ad hochome sign, which often reaches much higher levels of sophistication than gestures used by hearing people in spoken conversation.As early as 1541 at first contact byFrancisco Vásquez de Coronado, there were reports that theIndigenous peoples of the Great Plainswidely spokea sign languageto communicate across vast national and linguistic lines. In the 19th century, a \"triangle\" ofvillage sign languagesdeveloped inNew England: one inMartha's Vineyard, Massachusetts; one inHenniker, New Hampshire, and one inSandy River Valley, Maine.Martha's Vineyard Sign Language(MVSL), which was particularly important for the history of ASL, was used mainly inChilmark, Massachusetts.Due to intermarriage in the original community of English settlers of the 1690s, and therecessivenature of genetic deafness, Chilmark had a high 4% rate of genetic deafness.MVSL was used even by hearing residents whenever a deaf person was present,and also in some situations where spoken language would be ineffective or inappropriate, such as during church sermons or between boats at sea. ASL is thought to have originated in theAmerican School for the Deaf(ASD), founded inHartford, Connecticut, in 1817.Originally known asThe American Asylum, At Hartford, For The Education And Instruction Of The Deaf And Dumb, the school was founded by the Yale graduate and divinity studentThomas Hopkins Gallaudet.Gallaudet, inspired by his success in demonstrating the learning abilities of a young deaf girlAlice Cogswell, traveled to Europe in order to learn deaf pedagogy from European institutions.Ultimately, Gallaudet chose to adopt the methods of the FrenchInstitut National de Jeunes Sourds de Paris, and convincedLaurent Clerc, an assistant to the school's founderCharles-Michel de l'Épée, to accompany him back to the United States.Upon his return, Gallaudet founded the ASD on April 15, 1817. The largest group of students during the first seven decades of the school were from Martha's Vineyard, and they brought MVSL with them.There were also 44 students from around Henniker, New Hampshire, and 27 from the Sandy River valley in Maine, each of which had their own village sign language.Other students brought knowledge of their own home signs.Laurent Clerc, the first teacher at ASD, taught usingFrench Sign Language(LSF), which itself had developed in the Parisian school for the deaf established in 1755.From that situation oflanguage contact, a new language emerged, now known as ASL. More schools for the deaf were founded after ASD, and knowledge of ASL spread to those schools.In addition, the rise of Deaf community organizations bolstered the continued use of ASL.Societies such as theNational Association of the Deafand the National Fraternal Society of the Deaf held national conventions that attracted signers from across the country.All of that contributed to ASL's wide use over a large geographical area, atypical of a sign language. Whileoralism, an approach to educating deaf students focusing on oral language, had previously been used in American schools, theMilan Congressmade it dominant and effectively banned the use of sign languages at schools in the United States and Europe. However, the efforts of Deaf advocates and educators, more lenient enforcement of the Congress's mandate, and the use of ASL in religious education and proselytism ensured greater use and documentation compared to European sign languages, albeit more influenced by fingerspelled loanwords and borrowed idioms from English as students were societally pressured to achieve fluency in spoken language.Nevertheless, oralism remained the predominant method of deaf education up to the 1950s.Linguists did not consider sign language to be true \"language\" but as something inferior.Recognition of the legitimacy of ASL was achieved byWilliam Stokoe, a linguist who arrived atGallaudet Universityin 1955 when that was still the dominant assumption.Aided by theCivil Rights Movementof the1960s, Stokoe argued formanualism, the use of sign language in deaf education.Stokoe noted that sign language shares the important features that oral languages have as a means of communication, and even devised atranscriptionsystem for ASL.In doing so, Stokoe revolutionized both deaf education and linguistics.In the 1960s, ASL was sometimes referred to as \"Ameslan\", but that term is now considered obsolete. Counting the number of ASL signers is difficult because ASL users have never been counted by the American census.The ultimate source for current estimates of the number of ASL users in the United States is a report for the National Census of the Deaf Population (NCDP) by Schein and Delk (1974).Based on a 1972 survey of the NCDP, Schein and Delk provided estimates consistent with a signing population between 250,000 and 500,000.The survey did not distinguish between ASL and other forms of signing; in fact, the name \"ASL\" was not yet in widespread use. Incorrect figures are sometimes cited for the population of ASL users in the United States based on misunderstandings of known statistics.Demographics of the deaf population have been confused with those of ASL use since adults who become deaf late in life rarely use ASL in the home.That accounts for currently-cited estimations that are greater than 500,000; such mistaken estimations can reach as high as 15,000,000.A 100,000-person lower bound has been cited for ASL users; the source of that figure is unclear, but it may be an estimate ofprelingual deafness, which is correlated with but not equivalent to signing. ASL is sometimes incorrectly cited as the third- or fourth-most-spoken language in the United States.Those figures misquote Schein and Delk (1974), who actually concluded that ASL speakers constituted the third-largest population \"requiring an interpreter in court\".Although that would make ASL the third-most used language amongmonolingualsother than English, it does not imply that it is the fourth-most-spoken language in the United States since speakers of other languages may also speak English. ASL is used throughoutAnglo-America.That contrasts with Europe, where a variety of sign languages are used within the same continent.The unique situation of ASL seems to have been caused by the proliferation of ASL through schools influenced by the American School for the Deaf, wherein ASL originated, and the rise of community organizations for the Deaf. ThroughoutWest Africa, ASL-based sign languages are signed by educated Deaf adults.Such languages, imported by boarding schools, are often considered by associations to be the official sign languages of their countries and are named accordingly, such asNigerian Sign LanguageandGhanaian Sign Language.Such signing systems are found inBenin,Burkina Faso,Ivory Coast,Ghana,Liberia,Mauritania,Mali,Nigeria, andTogo.Due to lack of data, it is still an open question how similar those sign languages are to the variety of ASL used in America. In addition to the aforementioned West African countries, ASL is reported to be used as afirst languageinBarbados,Bolivia,Cambodia(alongsideCambodian Sign Language), theCentral African Republic,Chad,China(Hong Kong), theDemocratic Republic of the Congo,Gabon,Jamaica,Kenya,Madagascar, thePhilippines,Singapore, andZimbabwe.ASL is also used as alingua francathroughout the deaf world, widely learned as asecond language. Sign production can often vary according to location. Signers from the South tend to sign with more flow and ease. Native signers from New York have been reported as signing comparatively quicker and sharper. Sign production of native Californian signers has also been reported as being fast. Research on that phenomenon often concludes that the fast-paced production for signers from the coasts could be due to the fast-paced nature of living in large metropolitan areas. That conclusion also supports how the ease with which Southerners sign could be caused by the easygoing environment of the South in comparison to that of the coasts. Sign production can also vary depending on age and native language. For example, sign production of letters may vary in older signers. Slight differences in finger spelling production can be a signal of age. Additionally, signers who learned American Sign Language as a second language vary in production. For Deaf signers who learned a different sign language before learning American Sign Language, qualities of their native language may show in their ASL production. Some examples of that varied production include fingerspelling towards the body, instead of away from it, and signing certain movement from bottom to top, instead of top to bottom. Hearing people who learn American Sign Language also have noticeable differences in signing production. The most notable production difference of hearing people learning American Sign Language is their rhythm and arm posture. Most popularly, there are variants of the signs for English words such as \"birthday\", \"pizza\", \"Halloween\", \"early\", and \"soon\", just a sample of the most commonly recognized signs with variants based on regional change. The sign for \"school\" is commonly varied between black and white signers; the variants used by black signers are sometimes calledBlack American Sign Language.Social variation is also found between citation forms and forms used by Deaf gay men for words such as \"pain\" and \"protest\". The prevalence of residential Deaf schools can account for much of the regional variance of signs and sign productions across the United States. Deaf schools often serve students of the state in which the school resides. That limited access to signers from other regions, combined with the residential quality of Deaf Schools promoted specific use of certain sign variants. Native signers did not have much access to signers from other regions during the beginning years of their education. It is hypothesized that because of that seclusion, certain variants of a sign prevailed over others due to the choice of variant used by the student of the school/signers in the community. However, American Sign Language does not appear to be vastly varied in comparison to other signed languages. That is because when Deaf education was beginning in the United States, many educators flocked to the American School for the Deaf in Hartford, Connecticut, whose central location for the first generation of educators in Deaf education to learn American Sign Language allows ASL to be more standardized than its variant. Varieties of ASL are found throughout theworld. There is little difficulty in comprehension among the varieties of the United States and Canada. Just as there are accents in speech, there are regional accents in sign. People from the South sign slower than people in the North—even people from northern and southern Indiana have different styles. —Walker, Lou Ann (1987).A Loss for Words: The Story of Deafness in a Family. New York: HarperPerennial. p.31.ISBN978-0-06-091425-7. Mutual intelligibilityamong those ASL varieties is high, and the variation is primarilylexical.For example, there are three different words for Englishaboutin Canadian ASL; the standard way, and two regional variations (Atlantic and Ontario).Variation may also bephonological, meaning that the same sign may be signed in a different way depending on the region. For example, an extremely common type of variation is between the handshapes /1/, /L/, and /5/ in signs with one handshape. There is also a distinct variety of ASL used by the Black Deaf community.Black ASLevolved as a result ofracially segregated schoolsin some states, which included the residential schools for the deaf.Black ASL differs from standard ASL in vocabulary, phonology, and some grammatical structure.WhileAfrican American English(AAE) is generally viewed as more innovating than standard English, Black ASL is more conservative than standard ASL, preserving older forms of many signs.Black sign language speakers use more two-handed signs than in mainstream ASL, are less likely to show assimilatory lowering of signs produced on the forehead (e.g. KNOW) and use a wider signing space.Modern Black ASL borrows a number of idioms from AAE; for instance, the AAE idiom \"I feel you\" iscalquedinto Black ASL. ASL is used internationally as alingua franca, and a number of closely related sign languages derived from ASL are used in many different countries.Even so, there have been varying degrees of divergence from standard ASL in those imported ASL varieties.Bolivian Sign Languageis reported to be a dialect of ASL, no more divergent than other acknowledged dialects.On the other hand, it is also known that some imported ASL varieties have diverged to the extent of being separate languages. For example,Malaysian Sign Language, which has ASL origins, is no longer mutually comprehensible with ASL and must be considered its own language.For some imported ASL varieties, such as those used in West Africa, it is still an open question how similar they are to American ASL. When communicating with hearing English speakers, ASL-speakers often use what is commonly calledPidgin Signed English(PSE) or 'contact signing', a blend of English structure with ASL vocabulary.Various types of PSE exist, ranging from highly English-influenced PSE (practicallyrelexifiedEnglish) to PSE which is quite close to ASL lexically and grammatically, but may alter some subtle features of ASL grammar.Fingerspelling may be used more often in PSE than it is normally used in ASL.There have been someconstructed sign languages, known asManually Coded English(MCE), which match English grammar exactly and simply replace spoken words with signs; those systems are not considered to be varieties of ASL. Tactile ASL(TASL) is a variety of ASL used throughout the United States by and with thedeaf-blind.It is particularly common among those withUsher's syndrome.It results in deafness from birth followed by loss of vision later in life; consequently, those with Usher's syndrome often grow up in the Deaf community using ASL, and later transition to TASL.TASL differs from ASL in that signs are produced by touching the palms, and there are some grammatical differences from standard ASL in order to compensate for the lack ofnonmanual signing. ASL changes over time and from generation to generation. The sign for telephone has changed as the shape of phones and the manner of holding them have changed.The development of telephones with screens has also changed ASL, encouraging the use of signs that can be seen on small screens. In 2013, the White House published a response to a petition that gained over 37,000 signatures toofficially recognize American Sign Language as a community language and a language of instruction in schools. The response is titled \"there shouldn't be any stigma about American Sign Language\" and addressed that ASL is a vital language for the Deaf and hard of hearing. Stigmas associated with sign languages and the use of sign for educating children often lead to the absence of sign during periods in children's lives when they can access languages most effectively.Scholars such asBeth S. Benedictadvocate not only forbilingualism(using ASL and English training) but also forearly childhood interventionfor children who are deaf.  York University psychologistEllen Bialystokhas also campaigned for bilingualism, arguing that those who are bilingual acquire cognitive skills that may help to prevent dementia later in life. Most children born to deaf parents are hearing.Known asCODAs(\"Children of Deaf Adults\"), they are often moreculturally Deafthan deaf children, most of whom are born to hearing parents.Unlike many deaf children, CODAs acquire ASL as well as Deaf cultural values and behaviors from birth.Suchbilingualhearing children may be mistakenly labeled as being \"slow learners\" or as having \"language difficulties\" because of preferential attitudes towards spoken language. Although there is no well-established writing system for ASL,written sign language dates back almost two centuries. The first systematic writing system for a sign language seems to be that ofRoch-Ambroise Auguste Bébian, developed in 1825.However, written sign language remained marginal among the public.In the 1960s, linguist William Stokoe createdStokoe notationspecifically for ASL. It is alphabetic, with a letter ordiacriticfor everyphonemic(distinctive) hand shape, orientation, motion, and position, though it lacks any representation of facial expression, and is better suited for individual words than for extended passages of text.Stokoe used that system for his 1965A Dictionary of American Sign Language on Linguistic Principles. SignWriting, proposed in 1974 byValerie Sutton,is the first writing system to gain use among the public and the first writing system for sign languages to be included in theUnicode Standard.SignWriting consists of more than 5000 distinct iconic graphs/glyphs.Currently, it is in use in many schools for the Deaf, particularly in Brazil, and has been used inInternational Signforums with speakers and researchers in more than 40 countries, including Brazil, Ethiopia, France, Germany, Italy, Portugal, Saudi Arabia, Slovenia, Tunisia, and the United States. Sutton SignWriting has both a printed and an electronically produced form so that persons can use the system anywhere that oral languages are written (personal letters, newspapers, and media, academic research). The systematic examination of the International Sign Writing Alphabet (ISWA) as an equivalent usage structure to theInternational Phonetic Alphabetfor spoken languages has been proposed.According to some researchers, SignWriting is not aphonemic orthographyand does not have a one-to-one map from phonological forms to written forms.That assertion has been disputed, and the process for each country to look at the ISWA and create a phonemic/morphemic assignment of features of each sign language was proposed by researchers Msc. Roberto Cesar Reis da Costa and Madson Barreto in a thesis forum on June 23, 2014.The SignWriting community has an open project on Wikimedia Labs to support the various Wikimedia projects onWikimedia Incubatorand elsewhere involving SignWriting.  The ASL Wikipedia request was marked as eligible in 2008and the test ASL Wikipedia has 50 articles written in ASL using SignWriting. The most widely usedtranscriptionsystem among academics isHamNoSys, developed at theUniversity of Hamburg.Based on Stokoe Notation, HamNoSys was expanded to about 200 graphs in order to allow transcription of any sign language.Phonological features are usually indicated with single symbols, though the group of features that make up a handshape is indicated collectively with a symbol. Several additional candidates for written ASL have appeared over the years, includingSignFont,ASL-phabet, andSi5s. For English-speaking audiences, ASL is oftenglossedusing English words. Such glosses are typically all-capitalized and are arranged in ASL order. For example, the ASL sentenceDOG NOW CHASE>IX=3 CAT, meaning \"the dog is chasing the cat\", uses NOW to mark ASLprogressive aspectand shows ASL verbal inflection for the third person (>IX=3). However, glossing is not used to write the language for speakers of ASL. Each sign in ASL is composed of a number of distinctive components, generally referred to as parameters. A sign may use one hand or both. All signs can be described using the five parameters involved in signed languages, which arehandshape,movement,palm orientation,locationandnonmanual markers.Just as phonemes of sound distinguish meaning in spoken languages, those parameters are the phonemes that distinguish meaning in signed languages like ASL.Changing any one of them may change the meaning of a sign, as illustrated by the ASL signs THINK and DISAPPOINTED: There are also meaningfulnonmanual signalsin ASL,which may include movement of the eyebrows, the cheeks, the nose, the head, the torso, and the eyes. William Stokoeproposed that such components are analogous to thephonemesof spoken languages.There has also been a proposal that they are analogous to classes likeplaceandmanner of articulation.As in spoken languages, those phonological units can be split intodistinctive features.For instance, the handshapes /2/ and /3/ are distinguished by the presence or absence of the feature [± closed thumb], as illustrated to the right.ASL has processes ofallophonyandphonotacticrestrictions.There is ongoing research into whether ASL has an analog ofsyllablesin spoken language. ASL has a rich system of verbalinflection, which involves bothgrammatical aspect: how the action of verbs flows in time—andagreementmarking.Aspect can be marked by changing the manner of movement of the verb; for example,continuous aspectis marked by incorporating rhythmic, circular movement, while punctual aspect is achieved by modifying the sign so that it has a stationary hand position.Verbs may agree with both thesubjectand theobject, and are marked fornumberand reciprocity.Reciprocity is indicated by using two one-handed signs; for example, the sign SHOOT, made with an L-shaped handshape with inward movement of the thumb, inflects to SHOOT[reciprocal], articulated by having two L-shaped hands \"shooting\" at each other. ASL has a productive system ofclassifiers, which are used to classify objects and their movement in space.For example, a rabbit running downhill would use a classifier consisting of a bent V classifier handshape with a downhill-directed path; if the rabbit is hopping, the path is executed with a bouncy manner.In general, classifiers are composed of a \"classifier handshape\"boundto a \"movement root\".The classifier handshape represents the object as a whole, incorporating such attributes as surface, depth, and shape, and is usually very iconic.The movement root consists of a path, a direction and a manner. In linguistics, there are two primary ways of changing the form of a word: derivation and inflection. Derivation involves creating new words by adding something to an existing word, while inflection involves changing the form of a word to convey grammatical information without altering its fundamental meaning or category. For example, adding the suffix \"-ship\" to the noun \"friend\" creates the new word \"friendship\", which has a different meaning than the original word. Inflection, on the other hand, involves modifying a word's form to indicate grammatical features such as tense, number, gender, person, case, and degree of comparison. In American Sign Language (ASL), inflection is conveyed through facial expressions, body movements, and other non-manual markers. For instance, to indicate past tense in ASL, one might sign the present tense of a verb (such as \"walk\"), and then add a facial expression and head tilt to signify that the action occurred in the past (i.e., \"walked\"). According to the book Linguistics of American Sign Language, ASL signs have two main components: hold segments and movement segments. Hold segments consist of hand-shape, location, orientation, and non-manual features, while movement segments possess similar features. Morphology is the study of how languages form words by using smaller units to construct larger units. The smallest meaningful unit in a language is known as a \"morpheme\", with some morphemes able to stand alone as independent units (free morphemes), while others must occur with other morphemes (bound morphemes). For example, the plural \"-s\" and third person \"-s\" in English are bound morphemes. In ASL, the 3 handshape in signs like THREE-WEEKS and THREE-MONTHS are also bound morphemes. Affixes, which are morphemes added to words to create new words or modify their meanings, are part of the derivational process. For example, in English, prefixes like \"re-\" and suffixes like \"-able\" are affixes. In ASL, affixation can be used to modify the sign for CHAIR to indicate different types of chairs. The inflectional process, on the other hand, adds grammatical information to existing units. By studying morphemes and how they can be combined or modified, linguists gain insight into the underlying structure of language and the creative ways in which it can be used to express meaning. Understanding morphology is essential to understanding how languages are built and how new signs or words can be formed. Furthermore, understanding morphology has practical applications in language learning and teaching. For example, teaching students the basic morphological structures of a language can help them to better understand the language's grammar and syntax, and can also aid in their acquisition of new vocabulary. In summary, morphology is an essential component of language and provides valuable insights into the structure and function of languages. By understanding the morphological processes involved in language formation, we can gain a deeper understanding of how languages work and how they can be effectively taught and learned. American Sign Language possesses a set of 26 signs known as theAmerican manual alphabet, which can be used to spell out words from the English language.It is rather a representation of the English alphabet, and not a unique alphabet of ASL, although commonly labeled as the \"ASL alphabet\".It is borrowed from French Sign Language (LSF), as much of ASL is derived from LSF.Such signs make use of the 19 handshapes of ASL. For example, the signs for 'p' and 'k' use the same handshape but different orientations. A common misconception is that ASL consists only of fingerspelling; although such a method (Rochester Method) has been used, it is not ASL. Fingerspelling is a form ofborrowing, a linguistic process wherein words from one language are incorporated into another.In ASL, fingerspelling is used forproper nounsand for technical terms with no native ASL equivalent.There are also some other loan words which are fingerspelled, either very short English words or abbreviations of longer English words, e.g.O-Nfrom English 'on', andA-P-Tfrom English 'apartment'.Fingerspelling may also be used to emphasize a word that would normally be signed otherwise. ASL is asubject–verb–object(SVO) language, but various phenomena affect that basic word order.Basic SVO sentences are signed without any pauses: FATHER LOVE CHILD FATHER LOVE CHILD \"The father loves the child.\" However, other word orders may also occur since ASL allows thetopicof a sentence to be moved to sentence-initial position, a phenomenon known astopicalization.Inobject–subject–verb(OSV) sentences, the object is topicalized, marked by a forward head-tilt and a pause: CHILD, FATHER LOVE CHILD, FATHER LOVE \"The father loves the child.\" Besides, word orders can be obtained through the phenomenon of subject copy in which the subject is repeated at the end of the sentence, accompanied by head nodding for clarification or emphasis: FATHER LOVE CHILD FATHER FATHER LOVE CHILD FATHER \"The father loves the child.\" ASL also allowsnull subjectsentences whose subject is implied, rather than stated explicitly. Subjects can be copied even in a null subject sentence, and the subject is then omitted from its original position, yielding averb–object–subject(VOS) construction: LOVE CHILD FATHER LOVE CHILD FATHER \"The father loves the child.\" Topicalization, accompanied with a null subject and a subject copy, can produce yet another word order,object–verb–subject(OVS). CHILD, LOVE FATHER CHILD, LOVE FATHER \"The father loves the child.\" Those properties of ASL allow it a variety of word orders, leading many to question which is the true, underlying, \"basic\" order. There are several other proposals that attempt to account for the flexibility of word order in ASL. One proposal is that languages like ASL are best described with atopic–commentstructure whose words are ordered by their importance in the sentence, rather than by their syntactic properties.Another hypothesis is that ASL exhibitsfree word order, in which syntax is not encoded in word order but can be encoded by other means such as head nods, eyebrow movement, and body position. Common misconceptions are that signs are iconically self-explanatory, that they are a transparent imitation of what they mean, or even that they arepantomime.In fact, many signs bear no resemblance to their referent because they were originally arbitrary symbols, or their iconicity has been obscured over time.Even so, in ASLiconicityplays a significant role; a high percentage of signs resemble their referents in some way.That may be because the medium of sign, three-dimensional space, naturally allows more iconicity than oral language. In the era of the influential linguistFerdinand de Saussure, it was assumed that the mapping between form and meaning in language must be completely arbitrary.Althoughonomatopoeiais a clear exception, since words like \"choo-choo\" bear clear resemblance to the sounds that they mimic, the Saussurean approach was to treat them as marginal exceptions.ASL, with its significant inventory of iconic signs, directly challenges that theory. Research on acquisition of pronouns in ASL has shown that children do not always take advantage of the iconic properties of signs when they interpret their meaning.It has been found that when children acquire the pronoun \"you\", the iconicity of the point (at the child) is often confused, being treated more like a name.That is a similar finding to research in oral languages on pronoun acquisition. It has also been found that iconicity of signs does not affect immediate memory and recall; less iconic signs are remembered just as well as highly-iconic signs. ^bDenotes the number (if known) of languages within the family. No further information is given on these languages.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/American_Sign_Language", "https://en.wikipedia.org/wiki/American_Sign_Language", "https://en.wikipedia.org/wiki/American_Sign_Language", "https://en.wikipedia.org/wiki/ASL_(disambiguation)", "https://en.wikipedia.org/wiki/Quebec_Sign_Language", "https://en.wikipedia.org/wiki/Maritime_Sign_Language", "https://en.wikipedia.org/wiki/Hand_Talk", "https://en.wikipedia.org/wiki/United_States"]},
{"id": "a05b70a3862a", "url": "https://en.wikipedia.org/wiki/Stop_motion", "title": "Stop motion", "headings": ["Contents", "Terminology", "History", "1849 to 1895: Before film", "1895–1928: The silent film era", "1930s and 1940s", "1950s", "1960s and 1970s", "1980s", "1990s", "21st century", "Variations of stop motion", "Stereoscopic stop-", "Go motion", "Comparison to computer-generated imagery", "Stop motion in other media", "See also", "References", "Further reading", "External links"], "content": "Stop motion(also known asstop frame animation) is ananimatedfilmmakingandspecial effectstechnique in which objects are physically manipulated in small increments between individually photographed frames so that they will appear to exhibit independent motion or change when the series of frames is played back. Any kind of object can thus be animated, butpuppetswith movable joints (puppet animation) or clay figures (claymation) are most commonly used. Puppets, models or clay figures built around anarmatureare used inmodel animation. Stop motion with live actors is often referred to aspixilation. Stop motion of flat materials such as paper, fabrics or photographs is usually calledcutout animation. The term \"stop motion\", relating to the animation technique, is often spelled with ahyphenas \"stop-motion\"—either standalone or as acompound modifier. Both orthographic variants, with and without the hyphen, are correct, but the hyphenated one has a second meaning that is unrelated to animation or cinema: \"a device for automatically stopping a machine or engine when something has gone wrong\". Before the advent ofchronophotographyin 1878, a small number of picture sequences were photographed with subjects in separate poses. These can now be regarded as a form of stop motion or pixilation, but very few results were meant to be animated. Until celluloidfilm basewas established in 1888 and set the standard for the moving image, animation could only be presented via mechanisms such as thezoetrope. In 1849,Joseph Plateaupublished a note about improvements for his Fantascope (a.k.a.phénakisticope). A new translucent variation had improved picture quality and could be viewed with both eyes, by several people at the same time. Plateau stated that the illusion could be advanced even further with an idea communicated to him byCharles Wheatstone: a combination of the fantascope and Wheatstone'sstereoscope. Plateau thought the construction of a sequential set of stereoscopic image pairs would be the more difficult part of the plan than adapting two copies of his improved fantascope to be fitted with a stereoscope. Wheatstone had suggested using photographs on paper of a solid object, for instance a statuette. Plateau concluded that for this purpose 16 plaster models could be made with 16 regular modifications. He believed such a project would take much time and careful effort, but would be quite worth it because of the expected marvelous results.The plan was never executed, possibly because Plateau was almost completely blind by this time. In 1852,Jules Duboscqpatented a \"Stéréoscope-fantascope ou Bïoscope\" (or abbreviated as stéréofantascope)stroboscopic disc. The only known extant disc contains stereoscopic photograph pairs of different phases of the motion of a machine. Due to the long exposure times necessary to capture an image with the photographic emulsions of the period, the sequence could not be recorded live and must have been assembled from separate photographs of the various positions of the machinery. In 1855,Johann Nepomuk Czermakpublished an article about his Stereophoroskop and other experiments aimed at stereoscopic moving images. He mentioned a method of sticking needles in astroboscopic discso that it looked like one needle was being pushed in and out of the cardboard when animated. He realized that this method provided basically endless possibilities to make different 3D animations. He then introduced two methods to animate stereoscopic pairs of images, one was basically a stereo viewer using two stroboscopic discs and the other was more or less similar to the laterzoetrope. Czermak explained how suitable stereoscopic photographs could be made by recording a series of models, for instance to animate a growing pyramid. On 27 February 1860,Peter Hubert Desvignesreceived British patent no. 537 for 28 monocular and stereoscopic variations of cylindrical stroboscopic devices (much like the later zoetrope).Desvignes'Mimoscope, received an Honourable Mention \"for ingenuity of construction\" at the1862 International Exhibitionin London.Desvignes \"employed models, insects and other objects, instead of pictures, with perfect success\". In 1874,Jules Janssenmade several practice discs for the recording of the passage of Venus with his seriesPassage de Vénuswith hisphotographic revolver. He used a model of the planet and a light source standing in for the sun.While actual recordings of the passage of Venus have not been located, some practice discs survived and the images of one were turned into a short animated film decades after the development ofcinematography. In 1887,Étienne-Jules Mareycreated a large zoetrope with a series of plaster models based on hischronophotographsof birds in flight. It is estimated that 80 to 90 percent of allsilent filmsare lost.Extant contemporary movie catalogs, reviews and other documentation can provide some details on lost films, but this kind of written documentation is also incomplete and often insufficient to properly date all extant films or even identify them if original titles are missing. Possible stop motion in lost films is even harder to trace. The principles of animation and other special effects were mostly kept a secret, not only to prevent use of such techniques by competitors, but also to keep audiences interested in the mystery of the magic tricks. Stop motion is closely related to thestop trick, in which the camera is temporarily stopped during the recording of a scene to create a change before filming is continued (or for which the cause of the change is edited out of the film). In the resulting film, the change will be sudden and a logical cause of the change will be mysteriously absent or replaced with a fake cause that is suggested in the scene. The oldest known example is used for the beheading inEdison Manufacturing Company's 1895 filmThe Execution of Mary Stuart. The technique of stop motion can be interpreted as repeatedly applying the stop trick. In 1917, clay animation pioneerHelena Smith-Daytonreferred to the principle behind her work as \"stop action\",a synonym of \"stop motion\". Frenchtrick filmpioneerGeorges Mélièsclaimed to have invented the stop-trick and popularized it by using it in many of his short films. He reportedly used stop-motion animation in 1899 to produce moving letterforms. Spanish filmmakerSegundo de Chomón(1871–1929) made many trick films in France forPathé. He has often been compared to Georges Méliès as he also made many fantasy films with stop tricks and other illusions (helped by his wife,Julienne Mathieu). Le théâtre de Bob(April 1906)features stop motion with dolls and objects to represent a fictional automated theatre owned by Bob, played by a live-action child actor. The film used to be credited to Chomón, but he didn't come to Paris (to work forPathé) until later. Direction and special effects have been attributed to Gaston Velle. De Chomón'sLa maison ensorcelée(December 1907,or 1906) features stop-motion-animated cutlery and food, among other special effects that depict paranormal activity. De Chomón'sSculpteur modernewas released on 31 January 1908and features heaps of clay molding itself into detailed sculptures that are capable of minor movements. The final sculpture depicts an old woman and walks around before it's picked up, squashed and molded back into a sitting old lady. American film pioneerEdwin S. Porterfilmed a single-shot \"lightning sculpting\" film with a baker molding faces from a patch of dough inFun in a Bakery Shop(1902), considered as foreshadowing of clay animation. In 1905, Porter showed animated letters and very simple cutout animation of two hands in theintertitlesinHow Jones Lost His Roll. Porter experimented with a small bit of crude stop-motion animation in his trick filmDream of a Rarebit Fiend(1906). The \"Teddy\" Bears(2 March 1907), made in collaboration withWallace McCutcheon Sr.,mainly shows people in bear costumes, but the short film also features a short stop motion segment with small teddy bears. On 15 February 1908, Porter released the trick filmA Sculptor's Welsh Rabbit Dreamthat featured clay molding itself into three complete busts.No copy of the film has yet been located. It was soon followed by the similar extant filmThe Sculptor's Nightmare(6 May 1908) by Wallace McCutcheon Sr. J. Stuart Blackton'sThe Haunted Hotel(23 February 1907)featured a combination of live-action with practicalspecial effectsand stop-motion animation of several objects, a puppet and a model of the haunted hotel. It was the first stop-motion film to receive wide scale appreciation. Especially a large close-up view of a table being set by itself baffled viewers; there were no visible wires or other noticeable well-known tricks.This inspired other filmmakers, including French animatorÉmile Cohland Segundo de Chomón. De Chomón would release the similarThe House of Ghosts(La maison ensorcelée) andHôtel électriquein 1908, with the latter also containing some very early pixilation. The Humpty Dumpty Circus(1908, considered lost) by Blackton and his British-American Vitagraph partnerAlbert E. Smithshowed an animated performance of figures from a popular wooden toy set.Smith would later claim that this was \"the first stop motion picture in America\". The inspiration would have come from seeing how puffs of smoke behaved in the interrupted recordings for a stop trick film they were making. Smith would have suggested to get a patent for the technique, but Blackton thought it wasn't that important.Smith's recollections are not considered to be very reliable. Blackton'sThe Haunted Hotelmade a big impression in Paris, where it was released asL'hôtel hanté: fantasmagorie épouvantable. WhenGaumontbought a copy to further distribute the film, it was carefully studied by some of their filmmakers to find out how it was made. Reportedly it was newcomerÉmile Cohlwho unraveled the mystery.Not long after, Cohl released his first film,Japon de fantaisie(June 1907),featuring his own imaginative use of the stop motion technique.\nIt was followed by the revolutionary hand-drawnFantasmagorie(17 August 1908) and many more animated films by Cohl. Other notable stop-motion films by Cohl includeLes allumettes animées (Animated Matches)(1908),andMobilier fidèle(1910, in collaboration withRomeo Bosetti).Mobilier fidèleis often confused with Bosetti's object animation tour de forceLe garde-meubles automatique (The Automatic Moving Company)(1912).Both films feature furniture moving by itself. Of the more than 300 short films produced between 1896 and 1915 by British film pioneerArthur Melbourne-Cooper, an estimated 36 contained forms of animation. Based on later reports by Melbourne-Cooper and by his daughter Audrey Wadowska, some believe that Cooper'sMatches: an Appealwas produced in 1899 and therefore the first stop-motion animation. The extant black-and-white film shows amatchstickfigure writing an appeal to donate aGuineafor whichBryant & Maywould supply soldiers with sufficient matches. No archival records are known that could prove that the film was indeed created in 1899 during the beginning of theSecond Boer War. Others place it at 1914, during the beginning ofWorld War I.Cooper created moreAnimated Matchesscenes in the same setting. These are believed to also have been produced in 1899,while a release date of 1908 has also been given.The 1908Animated Matchesfilm by Émile Cohl may have caused more confusion about the release dates of Cooper's matchstick animations. It also raises the question whether Cohl may have been inspired by Melbourne-Cooper or vice versa. Melbourne-Cooper's lost filmsDolly’s Toys(1901) andThe Enchanted Toymaker(1904) may have included stop-motion animation.Dreams of Toyland(1908) features a scene with many animated toys that lasts approximately three and a half minutes. As a means to plan his performances, ballet dancer and choreographerAlexander Shiryaevstarted making approximately 20- to 25-centimeter-tall puppets out ofpapier-mâchéon poseable wire frames. He then sketched all the sequential movements on paper. When he arranged these vertically on a long strip, it was possible to give a presentation of the complete dance with a home cinema projector. Later on, he bought a movie camera and between 1906 and 1909 he made many short films, including puppet animations. As a dancer and choreographer, Shiryaev had a special talent to create motion in his animated films. According to animatorPeter Lordhis work was decades ahead of its time. Part of Shiryaev's animation work is featured in Viktor Bocharov's documentaryAlexander Shiryaev: A Belated Premiere(2003). Polish-RussianLadislas Starevich(1882–1965), started his film career around 1909 inKaunasfilming live insects. He wanted to documentruttingstag beetles, but the creatures wouldn't cooperate or would even die under the bright lamps needed for filming. He solved the problem by using wire for the limbs of dried beetles and then animating them in stop-motion. The resulting short film, presumably 1 minute long,was probably titled by the Latin name for the species:Lucanus Cervus(Жук-олень, 1910, considered lost). After moving to Moscow, Starevich continued animating dead insects, but now as characters in imaginative stories with much dramatic complexity. He garnered much attention and international acclaim with these short films, including the 10-minuteThe Beautiful Leukanida(Прекрасная Люканида, или Война усачей с рогачами) (March 1912), the two-minuteHappy Scenes from Animal Life(Веселые сценки из жизни животных), the 12-minuteThe Cameraman's Revenge(Прекрасная Люканида, или Война усачей с рогачами, October 1912) and the 5-minuteThe Grasshopper and the Ant(Стрекоза и муравей, 1913). Reportedly many viewers were impressed with how much could be achieved with trained insects, or at least wondered what tricks could have been used, since few people were familiar with the secrets of stop-motion animation.The Insects' Christmas(Рождество обитателей леса, 1913) featured other animated puppets, including Father Christmas and a frog. Starevich made several other stop-motion films in the next two years, but mainly went on to direct live-action short and feature films before he fled from Russia in 1918. Willis O' Brien's first stop-motion film wasThe Dinosaur and the Missing Link: A Prehistoric Tragedy(1915). Apart from the titular dinosaur and \"missing link\" ape, it featured several cavemen and an ostrich-like \"desert quail\", all relatively lifelike models made with clay.This led to a series of short animated comedies with a prehistoric theme for Edison Company, includingPrehistoric Poultry(1916),R.F.D. 10,000 B.C.(1917),The Birth of a Flivver(1917) andCurious Pets of Our Ancestors(1917). O'Brien was then hired by producer Herbert M. Dawley to direct, create effects, co-write and co-star with him forThe Ghost of Slumber Mountain(1918). The collaborative film combined live-action with animated dinosaur models in a 45-minute film, but after the premiere it was cut down to approximately 12 minutes. Dawley did not give O'Brien credits for the visual effects, and instead claimed the animation process as his own invention and even applied for patents.O'Brien's stop motion work was recognized as a technique to create lifelike creatures for adventure films. O' Brien further pioneered the technique with animated dinosaur sequences for the live-action featureThe Lost World(1925). New York artistHelena Smith Dayton, possibly the first female animator, had much success with her \"Caricatypes\" clay statuettes before she began experimenting with clay animation. Some of her first resulting short films were screened on 25 March 1917. She released an adaptation ofWilliam Shakespeare'sRomeo and Julietapproximately half a year later. Although the films and her technique received much attention of the press, it seems she did not continue making films after she returned to New York from managing a YMCA in Paris around 1918. None of her films have yet surfaced, but the extant magazine articles have provided several stills and approximately 20 poorly printed frames from two film strips. By 1920 Starewicz had settled in Paris, and started making new stop-motion films.Dans les Griffes de L'araignée(finished 1920, released 1924) featured detailed hand-made insect puppets that could convey facial expressions with moving lips and eyelids. One of the earliest clay animation films wasModelling Extraordinary, which impressed audiences in 1912. The early Italian feature filmCabiria(1914) featured some stop motion techniques. Starewicz finished the first feature stop-motion filmLe Roman de Renard (The Tale of the Fox)in 1930, but problems with its soundtrack delayed its release. In 1937 it was released with a German soundtrack and in 1941 with its French soundtrack. Hungarian-American filmmakerGeorge Paldeveloped his own stop motion technique of replacing wooden dolls (or parts of them) with similar figures displaying changed poses and/or expressions. He called it Pal-Doll and used it for hisPuppetoonsfilms since 1932. The particular replacement animation method itself also became better known aspuppetoon. In Europe he mainly worked on promotional films for companies such asPhilips. Later Pal gained much success in Hollywood with a string ofAcademy Award for Best Animated Short Films, includingRhythm in the Ranks(1941),Tulips Shall Grow(1942),Jasper and the Haunted House(1942), theDr. SeusspennedThe 500 Hats of Bartholomew Cubbins(1943) andAnd to Think That I Saw It on Mulberry Street(1944),Jasper and the Beanstalk(1945),John Henry and the Inky-Poo(1946),Jasper in a Jam(1946), andTubby the Tuba(1947). Many of his puppetoon films were selected for preservation in the United StatesNational Film Registry. Willis O' Brien's expressive and emotionally convincing animation of the big ape inKing Kong(1933) is widely regarded as a milestone in stop-motion animation and a highlight of Hollywood cinema in general. In 1935,The New Gulliver, aSovietstop motion-animated cartoon, made an extensive use of puppet animation, running almost all the way through the film (it begins and ends with short live-action sequences). The film was released to widespread acclaim and earned directorAleksandr Ptushkoa special prize at the International Cinema Festival in Milan. A 1940 promotional film forAutolite, an automotive parts supplier, featured stop-motion animation of its products marching past Autolite factories to the tune ofFranz Schubert'sMilitary March. An abbreviated version of this sequence was later used in television ads for Autolite, especially those on the 1950s CBS programSuspense, which Autolite sponsored. The first British animated feature was the stop motion instruction filmHandling Ships(1945) byHalas and Batchelorfor theBritish Admiralty. It was not meant for general cinemas, but did become part of the official selection of the 1946Cannes Film Festival. The first Belgian animated feature was anadaptation of the Tintin comicThe Crab with the Golden Claws(1947) with animated puppets. The first Czech animated feature was the package filmThe Czech Year(1947) with animated puppets byJiří Trnka. The film won several awards at theVenice Film Festivaland other international festivals. Trnka would make several more award-winning stop motion features includingThe Emperor's Nightingale(1949),Prince Bayaya(1950),Old Czech Legends(1953), orA Midsummer Night's Dream(1959). He also directed many short films and experimented with other forms of animation. Ray Harryhausenlearned under O'Brien on the filmMighty Joe Young(1949). Harryhausen would go on to create many memorable stop motion effects for a string of successful fantasy films over the next three decades. These includedThe Beast from 20,000 Fathoms(1953),It Came from Beneath the Sea(1955),Jason and the Argonauts(1963),The Golden Voyage of Sinbad(1973), andClash of the Titans(1981). It wasn't until 1954 before a feature animated film with a technique other than cel animation was produced in the US. The first was the stop motion adaptation of 19th century composerEngelbert Humperdinck's operaHänsel und GretelasHansel and Gretel: An Opera Fantasy. In 1955,Karel Zemanmade his first feature filmJourney to the Beginning of Timeinspired byJules Verne, featuring stop-motion animation of dinosaurs and other prehistoric creatures. Art Clokeystarted his adventures in clay with a freeform clay short film calledGumbasia(1955), which shortly thereafter propelled him into the production of his more structured TV seriesGumby(1955–1989), with the iconic titular character. In partnership with theUnited Lutheran Church in America, he also producedDavey and Goliath(1960–2004). The theatrical featureGumby: The Movie(1992, released in 1995) was abox-office bomb. In Hungary, Hungarian–French puppet designer and animated film director,Éva Balla‑Falus, began her series of 6 animated films with various collaborators (with the sculptor Zoltán Olcsai-Kiss,Megy a juhász szamáronin 1948, andVitamin ABCin 1950,Kacsain 1951,Balkéz Tóbiásin 1953,Mese a mihaszna köcsögrőlin 1956, andA didergő királyin 1957. On 22 November 1959, the first episode ofUnser Sandmänchen (Our Little Sandman)was broadcast onDFF (East German television). The 10-minute daily bedtime show for young children features the title character as an animated puppet, and other puppets in different segments. A very similarSandmänchenseries, possibly conceived earlier, ran on West German television from 1 December 1959 until theGerman reunificationin 1989. The East German show was continued on other German networks when DFF ended in 1991, and is one of the longest running animated series in the world.The theatrical featureDas Sandmännchen – Abenteuer im Traumland(2010) was fully animated with stop-motion puppets. Japanese puppet animatorTadahito Mochinagastarted out as assistant animator in short anime (propaganda) filmsArichan(1941) andMomotarō no Umiwashi(1943). He fled toManchukuoduring the war and stayed in China afterwards. Due to the scarcity of paint and film stock shortly after the war, Mochinaga decided to work with puppets and stop motion. His work helped popularize puppet animation in China, before he returned to Japan around 1953 where he continued working as animation director. In the 1960s, Mochinaga supervised the \"Animagic\" puppet animation for productions byArthur Rankin Jr.andJules Bass' Videocraft International, Ltd. (later calledRankin/Bass Productions, Inc.) andDentsu, starting with the syndicated television seriesThe New Adventures of Pinocchio(1960-1961). The Christmas TV specialRudolph the Red-Nosed Reindeerhas been telecasted annually since 1964 and has become one of the most beloved holiday specials in the United States. They made three theatrical feature filmsWilly McBean and His Magic Machine(1965),The Daydreamer(1966, stop motion / live-action) andMad Monster Party?(1966, released in 1967), and the television specialBallad of Smokey the Bear(1966) before the collaboration ended. Rankin/Bass worked with other animators for more TV specials, with titles such asThe Little Drummer Boy(1968),Santa Claus is Comin' to Town(1970) andHere Comes Peter Cottontail(1971). British television has shown many stop motion series for young children since the 1960s. An early example isSnip and Snap(1960-1961) byJohn Halasin collaboration with Danish paper sculptor Thok Søndergaard (Thoki Yenn), featuring dog Snap, cut from a sheet of paper by pair of scissors Snip. Apart from their cutout animation series, British studioSmallfilms(Peter FirminandOliver Postgate) produced several stop motion series with puppets, beginning withPingwings(1961-1965) featuring penguin-like birds knitted by Peter's wife Joan and filmed on their farm (where most of their productions were filmed in an unused barn). It was followed byPogles' Wood(1965-1967),Clangers(1969-1972, 1974, revived in 2015),Bagpuss(1974) andTottie: The Story of a Doll's House(1984). Czech surrealist filmmakerJan Švankmajer's released his short artistic films since 1964, which usually contain much experimental stop motion. He started to gain much international recognition in the 1980s. Since 1988 he has mostly been directing feature films which feature much more live action than stop motion. These includeAlice, an adaptation ofLewis Carroll'sAlice's Adventures in Wonderland, andFaust, a rendition ofthe legend of the German scholar. Švankmajer's work has been highly influential on other artists, such asTerry Gilliamand the Quay brothers (although the latter claim to have only discovered Švankmajer's films after having developed their own similar style). French animatorSerge DanotcreatedThe Magic Roundabout(1965) which played for many years on theBBC. Polish studioSe-ma-forproduced popular TV series with animated puppets in adaptations ofColargol(Barnaby the Bearin the UK,Jeremyin Canada) (1967-1974) andThe Moomins(1977-1982). In the 1960s and 1970s, independent clay animatorEliot Noyes Jr.refined the technique of \"free-form\" clay animation with his Oscar-nominated 1965 filmClay (or the Origin of Species). Noyes also used stop motion to animate sand lying on glass for his musical animated filmSandman(1975). Italian director Francesco Misseri created the clay animation TV seriesMio Mao(1970-1976, 2002–2007),The Red and the Blue(Il Rosso e il Blu, 1976), and a TV series with an animatedorigamiduckQuaq Quao(1978-1979). The British artists Brian Cosgrove and Mark Hall (Cosgrove Hall Films) produced two stop-motion animated adaptions ofEnid Blyton'sNoddybook series, including the original series of the same name (1975–1982) andNoddy's Toyland Adventures(1992–2001), a full-length filmThe Wind in the Willows(1983) and later amulti-season TV series, both based onKenneth Grahame'sclassic children's bookof the same title. They also produced a documentary of their production techniques,Making Frog and Toad. In 1975, filmmaker and clay animation experimenterWill Vintonjoined with sculptorBob Gardinerto create an experimental film calledClosed Mondayswhich became the first stop-motion film to win an Oscar. Will Vinton followed with several other successful short film experiments includingThe Great Cognito,The Creation, andRip Van Winklewhich were each nominated for Academy Awards. In 1977, Vinton made a documentary about this process and his style of animation which he dubbed \"claymation\"; he titled the documentaryClaymation. Soon after this documentary, the term was trademarked by Vinton to differentiate his team's work from others who had been, or were beginning to do, \"clay animation\". While the word has stuck and is often used to describe clay animation and stop motion, it remains a trademark owned currently by Laika Entertainment, Inc. Twenty clay-animation episodes featuring the clownMr. Billwere a feature ofSaturday Night Live, starting from a first appearance in February 1976. At very much the same time in the UK,Peter LordandDavid SproxtonformedAardman Animationsthat would produce many commercials, TV series, short films and eventually also feature films. In 1976 they created the characterMorphwho appeared as an animated side-kick to the TV presenterTony Harton hisBBC TVprogrammeTake Hart. The five-inch-high presenter was made from a traditional British modelling clay calledPlasticine. In 1977 they started on a series of animated films, again using modelling clay, but this time made for a more adult audience. The soundtrack forDown and Outwas recorded in a Salvation Army Hostel and Plasticine puppets were animated to dramatise the dialogue. A second film, also for the BBC followed in 1978. A TV seriesThe Amazing Adventures of Morphwas aired in 1980. Sand-coated puppet animation was used in the Oscar-winning 1977 filmThe Sand Castle, produced by Dutch-Canadian animatorCo Hoedeman. Hoedeman was one of dozens of animators sheltered by theNational Film Board of Canada, a Canadian government film arts agency that had supported animators for decades. A pioneer of refined multiple stop-motion films under the NFB banner wasNorman McLaren, who brought in many other animators to create their own creatively controlled films. Notable among these are thepinscreen animationfilms of Jacques Drouin, made with the original pinscreen donated byAlexandre Alexeieff and Claire Parker. Czech filmmakersLubomír BenešandVladimír Jiránekdebuted their animated puppet charactersPat & Mat, two inventive but clumsy neighbors, in the 7-minute shortKuťáciin 1976. Since 1979, over 100 episodes have been broadcast irregularly.Since 2014, new episodes were presented in theatrically released package films. The series became very popular in several countries, especially in The Netherlands, the only country where the characters are voiced. One of the main British animation teams,John Hardwick and Bob Bura, were the main animators in many early British TV shows, and are famous for their work on theTrumptonshiretrilogy (Camberwick Green,TrumptonandChigley). Their company was named Stop Motion Limited,the term having been their trademark until it becamegeneric. Disney experimented with several stop-motion techniques by hiring independent animator-directorMike Jittlovto make the first stop-motion animation ofMickey Mousetoys ever produced, in a short sequence calledMouse Mania, part of a TV special,Mickey's 50, which commemorated Mickey's 50th anniversary in 1978. Jittlov again produced some impressive multi-technique stop-motion animation a year later for a 1979 Disney special promoting their release of the feature filmThe Black Hole. TitledMajor Effects, Jittlov's work stood out as the best part of the special. Jittlov released his footage the following year to 16mm film collectors as a short film titledThe Wizard of Speed and Time, along with four of his other short multi-technique animated films, most of which eventually evolved into his own feature-length film of the same title. Effectively demonstrating almost all animation techniques, as well as how he produced them, the film was released to theaters in 1987 and to video in 1989. In the 1970s and 1980s,Industrial Light & Magicoften used stop-motion model animation in such films as theoriginalStar Warstrilogy: the holochess sequence inStar Wars, the Tauntauns and AT-AT walkers inThe Empire Strikes Back, and the AT-ST walkers inReturn of the Jediwere all filmed using stop-motion animation, with the latter two films utilisinggo motion: an invention from renowned visual effects veteranPhil Tippett. The many shots including the ghosts inRaiders of the Lost Ark, the Dragon inDragonslayer, and the first two feature films in theRoboCopseries use Tippett's go motion. In the UK, Aardman Animations continued to grow.Channel 4funded a new series of clay animated films,Conversation Pieces, using recorded soundtracks of real people talking. A further series in 1986, calledLip Sync, premiered the work ofRichard Goleszowski(Ident),Barry Purves(Next), andNick Park(Creature Comforts), as well as further films by Sproxton and Lord.Creature Comfortswon the Oscar for Best Animated Short in 1990. In 1986, they also produced a notablemusic video for \"Sledgehammer\", a song byPeter Gabriel. In 1980, Marc Paul Chinoy directed the 1st feature-length clay animated film, based on the famousPogocomic strip. TitledI go Pogo. It was aired a few times on American cable channels but has yet to be commercially released. Primarily clay, some characters required armatures, and walk cycles used pre-sculpted hard bases legs. Stop motion was also used for some shots of the final sequence of the firstTerminatormovie, also for the scenes of the small alien ships inSpielberg'sBatteries Not Includedin 1987, animated byDavid W. Allen. Allen's stop motion work can also be seen in such feature films asThe Crater Lake Monster(1977),Q - The Winged Serpent(1982),The Gate(1987) andFreaked(1993). Allen's King KongVolkswagencommercial from the 1970s is now legendary among model animation enthusiasts. In 1985,Will Vintonand his team released an ambitious feature film in stop motion called \"The Adventures Of Mark Twain\" based on the life and works of the famous American author. While the film may have been a little sophisticated for young audiences at the time, it got rave reviews from critics and adults in general.Vinton's team also created the Nomes and the Nome King for Disney's \"Return to Oz\" feature, for which they received an Academy Award Nomination forSpecial Visual Effects. In the late 1980s and early 1990s, Will Vinton became very well known for his commercial work as well with stop motion campaigns includingThe California RaisinsandThe Noid. Jiří Bartareleased his award-winning fantasy filmThe Pied Piper(1986). From 1986 to 1991,Churchill FilmsproducedThe Mouse and the Motorcycle,Runaway Ralph, andRalph S. Mousefor ABC television. The shows featured stop-motion characters combined with live action, based on the books of Beverly Cleary. John Clark Matthews was the animation director, with Justin Kohn, Joel Fletcher, and Gail Van Der Merwe providing character animation.The company also produced other films based on children's books. From 1986 to 2000,over 150 five-minute episodesofPingu, a Swisschildren'scomedy, were produced by Trickfilmstudio. Aardman Animations'Nick Parkbecame very successful with his short claymationCreature Comfortsin 1989, which hadtalking animalsvoicingvox popinterviews. Park then used the same format to produce a series of commercials between 1990 and 1992. The commercials have been credited as having introduced a more \"caring\" way of advertising in the UK.Richard Goleszowskilater directed two 13-episodeCreature ComfortsTV series (2003, 2005–2006) and a Christmas special (2005). \nAlso in 1989, Park introduced his very popular clay charactersWallace and GromitinA Grand Day Out. Three more short films and one feature film and many TV adaptions and spin-offs would follow. Among many other awards, Park won theAcademy Award for Best Animated Featurefor the feature-length outingWallace & Gromit: The Curse of the Were-Rabbit. Park also worked on theChicken Runmovie, which was another film from Aardman Animations. In 1992,Trey ParkerandMatt StonemadeThe Spirit of Christmas, a short cutout animated student film made withconstruction paper. In 1995 they made a second short with the same titled, commissioned as a Christmas greeting byFox Broadcasting CompanyexecutiveBrian Graden. The concepts and characters were further developed into the TV hit seriesSouth Park(since 1997). Except for the pilot, all animation has been created on computers in the same style. The Nightmare Before Christmas(1993), directed byHenry Selickand produced byTim Burton, was one of the more widely released stop-motion features and became the highest grossing stop-motion animated movie of its time, grossing over $50 million domestic. Henry Selick also went on to directJames and the Giant PeachandCoraline, and Tim Burton went on to directCorpse BrideandFrankenweenie. The stop-motion featureThe Secret Adventures of Tom Thumbwas released in 1993. In November 1998, the first episode ofBob the Builderreleased on BBC. Bob the Builder was a popular British stop-motion television series created by Keith Chapman & produced and owned byHIT Entertainment. In 1999, Will Vinton launched the first US prime-time stop-motion television series calledThe PJs, co-created by actor-comedianEddie Murphy. The Emmy-winning sitcom aired on Fox for two seasons, then moved to the WB for an additional season. Vinton launched another series,Gary & Mike, for UPN in 2001. In 1999,Tsuneo Gōdadirected 30-second sketches of the characterDomo. The shorts, animated by stop-motion studio Dwarf, are currently still produced inJapanand have received universal critical acclaim from fans and critics. Gōda also directed the stop-motion movie seriesKomanekoin 2004. The BBC commissioned thirteen episodes of stop frame animatedSummerton Millin 2004 as inserts into their flagship pre-school program,Tikkabilla. Created and produced by Pete Bryden and Ed Cookson, the series was then given its own slot on BBC1 and BBC2 and has been broadcast extensively around the world. Other notable stop-motion feature films released since 2000 includeFantastic Mr. Fox(2009),$9.99(2009),Anomalisa(2015),Henry Selick'sWendell and Wild(2022) andGuillermo del Toro's Pinocchio(2022). In 2003, the pilot film for the seriesCurucuru and Friends, produced by Korean studio Ffango Entertoyment is greenlighted into achildren'sanimated series in 2004 after an approval with the Gyeonggi Digital Contents Agency. It was aired inKBS1on November 24, 2006, and won the 13th Korean Animation Awards in 2007 for Best Animation. Ffango Entertoyment also worked withFrontier WorksinJapanto produce the 2010 film remake ofCheburashka. Since 2005,Robot Chickenhas mostly utilized stop-motion animation, using custom madeaction figuresand other toys as principal characters. Since 2009,Laika, the stop motion successor toWill Vinton Studios, has released fivefeature films, which have collectively grossed over $400 million:Coraline(2009),ParaNorman(2012),The Boxtrolls(2014),Kubo and the Two Strings(2016) andMissing Link(2019). Directors likeTim BurtonandWes Andersonare still using stop-motion animation in some of their live action films. In 2019 and 2020, cinematographerJeffrey Gardnerwon back-to-back Daytime Creative Arts Emmy Awards for Outstanding Cinematography on the stop-motion seriesTumble Leaf(Amazon Studios), marking one of the rare instances where a director of photography has been recognized for work in stop-motion television.While stop-motion histories often highlight animators and directors, Gardner’s awards underscore the vital role of cinematography in the medium, where lighting, lenses, and miniature set design create the show’s distinctive visual storytelling. In November 2024,DisneyreleasedMickey & Minnie's Christmas Carols, a series of five stop motion shorts featuring Mickey, Minnie, Donald, Daisy, Goofy and Pluto. Stop motion has very rarely been shot instereoscopic3Dthroughout film history. The first 3D stop motion short wasIn Tune With Tomorrow(also known asMotor Rhythm), made in 1939 by John Norling. The second stereoscopic stop motion release wasThe Adventures of Sam Spacein 1955 by Paul Sprunck. The third and latest stop motion short in stereo 3D wasThe Incredible Invasion of the 20,000 Giant Robots from Outer Spacein 2000 by Elmer Kaanand Alexander Lentjes.This is also the first ever 3D stereoscopic stop motion and CGI short in the history of film. The first all stop-motion 3D feature isCoraline(2009), based onNeil Gaiman'sbest-selling noveland directed by Henry Selick.Another recent example is theNintendo 3DSvideo software which comes with the option for Stop-Motion videos. This has been released December 8, 2011 as a 3DS system update. Also, the filmParaNormanis in 3D stop motion. Another more complicated variation on stop motion isgo motion, co-developed byPhil Tippettand first used on the filmsThe Empire Strikes Back(1980),Dragonslayer(1981), and theRoboCopfilms. Go motion involved programming a computer to move parts of a model slightly during each exposure of each frame of film, combined with traditional hand manipulation of the model in between frames, to produce a more realisticmotion blurringeffect. Tippett also used the process extensively in his 1984 short filmPrehistoric Beast, a 10 minutes long sequence depicting a herbivorous dinosaur (Monoclonius), being chased by a carnivorous one (Tyrannosaurus). With new footagePrehistoric BeastbecameDinosaur!in 1985, a full-length dinosaurs documentary hosted byChristopher Reeve. Those Phil Tippett's go motion tests acted as motion models for his first photo-realistic use of computers to depict dinosaurs inJurassic Parkin 1993. A low-tech, manual version of this blurring technique was originally pioneered byWładysław Starewiczin the silent era, and was used in his feature filmThe Tale of the Fox(1931). The reasons for using stop motion instead of the more advancedcomputer-generated imagery(CGI) include the appeal of its distinct look and the notion that it accurately displays real-life textures, while CGI texturing can look more artificial and isn't always quite as close to realism.This is appreciated by a number of animation directors, such asGuillermo del Toro,Henry Selick,Tim BurtonandTravis Knight. Guillermo del Toro aimed to praise the benefits of stop motion in his moviePinocchio, saying that he wanted \"the expressiveness and the material nature of a handmade piece of animation — an artisanal, beautiful exercise in carving, painting, sculpting\". Many young people begin their experiments in movie making with stop- , thanks to the ease of modern stop-motion software and online video publishing.Many new stop-motion shorts use clay animation into a new form. Singer-songwriterOren Lavie's music video for the songHer Morning Elegancewas posted on YouTube on January 19, 2009. The video, directed by Lavie and Yuval and Merav Nathan, uses stop motion and has achieved great success with over 25.4 million views, also earning a 2010 Grammy Award nomination for \"Best Short Form Music Video\". Stop motion has occasionally been used to create the characters forcomputer games, as an alternative to CGI. TheVirgin Interactive EntertainmentMythosgameMagic and Mayhem(1998) featured creatures built by stop-motion specialist Alan Friswell, who made the miniature figures from modelling clay and latex rubber, over armatures of wire and ball-and-socket joints. The models were then animated one frame at a time, and incorporated into the CGI elements of the game through digital photography. \"ClayFighter\" for theSuper NESandThe NeverhoodandHylics 2for thePCare other examples. Scientists at IBM used ascanning tunneling microscopeto single out and move individual atoms which were used to make characters inA Boy and His Atom. This was the tiniest scale stop-motion video made at that time. Replicating the distinct tactile look of traditional stop motion has gained popularity in contemporary media through the use of CGI. This approach can often provide a more cost-effective and accessible means of achieving the stop motion aesthetic. Noteworthy among such endeavors is the work ofBlenderanimator Ian Worthington, exemplified by his 2021 short film \"Captain Yajima\".Another prominent example of this trend includesThe LEGO Movie, which uses CGI to replicate the visual style and imperfections of stop motion.", "combined_text": "Stop motion Contents Terminology History 1849 to 1895: Before film 1895–1928: The silent film era 1930s and 1940s 1950s 1960s and 1970s 1980s 1990s 21st century Variations of stop motion Stereoscopic stop- Go motion Comparison to computer-generated imagery Stop motion in other media See also References Further reading External links Stop motion(also known asstop frame animation) is ananimatedfilmmakingandspecial effectstechnique in which objects are physically manipulated in small increments between individually photographed frames so that they will appear to exhibit independent motion or change when the series of frames is played back. Any kind of object can thus be animated, butpuppetswith movable joints (puppet animation) or clay figures (claymation) are most commonly used. Puppets, models or clay figures built around anarmatureare used inmodel animation. Stop motion with live actors is often referred to aspixilation. Stop motion of flat materials such as paper, fabrics or photographs is usually calledcutout animation. The term \"stop motion\", relating to the animation technique, is often spelled with ahyphenas \"stop-motion\"—either standalone or as acompound modifier. Both orthographic variants, with and without the hyphen, are correct, but the hyphenated one has a second meaning that is unrelated to animation or cinema: \"a device for automatically stopping a machine or engine when something has gone wrong\". Before the advent ofchronophotographyin 1878, a small number of picture sequences were photographed with subjects in separate poses. These can now be regarded as a form of stop motion or pixilation, but very few results were meant to be animated. Until celluloidfilm basewas established in 1888 and set the standard for the moving image, animation could only be presented via mechanisms such as thezoetrope. In 1849,Joseph Plateaupublished a note about improvements for his Fantascope (a.k.a.phénakisticope). A new translucent variation had improved picture quality and could be viewed with both eyes, by several people at the same time. Plateau stated that the illusion could be advanced even further with an idea communicated to him byCharles Wheatstone: a combination of the fantascope and Wheatstone'sstereoscope. Plateau thought the construction of a sequential set of stereoscopic image pairs would be the more difficult part of the plan than adapting two copies of his improved fantascope to be fitted with a stereoscope. Wheatstone had suggested using photographs on paper of a solid object, for instance a statuette. Plateau concluded that for this purpose 16 plaster models could be made with 16 regular modifications. He believed such a project would take much time and careful effort, but would be quite worth it because of the expected marvelous results.The plan was never executed, possibly because Plateau was almost completely blind by this time. In 1852,Jules Duboscqpatented a \"Stéréoscope-fantascope ou Bïoscope\" (or abbreviated as stéréofantascope)stroboscopic disc. The only known extant disc contains stereoscopic photograph pairs of different phases of the motion of a machine. Due to the long exposure times necessary to capture an image with the photographic emulsions of the period, the sequence could not be recorded live and must have been assembled from separate photographs of the various positions of the machinery. In 1855,Johann Nepomuk Czermakpublished an article about his Stereophoroskop and other experiments aimed at stereoscopic moving images. He mentioned a method of sticking needles in astroboscopic discso that it looked like one needle was being pushed in and out of the cardboard when animated. He realized that this method provided basically endless possibilities to make different 3D animations. He then introduced two methods to animate stereoscopic pairs of images, one was basically a stereo viewer using two stroboscopic discs and the other was more or less similar to the laterzoetrope. Czermak explained how suitable stereoscopic photographs could be made by recording a series of models, for instance to animate a growing pyramid. On 27 February 1860,Peter Hubert Desvignesreceived British patent no. 537 for 28 monocular and stereoscopic variations of cylindrical stroboscopic devices (much like the later zoetrope).Desvignes'Mimoscope, received an Honourable Mention \"for ingenuity of construction\" at the1862 International Exhibitionin London.Desvignes \"employed models, insects and other objects, instead of pictures, with perfect success\". In 1874,Jules Janssenmade several practice discs for the recording of the passage of Venus with his seriesPassage de Vénuswith hisphotographic revolver. He used a model of the planet and a light source standing in for the sun.While actual recordings of the passage of Venus have not been located, some practice discs survived and the images of one were turned into a short animated film decades after the development ofcinematography. In 1887,Étienne-Jules Mareycreated a large zoetrope with a series of plaster models based on hischronophotographsof birds in flight. It is estimated that 80 to 90 percent of allsilent filmsare lost.Extant contemporary movie catalogs, reviews and other documentation can provide some details on lost films, but this kind of written documentation is also incomplete and often insufficient to properly date all extant films or even identify them if original titles are missing. Possible stop motion in lost films is even harder to trace. The principles of animation and other special effects were mostly kept a secret, not only to prevent use of such techniques by competitors, but also to keep audiences interested in the mystery of the magic tricks. Stop motion is closely related to thestop trick, in which the camera is temporarily stopped during the recording of a scene to create a change before filming is continued (or for which the cause of the change is edited out of the film). In the resulting film, the change will be sudden and a logical cause of the change will be mysteriously absent or replaced with a fake cause that is suggested in the scene. The oldest known example is used for the beheading inEdison Manufacturing Company's 1895 filmThe Execution of Mary Stuart. The technique of stop motion can be interpreted as repeatedly applying the stop trick. In 1917, clay animation pioneerHelena Smith-Daytonreferred to the principle behind her work as \"stop action\",a synonym of \"stop motion\". Frenchtrick filmpioneerGeorges Mélièsclaimed to have invented the stop-trick and popularized it by using it in many of his short films. He reportedly used stop-motion animation in 1899 to produce moving letterforms. Spanish filmmakerSegundo de Chomón(1871–1929) made many trick films in France forPathé. He has often been compared to Georges Méliès as he also made many fantasy films with stop tricks and other illusions (helped by his wife,Julienne Mathieu). Le théâtre de Bob(April 1906)features stop motion with dolls and objects to represent a fictional automated theatre owned by Bob, played by a live-action child actor. The film used to be credited to Chomón, but he didn't come to Paris (to work forPathé) until later. Direction and special effects have been attributed to Gaston Velle. De Chomón'sLa maison ensorcelée(December 1907,or 1906) features stop-motion-animated cutlery and food, among other special effects that depict paranormal activity. De Chomón'sSculpteur modernewas released on 31 January 1908and features heaps of clay molding itself into detailed sculptures that are capable of minor movements. The final sculpture depicts an old woman and walks around before it's picked up, squashed and molded back into a sitting old lady. American film pioneerEdwin S. Porterfilmed a single-shot \"lightning sculpting\" film with a baker molding faces from a patch of dough inFun in a Bakery Shop(1902), considered as foreshadowing of clay animation. In 1905, Porter showed animated letters and very simple cutout animation of two hands in theintertitlesinHow Jones Lost His Roll. Porter experimented with a small bit of crude stop-motion animation in his trick filmDream of a Rarebit Fiend(1906). The \"Teddy\" Bears(2 March 1907), made in collaboration withWallace McCutcheon Sr.,mainly shows people in bear costumes, but the short film also features a short stop motion segment with small teddy bears. On 15 February 1908, Porter released the trick filmA Sculptor's Welsh Rabbit Dreamthat featured clay molding itself into three complete busts.No copy of the film has yet been located. It was soon followed by the similar extant filmThe Sculptor's Nightmare(6 May 1908) by Wallace McCutcheon Sr. J. Stuart Blackton'sThe Haunted Hotel(23 February 1907)featured a combination of live-action with practicalspecial effectsand stop-motion animation of several objects, a puppet and a model of the haunted hotel. It was the first stop-motion film to receive wide scale appreciation. Especially a large close-up view of a table being set by itself baffled viewers; there were no visible wires or other noticeable well-known tricks.This inspired other filmmakers, including French animatorÉmile Cohland Segundo de Chomón. De Chomón would release the similarThe House of Ghosts(La maison ensorcelée) andHôtel électriquein 1908, with the latter also containing some very early pixilation. The Humpty Dumpty Circus(1908, considered lost) by Blackton and his British-American Vitagraph partnerAlbert E. Smithshowed an animated performance of figures from a popular wooden toy set.Smith would later claim that this was \"the first stop motion picture in America\". The inspiration would have come from seeing how puffs of smoke behaved in the interrupted recordings for a stop trick film they were making. Smith would have suggested to get a patent for the technique, but Blackton thought it wasn't that important.Smith's recollections are not considered to be very reliable. Blackton'sThe Haunted Hotelmade a big impression in Paris, where it was released asL'hôtel hanté: fantasmagorie épouvantable. WhenGaumontbought a copy to further distribute the film, it was carefully studied by some of their filmmakers to find out how it was made. Reportedly it was newcomerÉmile Cohlwho unraveled the mystery.Not long after, Cohl released his first film,Japon de fantaisie(June 1907),featuring his own imaginative use of the stop motion technique.\nIt was followed by the revolutionary hand-drawnFantasmagorie(17 August 1908) and many more animated films by Cohl. Other notable stop-motion films by Cohl includeLes allumettes animées (Animated Matches)(1908),andMobilier fidèle(1910, in collaboration withRomeo Bosetti).Mobilier fidèleis often confused with Bosetti's object animation tour de forceLe garde-meubles automatique (The Automatic Moving Company)(1912).Both films feature furniture moving by itself. Of the more than 300 short films produced between 1896 and 1915 by British film pioneerArthur Melbourne-Cooper, an estimated 36 contained forms of animation. Based on later reports by Melbourne-Cooper and by his daughter Audrey Wadowska, some believe that Cooper'sMatches: an Appealwas produced in 1899 and therefore the first stop-motion animation. The extant black-and-white film shows amatchstickfigure writing an appeal to donate aGuineafor whichBryant & Maywould supply soldiers with sufficient matches. No archival records are known that could prove that the film was indeed created in 1899 during the beginning of theSecond Boer War. Others place it at 1914, during the beginning ofWorld War I.Cooper created moreAnimated Matchesscenes in the same setting. These are believed to also have been produced in 1899,while a release date of 1908 has also been given.The 1908Animated Matchesfilm by Émile Cohl may have caused more confusion about the release dates of Cooper's matchstick animations. It also raises the question whether Cohl may have been inspired by Melbourne-Cooper or vice versa. Melbourne-Cooper's lost filmsDolly’s Toys(1901) andThe Enchanted Toymaker(1904) may have included stop-motion animation.Dreams of Toyland(1908) features a scene with many animated toys that lasts approximately three and a half minutes. As a means to plan his performances, ballet dancer and choreographerAlexander Shiryaevstarted making approximately 20- to 25-centimeter-tall puppets out ofpapier-mâchéon poseable wire frames. He then sketched all the sequential movements on paper. When he arranged these vertically on a long strip, it was possible to give a presentation of the complete dance with a home cinema projector. Later on, he bought a movie camera and between 1906 and 1909 he made many short films, including puppet animations. As a dancer and choreographer, Shiryaev had a special talent to create motion in his animated films. According to animatorPeter Lordhis work was decades ahead of its time. Part of Shiryaev's animation work is featured in Viktor Bocharov's documentaryAlexander Shiryaev: A Belated Premiere(2003). Polish-RussianLadislas Starevich(1882–1965), started his film career around 1909 inKaunasfilming live insects. He wanted to documentruttingstag beetles, but the creatures wouldn't cooperate or would even die under the bright lamps needed for filming. He solved the problem by using wire for the limbs of dried beetles and then animating them in stop-motion. The resulting short film, presumably 1 minute long,was probably titled by the Latin name for the species:Lucanus Cervus(Жук-олень, 1910, considered lost). After moving to Moscow, Starevich continued animating dead insects, but now as characters in imaginative stories with much dramatic complexity. He garnered much attention and international acclaim with these short films, including the 10-minuteThe Beautiful Leukanida(Прекрасная Люканида, или Война усачей с рогачами) (March 1912), the two-minuteHappy Scenes from Animal Life(Веселые сценки из жизни животных), the 12-minuteThe Cameraman's Revenge(Прекрасная Люканида, или Война усачей с рогачами, October 1912) and the 5-minuteThe Grasshopper and the Ant(Стрекоза и муравей, 1913). Reportedly many viewers were impressed with how much could be achieved with trained insects, or at least wondered what tricks could have been used, since few people were familiar with the secrets of stop-motion animation.The Insects' Christmas(Рождество обитателей леса, 1913) featured other animated puppets, including Father Christmas and a frog. Starevich made several other stop-motion films in the next two years, but mainly went on to direct live-action short and feature films before he fled from Russia in 1918. Willis O' Brien's first stop-motion film wasThe Dinosaur and the Missing Link: A Prehistoric Tragedy(1915). Apart from the titular dinosaur and \"missing link\" ape, it featured several cavemen and an ostrich-like \"desert quail\", all relatively lifelike models made with clay.This led to a series of short animated comedies with a prehistoric theme for Edison Company, includingPrehistoric Poultry(1916),R.F.D. 10,000 B.C.(1917),The Birth of a Flivver(1917) andCurious Pets of Our Ancestors(1917). O'Brien was then hired by producer Herbert M. Dawley to direct, create effects, co-write and co-star with him forThe Ghost of Slumber Mountain(1918). The collaborative film combined live-action with animated dinosaur models in a 45-minute film, but after the premiere it was cut down to approximately 12 minutes. Dawley did not give O'Brien credits for the visual effects, and instead claimed the animation process as his own invention and even applied for patents.O'Brien's stop motion work was recognized as a technique to create lifelike creatures for adventure films. O' Brien further pioneered the technique with animated dinosaur sequences for the live-action featureThe Lost World(1925). New York artistHelena Smith Dayton, possibly the first female animator, had much success with her \"Caricatypes\" clay statuettes before she began experimenting with clay animation. Some of her first resulting short films were screened on 25 March 1917. She released an adaptation ofWilliam Shakespeare'sRomeo and Julietapproximately half a year later. Although the films and her technique received much attention of the press, it seems she did not continue making films after she returned to New York from managing a YMCA in Paris around 1918. None of her films have yet surfaced, but the extant magazine articles have provided several stills and approximately 20 poorly printed frames from two film strips. By 1920 Starewicz had settled in Paris, and started making new stop-motion films.Dans les Griffes de L'araignée(finished 1920, released 1924) featured detailed hand-made insect puppets that could convey facial expressions with moving lips and eyelids. One of the earliest clay animation films wasModelling Extraordinary, which impressed audiences in 1912. The early Italian feature filmCabiria(1914) featured some stop motion techniques. Starewicz finished the first feature stop-motion filmLe Roman de Renard (The Tale of the Fox)in 1930, but problems with its soundtrack delayed its release. In 1937 it was released with a German soundtrack and in 1941 with its French soundtrack. Hungarian-American filmmakerGeorge Paldeveloped his own stop motion technique of replacing wooden dolls (or parts of them) with similar figures displaying changed poses and/or expressions. He called it Pal-Doll and used it for hisPuppetoonsfilms since 1932. The particular replacement animation method itself also became better known aspuppetoon. In Europe he mainly worked on promotional films for companies such asPhilips. Later Pal gained much success in Hollywood with a string ofAcademy Award for Best Animated Short Films, includingRhythm in the Ranks(1941),Tulips Shall Grow(1942),Jasper and the Haunted House(1942), theDr. SeusspennedThe 500 Hats of Bartholomew Cubbins(1943) andAnd to Think That I Saw It on Mulberry Street(1944),Jasper and the Beanstalk(1945),John Henry and the Inky-Poo(1946),Jasper in a Jam(1946), andTubby the Tuba(1947). Many of his puppetoon films were selected for preservation in the United StatesNational Film Registry. Willis O' Brien's expressive and emotionally convincing animation of the big ape inKing Kong(1933) is widely regarded as a milestone in stop-motion animation and a highlight of Hollywood cinema in general. In 1935,The New Gulliver, aSovietstop motion-animated cartoon, made an extensive use of puppet animation, running almost all the way through the film (it begins and ends with short live-action sequences). The film was released to widespread acclaim and earned directorAleksandr Ptushkoa special prize at the International Cinema Festival in Milan. A 1940 promotional film forAutolite, an automotive parts supplier, featured stop-motion animation of its products marching past Autolite factories to the tune ofFranz Schubert'sMilitary March. An abbreviated version of this sequence was later used in television ads for Autolite, especially those on the 1950s CBS programSuspense, which Autolite sponsored. The first British animated feature was the stop motion instruction filmHandling Ships(1945) byHalas and Batchelorfor theBritish Admiralty. It was not meant for general cinemas, but did become part of the official selection of the 1946Cannes Film Festival. The first Belgian animated feature was anadaptation of the Tintin comicThe Crab with the Golden Claws(1947) with animated puppets. The first Czech animated feature was the package filmThe Czech Year(1947) with animated puppets byJiří Trnka. The film won several awards at theVenice Film Festivaland other international festivals. Trnka would make several more award-winning stop motion features includingThe Emperor's Nightingale(1949),Prince Bayaya(1950),Old Czech Legends(1953), orA Midsummer Night's Dream(1959). He also directed many short films and experimented with other forms of animation. Ray Harryhausenlearned under O'Brien on the filmMighty Joe Young(1949). Harryhausen would go on to create many memorable stop motion effects for a string of successful fantasy films over the next three decades. These includedThe Beast from 20,000 Fathoms(1953),It Came from Beneath the Sea(1955),Jason and the Argonauts(1963),The Golden Voyage of Sinbad(1973), andClash of the Titans(1981). It wasn't until 1954 before a feature animated film with a technique other than cel animation was produced in the US. The first was the stop motion adaptation of 19th century composerEngelbert Humperdinck's operaHänsel und GretelasHansel and Gretel: An Opera Fantasy. In 1955,Karel Zemanmade his first feature filmJourney to the Beginning of Timeinspired byJules Verne, featuring stop-motion animation of dinosaurs and other prehistoric creatures. Art Clokeystarted his adventures in clay with a freeform clay short film calledGumbasia(1955), which shortly thereafter propelled him into the production of his more structured TV seriesGumby(1955–1989), with the iconic titular character. In partnership with theUnited Lutheran Church in America, he also producedDavey and Goliath(1960–2004). The theatrical featureGumby: The Movie(1992, released in 1995) was abox-office bomb. In Hungary, Hungarian–French puppet designer and animated film director,Éva Balla‑Falus, began her series of 6 animated films with various collaborators (with the sculptor Zoltán Olcsai-Kiss,Megy a juhász szamáronin 1948, andVitamin ABCin 1950,Kacsain 1951,Balkéz Tóbiásin 1953,Mese a mihaszna köcsögrőlin 1956, andA didergő királyin 1957. On 22 November 1959, the first episode ofUnser Sandmänchen (Our Little Sandman)was broadcast onDFF (East German television). The 10-minute daily bedtime show for young children features the title character as an animated puppet, and other puppets in different segments. A very similarSandmänchenseries, possibly conceived earlier, ran on West German television from 1 December 1959 until theGerman reunificationin 1989. The East German show was continued on other German networks when DFF ended in 1991, and is one of the longest running animated series in the world.The theatrical featureDas Sandmännchen – Abenteuer im Traumland(2010) was fully animated with stop-motion puppets. Japanese puppet animatorTadahito Mochinagastarted out as assistant animator in short anime (propaganda) filmsArichan(1941) andMomotarō no Umiwashi(1943). He fled toManchukuoduring the war and stayed in China afterwards. Due to the scarcity of paint and film stock shortly after the war, Mochinaga decided to work with puppets and stop motion. His work helped popularize puppet animation in China, before he returned to Japan around 1953 where he continued working as animation director. In the 1960s, Mochinaga supervised the \"Animagic\" puppet animation for productions byArthur Rankin Jr.andJules Bass' Videocraft International, Ltd. (later calledRankin/Bass Productions, Inc.) andDentsu, starting with the syndicated television seriesThe New Adventures of Pinocchio(1960-1961). The Christmas TV specialRudolph the Red-Nosed Reindeerhas been telecasted annually since 1964 and has become one of the most beloved holiday specials in the United States. They made three theatrical feature filmsWilly McBean and His Magic Machine(1965),The Daydreamer(1966, stop motion / live-action) andMad Monster Party?(1966, released in 1967), and the television specialBallad of Smokey the Bear(1966) before the collaboration ended. Rankin/Bass worked with other animators for more TV specials, with titles such asThe Little Drummer Boy(1968),Santa Claus is Comin' to Town(1970) andHere Comes Peter Cottontail(1971). British television has shown many stop motion series for young children since the 1960s. An early example isSnip and Snap(1960-1961) byJohn Halasin collaboration with Danish paper sculptor Thok Søndergaard (Thoki Yenn), featuring dog Snap, cut from a sheet of paper by pair of scissors Snip. Apart from their cutout animation series, British studioSmallfilms(Peter FirminandOliver Postgate) produced several stop motion series with puppets, beginning withPingwings(1961-1965) featuring penguin-like birds knitted by Peter's wife Joan and filmed on their farm (where most of their productions were filmed in an unused barn). It was followed byPogles' Wood(1965-1967),Clangers(1969-1972, 1974, revived in 2015),Bagpuss(1974) andTottie: The Story of a Doll's House(1984). Czech surrealist filmmakerJan Švankmajer's released his short artistic films since 1964, which usually contain much experimental stop motion. He started to gain much international recognition in the 1980s. Since 1988 he has mostly been directing feature films which feature much more live action than stop motion. These includeAlice, an adaptation ofLewis Carroll'sAlice's Adventures in Wonderland, andFaust, a rendition ofthe legend of the German scholar. Švankmajer's work has been highly influential on other artists, such asTerry Gilliamand the Quay brothers (although the latter claim to have only discovered Švankmajer's films after having developed their own similar style). French animatorSerge DanotcreatedThe Magic Roundabout(1965) which played for many years on theBBC. Polish studioSe-ma-forproduced popular TV series with animated puppets in adaptations ofColargol(Barnaby the Bearin the UK,Jeremyin Canada) (1967-1974) andThe Moomins(1977-1982). In the 1960s and 1970s, independent clay animatorEliot Noyes Jr.refined the technique of \"free-form\" clay animation with his Oscar-nominated 1965 filmClay (or the Origin of Species). Noyes also used stop motion to animate sand lying on glass for his musical animated filmSandman(1975). Italian director Francesco Misseri created the clay animation TV seriesMio Mao(1970-1976, 2002–2007),The Red and the Blue(Il Rosso e il Blu, 1976), and a TV series with an animatedorigamiduckQuaq Quao(1978-1979). The British artists Brian Cosgrove and Mark Hall (Cosgrove Hall Films) produced two stop-motion animated adaptions ofEnid Blyton'sNoddybook series, including the original series of the same name (1975–1982) andNoddy's Toyland Adventures(1992–2001), a full-length filmThe Wind in the Willows(1983) and later amulti-season TV series, both based onKenneth Grahame'sclassic children's bookof the same title. They also produced a documentary of their production techniques,Making Frog and Toad. In 1975, filmmaker and clay animation experimenterWill Vintonjoined with sculptorBob Gardinerto create an experimental film calledClosed Mondayswhich became the first stop-motion film to win an Oscar. Will Vinton followed with several other successful short film experiments includingThe Great Cognito,The Creation, andRip Van Winklewhich were each nominated for Academy Awards. In 1977, Vinton made a documentary about this process and his style of animation which he dubbed \"claymation\"; he titled the documentaryClaymation. Soon after this documentary, the term was trademarked by Vinton to differentiate his team's work from others who had been, or were beginning to do, \"clay animation\". While the word has stuck and is often used to describe clay animation and stop motion, it remains a trademark owned currently by Laika Entertainment, Inc. Twenty clay-animation episodes featuring the clownMr. Billwere a feature ofSaturday Night Live, starting from a first appearance in February 1976. At very much the same time in the UK,Peter LordandDavid SproxtonformedAardman Animationsthat would produce many commercials, TV series, short films and eventually also feature films. In 1976 they created the characterMorphwho appeared as an animated side-kick to the TV presenterTony Harton hisBBC TVprogrammeTake Hart. The five-inch-high presenter was made from a traditional British modelling clay calledPlasticine. In 1977 they started on a series of animated films, again using modelling clay, but this time made for a more adult audience. The soundtrack forDown and Outwas recorded in a Salvation Army Hostel and Plasticine puppets were animated to dramatise the dialogue. A second film, also for the BBC followed in 1978. A TV seriesThe Amazing Adventures of Morphwas aired in 1980. Sand-coated puppet animation was used in the Oscar-winning 1977 filmThe Sand Castle, produced by Dutch-Canadian animatorCo Hoedeman. Hoedeman was one of dozens of animators sheltered by theNational Film Board of Canada, a Canadian government film arts agency that had supported animators for decades. A pioneer of refined multiple stop-motion films under the NFB banner wasNorman McLaren, who brought in many other animators to create their own creatively controlled films. Notable among these are thepinscreen animationfilms of Jacques Drouin, made with the original pinscreen donated byAlexandre Alexeieff and Claire Parker. Czech filmmakersLubomír BenešandVladimír Jiránekdebuted their animated puppet charactersPat & Mat, two inventive but clumsy neighbors, in the 7-minute shortKuťáciin 1976. Since 1979, over 100 episodes have been broadcast irregularly.Since 2014, new episodes were presented in theatrically released package films. The series became very popular in several countries, especially in The Netherlands, the only country where the characters are voiced. One of the main British animation teams,John Hardwick and Bob Bura, were the main animators in many early British TV shows, and are famous for their work on theTrumptonshiretrilogy (Camberwick Green,TrumptonandChigley). Their company was named Stop Motion Limited,the term having been their trademark until it becamegeneric. Disney experimented with several stop-motion techniques by hiring independent animator-directorMike Jittlovto make the first stop-motion animation ofMickey Mousetoys ever produced, in a short sequence calledMouse Mania, part of a TV special,Mickey's 50, which commemorated Mickey's 50th anniversary in 1978. Jittlov again produced some impressive multi-technique stop-motion animation a year later for a 1979 Disney special promoting their release of the feature filmThe Black Hole. TitledMajor Effects, Jittlov's work stood out as the best part of the special. Jittlov released his footage the following year to 16mm film collectors as a short film titledThe Wizard of Speed and Time, along with four of his other short multi-technique animated films, most of which eventually evolved into his own feature-length film of the same title. Effectively demonstrating almost all animation techniques, as well as how he produced them, the film was released to theaters in 1987 and to video in 1989. In the 1970s and 1980s,Industrial Light & Magicoften used stop-motion model animation in such films as theoriginalStar Warstrilogy: the holochess sequence inStar Wars, the Tauntauns and AT-AT walkers inThe Empire Strikes Back, and the AT-ST walkers inReturn of the Jediwere all filmed using stop-motion animation, with the latter two films utilisinggo motion: an invention from renowned visual effects veteranPhil Tippett. The many shots including the ghosts inRaiders of the Lost Ark, the Dragon inDragonslayer, and the first two feature films in theRoboCopseries use Tippett's go motion. In the UK, Aardman Animations continued to grow.Channel 4funded a new series of clay animated films,Conversation Pieces, using recorded soundtracks of real people talking. A further series in 1986, calledLip Sync, premiered the work ofRichard Goleszowski(Ident),Barry Purves(Next), andNick Park(Creature Comforts), as well as further films by Sproxton and Lord.Creature Comfortswon the Oscar for Best Animated Short in 1990. In 1986, they also produced a notablemusic video for \"Sledgehammer\", a song byPeter Gabriel. In 1980, Marc Paul Chinoy directed the 1st feature-length clay animated film, based on the famousPogocomic strip. TitledI go Pogo. It was aired a few times on American cable channels but has yet to be commercially released. Primarily clay, some characters required armatures, and walk cycles used pre-sculpted hard bases legs. Stop motion was also used for some shots of the final sequence of the firstTerminatormovie, also for the scenes of the small alien ships inSpielberg'sBatteries Not Includedin 1987, animated byDavid W. Allen. Allen's stop motion work can also be seen in such feature films asThe Crater Lake Monster(1977),Q - The Winged Serpent(1982),The Gate(1987) andFreaked(1993). Allen's King KongVolkswagencommercial from the 1970s is now legendary among model animation enthusiasts. In 1985,Will Vintonand his team released an ambitious feature film in stop motion called \"The Adventures Of Mark Twain\" based on the life and works of the famous American author. While the film may have been a little sophisticated for young audiences at the time, it got rave reviews from critics and adults in general.Vinton's team also created the Nomes and the Nome King for Disney's \"Return to Oz\" feature, for which they received an Academy Award Nomination forSpecial Visual Effects. In the late 1980s and early 1990s, Will Vinton became very well known for his commercial work as well with stop motion campaigns includingThe California RaisinsandThe Noid. Jiří Bartareleased his award-winning fantasy filmThe Pied Piper(1986). From 1986 to 1991,Churchill FilmsproducedThe Mouse and the Motorcycle,Runaway Ralph, andRalph S. Mousefor ABC television. The shows featured stop-motion characters combined with live action, based on the books of Beverly Cleary. John Clark Matthews was the animation director, with Justin Kohn, Joel Fletcher, and Gail Van Der Merwe providing character animation.The company also produced other films based on children's books. From 1986 to 2000,over 150 five-minute episodesofPingu, a Swisschildren'scomedy, were produced by Trickfilmstudio. Aardman Animations'Nick Parkbecame very successful with his short claymationCreature Comfortsin 1989, which hadtalking animalsvoicingvox popinterviews. Park then used the same format to produce a series of commercials between 1990 and 1992. The commercials have been credited as having introduced a more \"caring\" way of advertising in the UK.Richard Goleszowskilater directed two 13-episodeCreature ComfortsTV series (2003, 2005–2006) and a Christmas special (2005). \nAlso in 1989, Park introduced his very popular clay charactersWallace and GromitinA Grand Day Out. Three more short films and one feature film and many TV adaptions and spin-offs would follow. Among many other awards, Park won theAcademy Award for Best Animated Featurefor the feature-length outingWallace & Gromit: The Curse of the Were-Rabbit. Park also worked on theChicken Runmovie, which was another film from Aardman Animations. In 1992,Trey ParkerandMatt StonemadeThe Spirit of Christmas, a short cutout animated student film made withconstruction paper. In 1995 they made a second short with the same titled, commissioned as a Christmas greeting byFox Broadcasting CompanyexecutiveBrian Graden. The concepts and characters were further developed into the TV hit seriesSouth Park(since 1997). Except for the pilot, all animation has been created on computers in the same style. The Nightmare Before Christmas(1993), directed byHenry Selickand produced byTim Burton, was one of the more widely released stop-motion features and became the highest grossing stop-motion animated movie of its time, grossing over $50 million domestic. Henry Selick also went on to directJames and the Giant PeachandCoraline, and Tim Burton went on to directCorpse BrideandFrankenweenie. The stop-motion featureThe Secret Adventures of Tom Thumbwas released in 1993. In November 1998, the first episode ofBob the Builderreleased on BBC. Bob the Builder was a popular British stop-motion television series created by Keith Chapman & produced and owned byHIT Entertainment. In 1999, Will Vinton launched the first US prime-time stop-motion television series calledThe PJs, co-created by actor-comedianEddie Murphy. The Emmy-winning sitcom aired on Fox for two seasons, then moved to the WB for an additional season. Vinton launched another series,Gary & Mike, for UPN in 2001. In 1999,Tsuneo Gōdadirected 30-second sketches of the characterDomo. The shorts, animated by stop-motion studio Dwarf, are currently still produced inJapanand have received universal critical acclaim from fans and critics. Gōda also directed the stop-motion movie seriesKomanekoin 2004. The BBC commissioned thirteen episodes of stop frame animatedSummerton Millin 2004 as inserts into their flagship pre-school program,Tikkabilla. Created and produced by Pete Bryden and Ed Cookson, the series was then given its own slot on BBC1 and BBC2 and has been broadcast extensively around the world. Other notable stop-motion feature films released since 2000 includeFantastic Mr. Fox(2009),$9.99(2009),Anomalisa(2015),Henry Selick'sWendell and Wild(2022) andGuillermo del Toro's Pinocchio(2022). In 2003, the pilot film for the seriesCurucuru and Friends, produced by Korean studio Ffango Entertoyment is greenlighted into achildren'sanimated series in 2004 after an approval with the Gyeonggi Digital Contents Agency. It was aired inKBS1on November 24, 2006, and won the 13th Korean Animation Awards in 2007 for Best Animation. Ffango Entertoyment also worked withFrontier WorksinJapanto produce the 2010 film remake ofCheburashka. Since 2005,Robot Chickenhas mostly utilized stop-motion animation, using custom madeaction figuresand other toys as principal characters. Since 2009,Laika, the stop motion successor toWill Vinton Studios, has released fivefeature films, which have collectively grossed over $400 million:Coraline(2009),ParaNorman(2012),The Boxtrolls(2014),Kubo and the Two Strings(2016) andMissing Link(2019). Directors likeTim BurtonandWes Andersonare still using stop-motion animation in some of their live action films. In 2019 and 2020, cinematographerJeffrey Gardnerwon back-to-back Daytime Creative Arts Emmy Awards for Outstanding Cinematography on the stop-motion seriesTumble Leaf(Amazon Studios), marking one of the rare instances where a director of photography has been recognized for work in stop-motion television.While stop-motion histories often highlight animators and directors, Gardner’s awards underscore the vital role of cinematography in the medium, where lighting, lenses, and miniature set design create the show’s distinctive visual storytelling. In November 2024,DisneyreleasedMickey & Minnie's Christmas Carols, a series of five stop motion shorts featuring Mickey, Minnie, Donald, Daisy, Goofy and Pluto. Stop motion has very rarely been shot instereoscopic3Dthroughout film history. The first 3D stop motion short wasIn Tune With Tomorrow(also known asMotor Rhythm), made in 1939 by John Norling. The second stereoscopic stop motion release wasThe Adventures of Sam Spacein 1955 by Paul Sprunck. The third and latest stop motion short in stereo 3D wasThe Incredible Invasion of the 20,000 Giant Robots from Outer Spacein 2000 by Elmer Kaanand Alexander Lentjes.This is also the first ever 3D stereoscopic stop motion and CGI short in the history of film. The first all stop-motion 3D feature isCoraline(2009), based onNeil Gaiman'sbest-selling noveland directed by Henry Selick.Another recent example is theNintendo 3DSvideo software which comes with the option for Stop-Motion videos. This has been released December 8, 2011 as a 3DS system update. Also, the filmParaNormanis in 3D stop motion. Another more complicated variation on stop motion isgo motion, co-developed byPhil Tippettand first used on the filmsThe Empire Strikes Back(1980),Dragonslayer(1981), and theRoboCopfilms. Go motion involved programming a computer to move parts of a model slightly during each exposure of each frame of film, combined with traditional hand manipulation of the model in between frames, to produce a more realisticmotion blurringeffect. Tippett also used the process extensively in his 1984 short filmPrehistoric Beast, a 10 minutes long sequence depicting a herbivorous dinosaur (Monoclonius), being chased by a carnivorous one (Tyrannosaurus). With new footagePrehistoric BeastbecameDinosaur!in 1985, a full-length dinosaurs documentary hosted byChristopher Reeve. Those Phil Tippett's go motion tests acted as motion models for his first photo-realistic use of computers to depict dinosaurs inJurassic Parkin 1993. A low-tech, manual version of this blurring technique was originally pioneered byWładysław Starewiczin the silent era, and was used in his feature filmThe Tale of the Fox(1931). The reasons for using stop motion instead of the more advancedcomputer-generated imagery(CGI) include the appeal of its distinct look and the notion that it accurately displays real-life textures, while CGI texturing can look more artificial and isn't always quite as close to realism.This is appreciated by a number of animation directors, such asGuillermo del Toro,Henry Selick,Tim BurtonandTravis Knight. Guillermo del Toro aimed to praise the benefits of stop motion in his moviePinocchio, saying that he wanted \"the expressiveness and the material nature of a handmade piece of animation — an artisanal, beautiful exercise in carving, painting, sculpting\". Many young people begin their experiments in movie making with stop- , thanks to the ease of modern stop-motion software and online video publishing.Many new stop-motion shorts use clay animation into a new form. Singer-songwriterOren Lavie's music video for the songHer Morning Elegancewas posted on YouTube on January 19, 2009. The video, directed by Lavie and Yuval and Merav Nathan, uses stop motion and has achieved great success with over 25.4 million views, also earning a 2010 Grammy Award nomination for \"Best Short Form Music Video\". Stop motion has occasionally been used to create the characters forcomputer games, as an alternative to CGI. TheVirgin Interactive EntertainmentMythosgameMagic and Mayhem(1998) featured creatures built by stop-motion specialist Alan Friswell, who made the miniature figures from modelling clay and latex rubber, over armatures of wire and ball-and-socket joints. The models were then animated one frame at a time, and incorporated into the CGI elements of the game through digital photography. \"ClayFighter\" for theSuper NESandThe NeverhoodandHylics 2for thePCare other examples. Scientists at IBM used ascanning tunneling microscopeto single out and move individual atoms which were used to make characters inA Boy and His Atom. This was the tiniest scale stop-motion video made at that time. Replicating the distinct tactile look of traditional stop motion has gained popularity in contemporary media through the use of CGI. This approach can often provide a more cost-effective and accessible means of achieving the stop motion aesthetic. Noteworthy among such endeavors is the work ofBlenderanimator Ian Worthington, exemplified by his 2021 short film \"Captain Yajima\".Another prominent example of this trend includesThe LEGO Movie, which uses CGI to replicate the visual style and imperfections of stop motion.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Stop_motion", "https://en.wikipedia.org/wiki/Stop_motion", "https://en.wikipedia.org/wiki/Stop_motion", "https://en.wikipedia.org/wiki/Time_lapse", "https://en.wikipedia.org/wiki/Stopmotion_(film)", "https://en.wikipedia.org/wiki/Stop_Motion_(EP)", "https://en.wikipedia.org/wiki/Object_animation", "https://en.wikipedia.org/wiki/Animation"]},
{"id": "6b08b3d58fb6", "url": "https://en.wikipedia.org/wiki/Private_attorney_general", "title": "Private attorney general", "headings": ["Contents", "Origin", "India", "Historical cases", "United States", "Criticism", "See also", "Notes", "References"], "content": "Aprivate attorney generalorpublic interest lawyeris an informal term originating incommon lawjurisdictions for a private attorney who brings alawsuitclaiming it to be in thepublic interest, i.e., benefiting the general public and not just theplaintiff, on behalf of a citizen or group of citizens.The attorney may, at the equitable discretion of the court, be entitled to recoverattorney's feesif they prevail. The rationale behind this principle is to provide extra incentive to private attorneys to pursue suits that may be of benefit to society at large. Private attorney general suits are commonly, though not always, brought asclass actionsin jurisdictions that permit the certification of class action lawsuits. Historically in Englishcommon law, awritof qui tam was a writ through whichprivate individualswho assist aprosecutioncan receive for themselves all or part of the damages or financial penalties recovered by the government as a result of the prosecution. Its name is an abbreviation of theLatinphrasequi tam pro domino rege quam pro se ipso in hac parte sequitur, meaning \"[he] who sues in this matter for the king as well as for himself.\" While the writ fell into disuse inEngland and Walesfollowing theCommon Informers Act 1951, it remains current in theUnited Statesunder theFalse Claims Act,31 U.S.C.§ 3729et seq., which allows a private individual, or \"whistleblower\" (or relator), with knowledge of past or presentfraudcommitted against thefederal governmentto bring suit on its behalf. This allowance and, in some cases, reliance on private individual litigation to enforce the law has also been referred to as a \"bounty\" system due to the private citizen's potential financial gain if the suit is successful.There are alsoqui tamprovisions in18 U.S.C.§ 962regarding arming vessels against friendly nations;25 U.S.C.§ 201regarding violating Indian protection laws;46 U.S.C.§ 80103regarding the removal of undersea treasure from the Florida coast to foreign nations; and35 U.S.C.§ 292regarding false marking. However, in February 2011, thequi tamprovision regarding false marking was held to be unconstitutional bya U.S. District Court,and, in September of that year, the enactment of theLeahy–Smith America Invents Acteffectively removedqui tamremedies from § 292.Contemporary private attorney general lawsuits are an outgrowth of the rationale underlying the writ of qui tam that enabling private citizens to enforce the law will strengthen enforcement and contribute to therule of law. Non-governmental organisationsand activists in India acting as private attorneys general routinely undertake litigation to secure public interest and demonstrates the availability of justice to socially-disadvantaged parties and was introduced by JusticeP. N. Bhagwati. Traditionally, Indian courts applied the English doctrine oflocus standi, permitting litigation only from parties affected directly or indirectly by the defendant. However, by the end of the twentieth century, theSupreme Courtand the country's various high courts began permitting cases on the grounds of public interest litigation, permittingcivil societyactors to file litigation aimed at enforcing civil and consumer rights. Litigation brought in this manner by private citizens led to the development inIndian tort lawofabsolute liabilityfor enterprises engaging in hazardous activities that subsequently caused harm to any individual or community or to their property under the rule inM. C. Mehta v. Union of India. One of the earliest public interest litigation was filed byG. Vasantha Paiwho filed a case in theMadras High Courtagainst the then sitting Chief Justice of the Madras High courtS. Ramachandra Iyerafter it was found the judge had forged his date of birth to avoid compulsory retirement at the age of 60 and his younger brother  sent invitations to celebrate his60th birthdayand Pai found evidence after photographing his original birth register  which showed his real age.Ramachandra Iyer resigned on a request from the thenChief Justice of IndiaP. B. Gajendragadkaras the case would damage the judiciaryand he resigned before the case came up for hearing this led the case to be dismissed as he had resigned. In December 1979,Kapila Hingoranifiled a petition in regards to the condition of the prisoners detained in the Bihar jail, whose suits were pending in court. The petition was signed by prisoners of the Bihar jail and the case was filed in theSupreme Court of Indiabefore the bench headed by JusticeP. N. Bhagwati. The petition was filed under the name of a prisoner, Hussainara Khatoon, and the case was therefore namedHussainara Khatoon Vs State of Bihar. The Supreme Court decided that prisoners should receive free legal aid and fast hearings. As a result, 40,000 prisoners were released from jail. Thereafter many similar cases have been registered in the Supreme Court. It was in the case ofSP Gupta vs Union of Indiathat the Supreme Court of India defined the term \"public interest litigation\" in the Indian context. In Vishaka v State of Rajasthan, the plaintiff fought against sexual harassment in the workplace and was filed by Bhanwari Devi, who, after trying to stop the marriage of a one-year-old girl in rural Rajasthan, was raped by five men. She faced numerous problems when she (Devi) attempted to seek justice. Naina Kapoor decided to initiate a PIL to challenge sexual harassment at workplace in the Supreme Courts. The judgement of the case recognised sexual harassment as a violation of the fundamental constitutional rights ofArticles 14,15, and 21. The guidelines also directed for sexual harassment prevention. In the United States, manycivil rightsstatutes rely on private attorneys general for their enforcement. InNewman v. Piggie Park Enterprises, one of the earliest cases construing theCivil Rights Act of 1964, theUnited States Supreme Courtruled that \"A public accommodations suit is thus private in form only. When a plaintiff brings an action … he cannot recoverdamages. If he obtains aninjunction, he does so not for himself alone but also as a 'private attorney general,' vindicating a policy that Congress considered of the highest priority.\"TheUnited States Congresshas also passed laws with \"private attorney general\" provisions that provide for the enforcement of laws prohibitingemployment discrimination,police brutality, andwater pollution.  Under theClean Water Act, for example, \"any citizen\" may bring suit against an individual or a company that is a source ofwater pollution. Another example of the \"private attorney general\" provisions is theRacketeer Influenced and Corrupt Organizations Act(RICO).  RICO allows average citizens (private attorneys general) to sue organisations that commit mail and wire fraud as part of their criminal enterprise.To date, there are over 60 federal statutesthat encourage private enforcement by allowing prevailing plaintiffs to collect attorney's fees. Attorneys who function as a private attorney general do so without compensation. The statutes permitting a plaintiff to recover attorneys' fees have been held not to apply when the plaintiff is an attorney. President Clinton sought to find common ground between liberals who support stronger enforcement of civil rights andconsumer protectionlaw and conservatives sceptical of expensive government regulation, stating in his secondState of the Union Address\"That it was time for the American People to be given more power while the Federal Government down sizes\"One approach to compromise that rose to prominence was providing for private citizens to act as \"private attorneys general\" for the enforcement of civil rights law,thereby delegating both the task and the financial burden of regulation tocivil society. One instance of the use of \"private attorney general\" is inenvironmental activismand the enforcement of civil rights legislation protecting racial and ethnic minorities, where the role of private lawyers and organisations has generally been welcomed by federal authorities. For instance, in the case \"Chester Residents Concerned for Quality Living v Seif\", the federal government filed anamicus briefarguing that the regulations of Title VI of the Civil Rights Act of 1964 can be enforced by private attorneys generalCorrespondingly, theSupreme Courthas determined that Congress intended several civil rights statutes to be enforceable by private parties The U.S. Congress codified the private attorney general principle into law with the enactment ofCivil Rights Attorney's Fees Award Act of 1976,42 U.S.C.§ 1988.  The Senate Report on this statute stated that The Senate Committee on the Judiciary wanted to level the playing field so that privatecitizens, who might have little or no money, could still serve as \"private attorneys general\" and afford to bring actions, even against state or local bodies, to enforce the civil rights laws. The Committee acknowledged that, \"[i]f private citizens are to be able to assert their civil rights, and if those who violate the Nation's fundamental laws are not to proceed with impunity, then citizens must have the opportunity to recover what it costs them to vindicate these rights in court.\"  Where a plaintiff wins his or her lawsuit and is considered the \"prevailing party,\" § 1988 acts to shift fees, including expert witness fees at least in certain types of civil rights actions, under theCivil Rights Act of 1991, even if not in § 1983 actions, and to make those who acted as private attorneys general whole again, thus encouraging the enforcement of the civil rights laws.  The Senate reported that it intended fee awards to be \"adequate to attract competent counsel\" to represent client with civil rights grievances. S. Rep. No. 94-1011, p. 6 (1976).  The U.S. Supreme Court has interpreted the act to provide for the payment of a \"reasonable attorney's fee\" based on the fair market value of the legal services. While there is such a thing as a private attorney general act in the United States, it should be stated that there is no such thing as a private non-attorney citizen being a \"private attorney general\" for all purposes.  The term applies only to the exercise of one's ability to pursue certain specific kinds of legal actions which are statutorily authorized.  It does not create the ability to call one's self a \"private attorney general\". In the area of product liability and consumer protection law, advocates of tort reform criticise private attorney general suits as attempts at regulation through litigation, the idea that litigation is being used to achieve regulatory ends that advocates would not be able to achieve through the democratic process. Private attorney general suits in America are frequently criticised as examples of regulation through litigation.Similarly,public interest litigationin India has been criticised for underminingparliamentary sovereigntyand enabling the court system to exert inordinate power over the legislative and executive branches of government. For instance, the emergence ofconstitutional tortshas been criticised as an undemocratic example ofjudicial activism.Controversy further arose when judges began to read such obligations of the state into Article 21 of theIndian Constitution.However, opponents of tort reform assert that public interest litigation in India has served to secure \"social and distributive justice.\"Inlaw and economicsliterature, there is consequently a debate as to whether liability and regulation are substitutes or complements and thus whether the enforcement of predictable regulation known to manufacturers in advance can adequately assure consumer safety while providing greater legal certainty for manufacturers than strict liability Another criticism of private attorney general suits in common law jurisdictions is that the availability ofdiscoveryenables private attorneys general to impose costs on defendants in order to force settlements in unmeritorious cases to avoid the cost of discovery.Similarly, legal commentators incivil law jurisdictionsargue that broad discovery in the hands of private parties is destructive of therule of lawand amounts to \"a private inquisition.\"Civil law countries see the underlying objectives of discovery as properlymonopolised by the statein order to maintain the rule of law: the investigative objective of discovery is the prerogative of theexecutive branch, and insofar as discovery may be able to facilitate the creation of new rights, that is the prerogative of thelegislative branch. The principle underlying private attorney general lawsuits and the traditional writ of qui tam stands in contrast to the doctrine ofparens patriae, under which the government is best placed to protect citizens from harmful conduct in its capacity as the \"parent of the nation\".", "combined_text": "Private attorney general Contents Origin India Historical cases United States Criticism See also Notes References Aprivate attorney generalorpublic interest lawyeris an informal term originating incommon lawjurisdictions for a private attorney who brings alawsuitclaiming it to be in thepublic interest, i.e., benefiting the general public and not just theplaintiff, on behalf of a citizen or group of citizens.The attorney may, at the equitable discretion of the court, be entitled to recoverattorney's feesif they prevail. The rationale behind this principle is to provide extra incentive to private attorneys to pursue suits that may be of benefit to society at large. Private attorney general suits are commonly, though not always, brought asclass actionsin jurisdictions that permit the certification of class action lawsuits. Historically in Englishcommon law, awritof qui tam was a writ through whichprivate individualswho assist aprosecutioncan receive for themselves all or part of the damages or financial penalties recovered by the government as a result of the prosecution. Its name is an abbreviation of theLatinphrasequi tam pro domino rege quam pro se ipso in hac parte sequitur, meaning \"[he] who sues in this matter for the king as well as for himself.\" While the writ fell into disuse inEngland and Walesfollowing theCommon Informers Act 1951, it remains current in theUnited Statesunder theFalse Claims Act,31 U.S.C.§ 3729et seq., which allows a private individual, or \"whistleblower\" (or relator), with knowledge of past or presentfraudcommitted against thefederal governmentto bring suit on its behalf. This allowance and, in some cases, reliance on private individual litigation to enforce the law has also been referred to as a \"bounty\" system due to the private citizen's potential financial gain if the suit is successful.There are alsoqui tamprovisions in18 U.S.C.§ 962regarding arming vessels against friendly nations;25 U.S.C.§ 201regarding violating Indian protection laws;46 U.S.C.§ 80103regarding the removal of undersea treasure from the Florida coast to foreign nations; and35 U.S.C.§ 292regarding false marking. However, in February 2011, thequi tamprovision regarding false marking was held to be unconstitutional bya U.S. District Court,and, in September of that year, the enactment of theLeahy–Smith America Invents Acteffectively removedqui tamremedies from § 292.Contemporary private attorney general lawsuits are an outgrowth of the rationale underlying the writ of qui tam that enabling private citizens to enforce the law will strengthen enforcement and contribute to therule of law. Non-governmental organisationsand activists in India acting as private attorneys general routinely undertake litigation to secure public interest and demonstrates the availability of justice to socially-disadvantaged parties and was introduced by JusticeP. N. Bhagwati. Traditionally, Indian courts applied the English doctrine oflocus standi, permitting litigation only from parties affected directly or indirectly by the defendant. However, by the end of the twentieth century, theSupreme Courtand the country's various high courts began permitting cases on the grounds of public interest litigation, permittingcivil societyactors to file litigation aimed at enforcing civil and consumer rights. Litigation brought in this manner by private citizens led to the development inIndian tort lawofabsolute liabilityfor enterprises engaging in hazardous activities that subsequently caused harm to any individual or community or to their property under the rule inM. C. Mehta v. Union of India. One of the earliest public interest litigation was filed byG. Vasantha Paiwho filed a case in theMadras High Courtagainst the then sitting Chief Justice of the Madras High courtS. Ramachandra Iyerafter it was found the judge had forged his date of birth to avoid compulsory retirement at the age of 60 and his younger brother  sent invitations to celebrate his60th birthdayand Pai found evidence after photographing his original birth register  which showed his real age.Ramachandra Iyer resigned on a request from the thenChief Justice of IndiaP. B. Gajendragadkaras the case would damage the judiciaryand he resigned before the case came up for hearing this led the case to be dismissed as he had resigned. In December 1979,Kapila Hingoranifiled a petition in regards to the condition of the prisoners detained in the Bihar jail, whose suits were pending in court. The petition was signed by prisoners of the Bihar jail and the case was filed in theSupreme Court of Indiabefore the bench headed by JusticeP. N. Bhagwati. The petition was filed under the name of a prisoner, Hussainara Khatoon, and the case was therefore namedHussainara Khatoon Vs State of Bihar. The Supreme Court decided that prisoners should receive free legal aid and fast hearings. As a result, 40,000 prisoners were released from jail. Thereafter many similar cases have been registered in the Supreme Court. It was in the case ofSP Gupta vs Union of Indiathat the Supreme Court of India defined the term \"public interest litigation\" in the Indian context. In Vishaka v State of Rajasthan, the plaintiff fought against sexual harassment in the workplace and was filed by Bhanwari Devi, who, after trying to stop the marriage of a one-year-old girl in rural Rajasthan, was raped by five men. She faced numerous problems when she (Devi) attempted to seek justice. Naina Kapoor decided to initiate a PIL to challenge sexual harassment at workplace in the Supreme Courts. The judgement of the case recognised sexual harassment as a violation of the fundamental constitutional rights ofArticles 14,15, and 21. The guidelines also directed for sexual harassment prevention. In the United States, manycivil rightsstatutes rely on private attorneys general for their enforcement. InNewman v. Piggie Park Enterprises, one of the earliest cases construing theCivil Rights Act of 1964, theUnited States Supreme Courtruled that \"A public accommodations suit is thus private in form only. When a plaintiff brings an action … he cannot recoverdamages. If he obtains aninjunction, he does so not for himself alone but also as a 'private attorney general,' vindicating a policy that Congress considered of the highest priority.\"TheUnited States Congresshas also passed laws with \"private attorney general\" provisions that provide for the enforcement of laws prohibitingemployment discrimination,police brutality, andwater pollution.  Under theClean Water Act, for example, \"any citizen\" may bring suit against an individual or a company that is a source ofwater pollution. Another example of the \"private attorney general\" provisions is theRacketeer Influenced and Corrupt Organizations Act(RICO).  RICO allows average citizens (private attorneys general) to sue organisations that commit mail and wire fraud as part of their criminal enterprise.To date, there are over 60 federal statutesthat encourage private enforcement by allowing prevailing plaintiffs to collect attorney's fees. Attorneys who function as a private attorney general do so without compensation. The statutes permitting a plaintiff to recover attorneys' fees have been held not to apply when the plaintiff is an attorney. President Clinton sought to find common ground between liberals who support stronger enforcement of civil rights andconsumer protectionlaw and conservatives sceptical of expensive government regulation, stating in his secondState of the Union Address\"That it was time for the American People to be given more power while the Federal Government down sizes\"One approach to compromise that rose to prominence was providing for private citizens to act as \"private attorneys general\" for the enforcement of civil rights law,thereby delegating both the task and the financial burden of regulation tocivil society. One instance of the use of \"private attorney general\" is inenvironmental activismand the enforcement of civil rights legislation protecting racial and ethnic minorities, where the role of private lawyers and organisations has generally been welcomed by federal authorities. For instance, in the case \"Chester Residents Concerned for Quality Living v Seif\", the federal government filed anamicus briefarguing that the regulations of Title VI of the Civil Rights Act of 1964 can be enforced by private attorneys generalCorrespondingly, theSupreme Courthas determined that Congress intended several civil rights statutes to be enforceable by private parties The U.S. Congress codified the private attorney general principle into law with the enactment ofCivil Rights Attorney's Fees Award Act of 1976,42 U.S.C.§ 1988.  The Senate Report on this statute stated that The Senate Committee on the Judiciary wanted to level the playing field so that privatecitizens, who might have little or no money, could still serve as \"private attorneys general\" and afford to bring actions, even against state or local bodies, to enforce the civil rights laws. The Committee acknowledged that, \"[i]f private citizens are to be able to assert their civil rights, and if those who violate the Nation's fundamental laws are not to proceed with impunity, then citizens must have the opportunity to recover what it costs them to vindicate these rights in court.\"  Where a plaintiff wins his or her lawsuit and is considered the \"prevailing party,\" § 1988 acts to shift fees, including expert witness fees at least in certain types of civil rights actions, under theCivil Rights Act of 1991, even if not in § 1983 actions, and to make those who acted as private attorneys general whole again, thus encouraging the enforcement of the civil rights laws.  The Senate reported that it intended fee awards to be \"adequate to attract competent counsel\" to represent client with civil rights grievances. S. Rep. No. 94-1011, p. 6 (1976).  The U.S. Supreme Court has interpreted the act to provide for the payment of a \"reasonable attorney's fee\" based on the fair market value of the legal services. While there is such a thing as a private attorney general act in the United States, it should be stated that there is no such thing as a private non-attorney citizen being a \"private attorney general\" for all purposes.  The term applies only to the exercise of one's ability to pursue certain specific kinds of legal actions which are statutorily authorized.  It does not create the ability to call one's self a \"private attorney general\". In the area of product liability and consumer protection law, advocates of tort reform criticise private attorney general suits as attempts at regulation through litigation, the idea that litigation is being used to achieve regulatory ends that advocates would not be able to achieve through the democratic process. Private attorney general suits in America are frequently criticised as examples of regulation through litigation.Similarly,public interest litigationin India has been criticised for underminingparliamentary sovereigntyand enabling the court system to exert inordinate power over the legislative and executive branches of government. For instance, the emergence ofconstitutional tortshas been criticised as an undemocratic example ofjudicial activism.Controversy further arose when judges began to read such obligations of the state into Article 21 of theIndian Constitution.However, opponents of tort reform assert that public interest litigation in India has served to secure \"social and distributive justice.\"Inlaw and economicsliterature, there is consequently a debate as to whether liability and regulation are substitutes or complements and thus whether the enforcement of predictable regulation known to manufacturers in advance can adequately assure consumer safety while providing greater legal certainty for manufacturers than strict liability Another criticism of private attorney general suits in common law jurisdictions is that the availability ofdiscoveryenables private attorneys general to impose costs on defendants in order to force settlements in unmeritorious cases to avoid the cost of discovery.Similarly, legal commentators incivil law jurisdictionsargue that broad discovery in the hands of private parties is destructive of therule of lawand amounts to \"a private inquisition.\"Civil law countries see the underlying objectives of discovery as properlymonopolised by the statein order to maintain the rule of law: the investigative objective of discovery is the prerogative of theexecutive branch, and insofar as discovery may be able to facilitate the creation of new rights, that is the prerogative of thelegislative branch. The principle underlying private attorney general lawsuits and the traditional writ of qui tam stands in contrast to the doctrine ofparens patriae, under which the government is best placed to protect citizens from harmful conduct in its capacity as the \"parent of the nation\".", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Private_attorney_general", "https://en.wikipedia.org/wiki/Private_attorney_general", "https://en.wikipedia.org/wiki/Private_attorney_general", "https://en.wikipedia.org/wiki/Cause_lawyer", "https://en.wikipedia.org/wiki/Common_law", "https://en.wikipedia.org/wiki/Lawsuit", "https://en.wikipedia.org/wiki/Public_interest", "https://en.wikipedia.org/wiki/Plaintiff"]},
{"id": "507a5dbc7e62", "url": "https://en.wikipedia.org/wiki/Teleology", "title": "Teleology", "headings": ["Contents", "History", "Etymology", "Platonic", "Aristotelian", "Modern philosophy", "Kant, Hegel and Marx", "Postmodern philosophy", "Ethics", "Consequentialism", "Deontology", "Economics", "Science", "Biology", "Cybernetics", "See also", "References", "Notes", "Citations", "Further reading"], "content": "Teleology(fromτέλος,telos, 'end', 'aim', or 'goal', andλόγος,logos, 'explanation' or 'reason')orfinalityis a branch ofcausalitygiving the reason or an explanation for something as a function of its end, its purpose, or its goal, as opposed to as a function of its cause. A purpose that is imposed by human use, such as the purpose of a fork to hold food, is calledextrinsic.Natural teleology, common inclassical philosophy, though controversial today,contends that natural entities also haveintrinsicpurposes, regardless of human use or opinion. For instance,Aristotleclaimed that an acorn's intrinsictelosis to become a fully grown oak tree.Though ancient materialists rejected the notion of natural teleology, teleological accounts of non-personal or non-human nature were explored and often endorsed in ancient and medieval philosophies, but fell into disfavor during the modern era (1600–1900). Much of the discussion on teleology revolves around religion and the belief in a Godly, purposeful existence for the world and for humans.SeeTeleological argumentfor an in-depth discussion on teleology and religion.  InWestern philosophy, the term and concept ofteleologyoriginated in the writings ofPlatoandAristotle. Aristotle's 'four causes' gives a special place to the telos or \"final cause\" of eachthing. In this, he followed Plato in seeing purpose in both human and nonhuman nature. The wordteleologycombinesGreektelos(τέλος, fromτελε-, 'end' or 'purpose')andlogia(-λογία, 'speak of', 'study of', or 'a branch of learning').German philosopherChristian Wolffwould coin the term asteleologia(Latin) in his workPhilosophia rationalis, sive logica(1728). InPlato'sdialoguePhaedo,Socratesargues that true explanations for any given physical phenomenon must be teleological. He bemoans those who fail to distinguish between a thing's necessary and sufficient causes, which he identifies respectively asmaterialandfinalcauses: Imagine not being able to distinguish the real cause, from that without which the cause would not be able to act, as a cause. It is what the majority appear to do, like people groping in the dark; they call it a cause, thus giving it a name that does not belong to it. That is why one man surrounds the earth with a vortex to make the heavens keep it in place, another makes the air support it like a wide lid. As for their capacity of being in the best place they could be at this very time, this they do not look for, nor do they believe it to have any divine force, but they believe that they will sometime discover a stronger and more immortal Atlas to hold everything together more, and they do not believe that the truly good and 'binding' binds and holds them together. — Plato,Phaedo, 99 Socrates here argues that while the materials that compose a body are necessary conditions for its moving or acting in a certain way, they nevertheless cannot be thesufficientcondition for its moving or acting as it does. For example,if Socrates is sitting in an Athenian prison, the elasticity of his tendons is what allows him to be sitting, and so a physical description of his tendons can be listed asnecessary conditionsorauxiliary causesof his act of sitting.However, these are only necessary conditions of Socrates' sitting. To give a physical description of Socrates' body is to saythatSocrates is sitting, but it does not give any idea whyit came to bethat he was sitting in the first place. To say why he was sitting and notnotsitting, it is necessary to explain what it is about his sitting that isgood, for all things brought about (i.e., all products of actions) are brought about because the actor saw some good in them. Thus, to give an explanation of something is to determine what about it is good. Its goodness is itsactual cause—its purpose,telosor 'reason for which'. Aristotleargued thatDemocrituswas wrong to attempt to reduce all things to mere necessity, because doing so neglects the aim, order, and \"final cause\", which brings about these necessary conditions: Democritus, however, neglecting the final cause, reduces to necessity all the operations of nature. Now, they are necessary, it is true, but yet they are for a final cause and for the sake of what is best in each case. Thus nothing prevents the teeth from being formed and being shed in this way; but it is not on account of these causes but on account of the end. ... — Aristotle,Generation of Animals5.8, 789a8–b15 InPhysics, using thehylomorphic theory, (using eternalformsas his model), Aristotle rejects Plato's assumption that the universe was created by an intelligent designer. For Aristotle, natural ends are produced by \"natures\" (principles of change internal to living things), and natures, Aristotle argued, do not deliberate: It is absurd to suppose that ends are not present [in nature] because we do not see an agent deliberating. — Aristotle,Physics, 2.8, 199b27-9 These Platonic and Aristotelian arguments ran counter to those presented earlier byDemocritusand later byLucretius, both of whom were supporters of what is now often calledaccidentalism: Nothing in the body is made in order that we may use it. What happens to exist is the cause of its use. —Lucretius,De rerum natura[On the Nature of Things] 4, 833 In the 17th century, philosophers such asRené DescartesandThomas Hobbeswrote in opposition to Aristotelian teleology. The suggestion that there’s more to objects than their materialism was rejected in favor of a mechanistic view of even complex creatures and organisms.According to Hobbes, writing inLeviathan: Life is but a motion of limbs. For what is the heart, but a spring; and the nerves, but so many strings; and the joints, but so many wheels, giving motion to the whole body. But while science was doing a great job at explaining natural phenomena, it stopped short of explaining how life develops.In the late 18th century,Immanuel Kantacknowledged this shortcoming in hisCritique of Judgement: There will never be a Newton of the blade of grass, because human science will never be able to explain how a living being can originate from inanimate matter. The chief instance, and the largest polemic morass, of teleological viewpoint in modern cosmology and ontology is theteleological argumentthat posits anintelligent designeras agod. Immanuel Kantexplained teleology as a subjective (false) perception, necessary for humans to understand the world, but in actuality, not a determining factor in biology or even in human personal and social behavior. Biological behavior, reacting to \"self-preservation\" criteria, is an outcome of Darwinist-like adaptation, with the organisms having \"intrinsic and natural purposiveness\". (Note: Darwin's theory on evolution was published only after Kant's death.) Wilhelm Hegelopposed Kant's view and claimed it was legitimate for a materialistic view to accept \"high\" intrinsic teleology, where organisms, or at least the human self-conscious mind, and following it, whole societies are capable of determining and deciding their actions, for self-preservation and awareness, and the human pursuit of self-conscious freedom. This, according to Kant, differs from the \"low\" teleology where an entity decides to use external means for its own goal, which was the religious claim about god or some \"high\" entity with its own agenda for the world and humans. InThe Science of Logic, and more elaborately in Phenomenology of Spirit (1807),Wilhelm Hegelwrote that life occurs when a body advances from \"mechanism\" and \"chemism\" to acquire the goals of self-preservation and \"self-realization\", and acts accordingly. History (meaning the sequences of human behavior), according to him, is the outcome of humanity becoming conscious of its own freedom through social antagonism and self-recognition and changing from an irrational and unaware state to a free, rational, self-conscious state of being. Hegel's basic theory is that every idea being realized has a stage of thesis where its flaws are revealed, creating an antithesis, which resolves those flaws but has flaws of its own, and finally the two clash and a new, improved synthesis is created. This process continues with the ideas advancing and becoming better and refined. History, according to Hegel, is actually this realization of ideas through clashing and refinement. Leaning on these notions,Karl Marxwrote with teleological terminology that society advances through cultural clashes between classes striving for material economic goals, struggling through revolution with the ruling classes inherent to capitalism, until finally society will establish a classless commune.Since Marx is speaking about a scientific explanation to history and social behavior, many explain this as being consequentialist, with the culture clash caused by the existence of unequal classes and the lack of economic wealth by the lower classes, leading to an open, non-deterministic result caused by the situation and the collective behavior in response to it. Teleological-based \"grand narratives\" are renounced by thepostmoderntradition,where teleology may be viewed as reductive, exclusionary, and harmful to those whose stories are diminished or overlooked. Against this postmodern position,Alasdair MacIntyrehas argued that a narrative understanding of oneself, of one's capacity as an independent reasoner, one's dependence on others and on the social practices and traditions in which one participates, all tend towards an ultimate good of liberation. Social practices may themselves be understood as teleologically oriented to internal goods. For example, practices of philosophical and scientific inquiry are teleologically ordered to the elaboration of a true understanding of their objects. MacIntyre'sAfter Virtue(1981) famously dismissed the naturalistic teleology of Aristotle's \"metaphysical biology\", but he has cautiously moved from that book's account of a sociological teleology toward an exploration of what remains valid in a more traditional teleological naturalism. Teleology significantly informs the study ofethics, such as in: The broad spectrum ofconsequentialistethics—of whichutilitarianismis a well-known example—focuses on the result or consequences, with such principles asJohn Stuart Mill's 'principle of utility': \"the greatest good for the greatest number\". This principle is thus teleological, though in a broader sense than is elsewhere understood in philosophy. In the classical notion, teleology is grounded in the inherent nature of things themselves, whereas inconsequentialism, teleology is imposed on nature from outside by the human will. Consequentialist theories justify inherently what most people would call evil acts by their desirable outcomes, if the good of the outcome outweighs the bad of the act. So, for example, a consequentialist theory would say it was acceptable to kill one person in order to save two or more other people. These theories may be summarized by the maxim \"the end justifies the means.\" Consequentialism stands in contrast to the more classical notions ofdeontologicalethics, of which examples includeImmanuel Kant'scategorical imperative, andAristotle'svirtueethics—although formulations of virtue ethics are also often consequentialist in derivation. In deontological ethics, the goodness or badness of individual acts is primary and a larger, more desirable goal is insufficient to justify bad acts committed on the way to that goal, even if the bad acts are relatively minor and the goal is major (like telling a small lie to prevent a war and save millions of lives). In requiring all constituent acts to be good,deontological ethicsis much more rigid than consequentialism, which varies by circumstance. Practical ethicsare usually a mix of the two. For example, Mill also relies on deontic maxims to guide practical behavior, but they must be justifiable by the principle of utility. A teleology of human aims played a crucial role in the work ofeconomistLudwig von Mises, especially in the development of his science ofpraxeology. Mises believed that an individual's action is teleological because it is governed by the existence of their chosen ends.In other words, individuals select what they believe to be the most appropriate means to achieve a sought after goal or end. Mises also stressed that, with respect to human action, teleology is not independent of causality: \"No action can be devised and ventured upon without definite ideas about the relation of cause and effect, teleology presupposes causality.\" Assuming reason and action to be predominantly influenced by ideological credence, Mises derived his portrayal of human motivation fromEpicurean teachings, insofar as he assumes \"atomistic individualism, teleology, and libertarianism, and defines man as an egoist who seeks a maximum of happiness\" (i.e. the ultimate pursuit of pleasure over pain).\"Man strives for,\" Mises remarks, \"but never attains the perfect state of happiness described byEpicurus.\"Furthermore, expanding upon the Epicurean groundwork, Mises formalized his conception of pleasure and pain by assigning each specific meaning, allowing him to extrapolate his conception of attainable happiness to a critique of liberal versus socialist ideological societies. It is there, in his application of Epicurean belief to political theory, that Mises flouts Marxist theory, considering labor to be one of many of man's 'pains', a consideration which positioned labor as a violation of his original Epicurean assumption of man's manifest hedonistic pursuit. From here he further postulates a critical distinction between introversive labor and extroversive labor, further diverging from basic Marxist theory, in which Marx hails labor as man's \"species-essence\", or his \"species-activity\". Modern science sees the 'reason' for an event as causality. In cases ofteleonomy, wordings suggesting purpose are preferred to be avoided. For example, using teleological wording as an explanatory style within evolutionary biology is somewhat controversial. Since theNovum OrganumofFrancis Bacon, teleological explanations inphysical sciencetend to be deliberately avoided in favor of focus on material and efficient explanations, although some recent accounts of quantum phenomena make use of teleology.Final and formal causation came to be viewed as false or too subjective.Nonetheless, some disciplines, in particular withinevolutionary biology, continue to use language that appears teleological in describing natural tendencies towards certain end conditions. Somesuggest, however, that these arguments ought to be, and practicably can be, rephrased in non-teleological forms; others hold that teleological language cannot always beeasilyexpunged from descriptions in the life sciences, at least within the bounds of practicalpedagogy. Contemporary philosophers and scientists still debate whether teleologicalaxiomsare useful or accurate in proposing modern philosophies and scientific theories. An example of the reintroduction of teleology into modern language is the notion of anattractor.Another instance is whenThomas Nagel(2012), though not a biologist, proposed a non-Darwinianaccount ofevolutionthat incorporates impersonal and natural teleological laws to explain the existence of life,consciousness,rationality, and objective value.Regardless, the accuracy can also be considered independently from the usefulness: it is a common experience inpedagogythat a minimum of apparent teleology can be useful in thinking about and explaining Darwinian evolution even if there is no true teleology driving evolution. Thus, it is easier to say that evolution \"gave\" wolves sharpcanine teethbecause those teeth \"serve the purpose of\"predationregardless of whether there is an underlying non-teleologic reality in which evolution is not an actor with intentions. In other words, because humancognitionandlearningoften rely on the narrative structure of stories – with actors, goals, and immediate (proximate) rather than ultimate (distal) causation (see alsoproximate and ultimate causation) – some minimal level of teleology might be recognized as useful or at least tolerable for practical purposes even by people who reject itscosmologicaccuracy. Its accuracy is upheld by Barrow and Tipler (1986), whose citations of such teleologists asMax PlanckandNorbert Wienerare significant for scientific endeavor. Apparent teleology is a recurring issue inevolutionary biology,much to the consternation of some writers. Statements implying that nature has goals, for example, where a species is said to do something \"in order to\" achieve survival, appear teleological, and therefore invalid. Usually, it is possible to rewrite such sentences to avoid the apparent teleology. Some biology courses have incorporated exercises requiring students to rephrase such sentences so that they do not read teleologically. Nevertheless, biologists still frequently write in a way which can be read as implying teleology even if that is not the intention. John Reiss argues that evolutionary biology can be purged of such teleology by rejecting the analogy of natural selection as awatchmaker.Other arguments against this analogy have also been promoted by writers such asRichard Dawkins. Some authors, likeJames Lennox, have argued thatDarwinwas a teleologist,while others, such asMichael Ghiselin, describe this claim as a myth promoted by misinterpretations of his discussions and emphasized the distinction between using teleological metaphors and being teleological. Biologist philosopherFrancisco Ayalahas argued that all statements about processes can be trivially translated into teleological statements, and vice versa, but that teleological statements are more explanatory and cannot be disposed of.Karen Neanderhas argued that the modern concept of biological 'function' is dependent upon selection. So, for example, it is not possible to say that anything that simply winks into existence without going through a process of selection has functions. We decide whether an appendage has a function by analysing the process of selection that led to it. Therefore, any talk of functions must be posterior to natural selection and function cannot be defined in the manner advocated by Reiss and Dawkins. Ernst Mayrstates that \"adaptedness ... is ana posterioriresult rather than ana priorigoal-seeking\".Various commentators view the teleological phrases used in modern evolutionary biology as a type of shorthand. For example,Simon Hugh Piper Maddrellwrites that \"the proper but cumbersome way of describing change by evolutionary adaptation [may be] substituted by shorter overtly teleological statements\" for the sake of saving space, but that this \"should not be taken to imply that evolution proceeds by anything other than from mutations arising by chance, with those that impart an advantage being retained by natural selection\".Likewise,J. B. S. Haldanesays, \"Teleology is like a mistress to a biologist: he cannot live without her but he's unwilling to be seen with her in public.\" Cyberneticsis the study of thecommunicationandcontrolofregulatory feedbackboth in living beings and machines, and in combinations of the two. Arturo Rosenblueth,Norbert Wiener, andJulian Bigelowclassified behaviors as purposeful when there seems to be a goal directing that behavior, but non-purposeful when the causality is clear. Hence, a rock falling is non-purposeful, but the action of a rocket (fired by humans) is perhaps purposeful. They then divided the classification into teleological — if the targeted behavior was receiving feedback of any sort, or non-teleological, if on its way to the goal, there was no processing of feedback. So even machinery can be teleological, if it has afeedback mechanism.Wiener coined the termcyberneticsto denote the study of \"teleological mechanisms\".In the cybernetic classification presented by Rosenblueth, Wiener, and Bigelow,teleologyis feedback controlled purpose. Thus, decision making and intelligent or purposeful behavior, by any object, including machines, computers, living beings, humans, and societies, is a process in time that begins through physical, well-understood stages, caused by physical phenomena, processed by physically materialistic biochemical and physiological constructs of machinery or computers. In the case of biological behavior, the physical input is processed by neurons, brain parts, glands and hormonal interactions, interacting with previously stored learned or inherited biological constructs that result in actions which lead to the self preservation of the \norganism, with an emerging causality-based teleology. The classification system underlying cybernetics has been criticized byFrank Honywill Georgeand Les Johnson, who cite the need for an external observability to the purposeful behavior in order to establish and validate the goal-seeking behavior.\nJust because it seems to have a mechanism for accepting feedback does not necessitate that a machine is now \"behaving teleologically\".The fact that some phenomena is being observed and changed by the feedback mechanism, is well understood objective control, but the part of the mechanism that is doing the observing and takes part in self preservation in living beings is not the same as a machine with feedback. The living being (or at least the human brain) has \"subjectiveautonomy\".", "combined_text": "Teleology Contents History Etymology Platonic Aristotelian Modern philosophy Kant, Hegel and Marx Postmodern philosophy Ethics Consequentialism Deontology Economics Science Biology Cybernetics See also References Notes Citations Further reading Teleology(fromτέλος,telos, 'end', 'aim', or 'goal', andλόγος,logos, 'explanation' or 'reason')orfinalityis a branch ofcausalitygiving the reason or an explanation for something as a function of its end, its purpose, or its goal, as opposed to as a function of its cause. A purpose that is imposed by human use, such as the purpose of a fork to hold food, is calledextrinsic.Natural teleology, common inclassical philosophy, though controversial today,contends that natural entities also haveintrinsicpurposes, regardless of human use or opinion. For instance,Aristotleclaimed that an acorn's intrinsictelosis to become a fully grown oak tree.Though ancient materialists rejected the notion of natural teleology, teleological accounts of non-personal or non-human nature were explored and often endorsed in ancient and medieval philosophies, but fell into disfavor during the modern era (1600–1900). Much of the discussion on teleology revolves around religion and the belief in a Godly, purposeful existence for the world and for humans.SeeTeleological argumentfor an in-depth discussion on teleology and religion.  InWestern philosophy, the term and concept ofteleologyoriginated in the writings ofPlatoandAristotle. Aristotle's 'four causes' gives a special place to the telos or \"final cause\" of eachthing. In this, he followed Plato in seeing purpose in both human and nonhuman nature. The wordteleologycombinesGreektelos(τέλος, fromτελε-, 'end' or 'purpose')andlogia(-λογία, 'speak of', 'study of', or 'a branch of learning').German philosopherChristian Wolffwould coin the term asteleologia(Latin) in his workPhilosophia rationalis, sive logica(1728). InPlato'sdialoguePhaedo,Socratesargues that true explanations for any given physical phenomenon must be teleological. He bemoans those who fail to distinguish between a thing's necessary and sufficient causes, which he identifies respectively asmaterialandfinalcauses: Imagine not being able to distinguish the real cause, from that without which the cause would not be able to act, as a cause. It is what the majority appear to do, like people groping in the dark; they call it a cause, thus giving it a name that does not belong to it. That is why one man surrounds the earth with a vortex to make the heavens keep it in place, another makes the air support it like a wide lid. As for their capacity of being in the best place they could be at this very time, this they do not look for, nor do they believe it to have any divine force, but they believe that they will sometime discover a stronger and more immortal Atlas to hold everything together more, and they do not believe that the truly good and 'binding' binds and holds them together. — Plato,Phaedo, 99 Socrates here argues that while the materials that compose a body are necessary conditions for its moving or acting in a certain way, they nevertheless cannot be thesufficientcondition for its moving or acting as it does. For example,if Socrates is sitting in an Athenian prison, the elasticity of his tendons is what allows him to be sitting, and so a physical description of his tendons can be listed asnecessary conditionsorauxiliary causesof his act of sitting.However, these are only necessary conditions of Socrates' sitting. To give a physical description of Socrates' body is to saythatSocrates is sitting, but it does not give any idea whyit came to bethat he was sitting in the first place. To say why he was sitting and notnotsitting, it is necessary to explain what it is about his sitting that isgood, for all things brought about (i.e., all products of actions) are brought about because the actor saw some good in them. Thus, to give an explanation of something is to determine what about it is good. Its goodness is itsactual cause—its purpose,telosor 'reason for which'. Aristotleargued thatDemocrituswas wrong to attempt to reduce all things to mere necessity, because doing so neglects the aim, order, and \"final cause\", which brings about these necessary conditions: Democritus, however, neglecting the final cause, reduces to necessity all the operations of nature. Now, they are necessary, it is true, but yet they are for a final cause and for the sake of what is best in each case. Thus nothing prevents the teeth from being formed and being shed in this way; but it is not on account of these causes but on account of the end. ... — Aristotle,Generation of Animals5.8, 789a8–b15 InPhysics, using thehylomorphic theory, (using eternalformsas his model), Aristotle rejects Plato's assumption that the universe was created by an intelligent designer. For Aristotle, natural ends are produced by \"natures\" (principles of change internal to living things), and natures, Aristotle argued, do not deliberate: It is absurd to suppose that ends are not present [in nature] because we do not see an agent deliberating. — Aristotle,Physics, 2.8, 199b27-9 These Platonic and Aristotelian arguments ran counter to those presented earlier byDemocritusand later byLucretius, both of whom were supporters of what is now often calledaccidentalism: Nothing in the body is made in order that we may use it. What happens to exist is the cause of its use. —Lucretius,De rerum natura[On the Nature of Things] 4, 833 In the 17th century, philosophers such asRené DescartesandThomas Hobbeswrote in opposition to Aristotelian teleology. The suggestion that there’s more to objects than their materialism was rejected in favor of a mechanistic view of even complex creatures and organisms.According to Hobbes, writing inLeviathan: Life is but a motion of limbs. For what is the heart, but a spring; and the nerves, but so many strings; and the joints, but so many wheels, giving motion to the whole body. But while science was doing a great job at explaining natural phenomena, it stopped short of explaining how life develops.In the late 18th century,Immanuel Kantacknowledged this shortcoming in hisCritique of Judgement: There will never be a Newton of the blade of grass, because human science will never be able to explain how a living being can originate from inanimate matter. The chief instance, and the largest polemic morass, of teleological viewpoint in modern cosmology and ontology is theteleological argumentthat posits anintelligent designeras agod. Immanuel Kantexplained teleology as a subjective (false) perception, necessary for humans to understand the world, but in actuality, not a determining factor in biology or even in human personal and social behavior. Biological behavior, reacting to \"self-preservation\" criteria, is an outcome of Darwinist-like adaptation, with the organisms having \"intrinsic and natural purposiveness\". (Note: Darwin's theory on evolution was published only after Kant's death.) Wilhelm Hegelopposed Kant's view and claimed it was legitimate for a materialistic view to accept \"high\" intrinsic teleology, where organisms, or at least the human self-conscious mind, and following it, whole societies are capable of determining and deciding their actions, for self-preservation and awareness, and the human pursuit of self-conscious freedom. This, according to Kant, differs from the \"low\" teleology where an entity decides to use external means for its own goal, which was the religious claim about god or some \"high\" entity with its own agenda for the world and humans. InThe Science of Logic, and more elaborately in Phenomenology of Spirit (1807),Wilhelm Hegelwrote that life occurs when a body advances from \"mechanism\" and \"chemism\" to acquire the goals of self-preservation and \"self-realization\", and acts accordingly. History (meaning the sequences of human behavior), according to him, is the outcome of humanity becoming conscious of its own freedom through social antagonism and self-recognition and changing from an irrational and unaware state to a free, rational, self-conscious state of being. Hegel's basic theory is that every idea being realized has a stage of thesis where its flaws are revealed, creating an antithesis, which resolves those flaws but has flaws of its own, and finally the two clash and a new, improved synthesis is created. This process continues with the ideas advancing and becoming better and refined. History, according to Hegel, is actually this realization of ideas through clashing and refinement. Leaning on these notions,Karl Marxwrote with teleological terminology that society advances through cultural clashes between classes striving for material economic goals, struggling through revolution with the ruling classes inherent to capitalism, until finally society will establish a classless commune.Since Marx is speaking about a scientific explanation to history and social behavior, many explain this as being consequentialist, with the culture clash caused by the existence of unequal classes and the lack of economic wealth by the lower classes, leading to an open, non-deterministic result caused by the situation and the collective behavior in response to it. Teleological-based \"grand narratives\" are renounced by thepostmoderntradition,where teleology may be viewed as reductive, exclusionary, and harmful to those whose stories are diminished or overlooked. Against this postmodern position,Alasdair MacIntyrehas argued that a narrative understanding of oneself, of one's capacity as an independent reasoner, one's dependence on others and on the social practices and traditions in which one participates, all tend towards an ultimate good of liberation. Social practices may themselves be understood as teleologically oriented to internal goods. For example, practices of philosophical and scientific inquiry are teleologically ordered to the elaboration of a true understanding of their objects. MacIntyre'sAfter Virtue(1981) famously dismissed the naturalistic teleology of Aristotle's \"metaphysical biology\", but he has cautiously moved from that book's account of a sociological teleology toward an exploration of what remains valid in a more traditional teleological naturalism. Teleology significantly informs the study ofethics, such as in: The broad spectrum ofconsequentialistethics—of whichutilitarianismis a well-known example—focuses on the result or consequences, with such principles asJohn Stuart Mill's 'principle of utility': \"the greatest good for the greatest number\". This principle is thus teleological, though in a broader sense than is elsewhere understood in philosophy. In the classical notion, teleology is grounded in the inherent nature of things themselves, whereas inconsequentialism, teleology is imposed on nature from outside by the human will. Consequentialist theories justify inherently what most people would call evil acts by their desirable outcomes, if the good of the outcome outweighs the bad of the act. So, for example, a consequentialist theory would say it was acceptable to kill one person in order to save two or more other people. These theories may be summarized by the maxim \"the end justifies the means.\" Consequentialism stands in contrast to the more classical notions ofdeontologicalethics, of which examples includeImmanuel Kant'scategorical imperative, andAristotle'svirtueethics—although formulations of virtue ethics are also often consequentialist in derivation. In deontological ethics, the goodness or badness of individual acts is primary and a larger, more desirable goal is insufficient to justify bad acts committed on the way to that goal, even if the bad acts are relatively minor and the goal is major (like telling a small lie to prevent a war and save millions of lives). In requiring all constituent acts to be good,deontological ethicsis much more rigid than consequentialism, which varies by circumstance. Practical ethicsare usually a mix of the two. For example, Mill also relies on deontic maxims to guide practical behavior, but they must be justifiable by the principle of utility. A teleology of human aims played a crucial role in the work ofeconomistLudwig von Mises, especially in the development of his science ofpraxeology. Mises believed that an individual's action is teleological because it is governed by the existence of their chosen ends.In other words, individuals select what they believe to be the most appropriate means to achieve a sought after goal or end. Mises also stressed that, with respect to human action, teleology is not independent of causality: \"No action can be devised and ventured upon without definite ideas about the relation of cause and effect, teleology presupposes causality.\" Assuming reason and action to be predominantly influenced by ideological credence, Mises derived his portrayal of human motivation fromEpicurean teachings, insofar as he assumes \"atomistic individualism, teleology, and libertarianism, and defines man as an egoist who seeks a maximum of happiness\" (i.e. the ultimate pursuit of pleasure over pain).\"Man strives for,\" Mises remarks, \"but never attains the perfect state of happiness described byEpicurus.\"Furthermore, expanding upon the Epicurean groundwork, Mises formalized his conception of pleasure and pain by assigning each specific meaning, allowing him to extrapolate his conception of attainable happiness to a critique of liberal versus socialist ideological societies. It is there, in his application of Epicurean belief to political theory, that Mises flouts Marxist theory, considering labor to be one of many of man's 'pains', a consideration which positioned labor as a violation of his original Epicurean assumption of man's manifest hedonistic pursuit. From here he further postulates a critical distinction between introversive labor and extroversive labor, further diverging from basic Marxist theory, in which Marx hails labor as man's \"species-essence\", or his \"species-activity\". Modern science sees the 'reason' for an event as causality. In cases ofteleonomy, wordings suggesting purpose are preferred to be avoided. For example, using teleological wording as an explanatory style within evolutionary biology is somewhat controversial. Since theNovum OrganumofFrancis Bacon, teleological explanations inphysical sciencetend to be deliberately avoided in favor of focus on material and efficient explanations, although some recent accounts of quantum phenomena make use of teleology.Final and formal causation came to be viewed as false or too subjective.Nonetheless, some disciplines, in particular withinevolutionary biology, continue to use language that appears teleological in describing natural tendencies towards certain end conditions. Somesuggest, however, that these arguments ought to be, and practicably can be, rephrased in non-teleological forms; others hold that teleological language cannot always beeasilyexpunged from descriptions in the life sciences, at least within the bounds of practicalpedagogy. Contemporary philosophers and scientists still debate whether teleologicalaxiomsare useful or accurate in proposing modern philosophies and scientific theories. An example of the reintroduction of teleology into modern language is the notion of anattractor.Another instance is whenThomas Nagel(2012), though not a biologist, proposed a non-Darwinianaccount ofevolutionthat incorporates impersonal and natural teleological laws to explain the existence of life,consciousness,rationality, and objective value.Regardless, the accuracy can also be considered independently from the usefulness: it is a common experience inpedagogythat a minimum of apparent teleology can be useful in thinking about and explaining Darwinian evolution even if there is no true teleology driving evolution. Thus, it is easier to say that evolution \"gave\" wolves sharpcanine teethbecause those teeth \"serve the purpose of\"predationregardless of whether there is an underlying non-teleologic reality in which evolution is not an actor with intentions. In other words, because humancognitionandlearningoften rely on the narrative structure of stories – with actors, goals, and immediate (proximate) rather than ultimate (distal) causation (see alsoproximate and ultimate causation) – some minimal level of teleology might be recognized as useful or at least tolerable for practical purposes even by people who reject itscosmologicaccuracy. Its accuracy is upheld by Barrow and Tipler (1986), whose citations of such teleologists asMax PlanckandNorbert Wienerare significant for scientific endeavor. Apparent teleology is a recurring issue inevolutionary biology,much to the consternation of some writers. Statements implying that nature has goals, for example, where a species is said to do something \"in order to\" achieve survival, appear teleological, and therefore invalid. Usually, it is possible to rewrite such sentences to avoid the apparent teleology. Some biology courses have incorporated exercises requiring students to rephrase such sentences so that they do not read teleologically. Nevertheless, biologists still frequently write in a way which can be read as implying teleology even if that is not the intention. John Reiss argues that evolutionary biology can be purged of such teleology by rejecting the analogy of natural selection as awatchmaker.Other arguments against this analogy have also been promoted by writers such asRichard Dawkins. Some authors, likeJames Lennox, have argued thatDarwinwas a teleologist,while others, such asMichael Ghiselin, describe this claim as a myth promoted by misinterpretations of his discussions and emphasized the distinction between using teleological metaphors and being teleological. Biologist philosopherFrancisco Ayalahas argued that all statements about processes can be trivially translated into teleological statements, and vice versa, but that teleological statements are more explanatory and cannot be disposed of.Karen Neanderhas argued that the modern concept of biological 'function' is dependent upon selection. So, for example, it is not possible to say that anything that simply winks into existence without going through a process of selection has functions. We decide whether an appendage has a function by analysing the process of selection that led to it. Therefore, any talk of functions must be posterior to natural selection and function cannot be defined in the manner advocated by Reiss and Dawkins. Ernst Mayrstates that \"adaptedness ... is ana posterioriresult rather than ana priorigoal-seeking\".Various commentators view the teleological phrases used in modern evolutionary biology as a type of shorthand. For example,Simon Hugh Piper Maddrellwrites that \"the proper but cumbersome way of describing change by evolutionary adaptation [may be] substituted by shorter overtly teleological statements\" for the sake of saving space, but that this \"should not be taken to imply that evolution proceeds by anything other than from mutations arising by chance, with those that impart an advantage being retained by natural selection\".Likewise,J. B. S. Haldanesays, \"Teleology is like a mistress to a biologist: he cannot live without her but he's unwilling to be seen with her in public.\" Cyberneticsis the study of thecommunicationandcontrolofregulatory feedbackboth in living beings and machines, and in combinations of the two. Arturo Rosenblueth,Norbert Wiener, andJulian Bigelowclassified behaviors as purposeful when there seems to be a goal directing that behavior, but non-purposeful when the causality is clear. Hence, a rock falling is non-purposeful, but the action of a rocket (fired by humans) is perhaps purposeful. They then divided the classification into teleological — if the targeted behavior was receiving feedback of any sort, or non-teleological, if on its way to the goal, there was no processing of feedback. So even machinery can be teleological, if it has afeedback mechanism.Wiener coined the termcyberneticsto denote the study of \"teleological mechanisms\".In the cybernetic classification presented by Rosenblueth, Wiener, and Bigelow,teleologyis feedback controlled purpose. Thus, decision making and intelligent or purposeful behavior, by any object, including machines, computers, living beings, humans, and societies, is a process in time that begins through physical, well-understood stages, caused by physical phenomena, processed by physically materialistic biochemical and physiological constructs of machinery or computers. In the case of biological behavior, the physical input is processed by neurons, brain parts, glands and hormonal interactions, interacting with previously stored learned or inherited biological constructs that result in actions which lead to the self preservation of the \norganism, with an emerging causality-based teleology. The classification system underlying cybernetics has been criticized byFrank Honywill Georgeand Les Johnson, who cite the need for an external observability to the purposeful behavior in order to establish and validate the goal-seeking behavior.\nJust because it seems to have a mechanism for accepting feedback does not necessitate that a machine is now \"behaving teleologically\".The fact that some phenomena is being observed and changed by the feedback mechanism, is well understood objective control, but the part of the mechanism that is doing the observing and takes part in self preservation in living beings is not the same as a machine with feedback. The living being (or at least the human brain) has \"subjectiveautonomy\".", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Teleology", "https://en.wikipedia.org/wiki/Teleology", "https://en.wikipedia.org/wiki/Teleology", "https://en.wikipedia.org/wiki/Plato", "https://en.wikipedia.org/wiki/Aristotle", "https://en.wikipedia.org/wiki/The_School_of_Athens", "https://en.wikipedia.org/wiki/Logos", "https://en.wikipedia.org/wiki/Telos_(philosophy)"]},
{"id": "6a4643712f7d", "url": "https://en.wikipedia.org/wiki/Ren%C3%A9_Clair", "title": "René Clair", "headings": ["Contents", "Early life", "Film career", "1924–1934", "1935–1946", "1947–1965", "Writing and later work", "Personal life", "Reputation", "Filmography", "Feature films", "Short films", "Television", "Awards and honours", "See also", "References", "External links"], "content": " René Clair(French pronunciation:[ʁəneklɛʁ]; 11 November 1898 – 15 March 1981), bornRené-Lucien Chomette([ʁənelysjɛ̃ʃɔmɛt]), was a French filmmaker and writer. He first established his reputation in the 1920s as a director of silent films in which comedy was often mingled with fantasy. He went on to make some of the most innovative early sound films in France, before going abroad to work in the UK and USA for more than a decade. Returning to France after World War II, he continued to make films that were characterised by their elegance and wit, often presenting a nostalgic view of French life in earlier years. He was elected to theAcadémie Françaisein 1960. Clair's best known films includeUn chapeau de paille d'Italie(The Italian Straw Hat, 1928),Sous les toits de Paris(Under the Roofs of Paris, 1930),Le Million(1931),À nous la liberté(1931),I Married a Witch(1942), andAnd Then There Were None(1945). René Clair was born and grew up in Paris in the district ofLes Halles, whose lively and picturesque character made a lasting impression on him.His father was a soap merchant; he had an elder brother, Henri Chomette (born 1896). He attended the Lycée Montaigne and the Lycée Louis-le-Grand. In 1914 he was studying philosophy; his friends at that time included Raymond Payelle who became the actor and writerPhilippe Hériat.In 1917, at the age of 18, he served as an ambulance driver inWorld War I, before being invalided out with a spinal injury. He was deeply affected by the horrors of war that he witnessed and gave expression to this in writing a volume of poetry calledLa Tête de l'homme(which remained unpublished). Back in Paris after the war, he started a career as a journalist at the left-wing newspaperL'Intransigeant. Having met the music-hall singerDamiaand written some songs for her, Clair was persuaded by her to visit Gaumont studios in 1920 where a film was being cast and he then agreed to take on a leading role inLe Lys de la vie,directed byLoïe FullerandGabrielle Sorère. He adopted the stage-name of René Clair, and several other acting jobs followed, includingParisetteforLouis Feuillade. In 1922 he extended his career as a journalist, becoming the editor of a new film supplement to a monthly magazine,Théâtre et Comœdia illustrés.  He also visited Belgium and after an introduction from his brother Henri, he became an assistant to the directorJacques de Baroncellion several films. In 1924, with the support of the producerHenri Diamant-Berger, Clair got the opportunity to direct his own first film,Paris qui dort(The Crazy Ray), a short comic fantasy. Before it had been shown however, Clair was asked byFrancis PicabiaandErik Satieto make a short film to be shown as part of their Dadaist balletRelâche; he madeEntr'acte(1924), and it established Clair as a leading member of the Parisian avant-garde. Fantasy and dreams were also components of his next two films, but in 1926 Clair took a new direction when he joined Alexandre Kamenka'sFilms Albatroscompany to film a dramatic story,La Proie du vent(The Prey of the Wind), which met with commercial success. He remained at Albatros for his last two silent films,Un chapeau de paille d'Italie(An Italian Straw Hat) andLes Deux Timides(Two Timid Souls) (both 1928), in which he sought to translate the essentially verbal comedy of two plays byLabicheinto works of silent cinema.While at Albatros, Clair met the designerLazare Meersonand the cameramanGeorges Périnalwho were to remain important collaborators with him for the next decade. By the end of the silent era, Clair was celebrated as one of the great names in cinema, alongsideGriffith,Chaplin,PabstandEisenstein. As the author of all of his own scripts, who also paid close attention to every aspect of the making of a film, including the editing, Clair was one of the first French film-makers to establish for himself the full role of anauteur. Clair was initially sceptical about the introduction of sound to films, and called it \"an unnatural creation\".He then realised the creative possibilities that it offered, particularly, in his view, if the soundtrack was not used realistically; words and pictures need not, and indeed should not, be tied together in a clumsy duplication of information; dialogue did not always need to be heard.Between 1930 and 1933, Clair explored these ideas in his first four sound films, starting withSous les toits de Paris(Under the Roofs of Paris); this was followed byLe Million(1931),À nous la liberté(1931), andQuatorze juillet(Bastille Day) (1933). All of these films portrayed an affectionate and idealized view of working class life, and they did much to create a popular romantic image of Paris which was seen around the world.These films were made at theEpinay Studiosfor Films Sonores Tobis, a French subsidiary of the German-ownedTobiscompany. When Chaplin madeModern Timesin 1936, it was noted that some parts of it bore a marked similarity to scenes inÀ nous la liberté, and the production company Tobis launched a lawsuit for plagiarism againstUnited Artists, the producers of Chaplin's film. Clair was embarrassed by this since he acknowledged his own debt to the spirit of Chaplin, and he refused to be associated with the action. After the immense success of these early sound films, Clair met with a major setback when his next film,Le Dernier Milliardaire(The Last Billionaire/The Last Millionaire) (1934), was a critical and commercial flop. While he was visiting London for the film's British première, he metAlexander Kordawho offered him a contract to work in England.  He accepted, and began a lengthy period of exile from film-making in France. Clair's contract with Korda'sLondon Filmswas for two years and it envisaged three films. Because of his limited English, he collaborated with the American dramatistRobert E. Sherwoodas script-writer for his first film,The Ghost Goes West(1935), a comic fantasy about transatlantic culture clash. Clair and Sherwood became close friends. In January 1936, Clair visited America for two weeks, checking out for future employment possibilities but still planning to remain with Korda. Korda however rejected Clair's next script and they parted company.Clair's remaining time in England led to only one more completed film,Break the News(1938), a musical comedy withJack BuchananandMaurice Chevalier. Returning to France, Clair attempted to make another film there in 1939,Air pur, which was to be a celebration of youth and childhood, but the outbreak of war interrupted filming and it was abandoned.In May 1940,Jean Giraudoux, then Minister of Information, suggested to Clair that the film profession should concentrate its resources in the south of country in Nice and Marseille – and if necessary establish a French production centre in the United States. It was with this last plan in mind that Clair and his family, along withJulien Duvivier, departed for America, but by the time he reached New York the project had already fallen through and he went straight on to Hollywood where several studios were interested in employing him.He made his first American film for Universal Studios,The Flame of New Orleans(1941), but it was such a commercial failure that for a time Clair's career as a director was in the balance.After more than a year's delay, his next film wasI Married a Witch(1942), followed byIt Happened Tomorrow(1944), both of which did respectably well, and thenAnd Then There Were None(1945), which turned out to be an exceptional commercial success despite being perhaps the least personal of his Hollywood ventures.Each of Clair's American films was made for a different studio. In 1941 Clair was stripped of his French citizenship by the Vichy government, though this was later reversed.It was also in 1941 that he learned of the death of his brother Henri Chomette in France from polio.In 1943, he was planning to go to Algeria to organise the Service Cinématographique de l'Armée, but funding for the project was withdrawn just as he was on the point of departure.In July 1945 he went back to France for a short visit, and then returned finally in July 1946, having signed a contract with RKO for his next film to be made in France. Clair's American exile had allowed him to develop his characteristic vein of ironical fantasy with several commercially successful films, but there was some feeling that it had been at the expense of personal control and that his output there had not matched the quality of his earlier work in France.Clair himself recognised that being employed by the highly organized American studios had allowed him to work in ideal circumstances: \"In spite of the restrictions of the American system, it is possible, if one wishes, to take responsibility. In my four Hollywood films I managed to do what I wanted.\" Clair's first film on his return to France was the romantic comedyLe silence est d'or(Silence is Golden) (1947), which was set in 1906 and nostalgically evoked the world of early French film-making; its plot also created variations on Molière'sL'École des femmes.Clair considered it one of his best post-war films.Literary inspirations also underpinned other films:FaustforLa Beauté du diable(Beauty and the Devil) (1950); andDon JuanforLes Grandes Manœuvres(1955). In these two films and the interveningLes Belles de nuit(Beauties of the Night) (1952), the leading actor wasGérard Philipewho became a friend and a favourite performer for Clair.Porte des Lilas(1957) was a sombre film, set once again in a popular district of Paris with its picturesque inhabitants, for which the singerGeorges Brassenswas persuaded to give his only film performance. During the 1950s, as a new generation of French critics and film-makers emerged who were impatient of the prevailing modes of film production, Clair found himself increasingly criticised as a representative of thecinéma de qualité, a \"cinema of old men\"dominated by nostalgia for their younger days.His status as a figure of the 'establishment' was further confirmed by his election to theAcadémie Françaisein 1960. Although he continued to make a few more films in comic vein such asTout l'or du monde(All the Gold in the World) (1961), they were not well received and he made his last film,Les Fêtes galantes(The Lace Wars), in 1965. Clair began his career as a journalist, and writing remained an important interest for him to which he increasingly turned in his later years. In 1926 he published a novel,Adams(translated into English asStar Turn), about a Hollywood star for whom the distinction between the real and unreal becomes blurred.He occasionally returned to writing fiction (La Princesse de ChineandJeux du hasard), but many of his publications dealt with the cinema, including reflections on his own films. Apart from many journal articles, his main publications were: Clair also ventured into other media.  In 1951 he directed his first radio production,Une larme du diable.  In 1959 he directed a stage production ofMusset'sOn ne badine pas avec l'amour, in whichGérard Philipegave one of his last performances before his death. In 1972 he staged Gluck'sOrphéefor the Paris Opéra. At the end of 1924, while Clair was working onCiné-sketchfor the theatre with France Picabia, he first met a young actress, Bronja Perlmutter, who subsequently appeared in his filmLe Voyage imaginaire(1926) premiered at the newly openedStudio des Ursulines. They married in 1926, and their son, Jean-François, was born in 1927. René Clair died at home on 15 March 1981, and he was buried privately at Saint-Germain-l'Auxerrois. Clair's reputation as a film-maker underwent a considerable reevaluation during the course of his own lifetime: in the 1930s he was widely seen as one of France's greatest directors, alongsideRenoirandCarné, but thereafter his work's artifice and detachment from the realities of life fell increasingly from favour.The avant-gardism of his first films, and especiallyEntr'acte, had given him a temporary notoriety, and a grounding in surrealism continued to underlie much of his comedy work. It was however the imaginative manner in which he overcame his initial scepticism about the arrival of sound which established his originality, and his first four sound films brought him international fame. Clair's years of working in the UK and USA made him still more widely known but did not show any marked development in his style or thematic concerns. It was in the post-war films that he made on his return to France that some critics have observed a new maturity and emotional depth, accompanied by a prevailing sense of melancholy but still framed by the elegance and wit that characterised his earlier work. However, in the 1950s the critics who heralded the arrival of theFrench New Wave, especially those associated withCahiers du Cinéma, found Clair's work old-fashioned and academic.François Truffautwrote harshly of him after seeingThe Flame of New Orleans: \"We don't follow our elders in paying the same tribute to Renoir and Clair. There is no film by Clair which matches the invention and wit of Renoir'sTire au flanc.... Clair makes films for old ladies who go to the cinema twice a year.\" André Bazin, the founding editor ofCahiers, made a more measured assessment: \"René Clair has remained in a way a film-maker of the silent cinema. Whatever the quality and importance of his recent films, expression through the image always predominates over that of the word and one almost never misses the essence if one can only vaguely hear the dialogue.\"It was also in a special number ofCahiers du Cinémareviewing the current state of the French cinema in 1957 that Clair received one of his most positive appreciations: \"A complete film author who, since the silent era, has brought to the French cinema intelligence, refinement, humour, an intellectual quality that is slightly dry but smiling and in good taste.... Whatever may follow in his rich career, he has created a cinematic world that is his own, full of rigour and not lacking in imagination, thanks to which he remains one of our greatest film-makers.\" Such appreciations have subsequently been rare, and the self-contained artificiality of Clair's films, his insistence on the meticulous preparation of an often literary script, and his preference for filming in studio sets rather than on location increasingly set him apart from modern trends in film-making.The paradox of Clair's reputation has been further heightened by those commentators who have seen François Truffaut as the French cinema's true successor to Clair, notwithstanding the occasions of their mutual disdain.  René Clair held the national honours of Grand officier de laLégion d'honneur,Commandeur des Arts et des Lettres, andGrand-croix de l'ordre national du Mérite.  He received the Grand Prix du cinéma français in 1953. In 1951, he won thePrix Italiain Naples for a French radio production ofUne larme du diablebyThéophile Gautier. In 1956 he was awarded an honorary doctorate by theUniversity of Cambridge. In 1960 he was elected to theAcadémie Française; he was not the first film-maker so honoured (he was preceded byMarcel Pagnol(1946),Jean Cocteau(1955), andMarcel Achard(1959)) but he was the first to be elected primarily as a film-maker. In 1994 the Académie established thePrix René-Clairas an annual prize awarded to a distinguished film-maker. In 1967 he received an honorary doctorate from theRoyal College of Artin London. As well as many awards made for individual films, Clair received an honorary prize at the11th Moscow International Film Festivalin 1979 for his contribution to cinema. Place René Clair inBoulogne-Billancourt, on the outskirts of Paris and near the site of the formerfilm studiosin that district, is named after him.", "combined_text": "René Clair Contents Early life Film career 1924–1934 1935–1946 1947–1965 Writing and later work Personal life Reputation Filmography Feature films Short films Television Awards and honours See also References External links  René Clair(French pronunciation:[ʁəneklɛʁ]; 11 November 1898 – 15 March 1981), bornRené-Lucien Chomette([ʁənelysjɛ̃ʃɔmɛt]), was a French filmmaker and writer. He first established his reputation in the 1920s as a director of silent films in which comedy was often mingled with fantasy. He went on to make some of the most innovative early sound films in France, before going abroad to work in the UK and USA for more than a decade. Returning to France after World War II, he continued to make films that were characterised by their elegance and wit, often presenting a nostalgic view of French life in earlier years. He was elected to theAcadémie Françaisein 1960. Clair's best known films includeUn chapeau de paille d'Italie(The Italian Straw Hat, 1928),Sous les toits de Paris(Under the Roofs of Paris, 1930),Le Million(1931),À nous la liberté(1931),I Married a Witch(1942), andAnd Then There Were None(1945). René Clair was born and grew up in Paris in the district ofLes Halles, whose lively and picturesque character made a lasting impression on him.His father was a soap merchant; he had an elder brother, Henri Chomette (born 1896). He attended the Lycée Montaigne and the Lycée Louis-le-Grand. In 1914 he was studying philosophy; his friends at that time included Raymond Payelle who became the actor and writerPhilippe Hériat.In 1917, at the age of 18, he served as an ambulance driver inWorld War I, before being invalided out with a spinal injury. He was deeply affected by the horrors of war that he witnessed and gave expression to this in writing a volume of poetry calledLa Tête de l'homme(which remained unpublished). Back in Paris after the war, he started a career as a journalist at the left-wing newspaperL'Intransigeant. Having met the music-hall singerDamiaand written some songs for her, Clair was persuaded by her to visit Gaumont studios in 1920 where a film was being cast and he then agreed to take on a leading role inLe Lys de la vie,directed byLoïe FullerandGabrielle Sorère. He adopted the stage-name of René Clair, and several other acting jobs followed, includingParisetteforLouis Feuillade. In 1922 he extended his career as a journalist, becoming the editor of a new film supplement to a monthly magazine,Théâtre et Comœdia illustrés.  He also visited Belgium and after an introduction from his brother Henri, he became an assistant to the directorJacques de Baroncellion several films. In 1924, with the support of the producerHenri Diamant-Berger, Clair got the opportunity to direct his own first film,Paris qui dort(The Crazy Ray), a short comic fantasy. Before it had been shown however, Clair was asked byFrancis PicabiaandErik Satieto make a short film to be shown as part of their Dadaist balletRelâche; he madeEntr'acte(1924), and it established Clair as a leading member of the Parisian avant-garde. Fantasy and dreams were also components of his next two films, but in 1926 Clair took a new direction when he joined Alexandre Kamenka'sFilms Albatroscompany to film a dramatic story,La Proie du vent(The Prey of the Wind), which met with commercial success. He remained at Albatros for his last two silent films,Un chapeau de paille d'Italie(An Italian Straw Hat) andLes Deux Timides(Two Timid Souls) (both 1928), in which he sought to translate the essentially verbal comedy of two plays byLabicheinto works of silent cinema.While at Albatros, Clair met the designerLazare Meersonand the cameramanGeorges Périnalwho were to remain important collaborators with him for the next decade. By the end of the silent era, Clair was celebrated as one of the great names in cinema, alongsideGriffith,Chaplin,PabstandEisenstein. As the author of all of his own scripts, who also paid close attention to every aspect of the making of a film, including the editing, Clair was one of the first French film-makers to establish for himself the full role of anauteur. Clair was initially sceptical about the introduction of sound to films, and called it \"an unnatural creation\".He then realised the creative possibilities that it offered, particularly, in his view, if the soundtrack was not used realistically; words and pictures need not, and indeed should not, be tied together in a clumsy duplication of information; dialogue did not always need to be heard.Between 1930 and 1933, Clair explored these ideas in his first four sound films, starting withSous les toits de Paris(Under the Roofs of Paris); this was followed byLe Million(1931),À nous la liberté(1931), andQuatorze juillet(Bastille Day) (1933). All of these films portrayed an affectionate and idealized view of working class life, and they did much to create a popular romantic image of Paris which was seen around the world.These films were made at theEpinay Studiosfor Films Sonores Tobis, a French subsidiary of the German-ownedTobiscompany. When Chaplin madeModern Timesin 1936, it was noted that some parts of it bore a marked similarity to scenes inÀ nous la liberté, and the production company Tobis launched a lawsuit for plagiarism againstUnited Artists, the producers of Chaplin's film. Clair was embarrassed by this since he acknowledged his own debt to the spirit of Chaplin, and he refused to be associated with the action. After the immense success of these early sound films, Clair met with a major setback when his next film,Le Dernier Milliardaire(The Last Billionaire/The Last Millionaire) (1934), was a critical and commercial flop. While he was visiting London for the film's British première, he metAlexander Kordawho offered him a contract to work in England.  He accepted, and began a lengthy period of exile from film-making in France. Clair's contract with Korda'sLondon Filmswas for two years and it envisaged three films. Because of his limited English, he collaborated with the American dramatistRobert E. Sherwoodas script-writer for his first film,The Ghost Goes West(1935), a comic fantasy about transatlantic culture clash. Clair and Sherwood became close friends. In January 1936, Clair visited America for two weeks, checking out for future employment possibilities but still planning to remain with Korda. Korda however rejected Clair's next script and they parted company.Clair's remaining time in England led to only one more completed film,Break the News(1938), a musical comedy withJack BuchananandMaurice Chevalier. Returning to France, Clair attempted to make another film there in 1939,Air pur, which was to be a celebration of youth and childhood, but the outbreak of war interrupted filming and it was abandoned.In May 1940,Jean Giraudoux, then Minister of Information, suggested to Clair that the film profession should concentrate its resources in the south of country in Nice and Marseille – and if necessary establish a French production centre in the United States. It was with this last plan in mind that Clair and his family, along withJulien Duvivier, departed for America, but by the time he reached New York the project had already fallen through and he went straight on to Hollywood where several studios were interested in employing him.He made his first American film for Universal Studios,The Flame of New Orleans(1941), but it was such a commercial failure that for a time Clair's career as a director was in the balance.After more than a year's delay, his next film wasI Married a Witch(1942), followed byIt Happened Tomorrow(1944), both of which did respectably well, and thenAnd Then There Were None(1945), which turned out to be an exceptional commercial success despite being perhaps the least personal of his Hollywood ventures.Each of Clair's American films was made for a different studio. In 1941 Clair was stripped of his French citizenship by the Vichy government, though this was later reversed.It was also in 1941 that he learned of the death of his brother Henri Chomette in France from polio.In 1943, he was planning to go to Algeria to organise the Service Cinématographique de l'Armée, but funding for the project was withdrawn just as he was on the point of departure.In July 1945 he went back to France for a short visit, and then returned finally in July 1946, having signed a contract with RKO for his next film to be made in France. Clair's American exile had allowed him to develop his characteristic vein of ironical fantasy with several commercially successful films, but there was some feeling that it had been at the expense of personal control and that his output there had not matched the quality of his earlier work in France.Clair himself recognised that being employed by the highly organized American studios had allowed him to work in ideal circumstances: \"In spite of the restrictions of the American system, it is possible, if one wishes, to take responsibility. In my four Hollywood films I managed to do what I wanted.\" Clair's first film on his return to France was the romantic comedyLe silence est d'or(Silence is Golden) (1947), which was set in 1906 and nostalgically evoked the world of early French film-making; its plot also created variations on Molière'sL'École des femmes.Clair considered it one of his best post-war films.Literary inspirations also underpinned other films:FaustforLa Beauté du diable(Beauty and the Devil) (1950); andDon JuanforLes Grandes Manœuvres(1955). In these two films and the interveningLes Belles de nuit(Beauties of the Night) (1952), the leading actor wasGérard Philipewho became a friend and a favourite performer for Clair.Porte des Lilas(1957) was a sombre film, set once again in a popular district of Paris with its picturesque inhabitants, for which the singerGeorges Brassenswas persuaded to give his only film performance. During the 1950s, as a new generation of French critics and film-makers emerged who were impatient of the prevailing modes of film production, Clair found himself increasingly criticised as a representative of thecinéma de qualité, a \"cinema of old men\"dominated by nostalgia for their younger days.His status as a figure of the 'establishment' was further confirmed by his election to theAcadémie Françaisein 1960. Although he continued to make a few more films in comic vein such asTout l'or du monde(All the Gold in the World) (1961), they were not well received and he made his last film,Les Fêtes galantes(The Lace Wars), in 1965. Clair began his career as a journalist, and writing remained an important interest for him to which he increasingly turned in his later years. In 1926 he published a novel,Adams(translated into English asStar Turn), about a Hollywood star for whom the distinction between the real and unreal becomes blurred.He occasionally returned to writing fiction (La Princesse de ChineandJeux du hasard), but many of his publications dealt with the cinema, including reflections on his own films. Apart from many journal articles, his main publications were: Clair also ventured into other media.  In 1951 he directed his first radio production,Une larme du diable.  In 1959 he directed a stage production ofMusset'sOn ne badine pas avec l'amour, in whichGérard Philipegave one of his last performances before his death. In 1972 he staged Gluck'sOrphéefor the Paris Opéra. At the end of 1924, while Clair was working onCiné-sketchfor the theatre with France Picabia, he first met a young actress, Bronja Perlmutter, who subsequently appeared in his filmLe Voyage imaginaire(1926) premiered at the newly openedStudio des Ursulines. They married in 1926, and their son, Jean-François, was born in 1927. René Clair died at home on 15 March 1981, and he was buried privately at Saint-Germain-l'Auxerrois. Clair's reputation as a film-maker underwent a considerable reevaluation during the course of his own lifetime: in the 1930s he was widely seen as one of France's greatest directors, alongsideRenoirandCarné, but thereafter his work's artifice and detachment from the realities of life fell increasingly from favour.The avant-gardism of his first films, and especiallyEntr'acte, had given him a temporary notoriety, and a grounding in surrealism continued to underlie much of his comedy work. It was however the imaginative manner in which he overcame his initial scepticism about the arrival of sound which established his originality, and his first four sound films brought him international fame. Clair's years of working in the UK and USA made him still more widely known but did not show any marked development in his style or thematic concerns. It was in the post-war films that he made on his return to France that some critics have observed a new maturity and emotional depth, accompanied by a prevailing sense of melancholy but still framed by the elegance and wit that characterised his earlier work. However, in the 1950s the critics who heralded the arrival of theFrench New Wave, especially those associated withCahiers du Cinéma, found Clair's work old-fashioned and academic.François Truffautwrote harshly of him after seeingThe Flame of New Orleans: \"We don't follow our elders in paying the same tribute to Renoir and Clair. There is no film by Clair which matches the invention and wit of Renoir'sTire au flanc.... Clair makes films for old ladies who go to the cinema twice a year.\" André Bazin, the founding editor ofCahiers, made a more measured assessment: \"René Clair has remained in a way a film-maker of the silent cinema. Whatever the quality and importance of his recent films, expression through the image always predominates over that of the word and one almost never misses the essence if one can only vaguely hear the dialogue.\"It was also in a special number ofCahiers du Cinémareviewing the current state of the French cinema in 1957 that Clair received one of his most positive appreciations: \"A complete film author who, since the silent era, has brought to the French cinema intelligence, refinement, humour, an intellectual quality that is slightly dry but smiling and in good taste.... Whatever may follow in his rich career, he has created a cinematic world that is his own, full of rigour and not lacking in imagination, thanks to which he remains one of our greatest film-makers.\" Such appreciations have subsequently been rare, and the self-contained artificiality of Clair's films, his insistence on the meticulous preparation of an often literary script, and his preference for filming in studio sets rather than on location increasingly set him apart from modern trends in film-making.The paradox of Clair's reputation has been further heightened by those commentators who have seen François Truffaut as the French cinema's true successor to Clair, notwithstanding the occasions of their mutual disdain.  René Clair held the national honours of Grand officier de laLégion d'honneur,Commandeur des Arts et des Lettres, andGrand-croix de l'ordre national du Mérite.  He received the Grand Prix du cinéma français in 1953. In 1951, he won thePrix Italiain Naples for a French radio production ofUne larme du diablebyThéophile Gautier. In 1956 he was awarded an honorary doctorate by theUniversity of Cambridge. In 1960 he was elected to theAcadémie Française; he was not the first film-maker so honoured (he was preceded byMarcel Pagnol(1946),Jean Cocteau(1955), andMarcel Achard(1959)) but he was the first to be elected primarily as a film-maker. In 1994 the Académie established thePrix René-Clairas an annual prize awarded to a distinguished film-maker. In 1967 he received an honorary doctorate from theRoyal College of Artin London. As well as many awards made for individual films, Clair received an honorary prize at the11th Moscow International Film Festivalin 1979 for his contribution to cinema. Place René Clair inBoulogne-Billancourt, on the outskirts of Paris and near the site of the formerfilm studiosin that district, is named after him.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Ren%C3%A9_Clair", "https://en.wikipedia.org/wiki/Ren%C3%A9_Clair", "https://en.wikipedia.org/wiki/Ren%C3%A9_Clair", "https://en.wikipedia.org/wiki/Erik_Satie", "https://en.wikipedia.org/wiki/Paris", "https://en.wikipedia.org/wiki/Neuilly-sur-Seine", "https://en.wikipedia.org/wiki/Hauts-de-Seine", "https://en.wikipedia.org/wiki/%C3%8Ele-de-France_(region)"]},
{"id": "ecd5a4b65469", "url": "https://en.wikipedia.org/wiki/Nature_Neuroscience", "title": "Nature Neuroscience", "headings": ["Contents", "References", "External links"], "content": "Nature Neuroscienceis a monthlyscientific journalpublished byNature Publishing Group. Its focus is original research papers relating specifically toneuroscienceand was established in May 1998. The chief editor is Shari Wiseman.According to theJournal Citation Reports,Nature Neurosciencehad a 2024impact factorof 19.5.  This article about aneurosciencejournalis astub. You can help Wikipedia byexpanding it. See tips for writing articles about academic journals. Further suggestions might be found on the article'stalk page.", "combined_text": "Nature Neuroscience Contents References External links Nature Neuroscienceis a monthlyscientific journalpublished byNature Publishing Group. Its focus is original research papers relating specifically toneuroscienceand was established in May 1998. The chief editor is Shari Wiseman.According to theJournal Citation Reports,Nature Neurosciencehad a 2024impact factorof 19.5.  This article about aneurosciencejournalis astub. You can help Wikipedia byexpanding it. See tips for writing articles about academic journals. Further suggestions might be found on the article'stalk page.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Nature_Neuroscience", "https://en.wikipedia.org/wiki/Nature_Neuroscience", "https://en.wikipedia.org/wiki/Nature_Neuroscience", "https://en.wikipedia.org/wiki/Outline_of_academic_disciplines", "https://en.wikipedia.org/wiki/Neuroscience", "https://en.wikipedia.org/wiki/Editor-in-chief", "https://en.wikipedia.org/wiki/Shari_Wiseman", "https://en.wikipedia.org/wiki/Academic_publishing"]},
{"id": "ca24067cd398", "url": "https://en.wikipedia.org/wiki/Deep_reinforcement_learning", "title": "Deep reinforcement learning", "headings": ["Contents", "Overview", "Deep learning", "Reinforcement learning", "Deep reinforcement learning", "History", "Algorithms", "Research", "Exploration", "Off-policy reinforcement learning", "Inverse reinforcement learning", "Goal-conditioned reinforcement learning", "Multi-agent reinforcement learning", "Generalization", "References"], "content": "Deep reinforcement learning(deep RL) is a subfield ofmachine learningthat combinesreinforcement learning(RL) anddeep learning. RL considers the problem of a computational agent learning to make decisions by trial and error. Deep RL incorporates deep learning into the solution, allowing agents to make decisions from unstructured input data without manual engineering of thestate space. Deep RL algorithms are able to take in very large inputs (e.g. every pixel rendered to the screen in a video game) and decide what actions to perform to optimize an objective (e.g. maximizing the game score). Deep reinforcement learning has been used for a diverse set of applications including but not limited torobotics,video games,natural language processing,computer vision,education, transportation, finance andhealthcare. Deep learningis a form ofmachine learningthat transforms a set of inputs into a set of outputs via anartificial neural network. Deep learning methods, often usingsupervised learningwith labeled datasets, have been shown to solve tasks that involve handling complex, high-dimensional raw input data (such as images) with less manualfeature engineeringthan prior methods, enabling significant progress in several fields includingcomputer visionandnatural language processing. In the past decade, deep RL has achieved remarkable results on a range of problems, from single and multiplayer games such asGo,Atari Games, andDota 2to robotics. Reinforcement learningis a process in which an agent learns to make decisions through trial and error. This problem is often modeled mathematically as aMarkov decision process(MDP), where an agent at every timestep is in a states{\\displaystyle s}, takes actiona{\\displaystyle a}, receives a scalar reward and transitions to the next states′{\\displaystyle s'}according to environment dynamicsp(s′|s,a){\\displaystyle p(s'|s,a)}. The agent attempts to learn a policyπ(a|s){\\displaystyle \\pi (a|s)}, or map from observations to actions, in order to maximize its returns (expected sum of rewards). In reinforcement learning (as opposed tooptimal control) the algorithm only has access to the dynamicsp(s′|s,a){\\displaystyle p(s'|s,a)}through sampling. In many practical decision-making problems, the statess{\\displaystyle s}of the MDP are high-dimensional (e.g., images from a camera or the raw sensor stream from a robot) and cannot be solved by traditional RL algorithms. Deep reinforcement learning algorithms incorporate deep learning to solve such MDPs, often representing the policyπ(a|s){\\displaystyle \\pi (a|s)}or other learned functions as a neural network and developing specialized algorithms that perform well in this setting. Along with rising interest in neural networks beginning in the mid 1980s, interest grew in deep reinforcement learning,  where a neural network is used in reinforcement learning to represent policies or value functions. Because in such a system, the entire decision making process from sensors to motors in a robot or agent involves a singleneural network, it is also sometimes called end-to-end reinforcement learning.One of the first successful applications of reinforcement learning with neural networks wasTD-Gammon, a computer program developed in 1992 for playingbackgammon.Four inputs were used for the number of pieces of a given color at a given location on the board, totaling 198 input signals. With zero knowledge built in, the network learned to play the game at an intermediate level by self-play andTD(λ{\\displaystyle \\lambda }). Seminal textbooks bySuttonandBartoon reinforcement learning,BertsekasandTsitiklison neuro-dynamic programming,and othersadvanced knowledge and interest in the field. Katsunari Shibata's group showed that various functions emerge in this framework,including image recognition, color constancy, sensor motion (active recognition), hand-eye coordination and hand reaching movement, explanation of brain activities, knowledge transfer, memory,selective attention, prediction, and exploration. Starting around 2012, the so-calleddeep learning revolutionled to an increased interest in using deep neural networks as function approximators across a variety of domains. This led to a renewed interest in researchers using deep neural networks to learn the policy, value, and/or Q functions present in existing reinforcement learning algorithms. Beginning around 2013,DeepMindshowed impressive learning results using deep RL to playAtarivideo games.The computer player a neural network trained using a deep RL algorithm, a deep version ofQ-learningthey termed deep Q-networks (DQN), with the game score as the reward. They used a deepconvolutional neural networkto process 4 frames RGB pixels (84x84) as inputs. All 49 games were learned using the same network architecture and with minimal prior knowledge, outperforming competing methods on almost all the games and performing at a level comparable or superior to a professional human game tester. Deep reinforcement learning reached another milestone in 2015 whenAlphaGo,a computer program trained with deep RL to playGo, became the first computer Go program to beat a human professional Go player without handicap on a full-sized 19×19 board.\nIn a subsequent project in 2017,AlphaZeroimproved performance on Go while also demonstrating they could use the same algorithm to learn to playchessandshogiat a level competitive or superior to existing computer programs for those games, and again improved in 2019 withMuZero.Separately, another milestone was achieved by researchers fromCarnegie Mellon Universityin 2019 developingPluribus, a computer program to playpokerthat was the first to beat professionals at multiplayer games of no-limitTexas hold 'em.OpenAI Five, a program for playing five-on-fiveDota 2beat the previous world champions in a demonstration match in 2019. Deep reinforcement learning has also been applied to many domains beyond games. In robotics, it has been used to let robots perform simple household tasksand solve a Rubik's cube with a robot hand.Deep RL has also found sustainability applications, used to reduce energy consumption at data centers.Deep RL forautonomous drivingis an active area of research in academia and industry.Loonexplored deep RL for autonomously navigating their high-altitude balloons. Various techniques exist to train policies to solve tasks with deep reinforcement learning algorithms, each having their own benefits. At the highest level, there is a distinction between model-based and model-free reinforcement learning, which refers to whether the algorithm attempts to learn a forward model of the environment dynamics. Inmodel-baseddeep reinforcement learning algorithms, a forward model of the environment dynamics is estimated, usually bysupervised learningusing a neural network. Then, actions are obtained by usingmodel predictive controlusing the learned model. Since the true environment dynamics will usually diverge from the learned dynamics, the agent re-plans often when carrying out actions in the environment. The actions selected may be optimized usingMonte Carlo methodssuch as thecross-entropy method, or a combination of model-learning with model-free methods. Inmodel-freedeep reinforcement learning algorithms, a policyπ(a|s){\\displaystyle \\pi (a|s)}is learned without explicitly modeling the forward dynamics. A policy can be optimized to maximize returns by directly estimating the policy gradientbut suffers from high variance, making it impractical for use with function approximation in deep RL. Subsequent algorithms have been developed for more stable learning and widely applied.Another class of model-free deep reinforcement learning algorithms rely ondynamic programming, inspired bytemporal difference learningandQ-learning. In discrete action spaces, these algorithms usually learn a neural network Q-functionQ(s,a){\\displaystyle Q(s,a)}that estimates the future returns taking actiona{\\displaystyle a}from states{\\displaystyle s}.In continuous spaces, these algorithms often learn both a value estimate and a policy. Deep reinforcement learning is an active area of research, with several lines of inquiry. An RL agent must balance the exploration/exploitation tradeoff: the problem of deciding whether to pursue actions that are already known to yield high rewards or explore other actions in order to discover higher rewards. RL agents usually collect data with some type of stochastic policy, such as aBoltzmann distributionin discrete action spaces or aGaussian distributionin continuous action spaces, inducing basic exploration behavior. The idea behind novelty-based, or curiosity-driven, exploration is giving the agent a motive to explore unknown outcomes in order to find the best solutions. This is done by \"modify[ing] the loss function (or even the network architecture) by adding terms to incentivize exploration\".An agent may also be aided in exploration by utilizing demonstrations of successful trajectories, or reward-shaping, giving an agent intermediate rewards that are customized to fit the task it is attempting to complete. An important distinction in RL is the difference between on-policy algorithms that require evaluating or improving the policy that collects data, and off-policy algorithms that can learn a policy from data generated by an arbitrary policy. Generally, value-function based methods such asQ-learningare better suited for off-policy learning and have better sample-efficiency - the amount of data required to learn a task is reduced because data is re-used for learning. At the extreme, offline (or \"batch\") RL considers learning a policy from a fixed dataset without additional interaction with the environment. Inverse RL refers to inferring the reward function of an agent given the agent's behavior. Inverse reinforcement learning can be used for learning from demonstrations (orapprenticeship learning) by inferring the demonstrator's reward and then optimizing a policy to maximize returns with RL. Deep learning approaches have been used for various forms of imitation learning and inverse RL. Another active area of research is in learning goal-conditioned policies, also called contextual or universal policiesπ(a|s,g){\\displaystyle \\pi (a|s,g)}that take in an additional goalg{\\displaystyle g}as input to communicate a desired aim to the agent.Hindsight experience replay is a method for goal-conditioned RL that involves storing and learning from previous failed attempts to complete a task.While a failed attempt may not have reached the intended goal, it can serve as a lesson for how achieve the unintended result through hindsight relabeling. Many applications of reinforcement learning do not involve just a single agent, but rather a collection of agents that learn together and co-adapt. These agents may be competitive, as in many games, or cooperative as in many real-world multi-agent systems.Multi-agent reinforcement learningstudies the problems introduced in this setting. The promise of using deep learning tools in reinforcement learning is generalization: the ability to operate correctly on previously unseen inputs. For instance, neural networks trained for image recognition can recognize that a picture contains a bird even it has never seen that particular image or even that particular bird. Since deep RL allows raw data (e.g. pixels) as input, there is a reduced need to predefine the environment, allowing the model to be generalized to multiple applications. With this layer of abstraction, deep reinforcement learning algorithms can be designed in a way that allows them to be general and the same model can be used for different tasks.One method of increasing the ability of policies trained with deep RL policies to generalize is to incorporaterepresentation learning.", "combined_text": "Deep reinforcement learning Contents Overview Deep learning Reinforcement learning Deep reinforcement learning History Algorithms Research Exploration Off-policy reinforcement learning Inverse reinforcement learning Goal-conditioned reinforcement learning Multi-agent reinforcement learning Generalization References Deep reinforcement learning(deep RL) is a subfield ofmachine learningthat combinesreinforcement learning(RL) anddeep learning. RL considers the problem of a computational agent learning to make decisions by trial and error. Deep RL incorporates deep learning into the solution, allowing agents to make decisions from unstructured input data without manual engineering of thestate space. Deep RL algorithms are able to take in very large inputs (e.g. every pixel rendered to the screen in a video game) and decide what actions to perform to optimize an objective (e.g. maximizing the game score). Deep reinforcement learning has been used for a diverse set of applications including but not limited torobotics,video games,natural language processing,computer vision,education, transportation, finance andhealthcare. Deep learningis a form ofmachine learningthat transforms a set of inputs into a set of outputs via anartificial neural network. Deep learning methods, often usingsupervised learningwith labeled datasets, have been shown to solve tasks that involve handling complex, high-dimensional raw input data (such as images) with less manualfeature engineeringthan prior methods, enabling significant progress in several fields includingcomputer visionandnatural language processing. In the past decade, deep RL has achieved remarkable results on a range of problems, from single and multiplayer games such asGo,Atari Games, andDota 2to robotics. Reinforcement learningis a process in which an agent learns to make decisions through trial and error. This problem is often modeled mathematically as aMarkov decision process(MDP), where an agent at every timestep is in a states{\\displaystyle s}, takes actiona{\\displaystyle a}, receives a scalar reward and transitions to the next states′{\\displaystyle s'}according to environment dynamicsp(s′|s,a){\\displaystyle p(s'|s,a)}. The agent attempts to learn a policyπ(a|s){\\displaystyle \\pi (a|s)}, or map from observations to actions, in order to maximize its returns (expected sum of rewards). In reinforcement learning (as opposed tooptimal control) the algorithm only has access to the dynamicsp(s′|s,a){\\displaystyle p(s'|s,a)}through sampling. In many practical decision-making problems, the statess{\\displaystyle s}of the MDP are high-dimensional (e.g., images from a camera or the raw sensor stream from a robot) and cannot be solved by traditional RL algorithms. Deep reinforcement learning algorithms incorporate deep learning to solve such MDPs, often representing the policyπ(a|s){\\displaystyle \\pi (a|s)}or other learned functions as a neural network and developing specialized algorithms that perform well in this setting. Along with rising interest in neural networks beginning in the mid 1980s, interest grew in deep reinforcement learning,  where a neural network is used in reinforcement learning to represent policies or value functions. Because in such a system, the entire decision making process from sensors to motors in a robot or agent involves a singleneural network, it is also sometimes called end-to-end reinforcement learning.One of the first successful applications of reinforcement learning with neural networks wasTD-Gammon, a computer program developed in 1992 for playingbackgammon.Four inputs were used for the number of pieces of a given color at a given location on the board, totaling 198 input signals. With zero knowledge built in, the network learned to play the game at an intermediate level by self-play andTD(λ{\\displaystyle \\lambda }). Seminal textbooks bySuttonandBartoon reinforcement learning,BertsekasandTsitiklison neuro-dynamic programming,and othersadvanced knowledge and interest in the field. Katsunari Shibata's group showed that various functions emerge in this framework,including image recognition, color constancy, sensor motion (active recognition), hand-eye coordination and hand reaching movement, explanation of brain activities, knowledge transfer, memory,selective attention, prediction, and exploration. Starting around 2012, the so-calleddeep learning revolutionled to an increased interest in using deep neural networks as function approximators across a variety of domains. This led to a renewed interest in researchers using deep neural networks to learn the policy, value, and/or Q functions present in existing reinforcement learning algorithms. Beginning around 2013,DeepMindshowed impressive learning results using deep RL to playAtarivideo games.The computer player a neural network trained using a deep RL algorithm, a deep version ofQ-learningthey termed deep Q-networks (DQN), with the game score as the reward. They used a deepconvolutional neural networkto process 4 frames RGB pixels (84x84) as inputs. All 49 games were learned using the same network architecture and with minimal prior knowledge, outperforming competing methods on almost all the games and performing at a level comparable or superior to a professional human game tester. Deep reinforcement learning reached another milestone in 2015 whenAlphaGo,a computer program trained with deep RL to playGo, became the first computer Go program to beat a human professional Go player without handicap on a full-sized 19×19 board.\nIn a subsequent project in 2017,AlphaZeroimproved performance on Go while also demonstrating they could use the same algorithm to learn to playchessandshogiat a level competitive or superior to existing computer programs for those games, and again improved in 2019 withMuZero.Separately, another milestone was achieved by researchers fromCarnegie Mellon Universityin 2019 developingPluribus, a computer program to playpokerthat was the first to beat professionals at multiplayer games of no-limitTexas hold 'em.OpenAI Five, a program for playing five-on-fiveDota 2beat the previous world champions in a demonstration match in 2019. Deep reinforcement learning has also been applied to many domains beyond games. In robotics, it has been used to let robots perform simple household tasksand solve a Rubik's cube with a robot hand.Deep RL has also found sustainability applications, used to reduce energy consumption at data centers.Deep RL forautonomous drivingis an active area of research in academia and industry.Loonexplored deep RL for autonomously navigating their high-altitude balloons. Various techniques exist to train policies to solve tasks with deep reinforcement learning algorithms, each having their own benefits. At the highest level, there is a distinction between model-based and model-free reinforcement learning, which refers to whether the algorithm attempts to learn a forward model of the environment dynamics. Inmodel-baseddeep reinforcement learning algorithms, a forward model of the environment dynamics is estimated, usually bysupervised learningusing a neural network. Then, actions are obtained by usingmodel predictive controlusing the learned model. Since the true environment dynamics will usually diverge from the learned dynamics, the agent re-plans often when carrying out actions in the environment. The actions selected may be optimized usingMonte Carlo methodssuch as thecross-entropy method, or a combination of model-learning with model-free methods. Inmodel-freedeep reinforcement learning algorithms, a policyπ(a|s){\\displaystyle \\pi (a|s)}is learned without explicitly modeling the forward dynamics. A policy can be optimized to maximize returns by directly estimating the policy gradientbut suffers from high variance, making it impractical for use with function approximation in deep RL. Subsequent algorithms have been developed for more stable learning and widely applied.Another class of model-free deep reinforcement learning algorithms rely ondynamic programming, inspired bytemporal difference learningandQ-learning. In discrete action spaces, these algorithms usually learn a neural network Q-functionQ(s,a){\\displaystyle Q(s,a)}that estimates the future returns taking actiona{\\displaystyle a}from states{\\displaystyle s}.In continuous spaces, these algorithms often learn both a value estimate and a policy. Deep reinforcement learning is an active area of research, with several lines of inquiry. An RL agent must balance the exploration/exploitation tradeoff: the problem of deciding whether to pursue actions that are already known to yield high rewards or explore other actions in order to discover higher rewards. RL agents usually collect data with some type of stochastic policy, such as aBoltzmann distributionin discrete action spaces or aGaussian distributionin continuous action spaces, inducing basic exploration behavior. The idea behind novelty-based, or curiosity-driven, exploration is giving the agent a motive to explore unknown outcomes in order to find the best solutions. This is done by \"modify[ing] the loss function (or even the network architecture) by adding terms to incentivize exploration\".An agent may also be aided in exploration by utilizing demonstrations of successful trajectories, or reward-shaping, giving an agent intermediate rewards that are customized to fit the task it is attempting to complete. An important distinction in RL is the difference between on-policy algorithms that require evaluating or improving the policy that collects data, and off-policy algorithms that can learn a policy from data generated by an arbitrary policy. Generally, value-function based methods such asQ-learningare better suited for off-policy learning and have better sample-efficiency - the amount of data required to learn a task is reduced because data is re-used for learning. At the extreme, offline (or \"batch\") RL considers learning a policy from a fixed dataset without additional interaction with the environment. Inverse RL refers to inferring the reward function of an agent given the agent's behavior. Inverse reinforcement learning can be used for learning from demonstrations (orapprenticeship learning) by inferring the demonstrator's reward and then optimizing a policy to maximize returns with RL. Deep learning approaches have been used for various forms of imitation learning and inverse RL. Another active area of research is in learning goal-conditioned policies, also called contextual or universal policiesπ(a|s,g){\\displaystyle \\pi (a|s,g)}that take in an additional goalg{\\displaystyle g}as input to communicate a desired aim to the agent.Hindsight experience replay is a method for goal-conditioned RL that involves storing and learning from previous failed attempts to complete a task.While a failed attempt may not have reached the intended goal, it can serve as a lesson for how achieve the unintended result through hindsight relabeling. Many applications of reinforcement learning do not involve just a single agent, but rather a collection of agents that learn together and co-adapt. These agents may be competitive, as in many games, or cooperative as in many real-world multi-agent systems.Multi-agent reinforcement learningstudies the problems introduced in this setting. The promise of using deep learning tools in reinforcement learning is generalization: the ability to operate correctly on previously unseen inputs. For instance, neural networks trained for image recognition can recognize that a picture contains a bird even it has never seen that particular image or even that particular bird. Since deep RL allows raw data (e.g. pixels) as input, there is a reduced need to predefine the environment, allowing the model to be generalized to multiple applications. With this layer of abstraction, deep reinforcement learning algorithms can be designed in a way that allows them to be general and the same model can be used for different tasks.One method of increasing the ability of policies trained with deep RL policies to generalize is to incorporaterepresentation learning.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Deep_reinforcement_learning", "https://en.wikipedia.org/wiki/Deep_reinforcement_learning", "https://en.wikipedia.org/wiki/Deep_reinforcement_learning", "https://en.wikipedia.org/wiki/Machine_learning", "https://en.wikipedia.org/wiki/Data_mining", "https://en.wikipedia.org/wiki/Supervised_learning", "https://en.wikipedia.org/wiki/Unsupervised_learning", "https://en.wikipedia.org/wiki/Semi-supervised_learning"]},
{"id": "7e57fa11c74e", "url": "https://en.wikipedia.org/wiki/Temporoparietal_junction", "title": "Temporoparietal junction", "headings": ["Contents", "Anatomy and function", "Right temporoparietal junction", "Left temporoparietal junction", "Disorders", "Amnesia", "Alzheimer's disease", "Autism spectrum disorder", "Schizophrenia", "Anxiety disorders", "Future of possible treatments", "Current research", "Theory of mind", "Out-of-body experiences", "Temporal order judgement", "Morality", "See also", "References"], "content": "Thetemporoparietal junction(TPJ) is an area of thebrainwhere thetemporalandparietallobes meet, at the posterior end of thelateral sulcus(Sylvian fissure). The TPJ incorporates information from thethalamusand thelimbic systemas well as from the visual, auditory, andsomatosensory systems. The TPJ also integrates information from both the external environment as well as from within the body. The TPJ is responsible for collecting all of this information and then processing it. This area is also known to play a crucial role in self–other distinctions processes andtheory of mind(ToM).Furthermore, damage to the TPJ has been implicated in having adverse effects on an individual's ability to make moral decisions and has been known to produceout-of-body experiences(OBEs).Electromagnetic stimulationof the TPJ can also cause these effects.Apart from these diverse roles that the TPJ plays, it is also known for its involvement in a variety of widespread disorders including anxiety disorders,amnesia,Alzheimer's disease,autism spectrum disorder, andschizophrenia. The brain contains four main lobes:temporal lobe,parietal lobe,frontal lobe, and theoccipital lobe. The temporoparietal junction lies in the region between the temporal and parietal lobes, near thelateral sulcus(Sylvian fissure). Specifically, it is composed of theinferior parietal lobuleand the caudal parts of thesuperior temporal sulcus.There are two halves to the temporoparietal junction, with each component in their respective hemispheres of the brain. Each half of the TPJ pertains to various aspects of cognitive function. Often, however, the separate halves of the TPJ will work in coordination. The TPJ is mainly involved in information processing and perception. The right temporoparietal junction (rTPJ) is involved in the processing of information in terms of the ability of an individual to orientattentionto new stimuli.Evidence from neuroimaging studies as well as lesion studies revealed that the rTPJ plays a pivotal role in analyzing signals from self-produced actions as well as with signals from the external environment.For example, an individual with lesions in their rTPJ would more than likely exhibit a sense ofhemi-neglect, wherein they would no longer be able to pay attention to anything they observe on the left. So, if someone were to have a lesion in their rTPJ, then over time the awareness of the left limbs may fade withouttreatment. Visual signals provide the sensory information necessary for the brain to process spatial recognition of the world. When vision is limited, knowledge of existence begins to fade away since as far as the brain is concerned the object does not exist. Furthermore, the rTPJ plays a role in the way individuals observe and process information, thus impacting social interaction.Empathyandsympathyrequire an individual to simultaneously distinguish between different possible perspectives on the same situation. Imaging studies show that this ability depends upon the coordinated interaction of the rTPJ to identify and process the social cues presented to it.This rapid process allows for an individual to quickly react to situations. The left temporoparietal junction (lTPJ) contains bothWernicke's areaand theangular gyrus, both prominent anatomical structures of the brain that are involved in language cognition, processing, and comprehension of both written and spoken language.Steven Pinkerdiscusses this brain region, theorising that it underlies an amodal 'language of thought' orMentalese.  The lTPJ, in this account, takes in observations from external environments, such as conversations, makes connections in the brain regarding memories or incidents and then converts those thoughts and connections to written and spoken language. Pinker's full account of this is explained inThe Language Instinct: How the Mind Creates Language. The lTPJ also plays an important role in reasoning of other's beliefs, intentions, and desires.Activation of the lTPJ was observed in patients processing mental states such as beliefs when anfMRIwas used on patients as they were asked to make inferences regarding the mental states of others such as lying. This study was further supplemented by a study which identified that lesions to the left TPJ can impair cognitive processes specifically involved in the inference of someone else's belief, intention, or desire. Individuals with lesions in the lTPJ were no longer able to correctly identify when someone was lying or insinuating a false sense of belief or desire.The lTPJ is also involved in the processing of associating and remembering the names of individuals and objects. Thedopaminergic-serotonergicsystem mediates our ability to distinguish and understand others' beliefs as well as predict their behavior in light of that understanding. In certain disorders involving the dopaminergic-serotonergic system, this mentalizing process is disrupted and part or all of the process is impaired; this includesamnesia,Alzheimer's disease, andschizophrenia. Amnesiais a deficit in memory caused by brain damage, disease, or physiological trauma. Amnesia is best understood viaHenry Molaison, or patient H.M., who suffered from severeepilepsyand eventually had atemporal lobectomy. After surgery, his epilepsy improved but then he had anterograde amnesia, whereinlong-term memoryformation is inhibited.Short-term memoryremained normal except that he could never remember anything that had happened after his surgery for very long. Based on general known roles of the TPJ, it is known that the TPJ is involved in the memory processing system of the body. Studies have also revealed that certain types of epileptic amnesia could be attributed to TPJ.fMRIstudies indicated that there was lower activation of the rTPJ in patients with epileptic amnesia.Furthermore, it was noticed the autobiographical memories were affected in these patients. As such, the rTPJ along with the rightcerebellumwere identified as core components of autobiographical memory. In terms of treatment, most forms of amnesia fix themselves without actually undergoing treatment.However, options such as cognitive therapy or occupational therapy have proved to help. Therapy will focus on various methods to improve a patient's memory and with repetition over time, a patient's memory as a whole will improve and eventually become close to normal. Alzheimer's diseaseis the most common form ofdementiaand is also the sixth leading cause of death in the United States.This disease has no known cure and is a disease that worsens as it progresses and eventually leads to death. Reduced metabolism in the TPJ, along with thesuperior frontal sulcus, correlates with Alzheimer's patients' inability to perceive themselves as others do (with a third-person point of view); the discrepancy between a patient's understanding of their own cognitive impairment and the actual extent of their cognitive impairment increases as metabolism in the TPJ decreases.Additionally, the TPJ contains thepraxicon, a dictionary of representations of different human actions, which is necessary to distinguishing between actions of the self and other people. Becausedementia(including Alzheimer's) patients withanosognosiaare unable to distinguish between the normal actions of other people and their own diminished abilities, it is expected that damage to the TPJ is arresting this cognitive function. There may be a connection between the temporoparietal junction and how individuals with autism spectrum disorder's recognition of socially awkward situations may differ from those not autistic. Research reported in 2015 from an experiment in which participants, high-functioning adults with autism spectrum disorder (ASD) and non autistic controls, were asked to watch socially awkward situations (a complete episode of the sitcomThe Office) under an fMRI, which measured their brain activity. Several brain regions implicated in social perceptual and cognitive processes were of interest: \"the dorsal, middle and ventral parts of medialprefrontal cortex(DMPFC, MMPFC and VMPFC), right and left temporo-parietal junctions (RTPJ and LTPJ), rightsuperior temporal sulcus(RSTS) and temporal pole, and posterior medial cortices [posterior cingulate,precuneus(PC)].\"In general, participants' activity in several of those brain regions tracked the episode's socially awkward moments to similar extents—the results were evidence of alackof group differenceexcept in one region: their activity near the RTPJ, spanning into the posterior end of the RSTS, showed notable quantitative differences between the ASD and NT groups (with ASD group showing lower activity). Research reported in 2016 on ASC-related structural or physiological differences found using neuroimaging noted that results are often inconsistent across the literature, which could be caused by a variety of variance sources. (Re-)analysis using a technique they developed to reduce one common external source of variance showed group differences in TPJ. However, althoughstatistically significant, results did not display the discriminative power sufficient to classify diagnostic groups, instead yielding accuracy results close to random. They concluded that ASD is a highly heterogeneous syndrome/diagnostic category whose differences from NT controls are difficult to characterize globally using neuroimaging. The decreased ability forschizophreniapatients to function in social situations has been related to a deficit within thetheory of mindprocess.There have been relatively few studies that have examined the role of theory of mind in schizophrenia patients; the findings of these studies as they relate to the activation of the TPJ are varied. Some studies have found decreased activation of the TPJ in schizophrenia patients who were asked to make inferences about other peoples' social intentions based on cartoons; other studies, however, performed similar assessments of schizophrenia patients and found that the TPJ actually became hyperactive, compared to control individuals without schizophrenia, in the TPJ.This indicates that there is abnormal activation of the TPJ in these patients while performing tasks that involving understanding social intention of others, but the directionality of this abnormal activity is not clear, or possibly not universal throughout schizophrenia patients. It was found that the changes in activation in the TPJ were lateralized; they found that there was reduced activity in only the right TPJ and proposed that based on previous research about the different roles of the right and left TPJ the findings indicated that there was a more general deficit in the overall mentalizing process for these patients, but their ability to understand other individuals' basic social intentions through observing interaction is not impaired. A study found that there was a connection between the auditory hallucinations in schizophrenia and the TPJ; the TPJ has been determined as a critical node in the auditory-verbal hallucination system.This study found that there was a significant decrease in the connectivity between the left TPJ and the right hemispheric homotope of the Broca's area, which is related to the production of language that is also characteristic of AVH events.This aspect of impairment seen in schizophrenia patients may also be related to the involvement of the TPJ with producing out of body experiences. A recent study showed reduced activity in the TPJ of adolescents compared to adults during an extinction task, suggesting a role for the TPJ in anxiety disorders. Vasopressinis a neuropeptide that is involved in regulating social behaviors, including social memory and recognition.One study examined the connection between vasopressin and cortical areas that are involved in processing social interactions including the TPJ. This study looked specifically at the brain regions that were active in men who were given vasopressin and tested based on familiarity related tasks.They found that the introduction of vasopressin caused a localized specific change in social recognition-related activity in the left TPJ/Brodmann area 39; the presence of vasopressin diminishes the heightened activity in the left TPJ that is present upon exposure to an unfamiliar social stimulus indicating that the presence of vasopressin leads individuals to associate an unfamiliar face with a familiar category more readily. While recognizing that this is the first study that has looked into this connection, the authors propose that it has potential to lead into further research about regulating the TPJ with vasopressin or a similar compound, which could allowpharmacologiststo target this area of the brain and help with certain disorders including autism, social anxiety disorder.Perhaps such an approach could also be used to treat certain symptoms of schizophrenia or other disorders with know social cognitive impairments. Current research involving the TPJ is extensive, ranging from issues of physiology to issues of mental state. A wide range of cognitive processes rely on the TPJ and as such gaining information about it is crucial. Research is conducted by studying the role TPJ plays both with and without lesions when stimulated, and with task-based fMRI.Research concerns various issues such astheory of mind,out-of-body experiences, temporal order judgments,morality, etc. This is a growing field due to the prevalence of ailments that involve TPJ as well as because of the importance of perception in everyday life. Theory of mindrequires the collaboration of functionally related regions of the brain to form the distinction between self and other mental states and to create a comprehensive understanding of those mental states so that we may recognize, understand, and predict behavior.In general the theory of mind process is mediated by the dopaminergic-serotonergic system, which involves the TPJ as well as other associative regions necessary for mentalizing.Recent studies suggest that both the left TPJ, working in conjunction with the frontal cortex, and the right TPJ are involved in the representation of mental states; furthermore they suggest that the TPJ is particularly active in making the distinction between the mental states of self and others. A study inNature Neurosciencefrom 2004 describes how the TPJ is involved in processing socially relevant cues including gaze direction and goal-directed action and also explains that results from the study show that lesions to this area of the brain result in an impaired ability to detect another persons belief.Moreover, studies have reported an increase in activity in the TPJ when patients are absorbing information through reading or images regarding other peoples' beliefs but not while observing information about physical control stimuli.Some studies, however, have shown that the TPJ, along with the cingulate cortex, is more specifically involved with attributing beliefs, but the process of mentalizing more generally is associated more with the medial prefrontal cortex.Another study inCurrent Biologyfrom 2012 identifies the importance of the TPJ in both low-level, such as simple discrimination, and high-level, such as the ability to empathize, sociocognitive operations.In July 2011, a review fromNeuropsychologiapresented a model of the mentalizing network that established that mental states are first detected in the TPJ.The TPJ is composed of two discrete anatomical regions, theinferior parietal lobule(IPL) and the caudal parts of thesuperior temporal sulcus(pSTS), and both are active in the process of distinction between mental states of different individuals; thus, it is probable that this detection is the outcome of the combination and coordination of these two parts.Additionally, the right TPJ is involved in the ventral attention stream and contributes to the ability to focus attention on a particular stimuli or objective.  It has also been observed that the interaction and communication between the dorsal and ventral streams involves the TPJ. The TPJ is also a crucial structure for self-processing.Several neuro-imaging studies have shown an activation of the TPJ during different aspects of self-processing such as visuo-spatial perspective,self-other distinction, mental own body imagery, and vestibular and multi sensory integration.Damage in the TPJ has been linked to out-of-body experiences (OBEs), the feeling that one's self is located outside one's physical body. An OBE is defined by the presence of three characteristics: disembodiment, the impression of seeing the world from a distant and elevated visuo-spatial perspective, and the impression of seeing one's own body from this elevated perspective.OBEs mostly occur to people with epilepsy or migraines, but approximately 10% of the healthy population also experience OBEs once or twice in a lifetime.They usually occur spontaneously and are of short duration, making OBEs hard to study. Here is an example of a patient describing what he or she experienced during an OBE: \"I was in bed and about to fall asleep when I had the distinct impression that 'I' was at the ceiling level looking down at my body in the bed. I was very startled and frightened; immediately [afterward] I felt that, I was consciously back in the bed again.\" It is suggested that OBEs are caused by multi-sensory disintegration in the TPJ disrupting different aspects of self-processing such as illusory reduplication, illusory self-location, and illusory perspective.The brain integrates different sensory inputs to create a representation of one's body and its location in its surrounding. Some inhibition of discrepant inputs is required to have coherency, but in some cases, those discrepant inputs are so strong and come from more than one sensory source that it leads to two different representations of one's own body.This multi-sensory disintegration at the TPJ leads to OBEs. An electromagnetic stimulation to the right TPJ of a patient with epilepsy induced an OBE.The author also states that these experiences are closely related to schizophrenia andphantom limb. Temporal order is the arrangement of events in time. By judging this, one can understand how we process things.Temporal order judgmentsrequire an individual to determine the relative timing between two spatially separate events. One study revealed that subjects had to determine the order of appearance of two objects as well as which object fit a certain property better. What was learned from this study was that when identifying the order or appearance,fMRIstudies showed that there was bilateral activation of the TPJ. Meanwhile, when it comes to object characterization based on a property, it was noticed that there was only activation of the lTPJ. As such, it is evident that TPJ is involved in the \"when\" pathway of the brain. Part of judging how virtuous an action was, whether someone is an ethical person or what one ought to do,moralityusually (among other considerations) differentiates by actor intention. This applies to self-assessment as well as of others. Connections made at the TPJ help an individual understand their emotions: the TPJ allows association of emotions with events or individuals, aiding in any related decision-making process. Studies also show a relation between theory of mind and moral judgment, which further implicates the rTPJ in morality cognition. However, errors in this emotional processing can arise when patients have lesions in the TPJ or when the brain is electrically stimulated.Transcranial magnetic stimulation(TMS) to the rTPJ seems to affect the ability of an individual, when they make moral decisions, to consider actors' mental states.Patients' general ability to judge moral scenarios was not obviously impaired, but it did seem to specifically affect how much they integrated a protagonist'sbeliefinto the judgement—only affecting the judgement of a scenario in which the protagonist explicitly intends and so deliberately acts to cause significant harm but completely fails solely due to an incorrect belief (about tool/weapon used). TMS can be used to disrupt neural activity in the rTPJ justbeforea patient was to make a moral decision orduringthat decision-making process—constituting two different testing environments, but experimental results were unaffected.", "combined_text": "Temporoparietal junction Contents Anatomy and function Right temporoparietal junction Left temporoparietal junction Disorders Amnesia Alzheimer's disease Autism spectrum disorder Schizophrenia Anxiety disorders Future of possible treatments Current research Theory of mind Out-of-body experiences Temporal order judgement Morality See also References Thetemporoparietal junction(TPJ) is an area of thebrainwhere thetemporalandparietallobes meet, at the posterior end of thelateral sulcus(Sylvian fissure). The TPJ incorporates information from thethalamusand thelimbic systemas well as from the visual, auditory, andsomatosensory systems. The TPJ also integrates information from both the external environment as well as from within the body. The TPJ is responsible for collecting all of this information and then processing it. This area is also known to play a crucial role in self–other distinctions processes andtheory of mind(ToM).Furthermore, damage to the TPJ has been implicated in having adverse effects on an individual's ability to make moral decisions and has been known to produceout-of-body experiences(OBEs).Electromagnetic stimulationof the TPJ can also cause these effects.Apart from these diverse roles that the TPJ plays, it is also known for its involvement in a variety of widespread disorders including anxiety disorders,amnesia,Alzheimer's disease,autism spectrum disorder, andschizophrenia. The brain contains four main lobes:temporal lobe,parietal lobe,frontal lobe, and theoccipital lobe. The temporoparietal junction lies in the region between the temporal and parietal lobes, near thelateral sulcus(Sylvian fissure). Specifically, it is composed of theinferior parietal lobuleand the caudal parts of thesuperior temporal sulcus.There are two halves to the temporoparietal junction, with each component in their respective hemispheres of the brain. Each half of the TPJ pertains to various aspects of cognitive function. Often, however, the separate halves of the TPJ will work in coordination. The TPJ is mainly involved in information processing and perception. The right temporoparietal junction (rTPJ) is involved in the processing of information in terms of the ability of an individual to orientattentionto new stimuli.Evidence from neuroimaging studies as well as lesion studies revealed that the rTPJ plays a pivotal role in analyzing signals from self-produced actions as well as with signals from the external environment.For example, an individual with lesions in their rTPJ would more than likely exhibit a sense ofhemi-neglect, wherein they would no longer be able to pay attention to anything they observe on the left. So, if someone were to have a lesion in their rTPJ, then over time the awareness of the left limbs may fade withouttreatment. Visual signals provide the sensory information necessary for the brain to process spatial recognition of the world. When vision is limited, knowledge of existence begins to fade away since as far as the brain is concerned the object does not exist. Furthermore, the rTPJ plays a role in the way individuals observe and process information, thus impacting social interaction.Empathyandsympathyrequire an individual to simultaneously distinguish between different possible perspectives on the same situation. Imaging studies show that this ability depends upon the coordinated interaction of the rTPJ to identify and process the social cues presented to it.This rapid process allows for an individual to quickly react to situations. The left temporoparietal junction (lTPJ) contains bothWernicke's areaand theangular gyrus, both prominent anatomical structures of the brain that are involved in language cognition, processing, and comprehension of both written and spoken language.Steven Pinkerdiscusses this brain region, theorising that it underlies an amodal 'language of thought' orMentalese.  The lTPJ, in this account, takes in observations from external environments, such as conversations, makes connections in the brain regarding memories or incidents and then converts those thoughts and connections to written and spoken language. Pinker's full account of this is explained inThe Language Instinct: How the Mind Creates Language. The lTPJ also plays an important role in reasoning of other's beliefs, intentions, and desires.Activation of the lTPJ was observed in patients processing mental states such as beliefs when anfMRIwas used on patients as they were asked to make inferences regarding the mental states of others such as lying. This study was further supplemented by a study which identified that lesions to the left TPJ can impair cognitive processes specifically involved in the inference of someone else's belief, intention, or desire. Individuals with lesions in the lTPJ were no longer able to correctly identify when someone was lying or insinuating a false sense of belief or desire.The lTPJ is also involved in the processing of associating and remembering the names of individuals and objects. Thedopaminergic-serotonergicsystem mediates our ability to distinguish and understand others' beliefs as well as predict their behavior in light of that understanding. In certain disorders involving the dopaminergic-serotonergic system, this mentalizing process is disrupted and part or all of the process is impaired; this includesamnesia,Alzheimer's disease, andschizophrenia. Amnesiais a deficit in memory caused by brain damage, disease, or physiological trauma. Amnesia is best understood viaHenry Molaison, or patient H.M., who suffered from severeepilepsyand eventually had atemporal lobectomy. After surgery, his epilepsy improved but then he had anterograde amnesia, whereinlong-term memoryformation is inhibited.Short-term memoryremained normal except that he could never remember anything that had happened after his surgery for very long. Based on general known roles of the TPJ, it is known that the TPJ is involved in the memory processing system of the body. Studies have also revealed that certain types of epileptic amnesia could be attributed to TPJ.fMRIstudies indicated that there was lower activation of the rTPJ in patients with epileptic amnesia.Furthermore, it was noticed the autobiographical memories were affected in these patients. As such, the rTPJ along with the rightcerebellumwere identified as core components of autobiographical memory. In terms of treatment, most forms of amnesia fix themselves without actually undergoing treatment.However, options such as cognitive therapy or occupational therapy have proved to help. Therapy will focus on various methods to improve a patient's memory and with repetition over time, a patient's memory as a whole will improve and eventually become close to normal. Alzheimer's diseaseis the most common form ofdementiaand is also the sixth leading cause of death in the United States.This disease has no known cure and is a disease that worsens as it progresses and eventually leads to death. Reduced metabolism in the TPJ, along with thesuperior frontal sulcus, correlates with Alzheimer's patients' inability to perceive themselves as others do (with a third-person point of view); the discrepancy between a patient's understanding of their own cognitive impairment and the actual extent of their cognitive impairment increases as metabolism in the TPJ decreases.Additionally, the TPJ contains thepraxicon, a dictionary of representations of different human actions, which is necessary to distinguishing between actions of the self and other people. Becausedementia(including Alzheimer's) patients withanosognosiaare unable to distinguish between the normal actions of other people and their own diminished abilities, it is expected that damage to the TPJ is arresting this cognitive function. There may be a connection between the temporoparietal junction and how individuals with autism spectrum disorder's recognition of socially awkward situations may differ from those not autistic. Research reported in 2015 from an experiment in which participants, high-functioning adults with autism spectrum disorder (ASD) and non autistic controls, were asked to watch socially awkward situations (a complete episode of the sitcomThe Office) under an fMRI, which measured their brain activity. Several brain regions implicated in social perceptual and cognitive processes were of interest: \"the dorsal, middle and ventral parts of medialprefrontal cortex(DMPFC, MMPFC and VMPFC), right and left temporo-parietal junctions (RTPJ and LTPJ), rightsuperior temporal sulcus(RSTS) and temporal pole, and posterior medial cortices [posterior cingulate,precuneus(PC)].\"In general, participants' activity in several of those brain regions tracked the episode's socially awkward moments to similar extents—the results were evidence of alackof group differenceexcept in one region: their activity near the RTPJ, spanning into the posterior end of the RSTS, showed notable quantitative differences between the ASD and NT groups (with ASD group showing lower activity). Research reported in 2016 on ASC-related structural or physiological differences found using neuroimaging noted that results are often inconsistent across the literature, which could be caused by a variety of variance sources. (Re-)analysis using a technique they developed to reduce one common external source of variance showed group differences in TPJ. However, althoughstatistically significant, results did not display the discriminative power sufficient to classify diagnostic groups, instead yielding accuracy results close to random. They concluded that ASD is a highly heterogeneous syndrome/diagnostic category whose differences from NT controls are difficult to characterize globally using neuroimaging. The decreased ability forschizophreniapatients to function in social situations has been related to a deficit within thetheory of mindprocess.There have been relatively few studies that have examined the role of theory of mind in schizophrenia patients; the findings of these studies as they relate to the activation of the TPJ are varied. Some studies have found decreased activation of the TPJ in schizophrenia patients who were asked to make inferences about other peoples' social intentions based on cartoons; other studies, however, performed similar assessments of schizophrenia patients and found that the TPJ actually became hyperactive, compared to control individuals without schizophrenia, in the TPJ.This indicates that there is abnormal activation of the TPJ in these patients while performing tasks that involving understanding social intention of others, but the directionality of this abnormal activity is not clear, or possibly not universal throughout schizophrenia patients. It was found that the changes in activation in the TPJ were lateralized; they found that there was reduced activity in only the right TPJ and proposed that based on previous research about the different roles of the right and left TPJ the findings indicated that there was a more general deficit in the overall mentalizing process for these patients, but their ability to understand other individuals' basic social intentions through observing interaction is not impaired. A study found that there was a connection between the auditory hallucinations in schizophrenia and the TPJ; the TPJ has been determined as a critical node in the auditory-verbal hallucination system.This study found that there was a significant decrease in the connectivity between the left TPJ and the right hemispheric homotope of the Broca's area, which is related to the production of language that is also characteristic of AVH events.This aspect of impairment seen in schizophrenia patients may also be related to the involvement of the TPJ with producing out of body experiences. A recent study showed reduced activity in the TPJ of adolescents compared to adults during an extinction task, suggesting a role for the TPJ in anxiety disorders. Vasopressinis a neuropeptide that is involved in regulating social behaviors, including social memory and recognition.One study examined the connection between vasopressin and cortical areas that are involved in processing social interactions including the TPJ. This study looked specifically at the brain regions that were active in men who were given vasopressin and tested based on familiarity related tasks.They found that the introduction of vasopressin caused a localized specific change in social recognition-related activity in the left TPJ/Brodmann area 39; the presence of vasopressin diminishes the heightened activity in the left TPJ that is present upon exposure to an unfamiliar social stimulus indicating that the presence of vasopressin leads individuals to associate an unfamiliar face with a familiar category more readily. While recognizing that this is the first study that has looked into this connection, the authors propose that it has potential to lead into further research about regulating the TPJ with vasopressin or a similar compound, which could allowpharmacologiststo target this area of the brain and help with certain disorders including autism, social anxiety disorder.Perhaps such an approach could also be used to treat certain symptoms of schizophrenia or other disorders with know social cognitive impairments. Current research involving the TPJ is extensive, ranging from issues of physiology to issues of mental state. A wide range of cognitive processes rely on the TPJ and as such gaining information about it is crucial. Research is conducted by studying the role TPJ plays both with and without lesions when stimulated, and with task-based fMRI.Research concerns various issues such astheory of mind,out-of-body experiences, temporal order judgments,morality, etc. This is a growing field due to the prevalence of ailments that involve TPJ as well as because of the importance of perception in everyday life. Theory of mindrequires the collaboration of functionally related regions of the brain to form the distinction between self and other mental states and to create a comprehensive understanding of those mental states so that we may recognize, understand, and predict behavior.In general the theory of mind process is mediated by the dopaminergic-serotonergic system, which involves the TPJ as well as other associative regions necessary for mentalizing.Recent studies suggest that both the left TPJ, working in conjunction with the frontal cortex, and the right TPJ are involved in the representation of mental states; furthermore they suggest that the TPJ is particularly active in making the distinction between the mental states of self and others. A study inNature Neurosciencefrom 2004 describes how the TPJ is involved in processing socially relevant cues including gaze direction and goal-directed action and also explains that results from the study show that lesions to this area of the brain result in an impaired ability to detect another persons belief.Moreover, studies have reported an increase in activity in the TPJ when patients are absorbing information through reading or images regarding other peoples' beliefs but not while observing information about physical control stimuli.Some studies, however, have shown that the TPJ, along with the cingulate cortex, is more specifically involved with attributing beliefs, but the process of mentalizing more generally is associated more with the medial prefrontal cortex.Another study inCurrent Biologyfrom 2012 identifies the importance of the TPJ in both low-level, such as simple discrimination, and high-level, such as the ability to empathize, sociocognitive operations.In July 2011, a review fromNeuropsychologiapresented a model of the mentalizing network that established that mental states are first detected in the TPJ.The TPJ is composed of two discrete anatomical regions, theinferior parietal lobule(IPL) and the caudal parts of thesuperior temporal sulcus(pSTS), and both are active in the process of distinction between mental states of different individuals; thus, it is probable that this detection is the outcome of the combination and coordination of these two parts.Additionally, the right TPJ is involved in the ventral attention stream and contributes to the ability to focus attention on a particular stimuli or objective.  It has also been observed that the interaction and communication between the dorsal and ventral streams involves the TPJ. The TPJ is also a crucial structure for self-processing.Several neuro-imaging studies have shown an activation of the TPJ during different aspects of self-processing such as visuo-spatial perspective,self-other distinction, mental own body imagery, and vestibular and multi sensory integration.Damage in the TPJ has been linked to out-of-body experiences (OBEs), the feeling that one's self is located outside one's physical body. An OBE is defined by the presence of three characteristics: disembodiment, the impression of seeing the world from a distant and elevated visuo-spatial perspective, and the impression of seeing one's own body from this elevated perspective.OBEs mostly occur to people with epilepsy or migraines, but approximately 10% of the healthy population also experience OBEs once or twice in a lifetime.They usually occur spontaneously and are of short duration, making OBEs hard to study. Here is an example of a patient describing what he or she experienced during an OBE: \"I was in bed and about to fall asleep when I had the distinct impression that 'I' was at the ceiling level looking down at my body in the bed. I was very startled and frightened; immediately [afterward] I felt that, I was consciously back in the bed again.\" It is suggested that OBEs are caused by multi-sensory disintegration in the TPJ disrupting different aspects of self-processing such as illusory reduplication, illusory self-location, and illusory perspective.The brain integrates different sensory inputs to create a representation of one's body and its location in its surrounding. Some inhibition of discrepant inputs is required to have coherency, but in some cases, those discrepant inputs are so strong and come from more than one sensory source that it leads to two different representations of one's own body.This multi-sensory disintegration at the TPJ leads to OBEs. An electromagnetic stimulation to the right TPJ of a patient with epilepsy induced an OBE.The author also states that these experiences are closely related to schizophrenia andphantom limb. Temporal order is the arrangement of events in time. By judging this, one can understand how we process things.Temporal order judgmentsrequire an individual to determine the relative timing between two spatially separate events. One study revealed that subjects had to determine the order of appearance of two objects as well as which object fit a certain property better. What was learned from this study was that when identifying the order or appearance,fMRIstudies showed that there was bilateral activation of the TPJ. Meanwhile, when it comes to object characterization based on a property, it was noticed that there was only activation of the lTPJ. As such, it is evident that TPJ is involved in the \"when\" pathway of the brain. Part of judging how virtuous an action was, whether someone is an ethical person or what one ought to do,moralityusually (among other considerations) differentiates by actor intention. This applies to self-assessment as well as of others. Connections made at the TPJ help an individual understand their emotions: the TPJ allows association of emotions with events or individuals, aiding in any related decision-making process. Studies also show a relation between theory of mind and moral judgment, which further implicates the rTPJ in morality cognition. However, errors in this emotional processing can arise when patients have lesions in the TPJ or when the brain is electrically stimulated.Transcranial magnetic stimulation(TMS) to the rTPJ seems to affect the ability of an individual, when they make moral decisions, to consider actors' mental states.Patients' general ability to judge moral scenarios was not obviously impaired, but it did seem to specifically affect how much they integrated a protagonist'sbeliefinto the judgement—only affecting the judgement of a scenario in which the protagonist explicitly intends and so deliberately acts to cause significant harm but completely fails solely due to an incorrect belief (about tool/weapon used). TMS can be used to disrupt neural activity in the rTPJ justbeforea patient was to make a moral decision orduringthat decision-making process—constituting two different testing environments, but experimental results were unaffected.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Temporoparietal_junction", "https://en.wikipedia.org/wiki/Temporoparietal_junction", "https://en.wikipedia.org/wiki/Temporoparietal_junction", "https://en.wikipedia.org/wiki/NeuroLex", "https://en.wikipedia.org/wiki/Anatomical_terms_of_neuroanatomy", "https://en.wikipedia.org/wiki/Brain", "https://en.wikipedia.org/wiki/Temporal_lobe", "https://en.wikipedia.org/wiki/Parietal_lobe"]},
{"id": "5c8e363af246", "url": "https://en.wikipedia.org/wiki/United_Nations_Human_Rights_Committee", "title": "United Nations Human Rights Committee", "headings": ["Contents", "Members", "Recent elections", "Meetings and activities", "State reporting under the ICCPR", "Procedure, and recent procedural changes", "NGO participation", "Limitations of the reporting system", "Individual complaints to the Committee", "Procedure", "Decisions", "General Comments", "Inter-State Communications", "References", "External links"], "content": "TheUnited Nations Human Rights Committeeis atreaty bodycomposed of 18 experts, established by a 1966 human rights treaty, theInternational Covenant on Civil and Political Rights(ICCPR). The Committee meets for three four-week sessions per year to consider the periodic reports submitted by the 173 States parties to the ICCPR on their compliance with the treaty, and any individual petitions concerning the 116 States parties to the ICCPR'sFirst Optional Protocol.The Committee is one of ten UNhuman rightstreaty bodies, each responsible for overseeing the implementation of a particular treaty. The UN Human Rights Committee should not be confused with the more high-profileUN Human Rights Council(HRC), or the predecessor of the HRC, theUN Commission on Human Rights. Whereas the Human Rights Council (since June 2006) and the Commission on Human Rights (before that date) areUN political bodies:composed of states, established by a UN General Assembly resolution and the UN Charter, and discussing the entire range of human rights concerns; the Human Rights Committee is aUN expert body:composed of persons, established by the ICCPR, and discussing matters pertaining only to that treaty. The Human Rights Committee is often referred to as CCPR (Committee on Civil and Political Rights) in order to avoid that confusion. The ICCPR states the basic rules for the membership of the Human Rights Committee. Article 28 of the ICCPR states that the Committee is composed of 18 members from states parties to the ICCPR, \"who shall be persons of high moral character and recognized competence in the field of human rights\", with consideration \"to the usefulness of the participation of some persons having legal experience.\" Also according to Article 28, the members serve in their individual capacity, rather than as representatives of their countries.  As stated in Articles 29 and 30 of the ICCPR, they are elected by a meeting of the states parties to the ICCPR held at UN Headquarters.  Based on Article 32, they serve four-year terms, with one-half of their number elected every second year. The current membership is as follows: On June 17, 2022, the States parties to the ICCPR met in New York and elected nine members of the Committee, to replace those whose terms would expire at the end of 2022. There were seventeen candidates for the nine positions, including one whose nomination was late. Those elected were Yvonne Donders (The Netherlands),Hélène Tigroudja* (France), Bacre Waly Ndiaye (Senegal), Tijana Šurlan (Serbia), Koji Teraya (Japan), Farid Ahmadov (Azerbaijan),Laurence R. Helfer(United States),Rodrigo A. Carazo(Costa Rica), and Hernán Quezada Cabrera* (Chile). Asterisks denote sitting members who were re-elected. On September 17, 2020 (postponed from June 15, 2020), the States parties to the ICCPR met and elected nine members of the Committee, to replace those whose terms would expire at the end of 2020. There were fourteen candidates for the nine positions, not counting two who were withdrawn shortly before the election but counting one whose nomination was late (and who was elected). Those elected were Carlos Gómez Martínez (Spain), Changrok Soh (Republic of Korea), Imeru Tamerat Yigezu (Ethiopia), Mahjoub El Haiba (Morocco), José Manuel Santos Pais* (Portugal), Tania María Abdo Rocholl* (Paraguay), Wafaa Ashraf Moharram Bassim (Egypt), Kobauyah Tchamdja Kpatcha (Togo), and Marcia V.J. Kran* (Canada). Asterisks denote sitting members who were re-elected. David H. Moorre (United States) won an additional, contested \"by-election\" held on the same date, to elect a member to complete the term ending December 31, 2020, of Ilze Brands Kehris (Latvia), who had resigned effective December 31, 2019, upon her appointment as UN Assistant Secretary-General for Human Rights. On August 28, 2018, Andreas B. Zimmermann (Germany) won an uncontested by-election to complete the term ending December 31, 2020, of Anja Seibert-Fohr (Germany), who had resigned effective March 1, 2018. On June 14, 2018, the States parties to the ICCPR met and elected nine members of the Committee, to replace those whose terms would expire at the end of 2018. There were sixteen candidates for the nine positions, not counting two who were withdrawn shortly before the election and one whose nomination was late. Those elected were Yadh Ben Achour* (Tunisia), Christopher Bulkan (Guyana), Photini Pazartzis* (Greece), Hélène Tigroudja (France), Hernán Quezada Cabrera (Chile), Gentian Zyberi (Albania), Vasilka Sancin (Slovenia), Shuichi Furuya (Japan), and Duncan Muhumuza Laki* (Uganda). Asterisks denote sitting members who were re-elected.Pierre-Richard Prosperof the United States was not elected, in reportedly \"a first-ever defeat of a US candidate for the UN Human Rights Committee.\" The Committee meets three times a year for four-week sessions (spring session at UN headquarters in New York, summer and fall sessions at the UN Office in Geneva).  The categories of its work, outlined below, include state reporting, individual complaints, general comments, and inter-state communications. All states parties to the ICCPR have an obligation \"to submit reports on the measures they have adopted which give effect to the rights recognized [in the ICCPR] and on the progress made in the enjoyment of those rights.\"  The Human Rights Committee is responsible for \"study[ing]\" and responding to those reports submitted by states.  States parties must submit an initial report within one year of the ICCPR's entry into force, and subsequent periodic reports as requested by the Committee.  This reporting system is mandated by Article 40 of the ICCPR. The frequency of the periodic reports was formerly about every five years, but starting in 2020 is every eight years.The UN has published guidance for states on reporting to the Committee and other human rightstreaty bodies.The principal purpose of the report is to promote state compliance with the treaty principles and it should be an \"honest appraisal of their conformity to the treaty obligations\". Following the submission of a state's report, representatives of the state appear before the Committee in Geneva or New York to discuss the report, in an in-person constructive dialogue which is generally webcast live on UN Web TV.  Following this dialogue, the Committee drafts and adopts its concluding observations, a document including positive aspects, subjects of concern, and suggestions and recommendations.  Subsequently, under its follow-up procedure, the Committee assesses whether certain recommendations have been fulfilled within one year. In July 2010, the Committee proposed a new optional reporting procedure called the \"List of Issues Prior to Reporting\" (LOIPR) or \"Simplified Reporting Procedure\".Under this system, instead of the state submitting a full report on its implementation of each article of the ICCPR, the Committee sends the state a list of issues to address, and the state's report must only answer the questions raised in that list of issues.The Committee subsequently adopted  the simplified reporting procedure on a pilot basis, although it remains an optional alternative to the \"regular\" procedure, i.e., submission of a full report.  At its 124th session in 2018, the Committee decided to adopt the simplified reporting procedure on a permanent basis, and to encourage all states to switch to simplified reporting. It also decided to strive to limit the number of questions in each list of issues to 25.In 2019, the Committee decided to make the simplified reporting procedure the default, changing a state's selection of it from an opt-in to an opt-out model. In July 2019 the Committee decided to move, beginning in 2020, to an eight-year \"Predictable Review Cycle\" (PRC), under which it would schedule one review for each state party (including those states that failed to report).  This cycle involves a five-year review process, and a three-year interval before the next review process begins.  All states parties were divided into 8 groups of 21-22 states each, with the reporting process to start for each group on a different year. NGOs and other civil society organizations play a crucial role in the reporting process.  Any NGO, regardless of accreditation, may submit its own reports (sometimes called \"shadow reports\") to the Committee, comment on state reports, and attend all Committee sessions as observers.  Furthermore, the Committee often holds a closed meeting with interested NGOs as part of its review of a state's report. One set of weaknesses is inherent to a system of self-reporting.  Though in theory, reports should be an honest appraisal, constructive criticism of perceived failures to adhere to Covenant principles is unlikely.The Centre for Civil and Political Rights, an NGO, states that \"State reports often . . . fail to describe the implementation of the Covenant in practice\" and \"frequently lack an honest evaluation of the difficulties the State faces in implementing the rights guaranteed under the Covenant.\" Late reporting and non-reporting by states is another problem.  The Committee's annual report through March 2019 stated that fifteen states' \"initial reports are overdue, of which 7 are overdue by between 5 and 10 years and 8 are overdue by 10 years or more.\"  The report's Annex IV listed them; Equatorial Guinea's initial report was 30 years overdue.  That Annex also listed thirteen states whose periodic reports were ten years or more overdue, with Afghanistan's overdue by 22 years, and Nigeria's overdue by 19; ten states whose periodic reports were five to ten years overdue; and 28 states whose periodic reports were overdue by less than five years.CSW, a UK-based NGO, asserts that \"there remains a relatively low level of engagement and implementation of recommendations\" on the part of States, and that the level of States compliance withtreaty bodyrecommendations is only 19%. Other widely noted problems include the backlog of the Committee and the heavy burden on states, particularly small states. States that are party to theFirst Optional Protocol to the ICCPR(currently 116 countries) have agreed to allow persons within their jurisdiction to submit complaints (\"individual communications\") to the Committee claiming that their rights under the ICCPR have been violated.The ICCPR is one of eight UN human rights treaties with individual complaints procedures available; two other treaties state such procedures that are not yet in force. Before considering the merits (substance) of an individual communication, the Committee must be satisfied that it is admissible.The Committee may review many factors in determining admissibility and may conclude that, for an individual communication to be admissible, it must: Individual communications that contain the necessary prima facie elements are referred to the Committee’s Special Rapporteur on New Communications and Interim Measures, who decides whether the case should be registered. At that point, the case is transmitted to the State party, which is requested to submit its observations within six months, under Article 4 of the First Optional Protocol.Once the State replies to the complaint, the complainant is offered an opportunity to comment, within a set time frame.  If the Committee concludes that a violation of the ICCPR has taken place, in its follow-up procedure the Committee invites the State to provide information within 180 days on its steps to implement the Committee's recommendations. The State’s response is transmitted to the complainant for comments.  If the State party fails to take appropriate action, the Committee keeps the case under consideration.  Thus, the Committee maintains a dialogue with the State party and the case remains open until satisfactory measures are taken. The Committee considers individual communications in closed session, but its decisions (\"Views\") and any follow-up are public.Given the large number of complaints, several years may elapse between submission of a complaint and the Committee’s decision on it. Information on the process and how to use it, including examples and guidelines for submitting complaints, is available from someNGOsand theUnited Nations. All Committee decisions on individual complaints are available in online compilations published by UN,NGO,and academicsources. The Committee has received thousands of complaints since its inception.A few of its decisions that are notable are listed below, in reverse chronological order.  Among more recent decisions that attracted press and academic attention, in two October 2018 decisions the Committee concluded that France's ban on theniqab, the full-face Islamic veil, violated human rights guaranteed under the ICCPR, in particular the rights to manifest one's religion or beliefs and to protection against discrimination. To date the Committee has issued 36 \"General Comments\", each of which provides detailed guidance on particular parts of the ICCPR. The Committee has circulated a draft of its next, forthcoming General Comment, General Comment 37 on ICCPR Article 21, the right of peaceful assembly, seeking public comments on the draft by an extended deadline of February 21, 2020.The draft has been criticized for its reliance on decisions of regional, as opposed to global, human rights bodies. The Committee's most recent General Comment (of October 30, 2018) was General Comment 36 on ICCPR Article 6, on the right to life (replacing General Comments 6 and 14, of 1982 and 1984, respectively).Of its seventy paragraphs, twenty addresscapital punishment, in a section headed \"The death penalty.\"  One commentator has stated that its description of how the right to life applies during situations of armed conflict and its statement of the relationship between international human rights law and international humanitarian law are noteworthy. In December 2014 the Committee issued General Comment 35 on ICCPR Article 9, \"liberty and security of person\". In July 2011, the UN Human Rights Committee adopted a 52-paragraph statement, General Comment 34 on ICCPR Article 19, concerning freedoms of opinion and expression. Paragraph 48 states: The Covenant provides for inter-State complaints \"that enables one State Party to charge another with a violation to the treaty.\"\"[N]o interstate complaint mechanism has yet been submitted\" (up to 2009).This is still a matter of jurisdiction and it is optional to the committee of whether or not they will accept such complaint or not.", "combined_text": "United Nations Human Rights Committee Contents Members Recent elections Meetings and activities State reporting under the ICCPR Procedure, and recent procedural changes NGO participation Limitations of the reporting system Individual complaints to the Committee Procedure Decisions General Comments Inter-State Communications References External links TheUnited Nations Human Rights Committeeis atreaty bodycomposed of 18 experts, established by a 1966 human rights treaty, theInternational Covenant on Civil and Political Rights(ICCPR). The Committee meets for three four-week sessions per year to consider the periodic reports submitted by the 173 States parties to the ICCPR on their compliance with the treaty, and any individual petitions concerning the 116 States parties to the ICCPR'sFirst Optional Protocol.The Committee is one of ten UNhuman rightstreaty bodies, each responsible for overseeing the implementation of a particular treaty. The UN Human Rights Committee should not be confused with the more high-profileUN Human Rights Council(HRC), or the predecessor of the HRC, theUN Commission on Human Rights. Whereas the Human Rights Council (since June 2006) and the Commission on Human Rights (before that date) areUN political bodies:composed of states, established by a UN General Assembly resolution and the UN Charter, and discussing the entire range of human rights concerns; the Human Rights Committee is aUN expert body:composed of persons, established by the ICCPR, and discussing matters pertaining only to that treaty. The Human Rights Committee is often referred to as CCPR (Committee on Civil and Political Rights) in order to avoid that confusion. The ICCPR states the basic rules for the membership of the Human Rights Committee. Article 28 of the ICCPR states that the Committee is composed of 18 members from states parties to the ICCPR, \"who shall be persons of high moral character and recognized competence in the field of human rights\", with consideration \"to the usefulness of the participation of some persons having legal experience.\" Also according to Article 28, the members serve in their individual capacity, rather than as representatives of their countries.  As stated in Articles 29 and 30 of the ICCPR, they are elected by a meeting of the states parties to the ICCPR held at UN Headquarters.  Based on Article 32, they serve four-year terms, with one-half of their number elected every second year. The current membership is as follows: On June 17, 2022, the States parties to the ICCPR met in New York and elected nine members of the Committee, to replace those whose terms would expire at the end of 2022. There were seventeen candidates for the nine positions, including one whose nomination was late. Those elected were Yvonne Donders (The Netherlands),Hélène Tigroudja* (France), Bacre Waly Ndiaye (Senegal), Tijana Šurlan (Serbia), Koji Teraya (Japan), Farid Ahmadov (Azerbaijan),Laurence R. Helfer(United States),Rodrigo A. Carazo(Costa Rica), and Hernán Quezada Cabrera* (Chile). Asterisks denote sitting members who were re-elected. On September 17, 2020 (postponed from June 15, 2020), the States parties to the ICCPR met and elected nine members of the Committee, to replace those whose terms would expire at the end of 2020. There were fourteen candidates for the nine positions, not counting two who were withdrawn shortly before the election but counting one whose nomination was late (and who was elected). Those elected were Carlos Gómez Martínez (Spain), Changrok Soh (Republic of Korea), Imeru Tamerat Yigezu (Ethiopia), Mahjoub El Haiba (Morocco), José Manuel Santos Pais* (Portugal), Tania María Abdo Rocholl* (Paraguay), Wafaa Ashraf Moharram Bassim (Egypt), Kobauyah Tchamdja Kpatcha (Togo), and Marcia V.J. Kran* (Canada). Asterisks denote sitting members who were re-elected. David H. Moorre (United States) won an additional, contested \"by-election\" held on the same date, to elect a member to complete the term ending December 31, 2020, of Ilze Brands Kehris (Latvia), who had resigned effective December 31, 2019, upon her appointment as UN Assistant Secretary-General for Human Rights. On August 28, 2018, Andreas B. Zimmermann (Germany) won an uncontested by-election to complete the term ending December 31, 2020, of Anja Seibert-Fohr (Germany), who had resigned effective March 1, 2018. On June 14, 2018, the States parties to the ICCPR met and elected nine members of the Committee, to replace those whose terms would expire at the end of 2018. There were sixteen candidates for the nine positions, not counting two who were withdrawn shortly before the election and one whose nomination was late. Those elected were Yadh Ben Achour* (Tunisia), Christopher Bulkan (Guyana), Photini Pazartzis* (Greece), Hélène Tigroudja (France), Hernán Quezada Cabrera (Chile), Gentian Zyberi (Albania), Vasilka Sancin (Slovenia), Shuichi Furuya (Japan), and Duncan Muhumuza Laki* (Uganda). Asterisks denote sitting members who were re-elected.Pierre-Richard Prosperof the United States was not elected, in reportedly \"a first-ever defeat of a US candidate for the UN Human Rights Committee.\" The Committee meets three times a year for four-week sessions (spring session at UN headquarters in New York, summer and fall sessions at the UN Office in Geneva).  The categories of its work, outlined below, include state reporting, individual complaints, general comments, and inter-state communications. All states parties to the ICCPR have an obligation \"to submit reports on the measures they have adopted which give effect to the rights recognized [in the ICCPR] and on the progress made in the enjoyment of those rights.\"  The Human Rights Committee is responsible for \"study[ing]\" and responding to those reports submitted by states.  States parties must submit an initial report within one year of the ICCPR's entry into force, and subsequent periodic reports as requested by the Committee.  This reporting system is mandated by Article 40 of the ICCPR. The frequency of the periodic reports was formerly about every five years, but starting in 2020 is every eight years.The UN has published guidance for states on reporting to the Committee and other human rightstreaty bodies.The principal purpose of the report is to promote state compliance with the treaty principles and it should be an \"honest appraisal of their conformity to the treaty obligations\". Following the submission of a state's report, representatives of the state appear before the Committee in Geneva or New York to discuss the report, in an in-person constructive dialogue which is generally webcast live on UN Web TV.  Following this dialogue, the Committee drafts and adopts its concluding observations, a document including positive aspects, subjects of concern, and suggestions and recommendations.  Subsequently, under its follow-up procedure, the Committee assesses whether certain recommendations have been fulfilled within one year. In July 2010, the Committee proposed a new optional reporting procedure called the \"List of Issues Prior to Reporting\" (LOIPR) or \"Simplified Reporting Procedure\".Under this system, instead of the state submitting a full report on its implementation of each article of the ICCPR, the Committee sends the state a list of issues to address, and the state's report must only answer the questions raised in that list of issues.The Committee subsequently adopted  the simplified reporting procedure on a pilot basis, although it remains an optional alternative to the \"regular\" procedure, i.e., submission of a full report.  At its 124th session in 2018, the Committee decided to adopt the simplified reporting procedure on a permanent basis, and to encourage all states to switch to simplified reporting. It also decided to strive to limit the number of questions in each list of issues to 25.In 2019, the Committee decided to make the simplified reporting procedure the default, changing a state's selection of it from an opt-in to an opt-out model. In July 2019 the Committee decided to move, beginning in 2020, to an eight-year \"Predictable Review Cycle\" (PRC), under which it would schedule one review for each state party (including those states that failed to report).  This cycle involves a five-year review process, and a three-year interval before the next review process begins.  All states parties were divided into 8 groups of 21-22 states each, with the reporting process to start for each group on a different year. NGOs and other civil society organizations play a crucial role in the reporting process.  Any NGO, regardless of accreditation, may submit its own reports (sometimes called \"shadow reports\") to the Committee, comment on state reports, and attend all Committee sessions as observers.  Furthermore, the Committee often holds a closed meeting with interested NGOs as part of its review of a state's report. One set of weaknesses is inherent to a system of self-reporting.  Though in theory, reports should be an honest appraisal, constructive criticism of perceived failures to adhere to Covenant principles is unlikely.The Centre for Civil and Political Rights, an NGO, states that \"State reports often . . . fail to describe the implementation of the Covenant in practice\" and \"frequently lack an honest evaluation of the difficulties the State faces in implementing the rights guaranteed under the Covenant.\" Late reporting and non-reporting by states is another problem.  The Committee's annual report through March 2019 stated that fifteen states' \"initial reports are overdue, of which 7 are overdue by between 5 and 10 years and 8 are overdue by 10 years or more.\"  The report's Annex IV listed them; Equatorial Guinea's initial report was 30 years overdue.  That Annex also listed thirteen states whose periodic reports were ten years or more overdue, with Afghanistan's overdue by 22 years, and Nigeria's overdue by 19; ten states whose periodic reports were five to ten years overdue; and 28 states whose periodic reports were overdue by less than five years.CSW, a UK-based NGO, asserts that \"there remains a relatively low level of engagement and implementation of recommendations\" on the part of States, and that the level of States compliance withtreaty bodyrecommendations is only 19%. Other widely noted problems include the backlog of the Committee and the heavy burden on states, particularly small states. States that are party to theFirst Optional Protocol to the ICCPR(currently 116 countries) have agreed to allow persons within their jurisdiction to submit complaints (\"individual communications\") to the Committee claiming that their rights under the ICCPR have been violated.The ICCPR is one of eight UN human rights treaties with individual complaints procedures available; two other treaties state such procedures that are not yet in force. Before considering the merits (substance) of an individual communication, the Committee must be satisfied that it is admissible.The Committee may review many factors in determining admissibility and may conclude that, for an individual communication to be admissible, it must: Individual communications that contain the necessary prima facie elements are referred to the Committee’s Special Rapporteur on New Communications and Interim Measures, who decides whether the case should be registered. At that point, the case is transmitted to the State party, which is requested to submit its observations within six months, under Article 4 of the First Optional Protocol.Once the State replies to the complaint, the complainant is offered an opportunity to comment, within a set time frame.  If the Committee concludes that a violation of the ICCPR has taken place, in its follow-up procedure the Committee invites the State to provide information within 180 days on its steps to implement the Committee's recommendations. The State’s response is transmitted to the complainant for comments.  If the State party fails to take appropriate action, the Committee keeps the case under consideration.  Thus, the Committee maintains a dialogue with the State party and the case remains open until satisfactory measures are taken. The Committee considers individual communications in closed session, but its decisions (\"Views\") and any follow-up are public.Given the large number of complaints, several years may elapse between submission of a complaint and the Committee’s decision on it. Information on the process and how to use it, including examples and guidelines for submitting complaints, is available from someNGOsand theUnited Nations. All Committee decisions on individual complaints are available in online compilations published by UN,NGO,and academicsources. The Committee has received thousands of complaints since its inception.A few of its decisions that are notable are listed below, in reverse chronological order.  Among more recent decisions that attracted press and academic attention, in two October 2018 decisions the Committee concluded that France's ban on theniqab, the full-face Islamic veil, violated human rights guaranteed under the ICCPR, in particular the rights to manifest one's religion or beliefs and to protection against discrimination. To date the Committee has issued 36 \"General Comments\", each of which provides detailed guidance on particular parts of the ICCPR. The Committee has circulated a draft of its next, forthcoming General Comment, General Comment 37 on ICCPR Article 21, the right of peaceful assembly, seeking public comments on the draft by an extended deadline of February 21, 2020.The draft has been criticized for its reliance on decisions of regional, as opposed to global, human rights bodies. The Committee's most recent General Comment (of October 30, 2018) was General Comment 36 on ICCPR Article 6, on the right to life (replacing General Comments 6 and 14, of 1982 and 1984, respectively).Of its seventy paragraphs, twenty addresscapital punishment, in a section headed \"The death penalty.\"  One commentator has stated that its description of how the right to life applies during situations of armed conflict and its statement of the relationship between international human rights law and international humanitarian law are noteworthy. In December 2014 the Committee issued General Comment 35 on ICCPR Article 9, \"liberty and security of person\". In July 2011, the UN Human Rights Committee adopted a 52-paragraph statement, General Comment 34 on ICCPR Article 19, concerning freedoms of opinion and expression. Paragraph 48 states: The Covenant provides for inter-State complaints \"that enables one State Party to charge another with a violation to the treaty.\"\"[N]o interstate complaint mechanism has yet been submitted\" (up to 2009).This is still a matter of jurisdiction and it is optional to the committee of whether or not they will accept such complaint or not.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/United_Nations_Human_Rights_Committee", "https://en.wikipedia.org/wiki/United_Nations_Human_Rights_Committee", "https://en.wikipedia.org/wiki/United_Nations_Human_Rights_Committee", "https://en.wikipedia.org/wiki/United_Nations_human_rights_organization_(disambiguation)", "https://en.wikipedia.org/wiki/Treaty_body", "https://en.wikipedia.org/wiki/International_Covenant_on_Civil_and_Political_Rights", "https://en.wikipedia.org/wiki/First_Optional_Protocol_to_the_International_Covenant_on_Civil_and_Political_Rights", "https://en.wikipedia.org/wiki/Human_rights_treaty_bodies"]},
{"id": "3cd3b754ad1a", "url": "https://en.wikipedia.org/wiki/Orders,_decorations,_and_medals_of_SFR_Yugoslavia", "title": "Orders, decorations, and medals of the Socialist Federal Republic of Yugoslavia", "headings": ["Contents", "Orders", "Medals", "Commemorative medal", "Other medals", "See also", "References", "External links"], "content": " Orders, decorations, and medals of the Socialist Federal Republic of Yugoslaviawere created during theSecond World Warand used throughout the existence of theSocialist Federal Republic of Yugoslavia(called Federal People's Republic of Yugoslavia until 1963). The first decorations were created byAVNOJon August 15, 1943 and included theOrder of the People's Hero,Order of the People's Liberation, Order of the Partisan Star, Order of the Brotherhood and Unity, Order for Bravery and Medal for Bravery.By 1960 the total number of decorations increased to 42 and consisted of 35 orders, 6 medals and 1 commemorative medal. The designers of the Yugoslav orders and medals wereAntun AugustinčićandĐorđe Andrejević Kun. The Law on Decorations of 1945 introduced two new orders (Order of Freedom,Order of Merits for the People) and one new medal (Medal for Merits for the People) and assigned the order of precedence of all orders and medals.The Law was amended in 1946, when the Commemorative medal of Partisans of 1941 was removed and no long considered a decoration.New decorations were introduced in 1947 (Order of the Yugoslav Flag),1948 (Order of the Hero of Socialist Labour),1951 (Order of the War Banner,Order of the People's Army,Order of Military Merits, Medal for Military Merits, Medal for Military Virtues),1954 (Order of the Yugoslav Star),1955 (Medal for Merits),and 1960 (Order of the Republic).In 1961, the Law was amended again, so that names of many lower class orders was changed, and the order of precedence was slightly changed.In 1973, new Law on Decorations was adopted. It kept all the previous decorations, but the order of precedence was abolished. Before 1955, no distinction was made between the civil and military decorations. The Law on Decorations of 1955 made this distinction for the first timeand it was kept until the Law of 1973 when this distinction was abolished.Between 1955 and 1973, the orders of Freedom, People's Hero, War Banner, Partisan Star, People's Army, Military Merits, and Bravery, and the medals for Bravery, Military Merits and Military Virtues were considered military decorations, while all others were considered civil decorations. The original decorations are kept at theWorld Intellectual Property Organization.The Yugoslav government requested that the decorations be given the status of \"official sign\" as opposed to other countries and states where the status of official control and warranty is reserved only for the national seal. With the dissolution of Yugoslavia the decorations stopped being awarded but continue to be protected by Article 6 of theParis Convention for the Protection of Industrial Property. In 1998, theFederal Republic of Yugoslavia(also known as Serbia and Montenegro) adopted new Law on Decorations that kept most of the decorations of the Socialist Yugoslavia, with some additions. (1945) (1955) (1960) (1961) (until the end of 1985) (until the end of 1985) Instituted on 14 September 1944 for award to those actively involved in partisan or political units between 1941 and the end of WW2. At first, the Commemorative medal of the partisans of 1941 was considered to be the lowest of rank among the orders, but later lost that status to be considered outside of the before mentioned group and listed below medals.", "combined_text": "Orders, decorations, and medals of the Socialist Federal Republic of Yugoslavia Contents Orders Medals Commemorative medal Other medals See also References External links  Orders, decorations, and medals of the Socialist Federal Republic of Yugoslaviawere created during theSecond World Warand used throughout the existence of theSocialist Federal Republic of Yugoslavia(called Federal People's Republic of Yugoslavia until 1963). The first decorations were created byAVNOJon August 15, 1943 and included theOrder of the People's Hero,Order of the People's Liberation, Order of the Partisan Star, Order of the Brotherhood and Unity, Order for Bravery and Medal for Bravery.By 1960 the total number of decorations increased to 42 and consisted of 35 orders, 6 medals and 1 commemorative medal. The designers of the Yugoslav orders and medals wereAntun AugustinčićandĐorđe Andrejević Kun. The Law on Decorations of 1945 introduced two new orders (Order of Freedom,Order of Merits for the People) and one new medal (Medal for Merits for the People) and assigned the order of precedence of all orders and medals.The Law was amended in 1946, when the Commemorative medal of Partisans of 1941 was removed and no long considered a decoration.New decorations were introduced in 1947 (Order of the Yugoslav Flag),1948 (Order of the Hero of Socialist Labour),1951 (Order of the War Banner,Order of the People's Army,Order of Military Merits, Medal for Military Merits, Medal for Military Virtues),1954 (Order of the Yugoslav Star),1955 (Medal for Merits),and 1960 (Order of the Republic).In 1961, the Law was amended again, so that names of many lower class orders was changed, and the order of precedence was slightly changed.In 1973, new Law on Decorations was adopted. It kept all the previous decorations, but the order of precedence was abolished. Before 1955, no distinction was made between the civil and military decorations. The Law on Decorations of 1955 made this distinction for the first timeand it was kept until the Law of 1973 when this distinction was abolished.Between 1955 and 1973, the orders of Freedom, People's Hero, War Banner, Partisan Star, People's Army, Military Merits, and Bravery, and the medals for Bravery, Military Merits and Military Virtues were considered military decorations, while all others were considered civil decorations. The original decorations are kept at theWorld Intellectual Property Organization.The Yugoslav government requested that the decorations be given the status of \"official sign\" as opposed to other countries and states where the status of official control and warranty is reserved only for the national seal. With the dissolution of Yugoslavia the decorations stopped being awarded but continue to be protected by Article 6 of theParis Convention for the Protection of Industrial Property. In 1998, theFederal Republic of Yugoslavia(also known as Serbia and Montenegro) adopted new Law on Decorations that kept most of the decorations of the Socialist Yugoslavia, with some additions. (1945) (1955) (1960) (1961) (until the end of 1985) (until the end of 1985) Instituted on 14 September 1944 for award to those actively involved in partisan or political units between 1941 and the end of WW2. At first, the Commemorative medal of the partisans of 1941 was considered to be the lowest of rank among the orders, but later lost that status to be considered outside of the before mentioned group and listed below medals.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Orders,_decorations,_and_medals_of_the_Socialist_Federal_Republic_of_Yugoslavia", "https://en.wikipedia.org/wiki/Orders,_decorations,_and_medals_of_the_Socialist_Federal_Republic_of_Yugoslavia", "https://en.wikipedia.org/wiki/Orders,_decorations,_and_medals_of_the_Socialist_Federal_Republic_of_Yugoslavia", "https://en.wikipedia.org/wiki/Second_World_War", "https://en.wikipedia.org/wiki/Socialist_Federal_Republic_of_Yugoslavia", "https://en.wikipedia.org/wiki/AVNOJ", "https://en.wikipedia.org/wiki/Order_of_the_People%27s_Hero", "https://en.wikipedia.org/wiki/Order_of_the_People%27s_Liberation"]},
{"id": "6a40e239a83e", "url": "https://en.wikipedia.org/wiki/Philips_VG_8000", "title": "Philips VG 8000", "headings": ["Contents", "Philips VG 8010", "Specifications", "References"], "content": "ThePhilips VG-8000, released in 1983, was the first PhilipsMSXcomputer, although it was not 100% compliant with the standard (as it lacked aCentronicsprinter port,expansion bus, or audio out, and had a custom video out). The VG-8000 was built in France, atLe MansbyRadiotechnique.It was released inBelgium,Finland,Germany, andItaly(as thePhonola VG-8000). The computer had a poorchiclet type keyboard, with twocartridgeports above it. The keyboard layout wasqwertyorazerty, according to the market the computer was sold. It had five doublefunction keys(F1toF10) on top, and fourarrow keyson the right. There were three colorLEDs:Power(red),Caps(orange) andCode(green). There were three versions of this machine: The machine was expensive and not successful. TheVG-8010, released in January 1984, was a more advanced model with 32KBof RAM and popular inthe Netherlands. It was built in France, atLe MansbyRadiotechnique, with a retail price of 2290Frin September 1985.It was sold in Italy as thePhonola VG-8010. There were two versions of this machine: Besides the mentioned Phonola branding, these machines were also sold under theSchneiderand Radiola brands: The VG-8010 was replaced with thePhilips VG-8020, a more advanced machine.  Thiscomputer hardwarearticle is astub. You can help Wikipedia byexpanding it.", "combined_text": "Philips VG 8000 Contents Philips VG 8010 Specifications References ThePhilips VG-8000, released in 1983, was the first PhilipsMSXcomputer, although it was not 100% compliant with the standard (as it lacked aCentronicsprinter port,expansion bus, or audio out, and had a custom video out). The VG-8000 was built in France, atLe MansbyRadiotechnique.It was released inBelgium,Finland,Germany, andItaly(as thePhonola VG-8000). The computer had a poorchiclet type keyboard, with twocartridgeports above it. The keyboard layout wasqwertyorazerty, according to the market the computer was sold. It had five doublefunction keys(F1toF10) on top, and fourarrow keyson the right. There were three colorLEDs:Power(red),Caps(orange) andCode(green). There were three versions of this machine: The machine was expensive and not successful. TheVG-8010, released in January 1984, was a more advanced model with 32KBof RAM and popular inthe Netherlands. It was built in France, atLe MansbyRadiotechnique, with a retail price of 2290Frin September 1985.It was sold in Italy as thePhonola VG-8010. There were two versions of this machine: Besides the mentioned Phonola branding, these machines were also sold under theSchneiderand Radiola brands: The VG-8010 was replaced with thePhilips VG-8020, a more advanced machine.  Thiscomputer hardwarearticle is astub. You can help Wikipedia byexpanding it.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Philips_VG_8000", "https://en.wikipedia.org/wiki/Philips_VG_8000", "https://en.wikipedia.org/wiki/Philips_VG_8000", "https://en.wikipedia.org/wiki/MSX", "https://en.wikipedia.org/wiki/Centronics_connector", "https://en.wikipedia.org/wiki/Expansion_bus", "https://en.wikipedia.org/wiki/Le_Mans", "https://en.wikipedia.org/wiki/Radiotechnique"]},
{"id": "2872518ad3b4", "url": "https://en.wikipedia.org/wiki/Jacob", "title": "Jacob", "headings": ["Contents", "Etymology", "Hebrew", "Greek", "Genesis narrative", "Birth to Isaac and Rebecca", "Acquiring Esau's birthright", "Blessing of Isaac", "Jacob's Ladder", "Marriages", "Journey back to Canaan", "Famine of the Near East", "Migration to Egypt", "Final days: Blessing of Jacob", "Children of Israel", "Religious perspectives", "Judaism", "Christianity", "Islam", "Historicity", "See also", "Notes", "References", "Further reading", "External links"], "content": " Jacob,later known asIsrael,is aHebrew patriarchof theAbrahamic religions. He first appears in theTorah, where he is described in theBook of Genesisas a son ofIsaacandRebecca. Accordingly, alongside his older fraternal twin brotherEsau, Jacob's paternal grandparents areAbrahamandSarahand his maternal grandfather isBethuel, whose wife is not mentioned. He is said to have bought Esau's birthright and, with his mother's help, deceived his aging father to bless him instead of Esau.Then, following a severe drought in his homelandCanaan, Jacob and his descendants migrated to neighbouringEgyptthrough the efforts of his sonJoseph, who had become a confidant of thepharaoh. After dying in Egypt at the age of 147, he is supposed to have been buried in theCave of MachpelahinHebron. Per theHebrew Bible, Jacob's progeny were beget by four women: his wives (and maternal cousins)LeahandRachel; and his concubinesBilhahandZilpah. His sons were, in order of their birth:Reuben,Simeon,Levi,Judah,Dan,Naphtali,Gad,Asher,Issachar,Zebulun, Joseph, andBenjamin. He also had a daughter namedDinah, born to his first wife Leah.The descendants of Jacob's sons were collectively known as theIsraelites, with each son being the forefather of one of theTwelve Tribes of Israel, of whom all but theTribe of Leviwere allotted territory in theLand of Israel. The Genesis narrative also states that Jacob displayed favoritism among his wives and children, preferring Rachel and her sons Joseph and Benjamin to the rest—culminating in Joseph's older brothers selling him into slavery out of resentment. Scholars have taken a mixed view as toJacob's historicity, with archaeology so far producing no evidence for his existence.Archaeologist and scholarWilliam Albrightinitially dated Jacob to the 19th century BCE, but later scholars, such as John J. Bimson andNahum Sarna, argued against using archaeological evidence to support such claims due to limited knowledge of that period. Recent scholarship byThomas L. ThompsonandWilliam Deversuggest that these narratives are late literary compositions with ideological purposes rather than historical accounts. According to thefolk etymologyfound inGenesis25:26, the nameYaʿaqōvיעקבis derived fromʿaqevעָקֵב\"heel\", as Jacob was born grasping the heel of his twin brotherEsau.The historical origin of the name is uncertain, although similar names have been recorded.Yaqub-Haris recorded as a place name in a list byThutmose III(15th century BC), and later as thenomenof aHyksospharaoh. The hieroglyphs are ambiguous, and can be read as \"Yaqub-Har\", \"Yaqubaal\", or \"Yaqub El\". The same name is recorded earlier still, inc.1800 BC, in cuneiform inscriptions (spelledya-ah-qu-ub-el,ya-qu-ub-el).The suggestion that the personal name may be shortened from this compound name, which would translate to \"mayElprotect\", originates with Bright (1960).In theAmorite language, parallel forms of Jacob's name are attested asia-aḫ-qú-ub-DINGIRandia-aḫ-qú-bu-um. The nameIsraelgiven to Jacob following the episode of hiswrestling with the angel(Genesis 32:22–32) is etymologized as composition ofאֵלel\"god\" and the rootשָׂרָהśarah\"to rule, contend, have power, prevail over\":שָׂרִיתָ עִם־אֱלֹהִים(KJV: \"a prince hast thou power withGod\"); alternatively, theelcan be read as the subject, for a translation of \"El rules/contends/struggles\".The word \"strive\" is often used for the proposedetymonשרה, but as Genesis novelly uses the word without defining it, this interpretation is merely based upon the context in the story. TheSeptuagintrenders the nameIákobos(Ancient Greek:Ἰάκωβος), whence LatinJacobus, EnglishJacob. The biblical account of the life of Jacob is found in the Book of Genesis, chapters 25–50. Jacob and his twin brother, Esau, were born toIsaacandRebeccaafter 20 years of marriage, when Isaac was 60 years of age.Rebecca was uncomfortable during her pregnancy and went to inquire of God why she was suffering. She received the prophecy thattwinswere fighting in her womb and would continue to fight all their lives, even after they became two separate nations. The prophecy also said that \"the one people shall be stronger than the other people; and the elder shall serve the younger\"(Genesis 25:25 KJV). When the time came for Rebecca to give birth, the firstborn, Esau, came out covered with red hair, as if he were wearing a hairy garment, and his heel was grasped by the hand of Jacob, the secondborn. According to Genesis 25, Isaac and Rebecca named the first son Esau (Hebrew:עשו).The second son they named Jacob (Hebrew: יעקב, Ya'aqob or Ya'aqov, meaning \"heel-catcher\", \"supplanter\", \"leg-puller\", \"he who follows upon the heels of one\", from Hebrew:עקב,'aqabor'aqav, \"seize by the heel\", \"circumvent\", \"restrain\", a wordplay upon Hebrew:עקבה,'iqqebahor'iqqbah, \"heel\"). The boys displayed very different natures as they matured: \"... and Esau was a cunning hunter, a man of the field; but Jacob was a simple man, dwelling in tents\".Moreover, the attitudes of their parents toward them also differed: \"And Isaac loved Esau, because he did eat of his venison: but Rebecca loved Jacob.\" Genesis 25:29–34 tells the account of Esau selling hisbirthrightto Jacob.This passage tells that Esau, returning famished from the fields, begged Jacob to give him some of the stew that Jacob had just made. (Esau referred to the dish as \"that same red pottage\", giving rise to his nickname, Hebrew:אדום('Edom, meaning \"Red\").) Jacob offered to give Esau a bowl of stew in exchange for his birthright, to which Esau agreed. As Isaac aged, he became blind and was uncertain when he would die, so he decided to bestow Esau's birthright upon him. He requested that Esau go out to the fields with his weapons (quiver and bow) to kill some venison. Isaac then requested that Esau make \"savory meat\" for him out of the venison, according to the way he enjoyed it the most, so that he could eat it and bless Esau. Rebecca overheard this conversation. It is suggested that she realized prophetically that Isaac's blessings would go to Jacob, since she was told before the twins' birth that the older son would serve the younger.Rebecca blessed Jacob and she quickly ordered Jacob to bring her two kid goats from their flock so that he could take Esau's place in serving Isaac and receiving his blessing. Jacob protested that his father would recognize their deception since Esau was hairy and he himself was smooth-skinned. He feared his father would curse him as soon as he felt him, but Rebecca offered to take the curse herself, then insisted that Jacob obey her.Jacob did as his mother instructed and, when he returned with the kids, Rebecca made the savory meat that Isaac loved.  Before she sent Jacob to his father, she dressed him in Esau's garments and laid goatskins on his arms and neck to simulate hairy skin. Disguised as Esau, Jacob entered Isaac's room. Surprised that Esau was back so soon, Isaac asked how it could be that the hunt went so quickly. Jacob responded, \"Because the LORD your God brought it to me.\"Rashisays Isaac's suspicions were aroused even more, because Esau never used the personal name of God.Isaac demanded that Jacob come close so he could feel him, but the goatskins felt just like Esau's hairy skin. Confused, Isaac exclaimed, \"The voice is Jacob's voice, but the hands are the hands of Esau!\"Still trying to get at the truth, Isaac asked him directly, \"Art thou my very son Esau?\" and Jacob answered simply, \"I am.\" Isaac proceeded to eat the food and to drink the wine that Jacob gave him, and then told him to come close and kiss him. As Jacob kissed his father, Isaac smelled the clothes which belonged to Esau and finally accepted that the person in front of him was Esau. Isaac then blessed Jacob with the blessing that was meant for Esau. Genesis 27:28–29 states Isaac's blessing: \"Therefore God give thee of the dew of heavens, and the fatness of the earth, and plenty of corn and wine: Let people serve thee: be lord over thy brethren, and let thy mother's sons bow down to thee: cursed be every one that curseth thee, and blessed be he that blesseth thee.\" Jacob had scarcely left the room when Esau returned from the hunt to prepare his game and receive the blessing. The realization that he had been deceived shocked Isaac, yet he acknowledged that Jacob had received the blessings by adding, \"Indeed, he will be [or remain] blessed!\" (27:33). Esau was heartbroken by the deception and begged for his own blessing. Having made Jacob a ruler over his brothers, Isaac could only promise, \"By your sword you shall live, but your brother you shall serve; yet it shall be that when you are aggrieved, you may cast off his yoke from upon your neck\" (27:39–40). Although Esau sold Jacob his own birthright, which was his blessing, for \"red pottage,\" Esau still hated Jacob for receiving his blessing that their father Isaac unknowingly had given to him. He vowed to kill Jacob as soon as Isaac died. When Rebecca heard about his murderous intentions,she ordered Jacob to travel to her brotherLaban's house inHaran, until Esau's anger subsided. She convinced Isaac to send Jacob away by telling him that she despaired of his marrying a local girl from the idol-worshipping families ofCanaan(as Esau had done). After Isaac sent Jacob away to find a wife, Esau realized his own Canaanite wives were evil in his father's eyes and so he took a daughter of Isaac's half-brother,Ishmael, as another wife. NearLuzen route to Haran, Jacob experienced a vision of a ladder, or staircase, reaching into heaven with angels going up and down it, subsequently referred to in popular culture as \"Jacob's ladder.\" He heard the voice of God, who repeated many of the blessings upon him, coming from the top of the ladder. According toPirkei DeRabbi Eliezer, the ladder signified the exiles that the Jewish people would suffer before the coming of theJewish Messiah: the angels that represented the exiles of Babylonia, Persia, and Greece each climbed up a certain number of steps, paralleling the years of the exile, before they \"fell down\"; but the angel representing the last exile, that ofEdom, kept climbing higher and higher into the clouds. Jacob feared that his descendants would never be free of Esau's domination, but God assured him that at the End of Days, Edom too would come falling down. In the morning, Jacob awakened and continued on his way to Haran, after naming the place where he had spent the night \"Bethel\", \"God's house.\" Arriving in Haran, Jacob saw a well where shepherds were gathering their flocks to water them and metLaban's younger daughter,Rachel, Jacob'sfirst cousin; she was working as a shepherdess. Jacob was 77 years old,and he loved Rachel immediately. After spending a month with his relatives he asked for her hand in marriage in return for working seven years for Laban theAramean. Laban agreed to the arrangement. These seven years seemed to Jacob \"but a few days, for the love he had for her.\" When they were complete and he was 84 years oldhe asked for his wife, but Laban deceived him by switching Rachel for her older sister,Leah, as the veiled bride. In the morning, when the truth became known, Laban justified his action, saying that in his country it was unheard of to give a younger daughter before the older. However, he agreed to give Rachel in marriage as well if Jacob would work another seven years. After the week of wedding celebrations with Leah, Jacob married Rachel, and he continued to work for Laban for another seven years. In those seven years, Jacob fathered twelve children.He loved Rachel more than Leah, and Leah felt hated. God opened Leah's womb and she gave birth to four sons rapidly:Reuben,Simeon,Levi, andJudah. Rachel, however, remained barren. Following the example of Sarah, who gave her handmaid toAbrahamafter years of infertility, Rachel gave her handmaidBilhahto Jacob so that Rachel could raise children through her. Bilhah gave birth toDanandNaphtali. Seeing that she had left off childbearing temporarily, Leah then gave her handmaidZilpahto Jacob so that Leah could raise more children through her. Zilpah gave birth toGadandAsher. Afterwards, Leah became fertile again and gave birth toIssachar,Zebulun, andDinah, Jacob's only daughter. God remembered Rachel, who gave birth toJoseph, and later,Benjamin. After Joseph was born, Jacob decided to return home to his parents. Labanthe Arameanwas reluctant to release him, as God had blessed his flock on account of Jacob. Laban asked what he could pay Jacob. Jacob suggested that all the spotted, speckled, and brown goats and sheep of Laban's flock, at any given moment, would be his wages. Jacob placed rods of poplar, hazel, and chestnut, all of which he peeled \"white streaks upon them,\"within the flocks' watering holes or troughs, associating the stripes of the rods with the growth of stripes on the livestock.Despite this practicing of magic, later on Jacob says to his wives that it was God who made the livestock give birth to the convenient offspring, in order to turn the tide against the deceptive Laban.As time passed, Laban's sons noticed that Jacob was taking the better part of their flocks, and so Laban's friendly attitude towards Jacob began to change. Theangel of the Lord, in a dream back during the breeding season, told Jacob \"Now lift your eyes and see [that] all the he goats mounting the animals are ringed, speckled, and striped, for I have seen all that Laban is doing to you\",that he is the God whom Jacob met at Bethel,and that Jacob should leave and go back to the land where he was born,which he and his wives and children did without informing Laban. Before they left, Rachel stole theteraphim,considered to be householdidols, from Laban's house. Laban pursued Jacob for seven days. The night before he caught up to him, God appeared to Laban in a dream and warned him not to say anything good or bad to Jacob. When the two met, Laban said to Jacob, \"What have you done, that you have tricked me and driven away my daughters like captives of the sword?\"He also asked for his stolenteraphimback. Knowing nothing about Rachel's theft, Jacob told Laban that whoever stole them should die and stood aside to let him search. When Laban reached Rachel's tent, she hid theteraphimby sitting on them and stating she could not get up because she wasmenstruating. Jacob and Laban then parted from each other with a pact to preserve the peace between them nearGilead. Laban returned to his home and Jacob continued on his way. As Jacob neared the land of Canaan as he passedMahanaim, he sent messengers ahead to his brother Esau. They returned with the news that Esau was coming to meet Jacob with an army of 400 men. With great apprehension, Jacob prepared for the worst. He engaged in earnest prayer to God, then sent on before him a tribute of flocks and herds to Esau, \"A present to my lord Esau from thy servant Jacob.\" Jacob then transported his family and flocks across the fordJabbokby night, then recrossed back to send over his possessions, being left alone in communion with God. There, a mysterious being appeared (\"man,\" Genesis 32:24, 28; or \"God,\" Genesis 32:28, 30, Hosea 12:3, 5; or \"angel,\" Hosea 12:4), and the two wrestled until daybreak. When the being saw that he did not overpower Jacob, he touched Jacob on the sinew of his thigh (thegid hanasheh, גיד הנשה), and, as a result, Jacob developed a limp (Genesis 32:31). Because of this, \"to this day the people of Israel do not eat the sinew of the thigh that is on the hip socket\"This incident is the source of themitzvahofporging. Jacob then demanded a blessing, and the being declared in Genesis 32:28 that, from then on, Jacob would be called יִשְׂרָאֵל, Israel (Yisra'el, meaning \"one that struggled with the divine angel\" (Josephus), \"one who has prevailed with God\" (Rashi), \"a man seeing God\" (Whiston), \"he will rule as God\" (Strong), or \"a prince with God\" (Morris), from Hebrew:שרה, \"prevail,\" \"have power as a prince\").While he is still called Jacob in later texts, his name Israel makes some consider him theeponymousancestor of theIsraelites. Jacob asked the being's name, but he refused to answer. Afterwards, Jacob named the placePenuel(Penuw'el,Peniy'el, meaning \"face of God\"),saying: \"I have seen God face to face and lived.\" Because the terminology is ambiguous (\"el\"inYisra'el) and inconsistent, and because this being refused to reveal his name, there are varying views as to whether he was a man, an angel, or God. Josephus uses only the terms \"angel\", \"divine angel,\" and \"angel of God,\" describing the struggle as no small victory. According to Rashi, the being was the guardian angel of Esau himself, sent to destroy Jacob before he could return to the land of Canaan. Trachtenberg theorized that the being refused to identify itself for fear that, if its secret name was known, it would be conjurable by incantations.Literal Christian interpreters likeHenry M. Morrissay that the stranger was \"God Himself and, therefore, Christ in His preincarnate state\", citing Jacob's own evaluation and the name he assumed thereafter, \"one who fights victoriously with God\", and adding that God had appeared in the human form of theAngel of the Lordto eat a meal with Abraham in Genesis 18.Geller wrote that, \"in the context of the wrestling bout, the name implies that Jacob won this supremacy, linked to that of God's, by a kind oftheomachy.\" In the morning, Jacob assembled his four wives and 11 sons, placing the maidservants and their children in front, Leah and her children next, and Rachel and Joseph in the rear. Some commentators cite this placement as proof that Jacob continued to favor Joseph over Leah's children, as presumably the rear position would have been safer from a frontal assault by Esau, which Jacob feared. Jacob himself took the foremost position. Esau's spirit of revenge, however, was apparently appeased by Jacob's bounteous gifts of camels, goats and flocks. Their reunion was an emotional one. Esau offered to accompany them on their way back to Israel, but Jacob protested that his children were still young and tender (born six to 13 years prior in the narrative); Jacob suggested eventually catching up with Esau atMount Seir. According to the Sages, this was a prophetic reference to the End of Days, when Jacob's descendants will come to Mount Seir, the home of Edom, to deliver judgment against Esau's descendants for persecuting them throughout the millennia.Jacob actually diverted himself to Succoth and was not recorded as rejoining Esau until, atMachpelah, the two bury their father Isaac, who lived to be 180, and was 60 years older than they were. Jacob then arrived inShechem, where he bought a parcel of land, now identified asJoseph's Tomb. In Shechem, Jacob's daughter Dinah was kidnapped and raped by the ruler's son, who desired to marry the girl. Dinah's brothers, Simeon and Levi, agreed in Jacob's name to permit the marriage as long as all the men of Shechem firstcircumcisedthemselves, ostensibly to unite the children of Jacob in Abraham'scovenantof familial harmony. On the third day after the circumcisions, when all the men of Shechem were still in pain, Simeon and Levi put them all to death by the sword and rescued their sister Dinah, and their brothers plundered the property, women, and children. Jacob condemned this act, saying: \"You have brought trouble on me by making me a stench to theCanaanitesandPerizzites, the people living in this land.\"He later rebuked his two sons for their anger in his deathbed blessing (Genesis 49:5–7). Jacob returned to Bethel, where he had another vision of blessing. Although the death of Rebecca, Jacob's mother, is not explicitly recorded in the Bible, Deborah, Rebecca's nurse, died and was buried at Bethel, at a place that Jacob callsAllon Bachuth(אלון בכות), \"Oak of Weepings\" (Genesis 35:8). According to the Midrash,the plural form of the word \"weeping\" indicates the double sorrow that Rebecca also died at this time. Jacob then made a further move while Rachel was pregnant; nearBethlehem, Rachel went into labor and died as she gave birth to her second son,Benjamin(Jacob's twelfth son). Jacob buried her and erected a monument over her grave.Rachel's Tomb, just outside Bethlehem, remains a popular site for pilgrimages and prayers to this day. Jacob then settled inMigdal Eder, where his firstborn,Reuben, slept with Rachel's servant Bilhah; Jacob's response was not given at the time, but he did condemn Reuben for it later, in his deathbed blessing. Jacob was finally reunited with his father Isaac inMamre(outsideHebron). When Isaac died at the age of 180, Jacob and Esau buried him in theCave of the Patriarchs, which Abraham had purchased as a familyburial plot. At this point in the biblical narrative, two genealogies of Esau's family appear under the headings \"the generations of Esau\". A conservative interpretation is that, at Isaac's burial, Jacob obtained the records of Esau, who had been married 80 years prior, and incorporated them into his own family records, and that Moses augmented and published them. The house of Jacob dwelt inHebron,in the land of Canaan. His flocks were often fed in the pastures ofShechemas well asDothan.Of all the children in his household, he loved Rachel's firstborn son, Joseph, the most. Thus Joseph's half brothers were jealous of him and they ridiculed him often. Joseph even told his father about all of his half brothers' misdeeds. When Joseph was 17 years old, Jacob made a long coat ortunic of many colorsfor him. Seeing this, the half brothers began to hate Joseph. Then Joseph began to have dreams that implied that his family would bow down to him. When he told his brothers about such dreams, it drove them to conspire against him. When Jacob heard of these dreams, he rebuked his son for proposing the idea that the house of Jacob would even bow down to Joseph. Yet, he contemplated his son's words about these dreams. Sometime afterward, the sons of Jacob by Leah, Bilhah and Zilpah, were feeding his flocks in Shechem. Jacob wanted to know how things were doing, so he asked Joseph to go down there and return with a report.This was the last time he would ever see his son in Hebron. Later that day, the report that Jacob ended up receiving came from Joseph's brothers who brought before him a coat laden with blood from a goat. Jacob identified the coat as the one he made for Joseph. At that moment he cried, \"It is my son's tunic. A wild beast has devoured him. Without doubt Joseph is torn to pieces.\" He tore his clothes and put sackcloth around his waist mourning for days. No one from the house of Jacob could comfort him during this time of bereavement. The truth was that Joseph's older brothers had turned on him, apprehended him and ultimately sold him into slavery on a caravan headed for Egypt. Twenty years later,throughout the Middle East a severe famine occurred like none other that lasted seven years.It crippled nations.The word was that the only kingdom prospering was Egypt. In the second year of this great famine,when Israel (Jacob) was about 130 years old,he told his 10 sons of Leah, Bilhah and Zilpah, to go to Egypt and buy grain. Israel's youngest son Benjamin, born from Rachel, stayed behind by his father's order to keep him safe. Nine of the sons returned to their father Israel from Egypt, stockpiled with grain on their donkeys. They relayed to their father all that had happened in Egypt. They spoke of being accused as spies and that their brother Simeon had been taken prisoner. When Reuben, the eldest, mentioned that they needed to bring Benjamin to Egypt to prove their word as honest men, their father became furious with them. He couldn't understand how they were put in a position to tell the Egyptians all about their family. When the sons of Israel opened their sacks, they saw their money that they used to pay for the grain. It was still in their possession, and so they all became afraid. Israel then became angry with the loss of Joseph, Simeon, and now possibly Benjamin. It turned out that Joseph, who identified his brothers in Egypt, was able to secretly return the money that they used to pay for the grain, back to them.When the house of Israel consumed all the grain that they brought from Egypt, Israel told his sons to go back and buy more. This time, Judah spoke to his father in order to persuade him about having Benjamin accompany them, so as to prevent Egyptian retribution. In hopes of retrieving Simeon and ensuring Benjamin's return, Israel told them to bring the best fruits of their land, including:balm,honey, spices,myrrh,pistachionuts andalmonds. Israel also mentioned that the money that was returned to their money sacks was probably a mistake or an oversight on their part. So, he told them to bring that money back and use double that amount to pay for the new grain. Lastly, he let Benjamin go with them and said \"may God Almighty give you mercy... If I am bereaved, I am bereaved!\" When the sons of Israel (Jacob) returned to Hebron from their second trip, they came back with 20 additional donkeys carrying all kinds of goods and supplies as well as Egyptian transport wagons. When their father came out to meet them, his sons told him that Joseph was still alive, that he was the governor over all of Egypt and that he wanted the house of Israel to move to Egypt. Israel's heart \"stood still\" and just couldn't believe what he was hearing. Looking upon the wagons he declared \"Joseph my son is still alive. I will go and see him before I die.\" Israel and his entire house of 70,gathered up with all their livestock and began their journey to Egypt. En route, Israel stopped atBeershebafor the night to make a sacrificial offering to his God, Yahweh. Apparently he had some reservations about leaving the land of his forefathers, but God reassured him not to fear that he would rise again. God also assured that he would be with him, he would prosper, and he would also see his son Joseph who would lay him to rest. Continuing their journey to Egypt, when they approached in proximity, Israel sent his son Judah ahead to find out where the caravans were to stop. They were directed to disembark atGoshen. It was here, after 22 years, that Jacob saw his son Joseph once again. They embraced each other and wept together for quite a while. Israel then said, \"Now let me die, since I have seen your face, because you are still alive.\" The time had come for Joseph's family to personally meet thePharaohof Egypt. After Joseph prepared his family for the meeting, the brothers came before the Pharaoh first, formally requesting to pasture in Egyptian lands. The Pharaoh honored their stay and even made the notion that if there were any competent men in their house, then they may elect a chief herdsman to oversee Egyptian livestock. Finally, Joseph's father was brought out to meet the Pharaoh. Because the Pharaoh had such a high regard for Joseph, practically making him his equal,it was an honor to meet his father. Thus, Israel was able to bless the Pharaoh. The two chatted for a bit, the Pharaoh even inquiring of Israel's age which happened to be 130 years old at that time. After the meeting, the families were directed to pasture in the land of Ramses where they lived in the province of Goshen. The house of Israel acquired many possessions and multiplied exceedingly during the course of 17 years, even through the worst of the seven-year famine. Israel (Jacob) was 147 years old when he called to his favorite son Joseph and pleaded that he not be buried in Egypt. Rather, he requested to be carried to the land of Canaan to be buried with his forefathers. Joseph swore to do as his father asked of him. Not too long afterward, Israel had fallen ill, losing much of his vision. When Joseph came to visit his father, he brought with him his two sons, Ephraim and Manasseh. Israel declared that they would be heirs to the inheritance of the house of Israel, as if they were his own children, just as Reuben and Simeon were. Then Israel laid his right hand on the younger Ephraim's head and his left hand on the eldest Manasseh's head and blessed Joseph. However, Joseph was displeased that his father's right hand was not on the head of his firstborn, so he switched his father's hands. But Israel refused saying, \"but truly his younger brother shall be greater than he.\" A declaration he made, just as Israel himself was to his firstborn brother Esau. Then Israel called all of his sons in and prophesied their blessings or curses to all twelve of them in order of their ages. Afterward, Israel died and the family, including the Egyptians, mourned him 70 days. Israel was embalmed for 40 days and a great ceremonial journey to Canaan was prepared by Joseph. He led the servants of Pharaoh, and the elders of the houses Israel and Egypt beyond theJordan RivertoAtadwhere they observed seven days of mourning. Their lamentation was so great that it caught the attention of surrounding Canaanites who remarked \"This is a deep mourning of the Egyptians.\" This spot was then namedAbel Mizraim. Then they buried him in the cave ofMachpelah, the property of Abraham when he bought it from the HittiteEphron. Jacob, through his two wives and his two concubines had 12 biological sons;Reuben,Simeon,Levi,Judah,Dan,Naphtali,Gad,Asher,Issachar,Zebulun,JosephandBenjamin.The scene of Jacob mourning Joseph makes mention of him having a number of daughters,but no details are provided. Only one daughter,Dinah, is known by name.In addition, Jacob also adopted the two sons of Joseph,ManassehandEphraim. The offspring of Jacob's sons became thetribes of Israelfollowingthe Exodus, when the Israelites conquered and settled in theLand of Israel. There are two opinions in theMidrashas to how old Rebecca was at the time of her marriage and, consequently, at the twins' birth. According to the traditional counting cited byRashi, Isaac was 37 years old at the time of theBinding of Isaac, and news of Rebecca's birth reached Abraham immediately after that event.In that case, since Isaac was 60 when Jacob and Esau were born and they had been married for 20 years, then Isaac was 40 years old when he married Rebecca (Gen. 25:20), making Rebecca three years old at the time of her marriage, and 23 years old at the birth of Jacob and Esau. According to the second opinion, Rebecca was 14 years old at the time of their marriage, and 34 years old at the birth of Jacob and Esau. In either case, Isaac and Rebecca were married for 20 years before Jacob and Esau were born. The Midrash says that during Rebecca's pregnancy whenever she would pass a house of Torah study, Jacob would struggle to come out; whenever she would pass a house ofidolatry, Esau would agitate to come out. Rashi explained that Isaac, when blessing Jacob instead of Esau, smelled the heavenly scent ofGan Eden(Paradise) when Jacob entered his room and, in contrast, perceivedGehennaopening beneath Esau when the latter entered the room, showing him that he had been deceived all along by Esau's show of piety. According to the Talmud, Jacob did not flee directly to Haran (as would seem from the Biblical text), but rather studied for 14 years at thestudy house of Shem and Eberbefore continuing towards Haran. When Laban planned to deceive Jacob into marrying Leah instead of Rachel, theMidrashrecounts that both Jacob and Rachel suspected that Laban would pull such a trick; Laban was known as the \"Aramean\" (deceiver), and changed Jacob's wages ten times during his employ (Genesis 31:7). The couple therefore devised a series of signs by which Jacob could identify the veiled bride on his wedding night. But when Rachel saw her sister being taken out to the wedding canopy, her heart went out to her for the public shame Leah would suffer if she were exposed. Rachel therefore gave Leah the signs so that Jacob would not realize the switch. Jacob had still another reason for grieving the loss of Joseph. God had promised to him: \"If none of your sons dies during your lifetime, you may look upon it as a token that you will not be put in (Hellof)Gehennaafter your death.\"Thinking Joseph to be dead, Jacob had his own destiny to lament because he considered that he was doomed to that Hell. Jewishapocalyptic literatureof the Hellenistic period includes many ancient texts with narratives about Jacob, many times with details different from Genesis. The more important are theBook of Jubileesand theBook of Biblical Antiquities. Jacob is also the protagonist of theTestament of Jacob, of theLadder of Jacoband of thePrayer of Joseph, which interpret the experience of this Patriarch in the context ofmerkabahmysticism. TheEastern Orthodox Churchand thoseEastern Catholic Churcheswhich follow theByzantine Ritesee Jacob's dream as aprophecyof theincarnationof theLogos, wherebyJacob's ladderis understood as a symbol of theTheotokos(Virgin Mary), who, according toEastern Orthodox theology, united heaven and earth in her womb.The biblical account of this visionis one of the standard Old Testament readings atVespersonGreat Feastsof the Theotokos. The Eastern and Western Churches consider Jacob as asaintalong with otherbiblical patriarchs.Along with other patriarchs his feast day is celebrated in the Byzantine rite on the Second Sunday before the Advent (December 11–17), under the titlethe Sunday of the Forefathers. Two further references toIsra'il(Arabic: إِسْرَآئِیل [ˈisraāˈiyl]; Classical/ Quranic Arabic: إِسْرَآءِیْل [ˈisraāãˈiyl]) are believed to be mention of Jacob. The Arabic formYa'qūb(Arabic:يَعْقُوب,romanized:Yaʿqūb) may be direct from theHebrewor indirect throughSyriac. He is recognized inIslamas aprophetwho received inspiration from God. He is acknowledged as apatriarchofIslam. Muslims believe that he preached the same monotheistic faith as his forefathersʾIbrāhīm,ʾIsḥāqandIsmā'īl. Jacob is mentioned 16 times in theQuran.In the majority of these references, Jacob is mentioned alongside fellowprophetsandpatriarchsas an ancient and pious prophet. According to the Quran, Jacob remained in the company of the elect throughout his life. (38:47) The Quran specifically mentions that Jacob was guided (6:84) and inspired (4:163) and was chosen to enforce the awareness of the Hereafter. (38:46) Jacob is described as a good-doer (21:72) and the Quran further makes it clear that God inspired Jacob to contribute towards purification and hold the contact prayer. (21:73) Jacob is further described as being resourceful and a possessor of great vision (38:45) and is further spoken of as being granted a \"tongue [voice] of truthfulness to be heard.\" (19:50) Of the life of Jacob, the Quran narrates two especially important events. The first is the role he plays in the story of his sonJoseph. The Quran narrates the story of Joseph in detail, and Jacob, being Joseph's father, is mentioned thrice and is referenced another 25 times.In the narrative, Jacob does not trust some of his older sons (12: 11, 18, 23) because they do not respect him. (12: 8, 16–17) Jacob's prophetic nature is evident from his foreknowledge of Joseph's future greatness (12:6), his foreboding and response to the supposed death of Joseph (12: 13, 18) and in his response to the sons' plight inEgypt. (12: 83, 86–87, 96) Islamic literature fleshes out the narrative of Jacob, and mentions that his wives includedRachel.Jacob is later mentioned in the Quran in the context of the promise bestowed toZechariah, regarding the birth ofJohn the Baptist. (19:6) Jacob's second mention is in the Quran's second chapter. As Jacob lay on his deathbed, he asked his 12 sons to testify their faith to him before he departed from this world to the next. (2:132) Each son testified in front of Jacob that they would promise to remain Muslim (in submission to God) until the day of their death; that is they would surrender their wholeselves to God alone and would worship only Him. In contrast to theJudeo-Christianview of Jacob, one main difference is that the story of Jacob's blessing, in which he deceives Isaac, is not accepted in Islam. The Quran makes it clear that Jacob was blessed byGodas a prophet and, therefore, Muslims believe that his father, being a prophet as well, also knew of his son's greatness.Jacob is also cited in theHadithas an example of one who was patient and trusting in God in the face of suffering. According to the teachings of theNation of Islam(NOI), the original inhabitants of the world were black (referred to as the \"Asiatic Blackman\"), while the white race are \"devils\" who were created 6,000 years ago on what is today the Greek island ofPatmosby the biblical and quranic Jacob, whom the group refers to as the \"bigheaded scientist\" Yakub.Though rejected by the vast majority of American Muslims, several NOI breakaway sects, including theFive-Percent Nation, subscribe to this narrative.TheNuwaubian Nation, an NOI offshoot headed byMalachi Z. York, promotes analternative versionof the Yakub story. In contrast to both the Bible and Qu’ran, the NOI and its offshoots teach that Yakub was born inMecca. Although archaeologist and biblical scholarWilliam F. Albrightmaintained (c. 1961) that the narratives of Abraham and Jacob could be dated to about the 19th century BCE,John J. Bimson wrote in 1980: \"Since then ... there has been a strong reaction against the use of archaeological evidence in support of the biblical traditions, and Albright's comment could not be repeated with any truth today.\"Nahum M. Sarna(1978) noted that an inability to date the narratives of the patriarchs does not necessarily invalidate their historicity,a view supported by Bimson, who admitted that \"Our knowledge of the centuries around 2000 BCE is very small, and our ignorance very great.\" Gerhard von Rad, in hisOld Testament Theology(1962) postulated that the patriarchal narratives describe actual events subsequently interpreted by the community through its own experience.Other scholars, such asThomas L. Thompson, view the narratives as late literary compositions (6th and 5th centuries BCE) that have ideological and theological purposes but are unreliable for historical reconstruction of the pre-settlement period of the Israelites.InThe Historicity of the Patriarchal Narratives(1974), Thompson suggested that the narratives arose in a response to some emergent situation, expressed as an imaginative picture of the past to embody hope. InThe Ascent of Man(1973),Jacob Bronowskipointed out similarities between Jacob and Bakhtyar, who lends his name to Iran'sBakhtiari people. Both were herdsmen who had two wives, and are regarded as the ancestral patriarch of their nomadic people. ArchaeologistWilliam G. Deverwrote in 2001: \"After a century of exhaustive investigation, all respectable archaeologists have given up hope of recovering any context that would make Abraham, Isaac, or Jacob 'historical figures.'\"Excavations in theTimna Valleyproduced what may be the earliest camel bones found in Israel or even outside theArabian Peninsula, dating to around 930 BCE. This is seen by some as evidence that the stories of Abraham, Jacob, and Joseph (said to have taken place a thousand years earlier) were written no earlier than the 10th century BCE. Israel Finkelsteinproposed the Jacob-Esau narratives could have originated from 8th century BCEKingdom of Israelbecause the conflict with Edom fits well not only in a Judahite context but also in 8th century BCE Israelite context.Other scholars have suggested that the story could fit also in a 2nd millennium BCE context.Finkelstein suggests there is an archaeological evidence that 8th century Israel interacted with Edom: the graffiti ofKuntillet Ajrudthat mention both a \"YHWH of Samaria\" (center of Israel) and a \"YHWH of Teman\" (center of Edom).He proposed the Jacob-Laban narrative might stem from the 8th century BCE as Haran was then the western capital of the Assyrian empire.He also proposed that the earliest layer of Jacob cycle or the oldest Jacob tradition, which is the story of him and his uncle Laban establishing the border between them, might be a pre-monarchic tradition and could be originated fromGilead.", "combined_text": "Jacob Contents Etymology Hebrew Greek Genesis narrative Birth to Isaac and Rebecca Acquiring Esau's birthright Blessing of Isaac Jacob's Ladder Marriages Journey back to Canaan Famine of the Near East Migration to Egypt Final days: Blessing of Jacob Children of Israel Religious perspectives Judaism Christianity Islam Historicity See also Notes References Further reading External links  Jacob,later known asIsrael,is aHebrew patriarchof theAbrahamic religions. He first appears in theTorah, where he is described in theBook of Genesisas a son ofIsaacandRebecca. Accordingly, alongside his older fraternal twin brotherEsau, Jacob's paternal grandparents areAbrahamandSarahand his maternal grandfather isBethuel, whose wife is not mentioned. He is said to have bought Esau's birthright and, with his mother's help, deceived his aging father to bless him instead of Esau.Then, following a severe drought in his homelandCanaan, Jacob and his descendants migrated to neighbouringEgyptthrough the efforts of his sonJoseph, who had become a confidant of thepharaoh. After dying in Egypt at the age of 147, he is supposed to have been buried in theCave of MachpelahinHebron. Per theHebrew Bible, Jacob's progeny were beget by four women: his wives (and maternal cousins)LeahandRachel; and his concubinesBilhahandZilpah. His sons were, in order of their birth:Reuben,Simeon,Levi,Judah,Dan,Naphtali,Gad,Asher,Issachar,Zebulun, Joseph, andBenjamin. He also had a daughter namedDinah, born to his first wife Leah.The descendants of Jacob's sons were collectively known as theIsraelites, with each son being the forefather of one of theTwelve Tribes of Israel, of whom all but theTribe of Leviwere allotted territory in theLand of Israel. The Genesis narrative also states that Jacob displayed favoritism among his wives and children, preferring Rachel and her sons Joseph and Benjamin to the rest—culminating in Joseph's older brothers selling him into slavery out of resentment. Scholars have taken a mixed view as toJacob's historicity, with archaeology so far producing no evidence for his existence.Archaeologist and scholarWilliam Albrightinitially dated Jacob to the 19th century BCE, but later scholars, such as John J. Bimson andNahum Sarna, argued against using archaeological evidence to support such claims due to limited knowledge of that period. Recent scholarship byThomas L. ThompsonandWilliam Deversuggest that these narratives are late literary compositions with ideological purposes rather than historical accounts. According to thefolk etymologyfound inGenesis25:26, the nameYaʿaqōvיעקבis derived fromʿaqevעָקֵב\"heel\", as Jacob was born grasping the heel of his twin brotherEsau.The historical origin of the name is uncertain, although similar names have been recorded.Yaqub-Haris recorded as a place name in a list byThutmose III(15th century BC), and later as thenomenof aHyksospharaoh. The hieroglyphs are ambiguous, and can be read as \"Yaqub-Har\", \"Yaqubaal\", or \"Yaqub El\". The same name is recorded earlier still, inc.1800 BC, in cuneiform inscriptions (spelledya-ah-qu-ub-el,ya-qu-ub-el).The suggestion that the personal name may be shortened from this compound name, which would translate to \"mayElprotect\", originates with Bright (1960).In theAmorite language, parallel forms of Jacob's name are attested asia-aḫ-qú-ub-DINGIRandia-aḫ-qú-bu-um. The nameIsraelgiven to Jacob following the episode of hiswrestling with the angel(Genesis 32:22–32) is etymologized as composition ofאֵלel\"god\" and the rootשָׂרָהśarah\"to rule, contend, have power, prevail over\":שָׂרִיתָ עִם־אֱלֹהִים(KJV: \"a prince hast thou power withGod\"); alternatively, theelcan be read as the subject, for a translation of \"El rules/contends/struggles\".The word \"strive\" is often used for the proposedetymonשרה, but as Genesis novelly uses the word without defining it, this interpretation is merely based upon the context in the story. TheSeptuagintrenders the nameIákobos(Ancient Greek:Ἰάκωβος), whence LatinJacobus, EnglishJacob. The biblical account of the life of Jacob is found in the Book of Genesis, chapters 25–50. Jacob and his twin brother, Esau, were born toIsaacandRebeccaafter 20 years of marriage, when Isaac was 60 years of age.Rebecca was uncomfortable during her pregnancy and went to inquire of God why she was suffering. She received the prophecy thattwinswere fighting in her womb and would continue to fight all their lives, even after they became two separate nations. The prophecy also said that \"the one people shall be stronger than the other people; and the elder shall serve the younger\"(Genesis 25:25 KJV). When the time came for Rebecca to give birth, the firstborn, Esau, came out covered with red hair, as if he were wearing a hairy garment, and his heel was grasped by the hand of Jacob, the secondborn. According to Genesis 25, Isaac and Rebecca named the first son Esau (Hebrew:עשו).The second son they named Jacob (Hebrew: יעקב, Ya'aqob or Ya'aqov, meaning \"heel-catcher\", \"supplanter\", \"leg-puller\", \"he who follows upon the heels of one\", from Hebrew:עקב,'aqabor'aqav, \"seize by the heel\", \"circumvent\", \"restrain\", a wordplay upon Hebrew:עקבה,'iqqebahor'iqqbah, \"heel\"). The boys displayed very different natures as they matured: \"... and Esau was a cunning hunter, a man of the field; but Jacob was a simple man, dwelling in tents\".Moreover, the attitudes of their parents toward them also differed: \"And Isaac loved Esau, because he did eat of his venison: but Rebecca loved Jacob.\" Genesis 25:29–34 tells the account of Esau selling hisbirthrightto Jacob.This passage tells that Esau, returning famished from the fields, begged Jacob to give him some of the stew that Jacob had just made. (Esau referred to the dish as \"that same red pottage\", giving rise to his nickname, Hebrew:אדום('Edom, meaning \"Red\").) Jacob offered to give Esau a bowl of stew in exchange for his birthright, to which Esau agreed. As Isaac aged, he became blind and was uncertain when he would die, so he decided to bestow Esau's birthright upon him. He requested that Esau go out to the fields with his weapons (quiver and bow) to kill some venison. Isaac then requested that Esau make \"savory meat\" for him out of the venison, according to the way he enjoyed it the most, so that he could eat it and bless Esau. Rebecca overheard this conversation. It is suggested that she realized prophetically that Isaac's blessings would go to Jacob, since she was told before the twins' birth that the older son would serve the younger.Rebecca blessed Jacob and she quickly ordered Jacob to bring her two kid goats from their flock so that he could take Esau's place in serving Isaac and receiving his blessing. Jacob protested that his father would recognize their deception since Esau was hairy and he himself was smooth-skinned. He feared his father would curse him as soon as he felt him, but Rebecca offered to take the curse herself, then insisted that Jacob obey her.Jacob did as his mother instructed and, when he returned with the kids, Rebecca made the savory meat that Isaac loved.  Before she sent Jacob to his father, she dressed him in Esau's garments and laid goatskins on his arms and neck to simulate hairy skin. Disguised as Esau, Jacob entered Isaac's room. Surprised that Esau was back so soon, Isaac asked how it could be that the hunt went so quickly. Jacob responded, \"Because the LORD your God brought it to me.\"Rashisays Isaac's suspicions were aroused even more, because Esau never used the personal name of God.Isaac demanded that Jacob come close so he could feel him, but the goatskins felt just like Esau's hairy skin. Confused, Isaac exclaimed, \"The voice is Jacob's voice, but the hands are the hands of Esau!\"Still trying to get at the truth, Isaac asked him directly, \"Art thou my very son Esau?\" and Jacob answered simply, \"I am.\" Isaac proceeded to eat the food and to drink the wine that Jacob gave him, and then told him to come close and kiss him. As Jacob kissed his father, Isaac smelled the clothes which belonged to Esau and finally accepted that the person in front of him was Esau. Isaac then blessed Jacob with the blessing that was meant for Esau. Genesis 27:28–29 states Isaac's blessing: \"Therefore God give thee of the dew of heavens, and the fatness of the earth, and plenty of corn and wine: Let people serve thee: be lord over thy brethren, and let thy mother's sons bow down to thee: cursed be every one that curseth thee, and blessed be he that blesseth thee.\" Jacob had scarcely left the room when Esau returned from the hunt to prepare his game and receive the blessing. The realization that he had been deceived shocked Isaac, yet he acknowledged that Jacob had received the blessings by adding, \"Indeed, he will be [or remain] blessed!\" (27:33). Esau was heartbroken by the deception and begged for his own blessing. Having made Jacob a ruler over his brothers, Isaac could only promise, \"By your sword you shall live, but your brother you shall serve; yet it shall be that when you are aggrieved, you may cast off his yoke from upon your neck\" (27:39–40). Although Esau sold Jacob his own birthright, which was his blessing, for \"red pottage,\" Esau still hated Jacob for receiving his blessing that their father Isaac unknowingly had given to him. He vowed to kill Jacob as soon as Isaac died. When Rebecca heard about his murderous intentions,she ordered Jacob to travel to her brotherLaban's house inHaran, until Esau's anger subsided. She convinced Isaac to send Jacob away by telling him that she despaired of his marrying a local girl from the idol-worshipping families ofCanaan(as Esau had done). After Isaac sent Jacob away to find a wife, Esau realized his own Canaanite wives were evil in his father's eyes and so he took a daughter of Isaac's half-brother,Ishmael, as another wife. NearLuzen route to Haran, Jacob experienced a vision of a ladder, or staircase, reaching into heaven with angels going up and down it, subsequently referred to in popular culture as \"Jacob's ladder.\" He heard the voice of God, who repeated many of the blessings upon him, coming from the top of the ladder. According toPirkei DeRabbi Eliezer, the ladder signified the exiles that the Jewish people would suffer before the coming of theJewish Messiah: the angels that represented the exiles of Babylonia, Persia, and Greece each climbed up a certain number of steps, paralleling the years of the exile, before they \"fell down\"; but the angel representing the last exile, that ofEdom, kept climbing higher and higher into the clouds. Jacob feared that his descendants would never be free of Esau's domination, but God assured him that at the End of Days, Edom too would come falling down. In the morning, Jacob awakened and continued on his way to Haran, after naming the place where he had spent the night \"Bethel\", \"God's house.\" Arriving in Haran, Jacob saw a well where shepherds were gathering their flocks to water them and metLaban's younger daughter,Rachel, Jacob'sfirst cousin; she was working as a shepherdess. Jacob was 77 years old,and he loved Rachel immediately. After spending a month with his relatives he asked for her hand in marriage in return for working seven years for Laban theAramean. Laban agreed to the arrangement. These seven years seemed to Jacob \"but a few days, for the love he had for her.\" When they were complete and he was 84 years oldhe asked for his wife, but Laban deceived him by switching Rachel for her older sister,Leah, as the veiled bride. In the morning, when the truth became known, Laban justified his action, saying that in his country it was unheard of to give a younger daughter before the older. However, he agreed to give Rachel in marriage as well if Jacob would work another seven years. After the week of wedding celebrations with Leah, Jacob married Rachel, and he continued to work for Laban for another seven years. In those seven years, Jacob fathered twelve children.He loved Rachel more than Leah, and Leah felt hated. God opened Leah's womb and she gave birth to four sons rapidly:Reuben,Simeon,Levi, andJudah. Rachel, however, remained barren. Following the example of Sarah, who gave her handmaid toAbrahamafter years of infertility, Rachel gave her handmaidBilhahto Jacob so that Rachel could raise children through her. Bilhah gave birth toDanandNaphtali. Seeing that she had left off childbearing temporarily, Leah then gave her handmaidZilpahto Jacob so that Leah could raise more children through her. Zilpah gave birth toGadandAsher. Afterwards, Leah became fertile again and gave birth toIssachar,Zebulun, andDinah, Jacob's only daughter. God remembered Rachel, who gave birth toJoseph, and later,Benjamin. After Joseph was born, Jacob decided to return home to his parents. Labanthe Arameanwas reluctant to release him, as God had blessed his flock on account of Jacob. Laban asked what he could pay Jacob. Jacob suggested that all the spotted, speckled, and brown goats and sheep of Laban's flock, at any given moment, would be his wages. Jacob placed rods of poplar, hazel, and chestnut, all of which he peeled \"white streaks upon them,\"within the flocks' watering holes or troughs, associating the stripes of the rods with the growth of stripes on the livestock.Despite this practicing of magic, later on Jacob says to his wives that it was God who made the livestock give birth to the convenient offspring, in order to turn the tide against the deceptive Laban.As time passed, Laban's sons noticed that Jacob was taking the better part of their flocks, and so Laban's friendly attitude towards Jacob began to change. Theangel of the Lord, in a dream back during the breeding season, told Jacob \"Now lift your eyes and see [that] all the he goats mounting the animals are ringed, speckled, and striped, for I have seen all that Laban is doing to you\",that he is the God whom Jacob met at Bethel,and that Jacob should leave and go back to the land where he was born,which he and his wives and children did without informing Laban. Before they left, Rachel stole theteraphim,considered to be householdidols, from Laban's house. Laban pursued Jacob for seven days. The night before he caught up to him, God appeared to Laban in a dream and warned him not to say anything good or bad to Jacob. When the two met, Laban said to Jacob, \"What have you done, that you have tricked me and driven away my daughters like captives of the sword?\"He also asked for his stolenteraphimback. Knowing nothing about Rachel's theft, Jacob told Laban that whoever stole them should die and stood aside to let him search. When Laban reached Rachel's tent, she hid theteraphimby sitting on them and stating she could not get up because she wasmenstruating. Jacob and Laban then parted from each other with a pact to preserve the peace between them nearGilead. Laban returned to his home and Jacob continued on his way. As Jacob neared the land of Canaan as he passedMahanaim, he sent messengers ahead to his brother Esau. They returned with the news that Esau was coming to meet Jacob with an army of 400 men. With great apprehension, Jacob prepared for the worst. He engaged in earnest prayer to God, then sent on before him a tribute of flocks and herds to Esau, \"A present to my lord Esau from thy servant Jacob.\" Jacob then transported his family and flocks across the fordJabbokby night, then recrossed back to send over his possessions, being left alone in communion with God. There, a mysterious being appeared (\"man,\" Genesis 32:24, 28; or \"God,\" Genesis 32:28, 30, Hosea 12:3, 5; or \"angel,\" Hosea 12:4), and the two wrestled until daybreak. When the being saw that he did not overpower Jacob, he touched Jacob on the sinew of his thigh (thegid hanasheh, גיד הנשה), and, as a result, Jacob developed a limp (Genesis 32:31). Because of this, \"to this day the people of Israel do not eat the sinew of the thigh that is on the hip socket\"This incident is the source of themitzvahofporging. Jacob then demanded a blessing, and the being declared in Genesis 32:28 that, from then on, Jacob would be called יִשְׂרָאֵל, Israel (Yisra'el, meaning \"one that struggled with the divine angel\" (Josephus), \"one who has prevailed with God\" (Rashi), \"a man seeing God\" (Whiston), \"he will rule as God\" (Strong), or \"a prince with God\" (Morris), from Hebrew:שרה, \"prevail,\" \"have power as a prince\").While he is still called Jacob in later texts, his name Israel makes some consider him theeponymousancestor of theIsraelites. Jacob asked the being's name, but he refused to answer. Afterwards, Jacob named the placePenuel(Penuw'el,Peniy'el, meaning \"face of God\"),saying: \"I have seen God face to face and lived.\" Because the terminology is ambiguous (\"el\"inYisra'el) and inconsistent, and because this being refused to reveal his name, there are varying views as to whether he was a man, an angel, or God. Josephus uses only the terms \"angel\", \"divine angel,\" and \"angel of God,\" describing the struggle as no small victory. According to Rashi, the being was the guardian angel of Esau himself, sent to destroy Jacob before he could return to the land of Canaan. Trachtenberg theorized that the being refused to identify itself for fear that, if its secret name was known, it would be conjurable by incantations.Literal Christian interpreters likeHenry M. Morrissay that the stranger was \"God Himself and, therefore, Christ in His preincarnate state\", citing Jacob's own evaluation and the name he assumed thereafter, \"one who fights victoriously with God\", and adding that God had appeared in the human form of theAngel of the Lordto eat a meal with Abraham in Genesis 18.Geller wrote that, \"in the context of the wrestling bout, the name implies that Jacob won this supremacy, linked to that of God's, by a kind oftheomachy.\" In the morning, Jacob assembled his four wives and 11 sons, placing the maidservants and their children in front, Leah and her children next, and Rachel and Joseph in the rear. Some commentators cite this placement as proof that Jacob continued to favor Joseph over Leah's children, as presumably the rear position would have been safer from a frontal assault by Esau, which Jacob feared. Jacob himself took the foremost position. Esau's spirit of revenge, however, was apparently appeased by Jacob's bounteous gifts of camels, goats and flocks. Their reunion was an emotional one. Esau offered to accompany them on their way back to Israel, but Jacob protested that his children were still young and tender (born six to 13 years prior in the narrative); Jacob suggested eventually catching up with Esau atMount Seir. According to the Sages, this was a prophetic reference to the End of Days, when Jacob's descendants will come to Mount Seir, the home of Edom, to deliver judgment against Esau's descendants for persecuting them throughout the millennia.Jacob actually diverted himself to Succoth and was not recorded as rejoining Esau until, atMachpelah, the two bury their father Isaac, who lived to be 180, and was 60 years older than they were. Jacob then arrived inShechem, where he bought a parcel of land, now identified asJoseph's Tomb. In Shechem, Jacob's daughter Dinah was kidnapped and raped by the ruler's son, who desired to marry the girl. Dinah's brothers, Simeon and Levi, agreed in Jacob's name to permit the marriage as long as all the men of Shechem firstcircumcisedthemselves, ostensibly to unite the children of Jacob in Abraham'scovenantof familial harmony. On the third day after the circumcisions, when all the men of Shechem were still in pain, Simeon and Levi put them all to death by the sword and rescued their sister Dinah, and their brothers plundered the property, women, and children. Jacob condemned this act, saying: \"You have brought trouble on me by making me a stench to theCanaanitesandPerizzites, the people living in this land.\"He later rebuked his two sons for their anger in his deathbed blessing (Genesis 49:5–7). Jacob returned to Bethel, where he had another vision of blessing. Although the death of Rebecca, Jacob's mother, is not explicitly recorded in the Bible, Deborah, Rebecca's nurse, died and was buried at Bethel, at a place that Jacob callsAllon Bachuth(אלון בכות), \"Oak of Weepings\" (Genesis 35:8). According to the Midrash,the plural form of the word \"weeping\" indicates the double sorrow that Rebecca also died at this time. Jacob then made a further move while Rachel was pregnant; nearBethlehem, Rachel went into labor and died as she gave birth to her second son,Benjamin(Jacob's twelfth son). Jacob buried her and erected a monument over her grave.Rachel's Tomb, just outside Bethlehem, remains a popular site for pilgrimages and prayers to this day. Jacob then settled inMigdal Eder, where his firstborn,Reuben, slept with Rachel's servant Bilhah; Jacob's response was not given at the time, but he did condemn Reuben for it later, in his deathbed blessing. Jacob was finally reunited with his father Isaac inMamre(outsideHebron). When Isaac died at the age of 180, Jacob and Esau buried him in theCave of the Patriarchs, which Abraham had purchased as a familyburial plot. At this point in the biblical narrative, two genealogies of Esau's family appear under the headings \"the generations of Esau\". A conservative interpretation is that, at Isaac's burial, Jacob obtained the records of Esau, who had been married 80 years prior, and incorporated them into his own family records, and that Moses augmented and published them. The house of Jacob dwelt inHebron,in the land of Canaan. His flocks were often fed in the pastures ofShechemas well asDothan.Of all the children in his household, he loved Rachel's firstborn son, Joseph, the most. Thus Joseph's half brothers were jealous of him and they ridiculed him often. Joseph even told his father about all of his half brothers' misdeeds. When Joseph was 17 years old, Jacob made a long coat ortunic of many colorsfor him. Seeing this, the half brothers began to hate Joseph. Then Joseph began to have dreams that implied that his family would bow down to him. When he told his brothers about such dreams, it drove them to conspire against him. When Jacob heard of these dreams, he rebuked his son for proposing the idea that the house of Jacob would even bow down to Joseph. Yet, he contemplated his son's words about these dreams. Sometime afterward, the sons of Jacob by Leah, Bilhah and Zilpah, were feeding his flocks in Shechem. Jacob wanted to know how things were doing, so he asked Joseph to go down there and return with a report.This was the last time he would ever see his son in Hebron. Later that day, the report that Jacob ended up receiving came from Joseph's brothers who brought before him a coat laden with blood from a goat. Jacob identified the coat as the one he made for Joseph. At that moment he cried, \"It is my son's tunic. A wild beast has devoured him. Without doubt Joseph is torn to pieces.\" He tore his clothes and put sackcloth around his waist mourning for days. No one from the house of Jacob could comfort him during this time of bereavement. The truth was that Joseph's older brothers had turned on him, apprehended him and ultimately sold him into slavery on a caravan headed for Egypt. Twenty years later,throughout the Middle East a severe famine occurred like none other that lasted seven years.It crippled nations.The word was that the only kingdom prospering was Egypt. In the second year of this great famine,when Israel (Jacob) was about 130 years old,he told his 10 sons of Leah, Bilhah and Zilpah, to go to Egypt and buy grain. Israel's youngest son Benjamin, born from Rachel, stayed behind by his father's order to keep him safe. Nine of the sons returned to their father Israel from Egypt, stockpiled with grain on their donkeys. They relayed to their father all that had happened in Egypt. They spoke of being accused as spies and that their brother Simeon had been taken prisoner. When Reuben, the eldest, mentioned that they needed to bring Benjamin to Egypt to prove their word as honest men, their father became furious with them. He couldn't understand how they were put in a position to tell the Egyptians all about their family. When the sons of Israel opened their sacks, they saw their money that they used to pay for the grain. It was still in their possession, and so they all became afraid. Israel then became angry with the loss of Joseph, Simeon, and now possibly Benjamin. It turned out that Joseph, who identified his brothers in Egypt, was able to secretly return the money that they used to pay for the grain, back to them.When the house of Israel consumed all the grain that they brought from Egypt, Israel told his sons to go back and buy more. This time, Judah spoke to his father in order to persuade him about having Benjamin accompany them, so as to prevent Egyptian retribution. In hopes of retrieving Simeon and ensuring Benjamin's return, Israel told them to bring the best fruits of their land, including:balm,honey, spices,myrrh,pistachionuts andalmonds. Israel also mentioned that the money that was returned to their money sacks was probably a mistake or an oversight on their part. So, he told them to bring that money back and use double that amount to pay for the new grain. Lastly, he let Benjamin go with them and said \"may God Almighty give you mercy... If I am bereaved, I am bereaved!\" When the sons of Israel (Jacob) returned to Hebron from their second trip, they came back with 20 additional donkeys carrying all kinds of goods and supplies as well as Egyptian transport wagons. When their father came out to meet them, his sons told him that Joseph was still alive, that he was the governor over all of Egypt and that he wanted the house of Israel to move to Egypt. Israel's heart \"stood still\" and just couldn't believe what he was hearing. Looking upon the wagons he declared \"Joseph my son is still alive. I will go and see him before I die.\" Israel and his entire house of 70,gathered up with all their livestock and began their journey to Egypt. En route, Israel stopped atBeershebafor the night to make a sacrificial offering to his God, Yahweh. Apparently he had some reservations about leaving the land of his forefathers, but God reassured him not to fear that he would rise again. God also assured that he would be with him, he would prosper, and he would also see his son Joseph who would lay him to rest. Continuing their journey to Egypt, when they approached in proximity, Israel sent his son Judah ahead to find out where the caravans were to stop. They were directed to disembark atGoshen. It was here, after 22 years, that Jacob saw his son Joseph once again. They embraced each other and wept together for quite a while. Israel then said, \"Now let me die, since I have seen your face, because you are still alive.\" The time had come for Joseph's family to personally meet thePharaohof Egypt. After Joseph prepared his family for the meeting, the brothers came before the Pharaoh first, formally requesting to pasture in Egyptian lands. The Pharaoh honored their stay and even made the notion that if there were any competent men in their house, then they may elect a chief herdsman to oversee Egyptian livestock. Finally, Joseph's father was brought out to meet the Pharaoh. Because the Pharaoh had such a high regard for Joseph, practically making him his equal,it was an honor to meet his father. Thus, Israel was able to bless the Pharaoh. The two chatted for a bit, the Pharaoh even inquiring of Israel's age which happened to be 130 years old at that time. After the meeting, the families were directed to pasture in the land of Ramses where they lived in the province of Goshen. The house of Israel acquired many possessions and multiplied exceedingly during the course of 17 years, even through the worst of the seven-year famine. Israel (Jacob) was 147 years old when he called to his favorite son Joseph and pleaded that he not be buried in Egypt. Rather, he requested to be carried to the land of Canaan to be buried with his forefathers. Joseph swore to do as his father asked of him. Not too long afterward, Israel had fallen ill, losing much of his vision. When Joseph came to visit his father, he brought with him his two sons, Ephraim and Manasseh. Israel declared that they would be heirs to the inheritance of the house of Israel, as if they were his own children, just as Reuben and Simeon were. Then Israel laid his right hand on the younger Ephraim's head and his left hand on the eldest Manasseh's head and blessed Joseph. However, Joseph was displeased that his father's right hand was not on the head of his firstborn, so he switched his father's hands. But Israel refused saying, \"but truly his younger brother shall be greater than he.\" A declaration he made, just as Israel himself was to his firstborn brother Esau. Then Israel called all of his sons in and prophesied their blessings or curses to all twelve of them in order of their ages. Afterward, Israel died and the family, including the Egyptians, mourned him 70 days. Israel was embalmed for 40 days and a great ceremonial journey to Canaan was prepared by Joseph. He led the servants of Pharaoh, and the elders of the houses Israel and Egypt beyond theJordan RivertoAtadwhere they observed seven days of mourning. Their lamentation was so great that it caught the attention of surrounding Canaanites who remarked \"This is a deep mourning of the Egyptians.\" This spot was then namedAbel Mizraim. Then they buried him in the cave ofMachpelah, the property of Abraham when he bought it from the HittiteEphron. Jacob, through his two wives and his two concubines had 12 biological sons;Reuben,Simeon,Levi,Judah,Dan,Naphtali,Gad,Asher,Issachar,Zebulun,JosephandBenjamin.The scene of Jacob mourning Joseph makes mention of him having a number of daughters,but no details are provided. Only one daughter,Dinah, is known by name.In addition, Jacob also adopted the two sons of Joseph,ManassehandEphraim. The offspring of Jacob's sons became thetribes of Israelfollowingthe Exodus, when the Israelites conquered and settled in theLand of Israel. There are two opinions in theMidrashas to how old Rebecca was at the time of her marriage and, consequently, at the twins' birth. According to the traditional counting cited byRashi, Isaac was 37 years old at the time of theBinding of Isaac, and news of Rebecca's birth reached Abraham immediately after that event.In that case, since Isaac was 60 when Jacob and Esau were born and they had been married for 20 years, then Isaac was 40 years old when he married Rebecca (Gen. 25:20), making Rebecca three years old at the time of her marriage, and 23 years old at the birth of Jacob and Esau. According to the second opinion, Rebecca was 14 years old at the time of their marriage, and 34 years old at the birth of Jacob and Esau. In either case, Isaac and Rebecca were married for 20 years before Jacob and Esau were born. The Midrash says that during Rebecca's pregnancy whenever she would pass a house of Torah study, Jacob would struggle to come out; whenever she would pass a house ofidolatry, Esau would agitate to come out. Rashi explained that Isaac, when blessing Jacob instead of Esau, smelled the heavenly scent ofGan Eden(Paradise) when Jacob entered his room and, in contrast, perceivedGehennaopening beneath Esau when the latter entered the room, showing him that he had been deceived all along by Esau's show of piety. According to the Talmud, Jacob did not flee directly to Haran (as would seem from the Biblical text), but rather studied for 14 years at thestudy house of Shem and Eberbefore continuing towards Haran. When Laban planned to deceive Jacob into marrying Leah instead of Rachel, theMidrashrecounts that both Jacob and Rachel suspected that Laban would pull such a trick; Laban was known as the \"Aramean\" (deceiver), and changed Jacob's wages ten times during his employ (Genesis 31:7). The couple therefore devised a series of signs by which Jacob could identify the veiled bride on his wedding night. But when Rachel saw her sister being taken out to the wedding canopy, her heart went out to her for the public shame Leah would suffer if she were exposed. Rachel therefore gave Leah the signs so that Jacob would not realize the switch. Jacob had still another reason for grieving the loss of Joseph. God had promised to him: \"If none of your sons dies during your lifetime, you may look upon it as a token that you will not be put in (Hellof)Gehennaafter your death.\"Thinking Joseph to be dead, Jacob had his own destiny to lament because he considered that he was doomed to that Hell. Jewishapocalyptic literatureof the Hellenistic period includes many ancient texts with narratives about Jacob, many times with details different from Genesis. The more important are theBook of Jubileesand theBook of Biblical Antiquities. Jacob is also the protagonist of theTestament of Jacob, of theLadder of Jacoband of thePrayer of Joseph, which interpret the experience of this Patriarch in the context ofmerkabahmysticism. TheEastern Orthodox Churchand thoseEastern Catholic Churcheswhich follow theByzantine Ritesee Jacob's dream as aprophecyof theincarnationof theLogos, wherebyJacob's ladderis understood as a symbol of theTheotokos(Virgin Mary), who, according toEastern Orthodox theology, united heaven and earth in her womb.The biblical account of this visionis one of the standard Old Testament readings atVespersonGreat Feastsof the Theotokos. The Eastern and Western Churches consider Jacob as asaintalong with otherbiblical patriarchs.Along with other patriarchs his feast day is celebrated in the Byzantine rite on the Second Sunday before the Advent (December 11–17), under the titlethe Sunday of the Forefathers. Two further references toIsra'il(Arabic: إِسْرَآئِیل [ˈisraāˈiyl]; Classical/ Quranic Arabic: إِسْرَآءِیْل [ˈisraāãˈiyl]) are believed to be mention of Jacob. The Arabic formYa'qūb(Arabic:يَعْقُوب,romanized:Yaʿqūb) may be direct from theHebrewor indirect throughSyriac. He is recognized inIslamas aprophetwho received inspiration from God. He is acknowledged as apatriarchofIslam. Muslims believe that he preached the same monotheistic faith as his forefathersʾIbrāhīm,ʾIsḥāqandIsmā'īl. Jacob is mentioned 16 times in theQuran.In the majority of these references, Jacob is mentioned alongside fellowprophetsandpatriarchsas an ancient and pious prophet. According to the Quran, Jacob remained in the company of the elect throughout his life. (38:47) The Quran specifically mentions that Jacob was guided (6:84) and inspired (4:163) and was chosen to enforce the awareness of the Hereafter. (38:46) Jacob is described as a good-doer (21:72) and the Quran further makes it clear that God inspired Jacob to contribute towards purification and hold the contact prayer. (21:73) Jacob is further described as being resourceful and a possessor of great vision (38:45) and is further spoken of as being granted a \"tongue [voice] of truthfulness to be heard.\" (19:50) Of the life of Jacob, the Quran narrates two especially important events. The first is the role he plays in the story of his sonJoseph. The Quran narrates the story of Joseph in detail, and Jacob, being Joseph's father, is mentioned thrice and is referenced another 25 times.In the narrative, Jacob does not trust some of his older sons (12: 11, 18, 23) because they do not respect him. (12: 8, 16–17) Jacob's prophetic nature is evident from his foreknowledge of Joseph's future greatness (12:6), his foreboding and response to the supposed death of Joseph (12: 13, 18) and in his response to the sons' plight inEgypt. (12: 83, 86–87, 96) Islamic literature fleshes out the narrative of Jacob, and mentions that his wives includedRachel.Jacob is later mentioned in the Quran in the context of the promise bestowed toZechariah, regarding the birth ofJohn the Baptist. (19:6) Jacob's second mention is in the Quran's second chapter. As Jacob lay on his deathbed, he asked his 12 sons to testify their faith to him before he departed from this world to the next. (2:132) Each son testified in front of Jacob that they would promise to remain Muslim (in submission to God) until the day of their death; that is they would surrender their wholeselves to God alone and would worship only Him. In contrast to theJudeo-Christianview of Jacob, one main difference is that the story of Jacob's blessing, in which he deceives Isaac, is not accepted in Islam. The Quran makes it clear that Jacob was blessed byGodas a prophet and, therefore, Muslims believe that his father, being a prophet as well, also knew of his son's greatness.Jacob is also cited in theHadithas an example of one who was patient and trusting in God in the face of suffering. According to the teachings of theNation of Islam(NOI), the original inhabitants of the world were black (referred to as the \"Asiatic Blackman\"), while the white race are \"devils\" who were created 6,000 years ago on what is today the Greek island ofPatmosby the biblical and quranic Jacob, whom the group refers to as the \"bigheaded scientist\" Yakub.Though rejected by the vast majority of American Muslims, several NOI breakaway sects, including theFive-Percent Nation, subscribe to this narrative.TheNuwaubian Nation, an NOI offshoot headed byMalachi Z. York, promotes analternative versionof the Yakub story. In contrast to both the Bible and Qu’ran, the NOI and its offshoots teach that Yakub was born inMecca. Although archaeologist and biblical scholarWilliam F. Albrightmaintained (c. 1961) that the narratives of Abraham and Jacob could be dated to about the 19th century BCE,John J. Bimson wrote in 1980: \"Since then ... there has been a strong reaction against the use of archaeological evidence in support of the biblical traditions, and Albright's comment could not be repeated with any truth today.\"Nahum M. Sarna(1978) noted that an inability to date the narratives of the patriarchs does not necessarily invalidate their historicity,a view supported by Bimson, who admitted that \"Our knowledge of the centuries around 2000 BCE is very small, and our ignorance very great.\" Gerhard von Rad, in hisOld Testament Theology(1962) postulated that the patriarchal narratives describe actual events subsequently interpreted by the community through its own experience.Other scholars, such asThomas L. Thompson, view the narratives as late literary compositions (6th and 5th centuries BCE) that have ideological and theological purposes but are unreliable for historical reconstruction of the pre-settlement period of the Israelites.InThe Historicity of the Patriarchal Narratives(1974), Thompson suggested that the narratives arose in a response to some emergent situation, expressed as an imaginative picture of the past to embody hope. InThe Ascent of Man(1973),Jacob Bronowskipointed out similarities between Jacob and Bakhtyar, who lends his name to Iran'sBakhtiari people. Both were herdsmen who had two wives, and are regarded as the ancestral patriarch of their nomadic people. ArchaeologistWilliam G. Deverwrote in 2001: \"After a century of exhaustive investigation, all respectable archaeologists have given up hope of recovering any context that would make Abraham, Isaac, or Jacob 'historical figures.'\"Excavations in theTimna Valleyproduced what may be the earliest camel bones found in Israel or even outside theArabian Peninsula, dating to around 930 BCE. This is seen by some as evidence that the stories of Abraham, Jacob, and Joseph (said to have taken place a thousand years earlier) were written no earlier than the 10th century BCE. Israel Finkelsteinproposed the Jacob-Esau narratives could have originated from 8th century BCEKingdom of Israelbecause the conflict with Edom fits well not only in a Judahite context but also in 8th century BCE Israelite context.Other scholars have suggested that the story could fit also in a 2nd millennium BCE context.Finkelstein suggests there is an archaeological evidence that 8th century Israel interacted with Edom: the graffiti ofKuntillet Ajrudthat mention both a \"YHWH of Samaria\" (center of Israel) and a \"YHWH of Teman\" (center of Edom).He proposed the Jacob-Laban narrative might stem from the 8th century BCE as Haran was then the western capital of the Assyrian empire.He also proposed that the earliest layer of Jacob cycle or the oldest Jacob tradition, which is the story of him and his uncle Laban establishing the border between them, might be a pre-monarchic tradition and could be originated fromGilead.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Jacob", "https://en.wikipedia.org/wiki/Jacob", "https://en.wikipedia.org/wiki/Jacob", "https://en.wikipedia.org/wiki/Jacob_(name)", "https://en.wikipedia.org/wiki/Jacob_(disambiguation)", "https://en.wikipedia.org/wiki/Jan_Victors", "https://en.wikipedia.org/wiki/Cave_of_Machpelah", "https://en.wikipedia.org/wiki/Hebron"]},
{"id": "5279a23639ba", "url": "https://en.wikipedia.org/wiki/Glossary_of_philosophy", "title": "Glossary of philosophy", "headings": ["A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L", "M", "N", "O", "P", "Q", "R", "S", "T", "U", "V", "W", "Y", "Z", "See also", "References", "External links"], "content": " Thisglossary of philosophyis a list of definitions of terms and concepts relevant tophilosophyand related disciplines, includinglogic,ethics, andtheology. Also calledhumanocentrism. Also calledsurrealist automatism Also calledbiological determinism. Also calledcreation theology. Also called thedescriptivist theory of names. Also calledextropy. PhilanthropyPhilanthropyis a form ofaltruismthat consists of \"private initiatives for thepublic good, focusing onquality of life\". Philanthropy contrasts with business initiatives, which are private initiatives for private good, focusing on material gain; and with government endeavors that are public initiatives for public good, such as those that focus on the provision of public services. A person who practices philanthropy is aphilanthropist. Also calledRestitution creationismorRuin-Reconstruction. Also calledlogical empiricism,rational empiricism, andneo-positivism. Also calleddirect realismandcommon sense realism. Also calledautocracy. PhilanthropyPhilanthropyis a form ofaltruismthat consists of \"private initiatives for thepublic good, focusing onquality of life\". Philanthropy contrasts with business initiatives, which are private initiatives for private good, focusing on material gain; and with government endeavors that are public initiatives for public good, such as those that focus on the provision of public services. A person who practices philanthropy is aphilanthropist. Also known asscientific humanism. Also calledexplicit agnosticismandpositive agnosticism.", "combined_text": "Glossary of philosophy A B C D E F G H I J K L M N O P Q R S T U V W Y Z See also References External links  Thisglossary of philosophyis a list of definitions of terms and concepts relevant tophilosophyand related disciplines, includinglogic,ethics, andtheology. Also calledhumanocentrism. Also calledsurrealist automatism Also calledbiological determinism. Also calledcreation theology. Also called thedescriptivist theory of names. Also calledextropy. PhilanthropyPhilanthropyis a form ofaltruismthat consists of \"private initiatives for thepublic good, focusing onquality of life\". Philanthropy contrasts with business initiatives, which are private initiatives for private good, focusing on material gain; and with government endeavors that are public initiatives for public good, such as those that focus on the provision of public services. A person who practices philanthropy is aphilanthropist. Also calledRestitution creationismorRuin-Reconstruction. Also calledlogical empiricism,rational empiricism, andneo-positivism. Also calleddirect realismandcommon sense realism. Also calledautocracy. PhilanthropyPhilanthropyis a form ofaltruismthat consists of \"private initiatives for thepublic good, focusing onquality of life\". Philanthropy contrasts with business initiatives, which are private initiatives for private good, focusing on material gain; and with government endeavors that are public initiatives for public good, such as those that focus on the provision of public services. A person who practices philanthropy is aphilanthropist. Also known asscientific humanism. Also calledexplicit agnosticismandpositive agnosticism.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Glossary_of_philosophy", "https://en.wikipedia.org/wiki/Glossary_of_philosophy", "https://en.wikipedia.org/wiki/Glossary_of_philosophy", "https://en.wikipedia.org/wiki/List_of_philosophies", "https://en.wikipedia.org/wiki/List_of_philosophical_concepts", "https://en.wikipedia.org/wiki/Philosophy", "https://en.wikipedia.org/wiki/Logic", "https://en.wikipedia.org/wiki/Ethics"]},
{"id": "e9646243d2c5", "url": "https://en.wikipedia.org/wiki/Manualism", "title": "Manualism", "headings": ["Contents", "Origins", "Early deaf education in America", "Decline", "Revival", "See also", "References"], "content": "Manualismis a method ofeducation of deaf studentsusingsign languagewithin the classroom.Manualism arose in the late 18th century with the advent of free public schools for the deaf in Europe. These teaching methods were brought over to the United States where thefirst school for the deafwas established in 1817. Today manualism methods are used in conjunction withoralismmethods in the majority of American deaf schools. The first manual schools were inParis, France.Abbe de l’Épée, a Catholic priest, encountered two teenage deaf girls while he visited a family in the poor part of the city. He decided to take it upon himself to educate them. He invented a technique called \"methodical signing\" from the signs the girls already used, with the combination of methods influenced by the writings ofJohann Konrad AmmannandJuan Pablo Bonet. He created a one-hand manual alphabet to be able tofingerspellFrench words. L’Épée opened a free national school for the deaf in his home, on 14 Moulins Street (now called Thérèse Street). After his death in 1789,Abbé Roch-Ambroise Cucurron Sicardtook over as head of the school;it was renamedInstitut National de Jeunes Sourds de Paris. The school received monetary support from individuals and grants fromKing Louis XVI. Laurent Clerc, a graduate from the school and pupil of l’Épée and Sicard, returned to the school as a teacher. He was teaching there in 1816 whenThomas Hopkins Gallaudetvisited. Gallaudet met nine-year-oldAlice Cogswellwho knew no form of communication system. He learned of Sicard's theories and started tutoring Alice. Gallaudet traveled to Europe in May 1815 and attended demonstrations in France led by Sicard, Clerc, andMassieu. He returned in March 1816 and persuaded Clerc to return with him to the United States. Back in the US, they searched for funds and public support. Together, they established the first deaf school in the United States on April 15, 1817, inHartford, Connecticut; it was named theConnecticut Asylum for the Education and Instruction of Deaf and Dumb Persons. The school taught inFrench Sign Languageand a version of de l’Épée's methodical sign taught by Clerc and Thomas Hopkins Gallaudet.The students attending the school had some knowledge of an indigenous sign language used inMartha's Vineyard, Massachusetts. Out of the blend ofMartha's Vineyard Sign Languageand French Sign Language, emergedAmerican Sign Language. Manual education remained the primary method to educate deaf people until the 1860s. People then begin to subscribe to moreoralistmethods of education:lip readingand speech training. In 1867, the first private oral school opened inNew York City.The oral movement took off in full swing at theMilan Conference of 1880in whichAlexander Graham Belldeclared oral methods superior to manual methods. After the conference, schools all around Europe and the United States switched to using speech and lipreading, banning all sign language from the classroom. Thedeaf communitywas left in what some call the \"dark ages\". While working atGallaudet Universityin the 1960s,William Stokoefelt that American Sign Language was a language in its own right, with its own independent syntax and grammar. Stokoe classified the language into five parts which included: handshapes, orientation, location, movement, and facial expression in which much of the meaning of the sign is clarified as well as the grammar of the sentence expressed.Some sign languages, such as American Sign Language, have been promoted as the traditional way of communication for deaf people.Manualism is combined with oralismas the contemporary technique for the education of deaf students.", "combined_text": "Manualism Contents Origins Early deaf education in America Decline Revival See also References Manualismis a method ofeducation of deaf studentsusingsign languagewithin the classroom.Manualism arose in the late 18th century with the advent of free public schools for the deaf in Europe. These teaching methods were brought over to the United States where thefirst school for the deafwas established in 1817. Today manualism methods are used in conjunction withoralismmethods in the majority of American deaf schools. The first manual schools were inParis, France.Abbe de l’Épée, a Catholic priest, encountered two teenage deaf girls while he visited a family in the poor part of the city. He decided to take it upon himself to educate them. He invented a technique called \"methodical signing\" from the signs the girls already used, with the combination of methods influenced by the writings ofJohann Konrad AmmannandJuan Pablo Bonet. He created a one-hand manual alphabet to be able tofingerspellFrench words. L’Épée opened a free national school for the deaf in his home, on 14 Moulins Street (now called Thérèse Street). After his death in 1789,Abbé Roch-Ambroise Cucurron Sicardtook over as head of the school;it was renamedInstitut National de Jeunes Sourds de Paris. The school received monetary support from individuals and grants fromKing Louis XVI. Laurent Clerc, a graduate from the school and pupil of l’Épée and Sicard, returned to the school as a teacher. He was teaching there in 1816 whenThomas Hopkins Gallaudetvisited. Gallaudet met nine-year-oldAlice Cogswellwho knew no form of communication system. He learned of Sicard's theories and started tutoring Alice. Gallaudet traveled to Europe in May 1815 and attended demonstrations in France led by Sicard, Clerc, andMassieu. He returned in March 1816 and persuaded Clerc to return with him to the United States. Back in the US, they searched for funds and public support. Together, they established the first deaf school in the United States on April 15, 1817, inHartford, Connecticut; it was named theConnecticut Asylum for the Education and Instruction of Deaf and Dumb Persons. The school taught inFrench Sign Languageand a version of de l’Épée's methodical sign taught by Clerc and Thomas Hopkins Gallaudet.The students attending the school had some knowledge of an indigenous sign language used inMartha's Vineyard, Massachusetts. Out of the blend ofMartha's Vineyard Sign Languageand French Sign Language, emergedAmerican Sign Language. Manual education remained the primary method to educate deaf people until the 1860s. People then begin to subscribe to moreoralistmethods of education:lip readingand speech training. In 1867, the first private oral school opened inNew York City.The oral movement took off in full swing at theMilan Conference of 1880in whichAlexander Graham Belldeclared oral methods superior to manual methods. After the conference, schools all around Europe and the United States switched to using speech and lipreading, banning all sign language from the classroom. Thedeaf communitywas left in what some call the \"dark ages\". While working atGallaudet Universityin the 1960s,William Stokoefelt that American Sign Language was a language in its own right, with its own independent syntax and grammar. Stokoe classified the language into five parts which included: handshapes, orientation, location, movement, and facial expression in which much of the meaning of the sign is clarified as well as the grammar of the sentence expressed.Some sign languages, such as American Sign Language, have been promoted as the traditional way of communication for deaf people.Manualism is combined with oralismas the contemporary technique for the education of deaf students.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Manualism", "https://en.wikipedia.org/wiki/Manualism", "https://en.wikipedia.org/wiki/Manualism", "https://en.wikipedia.org/wiki/Manualism_(hand_music)", "https://en.wikipedia.org/wiki/Education_of_the_deaf", "https://en.wikipedia.org/wiki/Sign_language", "https://en.wikipedia.org/wiki/American_School_for_the_Deaf", "https://en.wikipedia.org/wiki/Oralism"]},
{"id": "3edeed2ccd81", "url": "https://en.wikipedia.org/wiki/Whitehouse.gov", "title": "whitehouse.gov", "headings": ["Contents", "Content", "Site differences in each administration", "Civic engagement", "Platform", "See also", "Notes", "References", "External links"], "content": " whitehouse.govorwh.govis the officialwebsiteof theWhite Houseand is managed by theOffice of Digital Strategyof theWhite House Officeunder theExecutive Office of the President of the United States. It was launched in 1994 by theClinton administration.The content of the website is in thepublic domainor licensed underCreative Commons Attributionlicense. The content of the White House website is designed to be an open portfolio for the public to know the current operations of the president during their presidency. The website contains information about thepresident, thevice president, their families, press releases, proclamations,executive orders, and a transcript of speeches by White House officials, though in May 2025,Donald Trumphad nearly all of his transcripts from hissecond presidencyremoved and replaced by limited video footageafter it was revealed that only 20% had been posted. The website also provides information about the current issues the president and vice president address (likeeducation,healthcare, etc.), also providing information about the history of the White House building,Air Force One, andCamp David. The website also reviews the structure of theFederal Government of the United States, including details aboutstateandlocal government, along with voting and elections. The website also offers information about getting involved with the White House. This includes directions on how to write or call the White House, as well as details about theWhite House Internship Programand theWhite House Fellows Program. The site also contains information about the currentCabinet of the United Statesand theExecutive Office of the President of the United States. After a new administration is sworn in onInauguration Day, the website is immediately redesigned for the new administration. Past administration websites are archived by theNational Archives. On September 1, 2011,David Plouffe,Senior Advisor to the President of the United StatestoBarack Obama, announced in an email that the White House was releasing \"We the People\", an online platform for the public to create petitions to the US Government. The launch of the petitioning platform was announced by Katelyn Sabochik on September 22, 2011, in a White House blog post. On December 19, 2017, theTrump administrationannounced its intention to temporarily shut down the platform and replace it with a \"new platform [that] would save taxpayers more than $1m a year\", though ultimately it was retained in its initial form.On January 20, 2021, the day of theinauguration of Joe Biden, the platform started redirecting to the main whitehouse.gov domain, marking the discontinuance of the feature by the incoming administration. It has not been relaunched since. In July 2001,theWhite Housestarted switching theirweb serversto an operating system based onRed Hat Linuxand using theApache HTTP Server.The installation was completed in February 2009.In October 2009, the White House web servers adoptedDrupal, afree and open-sourcecontent management system,which runs onRed Hat Enterprise Linux. In December 2017, theTrump administrationlaunched a redesigned website developed usingWordPresswhich it claimed would save taxpayers \"almost $3 million per year\".", "combined_text": "whitehouse.gov Contents Content Site differences in each administration Civic engagement Platform See also Notes References External links  whitehouse.govorwh.govis the officialwebsiteof theWhite Houseand is managed by theOffice of Digital Strategyof theWhite House Officeunder theExecutive Office of the President of the United States. It was launched in 1994 by theClinton administration.The content of the website is in thepublic domainor licensed underCreative Commons Attributionlicense. The content of the White House website is designed to be an open portfolio for the public to know the current operations of the president during their presidency. The website contains information about thepresident, thevice president, their families, press releases, proclamations,executive orders, and a transcript of speeches by White House officials, though in May 2025,Donald Trumphad nearly all of his transcripts from hissecond presidencyremoved and replaced by limited video footageafter it was revealed that only 20% had been posted. The website also provides information about the current issues the president and vice president address (likeeducation,healthcare, etc.), also providing information about the history of the White House building,Air Force One, andCamp David. The website also reviews the structure of theFederal Government of the United States, including details aboutstateandlocal government, along with voting and elections. The website also offers information about getting involved with the White House. This includes directions on how to write or call the White House, as well as details about theWhite House Internship Programand theWhite House Fellows Program. The site also contains information about the currentCabinet of the United Statesand theExecutive Office of the President of the United States. After a new administration is sworn in onInauguration Day, the website is immediately redesigned for the new administration. Past administration websites are archived by theNational Archives. On September 1, 2011,David Plouffe,Senior Advisor to the President of the United StatestoBarack Obama, announced in an email that the White House was releasing \"We the People\", an online platform for the public to create petitions to the US Government. The launch of the petitioning platform was announced by Katelyn Sabochik on September 22, 2011, in a White House blog post. On December 19, 2017, theTrump administrationannounced its intention to temporarily shut down the platform and replace it with a \"new platform [that] would save taxpayers more than $1m a year\", though ultimately it was retained in its initial form.On January 20, 2021, the day of theinauguration of Joe Biden, the platform started redirecting to the main whitehouse.gov domain, marking the discontinuance of the feature by the incoming administration. It has not been relaunched since. In July 2001,theWhite Housestarted switching theirweb serversto an operating system based onRed Hat Linuxand using theApache HTTP Server.The installation was completed in February 2009.In October 2009, the White House web servers adoptedDrupal, afree and open-sourcecontent management system,which runs onRed Hat Enterprise Linux. In December 2017, theTrump administrationlaunched a redesigned website developed usingWordPresswhich it claimed would save taxpayers \"almost $3 million per year\".", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Whitehouse.gov", "https://en.wikipedia.org/wiki/Whitehouse.gov", "https://en.wikipedia.org/wiki/Whitehouse.gov", "https://en.wikipedia.org/wiki/Federal_government_of_the_United_States", "https://en.wikipedia.org/wiki/URL_shortening", "https://en.wikipedia.org/wiki/WordPress", "https://en.wikipedia.org/wiki/Presidency_of_Bill_Clinton", "https://en.wikipedia.org/wiki/First_inauguration_of_Barack_Obama"]},
{"id": "ae65d03ba18b", "url": "https://en.wikipedia.org/wiki/Awaswas_language", "title": "Awaswas language", "headings": ["Contents", "History", "See also", "Notes", "References", "External links"], "content": "Awaswas, orSanta Cruz, is one of eightOhlone languages. It was historically spoken by theAwaswas people, anindigenous people of California. The last speaker of Awaswas died in the 19th century, and the language has been extinct ever since. Linguists originally called the language Santa Cruz after the mission in the area, but it was renamed to Awaswas as part of a move in the late 1960s and early 1970s by graduate students at the University of California Berkeley to use native names for the Ohlone languages.'Awaswas' is derived from the termʔawas-was, meaning 'north-people from there'. The Awaswas lived in theSanta Cruz Mountainsand along the coast of present-daySanta Cruz Countyfrom present-dayDavenporttoAptos. Awaswas became the main language spoken at theMission Santa Cruz.However, there is evidence that this grouping was more geographic than linguistic, and that the records of the \"Santa Cruz Costanoan\" language in fact represent several diverse dialects. A report from 1952 identified four different distinct forms of Costanoanand a more recent report from 2009 states, \"No area in North America was more crowded with distinct languages and language families than central California at the time of Spanish contact.\" The Ohlone language group is broken into branches with the most related languages grouped together. Awaswas has been grouped in both the northern and southern branches with different research disagreeing on the best fitting classification. Some branches within the Ohlone language group have been described as being as similar to each other as different local dialects of Italian, while others, such asRumsen,Mutsun, and Awaswas \"were as closely related as French, Spanish, and Portuguese.\" In 2012,Amah Mutsun[Wikidata]Tribal Chairman Valentin Lopez stated that \"his great-great-grandmother was the last of the Awaswas speakers.\"", "combined_text": "Awaswas language Contents History See also Notes References External links Awaswas, orSanta Cruz, is one of eightOhlone languages. It was historically spoken by theAwaswas people, anindigenous people of California. The last speaker of Awaswas died in the 19th century, and the language has been extinct ever since. Linguists originally called the language Santa Cruz after the mission in the area, but it was renamed to Awaswas as part of a move in the late 1960s and early 1970s by graduate students at the University of California Berkeley to use native names for the Ohlone languages.'Awaswas' is derived from the termʔawas-was, meaning 'north-people from there'. The Awaswas lived in theSanta Cruz Mountainsand along the coast of present-daySanta Cruz Countyfrom present-dayDavenporttoAptos. Awaswas became the main language spoken at theMission Santa Cruz.However, there is evidence that this grouping was more geographic than linguistic, and that the records of the \"Santa Cruz Costanoan\" language in fact represent several diverse dialects. A report from 1952 identified four different distinct forms of Costanoanand a more recent report from 2009 states, \"No area in North America was more crowded with distinct languages and language families than central California at the time of Spanish contact.\" The Ohlone language group is broken into branches with the most related languages grouped together. Awaswas has been grouped in both the northern and southern branches with different research disagreeing on the best fitting classification. Some branches within the Ohlone language group have been described as being as similar to each other as different local dialects of Italian, while others, such asRumsen,Mutsun, and Awaswas \"were as closely related as French, Spanish, and Portuguese.\" In 2012,Amah Mutsun[Wikidata]Tribal Chairman Valentin Lopez stated that \"his great-great-grandmother was the last of the Awaswas speakers.\"", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Awaswas_language", "https://en.wikipedia.org/wiki/Awaswas_language", "https://en.wikipedia.org/wiki/Awaswas_language", "https://en.wikipedia.org/wiki/Santa_Cruz_language", "https://en.wikipedia.org/wiki/United_States", "https://en.wikipedia.org/wiki/California", "https://en.wikipedia.org/wiki/Extinct_language", "https://en.wikipedia.org/wiki/Language_family"]},
{"id": "47fbb00d3d9e", "url": "https://en.wikipedia.org/wiki/Shell_plc", "title": "Shell plc", "headings": ["Contents", "History", "Origins", "20th century", "21st century", "Corporate affairs", "Business trends", "Management", "Name and logo", "Logo evolution", "Operations", "Business groupings", "Oil and gas activities", "Sponsorships", "Operations by region", "Arctic", "Australia", "Brunei", "China", "India", "Indonesia", "Ireland", "Italy", "Malaysia", "Nigeria", "Nordic countries", "North America", "Philippines", "Russia", "Singapore", "South Africa", "Sri Lanka", "United Kingdom", "Alternative energy", "Ownership", "Controversies", "Carbon capture storage beneath the sea bed", "Processing oil in the Amazon", "Operating in the hump back whale breeding grounds", "Climate change", "Oil spills", "Accusations of greenwashing", "Health and safety", "Reaction to the Russian invasion of Ukraine", "royaldutchshellplc.com", "See also", "Notes", "References", "Bibliography", "Commissioned works", "Other works", "External links"], "content": " Shell plcis a Britishmultinationaloilandgascompany, headquartered inLondon, United Kingdom.Shell is apublic limited companywith a primary listing on theLondon Stock Exchange(LSE) and secondary listings onEuronext Amsterdamand theNew York Stock Exchange. A core component ofBig Oil, Shell is the second largest investor-owned oil and gas company in the world by revenue (afterExxonMobil), and among theworld's largest companiesout of any industry.Measured by both its own emissions, and the emissions of all the fossil fuels it sells, Shell was theninth-largest corporate producer of greenhouse gas emissionsin the period 1988–2015. Shell was formed in April 1907 through themergerofRoyal Dutch Petroleum Companyof the Netherlands andThe \"Shell\" Transport and Trading Companyof the United Kingdom. The combined company rapidly became the leading competitor of the AmericanStandard Oiland by 1920 Shell was the largest producer of oil in the world.Shell first entered the chemicals industry in 1929. Shell was one of the \"Seven Sisters\" which dominated the global petroleum industry from the mid-1940s to the mid-1970s. In 1964, Shell was a partner in the world's first commercial sea transportation ofliquefied natural gas(LNG).In 1970, Shell acquired the mining companyBilliton, which it subsequently sold in 1994 and now forms part ofBHP. In recent decades gas has become an increasingly important part of Shell's businessand Shell acquiredBG Groupin 2016. Shell isvertically integratedand is active in every area of the oil and gas industry, includingexploration,production,refining,transport,distribution and marketing,petrochemicals,power generation, and trading. Shell has operations in over 99 countries,produces around 3.7 millionbarrels of oil equivalentper day and has around 44,000 service stations worldwide.As of 31 December 2019, Shell had total proved reserves of 11.1 billion barrels (1.76×10m) of oil equivalent.Shell USA, its principal subsidiary in the United States, is one of its largest businesses.Shell holds 44%ofRaízen, a publicly listed joint venture withCosan, which is the third-largest Brazil-based energy company.In addition to the main Shell brand, the company also owns theJiffy Lube,PennzoilandQuaker Statebrands. Shell is a constituent of theFTSE 100 Indexand had amarket capitalisationof US$199 billion on 15 September 2022, the largest of any company listed on the LSE and the 44th-largest of any company in the world.In terms of the revenue, Shell generated $284B in 2024, a significant decline over a decade, from $451B in 2013. The Royal Dutch Shell Group was created in April 1907 through the amalgamation of two rival companies: the Royal Dutch Petroleum Company (Dutch:Koninklijke Nederlandse Petroleum Maatschappij) of the Netherlands and The \"Shell\" Transport and Trading Company Limited of the United Kingdom.It was a move largely driven by the need to compete globally withStandard Oil.The Royal Dutch Petroleum Company was a Dutch company founded in 1890 to develop an oilfield inPangkalan Brandan,North Sumatra,and initially led byAugust Kessler, Hugo Loudon, andHenri Deterding. The \"Shell\" Transport and Trading Company (the quotation marks were part of the legal name) was aBritishcompany, founded in 1897 byMarcus Samuel, 1st Viscount Bearsted, and his brotherSamuel Samuel.Their father had owned an antique company inHoundsditch, London,which expanded in 1833 to import and sell seashells, after which the company \"Shell\" took its name. For various reasons, the new firm operated as adual-listed company, whereby the merging companies maintained their legal existence but operated as a single-unit partnership for business purposes. The terms of the merger gave 60 percent stock ownership of the new group to Royal Dutch, and 40 percent to Shell. Both becameholding companiesforBataafsche Petroleum Maatschappij, containing the production and refining assets, and Anglo-Saxon Petroleum Company, containing the transport and storage assets.National patriotic sensibilities would not permit a full-scale merger or takeover of either of the two companies.The Dutch company,Koninklijke Nederlandsche Petroleum MaatschappijatThe Hague, was in charge of production and manufacture.The BritishAnglo-Saxon Petroleum Companywas based in London, to direct the transport and storage of the products. In 1912, Royal Dutch Shell purchased theRothschilds'Russian oil assetsin a stock deal. The Group's production portfolio then consisted of 53 percent from theEast Indies, 29 percent from theRussian Empire, and 17 percent fromRomania. During theFirst World War, Shell was the main supplier of fuel to theBritish Expeditionary Force.It was also the sole supplier ofaviation fueland supplied 80 percent of the British Army'sTNT.It also volunteered all of its shipping to theBritish Admiralty. TheGerman invasion of Romaniain 1916 saw 17% of the group's worldwide production destroyed.In 1919, Shell took control of theMexican Eagle Petroleum Companyand in 1921 formed Shell-Mex Limited, which marketed products under the \"Shell\" and \"Eagle\" brands in the United Kingdom. During theGenoa Conferenceof 1922 Royal Dutch Shell was in negotiations for a monopoly over Soviet oilfields inBakuandGrosny, although the leak of a draft treaty led to breakdown of the talks.In 1929,Shell Chemicalswas founded.By the end of the 1920s, Shell was the world's leading oil company, producing 11 percent of the world'scrude oilsupply and owning 10 percent of its tanker tonnage. During theSpanish Civil Warthe company sold oil to the Nationalist side ofFrancisco Franco. Located in the north bank of theRiver Thamesin London,Shell Mex Housewas completed in 1931, and was the head office for Shell's marketing activity worldwide.In 1932, partly in response to the difficult economic conditions of theGreat Depression, Shell-Mex merged its UK marketing operations with those ofBP(British Petroleum) to createShell-Mex & BP,a company that traded until the brands separated in 1975. Royal Dutch Company ranked 79th among United States corporations in the value ofWorld War IImilitary production contracts. The 1930s saw Shell's Mexican assets seized by the local government.After theinvasion of the NetherlandsbyNazi Germanyin 1940, the head office of the Dutch companies was moved toCuraçao.In 1945, Shell's Danish headquarters inCopenhagen, at the time being used by theGestapo, was bombed byRoyal Air ForceDe Havilland MosquitoesinOperation Carthage. In 1937,Iraq Petroleum Company(IPC), 23.75 percent owned by Royal Dutch Shell plc,signed an oil concession agreement with theSultan of Muscat. In 1952, IPC offered financial support to raise an armed force that would assist the Sultan in occupying the interior region ofOman, an area that geologists believed to be rich in oil. This led to the 1954 outbreak of theJebel Akhdar Warin Oman that lasted for more than 5 years. Around 1952, Shell was the first company to purchase and use a computer in the Netherlands.The computer, aFerranti Mark 1*, was assembled and used at the Shell laboratory in Amsterdam. In 1970, Shell acquired the mining companyBilliton, which it subsequently sold in 1994. In 1989, Shell redesigned a $3-billion natural gas platform in theNorth Sea, raising its height one to two meters, to accommodate an anticipatedsea level risedue toglobal warming. In the 1990s, protesters criticised the company's environmental record, particularly the possible pollution caused by the proposed disposal of theBrent Sparplatform into the North Sea. Despite support from the UK government, Shell reversed the decision under public pressure but maintained that sinking the platform would have been environmentally better.Shell subsequently published an unequivocal commitment tosustainable development, supported by executive speeches reinforcing this commitment.Shell was subsequently criticised by theEuropean Commissionand five European Union members after deciding to leave part of its decommissioned oil rigs standing in the North Sea. Shell argued that removing them would be too costly and risky. Germany said that the estimated 11,000 tonnes of raw oil and toxins remaining in the rigs would eventually seep into the sea, and called it a 'ticking timebomb'. On 15 January 1999, off theArgentiniantown ofMagdalena, Buenos Aires, the Shell tankerEstrella pampeanacollided with a Germancargo ship, emptying its contents into the lake, polluting the environment, drinkable water, plants and animals. Over a decade after the spill, a referendum held in Magdalena determined the acceptance of a US$9.5 million compensatory payout from Shell.Shell denied responsibility for the spill, but an Argentine court ruled in 2002 that the corporation was responsible. In 2002, Shell acquiredPennzoil-Quaker Statethrough its American division for US$22 per share, or about US$1.8 billion. Through its acquisition of Pennzoil, Shell became adescendant of Standard Oil. With its acquisition, Shell inherited multiple auto part brands includingJiffy Lube,Rain-X, andFix-a-Flat. The company was notably late in its acquisition as seen by journalists, with Shell seen as streamlining its assets around the same time of other major mergers and acquisitions in the industry, such asBP's purchase ofAmocoand the merger ofExxonandMobil. In 2004, Shell overstated its oil reserves, resulting in loss of confidence in the group, a £17 million fine by theFinancial Services Authorityand the departure of the chairmanPhilip Watts. A lawsuit resulted in the payment of $450 million to non-American shareholders in 2007. As a result of the scandal, the corporate structure was simplified. Two classes of ordinary shares, A (code RDSA) and B (code RDSB), identical but for the tax treatment of dividends, were issued for the company. In November 2004, following a period of turmoil caused by the revelation that Shell had been overstating itsoil reserves, it was announced that the Shell Group would move to a single capital structure, creating a new parent company to be named Royal Dutch Shell plc, with its primary listing on the LSE, a secondary listing onEuronext Amsterdam, its headquarters and tax residency inThe Hague, Netherlands and its registered office in London. The company was already incorporated in 2002 asForthdeal Limited, ashelf corporationincorporated by Swift Incorporations Limited and Instant Companies Limited, both based in Bristol.The unification was completed on 20 July 2005 and the original owners delisted their companies from the respective exchanges. On 20 July 2005, The \"Shell\" Transport and Trading Company plc was delisted from the LSE,changing its name to The Shell Transport and Trading Company Limitedwhereas Royal Dutch Petroleum Company was delisted from theNew York Stock Exchangeon 18 November 2005.The shares of the company were issued at a 60/40 advantage for the shareholders of Royal Dutch in line with the original ownership of the Shell Group. During the2009 Iraqi oil services contracts tender, a consortium led by Shell (45%) and which includedPetronas(30%) was awarded a production contract for the \"Majnoon field\" in the south of Iraq, which contains an estimated 12.6 billion barrels (2.00×10m) of oil.The \"West Qurna 1 field\" production contract was awarded to a consortium led byExxonMobil(60%) and included Shell (15%). In February 2010, Shell andCosanformed a 50:50 joint-venture,Raízen, comprising all of Cosan's Brazilian ethanol, energy generation, fuel distribution and sugar activities, and all of Shell's Brazilian retail fuel and aviation distribution businesses.In March 2010, Shell announced the sale of some of its assets, including its liquefied petroleum gas (LPG) business, to meet the cost of a planned $28bn capital spending programme. Shell invited buyers to submit indicative bids, due by 22 March, with a plan to raise $2–3bn from the sale.In June 2010, Shell agreed to acquire all the business ofEast Resourcesfor a cash consideration of $4.7 billion. The transaction included East Resources' tight gas fields. Over the course of 2013, the corporation began the sale of itsUS shale gasassets and canceled a US$20 billion gas project that was to be constructed in the US state ofLouisiana. A new CEOBen van Beurdenwas appointed in January 2014, prior to the announcement that the corporation's overall performance in 2013 was 38 percent lower than in 2012—the value of Shell's shares fell by 3 percent as a result.Following the sale of the majority of its Australian assets in February 2014, the corporation plans to sell a further US$15 billion worth of assets in the period leading up to 2015, with deals announced in Australia, Brazil and Italy. Shell announced on 8 April 2015 it had agreed to buyBG Groupfor £47 billion (US$70 billion), subject to shareholder and regulatory approval.The acquisition was completed in February 2016, resulting in Shell surpassingChevron Corporationand becoming the world's second largest non-state oil company. On 7 June 2016, Shell announced that it would build anethane cracker plantnearPittsburgh, Pennsylvania, after spending several years doing an environmental cleanup of the proposed plant's site. In January 2017, Shell agreed to sell £2.46bn worth ofNorth Seaassets to oil exploration firm Chrysaor.In 2017, Shell sold itsoil sandsassets toCanadian Natural Resourcesin exchange of approximately 8.8% stake in that company. In May 2017, it was reported that Shell plans to sell its shares in Canadian Natural Resources fully exiting the oil sands business. On 5 November 2017, theParadise Papers, a set of confidentialelectronic documentsrelating tooffshore investment, revealed that Argentine Energy MinisterJuan José Arangurenwas revealed to have managed theoffshore companies'Shell Western Supply and Trading Limited' and 'Sol Antilles y Guianas Limited', both subsidiaries of Shell. One is the main bidder for the purchase of diesel oil by the government through the state ownedCAMMESA(Compañía Administradora del Mercado Mayorista Eléctrico). On 30 April 2020, Shell announced that it would cut itsdividendfor the first time since theSecond World War, due to theoil price collapsefollowing the reduction in oil demand during theCOVID-19 pandemic. Shell stated that their net income adjusted for the cost of supply dropped to US$2.9 billion in three months to 31 March. This compared with US$5.3 billion in the same period the previous year.On 30 September 2020, the company said that it would cut up to 9,000 jobs as a result of the economic effects caused by the pandemic and announced a \"broad restructuring\".In December 2020, Shell forecast another write-down of $3.5–4.5 billion for the fourth quarter due to lower oil prices, following $16.8 billion of impairment in the second quarter. In February 2021, Shell announced a loss of $21.7 billion in 2020 due to the COVID-19 pandemic,despite reducing its operating expenses by 12%, or $4.5 billion, according to aMorningstaranalysis cited byBarron's. In November 2021, Shell announced that it is planning to relocate their headquarters to London, abandon its dual share structure, and change its name from Royal Dutch Shell plc to Shell plc.The company's name change was registered in theCompanies Houseon 21 January 2022. In December 2021, Shell pulled out of theCambo oil field, off the Shetland Islands, claiming that \"the economic case for investment in this project is not strong enough at this time, as well as having the potential for delays\". The proposed oilfield had been the subject of intense campaigning by environmentalists in the run-up to the COP26 UN climate summit in Glasgow in November 2021. On 4 March 2022, during theRussian invasion of Ukraineand in the midst of the growingboycott of Russian economy and related divestments, Shell bought a cargo of discounted Russian crude oil.The next day, following criticism from Ukraine's Foreign MinisterDmytro Kuleba, Shell defended the purchase as a short term necessity, but also announced that it intended to reduce such purchases, and it would put profits from any Russian oil it purchases into a fund that would go towards humanitarian aid to Ukraine.On 8 March, Shell announced that it would stop buying Russian oil and gas and close its service stations in the country. In 2022, the major oil and gas companies, including Shell,reported sharp rises in interim revenues and profits.In fact, this rise in profit for Shell was so sharp, that 2022 was the company's best year, as Shell recorded double the profits from 2021, and the highest profit in its entire history. In November 2024, Shell won a case in the Hague court of appeal againstFriends of the Earthwhich would have required Shell to cut its carbon emissions by 45%, in line with theParis Climate Accords. The key trends of Shell are (as at the financial year ending 31 December): On 4 August 2005, the board of directors announced the appointment ofJorma Ollila, chairman and CEO ofNokiaat the time, to succeed Aad Jacobs as the company's non-executive chairman on 1 June 2006. Ollila is the first Shell chairman to be neither Dutch nor British. Other non-executive directors includeMaarten van den Bergh,Wim Kok, Nina Henderson,Lord Kerr, Adelbert van Roxe, and Christine Morin-Postel. Since 3 January 2014,Ben van Beurdenhas been CEO of Shell.His predecessor wasPeter Voserwho became CEO of Shell on 1 July 2009. Following a career at the corporation, in locations such as Australia and Africa, Ann Pickard was appointed as the executive vice president of the Arctic at Royal Dutch Shell, a role that was publicized in an interview withMcKinsey & Companyin June 2014. In January 2023,Wael Sawansucceeded Ben van Beurden as CEO. The name Shell is linked to The \"Shell\" Transport and Trading Company.In 1833, the founder's father, Marcus Samuel Sr., founded an import business to sellseashellsto London collectors. When collecting seashellspecimensin theCaspian Seaarea in 1892, the younger Samuel realised there was potential in exportinglamp oilfrom the region and commissioned the world's first purpose-builtoil tanker, theMurex(Latin for a type ofsnail shell), to enter this market; by 1907 the company had a fleet. Although for several decades the company had a refinery atShell Havenon the Thames, there is no evidence of this having provided the name. The Shell logo is one of the most familiar commercial symbols in the world. This logo is known as the \"pecten\" after the sea shellPecten maximus(the giantscallop), on which its design is based. The yellow and red colours used are thoughtto relate to the colours of theflag of Spain, as Shell built early service stations in California, previously aSpanish colony. The current revision of the logo was designed byRaymond Loewyin 1971. The slash was removed from the name \"Royal Dutch/Shell\" in 2005, concurrent with moves to merge the two legally separate companies (Royal Dutch and Shell) to the single legal entity which exists today. On 15 November 2021, Royal Dutch Shell plc announced plans to change its name to Shell plc. Shell is organised into four major business groupings: Shell's primary business is the management of avertically integratedoil company. The development of technical and commercial expertise in all stages of this vertical integration, from the initial search for oil (exploration) through its harvesting (production), transportation,refiningand finally trading and marketing established the core competencies on which the company was founded. Similar competencies were required for natural gas, which has become one of the most important businesses in which Shell is involved, and which contributes a significant proportion of the company's profits. While the vertically integrated business model provided significanteconomies of scaleandbarriers to entry, each business now seeks to be a self-supporting unit without subsidies from other parts of the company. Traditionally, Shell was a heavily decentralised business worldwide (especially in the downstream) with companies in over 100 countries, each of which operated with a high degree of independence. The upstream tended to be far more centralised with much of the technical and financial direction coming from the central offices inThe Hague. The upstream oil sector is also commonly known as the \"exploration and production\" sector. Downstream operations, which now also includes the chemicals business, generate the majority of Shell's profits worldwide and is known for its global network of more than 40,000petrol stationsand its variousoil refineries. The downstream business, which in some countries also includedoil refining, generally included a retailpetrol stationnetwork, lubricants manufacture and marketing, industrial fuel and lubricants sales, and a host of other product/market sectors such asLPGandbitumen. The practice in Shell was that these businesses were essentially local and that they were best managed by local \"operating companies\" – often with middle and senior management reinforced byexpatriates. Shell has a long history of motorsport sponsorship, most notablyScuderia Ferrari(1951–1964, 1966–1973 and 1996–present),BRM(1962–1966 and 1968–1972),Scuderia Toro Rosso(2007–2013 and 2016),McLaren(1967–1968 and 1984–1994),Lotus(1968–1971),Ducati Corse(since 1999),Team Penske(2011–present),Hyundai Motorsport(since 2005),AF Corse,Risi Competizione,BMW Motorsport(2015–present with alsoPennzoil) andDick Johnson Racing(1987–2004and2017–present). Starting in 2023, Shell became the official fuel forIndyCar Series, supplying E100 race fuel for all teams. In motorcycle racing, Shell andDucatihave been working together globally for a very long time. Shell has indeed been working with Ducati since 1999, through the first support in theSuperbike. The support continues to win more than 150 races, including seven MotoGP world champions. Both in lubricants and fuel products which have now been established for 25 years. This long-term cooperation contract has just been extended in theNetherlandsat 2024 and will continue until the end of 2027. Following the purchase of an offshore lease in 2005, Shell initiated its US$4.5 billionArcticdrilling program in 2006, after the corporation purchased the \"Kulluk\" oil rig and leased the Noble Discoverer drillship.At inception, the project was led by Pete Slaiby, a Shell executive who had previously worked in theNorth Sea.However, after the purchase of a second offshore lease in 2008, Shell only commenced drilling work in 2012, due to the refurbishment of rigs, permit delays from the relevant authorities and lawsuits.The plans to drill in the Arctic led to protests from environmental groups, particularlyGreenpeace; furthermore, analysts in the energy field, as well as related industries, also expressed skepticism due to perceptions that drilling in the region is \"too dangerous because of harsh conditions and remote locations\". Further problems hampered the Arctic project after the commencement of drilling in 2012, as Shell dealt with a series of issues that involved air permits,Coast Guardcertification of a marine vessel, and severe damage to essential oil-spill equipment. Additionally, difficult weather conditions resulted in the delay of drilling during mid-2012 and the already dire situation was exacerbated by the \"Kulluk\" incident at the end of the year. Shell had invested nearly US$5 billion by this stage of the project. As theKullukoil rig was being towed to the American state ofWashingtonto be serviced in preparation for the 2013 drilling season, a winter storm on 27 December 2012 caused the towing crews, as well as the rescue service, to lose control of the rig. As of 1 January 2013, the Kulluk was grounded off the coastSitkalidak Island, near the eastern end ofKodiak Island. Following the accident, aFortunemagazine contacted Larry McKinney, the executive director at the Harte Research Institute for Gulf of Mexico Studies atTexas A&M, and he explained that \"A two-month delay in the Arctic is not a two-month delay ... A two-month delay could wipe out the entire drilling season\". It was unclear if Shell would recommence drilling in mid-2013, following the \"Kulluk\" incident, and, in February 2013, the corporation stated that it would \"pause\" its closely watched drilling project off theAlaskancoast in 2013, and will instead prepare for future exploration.In January 2014, the corporation announced the extension of the suspension of its drilling program in the Arctic, with chief executive van Beurden explaining that the project is \"under review\" due to both market and internal issues. A June 2014 interview with Pickard indicated that, following a forensic analysis of the problems encountered in 2012, Shell will continue with the project and Pickard stated that she perceives the future of the corporation activity in the Arctic region as a long-term \"marathon\".Pickard stated that the forensic \"look back\" revealed \"there was an on/off switch\" and further explained: In other words, don't spend the money unless you're sure you're going to have the legal environment to go forward. Don't spend the money unless you're sure you're going to have the permit. No, I can't tell you that I'm going to have that permit until June, but we need to plan like we're going to have that permit in June. And so probably the biggest lesson is to make sure we could smooth out the on/off switches wherever we could and take control of our own destiny. Based upon the interview with Pickard, Shell is approaching the project as an investment that will reap energy resources with a lifespan of around 30 years. According to theBureau of Ocean Energy Managementreport in 2015 the chances of a major spill in a deep-sea Arctic drilling is 75% before century's end. In 2010, Greenpeace activists painted \"No Arctic Drilling\" using spilledBPoil on the side of a ship in theGulf of Mexicothat was en route to explore forArcticoil for Shell. At the protest,Phil Radfordof Greenpeace called for \"President Obama[to] ban all offshore oil drilling and call for an end to the use of oil in our cars by 2030\". On 16 March 2012, 52 Greenpeace activists from five different countries boardedFennicaandNordica, multipurposeicebreakerschartered to support Shell's drilling rigs near Alaska.Around the same time period, a reporter forFortunemagazinespoke withEdward Itta, anInupiatleader and the former mayor of theNorth Slope Borough, who expressed that he was conflicted about Shell's plans in the Arctic, as he was concerned that an oil spill could destroy the Inupiat peoples hunting-and-fishing culture, but his borough also received major tax revenue from oil and gas production; additionally, further revenue from energy activity was considered crucial to the future of the living standard in Itta's community. In July 2012, Greenpeace activists shut down 53 Shell petrol stations inEdinburghand London in a protest against the company's plans to drill for oil in the Arctic. Greenpeace's \"Save the Arctic\" campaign aims to prevent oil drilling andindustrial fishingin the Arctic by declaring the uninhabited area around the North Pole a global sanctuary. A review was announced after theKullukoil rig ran aground near Kodiak Island in December 2012. In response, Shell filed lawsuits to seek injunctions from possible protests, andBenjamin Jealousof theNAACPand Radford argued that the legal action was \"trampling Americans' rights\".According to Greenpeace, Shell lodged a request with Google to take down video footage of a Greenpeace protest action that occurred at the Shell-sponsoredFormula One(F1) Belgian Grand Prix on 25 August 2013, in which \"SaveTheArctic.org\" banners appear at the winners' podium ceremony. In the video, the banners rise up automatically—activists controlled their appearance with the use of four radio car antennas—revealing the website URL, alongside an image that consists of half of a polar bear's head and half of the Shell logo. Shell then announced a \"pause\" in the timeline of the project in early 2013and, in September 2015, the corporation announced the extension of the suspension of its drilling program in the Arctic. A June 2014 interview with the corporation's new executive vice president of the Arctic indicated that Shell will continue with its activity in the region. InSeattleprotests began in May 2015in response to the news that thePort of Seattlemade an agreement with Shell to berth rigs at the Port's Terminal 5 during the off-season ofoil explorationinAlaskanwaters. The arrival of Shell's new Arctic drilling vessel,Polar Pioneer(IMO number:8754140), asemi-submersibleoffshore drillingrig, was greeted by large numbers of environmental protesters paddling kayaks inElliott Bay. On 6 May 2015, it was reported that during a coast guard inspection ofPolar Pioneer, a piece of anti-pollution gear failed, resulting in fines and delay of the operation.Oil executives from Total and Eni interviewed by theNew York Times, expressed scepticism about Shell's new ambitions for offshore drilling in the Arctic, and cited economic and environmental hurdles.ConocoPhillipsandEquinor (formerly Statoil)suspended Arctic drilling earlier, after Shell's failed attempt in 2012. On 20 May 2011, Shell's final investment decision for the world's firstfloating liquefied natural gas(FLNG) facility was finalized following the discovery of the remote offshore Prelude field—located off Australia's northwestern coast and estimated to contain about 3 trillion cubic feet of natural gas equivalent reserves—in 2007. FLNG technology is based on liquefied natural gas (LNG) developments that were pioneered in the mid-20th century and facilitates the exploitation of untapped natural gas reserves located in remote areas, often too small to extract any other way. Thefloating vesselto be used for the Prelude field, known asPreludeFLNG, is promoted as the longest floating structure in the world and will take in the equivalent of 110,000 barrels of oil per day in natural gas—at a location 200 km (125 miles) off the coast ofWestern Australia—and cool it into liquefied natural gas for transport and sale in Asia. The Prelude is expected to start producing LNG in 2017—analysts estimated the total cost of construction at more thanUS$12 billion. Following the decision by the Shell fuel corporation to close itsGeelong Oil Refineryin Australia in April 2013, a third consecutive annual loss was recorded for Shell's Australian refining and fuel marketing assets. Revealed in June 2013, the writedown is worthA$203 million and was preceded by a A$638m writedown in 2012 and a A$407m writedown in 2011, after the closure of theClyde Refineryin Sydney. In February 2014, Shell sold its Australian refinery and petrol stations for US$2.6 billion (A$2.9 billion) to Swiss companyVitol. At the time of the downstream sale to Vitol, Shell was expected to continue investment into Australian upstream projects, with projects that involve Chevron Corp.,Woodside Petroleumand Prelude.In June 2014, Shell sold 9.5% of its 23.1% stake inWoodside Petroleumand advised that it had reached an agreement for Woodside to buy back 9.5% of its shares at a later stage. Shell became a major shareholder in Woodside after a 2001 takeover attempt was blocked by then federal TreasurerPeter Costelloand the corporation has been open about its intention to sell its stake in Woodside as part of its target to shed assets. At a general body meeting, held on 1 August 2014, 72 percent of shareholders voted to approve the buy-back, short of the 75 percent vote that was required for approval. A statement from Shell read: \"Royal Dutch Shell acknowledges the outcome of Woodside Petroleum Limited's shareholders' negative vote on the selective buy-back proposal. Shell is reviewing its options in relation to its remaining 13.6 percent holding\". Brunei Shell Petroleum (BSP) is a joint venture between the Government ofBruneiand Shell.The British Malayan Petroleum Company (BMPC), owned by Royal Dutch Shell, first found commercial amounts of oil in 1929.It currently produces 350,000 barrels of oil and gas equivalent per day.BSP is the largest oil and gas company in Brunei, a sector which contributes 90% of government revenue.In 1954, the BMPC in Seria had a total of 1,277 European and Asian staff. The company has upstream operations in unconventionaloilandgasin China. Shell has a joint venture withPetroChinaat the Changbeitight gasfield inShaanxi, which has produced natural gas since 2008. The company has also invested in exploring forshale oilin Sichuan.The other unconventional resource which Shell invested in in China was shale. The company was an early entrant in shale oil exploration in China but scaled down operations in 2014 due to difficulties with geology and population density.It has a joint venture to explore foroil shalein Jilin through a joint venture with Jilin Guangzheng Mineral Development Company Limited. In May 2024, Shell announced an exit from China power market business to focus on more profitable operations. Shell has been active in Hong Kong for a century, providing Retail, LPG, Commercial Fuel, Lubricants, Bitumen, Aviation, Marine and Chemicals services, and products. Shell also sponsored the first Hong Kong-built aircraft,Inspiration, for its around-the-world trip. Shell India has inaugurated its new lubricants laboratory at its Technology Centre inBangalore. Shell started operating in Indonesia since 1928. Shell started operatinggas stationsin Indonesia since 1 November 2005. Its first gas station was located inLippo Karawaci,Tangerang. On 1 March 2006, Shell opened a gas station inJakartalocated on Jalan S. Parman (Slipi). As of 2022, the fuels that Shell sells in Indonesia are Shell Super,Shell V-Power, Shell V-Power Nitro+,Shell V-Power Dieseland Shell Diesel Extra. Shell first started trading in Ireland in 1902.Shell E&P Ireland (SEPIL) (previously Enterprise Energy Ireland) is an Irish exploration and production subsidiary of Royal Dutch Shell. Its headquarters are onLeeson Streetin Dublin. It was acquired in May 2002.Its main project is theCorrib gas project, a large gas field off the northwest coast, for which Shell has encounteredcontroversy and protestsin relation to the onshore pipeline and licence terms. In 2005, Shell disposed of its entire retail and commercial fuels business in Ireland toTopaz EnergyGroup. This included depots, company-owned petrol stations and supply agreements stations throughout the island of Ireland.The retail outlets were re-branded as Topaz in 2008/9. The Topaz fuel network was subsequently acquired in 2015 byCouchetardand these stations began re-branding toCircle Kin 2018. Shell's activities in Italy began on 13 July 1912, with the creation of \"Nafta\",based inLa Spezia, founded after taking advantage of the weakness of the formerStandard Oil Trust, dissolved the previous year. During theFirst World War, Nafta abandoned the private sector, focusing on the war supplies to theItalian state. During the conflict, the company expanded, with the opening of new plants inNaplesandAugustaand, after the end of hostilities, with the exploitation of further internal deposits. In thefirst post-war period, the company controlled the Italian internal market together with the SIAP, the local branch of theStandard of New Jersey (Esso). In 1921, under pressure from the CEO Giovanni Attilio Pozzo (then also elected president in 1923), the share capital was increased reaching 100 million lire.The products sold at the time included \"Bentero Shell\" and \"Aureola Petroli\". In 1922, despite the difficult economic situation of the country, the company grew, and the newVado Ligureplant was inaugurated.The inauguration, however, caused a short political clash between the Prime MinisterFactaand thesocialistdeputyTonello, who in aparliamentary questionharshly criticized the official telegram sent by Facta to \"Nafta\" on the occasion of the ceremony.In the same year, the works for a coastal system inVenicealso continued. The birth ofAgipcreated some disagreements between Nafta and theMinistry of the National Economy, which in 1926 asked the Prefects to subordinate the release of new concessions for the plant ofpetrol stationsto an approval estimate of Agip; the question was resolved peacefully in 1927 on the initiative of the Italian company itself. At the end of the decade, taking advantage of a particularly advantageous legislation, the company launched into therefining sector, with the establishment of subsidiary companies in La Spezia. On 27 April 1939, Pozzo left \"Nafta\", after twenty years at the head of the company. The company controlled about 20% of the Italian market at the time. On 8 August 1940, following Italy's entry into theSecond World War, Nafta was seized and placed under the management of Agip, followed the following year by the US companies operating in Italy (SIAP,Vacuum,Texaco). On 30 July 1942 foreign oil companies were officially transferred to Agip, although the integration of their activities was somewhat complex and remained substantially unfinished. On 22 October 1945, after the end of hostilities, the measures were abandoned and the NAFTA and the other companies, under the guidance of the Italian Petroli Committee, returned to normal activity. In 1949 the company, now fully restored, was renamed \"Shell Italiana S.p.A\". with a share capital of more than 2 billion lira.Still in the early 1960s, Shell covered about 20% of the Italian oil needs. The Italian Shell was the first company to be advertised withCarosello. In 1959 the company purchased the former Condor refinery ofRhoand in 1967 it built a large plant inTaranto,whose works began in 1964 with an initial investment of 25 billion lire. Shell remained active in the country until April 1974 when, following difficulties in the oil sector caused by theKippur Warand the general conditions of the Italian economy, now not very favorable, the old company was sold toEni, which becameItaliana Petroli (IP).The company then returned to the fuel distribution in 1980,with the acquisition of theConoconetwork,while in 1987 the joint venture withMontedisonwhich led to the creation ofMonteShell. In July 2014 Shell gave its network of service stations and fuel deposits in Italy to theKuwait Petroleum Italia(Q8). In 2022 an agreement was announced with the Pad Multiegy company, for the brand to be restored and Shell products to be sold in over 500 Italian service stations,the first of which was inaugurated in March 2022. In Italy today Shell operates through Shell Italia S.p.A. controlled by Shell Italia Finanza S.p.A. The main locations are inSesto San GiovanniandRome. Shell discovered the first oil well in Borneo in 1910, inMiri, Sarawak. Today, the oil well is a state monument known as the Grand Old Lady. In 1914, following this discovery, Shell built Borneo's first oil refinery and laid a submarine pipeline inMiri. Shell began production inNigeriain 1958.InNigeria, Shell told US diplomats that it had placed staff in all the main ministries of thegovernment.Shell continues however upstream activities/extracting crude oil in the oil-richNiger Deltaas well as downstream/commercial activities in South Africa. In June 2013, the company announced a strategic review of its operations in Nigeria, hinting that assets could be divested.In August 2014, the company disclosed it was in the process of finalizing the sale of its interests in fourNigerian oil fields.On 29 January 2021 a Dutch court ruled that Shell was responsible for multiple oil leaks in Nigeria. The actions of companies like Shell has led to extremeenvironmental issues in the Niger Delta. Many pipelines in the Niger Delta owned by Shell are old and corroded. Shell has acknowledged its responsibility for keeping the pipelines new but has also denied responsibility for environmental causes.The heavy contamination of the air, ground and water with toxic pollutants by the oil industry in the Niger Delta is often used as an example ofecocide.This has led to mass protests from theNiger Deltainhabitants,Amnesty International, andFriends of the Earththe Netherlands against Shell. It has also led to action plans to boycott Shell byenvironmentalandhuman rights groups.In January 2013, a Dutch court rejected four out of five allegations brought against the firm over oil pollution in the Niger Delta but found a subsidiary guilty of one case of pollution, ordering compensation to be paid to a Nigerian farmer. On 27 August 2007, Shell andReitan Group, the owner of the7-Elevenbrand inScandinavia, announced an agreement to re-brand some 269 service stations acrossNorway, Sweden,FinlandandDenmark, subject to obtaining regulatory approvals under the differentcompetition lawsin each country.In April 2010 Shell announced that the corporation is in process of trying to find a potential buyer for all of its operations in Finland and is doing similar market research concerning Swedish operations.In October 2010 Shell's gas stations and the heavy vehicle fuel supply networks in Finland and Sweden, along with a refinery located inGothenburg, Sweden were sold toSt1, a Finnish energy company, more precisely to its major shareholding parent company Keele Oy.Shell gas stations in Norway were taken over by St1 in 2015, but continued operating under the Shell brand until 2025. Through most of Shell's early history, theShell USbusiness in the United States was substantially independent. Its stock was traded on theNYSE, and the group's central office had little direct involvement in running the operation. However, in 1984, Shell made a bid to purchase those shares of Shell Oil Company it did not own (around 30%) and, despite opposition from some minority shareholders which led to a court case, Shell completed the buyout for a sum of $5.7 billion. Royal Dutch Shell operates in thePhilippinesunder its subsidiary,Shell Pilipinas CorporationorSPC. Its headquarters is inTaguigand it has facilities in thePandacan oil depotand other key locations. In January 2010, theBureau of Customsclaimed 7.34 billion pesos worth of unpaidexcise taxesagainstPilipinas Shellfor importing Catalytic cracked gasoline (CCG) and light catalytic cracked gasoline (LCCG) stating that those imports are bound for tariff charges. In August 2016, Pilipinas Shell filed an application to sell US$629 million worth of primary and secondary shares to the investing public (registration statement) with theSEC. This was a prelude to filing its IPO listing application with thePhilippine Stock Exchange. On 3 November 2016 the Pilipinas Shell Petroleum Corporation was officially listed on thePhilippine Stock Exchangeunder the ticker symbol SHLPH after they held itsinitial public offeringon 19 to 25 October of the same year. Due to the economic slowdown caused by the COVID-19 pandemic on the global, regional and local economies, continually low refining margins, and competition with imported refined products, the management of Pilipinas Shell announced in August 2020 that the 110,000 bbl/d refinery in Tabangao, Batangas, which started operations in 1962, will be shutting down permanently and turned into an import terminal instead. In February 2022, Shell exited all its joint ventures withGazprombecause of the2022 Russian invasion of Ukraineand, in March 2022, Shell announced that it would stop buying oil from Russia and close all its service stations there.In April 2022, it emerged that Shell was to book up to $5 billion in impairment charges from exiting its interests in Russia. Singapore is the main centre for Shell's petrochemical operations in the Asia Pacific region. Shell Eastern Petroleum limited (SEPL) have their refinery located in Singapore'sPulau Bukomisland. They also operate as Shell Chemicals Seraya inJurong Island.In November 2020, Shell announced that, as part of efforts to curtail pollution emissions, it will cut its oil-processing capacity in Singapore. Shell Downstream SA (SDSA) was created through a merger of Shell South Africa andBBBEEcompany Thebe Investment Corporation. The South AfricanDepartment of Mineral Resources and Energygranted Shell exploration rights in the country, and it has been operating in South Africa since 1902. The company also owns an oil refinery inDurban, which has been closed since the end of March 2022. On 6 May 2024, Shell indicated its intent to exit the South African downstream market. This includes its refining, transport, and retail offerings. It is as yet unknown what will happen to its gas stations. Shell is a member of theFuels Industry Association of South Africa(FIASA), and was one of its founding members when the organization launched in 1994. Prior to the 1960s, Shell was one of the major multinational corporations operating in Sri Lanka, alongside companies likeEssoandCaltex. These companies played pivotal roles in importing, distributing, and retailing petroleum products across the country. However, in 1962, under the leadership of Prime MinisterSirimavo Bandaranaike, theSri Lankan governmentnationalizedthe assets of these oil giants. This move aimed to reduce foreign dominance in key economic sectors and led to the establishment of theCeylon Petroleum Corporation(CPC), granting it exclusive rights over the importation, sale, export, and distribution of most petroleum products in Sri Lanka. After a period of reduced presence, Shell re-entered the Sri Lankan market in the mid-1990s. In 1996, Shell acquired a 51% stake in theColombo Gas Companyfor $37 million, marking its significant return to the country's energy sector. This acquisition led to the establishment of Shell Gas Lanka Limited, which managed the importation, storage, and distribution of liquefied petroleum gas (LPG) in Sri Lanka. In recent years, Shell has signaled its intent to re-establish a presence in Sri Lanka's fuel retailing market. In collaboration with RM Parks and Tristar, Shell announced plans to introduce Shell-branded fuel stations in the country, marking a significant return to the Sri Lankan energy landscape. On 26 February 2025, Shell marked its return to Sri Lanka's fuel retail market by inaugurating its first Shell-branded fuel station in over six decades. This station is located at the B.S. Cooray Filling Station in Ambathale, Colombo District. In the UK sector of theNorth SeaShell employs around 4,500 staff in Scotland as well as an additional 1,000 service contractors: however in August 2014 it announced it was laying off 250 of them, mainly inAberdeen.Shell paid no UK taxes on its North Sea operations over the period 2018 to 2021. In the early 2000s Shell moved intoalternative energyand there is now an embryonic \"Renewables\" business that has made investments insolar power,wind power,hydrogen, andforestry. The forestry business went the way of nuclear, coal, metals and electricity generation, and was disposed of in 2003. In 2006 Shell paidSolarWorldto take over its entire solar businessand in 2008, the company withdrew from theLondon Arraywhich when built was the world's largest offshore wind farm. Shell also is involved in large-scale hydrogen projects. HydrogenForecast.com describes Shell's approach thus far as consisting of \"baby steps\", but with an underlying message of \"extreme optimism\".In 2015, the company announced plans to install hydrogen fuel pumps across Germany, planning on having 400 locations in operation by 2023. Shell holds 44% ofRaízen, a joint venture with Brazilian sugarcane producerCosanwhich is the third-largest Brazil-based energy company by revenues and a major producer ofethanol.In 2015, the company partnered with Brazilian start-up company Insolar to install solar panels inRio de Janeiroto deliver electricity to theSanta Martaneighbourhood. Shell is the operator and major shareholder of TheShell CanadaQuest Energy project, based within the Athabasca Oil Sands Project, located nearFort McMurray, Alberta.It holds a 60% share, alongsideChevron Canada Limited, which holds 20%, and Marathon Canadian Oil Sands Holding Limited, which holds the final 20%.Commercial operations launched in November 2015. It was the world's first commercial-scale oil and sandcarbon capture storage (CCS)project.It is expected to reduce CO2emissions in Canada by 1.08 million tonnes per year. In December 2016, Shell won the auction for the 700 MWBorssele III & IVoffshore wind farmsat a price of 5.45c/kWh, beating 6 otherconsortia.In June 2018, it was announced that the company and its co-investorPartners Grouphad secured $1.5bn for the project, which also involvesEneco,Van Oord, and Mitsubishi/DGE. In October 2017, it bought Europe's biggest vehicle charging network, \"NewMotion\". In November 2017, Shell's CEO Ben van Beurden announced Shell's plan to cut half of its carbon emissions by 2050, and 20 percent by 2035. In this regard, Shell promised to spend $2 billion annually on renewable energy sources. Shell began to develop its wind energy segment in 2001, the company now operates six wind farms in the United States and is part of a plan to build two offshore wind farms in the Netherlands. In December 2017, the company announced plans to buy UK household energy and broadband providerFirst Utility.In March 2019 it rebranded toShell Energyand announced that all electricity would be supplied from renewable sources. In December 2018, the company announced that it had partnered withSkyNRGto begin supplyingsustainable aviation fuelto airlines operating out ofSan Francisco Airport (SFO), includingKLM,SAS, andFinnair.In the same month, the company announced plans to double its renewable energy budget to investment in low-carbon energy to $4 billion US each year, with an aim to spend up to $2 billion US on renewable energy by 2021. In January 2018, the company acquired a 44% interest in Silicon Ranch, a solar energy company run byMatt Kisber, as part of its global New Energies project.The company took over from Partners Group, paying up to an estimated $217 million for the minority interest. In February 2019, the company acquired German solar battery companySonnen.It first invested in the company in May 2018 as part of its New Energies project.As of late 2021, the company had 800 employees and has installed 70.000 home battery systems. On 27 February 2019, the company acquired British VPP operator Limejump for an undisclosed amount. In July 2019, Shell installed their first 150 kW electric car chargers at its Londonpetrol stationswith payments handled viaSMOOV. They also plan to provide 350 kW chargers in Europe by entering into an agreement withIONITY. On 26 January 2021, Shell said it would buy 100 per cent of Ubitricity, owner of the largest public charging network forelectric vehicles in the United Kingdom, as the company expands its presence along the power supply chain.In 2023, Shell announced that it would rebrand its Ubitricity chargepoints under its Shell Recharge brand. On 25 February 2021, Shell announced the acquisition of German Virtual Power Plant (VPP) company Next Kraftwerke for an undisclosed amount. Next Kraftwerke connects renewable electricity generation- and storage projects to optimize the usage of those assets. The company mostly operates in Europe. In November 2022, it was announced Shell's wholly owned subsidiary, Shell Petroleum NV, had acquired theOdense-headquarteredrenewable natural gasproducer, Nature Energy Biogas A/S for nearly US$2 billion. Shell is mainly owned by institutional investors. The 10 largest shareholders of Shell plc in early 2024 were: In 2020, theNorthern Lights CCS projectwas announced, which is a joint project between Equinor, Shell and Total, operating in the European Union (Norway) and aiming to store liquid CO2beneath the seabed. Environmentalists have expressed concern that Shell is processing oil from theAmazon regionof South America. In the United States, the Martinez refinery (CA) and the Puget Sound Refinery (WA) carry Amazonian oil. In 2015, 14% of the Martinez refinery's gross, at 19,570 barrels per day, came from the Amazon. In December 2021, Royal Dutch Shell decided to move ahead with seismic tests to explore for oil inhumpback whalebreeding grounds along South Africa's eastern coastline.On 3 December 2021, a South African high court struck down an urgent application brought by environmentalists to stop the project, which will involve a vessel regularly firing an air gun that produces a very powerful shock wave underwater to help map subsea geology. According to Greenpeace Africa and the South African Deep Sea Angling Association, this could cause \"irreparable harm\" to the marine environment, especially to migrating humpback whales in the area. Measured by both its own emissions, and the emissions of all the fossil fuels it sells, Shell was theninth-largest corporate producer of greenhouse gas emissionsin the period 1988–2015.The burning of the fossil fuels produced by Shell are responsible for 1.67% of global industrialgreenhouse gas emissionsfrom 1988 to 2015. In the past, Shell has been a part of lobbying and trade groups that are against climate policy and promote climate skepticism. In 2017, a public information film (\"Climate of Concern\") unseen for years resurfaced and showed Shell had clear grasp of global warming 26 years earlier but has not acted accordingly since, said critics.During the years of 2010–2018, only 1% of Shell's long-term investments were dedicated to sources of low-carbon energy such as wind and solar. In the years of 2015–2017, just 0.4% of its revenue was put towards low-carbon technology. Shell failed to meet its own target in 2020 to spend $6 billion on renewable energy. In 2021, 30% of Shell's shareholders voted for a climate resolution filed byshareholder advocacygroupFollow This.Still, it is estimated that Shell is not on track to meet its own investment target for 2025, and that the company needs to direct over half of its capital expenditures (nearly $10 billion per year) to zero carbon investments to meet its long-term net-zero targets.In April 2020, Shell announced plans to achievenet zero greenhouse gas emissionsby 2050 or sooner.They also pledged to reduce carbon intensity of all energy products by 20% by 2030, and 45% by 2035 (compared to 2016 levels.)However, internal documents from the company released by the Democratic-led House committee reveal a private 2020 communication saying Shell does not have any plans to bring emissions to zero for next 10–20 years. In March 2024, Shell CEO Wael Sawan announced that the company would moderate its near-term carbon emissions reduction targets, revising its reduction innet carbon intensityof third-party use of products down to 15% from 20% and dropping its target of a 45% reduction in carbon emissions by 2035 from a 2016 baseline. Shell plc reported 58 million metric tons of emissions from its operations in 2024 with 50 million metric tons coming from Scope 1 sources and 8 million metric tons coming from Scope 2 sources. This high level of emissions is a result of Shell plc's main business activities, which include gas production and oil refining. Actually, industries with a high environmental risk account for 100% of the company's revenue, with consumable fuels making up 89.7% of this total.Even if Shell cut methane emissions by 19.5% and gas flaring by 14.3% in a single year, its green revenue is still only 0.2%.Additionally, there are extremely high environmental risks associated with the company's value chain, particularly with regard to greenhouse gas emissions and ecosystem change. Shell's company faces risks and challenges as a result of climate change. The corporation works in high-risk industries that could be impacted by public opinion and laws related to climate change. The fact that 3% of Shell's assets are located in pristine areas, for instance, may cause future disputes and more strict laws.Shell has declared a transition strategy and a target of achieving net zero emissions by 2050 in order to address these threats. By 2024, Shell had exceeded its goal of reducing emissions by 30% over a 14-year period.Its emissions, particularly those from Scope 3, are still greater than some industry standards, nonetheless. On 5 April 2019,Milieudefensie(Dutchfor \"environmental defense\"), together with six NGOs and more than 17,000 citizens, sued Shell, accusing the company of harming the climate despite knowing about global warming since 1986.In May 2021, the district court ofThe Hagueruled that Shell must reducecarbon dioxide emissionsby 45% by 2030 (compared to 2019 levels). Shell contested the 2021 ruling, contendeding that the ruling exceeded judicial authority and could lead to counterproductive outcomes. The outcome was anticipated to significantly impact Shell's operations and influence European energy companies' climate policies.On 12 November 2024, The Hague's appeals court dismissed the 2021 ruling that had required Shell to cut its absolute carbon emissions by 45% by 2030, relative to 2019 levels, including emissions resulting from the use of its products. On 2 September 2002, Shell chairman Philip Watts accepted the \"Greenwash Lifetime Achievement Award\" from the Greenwash Academy's Oscar Green, near the World Summit on Sustainable Development. In 2007, BritishASAruled against a Shell ad involving chimneys spewing flowers, which depicted Shell's waste management policies, claiming it was misleading the public about Shell's environmental impact. In 2008, the British ASA ruled that Shell had misled the public in an advertisement when it claimed that a $10 billionoil sandsproject inAlberta, Canada, was a \"sustainable energy source\". In 2021,Netherlandsofficials told Shell to stop running a campaign which claimed customers could turn their fuel \"carbon neutral\" by buying offsets, as it was concluded that this claim was devoid of evidence. In December 2022,U.S. House Oversight and Reform CommitteeChairCarolyn MaloneyandU.S. House Oversight Environment SubcommitteeChairRo Khannasent a memorandum to all House Oversight and Reform Committee members summarizing additional findings from the committee's investigation into the fossil fuel industry disinformation campaign to obscure the role of fossil fuels in causing global warming, and that upon reviewing internal company documents, accused Shell along withBP,Chevron Corporation, andExxonMobilofgreenwashingtheirParis Agreementcarbon neutralitypledges while continuing long-term investment in fossil fuel production and sales, for engaging in a campaign to promote the use of natural gas as a clean energy source and bridge fuel to renewable energy, and of intimidating journalists reporting about the companies' climate actions and of obstructing the committee's investigation, which ExxonMobil, Shell, and theAmerican Petroleum Institutedenied. A number of incidents over the years led to criticism of Shell'shealth and safetyrecord, including repeated warnings by theUK Health and Safety Executiveabout the poor state of the company's North Sea platforms. Shell already had previous experience exiting markets that were subject to sanctions pressure from NATO or EU member states. In particular, in 2013, Shell announced that it was suspending its operations in Syria.On 8 March 2022, Shell announced its intention to phase out all Russian hydrocarbon production and acquisition projects, including crude oil, petroleum products, natural gas and liquefied natural gas (LNG). In early 2022, the company was criticized by the Minister of Foreign Affairs of Ukraine for its slow response to the Russian invasion.As of April 2023, Shell still had shares in Russian companies, such as 27.5% in Sakhalin Energy Investment Company (SEIC), a joint venture with Gazprom (50%), Mitsui (12.5%) and Mitsubishi (10%). This domain name was first registered by a former marketing manager for Royal Dutch Shell plc, Alfred Donovan, and has been used as a \"gripe site\".It avoids being an illegalcybersquatteras long as it is non-commercial, active, and no attempt is made to sell the domain name, as determined byWIPOproceedings.In 2005, Donovan said he would relinquish the site to Shell after it \"gets rid of all the management he deems responsible for its various recent woes\".The site has been recognized by several media outlets for its role as anInternet leak. In 2008, theFinancial Timespublished an article based on a letter published by royaldutchshellplc.com,whichReutersandThe Timesalso covered shortly thereafter.On 18 October 2006, the site published an article stating that Shell had for some time been supplying information to the Russian government relating toSakhalin II.The Russian energy companyGazpromsubsequently obtained a 50% stake in the Sakhalin-II project.Other instances where the site has acted as an Internet leak include a 2007IToutsourcing plan,as well as a 2008 internal memo where CEOJeroen van der Veerexpressed disappointment in the company's share-price performance. The gripe site has also been recognized as a source of information regarding Shell by several news sources. In the 2006Fortune Global 500rankings, in which Royal Dutch Shell placed third, royaldutchshellplc.com was listed alongside shell.com as a source of information.In 2007, the site was described as \"a hub for activists and disgruntled former employees\".A 2009 article called royaldutchshellplc.com \"the world's most effective adversarial Web site\".The site has been described as \"an open wound for Shell\". (In chronological order)", "combined_text": "Shell plc Contents History Origins 20th century 21st century Corporate affairs Business trends Management Name and logo Logo evolution Operations Business groupings Oil and gas activities Sponsorships Operations by region Arctic Australia Brunei China India Indonesia Ireland Italy Malaysia Nigeria Nordic countries North America Philippines Russia Singapore South Africa Sri Lanka United Kingdom Alternative energy Ownership Controversies Carbon capture storage beneath the sea bed Processing oil in the Amazon Operating in the hump back whale breeding grounds Climate change Oil spills Accusations of greenwashing Health and safety Reaction to the Russian invasion of Ukraine royaldutchshellplc.com See also Notes References Bibliography Commissioned works Other works External links  Shell plcis a Britishmultinationaloilandgascompany, headquartered inLondon, United Kingdom.Shell is apublic limited companywith a primary listing on theLondon Stock Exchange(LSE) and secondary listings onEuronext Amsterdamand theNew York Stock Exchange. A core component ofBig Oil, Shell is the second largest investor-owned oil and gas company in the world by revenue (afterExxonMobil), and among theworld's largest companiesout of any industry.Measured by both its own emissions, and the emissions of all the fossil fuels it sells, Shell was theninth-largest corporate producer of greenhouse gas emissionsin the period 1988–2015. Shell was formed in April 1907 through themergerofRoyal Dutch Petroleum Companyof the Netherlands andThe \"Shell\" Transport and Trading Companyof the United Kingdom. The combined company rapidly became the leading competitor of the AmericanStandard Oiland by 1920 Shell was the largest producer of oil in the world.Shell first entered the chemicals industry in 1929. Shell was one of the \"Seven Sisters\" which dominated the global petroleum industry from the mid-1940s to the mid-1970s. In 1964, Shell was a partner in the world's first commercial sea transportation ofliquefied natural gas(LNG).In 1970, Shell acquired the mining companyBilliton, which it subsequently sold in 1994 and now forms part ofBHP. In recent decades gas has become an increasingly important part of Shell's businessand Shell acquiredBG Groupin 2016. Shell isvertically integratedand is active in every area of the oil and gas industry, includingexploration,production,refining,transport,distribution and marketing,petrochemicals,power generation, and trading. Shell has operations in over 99 countries,produces around 3.7 millionbarrels of oil equivalentper day and has around 44,000 service stations worldwide.As of 31 December 2019, Shell had total proved reserves of 11.1 billion barrels (1.76×10m) of oil equivalent.Shell USA, its principal subsidiary in the United States, is one of its largest businesses.Shell holds 44%ofRaízen, a publicly listed joint venture withCosan, which is the third-largest Brazil-based energy company.In addition to the main Shell brand, the company also owns theJiffy Lube,PennzoilandQuaker Statebrands. Shell is a constituent of theFTSE 100 Indexand had amarket capitalisationof US$199 billion on 15 September 2022, the largest of any company listed on the LSE and the 44th-largest of any company in the world.In terms of the revenue, Shell generated $284B in 2024, a significant decline over a decade, from $451B in 2013. The Royal Dutch Shell Group was created in April 1907 through the amalgamation of two rival companies: the Royal Dutch Petroleum Company (Dutch:Koninklijke Nederlandse Petroleum Maatschappij) of the Netherlands and The \"Shell\" Transport and Trading Company Limited of the United Kingdom.It was a move largely driven by the need to compete globally withStandard Oil.The Royal Dutch Petroleum Company was a Dutch company founded in 1890 to develop an oilfield inPangkalan Brandan,North Sumatra,and initially led byAugust Kessler, Hugo Loudon, andHenri Deterding. The \"Shell\" Transport and Trading Company (the quotation marks were part of the legal name) was aBritishcompany, founded in 1897 byMarcus Samuel, 1st Viscount Bearsted, and his brotherSamuel Samuel.Their father had owned an antique company inHoundsditch, London,which expanded in 1833 to import and sell seashells, after which the company \"Shell\" took its name. For various reasons, the new firm operated as adual-listed company, whereby the merging companies maintained their legal existence but operated as a single-unit partnership for business purposes. The terms of the merger gave 60 percent stock ownership of the new group to Royal Dutch, and 40 percent to Shell. Both becameholding companiesforBataafsche Petroleum Maatschappij, containing the production and refining assets, and Anglo-Saxon Petroleum Company, containing the transport and storage assets.National patriotic sensibilities would not permit a full-scale merger or takeover of either of the two companies.The Dutch company,Koninklijke Nederlandsche Petroleum MaatschappijatThe Hague, was in charge of production and manufacture.The BritishAnglo-Saxon Petroleum Companywas based in London, to direct the transport and storage of the products. In 1912, Royal Dutch Shell purchased theRothschilds'Russian oil assetsin a stock deal. The Group's production portfolio then consisted of 53 percent from theEast Indies, 29 percent from theRussian Empire, and 17 percent fromRomania. During theFirst World War, Shell was the main supplier of fuel to theBritish Expeditionary Force.It was also the sole supplier ofaviation fueland supplied 80 percent of the British Army'sTNT.It also volunteered all of its shipping to theBritish Admiralty. TheGerman invasion of Romaniain 1916 saw 17% of the group's worldwide production destroyed.In 1919, Shell took control of theMexican Eagle Petroleum Companyand in 1921 formed Shell-Mex Limited, which marketed products under the \"Shell\" and \"Eagle\" brands in the United Kingdom. During theGenoa Conferenceof 1922 Royal Dutch Shell was in negotiations for a monopoly over Soviet oilfields inBakuandGrosny, although the leak of a draft treaty led to breakdown of the talks.In 1929,Shell Chemicalswas founded.By the end of the 1920s, Shell was the world's leading oil company, producing 11 percent of the world'scrude oilsupply and owning 10 percent of its tanker tonnage. During theSpanish Civil Warthe company sold oil to the Nationalist side ofFrancisco Franco. Located in the north bank of theRiver Thamesin London,Shell Mex Housewas completed in 1931, and was the head office for Shell's marketing activity worldwide.In 1932, partly in response to the difficult economic conditions of theGreat Depression, Shell-Mex merged its UK marketing operations with those ofBP(British Petroleum) to createShell-Mex & BP,a company that traded until the brands separated in 1975. Royal Dutch Company ranked 79th among United States corporations in the value ofWorld War IImilitary production contracts. The 1930s saw Shell's Mexican assets seized by the local government.After theinvasion of the NetherlandsbyNazi Germanyin 1940, the head office of the Dutch companies was moved toCuraçao.In 1945, Shell's Danish headquarters inCopenhagen, at the time being used by theGestapo, was bombed byRoyal Air ForceDe Havilland MosquitoesinOperation Carthage. In 1937,Iraq Petroleum Company(IPC), 23.75 percent owned by Royal Dutch Shell plc,signed an oil concession agreement with theSultan of Muscat. In 1952, IPC offered financial support to raise an armed force that would assist the Sultan in occupying the interior region ofOman, an area that geologists believed to be rich in oil. This led to the 1954 outbreak of theJebel Akhdar Warin Oman that lasted for more than 5 years. Around 1952, Shell was the first company to purchase and use a computer in the Netherlands.The computer, aFerranti Mark 1*, was assembled and used at the Shell laboratory in Amsterdam. In 1970, Shell acquired the mining companyBilliton, which it subsequently sold in 1994. In 1989, Shell redesigned a $3-billion natural gas platform in theNorth Sea, raising its height one to two meters, to accommodate an anticipatedsea level risedue toglobal warming. In the 1990s, protesters criticised the company's environmental record, particularly the possible pollution caused by the proposed disposal of theBrent Sparplatform into the North Sea. Despite support from the UK government, Shell reversed the decision under public pressure but maintained that sinking the platform would have been environmentally better.Shell subsequently published an unequivocal commitment tosustainable development, supported by executive speeches reinforcing this commitment.Shell was subsequently criticised by theEuropean Commissionand five European Union members after deciding to leave part of its decommissioned oil rigs standing in the North Sea. Shell argued that removing them would be too costly and risky. Germany said that the estimated 11,000 tonnes of raw oil and toxins remaining in the rigs would eventually seep into the sea, and called it a 'ticking timebomb'. On 15 January 1999, off theArgentiniantown ofMagdalena, Buenos Aires, the Shell tankerEstrella pampeanacollided with a Germancargo ship, emptying its contents into the lake, polluting the environment, drinkable water, plants and animals. Over a decade after the spill, a referendum held in Magdalena determined the acceptance of a US$9.5 million compensatory payout from Shell.Shell denied responsibility for the spill, but an Argentine court ruled in 2002 that the corporation was responsible. In 2002, Shell acquiredPennzoil-Quaker Statethrough its American division for US$22 per share, or about US$1.8 billion. Through its acquisition of Pennzoil, Shell became adescendant of Standard Oil. With its acquisition, Shell inherited multiple auto part brands includingJiffy Lube,Rain-X, andFix-a-Flat. The company was notably late in its acquisition as seen by journalists, with Shell seen as streamlining its assets around the same time of other major mergers and acquisitions in the industry, such asBP's purchase ofAmocoand the merger ofExxonandMobil. In 2004, Shell overstated its oil reserves, resulting in loss of confidence in the group, a £17 million fine by theFinancial Services Authorityand the departure of the chairmanPhilip Watts. A lawsuit resulted in the payment of $450 million to non-American shareholders in 2007. As a result of the scandal, the corporate structure was simplified. Two classes of ordinary shares, A (code RDSA) and B (code RDSB), identical but for the tax treatment of dividends, were issued for the company. In November 2004, following a period of turmoil caused by the revelation that Shell had been overstating itsoil reserves, it was announced that the Shell Group would move to a single capital structure, creating a new parent company to be named Royal Dutch Shell plc, with its primary listing on the LSE, a secondary listing onEuronext Amsterdam, its headquarters and tax residency inThe Hague, Netherlands and its registered office in London. The company was already incorporated in 2002 asForthdeal Limited, ashelf corporationincorporated by Swift Incorporations Limited and Instant Companies Limited, both based in Bristol.The unification was completed on 20 July 2005 and the original owners delisted their companies from the respective exchanges. On 20 July 2005, The \"Shell\" Transport and Trading Company plc was delisted from the LSE,changing its name to The Shell Transport and Trading Company Limitedwhereas Royal Dutch Petroleum Company was delisted from theNew York Stock Exchangeon 18 November 2005.The shares of the company were issued at a 60/40 advantage for the shareholders of Royal Dutch in line with the original ownership of the Shell Group. During the2009 Iraqi oil services contracts tender, a consortium led by Shell (45%) and which includedPetronas(30%) was awarded a production contract for the \"Majnoon field\" in the south of Iraq, which contains an estimated 12.6 billion barrels (2.00×10m) of oil.The \"West Qurna 1 field\" production contract was awarded to a consortium led byExxonMobil(60%) and included Shell (15%). In February 2010, Shell andCosanformed a 50:50 joint-venture,Raízen, comprising all of Cosan's Brazilian ethanol, energy generation, fuel distribution and sugar activities, and all of Shell's Brazilian retail fuel and aviation distribution businesses.In March 2010, Shell announced the sale of some of its assets, including its liquefied petroleum gas (LPG) business, to meet the cost of a planned $28bn capital spending programme. Shell invited buyers to submit indicative bids, due by 22 March, with a plan to raise $2–3bn from the sale.In June 2010, Shell agreed to acquire all the business ofEast Resourcesfor a cash consideration of $4.7 billion. The transaction included East Resources' tight gas fields. Over the course of 2013, the corporation began the sale of itsUS shale gasassets and canceled a US$20 billion gas project that was to be constructed in the US state ofLouisiana. A new CEOBen van Beurdenwas appointed in January 2014, prior to the announcement that the corporation's overall performance in 2013 was 38 percent lower than in 2012—the value of Shell's shares fell by 3 percent as a result.Following the sale of the majority of its Australian assets in February 2014, the corporation plans to sell a further US$15 billion worth of assets in the period leading up to 2015, with deals announced in Australia, Brazil and Italy. Shell announced on 8 April 2015 it had agreed to buyBG Groupfor £47 billion (US$70 billion), subject to shareholder and regulatory approval.The acquisition was completed in February 2016, resulting in Shell surpassingChevron Corporationand becoming the world's second largest non-state oil company. On 7 June 2016, Shell announced that it would build anethane cracker plantnearPittsburgh, Pennsylvania, after spending several years doing an environmental cleanup of the proposed plant's site. In January 2017, Shell agreed to sell £2.46bn worth ofNorth Seaassets to oil exploration firm Chrysaor.In 2017, Shell sold itsoil sandsassets toCanadian Natural Resourcesin exchange of approximately 8.8% stake in that company. In May 2017, it was reported that Shell plans to sell its shares in Canadian Natural Resources fully exiting the oil sands business. On 5 November 2017, theParadise Papers, a set of confidentialelectronic documentsrelating tooffshore investment, revealed that Argentine Energy MinisterJuan José Arangurenwas revealed to have managed theoffshore companies'Shell Western Supply and Trading Limited' and 'Sol Antilles y Guianas Limited', both subsidiaries of Shell. One is the main bidder for the purchase of diesel oil by the government through the state ownedCAMMESA(Compañía Administradora del Mercado Mayorista Eléctrico). On 30 April 2020, Shell announced that it would cut itsdividendfor the first time since theSecond World War, due to theoil price collapsefollowing the reduction in oil demand during theCOVID-19 pandemic. Shell stated that their net income adjusted for the cost of supply dropped to US$2.9 billion in three months to 31 March. This compared with US$5.3 billion in the same period the previous year.On 30 September 2020, the company said that it would cut up to 9,000 jobs as a result of the economic effects caused by the pandemic and announced a \"broad restructuring\".In December 2020, Shell forecast another write-down of $3.5–4.5 billion for the fourth quarter due to lower oil prices, following $16.8 billion of impairment in the second quarter. In February 2021, Shell announced a loss of $21.7 billion in 2020 due to the COVID-19 pandemic,despite reducing its operating expenses by 12%, or $4.5 billion, according to aMorningstaranalysis cited byBarron's. In November 2021, Shell announced that it is planning to relocate their headquarters to London, abandon its dual share structure, and change its name from Royal Dutch Shell plc to Shell plc.The company's name change was registered in theCompanies Houseon 21 January 2022. In December 2021, Shell pulled out of theCambo oil field, off the Shetland Islands, claiming that \"the economic case for investment in this project is not strong enough at this time, as well as having the potential for delays\". The proposed oilfield had been the subject of intense campaigning by environmentalists in the run-up to the COP26 UN climate summit in Glasgow in November 2021. On 4 March 2022, during theRussian invasion of Ukraineand in the midst of the growingboycott of Russian economy and related divestments, Shell bought a cargo of discounted Russian crude oil.The next day, following criticism from Ukraine's Foreign MinisterDmytro Kuleba, Shell defended the purchase as a short term necessity, but also announced that it intended to reduce such purchases, and it would put profits from any Russian oil it purchases into a fund that would go towards humanitarian aid to Ukraine.On 8 March, Shell announced that it would stop buying Russian oil and gas and close its service stations in the country. In 2022, the major oil and gas companies, including Shell,reported sharp rises in interim revenues and profits.In fact, this rise in profit for Shell was so sharp, that 2022 was the company's best year, as Shell recorded double the profits from 2021, and the highest profit in its entire history. In November 2024, Shell won a case in the Hague court of appeal againstFriends of the Earthwhich would have required Shell to cut its carbon emissions by 45%, in line with theParis Climate Accords. The key trends of Shell are (as at the financial year ending 31 December): On 4 August 2005, the board of directors announced the appointment ofJorma Ollila, chairman and CEO ofNokiaat the time, to succeed Aad Jacobs as the company's non-executive chairman on 1 June 2006. Ollila is the first Shell chairman to be neither Dutch nor British. Other non-executive directors includeMaarten van den Bergh,Wim Kok, Nina Henderson,Lord Kerr, Adelbert van Roxe, and Christine Morin-Postel. Since 3 January 2014,Ben van Beurdenhas been CEO of Shell.His predecessor wasPeter Voserwho became CEO of Shell on 1 July 2009. Following a career at the corporation, in locations such as Australia and Africa, Ann Pickard was appointed as the executive vice president of the Arctic at Royal Dutch Shell, a role that was publicized in an interview withMcKinsey & Companyin June 2014. In January 2023,Wael Sawansucceeded Ben van Beurden as CEO. The name Shell is linked to The \"Shell\" Transport and Trading Company.In 1833, the founder's father, Marcus Samuel Sr., founded an import business to sellseashellsto London collectors. When collecting seashellspecimensin theCaspian Seaarea in 1892, the younger Samuel realised there was potential in exportinglamp oilfrom the region and commissioned the world's first purpose-builtoil tanker, theMurex(Latin for a type ofsnail shell), to enter this market; by 1907 the company had a fleet. Although for several decades the company had a refinery atShell Havenon the Thames, there is no evidence of this having provided the name. The Shell logo is one of the most familiar commercial symbols in the world. This logo is known as the \"pecten\" after the sea shellPecten maximus(the giantscallop), on which its design is based. The yellow and red colours used are thoughtto relate to the colours of theflag of Spain, as Shell built early service stations in California, previously aSpanish colony. The current revision of the logo was designed byRaymond Loewyin 1971. The slash was removed from the name \"Royal Dutch/Shell\" in 2005, concurrent with moves to merge the two legally separate companies (Royal Dutch and Shell) to the single legal entity which exists today. On 15 November 2021, Royal Dutch Shell plc announced plans to change its name to Shell plc. Shell is organised into four major business groupings: Shell's primary business is the management of avertically integratedoil company. The development of technical and commercial expertise in all stages of this vertical integration, from the initial search for oil (exploration) through its harvesting (production), transportation,refiningand finally trading and marketing established the core competencies on which the company was founded. Similar competencies were required for natural gas, which has become one of the most important businesses in which Shell is involved, and which contributes a significant proportion of the company's profits. While the vertically integrated business model provided significanteconomies of scaleandbarriers to entry, each business now seeks to be a self-supporting unit without subsidies from other parts of the company. Traditionally, Shell was a heavily decentralised business worldwide (especially in the downstream) with companies in over 100 countries, each of which operated with a high degree of independence. The upstream tended to be far more centralised with much of the technical and financial direction coming from the central offices inThe Hague. The upstream oil sector is also commonly known as the \"exploration and production\" sector. Downstream operations, which now also includes the chemicals business, generate the majority of Shell's profits worldwide and is known for its global network of more than 40,000petrol stationsand its variousoil refineries. The downstream business, which in some countries also includedoil refining, generally included a retailpetrol stationnetwork, lubricants manufacture and marketing, industrial fuel and lubricants sales, and a host of other product/market sectors such asLPGandbitumen. The practice in Shell was that these businesses were essentially local and that they were best managed by local \"operating companies\" – often with middle and senior management reinforced byexpatriates. Shell has a long history of motorsport sponsorship, most notablyScuderia Ferrari(1951–1964, 1966–1973 and 1996–present),BRM(1962–1966 and 1968–1972),Scuderia Toro Rosso(2007–2013 and 2016),McLaren(1967–1968 and 1984–1994),Lotus(1968–1971),Ducati Corse(since 1999),Team Penske(2011–present),Hyundai Motorsport(since 2005),AF Corse,Risi Competizione,BMW Motorsport(2015–present with alsoPennzoil) andDick Johnson Racing(1987–2004and2017–present). Starting in 2023, Shell became the official fuel forIndyCar Series, supplying E100 race fuel for all teams. In motorcycle racing, Shell andDucatihave been working together globally for a very long time. Shell has indeed been working with Ducati since 1999, through the first support in theSuperbike. The support continues to win more than 150 races, including seven MotoGP world champions. Both in lubricants and fuel products which have now been established for 25 years. This long-term cooperation contract has just been extended in theNetherlandsat 2024 and will continue until the end of 2027. Following the purchase of an offshore lease in 2005, Shell initiated its US$4.5 billionArcticdrilling program in 2006, after the corporation purchased the \"Kulluk\" oil rig and leased the Noble Discoverer drillship.At inception, the project was led by Pete Slaiby, a Shell executive who had previously worked in theNorth Sea.However, after the purchase of a second offshore lease in 2008, Shell only commenced drilling work in 2012, due to the refurbishment of rigs, permit delays from the relevant authorities and lawsuits.The plans to drill in the Arctic led to protests from environmental groups, particularlyGreenpeace; furthermore, analysts in the energy field, as well as related industries, also expressed skepticism due to perceptions that drilling in the region is \"too dangerous because of harsh conditions and remote locations\". Further problems hampered the Arctic project after the commencement of drilling in 2012, as Shell dealt with a series of issues that involved air permits,Coast Guardcertification of a marine vessel, and severe damage to essential oil-spill equipment. Additionally, difficult weather conditions resulted in the delay of drilling during mid-2012 and the already dire situation was exacerbated by the \"Kulluk\" incident at the end of the year. Shell had invested nearly US$5 billion by this stage of the project. As theKullukoil rig was being towed to the American state ofWashingtonto be serviced in preparation for the 2013 drilling season, a winter storm on 27 December 2012 caused the towing crews, as well as the rescue service, to lose control of the rig. As of 1 January 2013, the Kulluk was grounded off the coastSitkalidak Island, near the eastern end ofKodiak Island. Following the accident, aFortunemagazine contacted Larry McKinney, the executive director at the Harte Research Institute for Gulf of Mexico Studies atTexas A&M, and he explained that \"A two-month delay in the Arctic is not a two-month delay ... A two-month delay could wipe out the entire drilling season\". It was unclear if Shell would recommence drilling in mid-2013, following the \"Kulluk\" incident, and, in February 2013, the corporation stated that it would \"pause\" its closely watched drilling project off theAlaskancoast in 2013, and will instead prepare for future exploration.In January 2014, the corporation announced the extension of the suspension of its drilling program in the Arctic, with chief executive van Beurden explaining that the project is \"under review\" due to both market and internal issues. A June 2014 interview with Pickard indicated that, following a forensic analysis of the problems encountered in 2012, Shell will continue with the project and Pickard stated that she perceives the future of the corporation activity in the Arctic region as a long-term \"marathon\".Pickard stated that the forensic \"look back\" revealed \"there was an on/off switch\" and further explained: In other words, don't spend the money unless you're sure you're going to have the legal environment to go forward. Don't spend the money unless you're sure you're going to have the permit. No, I can't tell you that I'm going to have that permit until June, but we need to plan like we're going to have that permit in June. And so probably the biggest lesson is to make sure we could smooth out the on/off switches wherever we could and take control of our own destiny. Based upon the interview with Pickard, Shell is approaching the project as an investment that will reap energy resources with a lifespan of around 30 years. According to theBureau of Ocean Energy Managementreport in 2015 the chances of a major spill in a deep-sea Arctic drilling is 75% before century's end. In 2010, Greenpeace activists painted \"No Arctic Drilling\" using spilledBPoil on the side of a ship in theGulf of Mexicothat was en route to explore forArcticoil for Shell. At the protest,Phil Radfordof Greenpeace called for \"President Obama[to] ban all offshore oil drilling and call for an end to the use of oil in our cars by 2030\". On 16 March 2012, 52 Greenpeace activists from five different countries boardedFennicaandNordica, multipurposeicebreakerschartered to support Shell's drilling rigs near Alaska.Around the same time period, a reporter forFortunemagazinespoke withEdward Itta, anInupiatleader and the former mayor of theNorth Slope Borough, who expressed that he was conflicted about Shell's plans in the Arctic, as he was concerned that an oil spill could destroy the Inupiat peoples hunting-and-fishing culture, but his borough also received major tax revenue from oil and gas production; additionally, further revenue from energy activity was considered crucial to the future of the living standard in Itta's community. In July 2012, Greenpeace activists shut down 53 Shell petrol stations inEdinburghand London in a protest against the company's plans to drill for oil in the Arctic. Greenpeace's \"Save the Arctic\" campaign aims to prevent oil drilling andindustrial fishingin the Arctic by declaring the uninhabited area around the North Pole a global sanctuary. A review was announced after theKullukoil rig ran aground near Kodiak Island in December 2012. In response, Shell filed lawsuits to seek injunctions from possible protests, andBenjamin Jealousof theNAACPand Radford argued that the legal action was \"trampling Americans' rights\".According to Greenpeace, Shell lodged a request with Google to take down video footage of a Greenpeace protest action that occurred at the Shell-sponsoredFormula One(F1) Belgian Grand Prix on 25 August 2013, in which \"SaveTheArctic.org\" banners appear at the winners' podium ceremony. In the video, the banners rise up automatically—activists controlled their appearance with the use of four radio car antennas—revealing the website URL, alongside an image that consists of half of a polar bear's head and half of the Shell logo. Shell then announced a \"pause\" in the timeline of the project in early 2013and, in September 2015, the corporation announced the extension of the suspension of its drilling program in the Arctic. A June 2014 interview with the corporation's new executive vice president of the Arctic indicated that Shell will continue with its activity in the region. InSeattleprotests began in May 2015in response to the news that thePort of Seattlemade an agreement with Shell to berth rigs at the Port's Terminal 5 during the off-season ofoil explorationinAlaskanwaters. The arrival of Shell's new Arctic drilling vessel,Polar Pioneer(IMO number:8754140), asemi-submersibleoffshore drillingrig, was greeted by large numbers of environmental protesters paddling kayaks inElliott Bay. On 6 May 2015, it was reported that during a coast guard inspection ofPolar Pioneer, a piece of anti-pollution gear failed, resulting in fines and delay of the operation.Oil executives from Total and Eni interviewed by theNew York Times, expressed scepticism about Shell's new ambitions for offshore drilling in the Arctic, and cited economic and environmental hurdles.ConocoPhillipsandEquinor (formerly Statoil)suspended Arctic drilling earlier, after Shell's failed attempt in 2012. On 20 May 2011, Shell's final investment decision for the world's firstfloating liquefied natural gas(FLNG) facility was finalized following the discovery of the remote offshore Prelude field—located off Australia's northwestern coast and estimated to contain about 3 trillion cubic feet of natural gas equivalent reserves—in 2007. FLNG technology is based on liquefied natural gas (LNG) developments that were pioneered in the mid-20th century and facilitates the exploitation of untapped natural gas reserves located in remote areas, often too small to extract any other way. Thefloating vesselto be used for the Prelude field, known asPreludeFLNG, is promoted as the longest floating structure in the world and will take in the equivalent of 110,000 barrels of oil per day in natural gas—at a location 200 km (125 miles) off the coast ofWestern Australia—and cool it into liquefied natural gas for transport and sale in Asia. The Prelude is expected to start producing LNG in 2017—analysts estimated the total cost of construction at more thanUS$12 billion. Following the decision by the Shell fuel corporation to close itsGeelong Oil Refineryin Australia in April 2013, a third consecutive annual loss was recorded for Shell's Australian refining and fuel marketing assets. Revealed in June 2013, the writedown is worthA$203 million and was preceded by a A$638m writedown in 2012 and a A$407m writedown in 2011, after the closure of theClyde Refineryin Sydney. In February 2014, Shell sold its Australian refinery and petrol stations for US$2.6 billion (A$2.9 billion) to Swiss companyVitol. At the time of the downstream sale to Vitol, Shell was expected to continue investment into Australian upstream projects, with projects that involve Chevron Corp.,Woodside Petroleumand Prelude.In June 2014, Shell sold 9.5% of its 23.1% stake inWoodside Petroleumand advised that it had reached an agreement for Woodside to buy back 9.5% of its shares at a later stage. Shell became a major shareholder in Woodside after a 2001 takeover attempt was blocked by then federal TreasurerPeter Costelloand the corporation has been open about its intention to sell its stake in Woodside as part of its target to shed assets. At a general body meeting, held on 1 August 2014, 72 percent of shareholders voted to approve the buy-back, short of the 75 percent vote that was required for approval. A statement from Shell read: \"Royal Dutch Shell acknowledges the outcome of Woodside Petroleum Limited's shareholders' negative vote on the selective buy-back proposal. Shell is reviewing its options in relation to its remaining 13.6 percent holding\". Brunei Shell Petroleum (BSP) is a joint venture between the Government ofBruneiand Shell.The British Malayan Petroleum Company (BMPC), owned by Royal Dutch Shell, first found commercial amounts of oil in 1929.It currently produces 350,000 barrels of oil and gas equivalent per day.BSP is the largest oil and gas company in Brunei, a sector which contributes 90% of government revenue.In 1954, the BMPC in Seria had a total of 1,277 European and Asian staff. The company has upstream operations in unconventionaloilandgasin China. Shell has a joint venture withPetroChinaat the Changbeitight gasfield inShaanxi, which has produced natural gas since 2008. The company has also invested in exploring forshale oilin Sichuan.The other unconventional resource which Shell invested in in China was shale. The company was an early entrant in shale oil exploration in China but scaled down operations in 2014 due to difficulties with geology and population density.It has a joint venture to explore foroil shalein Jilin through a joint venture with Jilin Guangzheng Mineral Development Company Limited. In May 2024, Shell announced an exit from China power market business to focus on more profitable operations. Shell has been active in Hong Kong for a century, providing Retail, LPG, Commercial Fuel, Lubricants, Bitumen, Aviation, Marine and Chemicals services, and products. Shell also sponsored the first Hong Kong-built aircraft,Inspiration, for its around-the-world trip. Shell India has inaugurated its new lubricants laboratory at its Technology Centre inBangalore. Shell started operating in Indonesia since 1928. Shell started operatinggas stationsin Indonesia since 1 November 2005. Its first gas station was located inLippo Karawaci,Tangerang. On 1 March 2006, Shell opened a gas station inJakartalocated on Jalan S. Parman (Slipi). As of 2022, the fuels that Shell sells in Indonesia are Shell Super,Shell V-Power, Shell V-Power Nitro+,Shell V-Power Dieseland Shell Diesel Extra. Shell first started trading in Ireland in 1902.Shell E&P Ireland (SEPIL) (previously Enterprise Energy Ireland) is an Irish exploration and production subsidiary of Royal Dutch Shell. Its headquarters are onLeeson Streetin Dublin. It was acquired in May 2002.Its main project is theCorrib gas project, a large gas field off the northwest coast, for which Shell has encounteredcontroversy and protestsin relation to the onshore pipeline and licence terms. In 2005, Shell disposed of its entire retail and commercial fuels business in Ireland toTopaz EnergyGroup. This included depots, company-owned petrol stations and supply agreements stations throughout the island of Ireland.The retail outlets were re-branded as Topaz in 2008/9. The Topaz fuel network was subsequently acquired in 2015 byCouchetardand these stations began re-branding toCircle Kin 2018. Shell's activities in Italy began on 13 July 1912, with the creation of \"Nafta\",based inLa Spezia, founded after taking advantage of the weakness of the formerStandard Oil Trust, dissolved the previous year. During theFirst World War, Nafta abandoned the private sector, focusing on the war supplies to theItalian state. During the conflict, the company expanded, with the opening of new plants inNaplesandAugustaand, after the end of hostilities, with the exploitation of further internal deposits. In thefirst post-war period, the company controlled the Italian internal market together with the SIAP, the local branch of theStandard of New Jersey (Esso). In 1921, under pressure from the CEO Giovanni Attilio Pozzo (then also elected president in 1923), the share capital was increased reaching 100 million lire.The products sold at the time included \"Bentero Shell\" and \"Aureola Petroli\". In 1922, despite the difficult economic situation of the country, the company grew, and the newVado Ligureplant was inaugurated.The inauguration, however, caused a short political clash between the Prime MinisterFactaand thesocialistdeputyTonello, who in aparliamentary questionharshly criticized the official telegram sent by Facta to \"Nafta\" on the occasion of the ceremony.In the same year, the works for a coastal system inVenicealso continued. The birth ofAgipcreated some disagreements between Nafta and theMinistry of the National Economy, which in 1926 asked the Prefects to subordinate the release of new concessions for the plant ofpetrol stationsto an approval estimate of Agip; the question was resolved peacefully in 1927 on the initiative of the Italian company itself. At the end of the decade, taking advantage of a particularly advantageous legislation, the company launched into therefining sector, with the establishment of subsidiary companies in La Spezia. On 27 April 1939, Pozzo left \"Nafta\", after twenty years at the head of the company. The company controlled about 20% of the Italian market at the time. On 8 August 1940, following Italy's entry into theSecond World War, Nafta was seized and placed under the management of Agip, followed the following year by the US companies operating in Italy (SIAP,Vacuum,Texaco). On 30 July 1942 foreign oil companies were officially transferred to Agip, although the integration of their activities was somewhat complex and remained substantially unfinished. On 22 October 1945, after the end of hostilities, the measures were abandoned and the NAFTA and the other companies, under the guidance of the Italian Petroli Committee, returned to normal activity. In 1949 the company, now fully restored, was renamed \"Shell Italiana S.p.A\". with a share capital of more than 2 billion lira.Still in the early 1960s, Shell covered about 20% of the Italian oil needs. The Italian Shell was the first company to be advertised withCarosello. In 1959 the company purchased the former Condor refinery ofRhoand in 1967 it built a large plant inTaranto,whose works began in 1964 with an initial investment of 25 billion lire. Shell remained active in the country until April 1974 when, following difficulties in the oil sector caused by theKippur Warand the general conditions of the Italian economy, now not very favorable, the old company was sold toEni, which becameItaliana Petroli (IP).The company then returned to the fuel distribution in 1980,with the acquisition of theConoconetwork,while in 1987 the joint venture withMontedisonwhich led to the creation ofMonteShell. In July 2014 Shell gave its network of service stations and fuel deposits in Italy to theKuwait Petroleum Italia(Q8). In 2022 an agreement was announced with the Pad Multiegy company, for the brand to be restored and Shell products to be sold in over 500 Italian service stations,the first of which was inaugurated in March 2022. In Italy today Shell operates through Shell Italia S.p.A. controlled by Shell Italia Finanza S.p.A. The main locations are inSesto San GiovanniandRome. Shell discovered the first oil well in Borneo in 1910, inMiri, Sarawak. Today, the oil well is a state monument known as the Grand Old Lady. In 1914, following this discovery, Shell built Borneo's first oil refinery and laid a submarine pipeline inMiri. Shell began production inNigeriain 1958.InNigeria, Shell told US diplomats that it had placed staff in all the main ministries of thegovernment.Shell continues however upstream activities/extracting crude oil in the oil-richNiger Deltaas well as downstream/commercial activities in South Africa. In June 2013, the company announced a strategic review of its operations in Nigeria, hinting that assets could be divested.In August 2014, the company disclosed it was in the process of finalizing the sale of its interests in fourNigerian oil fields.On 29 January 2021 a Dutch court ruled that Shell was responsible for multiple oil leaks in Nigeria. The actions of companies like Shell has led to extremeenvironmental issues in the Niger Delta. Many pipelines in the Niger Delta owned by Shell are old and corroded. Shell has acknowledged its responsibility for keeping the pipelines new but has also denied responsibility for environmental causes.The heavy contamination of the air, ground and water with toxic pollutants by the oil industry in the Niger Delta is often used as an example ofecocide.This has led to mass protests from theNiger Deltainhabitants,Amnesty International, andFriends of the Earththe Netherlands against Shell. It has also led to action plans to boycott Shell byenvironmentalandhuman rights groups.In January 2013, a Dutch court rejected four out of five allegations brought against the firm over oil pollution in the Niger Delta but found a subsidiary guilty of one case of pollution, ordering compensation to be paid to a Nigerian farmer. On 27 August 2007, Shell andReitan Group, the owner of the7-Elevenbrand inScandinavia, announced an agreement to re-brand some 269 service stations acrossNorway, Sweden,FinlandandDenmark, subject to obtaining regulatory approvals under the differentcompetition lawsin each country.In April 2010 Shell announced that the corporation is in process of trying to find a potential buyer for all of its operations in Finland and is doing similar market research concerning Swedish operations.In October 2010 Shell's gas stations and the heavy vehicle fuel supply networks in Finland and Sweden, along with a refinery located inGothenburg, Sweden were sold toSt1, a Finnish energy company, more precisely to its major shareholding parent company Keele Oy.Shell gas stations in Norway were taken over by St1 in 2015, but continued operating under the Shell brand until 2025. Through most of Shell's early history, theShell USbusiness in the United States was substantially independent. Its stock was traded on theNYSE, and the group's central office had little direct involvement in running the operation. However, in 1984, Shell made a bid to purchase those shares of Shell Oil Company it did not own (around 30%) and, despite opposition from some minority shareholders which led to a court case, Shell completed the buyout for a sum of $5.7 billion. Royal Dutch Shell operates in thePhilippinesunder its subsidiary,Shell Pilipinas CorporationorSPC. Its headquarters is inTaguigand it has facilities in thePandacan oil depotand other key locations. In January 2010, theBureau of Customsclaimed 7.34 billion pesos worth of unpaidexcise taxesagainstPilipinas Shellfor importing Catalytic cracked gasoline (CCG) and light catalytic cracked gasoline (LCCG) stating that those imports are bound for tariff charges. In August 2016, Pilipinas Shell filed an application to sell US$629 million worth of primary and secondary shares to the investing public (registration statement) with theSEC. This was a prelude to filing its IPO listing application with thePhilippine Stock Exchange. On 3 November 2016 the Pilipinas Shell Petroleum Corporation was officially listed on thePhilippine Stock Exchangeunder the ticker symbol SHLPH after they held itsinitial public offeringon 19 to 25 October of the same year. Due to the economic slowdown caused by the COVID-19 pandemic on the global, regional and local economies, continually low refining margins, and competition with imported refined products, the management of Pilipinas Shell announced in August 2020 that the 110,000 bbl/d refinery in Tabangao, Batangas, which started operations in 1962, will be shutting down permanently and turned into an import terminal instead. In February 2022, Shell exited all its joint ventures withGazprombecause of the2022 Russian invasion of Ukraineand, in March 2022, Shell announced that it would stop buying oil from Russia and close all its service stations there.In April 2022, it emerged that Shell was to book up to $5 billion in impairment charges from exiting its interests in Russia. Singapore is the main centre for Shell's petrochemical operations in the Asia Pacific region. Shell Eastern Petroleum limited (SEPL) have their refinery located in Singapore'sPulau Bukomisland. They also operate as Shell Chemicals Seraya inJurong Island.In November 2020, Shell announced that, as part of efforts to curtail pollution emissions, it will cut its oil-processing capacity in Singapore. Shell Downstream SA (SDSA) was created through a merger of Shell South Africa andBBBEEcompany Thebe Investment Corporation. The South AfricanDepartment of Mineral Resources and Energygranted Shell exploration rights in the country, and it has been operating in South Africa since 1902. The company also owns an oil refinery inDurban, which has been closed since the end of March 2022. On 6 May 2024, Shell indicated its intent to exit the South African downstream market. This includes its refining, transport, and retail offerings. It is as yet unknown what will happen to its gas stations. Shell is a member of theFuels Industry Association of South Africa(FIASA), and was one of its founding members when the organization launched in 1994. Prior to the 1960s, Shell was one of the major multinational corporations operating in Sri Lanka, alongside companies likeEssoandCaltex. These companies played pivotal roles in importing, distributing, and retailing petroleum products across the country. However, in 1962, under the leadership of Prime MinisterSirimavo Bandaranaike, theSri Lankan governmentnationalizedthe assets of these oil giants. This move aimed to reduce foreign dominance in key economic sectors and led to the establishment of theCeylon Petroleum Corporation(CPC), granting it exclusive rights over the importation, sale, export, and distribution of most petroleum products in Sri Lanka. After a period of reduced presence, Shell re-entered the Sri Lankan market in the mid-1990s. In 1996, Shell acquired a 51% stake in theColombo Gas Companyfor $37 million, marking its significant return to the country's energy sector. This acquisition led to the establishment of Shell Gas Lanka Limited, which managed the importation, storage, and distribution of liquefied petroleum gas (LPG) in Sri Lanka. In recent years, Shell has signaled its intent to re-establish a presence in Sri Lanka's fuel retailing market. In collaboration with RM Parks and Tristar, Shell announced plans to introduce Shell-branded fuel stations in the country, marking a significant return to the Sri Lankan energy landscape. On 26 February 2025, Shell marked its return to Sri Lanka's fuel retail market by inaugurating its first Shell-branded fuel station in over six decades. This station is located at the B.S. Cooray Filling Station in Ambathale, Colombo District. In the UK sector of theNorth SeaShell employs around 4,500 staff in Scotland as well as an additional 1,000 service contractors: however in August 2014 it announced it was laying off 250 of them, mainly inAberdeen.Shell paid no UK taxes on its North Sea operations over the period 2018 to 2021. In the early 2000s Shell moved intoalternative energyand there is now an embryonic \"Renewables\" business that has made investments insolar power,wind power,hydrogen, andforestry. The forestry business went the way of nuclear, coal, metals and electricity generation, and was disposed of in 2003. In 2006 Shell paidSolarWorldto take over its entire solar businessand in 2008, the company withdrew from theLondon Arraywhich when built was the world's largest offshore wind farm. Shell also is involved in large-scale hydrogen projects. HydrogenForecast.com describes Shell's approach thus far as consisting of \"baby steps\", but with an underlying message of \"extreme optimism\".In 2015, the company announced plans to install hydrogen fuel pumps across Germany, planning on having 400 locations in operation by 2023. Shell holds 44% ofRaízen, a joint venture with Brazilian sugarcane producerCosanwhich is the third-largest Brazil-based energy company by revenues and a major producer ofethanol.In 2015, the company partnered with Brazilian start-up company Insolar to install solar panels inRio de Janeiroto deliver electricity to theSanta Martaneighbourhood. Shell is the operator and major shareholder of TheShell CanadaQuest Energy project, based within the Athabasca Oil Sands Project, located nearFort McMurray, Alberta.It holds a 60% share, alongsideChevron Canada Limited, which holds 20%, and Marathon Canadian Oil Sands Holding Limited, which holds the final 20%.Commercial operations launched in November 2015. It was the world's first commercial-scale oil and sandcarbon capture storage (CCS)project.It is expected to reduce CO2emissions in Canada by 1.08 million tonnes per year. In December 2016, Shell won the auction for the 700 MWBorssele III & IVoffshore wind farmsat a price of 5.45c/kWh, beating 6 otherconsortia.In June 2018, it was announced that the company and its co-investorPartners Grouphad secured $1.5bn for the project, which also involvesEneco,Van Oord, and Mitsubishi/DGE. In October 2017, it bought Europe's biggest vehicle charging network, \"NewMotion\". In November 2017, Shell's CEO Ben van Beurden announced Shell's plan to cut half of its carbon emissions by 2050, and 20 percent by 2035. In this regard, Shell promised to spend $2 billion annually on renewable energy sources. Shell began to develop its wind energy segment in 2001, the company now operates six wind farms in the United States and is part of a plan to build two offshore wind farms in the Netherlands. In December 2017, the company announced plans to buy UK household energy and broadband providerFirst Utility.In March 2019 it rebranded toShell Energyand announced that all electricity would be supplied from renewable sources. In December 2018, the company announced that it had partnered withSkyNRGto begin supplyingsustainable aviation fuelto airlines operating out ofSan Francisco Airport (SFO), includingKLM,SAS, andFinnair.In the same month, the company announced plans to double its renewable energy budget to investment in low-carbon energy to $4 billion US each year, with an aim to spend up to $2 billion US on renewable energy by 2021. In January 2018, the company acquired a 44% interest in Silicon Ranch, a solar energy company run byMatt Kisber, as part of its global New Energies project.The company took over from Partners Group, paying up to an estimated $217 million for the minority interest. In February 2019, the company acquired German solar battery companySonnen.It first invested in the company in May 2018 as part of its New Energies project.As of late 2021, the company had 800 employees and has installed 70.000 home battery systems. On 27 February 2019, the company acquired British VPP operator Limejump for an undisclosed amount. In July 2019, Shell installed their first 150 kW electric car chargers at its Londonpetrol stationswith payments handled viaSMOOV. They also plan to provide 350 kW chargers in Europe by entering into an agreement withIONITY. On 26 January 2021, Shell said it would buy 100 per cent of Ubitricity, owner of the largest public charging network forelectric vehicles in the United Kingdom, as the company expands its presence along the power supply chain.In 2023, Shell announced that it would rebrand its Ubitricity chargepoints under its Shell Recharge brand. On 25 February 2021, Shell announced the acquisition of German Virtual Power Plant (VPP) company Next Kraftwerke for an undisclosed amount. Next Kraftwerke connects renewable electricity generation- and storage projects to optimize the usage of those assets. The company mostly operates in Europe. In November 2022, it was announced Shell's wholly owned subsidiary, Shell Petroleum NV, had acquired theOdense-headquarteredrenewable natural gasproducer, Nature Energy Biogas A/S for nearly US$2 billion. Shell is mainly owned by institutional investors. The 10 largest shareholders of Shell plc in early 2024 were: In 2020, theNorthern Lights CCS projectwas announced, which is a joint project between Equinor, Shell and Total, operating in the European Union (Norway) and aiming to store liquid CO2beneath the seabed. Environmentalists have expressed concern that Shell is processing oil from theAmazon regionof South America. In the United States, the Martinez refinery (CA) and the Puget Sound Refinery (WA) carry Amazonian oil. In 2015, 14% of the Martinez refinery's gross, at 19,570 barrels per day, came from the Amazon. In December 2021, Royal Dutch Shell decided to move ahead with seismic tests to explore for oil inhumpback whalebreeding grounds along South Africa's eastern coastline.On 3 December 2021, a South African high court struck down an urgent application brought by environmentalists to stop the project, which will involve a vessel regularly firing an air gun that produces a very powerful shock wave underwater to help map subsea geology. According to Greenpeace Africa and the South African Deep Sea Angling Association, this could cause \"irreparable harm\" to the marine environment, especially to migrating humpback whales in the area. Measured by both its own emissions, and the emissions of all the fossil fuels it sells, Shell was theninth-largest corporate producer of greenhouse gas emissionsin the period 1988–2015.The burning of the fossil fuels produced by Shell are responsible for 1.67% of global industrialgreenhouse gas emissionsfrom 1988 to 2015. In the past, Shell has been a part of lobbying and trade groups that are against climate policy and promote climate skepticism. In 2017, a public information film (\"Climate of Concern\") unseen for years resurfaced and showed Shell had clear grasp of global warming 26 years earlier but has not acted accordingly since, said critics.During the years of 2010–2018, only 1% of Shell's long-term investments were dedicated to sources of low-carbon energy such as wind and solar. In the years of 2015–2017, just 0.4% of its revenue was put towards low-carbon technology. Shell failed to meet its own target in 2020 to spend $6 billion on renewable energy. In 2021, 30% of Shell's shareholders voted for a climate resolution filed byshareholder advocacygroupFollow This.Still, it is estimated that Shell is not on track to meet its own investment target for 2025, and that the company needs to direct over half of its capital expenditures (nearly $10 billion per year) to zero carbon investments to meet its long-term net-zero targets.In April 2020, Shell announced plans to achievenet zero greenhouse gas emissionsby 2050 or sooner.They also pledged to reduce carbon intensity of all energy products by 20% by 2030, and 45% by 2035 (compared to 2016 levels.)However, internal documents from the company released by the Democratic-led House committee reveal a private 2020 communication saying Shell does not have any plans to bring emissions to zero for next 10–20 years. In March 2024, Shell CEO Wael Sawan announced that the company would moderate its near-term carbon emissions reduction targets, revising its reduction innet carbon intensityof third-party use of products down to 15% from 20% and dropping its target of a 45% reduction in carbon emissions by 2035 from a 2016 baseline. Shell plc reported 58 million metric tons of emissions from its operations in 2024 with 50 million metric tons coming from Scope 1 sources and 8 million metric tons coming from Scope 2 sources. This high level of emissions is a result of Shell plc's main business activities, which include gas production and oil refining. Actually, industries with a high environmental risk account for 100% of the company's revenue, with consumable fuels making up 89.7% of this total.Even if Shell cut methane emissions by 19.5% and gas flaring by 14.3% in a single year, its green revenue is still only 0.2%.Additionally, there are extremely high environmental risks associated with the company's value chain, particularly with regard to greenhouse gas emissions and ecosystem change. Shell's company faces risks and challenges as a result of climate change. The corporation works in high-risk industries that could be impacted by public opinion and laws related to climate change. The fact that 3% of Shell's assets are located in pristine areas, for instance, may cause future disputes and more strict laws.Shell has declared a transition strategy and a target of achieving net zero emissions by 2050 in order to address these threats. By 2024, Shell had exceeded its goal of reducing emissions by 30% over a 14-year period.Its emissions, particularly those from Scope 3, are still greater than some industry standards, nonetheless. On 5 April 2019,Milieudefensie(Dutchfor \"environmental defense\"), together with six NGOs and more than 17,000 citizens, sued Shell, accusing the company of harming the climate despite knowing about global warming since 1986.In May 2021, the district court ofThe Hagueruled that Shell must reducecarbon dioxide emissionsby 45% by 2030 (compared to 2019 levels). Shell contested the 2021 ruling, contendeding that the ruling exceeded judicial authority and could lead to counterproductive outcomes. The outcome was anticipated to significantly impact Shell's operations and influence European energy companies' climate policies.On 12 November 2024, The Hague's appeals court dismissed the 2021 ruling that had required Shell to cut its absolute carbon emissions by 45% by 2030, relative to 2019 levels, including emissions resulting from the use of its products. On 2 September 2002, Shell chairman Philip Watts accepted the \"Greenwash Lifetime Achievement Award\" from the Greenwash Academy's Oscar Green, near the World Summit on Sustainable Development. In 2007, BritishASAruled against a Shell ad involving chimneys spewing flowers, which depicted Shell's waste management policies, claiming it was misleading the public about Shell's environmental impact. In 2008, the British ASA ruled that Shell had misled the public in an advertisement when it claimed that a $10 billionoil sandsproject inAlberta, Canada, was a \"sustainable energy source\". In 2021,Netherlandsofficials told Shell to stop running a campaign which claimed customers could turn their fuel \"carbon neutral\" by buying offsets, as it was concluded that this claim was devoid of evidence. In December 2022,U.S. House Oversight and Reform CommitteeChairCarolyn MaloneyandU.S. House Oversight Environment SubcommitteeChairRo Khannasent a memorandum to all House Oversight and Reform Committee members summarizing additional findings from the committee's investigation into the fossil fuel industry disinformation campaign to obscure the role of fossil fuels in causing global warming, and that upon reviewing internal company documents, accused Shell along withBP,Chevron Corporation, andExxonMobilofgreenwashingtheirParis Agreementcarbon neutralitypledges while continuing long-term investment in fossil fuel production and sales, for engaging in a campaign to promote the use of natural gas as a clean energy source and bridge fuel to renewable energy, and of intimidating journalists reporting about the companies' climate actions and of obstructing the committee's investigation, which ExxonMobil, Shell, and theAmerican Petroleum Institutedenied. A number of incidents over the years led to criticism of Shell'shealth and safetyrecord, including repeated warnings by theUK Health and Safety Executiveabout the poor state of the company's North Sea platforms. Shell already had previous experience exiting markets that were subject to sanctions pressure from NATO or EU member states. In particular, in 2013, Shell announced that it was suspending its operations in Syria.On 8 March 2022, Shell announced its intention to phase out all Russian hydrocarbon production and acquisition projects, including crude oil, petroleum products, natural gas and liquefied natural gas (LNG). In early 2022, the company was criticized by the Minister of Foreign Affairs of Ukraine for its slow response to the Russian invasion.As of April 2023, Shell still had shares in Russian companies, such as 27.5% in Sakhalin Energy Investment Company (SEIC), a joint venture with Gazprom (50%), Mitsui (12.5%) and Mitsubishi (10%). This domain name was first registered by a former marketing manager for Royal Dutch Shell plc, Alfred Donovan, and has been used as a \"gripe site\".It avoids being an illegalcybersquatteras long as it is non-commercial, active, and no attempt is made to sell the domain name, as determined byWIPOproceedings.In 2005, Donovan said he would relinquish the site to Shell after it \"gets rid of all the management he deems responsible for its various recent woes\".The site has been recognized by several media outlets for its role as anInternet leak. In 2008, theFinancial Timespublished an article based on a letter published by royaldutchshellplc.com,whichReutersandThe Timesalso covered shortly thereafter.On 18 October 2006, the site published an article stating that Shell had for some time been supplying information to the Russian government relating toSakhalin II.The Russian energy companyGazpromsubsequently obtained a 50% stake in the Sakhalin-II project.Other instances where the site has acted as an Internet leak include a 2007IToutsourcing plan,as well as a 2008 internal memo where CEOJeroen van der Veerexpressed disappointment in the company's share-price performance. The gripe site has also been recognized as a source of information regarding Shell by several news sources. In the 2006Fortune Global 500rankings, in which Royal Dutch Shell placed third, royaldutchshellplc.com was listed alongside shell.com as a source of information.In 2007, the site was described as \"a hub for activists and disgruntled former employees\".A 2009 article called royaldutchshellplc.com \"the world's most effective adversarial Web site\".The site has been described as \"an open wound for Shell\". (In chronological order)", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Shell_plc", "https://en.wikipedia.org/wiki/Shell_plc", "https://en.wikipedia.org/wiki/Shell_plc", "https://en.wikipedia.org/wiki/Shell_Centre", "https://en.wikipedia.org/wiki/Public_limited_company", "https://en.wikipedia.org/wiki/Ticker_symbol", "https://en.wikipedia.org/wiki/London_Stock_Exchange", "https://en.wikipedia.org/wiki/Euronext_Amsterdam"]},
{"id": "7c99a20f425e", "url": "https://en.wikipedia.org/wiki/Rich_Johnston", "title": "Rich Johnston", "headings": ["Contents", "Early life", "Career", "Comics journalism/gossip", "Comics creator", "Non-comics writing", "Media appearances", "Parodies", "Personal life", "Bibliography", "References", "External links"], "content": " Richard\"Rich\"Johnstonis a Britishcomicscreator, columnist,and founder of the comics news siteBleeding Cool. The Comics Journaldescribed Johnston as having claimed to be \"the oldest extant comics news reporter on the Internet.\"His past columns include \"All The Rage\" (forSilver Bullet Comic Books), and \"Lying in the Gutters\" (forComic Book Resources). Johnston grew up inPontefract,West Yorkshire. He subsequently moved to London. Rich's Revelationswas originally a simple relisting of British magazine comics news.Johnston began writing gossip onUSENETnewsgroups in 1994 asRich's Ramblings.He then took the column, around  onto the burgeoning World Wide Web, with \"Rich's Revelations\" on the now-defunct Twist And Shout Comics website.He later started the comics gossip column \"All The Rage\" forSilver Bullet Comic Books, laterComics Bulletin. Johnston wrote the column \"Lying in the Gutters\" forComic Book Resources,posting rumours and gossip, with atraffic lighticon imparting advisory caution as to the possible credibility of each rumour: a red light denoting the least likelihood of accuracy, a green light for the most credible reports, and a yellow light for those that fall somewhere in between. Johnston's writing does not often impart sources. About that, Johnston said, \"I often obfuscate sources to hide their identity—even deny that a story has sources on many occasions.\" Johnston sees himself as part of a tradition established by the \"British tabloid press, one that seeks to entertain rather than inform.\" On 27 March 2009, Johnston announced his launch of the website BleedingCool.com. Bleeding Cool was nominated for the \"Favourite Comics Related Website\"Eagle Awardin 2010and 2011 and won in 2012. It was named as one ofPC Magazine's top blogs of 2010.and Technorati gave it a perfect 1000 score for influence in the comics category.Johnston was awarded theShel Dorf Awardfor Best Comics Blogger for his work on Bleeding Cool in 2012.He was also nominated in 2011and 2013. Johnston has written a number of comics, mainly consisting ofone-shotsandgraphic novella. The first consists of parodies, such asWatchmenschandCivil Wardrobe(alluding toMarvel's2006 storyCivil War).The second include his original work, bothcreator-ownedand those based onlicensed properties, likeDoctor Who: A Room With A Deja View,The Flying Friar(based on the life ofJoseph of Cupertino)andChase Variantwhich started life atMam Tor Publishing'sEvent Horizon. In 2007, he wrote theIDWtrading card setGeorge W. Bush and the Weapons of Mass Distraction. He wrote and drew a number of pages for thePopbitchbook and curated theHarrodsComic Timing exhibition of original comic book artwork. In 2009, he had a story scheduled for theSpearmintanthology fromImage ComicswithSleaze Castlewriter-artistTerry Wiley.He wrote a short story, \"Rustlin Up Business,\" for the second volume ofOutlaw Territory, published in February 2011. He has also writtenKate and William: A Very Public Love Story, a comic commemorating thewedding of Prince William and Catherine Middleton, published byMarkosia. In 2012, he wrote a comic serialised inDark Horse PresentsentitledThe Many Murders of Miss Cranbourne, with art fromSimon Rohrmüller. He also wrote a series of parody comics forBoom! Studios, taking on Marvel Studios films, withIron Man,Thor,Captain America, andThe Avengersreinterpreted as \"Iron Muslim\", \"Scienthorlogy,\" \"Captain American Idol,\" and \"The Avengefuls,\" respectively. Johnston writes and draws weekly cartoons for the UK bloggerPaul Staines, appearing each Monday and collected atRichAndMark.com. Johnston wrote briefly for newspapers likeThe Guardianand magazines likePlayStation World.The now-closed publicationPunchmagazine named him Young Writer of the Year Award in 2001. His poster campaign for theChurches Advertising Networkin December 2006 generated coverage,including a leader in the Times Newspaperand an appearance on BBC'sThe One Show. He was an advertisingcopywriteruntil 2009. Johnston contributed to the BritishChannel 4sketch showSmack the Ponyas well as forBBC Radio 4's satirical sketch showWeek Endingand the stage/TV showThe Sitcom Trials. He appeared as an interviewee inAfter the Chalk Dust Settled, a documentary included on the DVD release ofSteven Moffat's sitcomChalk. He was a zombie extra inShaun of the Deadand a congregation member in the movieHitchhiker's Guide to the Galaxy. He wrote and directed a series of radio advertisements for telecommunications companyTalkTalkstarringMark Heap. In 2006, he appeared as a character in the comic bookCSI: Dying in the Guttersas a source of \"inside joke\" humour by featuring him as the victim in a murder mystery set at a comic book convention and using other notable real-world comics creators as suspects in the crime.He also appeared as a character in theJodie Picoultnovel,The Tenth Circleand made a more major appearance in theLeveragenovelThe Con Job. Johnston has two daughters.", "combined_text": "Rich Johnston Contents Early life Career Comics journalism/gossip Comics creator Non-comics writing Media appearances Parodies Personal life Bibliography References External links  Richard\"Rich\"Johnstonis a Britishcomicscreator, columnist,and founder of the comics news siteBleeding Cool. The Comics Journaldescribed Johnston as having claimed to be \"the oldest extant comics news reporter on the Internet.\"His past columns include \"All The Rage\" (forSilver Bullet Comic Books), and \"Lying in the Gutters\" (forComic Book Resources). Johnston grew up inPontefract,West Yorkshire. He subsequently moved to London. Rich's Revelationswas originally a simple relisting of British magazine comics news.Johnston began writing gossip onUSENETnewsgroups in 1994 asRich's Ramblings.He then took the column, around  onto the burgeoning World Wide Web, with \"Rich's Revelations\" on the now-defunct Twist And Shout Comics website.He later started the comics gossip column \"All The Rage\" forSilver Bullet Comic Books, laterComics Bulletin. Johnston wrote the column \"Lying in the Gutters\" forComic Book Resources,posting rumours and gossip, with atraffic lighticon imparting advisory caution as to the possible credibility of each rumour: a red light denoting the least likelihood of accuracy, a green light for the most credible reports, and a yellow light for those that fall somewhere in between. Johnston's writing does not often impart sources. About that, Johnston said, \"I often obfuscate sources to hide their identity—even deny that a story has sources on many occasions.\" Johnston sees himself as part of a tradition established by the \"British tabloid press, one that seeks to entertain rather than inform.\" On 27 March 2009, Johnston announced his launch of the website BleedingCool.com. Bleeding Cool was nominated for the \"Favourite Comics Related Website\"Eagle Awardin 2010and 2011 and won in 2012. It was named as one ofPC Magazine's top blogs of 2010.and Technorati gave it a perfect 1000 score for influence in the comics category.Johnston was awarded theShel Dorf Awardfor Best Comics Blogger for his work on Bleeding Cool in 2012.He was also nominated in 2011and 2013. Johnston has written a number of comics, mainly consisting ofone-shotsandgraphic novella. The first consists of parodies, such asWatchmenschandCivil Wardrobe(alluding toMarvel's2006 storyCivil War).The second include his original work, bothcreator-ownedand those based onlicensed properties, likeDoctor Who: A Room With A Deja View,The Flying Friar(based on the life ofJoseph of Cupertino)andChase Variantwhich started life atMam Tor Publishing'sEvent Horizon. In 2007, he wrote theIDWtrading card setGeorge W. Bush and the Weapons of Mass Distraction. He wrote and drew a number of pages for thePopbitchbook and curated theHarrodsComic Timing exhibition of original comic book artwork. In 2009, he had a story scheduled for theSpearmintanthology fromImage ComicswithSleaze Castlewriter-artistTerry Wiley.He wrote a short story, \"Rustlin Up Business,\" for the second volume ofOutlaw Territory, published in February 2011. He has also writtenKate and William: A Very Public Love Story, a comic commemorating thewedding of Prince William and Catherine Middleton, published byMarkosia. In 2012, he wrote a comic serialised inDark Horse PresentsentitledThe Many Murders of Miss Cranbourne, with art fromSimon Rohrmüller. He also wrote a series of parody comics forBoom! Studios, taking on Marvel Studios films, withIron Man,Thor,Captain America, andThe Avengersreinterpreted as \"Iron Muslim\", \"Scienthorlogy,\" \"Captain American Idol,\" and \"The Avengefuls,\" respectively. Johnston writes and draws weekly cartoons for the UK bloggerPaul Staines, appearing each Monday and collected atRichAndMark.com. Johnston wrote briefly for newspapers likeThe Guardianand magazines likePlayStation World.The now-closed publicationPunchmagazine named him Young Writer of the Year Award in 2001. His poster campaign for theChurches Advertising Networkin December 2006 generated coverage,including a leader in the Times Newspaperand an appearance on BBC'sThe One Show. He was an advertisingcopywriteruntil 2009. Johnston contributed to the BritishChannel 4sketch showSmack the Ponyas well as forBBC Radio 4's satirical sketch showWeek Endingand the stage/TV showThe Sitcom Trials. He appeared as an interviewee inAfter the Chalk Dust Settled, a documentary included on the DVD release ofSteven Moffat's sitcomChalk. He was a zombie extra inShaun of the Deadand a congregation member in the movieHitchhiker's Guide to the Galaxy. He wrote and directed a series of radio advertisements for telecommunications companyTalkTalkstarringMark Heap. In 2006, he appeared as a character in the comic bookCSI: Dying in the Guttersas a source of \"inside joke\" humour by featuring him as the victim in a murder mystery set at a comic book convention and using other notable real-world comics creators as suspects in the crime.He also appeared as a character in theJodie Picoultnovel,The Tenth Circleand made a more major appearance in theLeveragenovelThe Con Job. Johnston has two daughters.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Rich_Johnston", "https://en.wikipedia.org/wiki/Rich_Johnston", "https://en.wikipedia.org/wiki/Rich_Johnston", "https://en.wikipedia.org/wiki/Richard_Johnston_(disambiguation)", "https://en.wikipedia.org/wiki/The_Simpsons", "https://en.wikipedia.org/wiki/Homer_the_Smithers", "https://en.wikipedia.org/wiki/New_York_Comic_Con", "https://en.wikipedia.org/wiki/Watchmensch"]},
{"id": "d6689c240a48", "url": "https://en.wikipedia.org/wiki/List_of_animated_short_series", "title": "List of theatrical animated short film series", "headings": ["Contents", "1910s", "1920s", "1930s", "1940s", "1950s", "1960s", "1970s", "1980s", "1990s", "2000s", "2010s", "2020s", "References", "Sources"], "content": " The following is a list of theatrical shortanimated cartoonseries ordered by the decade and year their first episode was released. Most notable animated film series were produced during the silent era and the Hollywood golden era.All series below are from theUnited Statesexcept as noted. A real time interval of movie releases can be wider than it is listed due to incomplete reliable information about a series.", "combined_text": "List of theatrical animated short film series Contents 1910s 1920s 1930s 1940s 1950s 1960s 1970s 1980s 1990s 2000s 2010s 2020s References Sources  The following is a list of theatrical shortanimated cartoonseries ordered by the decade and year their first episode was released. Most notable animated film series were produced during the silent era and the Hollywood golden era.All series below are from theUnited Statesexcept as noted. A real time interval of movie releases can be wider than it is listed due to incomplete reliable information about a series.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/List_of_theatrical_animated_short_film_series", "https://en.wikipedia.org/wiki/List_of_theatrical_animated_short_film_series", "https://en.wikipedia.org/wiki/List_of_theatrical_animated_short_film_series", "https://en.wikipedia.org/wiki/Lists_of_feature_film_series", "https://en.wikipedia.org/wiki/Film_series", "https://en.wikipedia.org/wiki/Lists_of_feature_film_series", "https://en.wikipedia.org/wiki/List_of_short_film_series", "https://en.wikipedia.org/wiki/List_of_feature_film_series_with_more_than_thirty_entries"]},
{"id": "5a125fd9e35d", "url": "https://en.wikipedia.org/wiki/Financial_thriller", "title": "Financial thriller", "headings": ["Contents", "History", "Overview", "List of financial thrillers", "See also", "References"], "content": "Financial thrillersare a subgenre ofthriller fictionin which thefinancial systemandeconomyplay a major role. The novelThe Financier(1912) byTheodore Dreiserdisplays elements of a financial thriller and is an early example of the genre.Paul Erdmanhelped popularize the modern financial thriller, withThe Billion Dollar Sure Thing(1973). The former president of a Swiss bank, he penned the novel while in jail awaiting trial on fraud charges related to speculating in the cocoa market. In many cases the protagonist of a financial thriller is a financial professional such asChristian Slater’s character in the 2005 filmThe Deal, or John Kent in Martin Bodenham's2011 novel,The Geneva Connection. Often, the plot centers on a financial crime. It may be a crime that merely enriches a small number of individuals as withThe MillionairesbyBrad Meltzer, or one that threatens the entire financial system, as inTom Clancy’sDebt of Honor(1994). In \"Flash Crash,\" by Denison Hatch the financial crime involves an algorithmic programmer (\"quant\") who is blackmailed into writing a program that will crash the international gold markets. Financial thrillers are often used asmorality playsto illustrate the evils of greed, as inBlack Money(1995), byMichael M. Thomas. During the2008 financial crisis, some financial thrillers took on educational roles. The 2011 HBO TV-movieToo Big to Failis, in the words of Jesse Eisinger, \"extraordinarily revealing about the financial crisis\"but not always in a helpful way.For example, Eisinger says, \"The government gave the banks money but didn't get voting rights and didn't prevent the banks from using the money to pay dividends or bonuses. They wrote what was essentially a blank check...It's left to the hapless PR woman...to wonder why, if the government is saving these institutions, it couldn't impose any limits on how the money be used.\"  Another film in this genre isJ. C. Chandor'sAcademy Award-nominatedMargin Call, also from 2011. In the 2010s,The Big Shortwas adapted from anon-fiction bookinto a movie, and it is also a prominent financial thriller.", "combined_text": "Financial thriller Contents History Overview List of financial thrillers See also References Financial thrillersare a subgenre ofthriller fictionin which thefinancial systemandeconomyplay a major role. The novelThe Financier(1912) byTheodore Dreiserdisplays elements of a financial thriller and is an early example of the genre.Paul Erdmanhelped popularize the modern financial thriller, withThe Billion Dollar Sure Thing(1973). The former president of a Swiss bank, he penned the novel while in jail awaiting trial on fraud charges related to speculating in the cocoa market. In many cases the protagonist of a financial thriller is a financial professional such asChristian Slater’s character in the 2005 filmThe Deal, or John Kent in Martin Bodenham's2011 novel,The Geneva Connection. Often, the plot centers on a financial crime. It may be a crime that merely enriches a small number of individuals as withThe MillionairesbyBrad Meltzer, or one that threatens the entire financial system, as inTom Clancy’sDebt of Honor(1994). In \"Flash Crash,\" by Denison Hatch the financial crime involves an algorithmic programmer (\"quant\") who is blackmailed into writing a program that will crash the international gold markets. Financial thrillers are often used asmorality playsto illustrate the evils of greed, as inBlack Money(1995), byMichael M. Thomas. During the2008 financial crisis, some financial thrillers took on educational roles. The 2011 HBO TV-movieToo Big to Failis, in the words of Jesse Eisinger, \"extraordinarily revealing about the financial crisis\"but not always in a helpful way.For example, Eisinger says, \"The government gave the banks money but didn't get voting rights and didn't prevent the banks from using the money to pay dividends or bonuses. They wrote what was essentially a blank check...It's left to the hapless PR woman...to wonder why, if the government is saving these institutions, it couldn't impose any limits on how the money be used.\"  Another film in this genre isJ. C. Chandor'sAcademy Award-nominatedMargin Call, also from 2011. In the 2010s,The Big Shortwas adapted from anon-fiction bookinto a movie, and it is also a prominent financial thriller.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Financial_thriller", "https://en.wikipedia.org/wiki/Financial_thriller", "https://en.wikipedia.org/wiki/Financial_thriller", "https://en.wikipedia.org/wiki/Thriller_(genre)", "https://en.wikipedia.org/wiki/Financial_system", "https://en.wikipedia.org/wiki/Economy", "https://en.wikipedia.org/wiki/The_Financier", "https://en.wikipedia.org/wiki/Theodore_Dreiser"]},
{"id": "acaa74f57c5e", "url": "https://en.wikipedia.org/wiki/Herbert_Marcuse", "title": "Herbert Marcuse", "headings": ["Contents", "Biography", "Early years", "Institute for Social Research", "Emigration to the United States", "World War II", "Post-war career", "Marriages", "Children", "Death", "Philosophy and views", "Marcuse's early Heideggerian Marxism", "Marcuse and capitalism", "The New Left and radical politics", "Marcuse and feminism", "Criticism", "Legacy", "Bibliography", "See also", "References", "Further reading", "Herbert Marcuse", "Criticism and analysis", "General", "External links"], "content": "Herbert Marcuse(/mɑːrˈkuːzə/mar-KOO-zə;German:[maʁˈkuːzə]; July 19, 1898 – July 29, 1979) was a German–Americanphilosopher,social critic, andpolitical theorist, associated with theFrankfurt Schoolofcritical theory. Born inBerlin, Marcuse studied at Berlin'sFriedrich Wilhelm University of Berlinand then at theUniversity of Freiburg, where he received hisPhD.He was a prominent figure in the Frankfurt-basedInstitute for Social Research, which later became known as the Frankfurt School. In his written works, he criticizedcapitalism, modern technology,Soviet Communism, andpopular culture, arguing that they represent new forms ofsocial control. Between 1943 and 1950, Marcuse worked inU.S. governmentservice for theOffice of Strategic Services(predecessor of theCentral Intelligence Agency) where he criticized theideology of the Communist Party of the Soviet Unionin the bookSoviet Marxism: A Critical Analysis(1958). In the 1960s and the 1970s, he became known as the pre-eminent theorist of theNew Leftand the student movements ofWest Germany,France, and theUnited States; some consider him \"the Father of the New Left\". His best-known works areEros and Civilization(1955) andOne-Dimensional Man(1964). HisMarxistscholarship inspired many radical intellectuals and political activists in the 1960s and 1970s, both in the United States and internationally. Herbert Marcuse was born July 19, 1898, inBerlin, to Carl Marcuse and Gertrud Kreslawsky. Marcuse's family was a German upper-middle-classJewishfamily that was well integrated into German society.Marcuse moved from Berlin to the suburb ofCharlottenburg, the center of West Berlin. Marcuse's formal education began at Mommsen Gymnasium and continued at the Kaiserin-Augusta Gymnasium in Charlottenburg from 1911 to 1916.In 1916, he was drafted into theGerman Army, but only worked in horse stables in Berlin duringWorld War I. He spent his entire military service in Germany. While in Berlin, he managed to secure permission to attend lectures at the university of Berlin while still on active duty.He then became a member of aSoldiers' Councilthat participated in the abortivesocialistSpartacist uprising. In 1919, he attended theFriedrich Wilhelm University of Berlin, taking classes for four semesters. In 1920, he transferred to theUniversity of Freiburgto concentrate on German literature, philosophy, politics, and economics.He completed his Ph.D. thesis at the University of Freiburg in 1922 on the GermanKünstlerroman, after which he moved back to Berlin, where he worked in publishing. Two years later, he married Sophie Wertheim, a mathematician. He returned to Freiburg in 1928 to write ahabilitationunderMartin Heidegger,which was published in 1932 asHegel's Ontology and the Theory of Historicity(Hegels Ontologie und die Theorie der Geschichtlichkeit). This study was written in the context of the Hegel Renaissance that was taking place in Europe with an emphasis onGeorg Wilhelm Friedrich Hegel's ontology of life and history, idealist theory of spirit and dialectic. In 1932, Marcuse stopped working with Heidegger, who joined theNazi Partyin 1933. Marcuse understood that he would not qualify as a professor under theNazi regime.Marcuse was then hired to work for theUniversity of Frankfurt Institute for Social Research. The Institute deposited their endowment in Holland in anticipation of the Nazi takeover, so Marcuse never actually worked in the school there.Instead, he began his work with the Institute inGeneva, where a branch office was formed, after leaving Nazi Germany in May 1933.While a member of the Frankfurt School, Marcuse developed a model forcritical social theory, created a theory of the new stage of state and monopoly capitalism, described the relationships between philosophy, social theory, and cultural criticism, and provided an analysis and critique of German \"National Socialism\". Marcuse worked closely with critical theorists while at the Institute. Marcuse emigrated to the United States in June 1934. He served at the Institute'sColumbia Universitybranch from 1934 through 1942. He traveled toWashington, D.C., in 1942, to work for the Office of War Information, and afterward the Office of Strategic Services. Marcuse went on to teach atBrandeis Universityand theUniversity of California, San Diego, later in his career.In 1940, he became a US citizen and resided in the country until his death in 1979.Although he never returned to Germany to live, he remained one of the major theorists associated with the Frankfurt School, along withMax HorkheimerandTheodor W. Adorno(among others). In 1940, Marcuse publishedReason and Revolution, a dialectical work studyingG. W. F. HegelandKarl Marx. During World War II, Marcuse first worked for the USOffice of War Information(OWI) on anti-Nazi propaganda projects. In 1943, he transferred to theResearch and Analysis Branchof theOffice of Strategic Services(OSS), the precursor to theCentral Intelligence Agency. Directed by theHarvardhistorianWilliam L. Langer, the Research and Analysis (R&A) Branch was the largest American research institution in the first half of the twentieth century. At its zenith between 1943 and 1945, it employed over twelve hundred, four hundred of whom were stationed abroad. In many respects, it was the site where post-World War II American social science was born, with protégés of some of the most esteemed American university professors, as well as numerous European intellectual émigrés, in its ranks. In March 1943, Marcuse joined fellow Frankfurt School scholarFranz Neumannin R&A's Central European Section as senior analyst; there he rapidly established himself as \"the leading analyst on Germany\". After the dissolution of the OSS in 1945, Marcuse was employed by theUS Department of Stateas head of the Central European section, becoming an intelligence analyst of Nazism. A compilation of Marcuse's reports was published inSecret Reports on Nazi Germany: The Frankfurt School Contribution to the War Effort(2013). He retired after the death of his first wife in 1951. Marcuse began his teaching career as a political theorist atColumbia University, then continued atHarvard Universityin 1952. Marcuse worked atBrandeis Universityfrom 1954 to 1965, then at theUniversity of California, San Diegofrom 1965 to 1970.It was during his time at Brandeis that he wrote his most famous work,One-Dimensional Man(1964). Marcuse was a friend and collaborator of thepolitical sociologistBarrington Moore Jr.and of the political philosopherRobert Paul Wolff, and also a friend of the Columbia University sociology professorC. Wright Mills, one of the founders of theNew Leftmovement. In his \"Introduction\" toOne-Dimensional Man, Marcuse wrote: \"I should like to emphasize the vital importance of the work of C. Wright Mills.\" In the post-war period, Marcuse rejected the theory ofclass struggleand the Marxist concern with labor, instead claiming, according toLeszek Kołakowski, that since \"all questions of material existence have been solved, moral commands and prohibitions are no longer relevant.\" He regarded the realization of man's erotic nature as the true liberation of humanity, which inspired the utopias ofJerry Rubinand others. Marcuse's critiques ofcapitalistsociety (especially his 1955 synthesis of Marx andSigmund Freud,Eros and Civilization, and his 1964 bookOne-Dimensional Man) resonated with the concerns of the student movement in the 1960s because of his willingness to speak at student protests and his essay \"Repressive Tolerance\" (1965).He had been given the title \"Philosopher of the New Left\" for his rejection of the traditions of Western civilization. The New Left provided an attractive alternative to American society and Marcuse was able to appeal to many young individuals through his teachings of utopianism. His ideas critiqued contemporary liberalism and its conservative vestiges of nineteenth-century liberalism.Marcuse then soon became known in the media as \"Father of the New Left.\"Contending that the students of the '60s were not waiting for the publication of his work to act,Marcuse brushed the media's branding of him as \"Father of the New Left\" aside lightly,saying: \"It would have been better to call me not the father, but the grandfather, of the New Left.\"His work strongly influenced intellectual discourse onpopular cultureand scholarlypopular culture studies. In particular, he influenced youth because he \"spoke their language.\"He understood the importance of rock and roll,for example, as a symbol for New Left activism. He had many speaking engagements in the US andWestern Blocin the late 1960s and 1970s. He became a close friend and inspirer of the French philosopherAndré Gorz. Marcuse defended the arrestedEast GermandissidentRudolf Bahro(author ofDie Alternative: Zur Kritik des real existierenden Sozialismus[trans.,The Alternative in Eastern Europe]), discussing in a 1979 essay Bahro's theories of \"change from within.\" Marcuse married three times. His first wife wasmathematicianSophie Wertheim (1901–1951), whom he married in 1924 and had his first son Peter with in 1928. Before emigrating to New York in 1934, they resided in Freiburg, Berlin, Geneva, and Paris. They lived in Los Angeles/Santa Monica and Washington, D.C., in the 1930s and 1940s. In 1951, Sophie Wertheim died due to cancer.Marcuse later married Inge Neumann (1914–1973), the widow of his close friendFranz Neumann(1900–1954). After his second wife Inge died in 1973, Marcuse married Erica Sherover (1938–1988), a former graduate student at the University of California, in 1976. In his first marriage with Sophie Wertheim, they had one son, Peter Marcuse, born in 1928.Peter Marcusewas a professor emeritus ofurban planningatColumbia Universityin New York. Although Marcuse did not have any children with Inge Neumann Marcuse, he helped raise her two sons, Thomas Neumann andMichael Neumann.Thomas (now Osha) is a Berkeley-based writer, activist, lawyer, and muralist. Michael works as a philosophy professor atTrent Universityin Peterborough, Ontario, Canada. Marcuse's granddaughter was the novelistIrene Marcuseand his grandson,Harold Marcuse, is a professor of history at theUniversity of California, Santa Barbara. On July 29, 1979, ten days after his eighty-first birthday, Marcuse died after suffering astrokeduring his trip to Germany. He had just finished speaking at the FrankfurtRömerberggespräche, and was on his way to theMax Planck Institute for the Study of the Scientific-Technical Worldin Starnberg (where he had delivered lectures and participated in discussions from 1974 to 1979) at the invitation of second-generation Frankfurt School theoristJürgen Habermas. In 2003, after Marcuse's ashes were rediscovered in the United States, they were buried in theDorotheenstädtischer cemeteryin Berlin. Marcuse's concept ofrepressive desublimation, which has become well-known, refers to his argument that postwar mass culture, with its profusion of sexual provocations, serves to reinforce political repression. If people are preoccupied with inauthentic sexual stimulation, their political energy will be \"desublimated\"; instead of acting constructively to change the world, they remain repressed and uncritical. Marcuse advanced the prewar thinking of critical theory toward a critical account of the \"one-dimensional\" nature of bourgeois life in Europe and America. His thinking has been seen as an advance of the concerns of earlier liberal critics such asDavid Riesman. Two aspects of Marcuse's work are of particular importance. First, his use of language more familiar from the critique of Soviet or Nazi regimes to characterize developments in the advanced industrial world. Second, his grounding of critical theory in a particular use of psychoanalytic thought. During his years in Freiburg, Marcuse wrote a series of essays that explored the possibility of synthesizing Marxism and Heidegger'sfundamental ontology, as begun in the latter's workBeing and Time(1927). This early interest in Heidegger followed Marcuse's demand for \"concrete philosophy,\" which, he declared in 1928, \"concerns itself with the truth of contemporaneous human existence.\"These words were directed against theneo-Kantianismof the mainstream, and against both the revisionist and orthodox Marxist alternatives, in which the subjectivity of the individual played little role.Though Marcuse quickly distanced himself from Heidegger following Heidegger's endorsement of Nazism, thinkers such asJürgen Habermashave suggested that an understanding of Marcuse's later thinking demands an appreciation of his early Heideggerian influence. Marcuse's analysis of capitalism derives partially from one of Karl Marx's main concepts: Objectification,which under capitalism becomesAlienation. Marx believed that capitalism was exploiting humans; that by producing objects of a certain character, laborers became alienated, and this ultimately dehumanized them into functional objects themselves. Marcuse took this belief and expanded it. He argued that capitalism and industrialization pushed laborers so hard that they began to see themselves as extensions of the objects they were producing. At the beginning ofOne-Dimensional ManMarcuse writes, \"The people recognize themselves in their commodities; they find their soul in their automobile, hi-fi set, split-level home, kitchen equipment,\"meaning that under capitalism (in consumer society), humans become extensions of the commodities that they buy, thus making commodities extensions of people's minds and bodies. Affluent mass technological societies, he argues, are controlled and manipulated. In societies based upon mass production and mass distribution, the individual worker has become merely a consumer of its commodities and entire commodified way of life. Modern capitalism has created false needs and false consciousness geared to the consumption ofcommodities: it locks one-dimensional man into the one-dimensional society which produced the need for people to recognize themselves in their commodities. The very mechanism that ties the individual to his society has changed, and social control is anchored in the new needs that it has produced. Most important of all, the pressure of consumerism has led to the total integration of the working class into thecapitalistsystem. Its political parties and trade unions have become thoroughly bureaucratized and the power ofnegative thinkingor critical reflection has rapidly declined.The working class is no longer a potentially subversive force capable of bringing about revolutionary change. Marcuse evolved a theory over the years that stated modern technology is repressive naturally. He believed that in both capitalist and communist societies, workers did not question the manner in which they lived due to the mechanism of repression of technological advances. The use of technology allowed people to not be aware of what is occurring around them such as the fact that they might soon be out of their jobs because these technologies are carrying out their same jobs quicker and cheaper. He claimed the modern-day workers were not as rebellious as before during the Karl Marx era (19th century). They just freely conformed to the system they were under for the sake of satisfying their needs and survival. Since they had conformed, the people's revolution that Marcuse felt was necessary never happened. As a result, rather than looking to the workers as the revolutionary vanguard, Marcuse put his faith in an alliance between radical intellectuals and those groups not yet integrated into one-dimensional society: the socially marginalized, the substratum of the outcasts and outsiders, the exploited and persecuted of other ethnicities and other colors, the unemployed and the unemployable. These were the people whose standards of living demanded the ending of intolerable conditions and institutions and whose resistance to one-dimensional society would not be diverted by the system. Their opposition was revolutionary even if their consciousness was not. Many radical scholars and activists were influenced by Marcuse, such asNorman O. Brown,Angela Davis,Charles J. Moore,Abbie Hoffman,Rudi Dutschke, andRobert M. Young(see the List of Scholars and Activists link below). Among those who critiqued him from the left wereMarxist-humanistRaya Dunayevskaya, fellow German emigrePaul Mattick, both of whom subjectedOne-Dimensional Manto a Marxist critique, andNoam Chomsky, who knew and liked Marcuse \"but thought very little of his work.\"Marcuse's 1965 essay \"Repressive Tolerance\", in which he claimed capitalistdemocraciescan havetotalitarianaspects, has been criticized by conservatives.Marcuse argues that genuine tolerance does not permit support for \"repression\", since doing so ensures that marginalized voices will remain unheard. He characterizes tolerance of repressive speech as \"inauthentic\". Instead, he advocates a form of tolerance that is intolerant of repressive (namely right-wing) political movements: Liberating tolerance, then, would mean intolerance against movements from the Right and toleration of movements from the Left.\nSurely, no government can be expected to foster its own subversion, but in a democracy such a right is vested in the people (i.e. in the majority of the people). This means that the ways should not be blocked on which a subversive majority could develop, and if they are blocked by organized repression and indoctrination, their reopening may require apparently undemocratic means. They would include the withdrawal of toleration of speech and assembly from groups and movements that promote aggressive policies, armament, chauvinism, discrimination on the grounds of race and religion, or that oppose the extension of public services, social security, medical care, etc. Marcuse later expressed his radical ideas through three pieces of writing. He wroteAn Essay on Liberationin 1969, in which he celebrated liberation movements such as those inVietnam, which inspired many radicals. In 1972 he wroteCounterrevolution and Revolt, which argues that the hopes of the 1960s were facing a counterrevolution from the right. After Brandeis denied the renewal of his teaching contract in 1965, Marcuse taught at theUniversity of California, San Diego. In 1968, California GovernorRonald Reaganand other conservatives objected to his reappointment,but the university decided to let his contract run until 1970. He devoted the rest of his life to teaching, writing and giving lectures around the world. His efforts brought him attention from the media, which claimed that he openly advocated violence, although he often clarified that only \"violence of defense\" could be appropriate, not \"violence of aggression\". He continued to promote Marxian theory, with some of his students helping to spread his ideas. He published his final workThe Aesthetic Dimensionin 1977 on the role of art in the process of what he termed \"emancipation\" from bourgeois society. Marcuse felt that societal reform may be found among the outcast of society, thus he supported movements such as the Feminist movement. Marcuse was particularly concerned with Feminism near the end of his life, for reasons he explained in a public lectureMarxism and Feminismin 1974,mentioning this in a Stanford lecture, \"I believe the Women's Liberation Movement is perhaps the most important and potentially the most radical political movement that we have – even if the consciousness of this fact has not yet penetrated the Movement as a whole\".Many themes and ambitions from Marcuse's work found embodiment insocialist feminism, especially ideas developed inEros and Civilization.It involved changes not only in the structural power relations of society, but in the instinctual drives of individual human beings. Although he regarded women's participation in the labor force as positive, and a necessary condition for women's liberation, Marcuse did not consider it sufficient for true freedom. He hoped for a shift in moral values away from aggressive and masculine qualities towards feminine ones. Jessica BenjaminandNancy Chodorowbelieved that Marcuse's reliance on Freud'sdrive theoryas the source of the desire for societal change is inadequate for both philosophers since he fails to account for the individual's intersubjective growth. Leszek Kołakowskidescribed Marcuse's views as essentially anti-Marxist, in that they ignored Marx's critique of Hegel and discarded the historical theory ofclass struggleentirely in favor of an inverted Freudian reading of human history where all social rules could and should be discarded to create a \"New World of Happiness.\" Kołakowski concluded that Marcuse's ideal society \"is to be ruled despotically by an enlightened group [who] have realized in themselves the unity ofLogosand Eros, and thrown off the vexatious authority of logic, mathematics, and the empirical sciences.\" The philosopherAlasdair MacIntyreasserted that Marcuse falsely assumed consumers were completely passive, uncritically responding to corporate advertising.MacIntyre frankly opposed Marcuse. \"It will be my crucial contention in this book,\" MacIntyre stated, \"that almost all of Marcuse's key positions are false.For example, Marcuse was not an orthodox Marxist.Like many of the Frankfurt School, Marcuse wrote of \"critical theory\" not of \"Marxism\" and MacIntyre notes a similarity in this to theRight Hegelians, whom Marx attacked.Hence, MacIntyre proposed that Marcuse be regarded as \"a pre-Marxist thinker\".According to MacIntyre, Marcuse's assumptions about advancedindustrial societywere wrong in whole and in part.\"Marcuse,\" concluded MacIntyre, \"invokes the great names of freedom and reason while betraying their substance at every important point.\" Herbert Marcuse appealed to students of the New Left through his emphasis on the power of critical thought and his vision of total human emancipation and a non-repressive civilization. He supported students he felt were subject to the pressures of a commodifying system, and has been regarded as an inspirational intellectual leader.He is also considered among the most influential of the Frankfurt School critical theorists on American culture, due to his studies on student and counter-cultural movements on the 1960s.The legacy of the 1960s, of which Marcuse was a vital part, lives on, and thegreat refusalis still practiced by oppositional groups and individuals. Eros and Civilizationis one of Marcuse's most notable works, and his insensitivity to human relatedness portrayed in this project is considered the key failure of this work. His insights of psychoanalytic object relations theory in this project have not been wedded or reinterpreted, without abandoning its core principles. Marcuse's thought remains influential in the 21st century. In the introduction to an issue of the journalNew Political Sciencededicated to Marcuse, Robert Kirsch and Sarah Surak described his influence as \"alive and well, vibrant across multiple fields of inquiry across many areas of social relations\".Marcuse's concept of repressive tolerance attracted renewed attention following the9/11 attacks.Repressive tolerance is also relevant to 21st-century campus protests and theBlack Lives Mattermovement. Marcuse is not widely remembered outside of contexts where critical theory is taught or referenced.This theory, rooted in Marxist philosophy, remains as one of the main components of Marcuse's influence. Books Essays", "combined_text": "Herbert Marcuse Contents Biography Early years Institute for Social Research Emigration to the United States World War II Post-war career Marriages Children Death Philosophy and views Marcuse's early Heideggerian Marxism Marcuse and capitalism The New Left and radical politics Marcuse and feminism Criticism Legacy Bibliography See also References Further reading Herbert Marcuse Criticism and analysis General External links Herbert Marcuse(/mɑːrˈkuːzə/mar-KOO-zə;German:[maʁˈkuːzə]; July 19, 1898 – July 29, 1979) was a German–Americanphilosopher,social critic, andpolitical theorist, associated with theFrankfurt Schoolofcritical theory. Born inBerlin, Marcuse studied at Berlin'sFriedrich Wilhelm University of Berlinand then at theUniversity of Freiburg, where he received hisPhD.He was a prominent figure in the Frankfurt-basedInstitute for Social Research, which later became known as the Frankfurt School. In his written works, he criticizedcapitalism, modern technology,Soviet Communism, andpopular culture, arguing that they represent new forms ofsocial control. Between 1943 and 1950, Marcuse worked inU.S. governmentservice for theOffice of Strategic Services(predecessor of theCentral Intelligence Agency) where he criticized theideology of the Communist Party of the Soviet Unionin the bookSoviet Marxism: A Critical Analysis(1958). In the 1960s and the 1970s, he became known as the pre-eminent theorist of theNew Leftand the student movements ofWest Germany,France, and theUnited States; some consider him \"the Father of the New Left\". His best-known works areEros and Civilization(1955) andOne-Dimensional Man(1964). HisMarxistscholarship inspired many radical intellectuals and political activists in the 1960s and 1970s, both in the United States and internationally. Herbert Marcuse was born July 19, 1898, inBerlin, to Carl Marcuse and Gertrud Kreslawsky. Marcuse's family was a German upper-middle-classJewishfamily that was well integrated into German society.Marcuse moved from Berlin to the suburb ofCharlottenburg, the center of West Berlin. Marcuse's formal education began at Mommsen Gymnasium and continued at the Kaiserin-Augusta Gymnasium in Charlottenburg from 1911 to 1916.In 1916, he was drafted into theGerman Army, but only worked in horse stables in Berlin duringWorld War I. He spent his entire military service in Germany. While in Berlin, he managed to secure permission to attend lectures at the university of Berlin while still on active duty.He then became a member of aSoldiers' Councilthat participated in the abortivesocialistSpartacist uprising. In 1919, he attended theFriedrich Wilhelm University of Berlin, taking classes for four semesters. In 1920, he transferred to theUniversity of Freiburgto concentrate on German literature, philosophy, politics, and economics.He completed his Ph.D. thesis at the University of Freiburg in 1922 on the GermanKünstlerroman, after which he moved back to Berlin, where he worked in publishing. Two years later, he married Sophie Wertheim, a mathematician. He returned to Freiburg in 1928 to write ahabilitationunderMartin Heidegger,which was published in 1932 asHegel's Ontology and the Theory of Historicity(Hegels Ontologie und die Theorie der Geschichtlichkeit). This study was written in the context of the Hegel Renaissance that was taking place in Europe with an emphasis onGeorg Wilhelm Friedrich Hegel's ontology of life and history, idealist theory of spirit and dialectic. In 1932, Marcuse stopped working with Heidegger, who joined theNazi Partyin 1933. Marcuse understood that he would not qualify as a professor under theNazi regime.Marcuse was then hired to work for theUniversity of Frankfurt Institute for Social Research. The Institute deposited their endowment in Holland in anticipation of the Nazi takeover, so Marcuse never actually worked in the school there.Instead, he began his work with the Institute inGeneva, where a branch office was formed, after leaving Nazi Germany in May 1933.While a member of the Frankfurt School, Marcuse developed a model forcritical social theory, created a theory of the new stage of state and monopoly capitalism, described the relationships between philosophy, social theory, and cultural criticism, and provided an analysis and critique of German \"National Socialism\". Marcuse worked closely with critical theorists while at the Institute. Marcuse emigrated to the United States in June 1934. He served at the Institute'sColumbia Universitybranch from 1934 through 1942. He traveled toWashington, D.C., in 1942, to work for the Office of War Information, and afterward the Office of Strategic Services. Marcuse went on to teach atBrandeis Universityand theUniversity of California, San Diego, later in his career.In 1940, he became a US citizen and resided in the country until his death in 1979.Although he never returned to Germany to live, he remained one of the major theorists associated with the Frankfurt School, along withMax HorkheimerandTheodor W. Adorno(among others). In 1940, Marcuse publishedReason and Revolution, a dialectical work studyingG. W. F. HegelandKarl Marx. During World War II, Marcuse first worked for the USOffice of War Information(OWI) on anti-Nazi propaganda projects. In 1943, he transferred to theResearch and Analysis Branchof theOffice of Strategic Services(OSS), the precursor to theCentral Intelligence Agency. Directed by theHarvardhistorianWilliam L. Langer, the Research and Analysis (R&A) Branch was the largest American research institution in the first half of the twentieth century. At its zenith between 1943 and 1945, it employed over twelve hundred, four hundred of whom were stationed abroad. In many respects, it was the site where post-World War II American social science was born, with protégés of some of the most esteemed American university professors, as well as numerous European intellectual émigrés, in its ranks. In March 1943, Marcuse joined fellow Frankfurt School scholarFranz Neumannin R&A's Central European Section as senior analyst; there he rapidly established himself as \"the leading analyst on Germany\". After the dissolution of the OSS in 1945, Marcuse was employed by theUS Department of Stateas head of the Central European section, becoming an intelligence analyst of Nazism. A compilation of Marcuse's reports was published inSecret Reports on Nazi Germany: The Frankfurt School Contribution to the War Effort(2013). He retired after the death of his first wife in 1951. Marcuse began his teaching career as a political theorist atColumbia University, then continued atHarvard Universityin 1952. Marcuse worked atBrandeis Universityfrom 1954 to 1965, then at theUniversity of California, San Diegofrom 1965 to 1970.It was during his time at Brandeis that he wrote his most famous work,One-Dimensional Man(1964). Marcuse was a friend and collaborator of thepolitical sociologistBarrington Moore Jr.and of the political philosopherRobert Paul Wolff, and also a friend of the Columbia University sociology professorC. Wright Mills, one of the founders of theNew Leftmovement. In his \"Introduction\" toOne-Dimensional Man, Marcuse wrote: \"I should like to emphasize the vital importance of the work of C. Wright Mills.\" In the post-war period, Marcuse rejected the theory ofclass struggleand the Marxist concern with labor, instead claiming, according toLeszek Kołakowski, that since \"all questions of material existence have been solved, moral commands and prohibitions are no longer relevant.\" He regarded the realization of man's erotic nature as the true liberation of humanity, which inspired the utopias ofJerry Rubinand others. Marcuse's critiques ofcapitalistsociety (especially his 1955 synthesis of Marx andSigmund Freud,Eros and Civilization, and his 1964 bookOne-Dimensional Man) resonated with the concerns of the student movement in the 1960s because of his willingness to speak at student protests and his essay \"Repressive Tolerance\" (1965).He had been given the title \"Philosopher of the New Left\" for his rejection of the traditions of Western civilization. The New Left provided an attractive alternative to American society and Marcuse was able to appeal to many young individuals through his teachings of utopianism. His ideas critiqued contemporary liberalism and its conservative vestiges of nineteenth-century liberalism.Marcuse then soon became known in the media as \"Father of the New Left.\"Contending that the students of the '60s were not waiting for the publication of his work to act,Marcuse brushed the media's branding of him as \"Father of the New Left\" aside lightly,saying: \"It would have been better to call me not the father, but the grandfather, of the New Left.\"His work strongly influenced intellectual discourse onpopular cultureand scholarlypopular culture studies. In particular, he influenced youth because he \"spoke their language.\"He understood the importance of rock and roll,for example, as a symbol for New Left activism. He had many speaking engagements in the US andWestern Blocin the late 1960s and 1970s. He became a close friend and inspirer of the French philosopherAndré Gorz. Marcuse defended the arrestedEast GermandissidentRudolf Bahro(author ofDie Alternative: Zur Kritik des real existierenden Sozialismus[trans.,The Alternative in Eastern Europe]), discussing in a 1979 essay Bahro's theories of \"change from within.\" Marcuse married three times. His first wife wasmathematicianSophie Wertheim (1901–1951), whom he married in 1924 and had his first son Peter with in 1928. Before emigrating to New York in 1934, they resided in Freiburg, Berlin, Geneva, and Paris. They lived in Los Angeles/Santa Monica and Washington, D.C., in the 1930s and 1940s. In 1951, Sophie Wertheim died due to cancer.Marcuse later married Inge Neumann (1914–1973), the widow of his close friendFranz Neumann(1900–1954). After his second wife Inge died in 1973, Marcuse married Erica Sherover (1938–1988), a former graduate student at the University of California, in 1976. In his first marriage with Sophie Wertheim, they had one son, Peter Marcuse, born in 1928.Peter Marcusewas a professor emeritus ofurban planningatColumbia Universityin New York. Although Marcuse did not have any children with Inge Neumann Marcuse, he helped raise her two sons, Thomas Neumann andMichael Neumann.Thomas (now Osha) is a Berkeley-based writer, activist, lawyer, and muralist. Michael works as a philosophy professor atTrent Universityin Peterborough, Ontario, Canada. Marcuse's granddaughter was the novelistIrene Marcuseand his grandson,Harold Marcuse, is a professor of history at theUniversity of California, Santa Barbara. On July 29, 1979, ten days after his eighty-first birthday, Marcuse died after suffering astrokeduring his trip to Germany. He had just finished speaking at the FrankfurtRömerberggespräche, and was on his way to theMax Planck Institute for the Study of the Scientific-Technical Worldin Starnberg (where he had delivered lectures and participated in discussions from 1974 to 1979) at the invitation of second-generation Frankfurt School theoristJürgen Habermas. In 2003, after Marcuse's ashes were rediscovered in the United States, they were buried in theDorotheenstädtischer cemeteryin Berlin. Marcuse's concept ofrepressive desublimation, which has become well-known, refers to his argument that postwar mass culture, with its profusion of sexual provocations, serves to reinforce political repression. If people are preoccupied with inauthentic sexual stimulation, their political energy will be \"desublimated\"; instead of acting constructively to change the world, they remain repressed and uncritical. Marcuse advanced the prewar thinking of critical theory toward a critical account of the \"one-dimensional\" nature of bourgeois life in Europe and America. His thinking has been seen as an advance of the concerns of earlier liberal critics such asDavid Riesman. Two aspects of Marcuse's work are of particular importance. First, his use of language more familiar from the critique of Soviet or Nazi regimes to characterize developments in the advanced industrial world. Second, his grounding of critical theory in a particular use of psychoanalytic thought. During his years in Freiburg, Marcuse wrote a series of essays that explored the possibility of synthesizing Marxism and Heidegger'sfundamental ontology, as begun in the latter's workBeing and Time(1927). This early interest in Heidegger followed Marcuse's demand for \"concrete philosophy,\" which, he declared in 1928, \"concerns itself with the truth of contemporaneous human existence.\"These words were directed against theneo-Kantianismof the mainstream, and against both the revisionist and orthodox Marxist alternatives, in which the subjectivity of the individual played little role.Though Marcuse quickly distanced himself from Heidegger following Heidegger's endorsement of Nazism, thinkers such asJürgen Habermashave suggested that an understanding of Marcuse's later thinking demands an appreciation of his early Heideggerian influence. Marcuse's analysis of capitalism derives partially from one of Karl Marx's main concepts: Objectification,which under capitalism becomesAlienation. Marx believed that capitalism was exploiting humans; that by producing objects of a certain character, laborers became alienated, and this ultimately dehumanized them into functional objects themselves. Marcuse took this belief and expanded it. He argued that capitalism and industrialization pushed laborers so hard that they began to see themselves as extensions of the objects they were producing. At the beginning ofOne-Dimensional ManMarcuse writes, \"The people recognize themselves in their commodities; they find their soul in their automobile, hi-fi set, split-level home, kitchen equipment,\"meaning that under capitalism (in consumer society), humans become extensions of the commodities that they buy, thus making commodities extensions of people's minds and bodies. Affluent mass technological societies, he argues, are controlled and manipulated. In societies based upon mass production and mass distribution, the individual worker has become merely a consumer of its commodities and entire commodified way of life. Modern capitalism has created false needs and false consciousness geared to the consumption ofcommodities: it locks one-dimensional man into the one-dimensional society which produced the need for people to recognize themselves in their commodities. The very mechanism that ties the individual to his society has changed, and social control is anchored in the new needs that it has produced. Most important of all, the pressure of consumerism has led to the total integration of the working class into thecapitalistsystem. Its political parties and trade unions have become thoroughly bureaucratized and the power ofnegative thinkingor critical reflection has rapidly declined.The working class is no longer a potentially subversive force capable of bringing about revolutionary change. Marcuse evolved a theory over the years that stated modern technology is repressive naturally. He believed that in both capitalist and communist societies, workers did not question the manner in which they lived due to the mechanism of repression of technological advances. The use of technology allowed people to not be aware of what is occurring around them such as the fact that they might soon be out of their jobs because these technologies are carrying out their same jobs quicker and cheaper. He claimed the modern-day workers were not as rebellious as before during the Karl Marx era (19th century). They just freely conformed to the system they were under for the sake of satisfying their needs and survival. Since they had conformed, the people's revolution that Marcuse felt was necessary never happened. As a result, rather than looking to the workers as the revolutionary vanguard, Marcuse put his faith in an alliance between radical intellectuals and those groups not yet integrated into one-dimensional society: the socially marginalized, the substratum of the outcasts and outsiders, the exploited and persecuted of other ethnicities and other colors, the unemployed and the unemployable. These were the people whose standards of living demanded the ending of intolerable conditions and institutions and whose resistance to one-dimensional society would not be diverted by the system. Their opposition was revolutionary even if their consciousness was not. Many radical scholars and activists were influenced by Marcuse, such asNorman O. Brown,Angela Davis,Charles J. Moore,Abbie Hoffman,Rudi Dutschke, andRobert M. Young(see the List of Scholars and Activists link below). Among those who critiqued him from the left wereMarxist-humanistRaya Dunayevskaya, fellow German emigrePaul Mattick, both of whom subjectedOne-Dimensional Manto a Marxist critique, andNoam Chomsky, who knew and liked Marcuse \"but thought very little of his work.\"Marcuse's 1965 essay \"Repressive Tolerance\", in which he claimed capitalistdemocraciescan havetotalitarianaspects, has been criticized by conservatives.Marcuse argues that genuine tolerance does not permit support for \"repression\", since doing so ensures that marginalized voices will remain unheard. He characterizes tolerance of repressive speech as \"inauthentic\". Instead, he advocates a form of tolerance that is intolerant of repressive (namely right-wing) political movements: Liberating tolerance, then, would mean intolerance against movements from the Right and toleration of movements from the Left.\nSurely, no government can be expected to foster its own subversion, but in a democracy such a right is vested in the people (i.e. in the majority of the people). This means that the ways should not be blocked on which a subversive majority could develop, and if they are blocked by organized repression and indoctrination, their reopening may require apparently undemocratic means. They would include the withdrawal of toleration of speech and assembly from groups and movements that promote aggressive policies, armament, chauvinism, discrimination on the grounds of race and religion, or that oppose the extension of public services, social security, medical care, etc. Marcuse later expressed his radical ideas through three pieces of writing. He wroteAn Essay on Liberationin 1969, in which he celebrated liberation movements such as those inVietnam, which inspired many radicals. In 1972 he wroteCounterrevolution and Revolt, which argues that the hopes of the 1960s were facing a counterrevolution from the right. After Brandeis denied the renewal of his teaching contract in 1965, Marcuse taught at theUniversity of California, San Diego. In 1968, California GovernorRonald Reaganand other conservatives objected to his reappointment,but the university decided to let his contract run until 1970. He devoted the rest of his life to teaching, writing and giving lectures around the world. His efforts brought him attention from the media, which claimed that he openly advocated violence, although he often clarified that only \"violence of defense\" could be appropriate, not \"violence of aggression\". He continued to promote Marxian theory, with some of his students helping to spread his ideas. He published his final workThe Aesthetic Dimensionin 1977 on the role of art in the process of what he termed \"emancipation\" from bourgeois society. Marcuse felt that societal reform may be found among the outcast of society, thus he supported movements such as the Feminist movement. Marcuse was particularly concerned with Feminism near the end of his life, for reasons he explained in a public lectureMarxism and Feminismin 1974,mentioning this in a Stanford lecture, \"I believe the Women's Liberation Movement is perhaps the most important and potentially the most radical political movement that we have – even if the consciousness of this fact has not yet penetrated the Movement as a whole\".Many themes and ambitions from Marcuse's work found embodiment insocialist feminism, especially ideas developed inEros and Civilization.It involved changes not only in the structural power relations of society, but in the instinctual drives of individual human beings. Although he regarded women's participation in the labor force as positive, and a necessary condition for women's liberation, Marcuse did not consider it sufficient for true freedom. He hoped for a shift in moral values away from aggressive and masculine qualities towards feminine ones. Jessica BenjaminandNancy Chodorowbelieved that Marcuse's reliance on Freud'sdrive theoryas the source of the desire for societal change is inadequate for both philosophers since he fails to account for the individual's intersubjective growth. Leszek Kołakowskidescribed Marcuse's views as essentially anti-Marxist, in that they ignored Marx's critique of Hegel and discarded the historical theory ofclass struggleentirely in favor of an inverted Freudian reading of human history where all social rules could and should be discarded to create a \"New World of Happiness.\" Kołakowski concluded that Marcuse's ideal society \"is to be ruled despotically by an enlightened group [who] have realized in themselves the unity ofLogosand Eros, and thrown off the vexatious authority of logic, mathematics, and the empirical sciences.\" The philosopherAlasdair MacIntyreasserted that Marcuse falsely assumed consumers were completely passive, uncritically responding to corporate advertising.MacIntyre frankly opposed Marcuse. \"It will be my crucial contention in this book,\" MacIntyre stated, \"that almost all of Marcuse's key positions are false.For example, Marcuse was not an orthodox Marxist.Like many of the Frankfurt School, Marcuse wrote of \"critical theory\" not of \"Marxism\" and MacIntyre notes a similarity in this to theRight Hegelians, whom Marx attacked.Hence, MacIntyre proposed that Marcuse be regarded as \"a pre-Marxist thinker\".According to MacIntyre, Marcuse's assumptions about advancedindustrial societywere wrong in whole and in part.\"Marcuse,\" concluded MacIntyre, \"invokes the great names of freedom and reason while betraying their substance at every important point.\" Herbert Marcuse appealed to students of the New Left through his emphasis on the power of critical thought and his vision of total human emancipation and a non-repressive civilization. He supported students he felt were subject to the pressures of a commodifying system, and has been regarded as an inspirational intellectual leader.He is also considered among the most influential of the Frankfurt School critical theorists on American culture, due to his studies on student and counter-cultural movements on the 1960s.The legacy of the 1960s, of which Marcuse was a vital part, lives on, and thegreat refusalis still practiced by oppositional groups and individuals. Eros and Civilizationis one of Marcuse's most notable works, and his insensitivity to human relatedness portrayed in this project is considered the key failure of this work. His insights of psychoanalytic object relations theory in this project have not been wedded or reinterpreted, without abandoning its core principles. Marcuse's thought remains influential in the 21st century. In the introduction to an issue of the journalNew Political Sciencededicated to Marcuse, Robert Kirsch and Sarah Surak described his influence as \"alive and well, vibrant across multiple fields of inquiry across many areas of social relations\".Marcuse's concept of repressive tolerance attracted renewed attention following the9/11 attacks.Repressive tolerance is also relevant to 21st-century campus protests and theBlack Lives Mattermovement. Marcuse is not widely remembered outside of contexts where critical theory is taught or referenced.This theory, rooted in Marxist philosophy, remains as one of the main components of Marcuse's influence. Books Essays", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Herbert_Marcuse", "https://en.wikipedia.org/wiki/Herbert_Marcuse", "https://en.wikipedia.org/wiki/Herbert_Marcuse", "https://en.wikipedia.org/wiki/Marcuse_(disambiguation)", "https://en.wikipedia.org/wiki/Berlin", "https://en.wikipedia.org/wiki/German_Empire", "https://en.wikipedia.org/wiki/Starnberg", "https://en.wikipedia.org/wiki/West_Germany"]},
{"id": "7b1f0d31c059", "url": "https://en.wikipedia.org/wiki/Tor.com", "title": "Reactor(magazine)", "headings": ["Contents", "Reception", "Awards", "References"], "content": " Reactor, formerlyTor.com, is an onlinescience fictionandfantasymagazine published byTor Books, a division ofMacmillan Publishers. The magazine publishes articles, reviews, original short fiction, re-reads and commentary onspeculative fiction. Unlike traditional print magazines such asAsimov'sorAnalog, it releases online fiction that can be read free of charge. Reactorwas founded (asTor.com) in July 2008and renamedReactoron January 23, 2024. Gardner DozoiscalledTor.com\"one of the coolest and most eclectic genre-oriented sites on the Internet\". He felt in 2011 that its short fiction output that year was weaker than usual, but said it was still a fascinating place to visit.In 2014,The Guardian'sDamien Walter remarked on a \"digital renaissance\" in short SF, and cited a new generation ofonline magazines, includingLightspeed,Strange Horizons,Tor.comandEscape Pod, as having transformed the genre. Of these, he describedTor.comas \"the reigning champion of science-fiction magazines\". He noted the broad range of its output, and said that it had published \"many of the most exciting new talents\" such asMaria Dahvana HeadleyandKarin Tidbeck. Tor.comhas won eightLocus Awardsfor Best Magazine (2015, 2017–23), breaking a 40-year-long streak where the category was only won byAsimov'sandF&SF(in addition toLocusitself).For its art direction, Irene Gallo received the 2014World Fantasy Award for Professional Work. There have also been several award-winning collections ofTor.comcontent. Reviews and commentary byJo Waltonwere collected in the booksWhat Makes This Book So GreatandAn Informal History of the Hugos, with the former winning the 2014 Locus Award for Best Non-Fiction, and the latter nominated for the 2019 Hugo and Locus Awards.The fiction anthology,Worlds Seen in Passing: 10 Years of Tor.com Short Fiction, won the 2019World Fantasy Award for Best Anthology.", "combined_text": "Reactor(magazine) Contents Reception Awards References  Reactor, formerlyTor.com, is an onlinescience fictionandfantasymagazine published byTor Books, a division ofMacmillan Publishers. The magazine publishes articles, reviews, original short fiction, re-reads and commentary onspeculative fiction. Unlike traditional print magazines such asAsimov'sorAnalog, it releases online fiction that can be read free of charge. Reactorwas founded (asTor.com) in July 2008and renamedReactoron January 23, 2024. Gardner DozoiscalledTor.com\"one of the coolest and most eclectic genre-oriented sites on the Internet\". He felt in 2011 that its short fiction output that year was weaker than usual, but said it was still a fascinating place to visit.In 2014,The Guardian'sDamien Walter remarked on a \"digital renaissance\" in short SF, and cited a new generation ofonline magazines, includingLightspeed,Strange Horizons,Tor.comandEscape Pod, as having transformed the genre. Of these, he describedTor.comas \"the reigning champion of science-fiction magazines\". He noted the broad range of its output, and said that it had published \"many of the most exciting new talents\" such asMaria Dahvana HeadleyandKarin Tidbeck. Tor.comhas won eightLocus Awardsfor Best Magazine (2015, 2017–23), breaking a 40-year-long streak where the category was only won byAsimov'sandF&SF(in addition toLocusitself).For its art direction, Irene Gallo received the 2014World Fantasy Award for Professional Work. There have also been several award-winning collections ofTor.comcontent. Reviews and commentary byJo Waltonwere collected in the booksWhat Makes This Book So GreatandAn Informal History of the Hugos, with the former winning the 2014 Locus Award for Best Non-Fiction, and the latter nominated for the 2019 Hugo and Locus Awards.The fiction anthology,Worlds Seen in Passing: 10 Years of Tor.com Short Fiction, won the 2019World Fantasy Award for Best Anthology.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Reactor_(magazine)", "https://en.wikipedia.org/wiki/Reactor_(magazine)", "https://en.wikipedia.org/wiki/Reactor_(magazine)", "https://en.wikipedia.org/wiki/Tor_(network)", "https://en.wikipedia.org/wiki/Science_fiction", "https://en.wikipedia.org/wiki/Fantasy", "https://en.wikipedia.org/wiki/Macmillan_Publishers", "https://en.wikipedia.org/wiki/Science_fiction"]},
{"id": "189f46aaebe5", "url": "https://en.wikipedia.org/wiki/Alexander_Payne", "title": "Alexander Payne", "headings": ["Contents", "Early life and education", "Career", "1985–1996: Short films and film debut", "1999–2013: Breakthrough and acclaim", "2017–2022: Career slump", "2023–present: Resurgence", "Unrealized projects", "Style", "Personal life", "Family", "Philanthropy and business ventures", "Statutory rape allegation", "Works", "Short film", "Feature film", "Television", "Bibliography", "Awards and nominations", "See also", "References", "External links"], "content": " Constantine Alexander Payne(born February 10, 1961)is an American filmmaker. He is noted for hissatiricaldepictions of contemporary American society. Payne has receivednumerous accolades, including twoAcademy Awards, aBAFTA Awardand twoGolden Globe Awardsas well as a nomination for aGrammy Award. After directing several short films, Payne made his feature film debut with theblack comedyCitizen Ruth(1996). His career progressed with the political satireElection(1999), for which he received a nomination for theAcademy Award for Best Adapted Screenplay, and the comedy-dramaAbout Schmidt(2002). Payne twice won the Academy Award for Best Adapted Screenplay for co-writing his directorialsSideways(2004) andThe Descendants(2011). He was also nominated for theAcademy Award for Best Directorfor these two films and for the road filmNebraska(2013). He has since directed the comedy-dramasDownsizing(2017), andThe Holdovers(2023). Payne was born inOmaha, Nebraska, to Peggy and George Payne, restaurant owners.He is the youngest of three sonsand grew up in theDundeeneighborhood.He is of Greek ancestry.Payne's paternal grandfather, Nicholas \"Nick\" Payne,anglicizedthe last name from \"Papadopoulos\".His family comes from three areas in Greece: the island ofSyros,Livadia, andAegio.Payne's family was part of the fabricof Omaha, which he refers to as part of his upbringing.His grandfather was a founder of The Virginia Cafe, with Payne's father taking over the restaurant. Payne went there regularly as a child. The restaurant was destroyed in a fire in 1969; theW. Dale Clark Librarywas later built on the site.Payne's paternal grandmother, Clara Payne (née Hoffman), was from a German Nebraska family fromLincoln, Nebraska. In Omaha, Payne attendedBrownell-Talbot School, Dundee Elementary School, and Lewis and Clark Junior High.He graduated fromCreighton Prepfor high school in 1979.At Prep, Payne wrote a humor column for his high school newspaper and was the editor of the high school yearbook.Payne then attendedStanford University, where he majored in Spanish and History.As a part of his Spanish degree, he studied at Spain'sUniversity of Salamanca. He later lived a few months inMedellin, Colombia, where he published an article about social changes between 1900 and 1930.Payne received hisMFAin 1990 from theUCLA Film School. In the 1960s, Payne's father received aSuper 8mmprojector from Kraft Foods as a loyalty reward,and eventually passed it on to his son when Alexander was about 14 years old. A short time after getting hisMFAfromUCLA Film School—and after his successful thesis filmThe Passion of Martinhad attracted industry attention—Payne got a writing/directing deal withUniversal Pictures. The ensuing screenplay, which was turned down, ultimately becameAbout Schmidt.He says that he cleared about $60,000, which was enough to fund his simple lifestyle at the time for about five years.Payne has said he sees his talent as being one of learned economy, referring to the essay written byTennessee WilliamsonThe Catastrophe of Success.During this time Payne worked in various capacities on films and television including directing several films for thePlayboychannel. Payne co-wrote and directed his first full-length film,Citizen Ruth, which was released in 1996. The film is a satirical black comedy revolving around the issue ofabortion rights. The film starsLaura Dernas a dim-witted woman with substance abuse issues who happens to get pregnant. She unexpectedly becomes a pawn of figures from both sides of theabortion debate. The film co-starsKelly Preston,Burt Reynolds, andTippi Hedren. The film premiered at the 1996Sundance Film Festivalwhere it received favorable reviews. InJanet MaslinofThe New York Timesreview she wrote, \"There's no easy way out of this predicament, though Mr. Payne does beg the question with skill. AndCitizen Ruthcan easily be forgiven for not finding a fully satisfying ending. It delivers more than enough lively, gutsy satire along the way.\" His second film,Election, starringMatthew BroderickandReese Witherspoon, which takes aim at politics and education in America, attracted attention whenNew Yorkerfilm criticDavid Denbynamed it the best film of 1999. Payne received his firstAcademy Award for Writing Adapted Screenplaynomination forElection.Roger Ebertgave the film three and a half stars out of four, praising Witherspoon and Payne, and saying, \"...here is a movie that is not simply about an obnoxious student, but also about an imperfect teacher, a lockstep administration, and a student body that is mostly just marking time until it can go out into the world and occupy valuable space\".The film became a cult classic, ranking at #61 onBravo's\"100 Funniest Movies\" and #9 onEntertainment Weekly's list of the \"50 Best High School Movies\", while Witherspoon's performance was ranked at #45 on the list of the \"100 Greatest Film Performances of All Time\" byPremiere. According to Payne, it is also PresidentBarack Obama's favorite political film. In 2000, Payne completed an uncredited polish-up of the screenplay for the comedy filmMeet the Parents. In 2001, Payne wrote a draft ofJurassic Park III. In 2002, Payne's filmAbout Schmidt, about a recently retired widower who embarks on a journey to his estranged daughter's wedding, was released. The film starredJack Nicholsonas the title character, Warren Schmidt, and its script was based on the novel of the same name byLouis Begley. The film also co-starredHope Davis,Dermot Mulroney,June Squibb, andKathy Bates. The film premiered at the55th Cannes Film Festivalto rave reviews, with critics highlighting Nicholson's performance. Payne received aGolden Globefor the screenplay, which was also nominated for aWriters Guild of America Awardfor Best Adapted Screenplay. To the surprise of many who kept track of Hollywood news,Payne andJim Taylorwere not nominated for an Oscar for theAbout Schmidtscreenplay. In 2004, Payne followedAbout SchmidtwithSideways, a film about two middle-aged men who embark on a week-long road trip toSanta Barbara County wine countryto celebrate Jack's upcoming wedding. The film starsPaul GiamattiandThomas Hayden Churchas the two friends, withVirginia MadsenandSandra Oh. The film premiered at theToronto International Film Festivalwhere it received rave reviews.Roger Ebertof theChicago Sun-Timesgave the film four stars, saying: \"what happens during the seven days adds up to the best human comedy of the year – comedy, because it is funny, and human, because it is surprisingly moving.\"Payne won both theAcademy AwardandGolden Globein 2005 for Best Adapted Screenplay, while the film also won theGolden Globe Award for Best Motion Picture – Musical or Comedy. In total,Sidewaysreceived five Academy Award nominations includingBest Picture. In 2007 Payne served as an executive producer on the filmsKing of CaliforniaandThe Savages. He also collaborated once again with writing partner Jim Taylor to write a draft of the screenplay for the filmI Now Pronounce You Chuck and Larry(2007), a comedy directed byDennis Dugan, and starringAdam SandlerandKevin James. Payne disliked the final product, stating that Adam Sandler rewrote so much of the story that almost all of what Payne and Taylor wrote was gone. In 2009, Payne signed a petition calling for the release of film directorRoman Polanski, who had been arrested in Switzerland in relation to his1977 charge for drugging and raping a 13-year-old girl. Payne returned to directing in 2011 after a seven-year hiatus with the filmThe Descendants, a film about a man dealing with the aftermath of a boating accident involving his wife, leaving her in a coma. The film starredGeorge Clooney,Shailene Woodley,Beau Bridges,Judy Greer,Matthew Lillard, andRobert Forster. The film premiered at the2011 Toronto International Film Festivalwhere it received near universal praise ending up on many critics top 10 list of the year. Critics also hailed George Clooney's performance with many citing it as his best.Peter BradshawofThe Guardianpraised Payne as a director writing, \"Payne knows the difference between lightness and frivolity, between seriousness and solemnity, between different kinds of cloud...Within a single scene the film can tap into deep feelings of pain, switch into comic modes as various as farce and satire, and confront and evade moral challenges.\"Payne also co-wrote the screenplay along withNat Faxon, andJim Rashwho all won theAcademy Award for Best Adapted Screenplay. Payne executive produced the short filmRun Fast. Anna Musso, his long-time assistant and protégé, wrote and directed the film, which shot in March 2014. The project was partially funded by a Kickstarter campaign.Payne was also executive producer of the acclaimed 2014 filmKumiko, the Treasure Hunterdirected byDavid Zellner. Payne'sNebraskastarred veteran character actorBruce Dern(who received theCannes Film Festival Award for Best Actor) andSaturday Night LivealumnusWill Forte.It was released on November 15, 2013.The film received critical acclaim with David Edlestein ofNPRdescribing it as a \"superb balancing act\" and adding, \"it's a special kind of triumph\".The film was nominated for theAcademy Award for Best Picturewith Payne receiving aBest Directornomination, ultimately losing toAlfonso CuarónforGravity. Payne has said that during his seven-year hiatus betweenSideways(2004) andThe Descendants(2011), he, along with working partner Jim Taylor, were developing the satireDownsizing, which Payne has described as \"a large canvas, science-fiction social satire\" and \"an epic masterpiece.\" The film, about an impoverished married couple who decide the way ahead lies in shrinking themselves, was to starPaul GiamattiandReese Witherspoon, but was superseded byThe DescendantsandNebraska.In March 2016, Witherspoon was replaced byKristen Wiigand Giamatti byMatt Damon.Hong Chau,Christoph Waltz,Udo Kier,Neil Patrick Harris, andJason Sudeikisalso starred.Paramount Picturesreleased the film on December 22, 2017.It has received mixed reviews, with many critics describing it as the weakest film of Payne's career. In June 2021, it was announced that Payne would direct Paul Giamatti in theDavid Hemingson-scripted filmThe HoldoversforMiramax.The film premiered at theTelluride Film Festivalto widespread critical acclaim. Peter Debruge ofVarietycompared it to the films ofHal Ashbydescribing it as feeling as though it was a \"lost 70s classic\".Stephen Farber ofThe Hollywood Reporterhailed it as \"an engaging and often touching comic drama that builds power as it moves toward its immensely satisfying conclusion.\" In 2024, Payne was said to be in production on—and targeting a 2025 release for—adocumentaryfeature about film scholarJeanine Basinger.However, no updates have been given since. Payne is also currently set for directing a Danish-language film to be shot inDenmark, fully funded by European sources.This was later revealed to be titledSomewhere Out There, withRenate Reinsvejoining in a supporting roleandSearchlight Picturesacquiring worldwide distribution rights.Principal photographyis scheduled to begin in 2026. In 2025, Payne presided as the Jury President for the main competition of the82nd editionofVenice Film Festival. In 1999, it was reported that Payne was in talks to directEsquivel, a biopic starringJohn Leguizamoas Mexican musicianJuan García Esquivel. He was also developing an adaptation ofPaul Auster'sThe Locked Roomat the time. In 2000, it was reported that Payne was to co-write and direct an untitled film inspired byOscar Wilde'sThe Picture of Dorian Gray.\nHowever, nothing more was heard of this project. At one point, Payne was in talks to directthe remakeof the 1966 heist comedyGambit, after theCoen brothersdid a rewrite of the film in 2003. He planned to reunite withReese Witherspoonfor the project, but he ultimately decided against it, reluctant to direct a script he didn't write. In November 2010, it was reported that Payne would possibly direct thefilm adaptationofDaniel Clowes's graphic novelWilson.Then in November 2011, Payne confirmed that he was to directWilsonnext afterNebraska(2013).However, Payne officially confirmed in a 2014 interview withParadethat he was no longer attached to theWilsonproject. It was reported in 2011 that Payne was to direct a film titledFork in the Road.That project was to have been an adaptation of a novel by Denis Hamill. In 2012, it was reported that Payne andJim Taylorwrote a script titledThe Lost Cause, which was said to be an expansion of Taylor's 2004 short film of the same name. In November 2013, Payne was in talks to direct a film titledThe Judge's WillforFox Searchlight Pictures.The project was to have been based on aNew Yorkerarticle written byRuth Prawer Jhabvalaabout an elderly judge fromDelhiwho wants to make sure his much younger wife will be taken care of after his death.In May 2018, it was reported thatJames Ivorywould write the screenplay of the project for Payne.In June 2018, it was reported that Payne will possibly shootThe Judge's WillinChicago. In November 2014, it was announced that Payne would direct a film titledLa Vida Norteña.The project was to have been about a Latin music promoter who befriends a Nebraskan mayor. In April 2015, it was reported that Payne was interested in directingSeptillion to One, a contemporary romantic comedy inspired by the true story ofJoan Ginther, who won theTexas State Lotteryfour times.Adam R. Perlman and Graham Sack's spec script was purchased byOddLot Entertainment, who intended to produce and finance the film. Payne was not officially committed to directing at the time, due to his preoccupation with the production ofDownsizing(2017). In September 2016,Mark Romaneksigned on to direct the film. In February 2016, it was announced that Payne was to direct a film titledMy Saga, which is based on a pair of articles written byKarl Ove Knausgårdand published byThe New York Times Magazine.The articles cover Knausgård tracing theVikings' voyages in North America.The film was to have been distributed byNetflixand starMads Mikkelsen.In October 2019, the production was cancelled a week before filming was to begin due to Knausgard objecting to his life story being turned into a feature film. In March 2018, Payne was in talks to direct a legal drama film forAmazon StudiostitledThe Burial.The project was based on the true story ofMississippi-based lawyerWillie Gary, who takes on the case ofJeremiah O'Keefe, an owner of a chain of funeral homes who claimed he was swindled by a major funeral parlor conglomerate.Maggie Bettstook over as director and the film premiered in 2023 at theToronto International Film Festival. It was reported in February 2019 that Payne was attached to direct the comedy horror filmThe MenuforGary Sanchez Productions.The plot concerns a young couple that attends an exclusive restaurant in a tropical island only to experience some \"shocking surprises.\"By April 2019,Emma StoneandRalph Fienneswere set to star in the film.By May 2020,Mark Mylodreplaced Payne onThe Menu. On December 2, 2019, it was announced that Payne was attached to direct an American remake of the 1987 Oscar-winning Danish filmBabette's Feast.Payne's version is said to be set inMinnesota. On December 20, 2019, it was announced that Payne was going to direct the HBO miniseriesLandscapers.However, in October 2020, it was announced that Payne dropped out of the project due to a schedule conflict and was replaced byWill Sharpe. In 2021, Payne said that one of his upcoming projects, which he planned to followThe Holdovers, would be a comedy set in Paris based on the true story of rival antique chair dealers, and that he was using the pandemic downtime to craft the screenplay.In 2023, Payne toldIndieWirethat he was working withJim Taylorand a French screenwriting team, and that their script is \"maybe 65 percent there\".Project is based on the 2018Vanity Fairarticle \"The Chairmen\". In 2022, soon after the publication ofTracy Flick Can't Win, the sequel novel toElection, a film adaptation was announced to be in works atParamount+withReese Witherspoonset to reprise her role asTracy Flickand Payne returning to direct and co-write. While promotingThe Holdovers, Payne announced that he was collaborating with scribeDavid Hemingsonyet again on a long-time dream to make aWestern film. \"I finally found a creative partner who shares the same zeal that I have for Westerns\", Payne said.The film is said to be set in 1886Custer County, Nebraska, and will featurePaul Giamattiin a currently undisclosed role.Payne has cited the Westerns ofAnthony Mannas an influence on the project. On a 2023 episode ofHappy Sad Confused, Payne revealed that one of his favorite scripts which had not been produced was a rewrite withJim Tayloron a film calledTucker Ames as Himself, which he described as \"sort of aparodyof aBill Gatesguy who gets his comeuppance in some way.\"In the same interview, Payne reiterated that he and Taylor were still discussing how to adaptTracy Flick Can't Win, attributing his desire to addMatthew Broderick's character from the first film and veer away from \"making high school movies,\" since the novel is set at a high school again. Payne has set many of his films inOmaha, his hometown. His films sometimes include scenes of historical landmarks, black and white photographs, and museums, and he often uses amateur actors for minor roles. Payne is on the short list of directors who havefinal cut rightsfor their films. In 2005, he became a member of the Board of Governors of theAcademy of Motion Picture Arts and Sciences(Directors Branch). Payne married Canadian actressSandra Ohon January 1, 2003, after dating her for three years. On March 12, 2005, apublicistannounced their separation. The divorce was officially finalized on December 22, 2006,although the former couple took more than two years to settle their finances.In 2015, Payne married Maria Kontos, whom he met while visiting theAigioregion of Greece where some of his ancestors originated.They welcomed a daughter in 2017, and divorced in 2022.In 2022 he receivedGreek citizenship. Payne is on the Board of Directors of anOmahanon-profit film theater,Film Streams.He maintains a passion for preservation. In recent years, he helped preserve a historic film theater inScottsbluff, Nebraska. Payne was co-owner (along with friend Ann Beeder) of King Fong (now permanently closed), a Chinese restaurant in Omaha. Payne is a long-time supporterof theNebraska Coast Connection, a social networking organization that meets monthly inCulver City, California. In November 2013, he held a special screening ofNebraskafor the group's members at the Sherry Lansing Theatre on theParamount Studioslot. In a 2018 interview withRonan Farrow, actressRose McGowanaccused a \"prominent” man in Hollywood ofstatutory rapebut she did not name the person in question.In August 2020, McGowan said it was Payne and that he committed the act sometime in 1988 or 1989, when McGowan was 15 years old and Payne was about 28 years old. Payne responded to McGowan's allegation by writing a guest column inDeadline Hollywoodin which he admitted to a consensual relationship with her, stating that they had met at some point in 1991 (McGowan turned 18 in September 1991) at an audition for a comic short film that he was directing for thePlayboy Channeland had no reason to believe she was under theage of consentas the part required an actress who was of age. Payne ended his statement writing, \"While I cannot allow false statements about events 29 years ago to go uncorrected, I will continue to wish only the best for Rose\". Executive producer Producer Writer only Over his career Payne has received numerous accolades including twoAcademy Awards, aBAFTA Award, twoGolden Globe Awards, and fiveIndependent Spirit Awards. He has also received a nomination for aGrammy Award. In 2017,Metacriticranked Payne 2nd on its list of the 25 best film directors of the 21st century. Directed Academy Award performancesUnder Payne's direction, these actors have receivedAcademy Awardnominations and wins for their performances in their respective roles. In 2012, he was named as a member of the Jury for the Main Competition at the2012 Cannes Film Festival.His 2013 filmNebraskawas nominated for thePalme d'Orat the2013 Cannes Film Festival.With hisAcademy Awardnomination forNebraskain 2014,Payne has been nominated seven times, winning theAcademy Award for Best Adapted Screenplaytwice. In 2014, TheLocation Managers Guild of Americahonored Payne with their inauguralEva Monley Awardfor his masterful use of location as another character.", "combined_text": "Alexander Payne Contents Early life and education Career 1985–1996: Short films and film debut 1999–2013: Breakthrough and acclaim 2017–2022: Career slump 2023–present: Resurgence Unrealized projects Style Personal life Family Philanthropy and business ventures Statutory rape allegation Works Short film Feature film Television Bibliography Awards and nominations See also References External links  Constantine Alexander Payne(born February 10, 1961)is an American filmmaker. He is noted for hissatiricaldepictions of contemporary American society. Payne has receivednumerous accolades, including twoAcademy Awards, aBAFTA Awardand twoGolden Globe Awardsas well as a nomination for aGrammy Award. After directing several short films, Payne made his feature film debut with theblack comedyCitizen Ruth(1996). His career progressed with the political satireElection(1999), for which he received a nomination for theAcademy Award for Best Adapted Screenplay, and the comedy-dramaAbout Schmidt(2002). Payne twice won the Academy Award for Best Adapted Screenplay for co-writing his directorialsSideways(2004) andThe Descendants(2011). He was also nominated for theAcademy Award for Best Directorfor these two films and for the road filmNebraska(2013). He has since directed the comedy-dramasDownsizing(2017), andThe Holdovers(2023). Payne was born inOmaha, Nebraska, to Peggy and George Payne, restaurant owners.He is the youngest of three sonsand grew up in theDundeeneighborhood.He is of Greek ancestry.Payne's paternal grandfather, Nicholas \"Nick\" Payne,anglicizedthe last name from \"Papadopoulos\".His family comes from three areas in Greece: the island ofSyros,Livadia, andAegio.Payne's family was part of the fabricof Omaha, which he refers to as part of his upbringing.His grandfather was a founder of The Virginia Cafe, with Payne's father taking over the restaurant. Payne went there regularly as a child. The restaurant was destroyed in a fire in 1969; theW. Dale Clark Librarywas later built on the site.Payne's paternal grandmother, Clara Payne (née Hoffman), was from a German Nebraska family fromLincoln, Nebraska. In Omaha, Payne attendedBrownell-Talbot School, Dundee Elementary School, and Lewis and Clark Junior High.He graduated fromCreighton Prepfor high school in 1979.At Prep, Payne wrote a humor column for his high school newspaper and was the editor of the high school yearbook.Payne then attendedStanford University, where he majored in Spanish and History.As a part of his Spanish degree, he studied at Spain'sUniversity of Salamanca. He later lived a few months inMedellin, Colombia, where he published an article about social changes between 1900 and 1930.Payne received hisMFAin 1990 from theUCLA Film School. In the 1960s, Payne's father received aSuper 8mmprojector from Kraft Foods as a loyalty reward,and eventually passed it on to his son when Alexander was about 14 years old. A short time after getting hisMFAfromUCLA Film School—and after his successful thesis filmThe Passion of Martinhad attracted industry attention—Payne got a writing/directing deal withUniversal Pictures. The ensuing screenplay, which was turned down, ultimately becameAbout Schmidt.He says that he cleared about $60,000, which was enough to fund his simple lifestyle at the time for about five years.Payne has said he sees his talent as being one of learned economy, referring to the essay written byTennessee WilliamsonThe Catastrophe of Success.During this time Payne worked in various capacities on films and television including directing several films for thePlayboychannel. Payne co-wrote and directed his first full-length film,Citizen Ruth, which was released in 1996. The film is a satirical black comedy revolving around the issue ofabortion rights. The film starsLaura Dernas a dim-witted woman with substance abuse issues who happens to get pregnant. She unexpectedly becomes a pawn of figures from both sides of theabortion debate. The film co-starsKelly Preston,Burt Reynolds, andTippi Hedren. The film premiered at the 1996Sundance Film Festivalwhere it received favorable reviews. InJanet MaslinofThe New York Timesreview she wrote, \"There's no easy way out of this predicament, though Mr. Payne does beg the question with skill. AndCitizen Ruthcan easily be forgiven for not finding a fully satisfying ending. It delivers more than enough lively, gutsy satire along the way.\" His second film,Election, starringMatthew BroderickandReese Witherspoon, which takes aim at politics and education in America, attracted attention whenNew Yorkerfilm criticDavid Denbynamed it the best film of 1999. Payne received his firstAcademy Award for Writing Adapted Screenplaynomination forElection.Roger Ebertgave the film three and a half stars out of four, praising Witherspoon and Payne, and saying, \"...here is a movie that is not simply about an obnoxious student, but also about an imperfect teacher, a lockstep administration, and a student body that is mostly just marking time until it can go out into the world and occupy valuable space\".The film became a cult classic, ranking at #61 onBravo's\"100 Funniest Movies\" and #9 onEntertainment Weekly's list of the \"50 Best High School Movies\", while Witherspoon's performance was ranked at #45 on the list of the \"100 Greatest Film Performances of All Time\" byPremiere. According to Payne, it is also PresidentBarack Obama's favorite political film. In 2000, Payne completed an uncredited polish-up of the screenplay for the comedy filmMeet the Parents. In 2001, Payne wrote a draft ofJurassic Park III. In 2002, Payne's filmAbout Schmidt, about a recently retired widower who embarks on a journey to his estranged daughter's wedding, was released. The film starredJack Nicholsonas the title character, Warren Schmidt, and its script was based on the novel of the same name byLouis Begley. The film also co-starredHope Davis,Dermot Mulroney,June Squibb, andKathy Bates. The film premiered at the55th Cannes Film Festivalto rave reviews, with critics highlighting Nicholson's performance. Payne received aGolden Globefor the screenplay, which was also nominated for aWriters Guild of America Awardfor Best Adapted Screenplay. To the surprise of many who kept track of Hollywood news,Payne andJim Taylorwere not nominated for an Oscar for theAbout Schmidtscreenplay. In 2004, Payne followedAbout SchmidtwithSideways, a film about two middle-aged men who embark on a week-long road trip toSanta Barbara County wine countryto celebrate Jack's upcoming wedding. The film starsPaul GiamattiandThomas Hayden Churchas the two friends, withVirginia MadsenandSandra Oh. The film premiered at theToronto International Film Festivalwhere it received rave reviews.Roger Ebertof theChicago Sun-Timesgave the film four stars, saying: \"what happens during the seven days adds up to the best human comedy of the year – comedy, because it is funny, and human, because it is surprisingly moving.\"Payne won both theAcademy AwardandGolden Globein 2005 for Best Adapted Screenplay, while the film also won theGolden Globe Award for Best Motion Picture – Musical or Comedy. In total,Sidewaysreceived five Academy Award nominations includingBest Picture. In 2007 Payne served as an executive producer on the filmsKing of CaliforniaandThe Savages. He also collaborated once again with writing partner Jim Taylor to write a draft of the screenplay for the filmI Now Pronounce You Chuck and Larry(2007), a comedy directed byDennis Dugan, and starringAdam SandlerandKevin James. Payne disliked the final product, stating that Adam Sandler rewrote so much of the story that almost all of what Payne and Taylor wrote was gone. In 2009, Payne signed a petition calling for the release of film directorRoman Polanski, who had been arrested in Switzerland in relation to his1977 charge for drugging and raping a 13-year-old girl. Payne returned to directing in 2011 after a seven-year hiatus with the filmThe Descendants, a film about a man dealing with the aftermath of a boating accident involving his wife, leaving her in a coma. The film starredGeorge Clooney,Shailene Woodley,Beau Bridges,Judy Greer,Matthew Lillard, andRobert Forster. The film premiered at the2011 Toronto International Film Festivalwhere it received near universal praise ending up on many critics top 10 list of the year. Critics also hailed George Clooney's performance with many citing it as his best.Peter BradshawofThe Guardianpraised Payne as a director writing, \"Payne knows the difference between lightness and frivolity, between seriousness and solemnity, between different kinds of cloud...Within a single scene the film can tap into deep feelings of pain, switch into comic modes as various as farce and satire, and confront and evade moral challenges.\"Payne also co-wrote the screenplay along withNat Faxon, andJim Rashwho all won theAcademy Award for Best Adapted Screenplay. Payne executive produced the short filmRun Fast. Anna Musso, his long-time assistant and protégé, wrote and directed the film, which shot in March 2014. The project was partially funded by a Kickstarter campaign.Payne was also executive producer of the acclaimed 2014 filmKumiko, the Treasure Hunterdirected byDavid Zellner. Payne'sNebraskastarred veteran character actorBruce Dern(who received theCannes Film Festival Award for Best Actor) andSaturday Night LivealumnusWill Forte.It was released on November 15, 2013.The film received critical acclaim with David Edlestein ofNPRdescribing it as a \"superb balancing act\" and adding, \"it's a special kind of triumph\".The film was nominated for theAcademy Award for Best Picturewith Payne receiving aBest Directornomination, ultimately losing toAlfonso CuarónforGravity. Payne has said that during his seven-year hiatus betweenSideways(2004) andThe Descendants(2011), he, along with working partner Jim Taylor, were developing the satireDownsizing, which Payne has described as \"a large canvas, science-fiction social satire\" and \"an epic masterpiece.\" The film, about an impoverished married couple who decide the way ahead lies in shrinking themselves, was to starPaul GiamattiandReese Witherspoon, but was superseded byThe DescendantsandNebraska.In March 2016, Witherspoon was replaced byKristen Wiigand Giamatti byMatt Damon.Hong Chau,Christoph Waltz,Udo Kier,Neil Patrick Harris, andJason Sudeikisalso starred.Paramount Picturesreleased the film on December 22, 2017.It has received mixed reviews, with many critics describing it as the weakest film of Payne's career. In June 2021, it was announced that Payne would direct Paul Giamatti in theDavid Hemingson-scripted filmThe HoldoversforMiramax.The film premiered at theTelluride Film Festivalto widespread critical acclaim. Peter Debruge ofVarietycompared it to the films ofHal Ashbydescribing it as feeling as though it was a \"lost 70s classic\".Stephen Farber ofThe Hollywood Reporterhailed it as \"an engaging and often touching comic drama that builds power as it moves toward its immensely satisfying conclusion.\" In 2024, Payne was said to be in production on—and targeting a 2025 release for—adocumentaryfeature about film scholarJeanine Basinger.However, no updates have been given since. Payne is also currently set for directing a Danish-language film to be shot inDenmark, fully funded by European sources.This was later revealed to be titledSomewhere Out There, withRenate Reinsvejoining in a supporting roleandSearchlight Picturesacquiring worldwide distribution rights.Principal photographyis scheduled to begin in 2026. In 2025, Payne presided as the Jury President for the main competition of the82nd editionofVenice Film Festival. In 1999, it was reported that Payne was in talks to directEsquivel, a biopic starringJohn Leguizamoas Mexican musicianJuan García Esquivel. He was also developing an adaptation ofPaul Auster'sThe Locked Roomat the time. In 2000, it was reported that Payne was to co-write and direct an untitled film inspired byOscar Wilde'sThe Picture of Dorian Gray.\nHowever, nothing more was heard of this project. At one point, Payne was in talks to directthe remakeof the 1966 heist comedyGambit, after theCoen brothersdid a rewrite of the film in 2003. He planned to reunite withReese Witherspoonfor the project, but he ultimately decided against it, reluctant to direct a script he didn't write. In November 2010, it was reported that Payne would possibly direct thefilm adaptationofDaniel Clowes's graphic novelWilson.Then in November 2011, Payne confirmed that he was to directWilsonnext afterNebraska(2013).However, Payne officially confirmed in a 2014 interview withParadethat he was no longer attached to theWilsonproject. It was reported in 2011 that Payne was to direct a film titledFork in the Road.That project was to have been an adaptation of a novel by Denis Hamill. In 2012, it was reported that Payne andJim Taylorwrote a script titledThe Lost Cause, which was said to be an expansion of Taylor's 2004 short film of the same name. In November 2013, Payne was in talks to direct a film titledThe Judge's WillforFox Searchlight Pictures.The project was to have been based on aNew Yorkerarticle written byRuth Prawer Jhabvalaabout an elderly judge fromDelhiwho wants to make sure his much younger wife will be taken care of after his death.In May 2018, it was reported thatJames Ivorywould write the screenplay of the project for Payne.In June 2018, it was reported that Payne will possibly shootThe Judge's WillinChicago. In November 2014, it was announced that Payne would direct a film titledLa Vida Norteña.The project was to have been about a Latin music promoter who befriends a Nebraskan mayor. In April 2015, it was reported that Payne was interested in directingSeptillion to One, a contemporary romantic comedy inspired by the true story ofJoan Ginther, who won theTexas State Lotteryfour times.Adam R. Perlman and Graham Sack's spec script was purchased byOddLot Entertainment, who intended to produce and finance the film. Payne was not officially committed to directing at the time, due to his preoccupation with the production ofDownsizing(2017). In September 2016,Mark Romaneksigned on to direct the film. In February 2016, it was announced that Payne was to direct a film titledMy Saga, which is based on a pair of articles written byKarl Ove Knausgårdand published byThe New York Times Magazine.The articles cover Knausgård tracing theVikings' voyages in North America.The film was to have been distributed byNetflixand starMads Mikkelsen.In October 2019, the production was cancelled a week before filming was to begin due to Knausgard objecting to his life story being turned into a feature film. In March 2018, Payne was in talks to direct a legal drama film forAmazon StudiostitledThe Burial.The project was based on the true story ofMississippi-based lawyerWillie Gary, who takes on the case ofJeremiah O'Keefe, an owner of a chain of funeral homes who claimed he was swindled by a major funeral parlor conglomerate.Maggie Bettstook over as director and the film premiered in 2023 at theToronto International Film Festival. It was reported in February 2019 that Payne was attached to direct the comedy horror filmThe MenuforGary Sanchez Productions.The plot concerns a young couple that attends an exclusive restaurant in a tropical island only to experience some \"shocking surprises.\"By April 2019,Emma StoneandRalph Fienneswere set to star in the film.By May 2020,Mark Mylodreplaced Payne onThe Menu. On December 2, 2019, it was announced that Payne was attached to direct an American remake of the 1987 Oscar-winning Danish filmBabette's Feast.Payne's version is said to be set inMinnesota. On December 20, 2019, it was announced that Payne was going to direct the HBO miniseriesLandscapers.However, in October 2020, it was announced that Payne dropped out of the project due to a schedule conflict and was replaced byWill Sharpe. In 2021, Payne said that one of his upcoming projects, which he planned to followThe Holdovers, would be a comedy set in Paris based on the true story of rival antique chair dealers, and that he was using the pandemic downtime to craft the screenplay.In 2023, Payne toldIndieWirethat he was working withJim Taylorand a French screenwriting team, and that their script is \"maybe 65 percent there\".Project is based on the 2018Vanity Fairarticle \"The Chairmen\". In 2022, soon after the publication ofTracy Flick Can't Win, the sequel novel toElection, a film adaptation was announced to be in works atParamount+withReese Witherspoonset to reprise her role asTracy Flickand Payne returning to direct and co-write. While promotingThe Holdovers, Payne announced that he was collaborating with scribeDavid Hemingsonyet again on a long-time dream to make aWestern film. \"I finally found a creative partner who shares the same zeal that I have for Westerns\", Payne said.The film is said to be set in 1886Custer County, Nebraska, and will featurePaul Giamattiin a currently undisclosed role.Payne has cited the Westerns ofAnthony Mannas an influence on the project. On a 2023 episode ofHappy Sad Confused, Payne revealed that one of his favorite scripts which had not been produced was a rewrite withJim Tayloron a film calledTucker Ames as Himself, which he described as \"sort of aparodyof aBill Gatesguy who gets his comeuppance in some way.\"In the same interview, Payne reiterated that he and Taylor were still discussing how to adaptTracy Flick Can't Win, attributing his desire to addMatthew Broderick's character from the first film and veer away from \"making high school movies,\" since the novel is set at a high school again. Payne has set many of his films inOmaha, his hometown. His films sometimes include scenes of historical landmarks, black and white photographs, and museums, and he often uses amateur actors for minor roles. Payne is on the short list of directors who havefinal cut rightsfor their films. In 2005, he became a member of the Board of Governors of theAcademy of Motion Picture Arts and Sciences(Directors Branch). Payne married Canadian actressSandra Ohon January 1, 2003, after dating her for three years. On March 12, 2005, apublicistannounced their separation. The divorce was officially finalized on December 22, 2006,although the former couple took more than two years to settle their finances.In 2015, Payne married Maria Kontos, whom he met while visiting theAigioregion of Greece where some of his ancestors originated.They welcomed a daughter in 2017, and divorced in 2022.In 2022 he receivedGreek citizenship. Payne is on the Board of Directors of anOmahanon-profit film theater,Film Streams.He maintains a passion for preservation. In recent years, he helped preserve a historic film theater inScottsbluff, Nebraska. Payne was co-owner (along with friend Ann Beeder) of King Fong (now permanently closed), a Chinese restaurant in Omaha. Payne is a long-time supporterof theNebraska Coast Connection, a social networking organization that meets monthly inCulver City, California. In November 2013, he held a special screening ofNebraskafor the group's members at the Sherry Lansing Theatre on theParamount Studioslot. In a 2018 interview withRonan Farrow, actressRose McGowanaccused a \"prominent” man in Hollywood ofstatutory rapebut she did not name the person in question.In August 2020, McGowan said it was Payne and that he committed the act sometime in 1988 or 1989, when McGowan was 15 years old and Payne was about 28 years old. Payne responded to McGowan's allegation by writing a guest column inDeadline Hollywoodin which he admitted to a consensual relationship with her, stating that they had met at some point in 1991 (McGowan turned 18 in September 1991) at an audition for a comic short film that he was directing for thePlayboy Channeland had no reason to believe she was under theage of consentas the part required an actress who was of age. Payne ended his statement writing, \"While I cannot allow false statements about events 29 years ago to go uncorrected, I will continue to wish only the best for Rose\". Executive producer Producer Writer only Over his career Payne has received numerous accolades including twoAcademy Awards, aBAFTA Award, twoGolden Globe Awards, and fiveIndependent Spirit Awards. He has also received a nomination for aGrammy Award. In 2017,Metacriticranked Payne 2nd on its list of the 25 best film directors of the 21st century. Directed Academy Award performancesUnder Payne's direction, these actors have receivedAcademy Awardnominations and wins for their performances in their respective roles. In 2012, he was named as a member of the Jury for the Main Competition at the2012 Cannes Film Festival.His 2013 filmNebraskawas nominated for thePalme d'Orat the2013 Cannes Film Festival.With hisAcademy Awardnomination forNebraskain 2014,Payne has been nominated seven times, winning theAcademy Award for Best Adapted Screenplaytwice. In 2014, TheLocation Managers Guild of Americahonored Payne with their inauguralEva Monley Awardfor his masterful use of location as another character.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Alexander_Payne", "https://en.wikipedia.org/wiki/Alexander_Payne", "https://en.wikipedia.org/wiki/Alexander_Payne", "https://en.wikipedia.org/wiki/Omaha", "https://en.wikipedia.org/wiki/Nebraska", "https://en.wikipedia.org/wiki/Stanford_University", "https://en.wikipedia.org/wiki/Bachelor_of_Arts", "https://en.wikipedia.org/wiki/University_of_California,_Los_Angeles"]},
{"id": "91e16c2601c9", "url": "https://en.wikipedia.org/wiki/Chelsea_Finn", "title": "Chelsea Finn", "headings": ["Contents", "Early life and education", "Research and career", "Awards and honors", "Select publications", "References"], "content": "Chelsea Finn(born 1992 or 1993) is an American computer scientist and assistant professor atStanford University. Her research investigates intelligence through the interactions of robots, with the hope to create robotic systems that can learn how to learn. She is part of theGoogle Braingroup. Finn was an undergraduate student in electrical engineering and computer science atMassachusetts Institute of Technology. She then moved to theUniversity of California, Berkeley, where she earned her Ph.D. in 2018 underPieter AbbeelandSergey Levine. Her work in the Berkeley Artificial Intelligence Lab (BAIR) focused on gradient based algorithms .Such algorithms allow machines to 'learn to learn', more akin to human learning than traditional machine learning systems.These “meta-learning” techniques train machines to quickly adapt, such that when they encounter new scenarios they can learn quickly.As a doctoral student she worked as an intern atGoogle Brain, where she worked on robot learning algorithms from deep predictive models. She delivered amassive open online courseondeep reinforcement learning.She was the first woman to win the C.V. & Daulat Ramamoorthy Distinguished Research Award. Finn investigates the capabilities of robots to develop intelligence through learning and interaction.She has made use ofdeep learningalgorithms to simultaneously learn visual perception and control robotic skills. She developed meta-learning approaches to train neural networks to take in student code and output useful feedback.She showed that the system could quickly adapt without too much input from the instructor.She trialled the programme on Code in Place, a 12,000 student course delivered byStanford Universityevery year. She found that 97.9% of the time the students agreed with the feedback being given.", "combined_text": "Chelsea Finn Contents Early life and education Research and career Awards and honors Select publications References Chelsea Finn(born 1992 or 1993) is an American computer scientist and assistant professor atStanford University. Her research investigates intelligence through the interactions of robots, with the hope to create robotic systems that can learn how to learn. She is part of theGoogle Braingroup. Finn was an undergraduate student in electrical engineering and computer science atMassachusetts Institute of Technology. She then moved to theUniversity of California, Berkeley, where she earned her Ph.D. in 2018 underPieter AbbeelandSergey Levine. Her work in the Berkeley Artificial Intelligence Lab (BAIR) focused on gradient based algorithms .Such algorithms allow machines to 'learn to learn', more akin to human learning than traditional machine learning systems.These “meta-learning” techniques train machines to quickly adapt, such that when they encounter new scenarios they can learn quickly.As a doctoral student she worked as an intern atGoogle Brain, where she worked on robot learning algorithms from deep predictive models. She delivered amassive open online courseondeep reinforcement learning.She was the first woman to win the C.V. & Daulat Ramamoorthy Distinguished Research Award. Finn investigates the capabilities of robots to develop intelligence through learning and interaction.She has made use ofdeep learningalgorithms to simultaneously learn visual perception and control robotic skills. She developed meta-learning approaches to train neural networks to take in student code and output useful feedback.She showed that the system could quickly adapt without too much input from the instructor.She trialled the programme on Code in Place, a 12,000 student course delivered byStanford Universityevery year. She found that 97.9% of the time the students agreed with the feedback being given.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Chelsea_Finn", "https://en.wikipedia.org/wiki/Chelsea_Finn", "https://en.wikipedia.org/wiki/Chelsea_Finn", "https://en.wikipedia.org/wiki/UC_Berkeley", "https://en.wikipedia.org/wiki/University_of_California,_Berkeley", "https://en.wikipedia.org/wiki/Massachusetts_Institute_of_Technology", "https://en.wikipedia.org/wiki/Deep_reinforcement_learning", "https://en.wikipedia.org/wiki/Stanford_University"]},
{"id": "23bc976c19fa", "url": "https://en.wikipedia.org/wiki/Brodmann_area", "title": "Brodmann area", "headings": ["Contents", "History", "Present importance", "Overview", "For humans and other primates", "Clickable map: lateral surface", "Clickable map: medial surface", "Criticism", "See also", "References", "External links"], "content": " ABrodmann areais a region of thecerebral cortex, in thehumanor otherprimatebrain, defined by itscytoarchitecture, orhistologicalstructure and organization ofcells. The concept was first introduced by the German anatomistKorbinian Brodmannin the early 20th century. Brodmann mapped the human brain based on the varied cellular structure across the cortex and identified 52 distinct regions, which he numbered 1 to 52. These regions, or Brodmann areas, correspond with diverse functions including sensation, motor control, and cognition. Brodmann areas were originally defined and numbered by theGermananatomistKorbinian Brodmannbased on thecytoarchitecturalorganization ofneuronshe observed in the cerebral cortex using theNissl methodof cell staining. Brodmann published his maps of cortical areas in humans, monkeys, and other species in 1909,along with many other findings and observations regarding the general cell types andlaminar organizationof the mammaliancortex. The same Brodmann area number in different species does not necessarily indicatehomologousareas.A similar, but more detailed cortical map was published byConstantin von EconomoandGeorg N. Koskinasin 1925. Brodmann areas have been discussed, debated, refined, and renamed exhaustively for nearly a century and remain the most widely known and frequently cited cytoarchitectural organization of the human cortex. Many of the areas Brodmann defined based solely on their neuronal organization have since been correlated closely to diverse cortical functions. For example, Brodmann areas 1, 2 and 3 are theprimary somatosensory cortex; area 4 is theprimary motor cortex; area 17 is theprimary visual cortex; and areas 41 and 42 correspond closely toprimary auditory cortex.Higher order functionsof theassociation cortical areasare also consistently localized to the same Brodmann areas byneurophysiological,functional imaging, and other methods (e.g., the consistent localization ofBroca'sspeech and language area to the leftBrodmann areas 44 and 45). However, functional imaging can only identify the approximate localization of brain activations in terms of Brodmann areas since their actual boundaries in any individual brain require itshistologicalexamination. Different parts of the cerebral cortex are involved in different cognitive and behavioral functions. The differences show up in a number of ways: the effects of localized brain damage, regional activity patterns exposed when the brain is examined using functional imaging techniques, connectivity with subcortical areas, and regional differences in the cellular architecture of the cortex. Theneocortexis divided into six layers, but not all layers are apparent in all areas, and the thickness and cellular organization of a single layer may vary.Maps of cortical areasare constructed on the basis of variations in the appearance of the layers as seen with a microscope. Korbinian Brodmanncreated one of the most widely used schemes, splitting the cortex into 52 different areas and assigned each a number (many of these Brodmann areas have since been subdivided). For example, Brodmann area 1 is the primary somatosensory cortex, Brodmann area 17 is the primary visual cortex, and Brodmann area 25 is the anterior cingulate cortex. Many of the brain areas defined by Brodmann have their own complex internal structures. In a number of cases, brain areas are organized intotopographic maps, where adjoining bits of the cortex correspond to adjoining parts of the body, or of some more abstract entity. A simple example of this type of correspondence is the primary motor cortex, a strip of tissue running along the anterior edge of thecentral sulcus. Motor areas innervating each part of the body arise from a distinct zone, with neighboring body parts represented by neighboring zones.Electrical stimulation of the cortex at any point causes a muscle-contraction in the represented body part. This \"somatotopic\" representation is not evenly distributed, however; the head, for example, is represented by a region about three times as large as the zone for the entire back and trunk. The size of any zone correlates to the precision of motor control and sensory discrimination possible. The areas for the lips, fingers, and tongue are particularly large, considering the proportional size of their represented body parts. The maps for visual areas areretinotopic(reflecting the topography of theretina). This representation is uneven, with thefovea(the area at the center of the visual field) overrepresented compared to the periphery. The visual circuitry in the human cerebral cortex contains several dozen distinct retinotopic maps, each devoted to analyzing the visual input stream in a particular way. The primary visual cortex (Brodmann area 17) contains many neurons that are most easily activated by edges with a particular orientation moving across a particular point in the visual field. Visual areas farther downstream extract features such as color, motion, and shape. In auditory areas, the primary map istonotopic.Sounds are parsed according to frequency (i.e., high pitch vs. low pitch) by subcortical auditory areas, and this parsing is reflected by the primary auditory zone of the cortex. As with the visual system, there are a number of tonotopic cortical maps, each devoted to analyzing sound in a particular way. Within a topographic map there can sometimes be finer levels of spatial structure. In the primary visual cortex, for example, where the main organization is retinotopic and the main responses are to moving edges, cells that respond to different edge-orientations are spatially segregated from one another.  (*) Area only found in non-humanprimates. Some of the original Brodmann areas have been subdivided further, e.g., \"23a\" and \"23b\". When von Bonin and Bailey constructed a brain map for themacaquemonkey, they found the description of Brodmann inadequate and wrote: \"Brodmann (1907), it is true, prepared a map of the human brain which has been widely reproduced, but, unfortunately, the data on which it was based was never published\"They instead used the cytoarchitectonic scheme ofConstantin von EconomoandGeorg N. Koskinaspublished in 1925which had the \"only acceptable detailed description of the human cortex\".", "combined_text": "Brodmann area Contents History Present importance Overview For humans and other primates Clickable map: lateral surface Clickable map: medial surface Criticism See also References External links  ABrodmann areais a region of thecerebral cortex, in thehumanor otherprimatebrain, defined by itscytoarchitecture, orhistologicalstructure and organization ofcells. The concept was first introduced by the German anatomistKorbinian Brodmannin the early 20th century. Brodmann mapped the human brain based on the varied cellular structure across the cortex and identified 52 distinct regions, which he numbered 1 to 52. These regions, or Brodmann areas, correspond with diverse functions including sensation, motor control, and cognition. Brodmann areas were originally defined and numbered by theGermananatomistKorbinian Brodmannbased on thecytoarchitecturalorganization ofneuronshe observed in the cerebral cortex using theNissl methodof cell staining. Brodmann published his maps of cortical areas in humans, monkeys, and other species in 1909,along with many other findings and observations regarding the general cell types andlaminar organizationof the mammaliancortex. The same Brodmann area number in different species does not necessarily indicatehomologousareas.A similar, but more detailed cortical map was published byConstantin von EconomoandGeorg N. Koskinasin 1925. Brodmann areas have been discussed, debated, refined, and renamed exhaustively for nearly a century and remain the most widely known and frequently cited cytoarchitectural organization of the human cortex. Many of the areas Brodmann defined based solely on their neuronal organization have since been correlated closely to diverse cortical functions. For example, Brodmann areas 1, 2 and 3 are theprimary somatosensory cortex; area 4 is theprimary motor cortex; area 17 is theprimary visual cortex; and areas 41 and 42 correspond closely toprimary auditory cortex.Higher order functionsof theassociation cortical areasare also consistently localized to the same Brodmann areas byneurophysiological,functional imaging, and other methods (e.g., the consistent localization ofBroca'sspeech and language area to the leftBrodmann areas 44 and 45). However, functional imaging can only identify the approximate localization of brain activations in terms of Brodmann areas since their actual boundaries in any individual brain require itshistologicalexamination. Different parts of the cerebral cortex are involved in different cognitive and behavioral functions. The differences show up in a number of ways: the effects of localized brain damage, regional activity patterns exposed when the brain is examined using functional imaging techniques, connectivity with subcortical areas, and regional differences in the cellular architecture of the cortex. Theneocortexis divided into six layers, but not all layers are apparent in all areas, and the thickness and cellular organization of a single layer may vary.Maps of cortical areasare constructed on the basis of variations in the appearance of the layers as seen with a microscope. Korbinian Brodmanncreated one of the most widely used schemes, splitting the cortex into 52 different areas and assigned each a number (many of these Brodmann areas have since been subdivided). For example, Brodmann area 1 is the primary somatosensory cortex, Brodmann area 17 is the primary visual cortex, and Brodmann area 25 is the anterior cingulate cortex. Many of the brain areas defined by Brodmann have their own complex internal structures. In a number of cases, brain areas are organized intotopographic maps, where adjoining bits of the cortex correspond to adjoining parts of the body, or of some more abstract entity. A simple example of this type of correspondence is the primary motor cortex, a strip of tissue running along the anterior edge of thecentral sulcus. Motor areas innervating each part of the body arise from a distinct zone, with neighboring body parts represented by neighboring zones.Electrical stimulation of the cortex at any point causes a muscle-contraction in the represented body part. This \"somatotopic\" representation is not evenly distributed, however; the head, for example, is represented by a region about three times as large as the zone for the entire back and trunk. The size of any zone correlates to the precision of motor control and sensory discrimination possible. The areas for the lips, fingers, and tongue are particularly large, considering the proportional size of their represented body parts. The maps for visual areas areretinotopic(reflecting the topography of theretina). This representation is uneven, with thefovea(the area at the center of the visual field) overrepresented compared to the periphery. The visual circuitry in the human cerebral cortex contains several dozen distinct retinotopic maps, each devoted to analyzing the visual input stream in a particular way. The primary visual cortex (Brodmann area 17) contains many neurons that are most easily activated by edges with a particular orientation moving across a particular point in the visual field. Visual areas farther downstream extract features such as color, motion, and shape. In auditory areas, the primary map istonotopic.Sounds are parsed according to frequency (i.e., high pitch vs. low pitch) by subcortical auditory areas, and this parsing is reflected by the primary auditory zone of the cortex. As with the visual system, there are a number of tonotopic cortical maps, each devoted to analyzing sound in a particular way. Within a topographic map there can sometimes be finer levels of spatial structure. In the primary visual cortex, for example, where the main organization is retinotopic and the main responses are to moving edges, cells that respond to different edge-orientations are spatially segregated from one another.  (*) Area only found in non-humanprimates. Some of the original Brodmann areas have been subdivided further, e.g., \"23a\" and \"23b\". When von Bonin and Bailey constructed a brain map for themacaquemonkey, they found the description of Brodmann inadequate and wrote: \"Brodmann (1907), it is true, prepared a map of the human brain which has been widely reproduced, but, unfortunately, the data on which it was based was never published\"They instead used the cytoarchitectonic scheme ofConstantin von EconomoandGeorg N. Koskinaspublished in 1925which had the \"only acceptable detailed description of the human cortex\".", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Brodmann_area", "https://en.wikipedia.org/wiki/Brodmann_area", "https://en.wikipedia.org/wiki/Brodmann_area", "https://en.wikipedia.org/wiki/Cerebrum", "https://en.wikipedia.org/wiki/NeuroNames", "https://en.wikipedia.org/wiki/Foundational_Model_of_Anatomy", "https://en.wikipedia.org/wiki/Anatomical_terms_of_neuroanatomy", "https://en.wikipedia.org/wiki/Cerebral_cortex"]},
{"id": "8d3206b5136c", "url": "https://en.wikipedia.org/wiki/World_Population_Prospects", "title": "World Population Prospects", "headings": ["Contents", "Development", "History", "Editions", "Reception and accuracy", "See also", "References"], "content": " TheUnited NationsWorld Population Prospects(WPP) is the official series ofglobal populationestimates and projections produced by thePopulation DivisionofUnited Nations Department of Economic and Social Affairs(UNDESA).  Each new revision presents updated data on population size by country and region, covering past estimates (from 1950 onward) and future forecasts (typically through 2100).  For example, the 2024 Revision – the 28th edition since the first 1951 projection – reports annual population counts up to 2023 for 237 countries and territories, drawing on over 1,900 national censuses (1950–2023) and thousands of surveys, and generates multi-variant projections (medium, low, high, etc.) into the future. These data include age‐ and sex‐specific breakdowns offertility,mortalityandmigration, allowing calculation of detailed demographic indicators.Statistics from the WPP are often cited in academia and by the media. WPP estimates and projections are constructed using standard demographic methods.  The Division applies a cohort-component approach, ensuring that changes in population by age and sex are consistent with assumed fertility, mortality and net migration.Over time the methodology has been refined: for example, the 2010 Revision (22nd edition) extended the projection horizon to 2100 (instead of 2050) by introducing a newprobabilisticfertility model.In the 2022 Revision, the data format was modernized so that all population counts and rates are reported by single calendar years of age and time, rather than five-year groups. The 2024 Revision further enhanced the methods by incorporating a probabilistic treatment of future international migration (for the first time, treating migration in the same uncertainty framework as fertility and mortality).Through each revision, assumptions about the pace of fertility decline, mortality decline, and migration flows are updated based on new empirical research and expert judgment, reflecting the latest demographic evidence. The WPP data are often visualized as long-term population curves. WPP likewise provides age-structure projections (e.g. proportions of children, working-age adults, and elderly) for each country and region. Such projections show, for example, the rise in the share of elderly in nearly every region. By combining these components, WPP yields \"population pyramids\" and dependency ratios that are widely used in research and planning. In practice, the Division publishes tables, charts and online databases so that users can retrieve both historical population series and variant projections by single-year age cohorts and calendar-year intervals. World Population Prospectstraces its origins to the early post–World War IIera. In 1946, the United Nations began collecting country-by-country population data, culminating in a global count of about 2.47 billion people in 1950. The UN published the first set of world population projections in 1951, under the titleWorld Population Prospects (1951).Since then, revisions have appeared periodically, initially every few years, and more recently roughly every 2–3 years, each time incorporating the latestcensusand survey information.  By mid‑2024, twenty‑eight editions had been issued, making WPP one of the most continuously updated demographic series (the 2019 and 2024 Revisions correspond to the 26th and 28th editions, respectively).Each new edition not only projects forward from the present but also retrospectively revises past population estimates to maintain consistency. The following is a list of all major WPP editions (by year of revision): WPP is widely regarded as the authoritative source for global population figures and projections, and it plays a central role in demographic research and policy.  Major international agencies and analysts routinely use WPP data as a baseline.  For example, theWorld Bank’sWorld Development Indicatorspopulation series explicitly cites UN WPP estimates.Within the United Nations, WPP figures underpin many key statistics, such as a large part of theSDGindicators (such as those tracking education or health per capita indicators) rely on population totals from WPP. Researchers also depend on WPP; academic studies of trends in population growth, aging and migration nearly always reference the latest WPP data. Assessments of WPP’s accuracy have been generally positive. Historical UN forecasts of world population have proven quite close to later estimates: most global projections made for 20–30 years ahead have differed from the eventual totals by only a few percent.For instance, one review noted that of 12 UN projections of the year 2000 world population made since the 1950s, all but one were within 4% of the actual population. Country- or age-specific forecasts are naturally less precise, due to greater data uncertainty at finer levels.As Keilman (1998) concluded, “[the] accuracy of the UN projections isnota weak point,” noting that in recent years the UN’s world growth forecasts erred by only about 0.2 percentage points and got more accurate over time.", "combined_text": "World Population Prospects Contents Development History Editions Reception and accuracy See also References  TheUnited NationsWorld Population Prospects(WPP) is the official series ofglobal populationestimates and projections produced by thePopulation DivisionofUnited Nations Department of Economic and Social Affairs(UNDESA).  Each new revision presents updated data on population size by country and region, covering past estimates (from 1950 onward) and future forecasts (typically through 2100).  For example, the 2024 Revision – the 28th edition since the first 1951 projection – reports annual population counts up to 2023 for 237 countries and territories, drawing on over 1,900 national censuses (1950–2023) and thousands of surveys, and generates multi-variant projections (medium, low, high, etc.) into the future. These data include age‐ and sex‐specific breakdowns offertility,mortalityandmigration, allowing calculation of detailed demographic indicators.Statistics from the WPP are often cited in academia and by the media. WPP estimates and projections are constructed using standard demographic methods.  The Division applies a cohort-component approach, ensuring that changes in population by age and sex are consistent with assumed fertility, mortality and net migration.Over time the methodology has been refined: for example, the 2010 Revision (22nd edition) extended the projection horizon to 2100 (instead of 2050) by introducing a newprobabilisticfertility model.In the 2022 Revision, the data format was modernized so that all population counts and rates are reported by single calendar years of age and time, rather than five-year groups. The 2024 Revision further enhanced the methods by incorporating a probabilistic treatment of future international migration (for the first time, treating migration in the same uncertainty framework as fertility and mortality).Through each revision, assumptions about the pace of fertility decline, mortality decline, and migration flows are updated based on new empirical research and expert judgment, reflecting the latest demographic evidence. The WPP data are often visualized as long-term population curves. WPP likewise provides age-structure projections (e.g. proportions of children, working-age adults, and elderly) for each country and region. Such projections show, for example, the rise in the share of elderly in nearly every region. By combining these components, WPP yields \"population pyramids\" and dependency ratios that are widely used in research and planning. In practice, the Division publishes tables, charts and online databases so that users can retrieve both historical population series and variant projections by single-year age cohorts and calendar-year intervals. World Population Prospectstraces its origins to the early post–World War IIera. In 1946, the United Nations began collecting country-by-country population data, culminating in a global count of about 2.47 billion people in 1950. The UN published the first set of world population projections in 1951, under the titleWorld Population Prospects (1951).Since then, revisions have appeared periodically, initially every few years, and more recently roughly every 2–3 years, each time incorporating the latestcensusand survey information.  By mid‑2024, twenty‑eight editions had been issued, making WPP one of the most continuously updated demographic series (the 2019 and 2024 Revisions correspond to the 26th and 28th editions, respectively).Each new edition not only projects forward from the present but also retrospectively revises past population estimates to maintain consistency. The following is a list of all major WPP editions (by year of revision): WPP is widely regarded as the authoritative source for global population figures and projections, and it plays a central role in demographic research and policy.  Major international agencies and analysts routinely use WPP data as a baseline.  For example, theWorld Bank’sWorld Development Indicatorspopulation series explicitly cites UN WPP estimates.Within the United Nations, WPP figures underpin many key statistics, such as a large part of theSDGindicators (such as those tracking education or health per capita indicators) rely on population totals from WPP. Researchers also depend on WPP; academic studies of trends in population growth, aging and migration nearly always reference the latest WPP data. Assessments of WPP’s accuracy have been generally positive. Historical UN forecasts of world population have proven quite close to later estimates: most global projections made for 20–30 years ahead have differed from the eventual totals by only a few percent.For instance, one review noted that of 12 UN projections of the year 2000 world population made since the 1950s, all but one were within 4% of the actual population. Country- or age-specific forecasts are naturally less precise, due to greater data uncertainty at finer levels.As Keilman (1998) concluded, “[the] accuracy of the UN projections isnota weak point,” noting that in recent years the UN’s world growth forecasts erred by only about 0.2 percentage points and got more accurate over time.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/World_Population_Prospects", "https://en.wikipedia.org/wiki/World_Population_Prospects", "https://en.wikipedia.org/wiki/World_Population_Prospects", "https://en.wikipedia.org/wiki/United_Nations", "https://en.wikipedia.org/wiki/World_population", "https://en.wikipedia.org/wiki/Population_Division_of_the_Department_of_Economic_and_Social_Affairs_of_the_United_Nations_Secretariat", "https://en.wikipedia.org/wiki/United_Nations_Department_of_Economic_and_Social_Affairs", "https://en.wikipedia.org/wiki/Fertility"]},
{"id": "e120413e0a88", "url": "https://en.wikipedia.org/wiki/Orders,_decorations,_and_medals_of_Hawaii", "title": "Orders, decorations, and medals of Hawaii", "headings": ["Contents", "Kingdom of Hawaiʻi", "Royal Orders", "Royal Medals", "Royal Anniversary Medals", "Republic of Hawaiʻi", "State of Hawaiʻi", "Hawaii National Guard State Awards", "Others", "References"], "content": " Theorders, decorations, and medalsof theKingdom,Republic, andStateof Hawaiʻi includeknighthoods, orders ofmeritandprecedence, andmilitary awards and decorations. The orders and decorations formerly awarded in by theKingdom of Hawaiʻiare: The Orders and decorations formerly awarded by theRepublic of Hawaiʻiare:  ThisHawaiʻi-related article is astub. You can help Wikipedia byexpanding it.", "combined_text": "Orders, decorations, and medals of Hawaii Contents Kingdom of Hawaiʻi Royal Orders Royal Medals Royal Anniversary Medals Republic of Hawaiʻi State of Hawaiʻi Hawaii National Guard State Awards Others References  Theorders, decorations, and medalsof theKingdom,Republic, andStateof Hawaiʻi includeknighthoods, orders ofmeritandprecedence, andmilitary awards and decorations. The orders and decorations formerly awarded in by theKingdom of Hawaiʻiare: The Orders and decorations formerly awarded by theRepublic of Hawaiʻiare:  ThisHawaiʻi-related article is astub. You can help Wikipedia byexpanding it.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Orders,_decorations,_and_medals_of_Hawaii", "https://en.wikipedia.org/wiki/Orders,_decorations,_and_medals_of_Hawaii", "https://en.wikipedia.org/wiki/Orders,_decorations,_and_medals_of_Hawaii", "https://en.wikipedia.org/wiki/Kingdom_of_Hawaii", "https://en.wikipedia.org/wiki/Republic_of_Hawaii", "https://en.wikipedia.org/wiki/Hawaii", "https://en.wikipedia.org/wiki/Knight", "https://en.wikipedia.org/wiki/Order_of_merit"]},
{"id": "9365899280ed", "url": "https://en.wikipedia.org/wiki/Orders,_decorations,_and_medals_of_Tuvalu", "title": "Tuvalu Order of Merit", "headings": ["Contents", "Discussion of award", "Recipients", "Tuvalu Order of Merit", "Medal of the Tuvalu Order of Merit", "References"], "content": "TheTuvalu Order of Meritis anorder of meritofTuvalu. It was founded on 1 October 2016, on the 38th anniversary of Tuvaluan independence; with $30,000 for the award allocated in the Tuvalu 2017 National Budget. AtKensington Palaceon 30 October 2017,Prince Williamreceived His ExcellencySir Iftikhar Ayaz(Honorary Consul-General of Tuvalu) who invested His Royal Highnessand thethen Duchess of Cambridgewith the Tuvalu Order of Merit on behalf of theGovernor-General of Tuvalu.The award was given to the Prince and Princess of Wales in recognition of their visit to Tuvalu as part of theDiamond Jubilee of Queen Elizabeth II.", "combined_text": "Tuvalu Order of Merit Contents Discussion of award Recipients Tuvalu Order of Merit Medal of the Tuvalu Order of Merit References TheTuvalu Order of Meritis anorder of meritofTuvalu. It was founded on 1 October 2016, on the 38th anniversary of Tuvaluan independence; with $30,000 for the award allocated in the Tuvalu 2017 National Budget. AtKensington Palaceon 30 October 2017,Prince Williamreceived His ExcellencySir Iftikhar Ayaz(Honorary Consul-General of Tuvalu) who invested His Royal Highnessand thethen Duchess of Cambridgewith the Tuvalu Order of Merit on behalf of theGovernor-General of Tuvalu.The award was given to the Prince and Princess of Wales in recognition of their visit to Tuvalu as part of theDiamond Jubilee of Queen Elizabeth II.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Tuvalu_Order_of_Merit", "https://en.wikipedia.org/wiki/Tuvalu_Order_of_Merit", "https://en.wikipedia.org/wiki/Tuvalu_Order_of_Merit", "https://en.wikipedia.org/wiki/Monarch_of_Tuvalu", "https://en.wikipedia.org/wiki/Order_(honour)", "https://en.wikipedia.org/wiki/Elizabeth_II", "https://en.wikipedia.org/wiki/Charles_III", "https://en.wikipedia.org/wiki/Order_of_merit"]},
{"id": "477c9aefaf58", "url": "https://en.wikipedia.org/wiki/Romanization_of_Greek", "title": "Romanization of Greek", "headings": ["Contents", "History", "Tables", "Ancient Greek", "Modern Greek", "Diacritical marks", "Numerals", "Punctuation marks", "Uncommon letters", "Standardization", "See also", "References", "External links"], "content": " Romanization of Greekis thetransliteration(letter-mapping) ortranscription(sound-mapping) of text from theGreek alphabetinto theLatin alphabet. The conventions forwritingandromanizingAncient GreekandModern Greekdiffer markedly. The sound of theEnglish letterB(/b/) was written asβin ancient Greek but is now written as thedigraphμπ, while the modernβsounds like the English letterV(/v/) instead. TheGreek nameἸωάννηςbecameJohannesinLatinand thenJohnin English, but in modern Greek has becomeΓιάννης; this might be written asYannis, Jani, Ioannis, Yiannis, or Giannis, but not Giannes or Giannēs as it would be for ancient Greek. The wordΆγιοςmight variously appear as Hagiοs, Agios, Aghios, or Ayios, or simply betranslatedas \"Holy\" or \"Saint\" in English forms ofGreek placenames. Traditional English renderings of Greek names originated fromRomansystems established in antiquity. TheRoman alphabetitself was a form of theCumaean alphabetderived from theEuboean scriptthat valuedΧas/ks/andΗas/h/and used variant forms ofΛandΣthat becameLandS.When this script was used to write the classical Greek alphabet, ⟨κ⟩ was replaced with ⟨c⟩, ⟨αι⟩ and ⟨οι⟩ became ⟨æ⟩ and ⟨œ⟩, and ⟨ει⟩ and ⟨ου⟩ were simplified to ⟨i⟩ (more rarely—corresponding to an earlier pronunciation—⟨e⟩) and ⟨u⟩.Aspirated consonantslike ⟨θ⟩, ⟨φ⟩, initial-⟨ρ⟩, and ⟨χ⟩ simply wrote out the sound: ⟨th⟩, ⟨ph⟩, ⟨rh⟩, and ⟨ch⟩. BecauseEnglish orthographyhas changed so much from the originalGreek, modern scholarly transliteration now usually renders ⟨κ⟩ as ⟨k⟩ and the diphthongs ⟨αι, οι, ει, ου⟩ as ⟨ai, oi, ei, ou⟩. \"Greeklish\" has also spread withinGreeceitself, owing to the rapid spread of digitaltelephonyfrom cultures using theLatin alphabet. Since Greektypefacesandfontsare not always supported or robust,Greekemail and chatting has adopted a variety of formats for rendering Greek and Greek shorthand using Latin letters. Examples include \"8elo\" and \"thelw\" forθέλω, \"3ava\" forξανά, and \"yuxi\" forψυχή. Owing to the difficulties encountered in transliterating and transcribing both ancient and modern Greek into the Latin alphabet, a number of regulatory bodies have been established. TheHellenic Organization for Standardization(ELOT), in cooperation with theInternational Organization for Standardization(ISO), released a system in 1983 which has since been formally adopted by theUnited Nations, the United Kingdom and United States. The following tables list several romanization schemes from the Greek alphabet to modern English. Note, however, that the ELOT, UN, and ISO formats for Modern Greek intend themselves as translingual and may be applied in any language using theLatin alphabet. TheAmerican Library AssociationandLibrary of Congressromanization scheme employs its \"Ancient or Medieval Greek\" system for all works and authors up to theFall of Constantinoplein 1453,althoughByzantine Greekwas pronounced distinctly and some have considered \"Modern\" Greek to have begun as early as the 12th century. For treatment ofpolytonic Greek letters—for example,ᾤ—see also thesection on romanizing Greek diacritical marksbelow.  ELOTapproved in 1982 theELOT 743standard, revised in 2001,whoseType 2(Greek:Τύπος 2,romanized:Typos 2)transcriptionscheme has been adopted by the Greek and Cypriot governments as standard for romanization of names onGreekandCypriot passports. It also comprised aType 1(Greek:Τύπος 1,romanized:Typos 1)transliterationtable, which was extensively modified in the second edition of the standard. International versions of ELOT 743, with an English language standard document, were approved by the UN (V/19, 1987) and the British and American governments.\nThe ISO approved in 1997 its version,ISO 843, with a differentType 1transliteration system, which was adopted four years later by ELOT itself, while the U.N. did not update its version. So thetranscriptionsof Modern Greek into Latin letters used by ELOT, UN and ISO are essentially equivalent, while there remain minor differences in how they approach reversibletransliteration. TheAmerican Library AssociationandLibrary of Congressromanization scheme employs its \"Modern Greek\" system for all works and authors following theFall of Constantinoplein 1453. In the table below, the special rules for vowel combinations (αι, αυ, ει, ευ, ηυ, οι, ου, ωυ) only apply when these letters function asdigraphs. There are also words where the same letters stand side by side incidentally but represent separate vowels. In these cases each of the two letters is transcribed separately according to the normal rules for single letters. Such cases are marked in Greek orthography by either having anaccenton the first rather than the second vowel letter, or by having adiaeresis(¨)over the second letter. For treatment ofaccentsanddiaereses—for example,ϊ—also see thesection on romanizing Greek diacritical marksbelow.  The traditionalpolytonic orthographyof Greek usesseveral distinct diacritical marksto render what was originally thepitch accentof Ancient Greek and the presence or absence of word-initial/h/. In 1982,monotonic orthographywas officially introduced for modern Greek. The only diacritics that remain are theacute accent(indicating stress) and thediaeresis(indicating that two consecutive vowels should not be combined). When a Greekdiphthongis accented, the accent mark is placed over thesecondletter of the pair. This means that an accent over thefirstletter of the pair indicates vowels which should be taken (and romanized) separately. Although the second vowel is not marked with a superfluous diaeresis in Greek, the first-edition ELOT 743 and the UN systems place a diaeresis on the Latin vowel for the sake of clarity. Apart from the diacritical marks native to Greek itself or used to romanize its characters,linguistsalso regularly markvowel lengthwithmacrons(¯) markinglong vowelsand roundedbreves(˘) markingshort vowels. Where these are romanized, it is common to mark the long vowels with macrons over the Latin letters and to leave the short vowels unmarked; such macrons should not be confused or conflated with those used by some systems to marketaandomegaas distinct fromepsilon,iota, andomicron. Greece's earlyAttic numeralswere based on a small sample of letters (includingheta) arranged in multiples of 5 and 10, likely forming the inspiration for the laterEtruscanandRoman numerals. This early system was replaced byGreek numeralswhich employed the entire alphabet, including thenonstandard letters digamma,stigma, or sigma-tau (placed between epsilon and zeta),koppa(placed between pi and rho), andsampi(placed after omega). As revised in 2001, ELOT 743 provides for the uncommon characters to be given (in Greek) as$for stigma,+for koppa, and/for sampi. These symbols are not given lower-case equivalents.When used as numbers, the letters are used in combination with the upperkeraianumeral sign ⟨ʹ⟩ to denote numbers from 1 to 900 and in combination with the lowerkeraia⟨͵⟩ to denote multiples of 1000. (For a full table of the signs and their values, seeGreek numerals.) These values are traditionally romanized asRoman numerals, so thatΑλέξανδρος Γ' ο Μακεδώνwould be translated asAlexander III of Macedonand transliterated asAléxandros III o Makedṓnrather thanAléxandros G'orAléxandros 3.Greeklaws and other official documents ofGreecewhich employ these numerals, however, are to be formally romanized using \"decimal\"Arabic numerals.  Ancient Greek text did not mark word division withspacesorinterpuncts, instead running the words together (scripta continua). In the Hellenistic period, a variety of symbols arose forpunctuationoreditorial marking; such punctuation (or the lack thereof) are variously romanized, inserted, or ignored in different modern editions. ModernGreek punctuationgenerally followsFrenchwith the notable exception of Greek's use of a separatequestion mark, theerotimatiko, which is shaped like theLatinatesemicolon. Greek punctuation which has been given formal romanizations include:  There are manyarchaic forms and local variantsof theGreek alphabet.Beta, for example, might appear as round Β or pointedthroughout Greece but is also found in the forms(atGortyn),and(Thera),(Argos),(Melos),(Corinth),(MegaraandByzantium), and even(Cyclades).Well into the modern period, classical and medieval Greek was also set using a wide array ofligatures, symbols combining or abbreviating various sets of letters, such as those included inClaude Garamond's 16th-centurygrecs du roi. For the most part, such variants—asϖandforπ,ϛforστ, andϗforκαι—are just silently emended to their standard forms and transliterated accordingly. Letters with no equivalent in the classical Greek alphabet such asheta(Ͱ&ͱ), meanwhile, usually take their nearest English equivalent (in this case,h) but are too uncommon to be listed in formal transliteration schemes. Uncommon Greek letters which have been given formal romanizations include: The sounds ofModern Greekhave diverged from both those of Ancient Greek and their descendant letters in English and other languages. This led to a variety of romanizations for names and placenames in the 19th and 20th century. TheHellenic Organization for Standardization(ELOT) issued its system in cooperation with theInternational Organization for Standardization(ISO) in 1983. This system was adopted (with minor modifications) by theUnited Nations' Fifth Conference on the Standardization of Geographical Names atMontrealin 1987,by the United Kingdom'sPermanent Committee on Geographical Names for British Official Use(PCGN) and by the United States'Board on Geographic Names(BGN) in 1996,and by the ISO itself in 1997.Romanization of names for official purposes (as with passports and identity cards) were required to use the ELOT system within Greece until 2011, when a legal decision permitted Greeks to use irregular forms(such as \"Demetrios\" forΔημήτριος) provided that official identification and documents also list the standard forms (as, for example, \"Demetrios OR Dimitrios\").Other romanization systems still encountered are the BGN/PCGN's earlier 1962 systemand the system employed by theAmerican Library Associationand the United States'Library of Congress.", "combined_text": "Romanization of Greek Contents History Tables Ancient Greek Modern Greek Diacritical marks Numerals Punctuation marks Uncommon letters Standardization See also References External links  Romanization of Greekis thetransliteration(letter-mapping) ortranscription(sound-mapping) of text from theGreek alphabetinto theLatin alphabet. The conventions forwritingandromanizingAncient GreekandModern Greekdiffer markedly. The sound of theEnglish letterB(/b/) was written asβin ancient Greek but is now written as thedigraphμπ, while the modernβsounds like the English letterV(/v/) instead. TheGreek nameἸωάννηςbecameJohannesinLatinand thenJohnin English, but in modern Greek has becomeΓιάννης; this might be written asYannis, Jani, Ioannis, Yiannis, or Giannis, but not Giannes or Giannēs as it would be for ancient Greek. The wordΆγιοςmight variously appear as Hagiοs, Agios, Aghios, or Ayios, or simply betranslatedas \"Holy\" or \"Saint\" in English forms ofGreek placenames. Traditional English renderings of Greek names originated fromRomansystems established in antiquity. TheRoman alphabetitself was a form of theCumaean alphabetderived from theEuboean scriptthat valuedΧas/ks/andΗas/h/and used variant forms ofΛandΣthat becameLandS.When this script was used to write the classical Greek alphabet, ⟨κ⟩ was replaced with ⟨c⟩, ⟨αι⟩ and ⟨οι⟩ became ⟨æ⟩ and ⟨œ⟩, and ⟨ει⟩ and ⟨ου⟩ were simplified to ⟨i⟩ (more rarely—corresponding to an earlier pronunciation—⟨e⟩) and ⟨u⟩.Aspirated consonantslike ⟨θ⟩, ⟨φ⟩, initial-⟨ρ⟩, and ⟨χ⟩ simply wrote out the sound: ⟨th⟩, ⟨ph⟩, ⟨rh⟩, and ⟨ch⟩. BecauseEnglish orthographyhas changed so much from the originalGreek, modern scholarly transliteration now usually renders ⟨κ⟩ as ⟨k⟩ and the diphthongs ⟨αι, οι, ει, ου⟩ as ⟨ai, oi, ei, ou⟩. \"Greeklish\" has also spread withinGreeceitself, owing to the rapid spread of digitaltelephonyfrom cultures using theLatin alphabet. Since Greektypefacesandfontsare not always supported or robust,Greekemail and chatting has adopted a variety of formats for rendering Greek and Greek shorthand using Latin letters. Examples include \"8elo\" and \"thelw\" forθέλω, \"3ava\" forξανά, and \"yuxi\" forψυχή. Owing to the difficulties encountered in transliterating and transcribing both ancient and modern Greek into the Latin alphabet, a number of regulatory bodies have been established. TheHellenic Organization for Standardization(ELOT), in cooperation with theInternational Organization for Standardization(ISO), released a system in 1983 which has since been formally adopted by theUnited Nations, the United Kingdom and United States. The following tables list several romanization schemes from the Greek alphabet to modern English. Note, however, that the ELOT, UN, and ISO formats for Modern Greek intend themselves as translingual and may be applied in any language using theLatin alphabet. TheAmerican Library AssociationandLibrary of Congressromanization scheme employs its \"Ancient or Medieval Greek\" system for all works and authors up to theFall of Constantinoplein 1453,althoughByzantine Greekwas pronounced distinctly and some have considered \"Modern\" Greek to have begun as early as the 12th century. For treatment ofpolytonic Greek letters—for example,ᾤ—see also thesection on romanizing Greek diacritical marksbelow.  ELOTapproved in 1982 theELOT 743standard, revised in 2001,whoseType 2(Greek:Τύπος 2,romanized:Typos 2)transcriptionscheme has been adopted by the Greek and Cypriot governments as standard for romanization of names onGreekandCypriot passports. It also comprised aType 1(Greek:Τύπος 1,romanized:Typos 1)transliterationtable, which was extensively modified in the second edition of the standard. International versions of ELOT 743, with an English language standard document, were approved by the UN (V/19, 1987) and the British and American governments.\nThe ISO approved in 1997 its version,ISO 843, with a differentType 1transliteration system, which was adopted four years later by ELOT itself, while the U.N. did not update its version. So thetranscriptionsof Modern Greek into Latin letters used by ELOT, UN and ISO are essentially equivalent, while there remain minor differences in how they approach reversibletransliteration. TheAmerican Library AssociationandLibrary of Congressromanization scheme employs its \"Modern Greek\" system for all works and authors following theFall of Constantinoplein 1453. In the table below, the special rules for vowel combinations (αι, αυ, ει, ευ, ηυ, οι, ου, ωυ) only apply when these letters function asdigraphs. There are also words where the same letters stand side by side incidentally but represent separate vowels. In these cases each of the two letters is transcribed separately according to the normal rules for single letters. Such cases are marked in Greek orthography by either having anaccenton the first rather than the second vowel letter, or by having adiaeresis(¨)over the second letter. For treatment ofaccentsanddiaereses—for example,ϊ—also see thesection on romanizing Greek diacritical marksbelow.  The traditionalpolytonic orthographyof Greek usesseveral distinct diacritical marksto render what was originally thepitch accentof Ancient Greek and the presence or absence of word-initial/h/. In 1982,monotonic orthographywas officially introduced for modern Greek. The only diacritics that remain are theacute accent(indicating stress) and thediaeresis(indicating that two consecutive vowels should not be combined). When a Greekdiphthongis accented, the accent mark is placed over thesecondletter of the pair. This means that an accent over thefirstletter of the pair indicates vowels which should be taken (and romanized) separately. Although the second vowel is not marked with a superfluous diaeresis in Greek, the first-edition ELOT 743 and the UN systems place a diaeresis on the Latin vowel for the sake of clarity. Apart from the diacritical marks native to Greek itself or used to romanize its characters,linguistsalso regularly markvowel lengthwithmacrons(¯) markinglong vowelsand roundedbreves(˘) markingshort vowels. Where these are romanized, it is common to mark the long vowels with macrons over the Latin letters and to leave the short vowels unmarked; such macrons should not be confused or conflated with those used by some systems to marketaandomegaas distinct fromepsilon,iota, andomicron. Greece's earlyAttic numeralswere based on a small sample of letters (includingheta) arranged in multiples of 5 and 10, likely forming the inspiration for the laterEtruscanandRoman numerals. This early system was replaced byGreek numeralswhich employed the entire alphabet, including thenonstandard letters digamma,stigma, or sigma-tau (placed between epsilon and zeta),koppa(placed between pi and rho), andsampi(placed after omega). As revised in 2001, ELOT 743 provides for the uncommon characters to be given (in Greek) as$for stigma,+for koppa, and/for sampi. These symbols are not given lower-case equivalents.When used as numbers, the letters are used in combination with the upperkeraianumeral sign ⟨ʹ⟩ to denote numbers from 1 to 900 and in combination with the lowerkeraia⟨͵⟩ to denote multiples of 1000. (For a full table of the signs and their values, seeGreek numerals.) These values are traditionally romanized asRoman numerals, so thatΑλέξανδρος Γ' ο Μακεδώνwould be translated asAlexander III of Macedonand transliterated asAléxandros III o Makedṓnrather thanAléxandros G'orAléxandros 3.Greeklaws and other official documents ofGreecewhich employ these numerals, however, are to be formally romanized using \"decimal\"Arabic numerals.  Ancient Greek text did not mark word division withspacesorinterpuncts, instead running the words together (scripta continua). In the Hellenistic period, a variety of symbols arose forpunctuationoreditorial marking; such punctuation (or the lack thereof) are variously romanized, inserted, or ignored in different modern editions. ModernGreek punctuationgenerally followsFrenchwith the notable exception of Greek's use of a separatequestion mark, theerotimatiko, which is shaped like theLatinatesemicolon. Greek punctuation which has been given formal romanizations include:  There are manyarchaic forms and local variantsof theGreek alphabet.Beta, for example, might appear as round Β or pointedthroughout Greece but is also found in the forms(atGortyn),and(Thera),(Argos),(Melos),(Corinth),(MegaraandByzantium), and even(Cyclades).Well into the modern period, classical and medieval Greek was also set using a wide array ofligatures, symbols combining or abbreviating various sets of letters, such as those included inClaude Garamond's 16th-centurygrecs du roi. For the most part, such variants—asϖandforπ,ϛforστ, andϗforκαι—are just silently emended to their standard forms and transliterated accordingly. Letters with no equivalent in the classical Greek alphabet such asheta(Ͱ&ͱ), meanwhile, usually take their nearest English equivalent (in this case,h) but are too uncommon to be listed in formal transliteration schemes. Uncommon Greek letters which have been given formal romanizations include: The sounds ofModern Greekhave diverged from both those of Ancient Greek and their descendant letters in English and other languages. This led to a variety of romanizations for names and placenames in the 19th and 20th century. TheHellenic Organization for Standardization(ELOT) issued its system in cooperation with theInternational Organization for Standardization(ISO) in 1983. This system was adopted (with minor modifications) by theUnited Nations' Fifth Conference on the Standardization of Geographical Names atMontrealin 1987,by the United Kingdom'sPermanent Committee on Geographical Names for British Official Use(PCGN) and by the United States'Board on Geographic Names(BGN) in 1996,and by the ISO itself in 1997.Romanization of names for official purposes (as with passports and identity cards) were required to use the ELOT system within Greece until 2011, when a legal decision permitted Greeks to use irregular forms(such as \"Demetrios\" forΔημήτριος) provided that official identification and documents also list the standard forms (as, for example, \"Demetrios OR Dimitrios\").Other romanization systems still encountered are the BGN/PCGN's earlier 1962 systemand the system employed by theAmerican Library Associationand the United States'Library of Congress.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Romanization_of_Greek", "https://en.wikipedia.org/wiki/Romanization_of_Greek", "https://en.wikipedia.org/wiki/Romanization_of_Greek", "https://en.wikipedia.org/wiki/Greek_alphabet", "https://en.wikipedia.org/wiki/Mojibake", "https://en.wikipedia.org/wiki/Transliteration", "https://en.wikipedia.org/wiki/Alphabet", "https://en.wikipedia.org/wiki/Transcription_(linguistics)"]},
{"id": "045d57a62079", "url": "https://en.wikipedia.org/wiki/Philomena", "title": "Philomena", "headings": ["Contents", "Biography", "Discovery of her remains", "Veneration", "Liturgy", "Veneration by other saints", "Places dedicated to Saint Philomena", "Criticism", "References", "Bibliography", "External links"], "content": "Philomena(/ˌfɪləˈmiːnə/FIL-ə-MEE-nə), also known asSaint Philomena(Ancient Greek:Ἁγία Φιλουμένη,romanized:Hagía Philouménē;Modern Greek:Αγία Φιλομένα,romanized:Agía Filoména) orPhilomena of Rome(c.10 January 291 –c.10 August 304) was avirgin martyrwhose remains were discovered on May 24–25, 1802, in theCatacomb of Priscilla. Three tiles enclosing the tomb bore an inscription,Pax Tecum Filumena(i.e. \"Peace be unto you, Philomena\"), that was taken to indicate that her name (in the Latin of the inscription) wasFilumena(Ancient Greek:φιλουμένη,romanized:philouménē,lit.'beloved'), the English form of which isPhilomena. Philomena is the patroness saint of babies, infants, and youth,and is known as \"The Wonderworker\". The remains were moved toMugnano del Cardinalein 1805. There, they became the focus of widespread devotion; severalmiracleswere credited to Philomena'sintercession, including the healing ofPauline Jaricotin 1835, which received wide publicity.John Vianneyattributed to her intercession the extraordinary cures that others attributed to him. From 1837 to 1961, celebration of herfeast daywas approved for regional calendars, but was never included in theGeneral Roman Calendar. The 1920 typical edition of theRoman Missalincluded a mention of her, under 11 August, in the section headedMissae pro aliquibus locis(\"Masses for some places\"), with an indication that theMassto be used in those places was one from thecommonof a virgin martyr, without anyproper.TheCoptic Orthodox Churchcelebrate the feast of Saint Philomena on 10 August of theGregorian calendarwhich is 4 Misra of theCoptic calendar. On December 21  1833, theHoly Officedeclared that there was nothing contrary to the Catholic faith in the revelations that Maria Luisa di Gesù, aDominican tertiaryfromNaples, claimed to have received from Philomena herself. According to Maria Luisa di Gesù, Philomena told her she was the daughter of a king in Greece who, with his wife, had converted to Christianity. At the age of about 13, she took a vow of virginity forChrist'ssake. When the EmperorDiocletianthreatened to make war on her father, her father went with his family to Rome to ask for peace. The Emperor \"fell in love\" with the young Philomena and, when she refused to be his wife, subjected her to a series of torments:scourging, from whose effects two angels cured her; drowning with an anchor attached to her (two angels cut the rope and raised her to the river bank); and being shot with arrows (on the first occasion her wounds were healed; on the second, the arrows turned aside; and on the third, they returned and killed six of the archers, after which several of the others became Christians). Finally, the Emperor had her decapitated. The story goes that the decapitation occurred on a Friday at three in the afternoon, as with the death of Jesus. The two anchors, three arrows, the palm, and the ivy leaf on the tiles found in the tomb were interpreted as symbols of her martyrdom. In the Neapolitan tertiary's account, Philomena also revealed that her birthday was 10 January,that her martyrdom occurred on 10 August (the date also of the arrival of her relics in Mugnano del Cardinale),and that her name \"Filumena\" meant \"daughter of light\" (from Latin \"filia\" and \"lumen;\" however, it is usually taken to be derived from Greek φιλουμένηphilouménē(hence Latin \"u\" for \"ου\") meaning \"beloved.\").Publication of this account gave rise to critical study both of the account itself and of the many archaeological finds, leading to uncertainty that her supposed tomb was in fact that of a martyr. On May 24, 1802, in theCatacombs of Priscillaon the Via Salaria Nova, an inscribedloculus(a space hollowed out of the rock) was found, and on the following day it was carefully examined and opened. Theloculuswas closed with threeterracottatiles on which was the following inscription:lumena paxte cumfi. It was and is generally accepted that the tiles had not been positioned in the sequence of the words and that the inscription originally read, with the leftmost tile placed on the right:pax tecum Filumena(\"Peace with you, Philomena\"). The skeleton of a female between thirteen and fifteen years old was found within theloculus. Embedded in the cement was a small glass vial with vestiges of what was taken to be blood. By the assumptions of the time, the remains were taken to be those of a virgin martyr named Philomena. The belief that such vials were signs of the grave of a martyr was rejected by the investigations ofGiovanni Battista De Rossi(1822–1894),but more recently, this original view has found advocates, such as theologianMark Miravalle. In 1805,CanonFrancesco De Lucia ofMugnano del Cardinalerequested relics for his oratory and, on 8 June, obtained the remains discovered in May 1802 (then reduced to dust and fragments).The relics arrived in Mugnano on August 10, and were placed in the Church of Our Lady of Grace.A new Church of Our Lady of Grace was built, containing a chapel to which the sacred relics were moved on 29 September 1805. In 1827,Pope Leo XIIgave the church in Mugnano del Cardinale the three inscribed terracotta slabs taken from the tomb. In hisRelazione istorica della traslazione del sagro corpo di s. Filomena da Roma a Mugnano del Cardinale, written in 1833,Canon De Lucia recounted that wonders accompanied the arrival of the relics to his church: among them a statue that sweated some liquid continuously for three days.A miracle accepted as proved in the same year was the multiplication of the bone dust of the saint which provided for hundreds ofreliquarieswithout the original amount experiencing any decrease in quantity. Devotion to Philomena includes the wearing of the \"Cord of Philomena\", a red and white cord, which had a number ofindulgencesattached to it, including aplenary indulgenceon the day on which the cord was worn for the first time, indulgences that were not renewed inIndulgentiarum doctrina, the 1967 general revision of the discipline concerning them.There is also thechapletof Saint Philomena, with three white beads in honour of theChristian Trinityand thirteen red beads in honour of the thirteen years of Philomena's life.Asacramentalassociated with devotion to Philomena is theOil of Saint Philomena, used for the putative healing of the body and soul. In August 1876, the first issue ofMessenger of Saint Philomenawas published in Paris, France. On October 6 1876, Louis Petit, a priest, founded theConfraternityof Saint Philomena in Paris. In November 1886, the Confraternity was raised to the rank ofArchconfraternitybyPope Leo XIII. On May 21 1912,Pope Pius Xraised it to the rank of Universal Archconfraternity with theApostolic briefPias Fidelium Societatesstating, regarding the historical authenticity of Philomena, that: \"The current statements (regarding St. Philomena) are and remain always fixed, valid and effective; in this way it has to be judged as normative; and if it is proceeded in another way, it will be null and void, whatever its authority.\" In 1834, due to many supposed miracles,Pope Gregory XVIallowed the veneration of Saint Philomena and, in 1837, authorized the celebration of the feast of Saint Philomena on 11 Augustor, according to another source, 9 September,first in the Diocese ofNola(to which Mugnano del Cardinale belongs), and soon in several other dioceses in Italy. The name \"Philomena\" was not included in theRoman Martyrologyin which venerated persons are included immediately uponbeatificationor canonization.In the 1920 typical edition of theRoman Missal, Philomena is mentioned under 11 August with an indication that theMassfor her feast day was to be taken entirely from thecommon liturgy. On February 14, 1961, theHoly Seeordered that the name of Philomena be removed from all liturgical calendars.This order was given as part of an instruction on the application to local calendars of the principles enunciated in the 1960Code of Rubricsthat had already been applied to theGeneral Roman Calendar. Section 33of this document ordered the removal from local calendars of fourteen named feasts but allowed them to be retained in places with a special link to the feast. It then added: \"However, the feast of Saint Philomena, virgin and martyr (11 August), is to be removed from all calendars.\" Although correlation does not prove causation, the Holy See's instruction to remove the name of Philomena even from local calendars followed the raising of questions by certain scholars, whose interest had been drawn to the phenomenon more especially in connection with the revelations of Sister Maria Luisa di Gesù.The questions were raised in particular byOrazio Marucchi, whose study in the late 19th Century won the support ofJohann Peter Kirsch, an archaeologist and ecclesiastical historian who is the author of the 1911 article on Philomena in theCatholic Encyclopedia.Orazio Marucchihad argued that the inscription on the three tiles that had provided the Latin name \"Filumena\" belonged to the middle or second half of the second century,while the body that had been found was of the fourth century, when the persecutions of Christians had ended.Thus, on his theory, not only the name but also the leaf, the two anchors and the palm that decorated the three tiles, and which had been believed to indicate that Filumena was a martyr, had no relation to the person whose remains were found.The alleged disarrangement of the tiles would be explained by a fourth-century practice of re-using materials already engraved, with the aim of indicating that it was not the same person who was now buried in the place. More recently,Mark Miravallehas argued that Marucchi's conclusions should not be taken as the final word on the historicity of St. Philomena. His book,It Is Time to Meet St. Philomena, cites several specialists who disagree with Marucchi's conclusions.Historian Michael S. Carter (who supports Miravalle's position) has written about devotion to Saint Philomena within the broader context of veneration of \"catacomb martyrs\" and their relics in the history of the United States.Moreover, In April 2005, at theConference of Philomenian Studies – 1805-2005, findings of a study carried out on the tiles by the Opificio delle Pietre Dure e Laboratori di Restauro (Factory of Hard Stones and Restoration Laboratories) of Florence were made public. The analysis confirmed that only one type of mortal lime could be found on the tiles, thus giving strong support to the theory that the tiles had not been re-arranged. Others stress that the authenticity of her cult can be grounded on account of the miracles attributed to her, its long-standing papal approbation, and the saint's continued popularity. This has been the position of the rector of the shrine in Mugnano del Cardinale and the view presented in the Italian-languageEnciclopedia Dei Santi. Pilgrims from all over the world arrive continually at Philomena's shrine in the Diocese of Nola, Italy, displaying an intense degree of popular devotion. The website of \"The National Shrine of Saint Philomena, Miami, Florida\" (associated with theSSPX) sees \"the action taken in 1960 as the work of the devil in order to deprive the people of God of a most powerful Intercessor, particularly in the areas of purity and faith at a time when these virtues were so much being challenged as they continue to be up until now!\"", "combined_text": "Philomena Contents Biography Discovery of her remains Veneration Liturgy Veneration by other saints Places dedicated to Saint Philomena Criticism References Bibliography External links Philomena(/ˌfɪləˈmiːnə/FIL-ə-MEE-nə), also known asSaint Philomena(Ancient Greek:Ἁγία Φιλουμένη,romanized:Hagía Philouménē;Modern Greek:Αγία Φιλομένα,romanized:Agía Filoména) orPhilomena of Rome(c.10 January 291 –c.10 August 304) was avirgin martyrwhose remains were discovered on May 24–25, 1802, in theCatacomb of Priscilla. Three tiles enclosing the tomb bore an inscription,Pax Tecum Filumena(i.e. \"Peace be unto you, Philomena\"), that was taken to indicate that her name (in the Latin of the inscription) wasFilumena(Ancient Greek:φιλουμένη,romanized:philouménē,lit.'beloved'), the English form of which isPhilomena. Philomena is the patroness saint of babies, infants, and youth,and is known as \"The Wonderworker\". The remains were moved toMugnano del Cardinalein 1805. There, they became the focus of widespread devotion; severalmiracleswere credited to Philomena'sintercession, including the healing ofPauline Jaricotin 1835, which received wide publicity.John Vianneyattributed to her intercession the extraordinary cures that others attributed to him. From 1837 to 1961, celebration of herfeast daywas approved for regional calendars, but was never included in theGeneral Roman Calendar. The 1920 typical edition of theRoman Missalincluded a mention of her, under 11 August, in the section headedMissae pro aliquibus locis(\"Masses for some places\"), with an indication that theMassto be used in those places was one from thecommonof a virgin martyr, without anyproper.TheCoptic Orthodox Churchcelebrate the feast of Saint Philomena on 10 August of theGregorian calendarwhich is 4 Misra of theCoptic calendar. On December 21  1833, theHoly Officedeclared that there was nothing contrary to the Catholic faith in the revelations that Maria Luisa di Gesù, aDominican tertiaryfromNaples, claimed to have received from Philomena herself. According to Maria Luisa di Gesù, Philomena told her she was the daughter of a king in Greece who, with his wife, had converted to Christianity. At the age of about 13, she took a vow of virginity forChrist'ssake. When the EmperorDiocletianthreatened to make war on her father, her father went with his family to Rome to ask for peace. The Emperor \"fell in love\" with the young Philomena and, when she refused to be his wife, subjected her to a series of torments:scourging, from whose effects two angels cured her; drowning with an anchor attached to her (two angels cut the rope and raised her to the river bank); and being shot with arrows (on the first occasion her wounds were healed; on the second, the arrows turned aside; and on the third, they returned and killed six of the archers, after which several of the others became Christians). Finally, the Emperor had her decapitated. The story goes that the decapitation occurred on a Friday at three in the afternoon, as with the death of Jesus. The two anchors, three arrows, the palm, and the ivy leaf on the tiles found in the tomb were interpreted as symbols of her martyrdom. In the Neapolitan tertiary's account, Philomena also revealed that her birthday was 10 January,that her martyrdom occurred on 10 August (the date also of the arrival of her relics in Mugnano del Cardinale),and that her name \"Filumena\" meant \"daughter of light\" (from Latin \"filia\" and \"lumen;\" however, it is usually taken to be derived from Greek φιλουμένηphilouménē(hence Latin \"u\" for \"ου\") meaning \"beloved.\").Publication of this account gave rise to critical study both of the account itself and of the many archaeological finds, leading to uncertainty that her supposed tomb was in fact that of a martyr. On May 24, 1802, in theCatacombs of Priscillaon the Via Salaria Nova, an inscribedloculus(a space hollowed out of the rock) was found, and on the following day it was carefully examined and opened. Theloculuswas closed with threeterracottatiles on which was the following inscription:lumena paxte cumfi. It was and is generally accepted that the tiles had not been positioned in the sequence of the words and that the inscription originally read, with the leftmost tile placed on the right:pax tecum Filumena(\"Peace with you, Philomena\"). The skeleton of a female between thirteen and fifteen years old was found within theloculus. Embedded in the cement was a small glass vial with vestiges of what was taken to be blood. By the assumptions of the time, the remains were taken to be those of a virgin martyr named Philomena. The belief that such vials were signs of the grave of a martyr was rejected by the investigations ofGiovanni Battista De Rossi(1822–1894),but more recently, this original view has found advocates, such as theologianMark Miravalle. In 1805,CanonFrancesco De Lucia ofMugnano del Cardinalerequested relics for his oratory and, on 8 June, obtained the remains discovered in May 1802 (then reduced to dust and fragments).The relics arrived in Mugnano on August 10, and were placed in the Church of Our Lady of Grace.A new Church of Our Lady of Grace was built, containing a chapel to which the sacred relics were moved on 29 September 1805. In 1827,Pope Leo XIIgave the church in Mugnano del Cardinale the three inscribed terracotta slabs taken from the tomb. In hisRelazione istorica della traslazione del sagro corpo di s. Filomena da Roma a Mugnano del Cardinale, written in 1833,Canon De Lucia recounted that wonders accompanied the arrival of the relics to his church: among them a statue that sweated some liquid continuously for three days.A miracle accepted as proved in the same year was the multiplication of the bone dust of the saint which provided for hundreds ofreliquarieswithout the original amount experiencing any decrease in quantity. Devotion to Philomena includes the wearing of the \"Cord of Philomena\", a red and white cord, which had a number ofindulgencesattached to it, including aplenary indulgenceon the day on which the cord was worn for the first time, indulgences that were not renewed inIndulgentiarum doctrina, the 1967 general revision of the discipline concerning them.There is also thechapletof Saint Philomena, with three white beads in honour of theChristian Trinityand thirteen red beads in honour of the thirteen years of Philomena's life.Asacramentalassociated with devotion to Philomena is theOil of Saint Philomena, used for the putative healing of the body and soul. In August 1876, the first issue ofMessenger of Saint Philomenawas published in Paris, France. On October 6 1876, Louis Petit, a priest, founded theConfraternityof Saint Philomena in Paris. In November 1886, the Confraternity was raised to the rank ofArchconfraternitybyPope Leo XIII. On May 21 1912,Pope Pius Xraised it to the rank of Universal Archconfraternity with theApostolic briefPias Fidelium Societatesstating, regarding the historical authenticity of Philomena, that: \"The current statements (regarding St. Philomena) are and remain always fixed, valid and effective; in this way it has to be judged as normative; and if it is proceeded in another way, it will be null and void, whatever its authority.\" In 1834, due to many supposed miracles,Pope Gregory XVIallowed the veneration of Saint Philomena and, in 1837, authorized the celebration of the feast of Saint Philomena on 11 Augustor, according to another source, 9 September,first in the Diocese ofNola(to which Mugnano del Cardinale belongs), and soon in several other dioceses in Italy. The name \"Philomena\" was not included in theRoman Martyrologyin which venerated persons are included immediately uponbeatificationor canonization.In the 1920 typical edition of theRoman Missal, Philomena is mentioned under 11 August with an indication that theMassfor her feast day was to be taken entirely from thecommon liturgy. On February 14, 1961, theHoly Seeordered that the name of Philomena be removed from all liturgical calendars.This order was given as part of an instruction on the application to local calendars of the principles enunciated in the 1960Code of Rubricsthat had already been applied to theGeneral Roman Calendar. Section 33of this document ordered the removal from local calendars of fourteen named feasts but allowed them to be retained in places with a special link to the feast. It then added: \"However, the feast of Saint Philomena, virgin and martyr (11 August), is to be removed from all calendars.\" Although correlation does not prove causation, the Holy See's instruction to remove the name of Philomena even from local calendars followed the raising of questions by certain scholars, whose interest had been drawn to the phenomenon more especially in connection with the revelations of Sister Maria Luisa di Gesù.The questions were raised in particular byOrazio Marucchi, whose study in the late 19th Century won the support ofJohann Peter Kirsch, an archaeologist and ecclesiastical historian who is the author of the 1911 article on Philomena in theCatholic Encyclopedia.Orazio Marucchihad argued that the inscription on the three tiles that had provided the Latin name \"Filumena\" belonged to the middle or second half of the second century,while the body that had been found was of the fourth century, when the persecutions of Christians had ended.Thus, on his theory, not only the name but also the leaf, the two anchors and the palm that decorated the three tiles, and which had been believed to indicate that Filumena was a martyr, had no relation to the person whose remains were found.The alleged disarrangement of the tiles would be explained by a fourth-century practice of re-using materials already engraved, with the aim of indicating that it was not the same person who was now buried in the place. More recently,Mark Miravallehas argued that Marucchi's conclusions should not be taken as the final word on the historicity of St. Philomena. His book,It Is Time to Meet St. Philomena, cites several specialists who disagree with Marucchi's conclusions.Historian Michael S. Carter (who supports Miravalle's position) has written about devotion to Saint Philomena within the broader context of veneration of \"catacomb martyrs\" and their relics in the history of the United States.Moreover, In April 2005, at theConference of Philomenian Studies – 1805-2005, findings of a study carried out on the tiles by the Opificio delle Pietre Dure e Laboratori di Restauro (Factory of Hard Stones and Restoration Laboratories) of Florence were made public. The analysis confirmed that only one type of mortal lime could be found on the tiles, thus giving strong support to the theory that the tiles had not been re-arranged. Others stress that the authenticity of her cult can be grounded on account of the miracles attributed to her, its long-standing papal approbation, and the saint's continued popularity. This has been the position of the rector of the shrine in Mugnano del Cardinale and the view presented in the Italian-languageEnciclopedia Dei Santi. Pilgrims from all over the world arrive continually at Philomena's shrine in the Diocese of Nola, Italy, displaying an intense degree of popular devotion. The website of \"The National Shrine of Saint Philomena, Miami, Florida\" (associated with theSSPX) sees \"the action taken in 1960 as the work of the devil in order to deprive the people of God of a most powerful Intercessor, particularly in the areas of purity and faith at a time when these virtues were so much being challenged as they continue to be up until now!\"", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Philomena", "https://en.wikipedia.org/wiki/Philomena", "https://en.wikipedia.org/wiki/Philomena", "https://en.wikipedia.org/wiki/Philomena_(given_name)", "https://en.wikipedia.org/wiki/Philomena_(film)", "https://en.wikipedia.org/wiki/Thin_Lizzy", "https://en.wikipedia.org/wiki/Nightlife_(Thin_Lizzy_album)", "https://en.wikipedia.org/wiki/Saint"]},
{"id": "fae80313fc12", "url": "https://en.wikipedia.org/wiki/Virtuous_pagan", "title": "Virtuous pagan", "headings": ["Contents", "Biblical and theological foundations", "In literature and culture", "See also", "References", "Further reading"], "content": "Virtuous paganis a concept inChristian theologythat addressed thefate of the unlearned—the issue ofnonbelieverswho were neverevangelizedand consequently during their lifetime had no opportunity to recognizeChrist, but nevertheless ledvirtuouslives, so that it seemed objectionable to consider themdamned. Prominent examples of virtuous pagans areHeraclitus,Parmenides,Socrates,Plato,Aristotle,Cicero,Trajan, andVirgil. A Christian doctrinal formulation of this concept, though not universally accepted, is known as the \"Anonymous Christian\" in the theology ofKarl Rahner, which is analogous to teachings of thegerim toshaviminJudaismandHanifsinIslam. In theBible,Paul the Apostleteaches that the conscience of the pagan will be judged even though they cannot possess the law ofGod.Paul writes: For as many as have sinned without law shall also perish without law: and as many as have sinned in the law shall be judged by the law;(For not the hearers of the law are just before God, but the doers of the law shall be justified.For when the Gentiles, which have not the law, do by nature the things contained in the law, these, having not the law, are a law unto themselves:Which shew the work of the law written in their hearts, their conscience also bearing witness, and their thoughts the mean while accusing or else excusing one another;)In the day when God shall judge the secrets of men by Jesus Christ according to my gospel.Romans 2:12–16 CertainChurch Fathers, while encouragingevangelismof nonbelievers, are known to have taken a more broadly inclusive view as to the participation of non-Christians in divine wisdom. In Chapter 46 of hisFirst Apology,Justin Martyrwent so far as to claim alllogos-inspiredpagansas Christians, even those who espousednontheisticphilosophies: We have been taught that Christ is the First-born of God, and we have suggested above that He is the logos of whom every race of men and women were partakers. And they who lived with the logos are Christians, even though they have been thought atheists; as, among the Greeks, Socrates and Heraclitus, and people like them.\" Francis A. Sullivanbelieves that early Christian writers \"did not preclude virtuous pagans from possibly attaining salvation\", but he \"agrees that it is possible that the patristic Fathers, had they been asked directly, may have denied that pagans and Jews could become partakers of eternal life.\" Dante Alighieri, in hisDivine Comedy, places a number of virtuous pagans in the first circle of Hell (analogous toLimbo), includingHomer,Horace,Ovid, andLucan. Intriguingly, theMuslimchampionSaladinis also counted among the ranks of virtuous non-Christians due to his reputation for chivalry, despite the prevalent view among Christians that Muslims wereschismatic adherents of a heretical Christology; whereasMuhammadhimself was consigned to the ninth ditch of theeighth circle of hell, reserved for schismatics. Meanwhile, Dante placed the pagan emperorTrajanin Paradise andCato the Younger, a suicide, withStatiusinPurgatory, while Virgil, whose poetry was thought to prophesy the Christian epoch, he consigned to Limbo. It is clear that these portrayals reflect Dante's impressionistic assessments of each figure's true character rather than the application of doctrinal rigor to their cases. \"Virtuous paganism\" became relevant toRomanticismwith its interest inNorth European mythologyor enthusiasm for the rediscoveredpagan ethosof theIcelandic sagas.Tom Shippeyargues that the fiction ofJ. R. R. Tolkienis significantlybased on such a concept of virtuous paganism: Tolkien was \"rather disturbed by [anArmageddonwhich the wrong side wins (Ragnarök)]: he saw that the ethos it represented could be used by either side, as indeed it was in the deliberate cultivation ofGötterdämmerungby theNazileadership a few years later. Nevertheless it did provide an image of heroic virtue which could exist, and could be admired, outside the Christian framework. In some respects (as you can see in his 1936Beowulflecture, seeEssays, 24–25) the Old Norse 'theory of courage' might even be regarded as ethically superior to the Classical if not to the Christian world-view, in that it demanded commitment to virtue without any offer of lasting reward. ... He also felt that Old Norse mythology provided a model for what one might call 'virtuous paganism,' which was heathen; conscious of its own inadequacy, and so ripe for conversion; but not yet sunk into despair and disillusionment like so much of 20th-century post-Christian literature; a mythology which was in its way light-hearted.\"", "combined_text": "Virtuous pagan Contents Biblical and theological foundations In literature and culture See also References Further reading Virtuous paganis a concept inChristian theologythat addressed thefate of the unlearned—the issue ofnonbelieverswho were neverevangelizedand consequently during their lifetime had no opportunity to recognizeChrist, but nevertheless ledvirtuouslives, so that it seemed objectionable to consider themdamned. Prominent examples of virtuous pagans areHeraclitus,Parmenides,Socrates,Plato,Aristotle,Cicero,Trajan, andVirgil. A Christian doctrinal formulation of this concept, though not universally accepted, is known as the \"Anonymous Christian\" in the theology ofKarl Rahner, which is analogous to teachings of thegerim toshaviminJudaismandHanifsinIslam. In theBible,Paul the Apostleteaches that the conscience of the pagan will be judged even though they cannot possess the law ofGod.Paul writes: For as many as have sinned without law shall also perish without law: and as many as have sinned in the law shall be judged by the law;(For not the hearers of the law are just before God, but the doers of the law shall be justified.For when the Gentiles, which have not the law, do by nature the things contained in the law, these, having not the law, are a law unto themselves:Which shew the work of the law written in their hearts, their conscience also bearing witness, and their thoughts the mean while accusing or else excusing one another;)In the day when God shall judge the secrets of men by Jesus Christ according to my gospel.Romans 2:12–16 CertainChurch Fathers, while encouragingevangelismof nonbelievers, are known to have taken a more broadly inclusive view as to the participation of non-Christians in divine wisdom. In Chapter 46 of hisFirst Apology,Justin Martyrwent so far as to claim alllogos-inspiredpagansas Christians, even those who espousednontheisticphilosophies: We have been taught that Christ is the First-born of God, and we have suggested above that He is the logos of whom every race of men and women were partakers. And they who lived with the logos are Christians, even though they have been thought atheists; as, among the Greeks, Socrates and Heraclitus, and people like them.\" Francis A. Sullivanbelieves that early Christian writers \"did not preclude virtuous pagans from possibly attaining salvation\", but he \"agrees that it is possible that the patristic Fathers, had they been asked directly, may have denied that pagans and Jews could become partakers of eternal life.\" Dante Alighieri, in hisDivine Comedy, places a number of virtuous pagans in the first circle of Hell (analogous toLimbo), includingHomer,Horace,Ovid, andLucan. Intriguingly, theMuslimchampionSaladinis also counted among the ranks of virtuous non-Christians due to his reputation for chivalry, despite the prevalent view among Christians that Muslims wereschismatic adherents of a heretical Christology; whereasMuhammadhimself was consigned to the ninth ditch of theeighth circle of hell, reserved for schismatics. Meanwhile, Dante placed the pagan emperorTrajanin Paradise andCato the Younger, a suicide, withStatiusinPurgatory, while Virgil, whose poetry was thought to prophesy the Christian epoch, he consigned to Limbo. It is clear that these portrayals reflect Dante's impressionistic assessments of each figure's true character rather than the application of doctrinal rigor to their cases. \"Virtuous paganism\" became relevant toRomanticismwith its interest inNorth European mythologyor enthusiasm for the rediscoveredpagan ethosof theIcelandic sagas.Tom Shippeyargues that the fiction ofJ. R. R. Tolkienis significantlybased on such a concept of virtuous paganism: Tolkien was \"rather disturbed by [anArmageddonwhich the wrong side wins (Ragnarök)]: he saw that the ethos it represented could be used by either side, as indeed it was in the deliberate cultivation ofGötterdämmerungby theNazileadership a few years later. Nevertheless it did provide an image of heroic virtue which could exist, and could be admired, outside the Christian framework. In some respects (as you can see in his 1936Beowulflecture, seeEssays, 24–25) the Old Norse 'theory of courage' might even be regarded as ethically superior to the Classical if not to the Christian world-view, in that it demanded commitment to virtue without any offer of lasting reward. ... He also felt that Old Norse mythology provided a model for what one might call 'virtuous paganism,' which was heathen; conscious of its own inadequacy, and so ripe for conversion; but not yet sunk into despair and disillusionment like so much of 20th-century post-Christian literature; a mythology which was in its way light-hearted.\"", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Virtuous_pagan", "https://en.wikipedia.org/wiki/Virtuous_pagan", "https://en.wikipedia.org/wiki/Virtuous_pagan", "https://en.wikipedia.org/wiki/Plato", "https://en.wikipedia.org/wiki/Aristotle", "https://en.wikipedia.org/wiki/The_School_of_Athens", "https://en.wikipedia.org/wiki/Apostolic_Palace", "https://en.wikipedia.org/wiki/Vatican_City"]},
{"id": "e8a21815bb5b", "url": "https://en.wikipedia.org/wiki/Rain-X", "title": "Rain-X", "headings": ["Contents", "Products", "Uses", "Chemistry", "History and ownership", "References", "External links"], "content": "Rain-Xis a synthetichydrophobicsurface-applied product that causes water to bead up and run off surfaces, most commonly used onglass automobilesurfaces. The brand has since been extended to a range of automotive and surface care products, including wiper blades. The Rain-X brand includes seven categories of products:wiper blades, glass and windshield treatments, plastic cleaners, windshield washer fluid, car washes, car wax, and bug and tar washes. Rain-X Online Protectant was introduced to commercial carwashes in 2005.It is a water-based compound that is applied to the entire car's surface, working much like consumer grade Rain-X products. Competing products include Pittsburgh Glass Works' (formerly ofPPG) Aquapel. Rain X wiper blades have the highest market share in North America. Due to its general water-repellent properties, the original Rain-X formulation is used in a wide variety of consumer, commercial and industrial settings. The primary use of Rain-X is for automotive applications. Commercially sold \"Original Glass Treatment\" is the original and most well known Rain-X branded product. It is ahydrophobicsiliconepolymerthat forces water to bead and roll off of the car, often without needing wipers. It is sold in bottles of 3.5 or 7 US fluid ounces (100 or 210 ml), or as wipes or towelettes. The original coating has also had use in military and other government settings. The Australian military examined the effect of application of Rain-X and similar products to submarine antennas to improve signal transmission, although other coatings had longer lifespans when submerged in salt water. It is also occasionally used inlaboratorysettings tosilanisea surface. Ski and snowboard enthusiasts use Rain-X as \"wax\" to effectively overcome sticky wet snow common in spring conditions. While skiing or riding on mountains with hard snow pack, the heat of the sun changes snow conditions starting on the lower slopes. Skis may suddenly slow down, throwing one off-balance, because of a change in surface tension, a sort of \"sandpaper effect.\"  Rain-X is applied to the ski or board base, or to the bottoms of ski boots to reduce, or eliminate snow \"wedges\" that interfere with proper mounting into ski bindings. Rain-X's primary active ingredient arepolysiloxanes, the primary one beinghydroxy-terminatedpolydimethylsiloxane.The polysiloxanes have functional groups that bind to the hydroxyl group of the glass surface.Rain-X submitted safety documents which state that the solvent used is a mix ofacetoneand water, but the exact ratio is a trade secret. Rain-X was introduced in 1972 by Howard G. Ohlhausen of theUnelko Corporation.The product was originally registered as a trademark in 1972 by Unelko, and was sold toQuaker Statein 1997. Between 1997 and 2011, Rain-X was marketed bySOPUS Products, a subsidiary of Pennzoil-Quaker State,itself a subsidiary ofRoyal Dutch Shell. On 1 March 2011,Illinois Tool Worksacquired SOPUS's car care business. In the UK, prior to 2010, Rain-X branded products were distributed by the SOPUS subsidiary Auto Expressions. On 9 June 2010,Kraco Enterprisesacquired the company. Industrial Rain-X products were produced byEcolaband used incarwashesand other industrial applications.Ecolab sold its vehicle care business toZep, Inc.on 1 December 2012.The sale also included the Armor All Professional, Black Magic, Blue Coral, Niagara National, Washtronics, and Zep Enviroedge brands. Rain-X (retail products) was purchased by Illinois Tool Works, from Shell Oil Company, on 3/1/2011.  Today, Rain-X is part of ITW Global Brands division. ", "combined_text": "Rain-X Contents Products Uses Chemistry History and ownership References External links Rain-Xis a synthetichydrophobicsurface-applied product that causes water to bead up and run off surfaces, most commonly used onglass automobilesurfaces. The brand has since been extended to a range of automotive and surface care products, including wiper blades. The Rain-X brand includes seven categories of products:wiper blades, glass and windshield treatments, plastic cleaners, windshield washer fluid, car washes, car wax, and bug and tar washes. Rain-X Online Protectant was introduced to commercial carwashes in 2005.It is a water-based compound that is applied to the entire car's surface, working much like consumer grade Rain-X products. Competing products include Pittsburgh Glass Works' (formerly ofPPG) Aquapel. Rain X wiper blades have the highest market share in North America. Due to its general water-repellent properties, the original Rain-X formulation is used in a wide variety of consumer, commercial and industrial settings. The primary use of Rain-X is for automotive applications. Commercially sold \"Original Glass Treatment\" is the original and most well known Rain-X branded product. It is ahydrophobicsiliconepolymerthat forces water to bead and roll off of the car, often without needing wipers. It is sold in bottles of 3.5 or 7 US fluid ounces (100 or 210 ml), or as wipes or towelettes. The original coating has also had use in military and other government settings. The Australian military examined the effect of application of Rain-X and similar products to submarine antennas to improve signal transmission, although other coatings had longer lifespans when submerged in salt water. It is also occasionally used inlaboratorysettings tosilanisea surface. Ski and snowboard enthusiasts use Rain-X as \"wax\" to effectively overcome sticky wet snow common in spring conditions. While skiing or riding on mountains with hard snow pack, the heat of the sun changes snow conditions starting on the lower slopes. Skis may suddenly slow down, throwing one off-balance, because of a change in surface tension, a sort of \"sandpaper effect.\"  Rain-X is applied to the ski or board base, or to the bottoms of ski boots to reduce, or eliminate snow \"wedges\" that interfere with proper mounting into ski bindings. Rain-X's primary active ingredient arepolysiloxanes, the primary one beinghydroxy-terminatedpolydimethylsiloxane.The polysiloxanes have functional groups that bind to the hydroxyl group of the glass surface.Rain-X submitted safety documents which state that the solvent used is a mix ofacetoneand water, but the exact ratio is a trade secret. Rain-X was introduced in 1972 by Howard G. Ohlhausen of theUnelko Corporation.The product was originally registered as a trademark in 1972 by Unelko, and was sold toQuaker Statein 1997. Between 1997 and 2011, Rain-X was marketed bySOPUS Products, a subsidiary of Pennzoil-Quaker State,itself a subsidiary ofRoyal Dutch Shell. On 1 March 2011,Illinois Tool Worksacquired SOPUS's car care business. In the UK, prior to 2010, Rain-X branded products were distributed by the SOPUS subsidiary Auto Expressions. On 9 June 2010,Kraco Enterprisesacquired the company. Industrial Rain-X products were produced byEcolaband used incarwashesand other industrial applications.Ecolab sold its vehicle care business toZep, Inc.on 1 December 2012.The sale also included the Armor All Professional, Black Magic, Blue Coral, Niagara National, Washtronics, and Zep Enviroedge brands. Rain-X (retail products) was purchased by Illinois Tool Works, from Shell Oil Company, on 3/1/2011.  Today, Rain-X is part of ITW Global Brands division.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Rain-X", "https://en.wikipedia.org/wiki/Rain-X", "https://en.wikipedia.org/wiki/Rain-X", "https://en.wikipedia.org/wiki/Illinois_Tool_Works", "https://en.wikipedia.org/wiki/SOPUS_Products", "https://en.wikipedia.org/wiki/Hydrophobic", "https://en.wikipedia.org/wiki/Windshield", "https://en.wikipedia.org/wiki/Windshield_wiper"]},
{"id": "7074a9046b78", "url": "https://en.wikipedia.org/wiki/Government_House_(New_York_City)", "title": "Government House (New York City)", "headings": ["Contents", "Background", "History", "Legacy", "See also", "References", "Bibliography", "Further reading"], "content": " TheGovernment Housewas aGeorgian-stylemansion at the foot ofBroadway, south ofBowling Green, on the site previously occupied byFort GeorgeinManhattan,New York City. Built in 1790 by thestate of New York, it was intended to be theexecutive mansionforPresident George Washington, but he never occupied it. Before it was completed, the federal government moved temporarily toPhiladelphia; then permanently toWashington, D.C.It then became the state governor’s residence and was used byGeorge ClintonandJohn Jay. Later it was leased to John Avery and was known as the Elysian Boarding House. After the passage of the Customs Administration Act in 1799, it was converted into theCustom House in New York. Parts of the building were later leased to the American Academy of Arts, who then offered space to theNew-York Historical Societyin 1809. In 1813, the property was sold to the city. In 1815, the land was sold to the public and the building demolished. AfterEvacuation Day, November 25, 1783, the site ofFort Georgewas viewed as the \"social center of New York\", prime real estate for grand residences. From March 4, 1789, to December 5, 1790, thefederal capitalof the United States was in New York, atFederal Hall. President Washington first occupied theSamuel Osgood House– April 23, 1789, to February 23, 1790 – then theAlexander Macomb House– February 23 to August 30, 1790 – both private houses. On July 13, 1789, the New York State legislature passed a resolution that the site of Fort George should be used to build a \"proper House ... for the residence and accommodation of the President of the United States.\" On March 16, 1790, the New York state legislature authorized the demolition ofFort Georgeand the building of a government house for the \"temporary use and accommodation of the President of the United States of America, during such time as the Congress of the United States shall hold their sessions in the city of New York.\"On March 24, proposals for the building were requested. The architect,John McComb, Jr., submitted plans, but apparently they were not used, since they do not match the house as built. James Robinson became the architect and designed aGeorgian-stylemansion.During the coming months, the fort defensive walls and enclosed buildings were taken down. Some stones were even reused to build the new government house.The cornerstone of this new building was laid on May 21, 1790.However, before the building was completed, Congress passed theResidence Actof July 16, 1790, which namedPhiladelphiaas the temporary national capital for a 10-year period while the permanent national capital was under construction at what is nowWashington, D.C.Thus, President Washington never resided in this public building, intended to be his executive mansion. The Government House was described in 1791 by Rev. Garret Abeel as an \"elegant two-story brick building of an oblong square form ... In front is an elegant pediment, supported by four large pillars ... all the rooms in the house command a most extensive and delightful prospect, some into theEast River, some quite tothe Narrows; others up theNorth River.\" While the building was never used by the President, it did serve as the state governors' house. In 1791, Governor George Clinton moved into the building.Governor John Jay lived in the residence from 1795 to 1797.He was the last governor to live here, sinceAlbanybecame the state capital in 1797. In May 1798, the state leased the building to John Avery.He then opened it as the Elysian Boarding and Lodging House.The Elysian has also been called a tavern.John Avery left two weeks after the building became the Custom House. Alexander Hamiltoninspired the Customs Administration Act, passed by Congress on March 2, 1799, “An act to regulate the collection of duties on imports and tonnage.”On May 1, 1799, the building was converted for use as theCustom House in New York.The Custom House had previously been atS. William Street, opposite Mill Lane, known as 5 Mill Street.Government House was the Custom House until 1815. The following year, the Custom House occupied a store at the site of thesecond City HallonWall Street. On April 11, 1808, the upper room of the building was reserved for the American Academy of Arts.The academy was previously known as theNew York Academy of Fine Arts.In 1809, the academy invited theNew-York Historical Societyto use one room on the second floor for its collection. On May 26, 1812, the state legislature authorized the sale of the building and grounds to the city \"for the erection of private buildings or other individual purposes.\"The purchase was completed on August 2, 1813. On May 1, 1815, the city started the process to sell the property to the public. Seven lots facingBowling Greenwere sold at auction on May 25.By June 1, the demolition of the building and clearing of the adjacent lots was underway. Between 1815 and the construction of theAlexander Hamilton U.S. Custom House, the site of Government House contained rowhouse residences and a dead-end alley named Whitney Street, named for a property owner on it. On September 29, 1890, theHolland Society of New Yorkinstalled a commemorative tablet at 4 Bowling Green. It described that the Government House was built on the site of Fort Amsterdam, built in 1626. The site is now occupied by theAlexander Hamilton U.S. Custom House, built between 1902 and 1907. The historic Holland Society tablet was moved inside this new building.", "combined_text": "Government House (New York City) Contents Background History Legacy See also References Bibliography Further reading  TheGovernment Housewas aGeorgian-stylemansion at the foot ofBroadway, south ofBowling Green, on the site previously occupied byFort GeorgeinManhattan,New York City. Built in 1790 by thestate of New York, it was intended to be theexecutive mansionforPresident George Washington, but he never occupied it. Before it was completed, the federal government moved temporarily toPhiladelphia; then permanently toWashington, D.C.It then became the state governor’s residence and was used byGeorge ClintonandJohn Jay. Later it was leased to John Avery and was known as the Elysian Boarding House. After the passage of the Customs Administration Act in 1799, it was converted into theCustom House in New York. Parts of the building were later leased to the American Academy of Arts, who then offered space to theNew-York Historical Societyin 1809. In 1813, the property was sold to the city. In 1815, the land was sold to the public and the building demolished. AfterEvacuation Day, November 25, 1783, the site ofFort Georgewas viewed as the \"social center of New York\", prime real estate for grand residences. From March 4, 1789, to December 5, 1790, thefederal capitalof the United States was in New York, atFederal Hall. President Washington first occupied theSamuel Osgood House– April 23, 1789, to February 23, 1790 – then theAlexander Macomb House– February 23 to August 30, 1790 – both private houses. On July 13, 1789, the New York State legislature passed a resolution that the site of Fort George should be used to build a \"proper House ... for the residence and accommodation of the President of the United States.\" On March 16, 1790, the New York state legislature authorized the demolition ofFort Georgeand the building of a government house for the \"temporary use and accommodation of the President of the United States of America, during such time as the Congress of the United States shall hold their sessions in the city of New York.\"On March 24, proposals for the building were requested. The architect,John McComb, Jr., submitted plans, but apparently they were not used, since they do not match the house as built. James Robinson became the architect and designed aGeorgian-stylemansion.During the coming months, the fort defensive walls and enclosed buildings were taken down. Some stones were even reused to build the new government house.The cornerstone of this new building was laid on May 21, 1790.However, before the building was completed, Congress passed theResidence Actof July 16, 1790, which namedPhiladelphiaas the temporary national capital for a 10-year period while the permanent national capital was under construction at what is nowWashington, D.C.Thus, President Washington never resided in this public building, intended to be his executive mansion. The Government House was described in 1791 by Rev. Garret Abeel as an \"elegant two-story brick building of an oblong square form ... In front is an elegant pediment, supported by four large pillars ... all the rooms in the house command a most extensive and delightful prospect, some into theEast River, some quite tothe Narrows; others up theNorth River.\" While the building was never used by the President, it did serve as the state governors' house. In 1791, Governor George Clinton moved into the building.Governor John Jay lived in the residence from 1795 to 1797.He was the last governor to live here, sinceAlbanybecame the state capital in 1797. In May 1798, the state leased the building to John Avery.He then opened it as the Elysian Boarding and Lodging House.The Elysian has also been called a tavern.John Avery left two weeks after the building became the Custom House. Alexander Hamiltoninspired the Customs Administration Act, passed by Congress on March 2, 1799, “An act to regulate the collection of duties on imports and tonnage.”On May 1, 1799, the building was converted for use as theCustom House in New York.The Custom House had previously been atS. William Street, opposite Mill Lane, known as 5 Mill Street.Government House was the Custom House until 1815. The following year, the Custom House occupied a store at the site of thesecond City HallonWall Street. On April 11, 1808, the upper room of the building was reserved for the American Academy of Arts.The academy was previously known as theNew York Academy of Fine Arts.In 1809, the academy invited theNew-York Historical Societyto use one room on the second floor for its collection. On May 26, 1812, the state legislature authorized the sale of the building and grounds to the city \"for the erection of private buildings or other individual purposes.\"The purchase was completed on August 2, 1813. On May 1, 1815, the city started the process to sell the property to the public. Seven lots facingBowling Greenwere sold at auction on May 25.By June 1, the demolition of the building and clearing of the adjacent lots was underway. Between 1815 and the construction of theAlexander Hamilton U.S. Custom House, the site of Government House contained rowhouse residences and a dead-end alley named Whitney Street, named for a property owner on it. On September 29, 1890, theHolland Society of New Yorkinstalled a commemorative tablet at 4 Bowling Green. It described that the Government House was built on the site of Fort Amsterdam, built in 1626. The site is now occupied by theAlexander Hamilton U.S. Custom House, built between 1902 and 1907. The historic Holland Society tablet was moved inside this new building.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Government_House_(New_York_City)", "https://en.wikipedia.org/wiki/Government_House_(New_York_City)", "https://en.wikipedia.org/wiki/Government_House_(New_York_City)", "https://en.wikipedia.org/wiki/Geographic_coordinate_system", "https://en.wikipedia.org/wiki/Georgian_architecture", "https://en.wikipedia.org/wiki/Bowling_Green_(New_York_City)", "https://en.wikipedia.org/wiki/Fort_Amsterdam", "https://en.wikipedia.org/wiki/New_York,_New_York"]},
{"id": "5f34ffa4b8ee", "url": "https://en.wikipedia.org/wiki/World_Petroleum_Council", "title": "WPC Energy", "headings": ["Contents", "WPC Energy Congress", "Awards", "The Dewhurst Award", "References"], "content": "WPC Energyis a non-advocacy, non-political organisation with charitable status in the U.K. and has accreditation as a Non-Governmental Organization (NGO) from theUnited Nations. WPC Energy facilitates an open dialogue around oil, gas, energy and their products and is dedicated to the promotion of their sustainable management for the benefit of all. Until 2023, the organisation was known as the World Petroleum Council. The organisation's premier event is called the WPC Energy Congress. Starting in 1933, the congress was held every four years until 1991, with a 14-year hiatus in between 1937 and 1951 because ofWorld War II. After 1991, it was held every three years until the year 2000. There was a move to have it hosted every two years after the 2000 edition, withRio de Janeirohosting one in 2002, but the cycle returned to every three years after that. In order to host a congress, there is a bidding process by interested cities for one in a particular year.  Note: Due to the onset ofCOVID-19, the 23rd World Petroleum Congress was moved from 2020 to 2021. This award is named forInstitute of PetroleumPresident Thomas Dewhurst (1881-1973), who organized the first Congress in 1933, and is awarded to individuals who have shown \"excellence in the petroleum industry.\"  This article related to natural gas, petroleum or the petroleum industry is astub. You can help Wikipedia byexpanding it. This article about aninternational organizationis astub. You can help Wikipedia byexpanding it.", "combined_text": "WPC Energy Contents WPC Energy Congress Awards The Dewhurst Award References WPC Energyis a non-advocacy, non-political organisation with charitable status in the U.K. and has accreditation as a Non-Governmental Organization (NGO) from theUnited Nations. WPC Energy facilitates an open dialogue around oil, gas, energy and their products and is dedicated to the promotion of their sustainable management for the benefit of all. Until 2023, the organisation was known as the World Petroleum Council. The organisation's premier event is called the WPC Energy Congress. Starting in 1933, the congress was held every four years until 1991, with a 14-year hiatus in between 1937 and 1951 because ofWorld War II. After 1991, it was held every three years until the year 2000. There was a move to have it hosted every two years after the 2000 edition, withRio de Janeirohosting one in 2002, but the cycle returned to every three years after that. In order to host a congress, there is a bidding process by interested cities for one in a particular year.  Note: Due to the onset ofCOVID-19, the 23rd World Petroleum Congress was moved from 2020 to 2021. This award is named forInstitute of PetroleumPresident Thomas Dewhurst (1881-1973), who organized the first Congress in 1933, and is awarded to individuals who have shown \"excellence in the petroleum industry.\"  This article related to natural gas, petroleum or the petroleum industry is astub. You can help Wikipedia byexpanding it. This article about aninternational organizationis astub. You can help Wikipedia byexpanding it.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/WPC_Energy", "https://en.wikipedia.org/wiki/WPC_Energy", "https://en.wikipedia.org/wiki/WPC_Energy", "https://en.wikipedia.org/wiki/United_Nations", "https://en.wikipedia.org/wiki/World_War_II", "https://en.wikipedia.org/wiki/Rio_de_Janeiro", "https://en.wikipedia.org/wiki/London", "https://en.wikipedia.org/wiki/United_Kingdom"]},
{"id": "05db0af60b40", "url": "https://en.wikipedia.org/wiki/Dynamic_Forces", "title": "Dynamite Entertainment", "headings": ["Contents", "History", "List of Dynamite Entertainment titles", "#", "A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L", "M", "N", "O", "P", "Q", "R", "S", "T", "U", "V", "W", "X", "Y", "Z", "References", "General references", "Inline citations", "External links"], "content": " Dynamite Entertainmentis anAmerican comic bookpublisher founded in 2004 by Nick BarrucciinMount Laurel, New Jersey, known for publishingcomic book adaptationsof licensed feature film properties, such asArmy of Darkness,Terminator, andRoboCop; licensed orpublic domainliterary properties such asZorro,Dracula,Sherlock Holmes,Alice in Wonderland,Red Sonja,Tarzan, andJohn Carter of Mars;and superhero books includingProject Superpowers, which revived classic public domain characters,and originalcreator-owned comicslikeThe Boys. Creators who have produced Dynamite's books includeAlex Ross,John Cassaday,Matt Wagner,Garth Ennis,Howard ChaykinandFrank Miller.Dynamic Forces, a distribution of Dynamite's comics and books, announced a partnership with Diamond Distribution in 2008, when Diamond had the rights to publishing the international versions of books made by Dynamite Entertainment.Dynamite would later leave Diamond after the Diamond bankruptcy and go to Lunar Distribution.Dynamite would also sign a deal with Simon & Schuster which distribution their graphic novels and other items to wider market. Dynamite Entertainment was founded by Nick Barrucci in 2004, initially publishing one comic:Army of Darkness,a miniseries it published throughDevil's Due Publishinguntil it began self-publishing its own titles later that year. After devoting itself to publishing onlyArmy of Darkness, which included a second miniseries, Dynamite publishedRed Sonja, starting with a 25-cent issue #0. It sold 240,000 copies. Issue #1 ofRed Sonja, the first to sell at the full cover price of $2.99, sold 100,000 in initial orders, securing a stable position in the American comic book industry.By 2009, Dynamite was publishing 14–20 comic books and 2–10 collections per month. Dynamite focuses primarily oncomic book adaptationsof licensed properties, such asSherlock Holmes,The Lone Ranger, andRed Sonja. The company also publishes original titles likeProject Superpowers, andcreator-owned comicslikeThe Boys. Among its adaptations are those based on classic literature such asAlice in Wonderland,Dracula,andZorro;television seriessuch asXena: Warrior PrincessBattlestar Galactica,andBuck Rogers,and films such asDarkman,The Good, the Bad and the Ugly,RoboCop,Highlander,and theTerminatorfranchise. Its film adaptations also include those of classic monsters such asDracula,Dr. Jekyll & Mr. Hyde,Frankenstein's Monster, andthe Wolfman. The company gradually built itsgraphic novelprogram with titles likeHoward Chaykin'sAmerican Flagg!, reprints ofMarvel Comics'Red Sonjaseries, and material by creators likeJim StarlinandJae Lee. In addition to publishingcrossover storylinesin which characters from these various properties meet, such asTerminator/RoboCop,andVampirella/Dracula: Unholy!,Dynamite has also producedintercompany crossoverbooks with other publishers. One, titled \"Monster War\", was released throughImage Comicsin 2005, and consisted of several titles that pitted the classic monsters againstTop Cowpublished charactersWitchblade,the Darkness,Magdalena, andTomb Raider.The other was a 2006 crossover with DC Comics'Red Sonja/Claw The Unconquered: Devil's Hands. In February 2007, Dynamite Entertainment acquired the publishing rights toGarth Ennis' creator-owned seriesThe Boysafter the book was cancelled six months into its run byDC Comics'WildStormimprint. In 2009 Dynamite announced it would publish new comics featuringLee Falk'sThe Phantom. In 2010, Dynamite began publishing comic books based onThe Green Hornet, beginning with a miniseries written byKevin Smithand followed byGreen Hornet: Year One, which was written byMatt Wagner, and another written by Brett Matthews. In May 2010, Dynamite Entertainment acquiredChaos! Comics' library, which included almost all of that publisher's associated assets, with the exception ofLady Death. Among these properties were the publishing labels Black Label Graphics, Infinity Comics, and the propertiesEvil Ernie, Smiley The Psychotic Button,Chastity,Purgatori, Jade, Omen,Bad Kitty, Cremator, Lady Demon. In October 2013, Dynamite announced it would launch a line of comics based on titles originally published byGold Key Comics, the first of which would beMagnus: Robot Fighter,The Occult Files of Doctor Spektor,Solar: Man of the Atom, andTurok. In July 2016, authorAndy Mangelsstated in aNew York Timesinterview that he was writing a newintercompany crossovermini-series for the company, in conjunction with DC Comics,Wonder Woman '77 Meets the Bionic Woman, which brought together theLynda Carter television versionof the Amazon superhero withJaime Sommers, the cyborg super-heroine played byLindsay Wagnerin the 1970s TV series,The Bionic Woman.The series was released that December. In July 2019,Sony Pictures TelevisionandAmazon Studiospremieredan adapted television seriesofThe BoysforAmazon Prime Videoafter a brand licensing agreement was granted by Dynamite. In 2022, Dynamite announced a deal with Disney to create a new line of comics based on various properties, includingGargoyles(TV series)with spin-offs including a Halloween Special, Dark Ages mini series, and Quest mini series, andDarkwing Duckwith spin-offs including Negaduck and Justice Ducks, as well as Disney Villains characters includingMaleficent,Scar,HadesandCruella De Vil. They also have the first comic book series onLilo & Stitchand will be the first American publisher ofThe Nightmare Before Christmascomics In October 2023, Dynamite announced a deal with Warner Bros. Discovery to create a new line of comics based on various properties, includingThundercats,Space Ghost,Jonny Quest,The Powerpuff Girls,The Wizard of Oz,The Flintstones,andWe Bare Bears. Thundercats#1 sold over 170,000 copies.", "combined_text": "Dynamite Entertainment Contents History List of Dynamite Entertainment titles # A B C D E F G H I J K L M N O P Q R S T U V W X Y Z References General references Inline citations External links  Dynamite Entertainmentis anAmerican comic bookpublisher founded in 2004 by Nick BarrucciinMount Laurel, New Jersey, known for publishingcomic book adaptationsof licensed feature film properties, such asArmy of Darkness,Terminator, andRoboCop; licensed orpublic domainliterary properties such asZorro,Dracula,Sherlock Holmes,Alice in Wonderland,Red Sonja,Tarzan, andJohn Carter of Mars;and superhero books includingProject Superpowers, which revived classic public domain characters,and originalcreator-owned comicslikeThe Boys. Creators who have produced Dynamite's books includeAlex Ross,John Cassaday,Matt Wagner,Garth Ennis,Howard ChaykinandFrank Miller.Dynamic Forces, a distribution of Dynamite's comics and books, announced a partnership with Diamond Distribution in 2008, when Diamond had the rights to publishing the international versions of books made by Dynamite Entertainment.Dynamite would later leave Diamond after the Diamond bankruptcy and go to Lunar Distribution.Dynamite would also sign a deal with Simon & Schuster which distribution their graphic novels and other items to wider market. Dynamite Entertainment was founded by Nick Barrucci in 2004, initially publishing one comic:Army of Darkness,a miniseries it published throughDevil's Due Publishinguntil it began self-publishing its own titles later that year. After devoting itself to publishing onlyArmy of Darkness, which included a second miniseries, Dynamite publishedRed Sonja, starting with a 25-cent issue #0. It sold 240,000 copies. Issue #1 ofRed Sonja, the first to sell at the full cover price of $2.99, sold 100,000 in initial orders, securing a stable position in the American comic book industry.By 2009, Dynamite was publishing 14–20 comic books and 2–10 collections per month. Dynamite focuses primarily oncomic book adaptationsof licensed properties, such asSherlock Holmes,The Lone Ranger, andRed Sonja. The company also publishes original titles likeProject Superpowers, andcreator-owned comicslikeThe Boys. Among its adaptations are those based on classic literature such asAlice in Wonderland,Dracula,andZorro;television seriessuch asXena: Warrior PrincessBattlestar Galactica,andBuck Rogers,and films such asDarkman,The Good, the Bad and the Ugly,RoboCop,Highlander,and theTerminatorfranchise. Its film adaptations also include those of classic monsters such asDracula,Dr. Jekyll & Mr. Hyde,Frankenstein's Monster, andthe Wolfman. The company gradually built itsgraphic novelprogram with titles likeHoward Chaykin'sAmerican Flagg!, reprints ofMarvel Comics'Red Sonjaseries, and material by creators likeJim StarlinandJae Lee. In addition to publishingcrossover storylinesin which characters from these various properties meet, such asTerminator/RoboCop,andVampirella/Dracula: Unholy!,Dynamite has also producedintercompany crossoverbooks with other publishers. One, titled \"Monster War\", was released throughImage Comicsin 2005, and consisted of several titles that pitted the classic monsters againstTop Cowpublished charactersWitchblade,the Darkness,Magdalena, andTomb Raider.The other was a 2006 crossover with DC Comics'Red Sonja/Claw The Unconquered: Devil's Hands. In February 2007, Dynamite Entertainment acquired the publishing rights toGarth Ennis' creator-owned seriesThe Boysafter the book was cancelled six months into its run byDC Comics'WildStormimprint. In 2009 Dynamite announced it would publish new comics featuringLee Falk'sThe Phantom. In 2010, Dynamite began publishing comic books based onThe Green Hornet, beginning with a miniseries written byKevin Smithand followed byGreen Hornet: Year One, which was written byMatt Wagner, and another written by Brett Matthews. In May 2010, Dynamite Entertainment acquiredChaos! Comics' library, which included almost all of that publisher's associated assets, with the exception ofLady Death. Among these properties were the publishing labels Black Label Graphics, Infinity Comics, and the propertiesEvil Ernie, Smiley The Psychotic Button,Chastity,Purgatori, Jade, Omen,Bad Kitty, Cremator, Lady Demon. In October 2013, Dynamite announced it would launch a line of comics based on titles originally published byGold Key Comics, the first of which would beMagnus: Robot Fighter,The Occult Files of Doctor Spektor,Solar: Man of the Atom, andTurok. In July 2016, authorAndy Mangelsstated in aNew York Timesinterview that he was writing a newintercompany crossovermini-series for the company, in conjunction with DC Comics,Wonder Woman '77 Meets the Bionic Woman, which brought together theLynda Carter television versionof the Amazon superhero withJaime Sommers, the cyborg super-heroine played byLindsay Wagnerin the 1970s TV series,The Bionic Woman.The series was released that December. In July 2019,Sony Pictures TelevisionandAmazon Studiospremieredan adapted television seriesofThe BoysforAmazon Prime Videoafter a brand licensing agreement was granted by Dynamite. In 2022, Dynamite announced a deal with Disney to create a new line of comics based on various properties, includingGargoyles(TV series)with spin-offs including a Halloween Special, Dark Ages mini series, and Quest mini series, andDarkwing Duckwith spin-offs including Negaduck and Justice Ducks, as well as Disney Villains characters includingMaleficent,Scar,HadesandCruella De Vil. They also have the first comic book series onLilo & Stitchand will be the first American publisher ofThe Nightmare Before Christmascomics In October 2023, Dynamite announced a deal with Warner Bros. Discovery to create a new line of comics based on various properties, includingThundercats,Space Ghost,Jonny Quest,The Powerpuff Girls,The Wizard of Oz,The Flintstones,andWe Bare Bears. Thundercats#1 sold over 170,000 copies.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Dynamite_Entertainment", "https://en.wikipedia.org/wiki/Dynamite_Entertainment", "https://en.wikipedia.org/wiki/Dynamite_Entertainment", "https://en.wikipedia.org/wiki/Mount_Laurel,_New_Jersey", "https://en.wikipedia.org/wiki/Diamond_Book_Distributors", "https://en.wikipedia.org/wiki/Chief_executive_officer", "https://en.wikipedia.org/wiki/President_(corporate_title)", "https://en.wikipedia.org/wiki/Chief_operating_officer"]},
{"id": "fca14ac87307", "url": "https://en.wikipedia.org/wiki/Short_Circuit_(TV_series)", "title": "Short Circuit(TV series)", "headings": ["Contents", "Production", "Episodes", "Season 1 (2020)", "Season 2 (2021–22)", "Unaired shorts", "Release", "Reception", "Critical response", "Notes", "References"], "content": " Short Circuitis a series of Americanindependentanimatedshort filmsproduced byWalt Disney Animation Studios.Similar to theSparkShortsprogram launched at sister animation studioPixar, the series is a program in which the employees pitch their ideas for a short and work with fellow employees to create the short if selected, and is meant to take risks in both visual styles and storytelling. The shorts were released exclusively onDisney+on January 24, 2020.A second cycle of animated shorts premiered on August 4, 2021. Development on theShort Circuitprogram began in 2016.Similar to sister animation studioPixar'sSparkShorts,Walt Disney Animation Studioslaunched a program namedShort Circuit, consisting of a series of shorts of an experimental nature where any employee working at the studio can pitch an idea and can make a short if selected. In a statement, Disney said that \"[t]he goal of this innovative program is to take risks in both visual style and story, surface new voices at the studio, and experiment with new technical innovation\".The first short released under the program isCycles, directed by Jeff Gipson, which is Disney's first VR short. A little boy named Noah discovers that the puddles outside his home can transport him to another world. He tries to show his older sister Skylar his new discovery, but she is more concerned with looking at her phone. Finally fed up with his sister ignoring him, Noah grabs Skylar's phone and tosses into the puddle where it disappears. They both jump in and it is revealed that the other world is full of puddle topped mountains with fish and whales flying through the skies. Skylar tries to take a photo on her phone, but a fish eats it leaving the two siblings to have fun. Presented in the style of a newspaper comic strip, Ollie meets a new girl who he immediately falls in love with. His thought bubble reveals his secretive love for her and tries to convince Ollie to approach her, but he is too nervous to talk to her. He tries to get rid of his bubble, but it interrupts his class and reveals his feelings for her causing the entire class to laugh at him and leaving him humiliated. After school, the girl arrives with her thought bubble, revealing that she likes Ollie and the two of them hold hands just as their bubbles do so too. Told in reverse order in a 1960s era abode, the film tells the story of Bert, Rae and their daughter Rachel. Scenes play out revealing how Bert and Rae moved into their new home and welcomed Rachel into their lives. Bert eventually dies of a heart attack and an adult Rachel convinces Rae that they must move out now. As Rae reminisces on her life she tells Rachel, \"I'm gonna miss my home\". A farm boy wants to literally catch lightning in a bottle for his elementary school science fair. He succeeds and discovers a living ball of lightning creature. After dodging dangerous bolts of lightning, the lightning creature slows down time and reveals that it has a family of its own that it wants to return to. The boy solemnly lets the lightning creature go and it repays him with lightning works display. A martial artist named Jing Hua stands in front of the grave of her deceased master. She exerts her frustration by performing kung fu; creating the world around her as it is made of water colors and ink. As her pain and sorrow at the loss of a loved one climaxes through the appearance of dripping ink, Jing Hua learns to accept the fate of her master as she becomes tired, but undefeated. Drop, a water droplet, awakens in the sky to his new surroundings. He falls towards the earth with his fellow rain drops in a terrified manner and finds himself being tossed and swished around by the city below. He eventually ends up on a car where he makes contact with a little girl. Taken by the experience, Drop is absorbed back into the sky and excitedly awaits his return in the next storm. A luminous stag that leaps through the universe creating constellations of various figures all throughout space. Upon noticing some debris on his antlers, he accidentally creates a black hole that begins sucking up all of his work. The stag tries to stop it, but damages one of his antlers in the process. With no other option, the stag summons a lot of energy and races towards the black hole, blowing it up in a magnificent display. The constellations return, but at the cost of the stag who instead has become the galaxy that encompasses them all. A baby elephant gets separated from his family, but is found by a young boy and his father. The father immediately puts the elephant to work in collecting bananas in their banana plantation, but the boy bonds with the elephant by playing with him. Despite this, the elephant still wishes to be reunited with his herd which the boy recognizes. One day, the boy arrives with a bushel of bananas and numerous elephants chasing him back home. The baby is reunited with his family as the boy and his father look on. Later, the boy and his father are reunited with the happy elephant. A little girl wanders into the woods with a stick looking for Oliver, her pet. As she ventures deep into the woods, a large black furry creature with glowing blue eyes follows the little girl. It is soon revealed that this large intimidating creature, who displays dog–like behavior, is in actuality, Oliver who displays an affinity for chasing sticks and eating junk that it shares with the girl. Short Circuit's first three shorts,Exchange Student,Jing Hua, andJust a Thought, premiered atAnnecy. Later shorts were played at theEl Capitan Theatre, attached toThe Lion Kingin selected screenings. The shorts were screened at theD23 Expo. The shorts were publicly released on January 24, 2020, onDisney+.Unlike most original Disney+ content, the shorts were released all at once, instead of being released on a weekly basis.One day after its release, the shortDropwas temporarily removed from the service, due to technical issues with the intro to the short. It has since been added back. Five new shorts premiered on August 4, 2021. Petrana Radulovic ofPolygoncalledShort Circuita \"reinventedFantasia\": writing: \"Short Circuitproves that the Fantasia format still works for the streaming age — with a few little tweaks here and there. With such a wide range of visual styles and stories that span from cute childhood adventures to poignant heartbreak, the anthology is absolutely worth a watch\".Ashley Moulton ofCommon Sense MediagaveShort Circuita grade of 4 out of 5 stars, calling the animated shorts \"delightful\".", "combined_text": "Short Circuit(TV series) Contents Production Episodes Season 1 (2020) Season 2 (2021–22) Unaired shorts Release Reception Critical response Notes References  Short Circuitis a series of Americanindependentanimatedshort filmsproduced byWalt Disney Animation Studios.Similar to theSparkShortsprogram launched at sister animation studioPixar, the series is a program in which the employees pitch their ideas for a short and work with fellow employees to create the short if selected, and is meant to take risks in both visual styles and storytelling. The shorts were released exclusively onDisney+on January 24, 2020.A second cycle of animated shorts premiered on August 4, 2021. Development on theShort Circuitprogram began in 2016.Similar to sister animation studioPixar'sSparkShorts,Walt Disney Animation Studioslaunched a program namedShort Circuit, consisting of a series of shorts of an experimental nature where any employee working at the studio can pitch an idea and can make a short if selected. In a statement, Disney said that \"[t]he goal of this innovative program is to take risks in both visual style and story, surface new voices at the studio, and experiment with new technical innovation\".The first short released under the program isCycles, directed by Jeff Gipson, which is Disney's first VR short. A little boy named Noah discovers that the puddles outside his home can transport him to another world. He tries to show his older sister Skylar his new discovery, but she is more concerned with looking at her phone. Finally fed up with his sister ignoring him, Noah grabs Skylar's phone and tosses into the puddle where it disappears. They both jump in and it is revealed that the other world is full of puddle topped mountains with fish and whales flying through the skies. Skylar tries to take a photo on her phone, but a fish eats it leaving the two siblings to have fun. Presented in the style of a newspaper comic strip, Ollie meets a new girl who he immediately falls in love with. His thought bubble reveals his secretive love for her and tries to convince Ollie to approach her, but he is too nervous to talk to her. He tries to get rid of his bubble, but it interrupts his class and reveals his feelings for her causing the entire class to laugh at him and leaving him humiliated. After school, the girl arrives with her thought bubble, revealing that she likes Ollie and the two of them hold hands just as their bubbles do so too. Told in reverse order in a 1960s era abode, the film tells the story of Bert, Rae and their daughter Rachel. Scenes play out revealing how Bert and Rae moved into their new home and welcomed Rachel into their lives. Bert eventually dies of a heart attack and an adult Rachel convinces Rae that they must move out now. As Rae reminisces on her life she tells Rachel, \"I'm gonna miss my home\". A farm boy wants to literally catch lightning in a bottle for his elementary school science fair. He succeeds and discovers a living ball of lightning creature. After dodging dangerous bolts of lightning, the lightning creature slows down time and reveals that it has a family of its own that it wants to return to. The boy solemnly lets the lightning creature go and it repays him with lightning works display. A martial artist named Jing Hua stands in front of the grave of her deceased master. She exerts her frustration by performing kung fu; creating the world around her as it is made of water colors and ink. As her pain and sorrow at the loss of a loved one climaxes through the appearance of dripping ink, Jing Hua learns to accept the fate of her master as she becomes tired, but undefeated. Drop, a water droplet, awakens in the sky to his new surroundings. He falls towards the earth with his fellow rain drops in a terrified manner and finds himself being tossed and swished around by the city below. He eventually ends up on a car where he makes contact with a little girl. Taken by the experience, Drop is absorbed back into the sky and excitedly awaits his return in the next storm. A luminous stag that leaps through the universe creating constellations of various figures all throughout space. Upon noticing some debris on his antlers, he accidentally creates a black hole that begins sucking up all of his work. The stag tries to stop it, but damages one of his antlers in the process. With no other option, the stag summons a lot of energy and races towards the black hole, blowing it up in a magnificent display. The constellations return, but at the cost of the stag who instead has become the galaxy that encompasses them all. A baby elephant gets separated from his family, but is found by a young boy and his father. The father immediately puts the elephant to work in collecting bananas in their banana plantation, but the boy bonds with the elephant by playing with him. Despite this, the elephant still wishes to be reunited with his herd which the boy recognizes. One day, the boy arrives with a bushel of bananas and numerous elephants chasing him back home. The baby is reunited with his family as the boy and his father look on. Later, the boy and his father are reunited with the happy elephant. A little girl wanders into the woods with a stick looking for Oliver, her pet. As she ventures deep into the woods, a large black furry creature with glowing blue eyes follows the little girl. It is soon revealed that this large intimidating creature, who displays dog–like behavior, is in actuality, Oliver who displays an affinity for chasing sticks and eating junk that it shares with the girl. Short Circuit's first three shorts,Exchange Student,Jing Hua, andJust a Thought, premiered atAnnecy. Later shorts were played at theEl Capitan Theatre, attached toThe Lion Kingin selected screenings. The shorts were screened at theD23 Expo. The shorts were publicly released on January 24, 2020, onDisney+.Unlike most original Disney+ content, the shorts were released all at once, instead of being released on a weekly basis.One day after its release, the shortDropwas temporarily removed from the service, due to technical issues with the intro to the short. It has since been added back. Five new shorts premiered on August 4, 2021. Petrana Radulovic ofPolygoncalledShort Circuita \"reinventedFantasia\": writing: \"Short Circuitproves that the Fantasia format still works for the streaming age — with a few little tweaks here and there. With such a wide range of visual styles and stories that span from cute childhood adventures to poignant heartbreak, the anthology is absolutely worth a watch\".Ashley Moulton ofCommon Sense MediagaveShort Circuita grade of 4 out of 5 stars, calling the animated shorts \"delightful\".", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Short_Circuit_(TV_series)", "https://en.wikipedia.org/wiki/Short_Circuit_(TV_series)", "https://en.wikipedia.org/wiki/Short_Circuit_(TV_series)", "https://en.wikipedia.org/wiki/Walt_Disney_Animation_Studios", "https://en.wikipedia.org/wiki/Independent_film", "https://en.wikipedia.org/wiki/Animation", "https://en.wikipedia.org/wiki/Short_film", "https://en.wikipedia.org/wiki/Walt_Disney_Animation_Studios"]},
{"id": "02847f24b342", "url": "https://en.wikipedia.org/wiki/SparkShorts", "title": "SparkShorts", "headings": ["Contents", "Development", "Films", "Purl", "Smash and Grab", "Kitbull", "Float", "Wind", "Loop", "Out", "Burrow", "Twenty Something", "Nona", "Self", "Accolades", "Themes", "Music", "Outside media", "A Spark Story", "See also", "References", "External links"], "content": " SparkShortsis a series of Americanindependentanimatedshort filmsproduced byPixar Animation Studios. It consists of a program in which Pixar's employees are given six months and limited budgets to develop animated short films that were originally released on Pixar'sYouTubechannel, and later onDisney+. Producer Lindsey Collins confirmed that SparkShorts replaces the need to pair short films with their major theatrical films; admitting that she felt \"torn\" over the decision. Purl, the first short of theSparkShortsprogram, was released atSIGGRAPHon August 14, 2018, while the next two shorts,Smash and GrabandKitbull, were both given alimited releaseat theEl Capitan Theateron January 8, 2019, alongside the former.Purlwas officially released on February 4, 2019, on YouTube whileSmash and GrabandKitbullwere released on February 11 and 18, respectively. Subsequent shorts were released on November 12, 2019, on Disney+, beginning withFloat, rather than on YouTube. Pixar first announced theSparkShortsprogram on January 18, 2019.The program consists of giving employees at Pixar six months and a limited budget to developindieshort films, all of them based on personal experiences.The program was developed in order to find new filmmakers at Pixar.Bobby Rubio, writer/director of theSparkShortfilmFloat, described the program as \"different film from the kinds of films\" developed at Pixar, while Lindsey Collins said that the  shorts are referred to asSparkShortsbecause Pixar \"[wants] to discover that creative spark\" in its employees.Jim Morris said: \"The SparkShorts program is designed to discover new storytellers, explore new storytelling techniques, and experiment with new production workflows\", adding that it \"[provides] an opportunity to unlock the potential of individual artists and their inventive filmmaking approaches on a smaller scale than [Pixar's] normal fare\". Ananthropomorphicball ofyarnnamed Purl becomes the first ball of yarn to work at a company called B.R.O. Capital, but is discriminated against by her human coworkers. Purl promptly changes her appearance and personality in order to fit in, but soon finds out it may not be the best idea to do so. Set on a futuristicMars-like planet, two workerrobots, named Smash and Grab respectively, must fight their way to freedom after choosing to escape from their exhausting work routine. An independentkittenforms an unlikely friendship with an abusedpit bull, whom he eventually chooses to help escape from his owners. This short accompaniedTurning Red's 2024 U.S. theatrical release. Upon discovering his son's ability to fly, a father tries to hide his son's ability from the world. When his son's ability eventually becomes public though, the father must choose between going on the run or accepting his son. A grandmother and her grandson find themselves scavengingdebrisafter being trapped together in an endless chasm, and soon realize their dream of escaping. A non-verbal girl withautismand a chatty boy must learn to understand each other in order to fulfill a canoeing trip in an urban lake during summer camp. A young gay man who hasnot yet come outto his parents unexpectedly has his mindmagically swappedwith his dog's. A young rabbit tries to build the burrow of her dreams, becoming embarrassed each time she accidentally digs into a neighbor's home. This short was originally intended to receive a wide theatrical release alongside Pixar's feature-length filmSoul.While the theatrical release of both the short and feature were cancelled in countries whereDisney+was available,Burrowstill played theatrically beforeSoulin countries where Disney+ was not available in December 2020.The short would play again beforeSoulfor its U.S. theatrical release in 2024. The film examines the challenges and insecurities of 'adulting.' Some days you're nailing it, while other days, you're just a stack of kids hiding in a trench coat, hoping no one notices. The film's protagonist is Gia, who finds herself in this exact scenario the night of her 21st birthday. The film centers on a widowed grandmother named Nona who plans to spend her day off by shutting out the world to watch her favorite TV show, E.W.W. Smashdown Wrestling. However, when her five-year-old granddaughter Renee is unexpectedly dropped off, Nona is caught between her two favorite things. Renee wants to play, while the normally-doting Nona wrestles with wanting to watch the Smashdown, leading to a decisive showdown between the two, and a loving compromise. The film centers on a wooden doll who desperately wants to fit in makes an ill-fated wish upon a star, sparking a journey of self-discovery. Her desire to blend in with her peers leads her down a harmful path, challenging her perspective of both who she is and where she belongs. This film is Pixar's first hybrid stop-motion animation. Purlwas praised by many as an allegory forgender inequalityandfeminism,which Meghan Mehta ofStudy Breaksnoted was \"mature for Pixar's target audience\".Alex Reif ofLaughing Placesaid thatSmash and Grabis \"[a] story about two workers who don't get the same luxuries as those who control them\".Nick Skillicorn ofIdea to Valuefelt that theSparkShortsprogram \"enables the staff to flex their creative muscles in new ways, and try ideas which would never be accepted into a feature-length film aimed at families\". On January 29, 2020, Disney announced that an untitled documentary series focusing on theSparkShortsseries was in development forDisney+.The series, which provided \"an immersive look at the next generation of Pixar filmmaker[s]\", was executive-produced byBrian McGinn, Jason Sterman andDavid Gelb.On July 21, 2021, it was reported that the project was being redeveloped as a docu-film under the nameA Spark Story, with McGinn, Sterman, and Gelb producing.Sterman also directed the film alongside Leanne Dare.Pixar produced the project alongside Supper Club.The documentary, charting the production of then-recentSparkShortsTwenty SomethingandNona, was released on September 24, 2021. Category", "combined_text": "SparkShorts Contents Development Films Purl Smash and Grab Kitbull Float Wind Loop Out Burrow Twenty Something Nona Self Accolades Themes Music Outside media A Spark Story See also References External links  SparkShortsis a series of Americanindependentanimatedshort filmsproduced byPixar Animation Studios. It consists of a program in which Pixar's employees are given six months and limited budgets to develop animated short films that were originally released on Pixar'sYouTubechannel, and later onDisney+. Producer Lindsey Collins confirmed that SparkShorts replaces the need to pair short films with their major theatrical films; admitting that she felt \"torn\" over the decision. Purl, the first short of theSparkShortsprogram, was released atSIGGRAPHon August 14, 2018, while the next two shorts,Smash and GrabandKitbull, were both given alimited releaseat theEl Capitan Theateron January 8, 2019, alongside the former.Purlwas officially released on February 4, 2019, on YouTube whileSmash and GrabandKitbullwere released on February 11 and 18, respectively. Subsequent shorts were released on November 12, 2019, on Disney+, beginning withFloat, rather than on YouTube. Pixar first announced theSparkShortsprogram on January 18, 2019.The program consists of giving employees at Pixar six months and a limited budget to developindieshort films, all of them based on personal experiences.The program was developed in order to find new filmmakers at Pixar.Bobby Rubio, writer/director of theSparkShortfilmFloat, described the program as \"different film from the kinds of films\" developed at Pixar, while Lindsey Collins said that the  shorts are referred to asSparkShortsbecause Pixar \"[wants] to discover that creative spark\" in its employees.Jim Morris said: \"The SparkShorts program is designed to discover new storytellers, explore new storytelling techniques, and experiment with new production workflows\", adding that it \"[provides] an opportunity to unlock the potential of individual artists and their inventive filmmaking approaches on a smaller scale than [Pixar's] normal fare\". Ananthropomorphicball ofyarnnamed Purl becomes the first ball of yarn to work at a company called B.R.O. Capital, but is discriminated against by her human coworkers. Purl promptly changes her appearance and personality in order to fit in, but soon finds out it may not be the best idea to do so. Set on a futuristicMars-like planet, two workerrobots, named Smash and Grab respectively, must fight their way to freedom after choosing to escape from their exhausting work routine. An independentkittenforms an unlikely friendship with an abusedpit bull, whom he eventually chooses to help escape from his owners. This short accompaniedTurning Red's 2024 U.S. theatrical release. Upon discovering his son's ability to fly, a father tries to hide his son's ability from the world. When his son's ability eventually becomes public though, the father must choose between going on the run or accepting his son. A grandmother and her grandson find themselves scavengingdebrisafter being trapped together in an endless chasm, and soon realize their dream of escaping. A non-verbal girl withautismand a chatty boy must learn to understand each other in order to fulfill a canoeing trip in an urban lake during summer camp. A young gay man who hasnot yet come outto his parents unexpectedly has his mindmagically swappedwith his dog's. A young rabbit tries to build the burrow of her dreams, becoming embarrassed each time she accidentally digs into a neighbor's home. This short was originally intended to receive a wide theatrical release alongside Pixar's feature-length filmSoul.While the theatrical release of both the short and feature were cancelled in countries whereDisney+was available,Burrowstill played theatrically beforeSoulin countries where Disney+ was not available in December 2020.The short would play again beforeSoulfor its U.S. theatrical release in 2024. The film examines the challenges and insecurities of 'adulting.' Some days you're nailing it, while other days, you're just a stack of kids hiding in a trench coat, hoping no one notices. The film's protagonist is Gia, who finds herself in this exact scenario the night of her 21st birthday. The film centers on a widowed grandmother named Nona who plans to spend her day off by shutting out the world to watch her favorite TV show, E.W.W. Smashdown Wrestling. However, when her five-year-old granddaughter Renee is unexpectedly dropped off, Nona is caught between her two favorite things. Renee wants to play, while the normally-doting Nona wrestles with wanting to watch the Smashdown, leading to a decisive showdown between the two, and a loving compromise. The film centers on a wooden doll who desperately wants to fit in makes an ill-fated wish upon a star, sparking a journey of self-discovery. Her desire to blend in with her peers leads her down a harmful path, challenging her perspective of both who she is and where she belongs. This film is Pixar's first hybrid stop-motion animation. Purlwas praised by many as an allegory forgender inequalityandfeminism,which Meghan Mehta ofStudy Breaksnoted was \"mature for Pixar's target audience\".Alex Reif ofLaughing Placesaid thatSmash and Grabis \"[a] story about two workers who don't get the same luxuries as those who control them\".Nick Skillicorn ofIdea to Valuefelt that theSparkShortsprogram \"enables the staff to flex their creative muscles in new ways, and try ideas which would never be accepted into a feature-length film aimed at families\". On January 29, 2020, Disney announced that an untitled documentary series focusing on theSparkShortsseries was in development forDisney+.The series, which provided \"an immersive look at the next generation of Pixar filmmaker[s]\", was executive-produced byBrian McGinn, Jason Sterman andDavid Gelb.On July 21, 2021, it was reported that the project was being redeveloped as a docu-film under the nameA Spark Story, with McGinn, Sterman, and Gelb producing.Sterman also directed the film alongside Leanne Dare.Pixar produced the project alongside Supper Club.The documentary, charting the production of then-recentSparkShortsTwenty SomethingandNona, was released on September 24, 2021. Category", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/SparkShorts", "https://en.wikipedia.org/wiki/SparkShorts", "https://en.wikipedia.org/wiki/SparkShorts", "https://en.wikipedia.org/wiki/Pixar", "https://en.wikipedia.org/wiki/Purl_(film)", "https://en.wikipedia.org/wiki/The_Walt_Disney_Company", "https://en.wikipedia.org/wiki/Purl_(film)", "https://en.wikipedia.org/wiki/Smash_and_Grab_(2019_film)"]},
{"id": "0265db0a88e9", "url": "https://en.wikipedia.org/wiki/Drive_theory", "title": "Drive theory", "headings": ["Contents", "Psychoanalysis", "Early attachment theory", "Social psychology", "Corroborative evidence", "Evaluation apprehension", "References", "External links"], "content": "Inpsychology, adrive theory,theory of drivesordrive doctrineis a theory that attempts to analyze, classify or define  the psychological drives. A drive is an instinctual need that has the power of influencing the behavior of an individual;an \"excitatory state produced by ahomeostaticdisturbance\". Drive theory is based on the principle that organisms are born with certain psychological needs and that a negative state of tension is created when these needs are not satisfied. When a need is satisfied, drive is reduced and the organism returns to a state of homeostasis and relaxation. According to the theory, drive tends to increase over time and operates on a feedback control system, much like a thermostat. In 1943 two psychologists,Clark HullandKenneth Spence, put forward a drive theory as an explanation of all behavior.In a study conducted by Hull, two groups of rats were put in a maze, group A was given food after three hours and group B was given food after twenty-two hours. Hull had decided that the rats that were deprived of food longer would be more likely to develop a habit of going down the same path to obtain food. Influential figures applying psychoanalysis Influential works applying psychoanalysis Inpsychoanalysis, drive theory (German:TriebtheorieorTrieblehre)refers to the theory of drives, motivations, or instincts, that have clear objects.When an internal imbalance is detected by homeostatic mechanisms, a drive to restore balance is produced.In 1927,Sigmund Freudsaid that a drive theory was what was lacking most in psychoanalysis. He was opposed topersonality systematicsin psychology, rejecting it as a form of paranoia, and instead classified drives with dichotomies likeEros/Thanatosdrives (the drives toward life anddeath, respectively) and sexual/ego drives. Freud'sCivilization and Its Discontentswas published in Germany in 1930, when therise of fascismin that country was well under way, and the warnings of a second European war were leading to opposing calls for rearmament and pacifism. Against this background, Freud wrote \"In face of the destructive forces unleashed, now it may be expected that the other of the two 'heavenly forces,' eternal Eros, will put forth his strength so as to maintain himself alongside of his equally immortal adversary.\" In 1947, Hungarianpsychiatristand psychologistLeopold Szondiaimed instead at a systematic drive theory.Szondi's drive diagramhas been described as a revolutionary addition to psychology, and as paving the way for a theoretical psychiatry and apsychoanalytical anthropology. In earlyattachment theory, behavioral drive reduction was proposed byDollardandMiller(1950) as an explanation of the mechanisms behind early attachment in infants. Behavioural drive reduction theory suggests that infants are born with innate drives, such as hunger and thirst, which only the caregiver, usually the mother, can reduce. Through a process ofclassical conditioning, the infant learns to associate the mother with the satisfaction of reduced drive and is thus able to form a key attachment bond. However, this theory is challenged by the work done byHarry Harlow, particularly the experiments involving thematernal separation of rhesus monkeys, which indicate that comfort possesses greater motivational value than hunger. Insocial psychology, drive theory was used byRobert Zajoncin 1965 as an explanation of the phenomenon ofsocial facilitation.Theaudience effectnotes that, in some cases, the presence of a passive audience will facilitate the better performance of a task, while in other cases the presence of an audience will inhibit the performance of a task. Zajonc's drive theory suggests that the variable determining direction of performance is whether the task is composed of a correct dominant response (that is, the task is perceived as being subjectively easy to the individual) or an incorrect dominant response (perceived as being subjectively difficult). In the presence of a passive audience, an individual is in a heightened state ofarousal. Increased arousal, orstress, causes the individual to enact behaviours that form dominant responses, since an individual's dominant response is the most likely response, given the skills which are available. If the dominant response is correct, then social presence enhances performance of the task. However, if the dominant response is incorrect, social presence produces an impaired performance. Increasing performance of well learned tasks and impairing performance on poorly learned tasks. Such behaviour was first noticed by Triplett (1898) while observing the cyclists who were racing together versus cyclists who were racing alone.It was found that the mere presence of other cyclists produced greater performance. A similar effect was observed by Chen (1937) inantsbuilding colonies.However, it was not until Zajonc investigated this behaviour in the 1960s that any empirical explanation for the audience effect was pursued. Zajonc's drive theory is based on an experimentinvolving the investigation of the effect of social facilitation incockroaches. Zajonc devised a study in which individual cockroaches were released into a tube, at the end of which there was a light. In the presence of other cockroaches as spectators, cockroaches were observed to achieve a significantly faster time in reaching the light than those in the control, no-spectator group. However, when cockroaches in the same conditions were given a maze to negotiate, performance was impaired in the spectator condition, demonstrating that incorrect dominant responses in the presence of an audience impair performance. Cottrell'sevaluation apprehension modellater refined this theory to include yet another variable in the mechanisms of social facilitation. He suggested that the correctness of dominant responses only plays a role in social facilitation when there is an expectation of social reward or punishment based on performance. His study differs in design from Zajonc's as he introduced a separate condition in which participants were given tasks to perform in the presence of an audience that was blindfolded, and thus unable to evaluate the participant's performance. It was found that no social facilitation effect occurred, and hence the anticipation of performance evaluation must play a role in social facilitation.Evaluation apprehension, however, is only key in human social facilitation and is not observed in other animals. Abschnitt I Trieblehre, Kapitel I Das Menschliche Triebsystem.Triebe sind Radikale der menschlichen Handlungen und Verhaltungen. Sie sind die bedingenden und erhaltenden Wurzeln des menschlichen Daseins überhaupt. A drive system must give us a synthetic sight of the whole of the drive activities, comparable to the total impression which white light gives us, but it must also make it possible to display 'the spectrum' of the drives just like light can be divided in colours. It is an extremely difficult task and it is not at all astonishing that we have not yet arrived at this point. Cherche à jeter les bases d'une authentique anthropologie psychanalytique d'après le schéma pulsionnel de Szondi.", "combined_text": "Drive theory Contents Psychoanalysis Early attachment theory Social psychology Corroborative evidence Evaluation apprehension References External links Inpsychology, adrive theory,theory of drivesordrive doctrineis a theory that attempts to analyze, classify or define  the psychological drives. A drive is an instinctual need that has the power of influencing the behavior of an individual;an \"excitatory state produced by ahomeostaticdisturbance\". Drive theory is based on the principle that organisms are born with certain psychological needs and that a negative state of tension is created when these needs are not satisfied. When a need is satisfied, drive is reduced and the organism returns to a state of homeostasis and relaxation. According to the theory, drive tends to increase over time and operates on a feedback control system, much like a thermostat. In 1943 two psychologists,Clark HullandKenneth Spence, put forward a drive theory as an explanation of all behavior.In a study conducted by Hull, two groups of rats were put in a maze, group A was given food after three hours and group B was given food after twenty-two hours. Hull had decided that the rats that were deprived of food longer would be more likely to develop a habit of going down the same path to obtain food. Influential figures applying psychoanalysis Influential works applying psychoanalysis Inpsychoanalysis, drive theory (German:TriebtheorieorTrieblehre)refers to the theory of drives, motivations, or instincts, that have clear objects.When an internal imbalance is detected by homeostatic mechanisms, a drive to restore balance is produced.In 1927,Sigmund Freudsaid that a drive theory was what was lacking most in psychoanalysis. He was opposed topersonality systematicsin psychology, rejecting it as a form of paranoia, and instead classified drives with dichotomies likeEros/Thanatosdrives (the drives toward life anddeath, respectively) and sexual/ego drives. Freud'sCivilization and Its Discontentswas published in Germany in 1930, when therise of fascismin that country was well under way, and the warnings of a second European war were leading to opposing calls for rearmament and pacifism. Against this background, Freud wrote \"In face of the destructive forces unleashed, now it may be expected that the other of the two 'heavenly forces,' eternal Eros, will put forth his strength so as to maintain himself alongside of his equally immortal adversary.\" In 1947, Hungarianpsychiatristand psychologistLeopold Szondiaimed instead at a systematic drive theory.Szondi's drive diagramhas been described as a revolutionary addition to psychology, and as paving the way for a theoretical psychiatry and apsychoanalytical anthropology. In earlyattachment theory, behavioral drive reduction was proposed byDollardandMiller(1950) as an explanation of the mechanisms behind early attachment in infants. Behavioural drive reduction theory suggests that infants are born with innate drives, such as hunger and thirst, which only the caregiver, usually the mother, can reduce. Through a process ofclassical conditioning, the infant learns to associate the mother with the satisfaction of reduced drive and is thus able to form a key attachment bond. However, this theory is challenged by the work done byHarry Harlow, particularly the experiments involving thematernal separation of rhesus monkeys, which indicate that comfort possesses greater motivational value than hunger. Insocial psychology, drive theory was used byRobert Zajoncin 1965 as an explanation of the phenomenon ofsocial facilitation.Theaudience effectnotes that, in some cases, the presence of a passive audience will facilitate the better performance of a task, while in other cases the presence of an audience will inhibit the performance of a task. Zajonc's drive theory suggests that the variable determining direction of performance is whether the task is composed of a correct dominant response (that is, the task is perceived as being subjectively easy to the individual) or an incorrect dominant response (perceived as being subjectively difficult). In the presence of a passive audience, an individual is in a heightened state ofarousal. Increased arousal, orstress, causes the individual to enact behaviours that form dominant responses, since an individual's dominant response is the most likely response, given the skills which are available. If the dominant response is correct, then social presence enhances performance of the task. However, if the dominant response is incorrect, social presence produces an impaired performance. Increasing performance of well learned tasks and impairing performance on poorly learned tasks. Such behaviour was first noticed by Triplett (1898) while observing the cyclists who were racing together versus cyclists who were racing alone.It was found that the mere presence of other cyclists produced greater performance. A similar effect was observed by Chen (1937) inantsbuilding colonies.However, it was not until Zajonc investigated this behaviour in the 1960s that any empirical explanation for the audience effect was pursued. Zajonc's drive theory is based on an experimentinvolving the investigation of the effect of social facilitation incockroaches. Zajonc devised a study in which individual cockroaches were released into a tube, at the end of which there was a light. In the presence of other cockroaches as spectators, cockroaches were observed to achieve a significantly faster time in reaching the light than those in the control, no-spectator group. However, when cockroaches in the same conditions were given a maze to negotiate, performance was impaired in the spectator condition, demonstrating that incorrect dominant responses in the presence of an audience impair performance. Cottrell'sevaluation apprehension modellater refined this theory to include yet another variable in the mechanisms of social facilitation. He suggested that the correctness of dominant responses only plays a role in social facilitation when there is an expectation of social reward or punishment based on performance. His study differs in design from Zajonc's as he introduced a separate condition in which participants were given tasks to perform in the presence of an audience that was blindfolded, and thus unable to evaluate the participant's performance. It was found that no social facilitation effect occurred, and hence the anticipation of performance evaluation must play a role in social facilitation.Evaluation apprehension, however, is only key in human social facilitation and is not observed in other animals. Abschnitt I Trieblehre, Kapitel I Das Menschliche Triebsystem.Triebe sind Radikale der menschlichen Handlungen und Verhaltungen. Sie sind die bedingenden und erhaltenden Wurzeln des menschlichen Daseins überhaupt. A drive system must give us a synthetic sight of the whole of the drive activities, comparable to the total impression which white light gives us, but it must also make it possible to display 'the spectrum' of the drives just like light can be divided in colours. It is an extremely difficult task and it is not at all astonishing that we have not yet arrived at this point. Cherche à jeter les bases d'une authentique anthropologie psychanalytique d'après le schéma pulsionnel de Szondi.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Drive_theory", "https://en.wikipedia.org/wiki/Drive_theory", "https://en.wikipedia.org/wiki/Drive_theory", "https://en.wikipedia.org/wiki/Drive_reduction_theory_(learning_theory)", "https://en.wikipedia.org/wiki/Psychology", "https://en.wikipedia.org/wiki/Homeostasis", "https://en.wikipedia.org/wiki/Clark_Hull", "https://en.wikipedia.org/wiki/Kenneth_Spence"]},
{"id": "f1e22429fa1e", "url": "https://en.wikipedia.org/wiki/Juan_Garc%C3%ADa_Esquivel", "title": "Juan García Esquivel", "headings": ["Contents", "Early life", "Music", "Music in recent media", "Discography", "See also", "References", "Further reading", "External links"], "content": "Juan García Esquivel(January 20, 1918 – January 3, 2002),often known mononymously asEsquivel!, was a Mexicanbandleader,pianist, andcomposerfor television and films. He is recognized today as one of the foremost exponents of a sophisticated style of largely instrumental music that combines elements oflounge musicandjazzwithLatinflavors.  Esquivel is sometimes called \"The King ofSpace Age Pop\" and \"TheBusby Berkeleyof Cocktail Music\", and is considered one of the foremost exponents of a style of late 1950s-early 1960s quirky instrumental pop that became known (in retrospect) as \"Space Age Bachelor Pad Music\". He was born in 1918, inTampico,Tamaulipas, and his family moved toMexico Cityin 1928 where he became a self-taught musician from an early age. In interviews, Esquivel's family members have stated that the young boy started playing piano when he was around six years old, to the amazement of older musicians who would gather around him in disbelief and to his own delight exhibiting his musical gifts. They have also stated  that Esquivel continued to eschew formal musical training as he grew older, preferring to learn from books and by listening to and playing music instead. Esquivel played a style of late 1950s-early 1960s quirky instrumental pop known today aslounge music.Esquivel's musical style was highly idiosyncratic, and although elements sound like his contemporaries, many stylistic traits distinguished his music and made it instantly recognizable. These  included exotic percussion, wordless vocals, virtuoso piano runs, and exaggerated dynamic shifts.  He used manyjazz-like elements; however, other than his piano solos, there is no improvisation, and the works are meticulously arranged by Esquivel himself, who considered himself a perfectionist as a composer, performer, and recording artist. His orchestration employed novel instrumental combinations, such as Chinese bells, mariachi bands, whistling, and numerous percussion instruments, blended with orchestra, mixed chorus, and his own heavily ornamented piano style.Vocal groups were often utilized to sing only nonsense syllables, most famously \"zu-zu\" and \"pow!\"  A survey of Esquivel's recordings reveals a fondness forglissando,sometimes on a half-valved trumpet, sometimes on akettle drum, but most frequently on pitchedpercussion instrumentsandsteel guitars. Esquivel's use ofstereorecording was notable, and he occasionally employed two bands recording simultaneously in separate studios, such as on his albumLatin-esque(1962). That album's song \"Mucha Muchacha\" makes unusual use of stereo separation, with the chorus and brass rapidly alternating in the left and right audio channels. He arranged many traditionalMexicansongs like \"Bésame Mucho\", \"La Bamba\", \"El Manisero\" (Cuban/Mexican) and \"La Bikina\"; covered Brazilian songs like \"Aquarela do Brasil\" (also known simply as \"Brazil\") byAry Barroso, \"Surfboard\" and \"Agua de Beber\" byTom Jobim, and composed spicy lounge-like novelties such as \"Mini Skirt\", \"Yeyo\", \"Latin-esque\", \"Mucha Muchacha\" and \"Whatchamacallit\".  He was commissioned to compose the music of a Mexican children'sTVshowOdisea Burbujas. His 1958 albumFour Corners of the Worldfeatured a fusion of \"Latin American music combined with the wonderful melodies of European classical music.\" His concerts featured elaborate light shows years before such effects became popular in live music.  He performed inLas Vegason several occasions, often as the opening act forFrank Sinatra. He frequently performed at theStardust casinolounge circa 1964. Several compilations of Esquivel's music were issued on compact disc starting withSpace Age Bachelor Pad Musicin 1994.The first reissues were compiled byIrwin Chusid(who also produced the first CD compilation ofRaymond Scottrecordings and the premiere release ofThe Langley Schools Music Project). The success of these releases led to reissues of several of Esquivel's original 1950s-1960s albums. The last recording on which Esquivel worked wasMerry Xmas from the Space-Age Bachelor Padin 1996, for which he recordedvoiceoverson two tracks by the bandCombustible Edison; his voiceovers were recorded at home in Mexico by the band's keyboardistBrother Cleve, who also mixed the tracks. This album was a re-release of the six Esquivel recordings that originally appeared on the 1959 RCA Victor LPThe Merriest of Christmas Pops, along with four more Esquivel recordings from the late 1950s and 1960s and two new Combustible Edison tracks featuring Esquivel's holiday-themed voiceovers. The last CD released during his lifetime,See It In Sound(1998), was recorded in 1960 for RCA, but was not released at the time because RCA believed it would not be commercially successful. The album's concept was that Esquivel's music would be combined with sound effects and edited in a way that suggested a visual work such as a film, though without dialog or an explicitly stated narrative. For example, the album includes a version of \"Brazil\" with an arrangement that makes extensive use of editing and sound effects to suggest a person going in and out of several bars, each bar featuring a band playing a unique arrangement of \"Brazil\". Esquivel also worked as composer for Revue Productions/Universal Television. There he scored the TV western series \"The Tall Man\", and co-wrote, withStanley Wilson, theRevue/Universal TVlogo fanfare. His recording of his composition \"Mucha Muchacha\" was used in the filmsConfessions of a Dangerous Mind,The Big Lebowski,The Notorious Bettie Page,Stuart Saves His Family,Nacho LibreandBeavis and Butt-Head Do America. \"Mini Skirt\" was used as the opening theme for the BBC documentary seriesLouis Theroux's Weird WeekendsandWhen Louis Met.... His recording of his composition \"Whatchamacallit\" was used in the 2002 filmSecretary. Esquivel's recording of \"Boulevard of Broken Dreams\" was usedBetter Call SaulEpisode 2 \"Mijo\" (2015). Esquivel's recording of \"My Blue Heaven\" was used in the trailer for the 2021 filmMalibu Road. In 2022, Esquivel's 1959 recording of \"Fantasy\" was used byApplein its \"Data Auction\" global TV ad campaign, to promote privacy on itsiPhoneproduct. (12\" LP releases, US and Mexico) (CD releases) (Related releases featuring Esquivel's music)", "combined_text": "Juan García Esquivel Contents Early life Music Music in recent media Discography See also References Further reading External links Juan García Esquivel(January 20, 1918 – January 3, 2002),often known mononymously asEsquivel!, was a Mexicanbandleader,pianist, andcomposerfor television and films. He is recognized today as one of the foremost exponents of a sophisticated style of largely instrumental music that combines elements oflounge musicandjazzwithLatinflavors.  Esquivel is sometimes called \"The King ofSpace Age Pop\" and \"TheBusby Berkeleyof Cocktail Music\", and is considered one of the foremost exponents of a style of late 1950s-early 1960s quirky instrumental pop that became known (in retrospect) as \"Space Age Bachelor Pad Music\". He was born in 1918, inTampico,Tamaulipas, and his family moved toMexico Cityin 1928 where he became a self-taught musician from an early age. In interviews, Esquivel's family members have stated that the young boy started playing piano when he was around six years old, to the amazement of older musicians who would gather around him in disbelief and to his own delight exhibiting his musical gifts. They have also stated  that Esquivel continued to eschew formal musical training as he grew older, preferring to learn from books and by listening to and playing music instead. Esquivel played a style of late 1950s-early 1960s quirky instrumental pop known today aslounge music.Esquivel's musical style was highly idiosyncratic, and although elements sound like his contemporaries, many stylistic traits distinguished his music and made it instantly recognizable. These  included exotic percussion, wordless vocals, virtuoso piano runs, and exaggerated dynamic shifts.  He used manyjazz-like elements; however, other than his piano solos, there is no improvisation, and the works are meticulously arranged by Esquivel himself, who considered himself a perfectionist as a composer, performer, and recording artist. His orchestration employed novel instrumental combinations, such as Chinese bells, mariachi bands, whistling, and numerous percussion instruments, blended with orchestra, mixed chorus, and his own heavily ornamented piano style.Vocal groups were often utilized to sing only nonsense syllables, most famously \"zu-zu\" and \"pow!\"  A survey of Esquivel's recordings reveals a fondness forglissando,sometimes on a half-valved trumpet, sometimes on akettle drum, but most frequently on pitchedpercussion instrumentsandsteel guitars. Esquivel's use ofstereorecording was notable, and he occasionally employed two bands recording simultaneously in separate studios, such as on his albumLatin-esque(1962). That album's song \"Mucha Muchacha\" makes unusual use of stereo separation, with the chorus and brass rapidly alternating in the left and right audio channels. He arranged many traditionalMexicansongs like \"Bésame Mucho\", \"La Bamba\", \"El Manisero\" (Cuban/Mexican) and \"La Bikina\"; covered Brazilian songs like \"Aquarela do Brasil\" (also known simply as \"Brazil\") byAry Barroso, \"Surfboard\" and \"Agua de Beber\" byTom Jobim, and composed spicy lounge-like novelties such as \"Mini Skirt\", \"Yeyo\", \"Latin-esque\", \"Mucha Muchacha\" and \"Whatchamacallit\".  He was commissioned to compose the music of a Mexican children'sTVshowOdisea Burbujas. His 1958 albumFour Corners of the Worldfeatured a fusion of \"Latin American music combined with the wonderful melodies of European classical music.\" His concerts featured elaborate light shows years before such effects became popular in live music.  He performed inLas Vegason several occasions, often as the opening act forFrank Sinatra. He frequently performed at theStardust casinolounge circa 1964. Several compilations of Esquivel's music were issued on compact disc starting withSpace Age Bachelor Pad Musicin 1994.The first reissues were compiled byIrwin Chusid(who also produced the first CD compilation ofRaymond Scottrecordings and the premiere release ofThe Langley Schools Music Project). The success of these releases led to reissues of several of Esquivel's original 1950s-1960s albums. The last recording on which Esquivel worked wasMerry Xmas from the Space-Age Bachelor Padin 1996, for which he recordedvoiceoverson two tracks by the bandCombustible Edison; his voiceovers were recorded at home in Mexico by the band's keyboardistBrother Cleve, who also mixed the tracks. This album was a re-release of the six Esquivel recordings that originally appeared on the 1959 RCA Victor LPThe Merriest of Christmas Pops, along with four more Esquivel recordings from the late 1950s and 1960s and two new Combustible Edison tracks featuring Esquivel's holiday-themed voiceovers. The last CD released during his lifetime,See It In Sound(1998), was recorded in 1960 for RCA, but was not released at the time because RCA believed it would not be commercially successful. The album's concept was that Esquivel's music would be combined with sound effects and edited in a way that suggested a visual work such as a film, though without dialog or an explicitly stated narrative. For example, the album includes a version of \"Brazil\" with an arrangement that makes extensive use of editing and sound effects to suggest a person going in and out of several bars, each bar featuring a band playing a unique arrangement of \"Brazil\". Esquivel also worked as composer for Revue Productions/Universal Television. There he scored the TV western series \"The Tall Man\", and co-wrote, withStanley Wilson, theRevue/Universal TVlogo fanfare. His recording of his composition \"Mucha Muchacha\" was used in the filmsConfessions of a Dangerous Mind,The Big Lebowski,The Notorious Bettie Page,Stuart Saves His Family,Nacho LibreandBeavis and Butt-Head Do America. \"Mini Skirt\" was used as the opening theme for the BBC documentary seriesLouis Theroux's Weird WeekendsandWhen Louis Met.... His recording of his composition \"Whatchamacallit\" was used in the 2002 filmSecretary. Esquivel's recording of \"Boulevard of Broken Dreams\" was usedBetter Call SaulEpisode 2 \"Mijo\" (2015). Esquivel's recording of \"My Blue Heaven\" was used in the trailer for the 2021 filmMalibu Road. In 2022, Esquivel's 1959 recording of \"Fantasy\" was used byApplein its \"Data Auction\" global TV ad campaign, to promote privacy on itsiPhoneproduct. (12\" LP releases, US and Mexico) (CD releases) (Related releases featuring Esquivel's music)", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Juan_Garc%C3%ADa_Esquivel", "https://en.wikipedia.org/wiki/Juan_Garc%C3%ADa_Esquivel", "https://en.wikipedia.org/wiki/Juan_Garc%C3%ADa_Esquivel", "https://en.wikipedia.org/wiki/Tampico", "https://en.wikipedia.org/wiki/Jiutepec", "https://en.wikipedia.org/wiki/Easy_listening", "https://en.wikipedia.org/wiki/Lounge_music", "https://en.wikipedia.org/wiki/Space_age_pop"]},
{"id": "2819b2c00029", "url": "https://en.wikipedia.org/wiki/Jena_Friedman", "title": "Jena Friedman", "headings": ["Contents", "Early life", "Career", "Bibliography", "Notes", "References", "External links"], "content": " Jena Friedmanis an American comedian and writer. She is the creator ofSoft Focus with Jena FriedmanforAdult Swim, the first installment of which premiered in February 2018. Friedman was born and raised in a Conservative Jewish home inHaddonfield, New Jersey, where she had a bat mitzvah and went to Hebrew school through 10th Grade,andHaddonfield Memorial High School.She studiedanthropologyatNorthwestern University. After graduation, she worked as a healthcare consultant for consulting firmBooz Allen Hamilton. In 2007, Friedman wroteThe Refugee Girls Revue, a satire inspired byAmerican Girldolls. The play earned critical acclaim in the 2008New York International Fringe Festivaland had a successful runOff-Broadway. In 2010, she received acease-and-desistletter fromThe New York Timesfor parodying their wedding videos. The parody, titledTed and Gracie, has since become a popular web series. In 2015, Friedman's solo showAmerican Cuntpremiered in theEdinburgh Festival Fringeto critical acclaim.The magazinePastenamedAmerican Cuntone of the 10 Best Stand Up Comedy Specials of 2016.She createdSoft Focus with Jena Friedman, a series of Adult Swim specials that she also co-executive produces, directs, and hosts. The specials include interviews withJohn McAfee, the American software entrepreneur and Presidential hopeful,as well asGilberto Valle, a New York City police officer who was convicted of a conspiracy to kidnap, cook, and eat women, known as the \"Cannibal Cop\".The second installment premiered in January 2019. She has been a field produceratThe Daily Show with Jon Stewartand has written forLate Show with David Letterman. Friedman appeared in 2020 moviePalm Springs, and on TV shows includingConan,The Late Show with Stephen Colbert, and others.She has also been a contributing writer toThe New Yorker. In 2020, Friedman contributed to the screenplay ofBorat Subsequent Moviefilm, with the writing team receiving a nomination for theAcademy Award for Best Adapted Screenplay.She directed and starred inTrue Crime Story: IndefensibleonSundance TVin 2021. Friedman is the host of the comedic true-crime seriesIndefensibleonAMC+. Her latest comedy special,Ladykiller, premiered onPeacockin September of 2022. On a May 2023 episode (\"EP. 813 — Winkers and Blinkers\") of the comedy podcastComedy Bang! Bang!, Friedman recalled how she was asked to write for therevivalof the TV showRoseannein 2018 afterRoseanne Barrhad enjoyed a stand-up set by Friedman.On the day she was scheduled to start her new job, Barr went on a racist Twitter rant that resulted in the show being swiftly cancelled. In April 2025, Friedman gave aTEDtalk, The Jokes AI Won't Tell.And in August 2025, Friedman brought her solo show, \"Motherf*cker\" to theEdinburghFringe Festival.", "combined_text": "Jena Friedman Contents Early life Career Bibliography Notes References External links  Jena Friedmanis an American comedian and writer. She is the creator ofSoft Focus with Jena FriedmanforAdult Swim, the first installment of which premiered in February 2018. Friedman was born and raised in a Conservative Jewish home inHaddonfield, New Jersey, where she had a bat mitzvah and went to Hebrew school through 10th Grade,andHaddonfield Memorial High School.She studiedanthropologyatNorthwestern University. After graduation, she worked as a healthcare consultant for consulting firmBooz Allen Hamilton. In 2007, Friedman wroteThe Refugee Girls Revue, a satire inspired byAmerican Girldolls. The play earned critical acclaim in the 2008New York International Fringe Festivaland had a successful runOff-Broadway. In 2010, she received acease-and-desistletter fromThe New York Timesfor parodying their wedding videos. The parody, titledTed and Gracie, has since become a popular web series. In 2015, Friedman's solo showAmerican Cuntpremiered in theEdinburgh Festival Fringeto critical acclaim.The magazinePastenamedAmerican Cuntone of the 10 Best Stand Up Comedy Specials of 2016.She createdSoft Focus with Jena Friedman, a series of Adult Swim specials that she also co-executive produces, directs, and hosts. The specials include interviews withJohn McAfee, the American software entrepreneur and Presidential hopeful,as well asGilberto Valle, a New York City police officer who was convicted of a conspiracy to kidnap, cook, and eat women, known as the \"Cannibal Cop\".The second installment premiered in January 2019. She has been a field produceratThe Daily Show with Jon Stewartand has written forLate Show with David Letterman. Friedman appeared in 2020 moviePalm Springs, and on TV shows includingConan,The Late Show with Stephen Colbert, and others.She has also been a contributing writer toThe New Yorker. In 2020, Friedman contributed to the screenplay ofBorat Subsequent Moviefilm, with the writing team receiving a nomination for theAcademy Award for Best Adapted Screenplay.She directed and starred inTrue Crime Story: IndefensibleonSundance TVin 2021. Friedman is the host of the comedic true-crime seriesIndefensibleonAMC+. Her latest comedy special,Ladykiller, premiered onPeacockin September of 2022. On a May 2023 episode (\"EP. 813 — Winkers and Blinkers\") of the comedy podcastComedy Bang! Bang!, Friedman recalled how she was asked to write for therevivalof the TV showRoseannein 2018 afterRoseanne Barrhad enjoyed a stand-up set by Friedman.On the day she was scheduled to start her new job, Barr went on a racist Twitter rant that resulted in the show being swiftly cancelled. In April 2025, Friedman gave aTEDtalk, The Jokes AI Won't Tell.And in August 2025, Friedman brought her solo show, \"Motherf*cker\" to theEdinburghFringe Festival.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Jena_Friedman", "https://en.wikipedia.org/wiki/Jena_Friedman", "https://en.wikipedia.org/wiki/Jena_Friedman", "https://en.wikipedia.org/wiki/Edinburgh_Festival_Fringe", "https://en.wikipedia.org/wiki/Haddonfield,_New_Jersey", "https://en.wikipedia.org/wiki/Americans", "https://en.wikipedia.org/wiki/Comedic_genres", "https://en.wikipedia.org/wiki/Dark_comedy"]},
{"id": "6185895225e9", "url": "https://en.wikipedia.org/wiki/WDQ_(identifier)", "title": "Wikidata", "headings": ["Contents", "Concept", "Main parts", "Statements", "Properties", "Lexemes", "Entity schemas", "Content", "Development", "Initial rollout", "Statements and data access", "Query service and other improvements", "Logo", "Reception", "Applications", "See also", "Notes", "References", "Further reading", "External links"], "content": " Wikidatais acollaboratively editedmultilingualknowledge graphhosted by theWikimedia Foundation.It is a common source ofopen datathat Wikimedia projects such asWikipedia,and anyone else, are able to use under theCC0public domainlicense. Wikidata is a wiki powered by the softwareMediaWiki, including its extension forsemi-structured data, theWikibase. As of early 2025, Wikidata had 1.65 billion item statements (semantic triples). Wikidata is adocument-oriented database, focusing onitems, which represent any kind of topic, concept, or object. Each item is allocated a uniquepersistent identifiercalled itsQID, a positive integer prefixed with the upper-case letter \"Q\". This makes it possible to provide translations of the basic information describing the topic each item covers without favouring any particular language. Some examples of items and their QIDs are1988 Summer Olympics(Q8470),love(Q316),Johnny Cash(Q42775),Elvis Presley(Q303), andGorilla(Q36611). Itemlabelsdo not need to be unique. For example, there are two items named \"Elvis Presley\":Elvis Presley(Q303), which representsthe American singer and actor, andElvis Presley(Q610926), which represents hisself-titled album. However, the combination of a label and itsdescriptionmust be unique. To avoid ambiguity, an item's QID is hence linked to this combination. Fundamentally, an item consists of: Statementsare how any information known about an item is recorded in Wikidata. Formally, they consist ofkey–value pairs, which match aproperty(such as \"author\", or \"publication date\") with one or more entityvalues(such as \"Sir Arthur Conan Doyle\" or \"1902\"). For example, the informal English statement \"milk is white\" would be encoded by a statement pairing the propertycolor(P462)with the valuewhite(Q23444)under the itemmilk(Q8495). Statements may map a property to more than one value. For example, the \"occupation\" property forMarie Curiecould be linked with the values \"physicist\" and \"chemist\", to reflect the fact that she engaged in both occupations. Values may take on many types including other Wikidata items, strings, numbers, or media files. Properties prescribe what types of values they may be paired with. For example, the propertyofficial website(P856)may only be paired with values of type \"URL\". Optionally,qualifierscan be used to refine the meaning of a statement by providing additional information. For example, a \"population\" statement could be modified with a qualifier such as \"point in time (P585): 2011\" (as its own key-value pair). Values in the statements may also be annotated withreferences, pointing to a source backing up the statement's content.As with statements, all qualifiers and references are property–value pairs. Each property has a numeric identifier prefixed with a capital P and a page on Wikidata with optional label, description, aliases, and statements. As such, there are properties with the sole purpose of describing other properties, such assubproperty of(P1647). Properties may also define more complex rules about their intended usage, termedconstraints. For example, thecapital(P36)property includes a \"single value constraint\", reflecting the reality that (typically) territories have only one capital city. Constraints are treated as testing alerts and hints, rather than inviolable rules. Before a new property is created, it needs to undergo a discussion process. The most used property iscites work(P2860), which is used on more than 290,000,000 item pages as of November 2023. Inlinguistics, alexemeis a unit oflexicalmeaning representing a group of words that share the same core meaning and grammatical characteristics.Similarly, Wikidata'slexemesare items with a structure that makes them more suitable to storelexicographicaldata. Since 2016, Wikidata has supported lexicographical entries in the form of lexemes. In Wikidata, lexicographical entries have a different identifier from regular item entries. These entries are prefixed with the letter L, such as in the example entries forbookandcow. Lexicographical entries in Wikidata can contain statements, senses, and forms.The use of lexicographical entries in Wikidata allows for the documentation of word usage, the connection between words and items on Wikidata, word translations, and enables machine-readable lexicographical data. In 2020, lexicographical entries on Wikidata exceeded 250,000. The language with the most lexicographical entries wasRussian, with a total of 101,137 lexemes, followed byEnglishwith 38,122 lexemes. There are over 668 languages with lexicographical entries on Wikidata. In Wikidata, a schema is a data model that outlines the necessary attributes for a data item.For instance, a data item that uses the attribute \"instance of\" with the value \"human\" would typically include attributes such as \"place of birth,\" \"date of birth,\"\"date of death,\" and \"place of death.\"The entity schema in Wikidata utilizesShape Expression(ShEx) to describe the data in Wikidata items in the form of aResource Description Framework(RDF).The use of entity schemas in Wikidata helps address data inconsistencies and unchecked vandalism. In January 2019, development started of a new extension for MediaWiki to enable storing ShEx in a separate namespace.Entity schemas are stored with different identifiers than those used for items, properties, and lexemes. Entity schemas are stored with an \"E\" identifier, such asE10for the entity schema of human data instances andE270for the entity schema of building data instances. This extension has since been installed on Wikidataand enables contributors to use ShEx for validating and describing Resource Description Framework data in items and lexemes. Any item or lexeme on Wikidata can be validated against an entity schema,and this makes it an important tool for quality assurance. Wikidata's content collections include data for biographies,medicine,digital humanities,scholarly metadata through the WikiCite project. It includes data collections from other open projects includingFreebase. The creation of the project was funded by donations from theAllen Institute for AI, theGordon and Betty Moore Foundation, andGoogle, Inc., totaling€1.3 million.The development of the project is mainly driven byWikimedia Deutschlandunder the management ofLydia Pintscher, and was originally split into three phases: Wikidata was launched on 29 October 2012 and was the first new project of the Wikimedia Foundation since 2006.At this time,only the centralization of language links was available. This enabled items to be created and filled with basic information: a label – a name or title, aliases – alternative terms for the label, a description, and links to articles about the topic in all the various language editions of Wikipedia (interwikipedia links). Historically, a Wikipedia article would include a list of interlanguage links (links to articles on the same topic in other editions of Wikipedia, if they existed). Wikidata was originally a self-containedrepositoryof interlanguage links.Wikipedia language editions were still not able to access Wikidata, so they needed to continue to maintain their own lists of interlanguage links. On 14 January 2013, theHungarian Wikipediabecame the first to enable the provision of interlanguage links via Wikidata.This functionality was extended to theHebrewandItalianWikipedias on 30 January, to theEnglish Wikipediaon 13 February and to all other Wikipedias on 6 March.After no consensus was reached over a proposal to restrict the removal of language links from the English Wikipedia,they were automatically removed bybots. On 23 September 2013, interlanguage links went live on Wikimedia Commons. On 4 February 2013, statements were introduced to Wikidata entries. The possible values for properties were initially limited to two data types (items and images on Wikimedia Commons), with moredata types(such ascoordinatesand dates) to follow later. The first new type, string, was deployed on 6 March. The ability for the various language editions of Wikipedia to access data from Wikidata was rolled out progressively between 27 March and 25 April 2013.On 16 September 2015, Wikidata began allowing so-calledarbitrary access, or access from a given article of a Wikipedia to the statements on Wikidata items not directly connected to it. For example, it became possible to read data about Germany from the Berlin article, which was not feasible before.On 27 April 2016, arbitrary access was activated on Wikimedia Commons. According to a 2020 study, a large proportion of the data on Wikidata consists of entries imported en masse from other databases byInternet bots, which helps to \"break down the walls\" ofdata silos. On 7 September 2015, theWikimedia Foundationannounced the release of theWikidata Query Service,which lets users run queries on the data contained in Wikidata.The service usesSPARQLas the query language. As of November 2018, there are at least 26 different tools that allow querying the data in different ways.It usesBlazegraphas itstriplestoreandgraph database. In 2021,Wikimedia Deutschlandreleased the Query Builder,\"a form-based query builder to allow people who don't know how to use SPARQL\" to write a query. TheWikidata Embedding Projectwas made available in October 2025. It provides avector-basedsemantic search tool, allowing plain-language queries, and supports theModel Context Protocolstandard that makes the data more readily available to AI systems.The project is a partnership between Wikimedia Deutschland,Jina.AIandDataStax, an IBM subsidiary. The bars on thelogocontain the word \"WIKI\" encoded inMorse code.It was created by Arun Ganesh and selected through community decision. In November 2014, Wikidata received the Open Data Publisher Award from theOpen Data Institute\"for sheer scale, and built-in openness\". In December 2014, Google announced that it would shut downFreebasein favor of Wikidata. As of November 2018, Wikidata information was used in 58.4% of all English Wikipedia articles, mostly for external identifiers or coordinate locations. In aggregate, data from Wikidata is shown in 64% of allWikipedias' pages, 93% of allWikivoyagearticles, 34% of allWikiquotes', 32% of allWikisources', and 27% ofWikimedia Commons. As of December 2020, Wikidata's data was visualized by at least 20 other external toolsand over 300 papers have been published about Wikidata. A systematic literature review of the uses of Wikidata in research was carried out in 2019.", "combined_text": "Wikidata Contents Concept Main parts Statements Properties Lexemes Entity schemas Content Development Initial rollout Statements and data access Query service and other improvements Logo Reception Applications See also Notes References Further reading External links  Wikidatais acollaboratively editedmultilingualknowledge graphhosted by theWikimedia Foundation.It is a common source ofopen datathat Wikimedia projects such asWikipedia,and anyone else, are able to use under theCC0public domainlicense. Wikidata is a wiki powered by the softwareMediaWiki, including its extension forsemi-structured data, theWikibase. As of early 2025, Wikidata had 1.65 billion item statements (semantic triples). Wikidata is adocument-oriented database, focusing onitems, which represent any kind of topic, concept, or object. Each item is allocated a uniquepersistent identifiercalled itsQID, a positive integer prefixed with the upper-case letter \"Q\". This makes it possible to provide translations of the basic information describing the topic each item covers without favouring any particular language. Some examples of items and their QIDs are1988 Summer Olympics(Q8470),love(Q316),Johnny Cash(Q42775),Elvis Presley(Q303), andGorilla(Q36611). Itemlabelsdo not need to be unique. For example, there are two items named \"Elvis Presley\":Elvis Presley(Q303), which representsthe American singer and actor, andElvis Presley(Q610926), which represents hisself-titled album. However, the combination of a label and itsdescriptionmust be unique. To avoid ambiguity, an item's QID is hence linked to this combination. Fundamentally, an item consists of: Statementsare how any information known about an item is recorded in Wikidata. Formally, they consist ofkey–value pairs, which match aproperty(such as \"author\", or \"publication date\") with one or more entityvalues(such as \"Sir Arthur Conan Doyle\" or \"1902\"). For example, the informal English statement \"milk is white\" would be encoded by a statement pairing the propertycolor(P462)with the valuewhite(Q23444)under the itemmilk(Q8495). Statements may map a property to more than one value. For example, the \"occupation\" property forMarie Curiecould be linked with the values \"physicist\" and \"chemist\", to reflect the fact that she engaged in both occupations. Values may take on many types including other Wikidata items, strings, numbers, or media files. Properties prescribe what types of values they may be paired with. For example, the propertyofficial website(P856)may only be paired with values of type \"URL\". Optionally,qualifierscan be used to refine the meaning of a statement by providing additional information. For example, a \"population\" statement could be modified with a qualifier such as \"point in time (P585): 2011\" (as its own key-value pair). Values in the statements may also be annotated withreferences, pointing to a source backing up the statement's content.As with statements, all qualifiers and references are property–value pairs. Each property has a numeric identifier prefixed with a capital P and a page on Wikidata with optional label, description, aliases, and statements. As such, there are properties with the sole purpose of describing other properties, such assubproperty of(P1647). Properties may also define more complex rules about their intended usage, termedconstraints. For example, thecapital(P36)property includes a \"single value constraint\", reflecting the reality that (typically) territories have only one capital city. Constraints are treated as testing alerts and hints, rather than inviolable rules. Before a new property is created, it needs to undergo a discussion process. The most used property iscites work(P2860), which is used on more than 290,000,000 item pages as of November 2023. Inlinguistics, alexemeis a unit oflexicalmeaning representing a group of words that share the same core meaning and grammatical characteristics.Similarly, Wikidata'slexemesare items with a structure that makes them more suitable to storelexicographicaldata. Since 2016, Wikidata has supported lexicographical entries in the form of lexemes. In Wikidata, lexicographical entries have a different identifier from regular item entries. These entries are prefixed with the letter L, such as in the example entries forbookandcow. Lexicographical entries in Wikidata can contain statements, senses, and forms.The use of lexicographical entries in Wikidata allows for the documentation of word usage, the connection between words and items on Wikidata, word translations, and enables machine-readable lexicographical data. In 2020, lexicographical entries on Wikidata exceeded 250,000. The language with the most lexicographical entries wasRussian, with a total of 101,137 lexemes, followed byEnglishwith 38,122 lexemes. There are over 668 languages with lexicographical entries on Wikidata. In Wikidata, a schema is a data model that outlines the necessary attributes for a data item.For instance, a data item that uses the attribute \"instance of\" with the value \"human\" would typically include attributes such as \"place of birth,\" \"date of birth,\"\"date of death,\" and \"place of death.\"The entity schema in Wikidata utilizesShape Expression(ShEx) to describe the data in Wikidata items in the form of aResource Description Framework(RDF).The use of entity schemas in Wikidata helps address data inconsistencies and unchecked vandalism. In January 2019, development started of a new extension for MediaWiki to enable storing ShEx in a separate namespace.Entity schemas are stored with different identifiers than those used for items, properties, and lexemes. Entity schemas are stored with an \"E\" identifier, such asE10for the entity schema of human data instances andE270for the entity schema of building data instances. This extension has since been installed on Wikidataand enables contributors to use ShEx for validating and describing Resource Description Framework data in items and lexemes. Any item or lexeme on Wikidata can be validated against an entity schema,and this makes it an important tool for quality assurance. Wikidata's content collections include data for biographies,medicine,digital humanities,scholarly metadata through the WikiCite project. It includes data collections from other open projects includingFreebase. The creation of the project was funded by donations from theAllen Institute for AI, theGordon and Betty Moore Foundation, andGoogle, Inc., totaling€1.3 million.The development of the project is mainly driven byWikimedia Deutschlandunder the management ofLydia Pintscher, and was originally split into three phases: Wikidata was launched on 29 October 2012 and was the first new project of the Wikimedia Foundation since 2006.At this time,only the centralization of language links was available. This enabled items to be created and filled with basic information: a label – a name or title, aliases – alternative terms for the label, a description, and links to articles about the topic in all the various language editions of Wikipedia (interwikipedia links). Historically, a Wikipedia article would include a list of interlanguage links (links to articles on the same topic in other editions of Wikipedia, if they existed). Wikidata was originally a self-containedrepositoryof interlanguage links.Wikipedia language editions were still not able to access Wikidata, so they needed to continue to maintain their own lists of interlanguage links. On 14 January 2013, theHungarian Wikipediabecame the first to enable the provision of interlanguage links via Wikidata.This functionality was extended to theHebrewandItalianWikipedias on 30 January, to theEnglish Wikipediaon 13 February and to all other Wikipedias on 6 March.After no consensus was reached over a proposal to restrict the removal of language links from the English Wikipedia,they were automatically removed bybots. On 23 September 2013, interlanguage links went live on Wikimedia Commons. On 4 February 2013, statements were introduced to Wikidata entries. The possible values for properties were initially limited to two data types (items and images on Wikimedia Commons), with moredata types(such ascoordinatesand dates) to follow later. The first new type, string, was deployed on 6 March. The ability for the various language editions of Wikipedia to access data from Wikidata was rolled out progressively between 27 March and 25 April 2013.On 16 September 2015, Wikidata began allowing so-calledarbitrary access, or access from a given article of a Wikipedia to the statements on Wikidata items not directly connected to it. For example, it became possible to read data about Germany from the Berlin article, which was not feasible before.On 27 April 2016, arbitrary access was activated on Wikimedia Commons. According to a 2020 study, a large proportion of the data on Wikidata consists of entries imported en masse from other databases byInternet bots, which helps to \"break down the walls\" ofdata silos. On 7 September 2015, theWikimedia Foundationannounced the release of theWikidata Query Service,which lets users run queries on the data contained in Wikidata.The service usesSPARQLas the query language. As of November 2018, there are at least 26 different tools that allow querying the data in different ways.It usesBlazegraphas itstriplestoreandgraph database. In 2021,Wikimedia Deutschlandreleased the Query Builder,\"a form-based query builder to allow people who don't know how to use SPARQL\" to write a query. TheWikidata Embedding Projectwas made available in October 2025. It provides avector-basedsemantic search tool, allowing plain-language queries, and supports theModel Context Protocolstandard that makes the data more readily available to AI systems.The project is a partnership between Wikimedia Deutschland,Jina.AIandDataStax, an IBM subsidiary. The bars on thelogocontain the word \"WIKI\" encoded inMorse code.It was created by Arun Ganesh and selected through community decision. In November 2014, Wikidata received the Open Data Publisher Award from theOpen Data Institute\"for sheer scale, and built-in openness\". In December 2014, Google announced that it would shut downFreebasein favor of Wikidata. As of November 2018, Wikidata information was used in 58.4% of all English Wikipedia articles, mostly for external identifiers or coordinate locations. In aggregate, data from Wikidata is shown in 64% of allWikipedias' pages, 93% of allWikivoyagearticles, 34% of allWikiquotes', 32% of allWikisources', and 27% ofWikimedia Commons. As of December 2020, Wikidata's data was visualized by at least 20 other external toolsand over 300 papers have been published about Wikidata. A systematic literature review of the uses of Wikidata in research was carried out in 2019.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Wikidata", "https://en.wikipedia.org/wiki/Wikidata", "https://en.wikipedia.org/wiki/Wikidata", "https://en.wikipedia.org/wiki/Knowledge_base", "https://en.wikipedia.org/wiki/Wiki", "https://en.wikipedia.org/wiki/Wikimedia_Foundation", "https://en.wikipedia.org/wiki/Wikimedia_community", "https://en.wikipedia.org/wiki/Wiki"]},
{"id": "339d7b48c6d3", "url": "https://en.wikipedia.org/wiki/Brodmann_area_41_%26_42", "title": "Brodmann areas 41 and 42", "headings": ["Contents", "Function", "Additional images", "See also"], "content": "Brodmann areas 41 and 42 are parts of the primaryauditory cortex. Brodmann area41 is also known as the anterior transverse temporal area 41 (H). It is acytoarchitectonicdivision of thecerebral cortexoccupying theanteriortransverse temporal gyrus(H) in the bank of thelateral sulcuson the dorsal surface of the temporal lobe. Brodmann area 41 is bounded medially by theparainsular area 52(H) and laterally by the posterior transverse temporal area 42 (H) (Brodmann-1909). Brodmann area 42 is also known as the posterior transverse temporal area 42 (H), and is also a subdivision of the temporal lobe. Brodmann area 42 is bounded medially by the anterior transverse temporal area 41 (H) and laterally by thesuperior temporal area 22(Brodmann-1909). Brodmann areas 41 and 42 are parts of the primaryauditory cortex. This is the first cortical destination of auditory information stemming from the thalamus. Neural activity in this brain part corresponds most strongly with the objective physical properties of a sound.", "combined_text": "Brodmann areas 41 and 42 Contents Function Additional images See also Brodmann areas 41 and 42 are parts of the primaryauditory cortex. Brodmann area41 is also known as the anterior transverse temporal area 41 (H). It is acytoarchitectonicdivision of thecerebral cortexoccupying theanteriortransverse temporal gyrus(H) in the bank of thelateral sulcuson the dorsal surface of the temporal lobe. Brodmann area 41 is bounded medially by theparainsular area 52(H) and laterally by the posterior transverse temporal area 42 (H) (Brodmann-1909). Brodmann area 42 is also known as the posterior transverse temporal area 42 (H), and is also a subdivision of the temporal lobe. Brodmann area 42 is bounded medially by the anterior transverse temporal area 41 (H) and laterally by thesuperior temporal area 22(Brodmann-1909). Brodmann areas 41 and 42 are parts of the primaryauditory cortex. This is the first cortical destination of auditory information stemming from the thalamus. Neural activity in this brain part corresponds most strongly with the objective physical properties of a sound.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Brodmann_areas_41_and_42", "https://en.wikipedia.org/wiki/Brodmann_areas_41_and_42", "https://en.wikipedia.org/wiki/Brodmann_areas_41_and_42", "https://en.wikipedia.org/wiki/Coronal_section", "https://en.wikipedia.org/wiki/Cerebrum", "https://en.wikipedia.org/wiki/NeuroLex", "https://en.wikipedia.org/wiki/Anatomical_terms_of_neuroanatomy", "https://en.wikipedia.org/wiki/Auditory_cortex"]},
{"id": "a73509a23f18", "url": "https://en.wikipedia.org/wiki/Human_population_projections", "title": "Human population projections", "headings": ["Contents", "History of population projections", "19th century", "20th century", "21st century", "Drivers of population change", "Fertility", "Mortality", "Migration", "World population projections", "Up to 2050", "After 2050", "Growth regions", "Most populous nations by 2050 and 2100", "Population projections of the largest metropolitan areas", "See also", "Notes", "References"], "content": "Human population projectionsare attempts toextrapolatehowhuman populationswill change in the future.These projections are an important input toforecastsof the population's impact on this planet and humanity's future well-being.Models of population growth take trends inhuman developmentand apply projections into the future.These models use trend-based-assumptions about how populations will respond to economic, social and technological forces to understand how they will affectfertilityandmortality, and thuspopulation growth. The 2022 projections from theUnited Nations Population Division(chart #1) show that annual world population growth peaked at 2.3% per year in 1963, has since dropped to 0.9% in 2023, equivalent to about 74 million people each year, and could drop even further to minus 0.1% by 2100.Based on this, the UN projected that the world population, 8 billion as of 2023, would peak around the year 2084 at about 10.3 billion,and then start a slow decline, assuming a continuing decrease in the global averagefertility ratefrom 2.5 births per woman during the 2015–2020 period to 1.8 by the year 2100 (the medium-variant projection). However, estimates outside of the United Nations have put forward alternative models based on additional downward pressure on fertility (such as successful implementation of education and family planning goals in theUnited Nations'Sustainable Development Goals) which could result in peak population during the 2060–2070 period rather than later. According to the UN, all of the predicted growth in world population between 2020 and 2050 will come fromless developed countriesand more than half will come fromsub-Saharan Africa.Half of the growth will come from just eight countries, five of which are in Africa.The UN predicts that the population of sub-Saharan Africa will double by 2050.The Pew Research Center observes that 50% of births in the year 2100 will be in Africa.Other organizations project lower levels of population growth in Africa, based particularly on improvement in women's education and successful implementation of family planning. During the remainder of this century, some countries will see population growth and some will see population decline. For example, the UN projects thatNigeriawill gain about 340 million people, about the present population of the US, to become the third most populous country, andChinawill lose about half of its population. Even though the global fertility rate continues to fall, chart #2 shows that because ofpopulation momentumthe global population will continue to grow, although at a steadily slower rate, until the mid 2080s (the median line). The main driver of long-term future population growth on this planet is projected to be the continuing evolution offertilityandmortality. Projections of global human population are generally based on birth rates and death rates, and since these are difficult to predict very far into the future, forecasts of global population numbers and growth rates have changed over time. In 1831, president of Yale collegeJeremiah Dayincluded a United States population estimate as an example of anexponential equation. After stating that the 1820 population of the United States was 9,625,000, the projected 2020 population would be 2,464,000,000 (supposing it to double once every 25 years). Walter Greilingprojected in the 1950s that world population would reach a peak of about nine billion in the 21st century and then stop growing after an improvement inpublic healthinless developed countries. In 1992, the United Nations published five projections of long-term world population growth. According to their medium projection, the world population would grow to 10.0 billion by 2050, 11.2 billion by 2100, and 10.8 billion by 2150. Estimates published in the early 2000s tended to predict that the population of Earth would stop increasing around 2070.For example in a 2004 long-term prospective report, theUnited Nations Population Divisionprojected that world population would peak at 9.2 billion in 2075 and then stabilize at a value close to 9 billion out to as far as the year 2300. Jørgen Randers, one of the authors of the seminal 1972 long-term simulations inThe Limits to Growth, offered an alternative scenario in a 2012 book, arguing that traditional projections insufficiently take into account the downward impact of global urbanization on fertility. Randers' \"most likely scenario\" predicted a peak in world population in the early 2040s at about 8.1 billion people, followed by decline. In 2012, the UN changed its prediction to the effect that no maximum would likely be reached in the 21st century, and that by the year 2100 world population would increase to somewhere in the range 9.6 to 12.3 billion with 10.9 billion being the midpoint of that range.The main reason for the revision was a recognition that the high fertility rate inAfricawas not declining as fast as had been previously assumed. Another 2014 paper by demographers from several universities, using data from the UN's 2014 report and their own statistical methods, forecast that the world's population would reach about 10.9 billion in 2100 and continue growing thereafter. In 2017 the UN predicted that global population would reach 11.2 billion by 2100 and still be growing then at the rate of 0.1% per year.In 2019 it was updated to 10.9 billion by 2100 and still growing. The 2022 revision of the UN'sWorld Population Prospectsreportrepresents a departure from the pattern of the previous ten years, it was the first to project a peak in the 21st century. It expected that a slowing of the population growth rate will lead to a population peak of 10.4 billion in 2086 in the medium scenario, after which it would then begin to slowly fall. This shift from earlier projections of peak population and predicted date of zero population growth comes from a more rapid drop in Africa's birth rate than previous projections had expected.For example, the 2012 report predicted that the population of Nigeria, Africa's most populous country, would rise to 914 million by 2100; the 2022 report lowers that to 546 million, a reduction of 368 million; the 2024 report lowered that further to 477 million, a reduction of 69 million.Jose Rimon of Johns Hopkins University suggested, \"We have been underestimating what is happening in terms of fertility change in Africa. Africa will probably undergo the same kind of rapid changes as east Asia did.\"The 2024 edition brought the peak forward to 2084, with the population topping at 10.3 billion. A table based on UN World Population Prospects reports, using the medium fertility scenario: The population of a country or area grows or declines through the interaction of three demographic drivers: fertility, mortality, and migration. Fertility is expressed as thetotal fertility rate(TFR), a measure of the number of children on average that a woman will bear in her lifetime. Withlongevitytrending towards uniform and stable values worldwide, the main driver of future population growth will be the evolution of the fertility rate. Where fertility is high, demographers generally assume that fertility will decline and eventually stabilize at about two children per woman. During the period 2015–2020, the average world fertility rate was 2.1 children per woman, about half the level in 1950–1955 (5 children per woman). In the medium variant, global fertility is projected to decline further to 2.0 in 2045–2050 and to 1.8 in 2095–2100. If themortality rateis relatively high and the resultinglife expectancyis therefore relatively low, changes in mortality can have a material impact on population growth. When the mortality rate is low and life expectancy has therefore risen, a change in mortality has much less of an effect. Becausechild mortalityhas declined substantially over the last several decades,globallife expectancyat birth, has risen from 48 years in 1950–1955 to 67 years in 2000–2005, is expected to keep rising to reach 77 years in 2045–2050 and 83 years in 2095–2100. In the more developed regions, the projected increase is from 76 years during the period 2000–2005 to 84 years during the period 2045–2050 and 90 in 2095–2100. Among the less developed countries, where life expectancy during the period 2000–2005 was just under 66 years, it is expected to be 76 years in 2045–2050 and 81 years by 2100. Migration can have a significant effect on population change. Global south–south migration accounts for 38% of total migration, and global south–north for 34%.For example, the United Nations reports that during the period 2010–2020, fourteen countries will have seen a net inflow of more than one million migrants, while ten countries will have seen a net outflow of similar proportions. The largest migratory outflows have been in response to demand for workers in other countries (Bangladesh, Nepal, and the Philippines) or to insecurity in the home country (Myanmar, Syria, and Venezuela). Belarus, Estonia, Germany, Hungary, Italy, Japan, Russia, Serbia, and Ukraine have experienced a net inflow of migrants over the decade, helping to offset population losses caused by a negativenatural increase(births minus deaths). This section describes near-term population changes, up to the year 2050, and long-term population changes, out to the year 2100. The median scenario of the UN's 2022 World Population Prospects predicts the following populations by region in 2050 compared to population in 2000 and shows the differing growth rates for each over the first half of this century. in 2000 and in 2050 (pie chart size to scale):AsiaAfricaEuropeLatin AmericaNorthern AmericaOceania Projections of population beyond the year 2050 tend to vary depending on the organization making them because each make their own assumptions of the drivers of population change: fertility, mortality and migration. The UN Population Division report of 2022 projects world population to continue growing after 2050, although at a steadily decreasing rate, to peak at 10.4 billion in 2086, and then to start a slow decline to about 10.3 billion in 2100 with a growth rate at that time of -0.1%. This projected growth of population, like all others, depends on assumptions about vital rates. For example, the chart below shows that the UN Population Division assumes that the total fertility rate (TFR), which has been steadily declining since 1963, will continue to decline, at varying paces depending on circumstances in individual regions, to a below-replacement level of 1.8 by 2100. Between now (2020) and 2100, regions with a TFR currently below this rate, for example Europe, will see their TFR rise. Regions with a TFR above this rate will see their TFR continue to decline. Other organizations have published different forecasts. Other assumptions can produce other results. Some of the authors of the 2004 UN report assumed thatlife expectancywould rise slowly and continuously. The projections in the report assume this with no upper limit, though at a slowing pace depending on circumstances in individual countries. By 2100, the report assumed life expectancy to be from 66 to 97 years, and by 2300 from 87 to 106 years, depending on the country. Based on that assumption, they expect that rising life expectancy will produce small but continuing population growth by the end of the projections, ranging from 0.03 to 0.07 percent annually. The hypothetical feasibility (and wide availability) oflife extensionby technological means would further contribute to long term (beyond 2100) population growth. Evolutionary biologyalso suggests that thedemographic transitionmay reverse itself and global population may continue to grow in the long term.In addition, recent evidence suggests birth rates may be rising in the 21st century in the developed world.Some researchers, such as Jane N. O'Sullivan, contend that many recent population projections have underestimated population growth. She notes that in the last decades, \"support for family planning has waned, and global fertility decline has decelerated as a result\". The table below shows that from 2020 to 2050 and beyond to 2100, the bulk of the world's population growth is projected to take place inAfrica. Of the additional 1.9 billion people projected between 2020 and 2050, 1.2 billion will be added in Africa, 0.7 billion in Asia and zero in the rest of the world. Africa's share of global population is projected to grow from 17% in 2020 to 25% in 2050 and 38% by 2100, while the share of Asia will fall from 60% in 2020 to 55% in 2050 and 45% in 2100.The strong growth of the African population will happen regardless of the rate of decrease of fertility, because of the high proportion of young people already living today, who arein, or approaching, their fertile years. For example, the UN projects that the population ofNigeriawill surpass that of theUnited Statesby about 2050. (bn) 2020–2100 (bn) The population of the More Developed regions is slated to remain mostly unchanged, at 1.2-1.3 billion for the remainder of the 21st century. All population growth comes from the Less Developed regions. The table below breaks out the UN's future population growth predictions by region (%/yr) (%/yr) (%/yr) The UN projects that between 2020 and 2100 there will be declines in population growth in all six regions, that by 2100 three of them will be undergoing population decline, and the world will have entered a period of global population decline. The UN Population Division has calculated the future population of the world's countries, based on current demographic trends. The UN's 2024 report projectsworldpopulationto be 8.1 billion in 2024, about 9.6 billion in 2050, and about 10.2 billion in 2100. The following table shows the largest 15 countries by population as of 2024, 2050 and 2100 to show how the rankings will change between now and the end of this century. From 2024 to 2050, the eight highlighted countries are expected to account for about half of the world's projected population increase:India,Nigeria, theDemocratic Republic of the Congo,Pakistan,Ethiopia,Tanzania,Egypt, andIndonesia. Largeurban areasare hubs of economic development and innovation, with larger cities underpinningregional economiesand local and globalsustainabilityinitiatives. As of 2016, 757 million people live in the 101 largest cities;these cities are home to 11% of the world's population.By the end of the century, the world population is projected to grow, with estimates ranging from 6.9 billion to 13.1 billion;the percentage of people living in the 101 largest cities is estimated to be 15% to 23%. The following 101 metropolitan areas with the largest population projections for the years 2025, 2050, 2075, and 2100, according to professors Daniel Hoornweg and Kevin Pope, are listed below.", "combined_text": "Human population projections Contents History of population projections 19th century 20th century 21st century Drivers of population change Fertility Mortality Migration World population projections Up to 2050 After 2050 Growth regions Most populous nations by 2050 and 2100 Population projections of the largest metropolitan areas See also Notes References Human population projectionsare attempts toextrapolatehowhuman populationswill change in the future.These projections are an important input toforecastsof the population's impact on this planet and humanity's future well-being.Models of population growth take trends inhuman developmentand apply projections into the future.These models use trend-based-assumptions about how populations will respond to economic, social and technological forces to understand how they will affectfertilityandmortality, and thuspopulation growth. The 2022 projections from theUnited Nations Population Division(chart #1) show that annual world population growth peaked at 2.3% per year in 1963, has since dropped to 0.9% in 2023, equivalent to about 74 million people each year, and could drop even further to minus 0.1% by 2100.Based on this, the UN projected that the world population, 8 billion as of 2023, would peak around the year 2084 at about 10.3 billion,and then start a slow decline, assuming a continuing decrease in the global averagefertility ratefrom 2.5 births per woman during the 2015–2020 period to 1.8 by the year 2100 (the medium-variant projection). However, estimates outside of the United Nations have put forward alternative models based on additional downward pressure on fertility (such as successful implementation of education and family planning goals in theUnited Nations'Sustainable Development Goals) which could result in peak population during the 2060–2070 period rather than later. According to the UN, all of the predicted growth in world population between 2020 and 2050 will come fromless developed countriesand more than half will come fromsub-Saharan Africa.Half of the growth will come from just eight countries, five of which are in Africa.The UN predicts that the population of sub-Saharan Africa will double by 2050.The Pew Research Center observes that 50% of births in the year 2100 will be in Africa.Other organizations project lower levels of population growth in Africa, based particularly on improvement in women's education and successful implementation of family planning. During the remainder of this century, some countries will see population growth and some will see population decline. For example, the UN projects thatNigeriawill gain about 340 million people, about the present population of the US, to become the third most populous country, andChinawill lose about half of its population. Even though the global fertility rate continues to fall, chart #2 shows that because ofpopulation momentumthe global population will continue to grow, although at a steadily slower rate, until the mid 2080s (the median line). The main driver of long-term future population growth on this planet is projected to be the continuing evolution offertilityandmortality. Projections of global human population are generally based on birth rates and death rates, and since these are difficult to predict very far into the future, forecasts of global population numbers and growth rates have changed over time. In 1831, president of Yale collegeJeremiah Dayincluded a United States population estimate as an example of anexponential equation. After stating that the 1820 population of the United States was 9,625,000, the projected 2020 population would be 2,464,000,000 (supposing it to double once every 25 years). Walter Greilingprojected in the 1950s that world population would reach a peak of about nine billion in the 21st century and then stop growing after an improvement inpublic healthinless developed countries. In 1992, the United Nations published five projections of long-term world population growth. According to their medium projection, the world population would grow to 10.0 billion by 2050, 11.2 billion by 2100, and 10.8 billion by 2150. Estimates published in the early 2000s tended to predict that the population of Earth would stop increasing around 2070.For example in a 2004 long-term prospective report, theUnited Nations Population Divisionprojected that world population would peak at 9.2 billion in 2075 and then stabilize at a value close to 9 billion out to as far as the year 2300. Jørgen Randers, one of the authors of the seminal 1972 long-term simulations inThe Limits to Growth, offered an alternative scenario in a 2012 book, arguing that traditional projections insufficiently take into account the downward impact of global urbanization on fertility. Randers' \"most likely scenario\" predicted a peak in world population in the early 2040s at about 8.1 billion people, followed by decline. In 2012, the UN changed its prediction to the effect that no maximum would likely be reached in the 21st century, and that by the year 2100 world population would increase to somewhere in the range 9.6 to 12.3 billion with 10.9 billion being the midpoint of that range.The main reason for the revision was a recognition that the high fertility rate inAfricawas not declining as fast as had been previously assumed. Another 2014 paper by demographers from several universities, using data from the UN's 2014 report and their own statistical methods, forecast that the world's population would reach about 10.9 billion in 2100 and continue growing thereafter. In 2017 the UN predicted that global population would reach 11.2 billion by 2100 and still be growing then at the rate of 0.1% per year.In 2019 it was updated to 10.9 billion by 2100 and still growing. The 2022 revision of the UN'sWorld Population Prospectsreportrepresents a departure from the pattern of the previous ten years, it was the first to project a peak in the 21st century. It expected that a slowing of the population growth rate will lead to a population peak of 10.4 billion in 2086 in the medium scenario, after which it would then begin to slowly fall. This shift from earlier projections of peak population and predicted date of zero population growth comes from a more rapid drop in Africa's birth rate than previous projections had expected.For example, the 2012 report predicted that the population of Nigeria, Africa's most populous country, would rise to 914 million by 2100; the 2022 report lowers that to 546 million, a reduction of 368 million; the 2024 report lowered that further to 477 million, a reduction of 69 million.Jose Rimon of Johns Hopkins University suggested, \"We have been underestimating what is happening in terms of fertility change in Africa. Africa will probably undergo the same kind of rapid changes as east Asia did.\"The 2024 edition brought the peak forward to 2084, with the population topping at 10.3 billion. A table based on UN World Population Prospects reports, using the medium fertility scenario: The population of a country or area grows or declines through the interaction of three demographic drivers: fertility, mortality, and migration. Fertility is expressed as thetotal fertility rate(TFR), a measure of the number of children on average that a woman will bear in her lifetime. Withlongevitytrending towards uniform and stable values worldwide, the main driver of future population growth will be the evolution of the fertility rate. Where fertility is high, demographers generally assume that fertility will decline and eventually stabilize at about two children per woman. During the period 2015–2020, the average world fertility rate was 2.1 children per woman, about half the level in 1950–1955 (5 children per woman). In the medium variant, global fertility is projected to decline further to 2.0 in 2045–2050 and to 1.8 in 2095–2100. If themortality rateis relatively high and the resultinglife expectancyis therefore relatively low, changes in mortality can have a material impact on population growth. When the mortality rate is low and life expectancy has therefore risen, a change in mortality has much less of an effect. Becausechild mortalityhas declined substantially over the last several decades,globallife expectancyat birth, has risen from 48 years in 1950–1955 to 67 years in 2000–2005, is expected to keep rising to reach 77 years in 2045–2050 and 83 years in 2095–2100. In the more developed regions, the projected increase is from 76 years during the period 2000–2005 to 84 years during the period 2045–2050 and 90 in 2095–2100. Among the less developed countries, where life expectancy during the period 2000–2005 was just under 66 years, it is expected to be 76 years in 2045–2050 and 81 years by 2100. Migration can have a significant effect on population change. Global south–south migration accounts for 38% of total migration, and global south–north for 34%.For example, the United Nations reports that during the period 2010–2020, fourteen countries will have seen a net inflow of more than one million migrants, while ten countries will have seen a net outflow of similar proportions. The largest migratory outflows have been in response to demand for workers in other countries (Bangladesh, Nepal, and the Philippines) or to insecurity in the home country (Myanmar, Syria, and Venezuela). Belarus, Estonia, Germany, Hungary, Italy, Japan, Russia, Serbia, and Ukraine have experienced a net inflow of migrants over the decade, helping to offset population losses caused by a negativenatural increase(births minus deaths). This section describes near-term population changes, up to the year 2050, and long-term population changes, out to the year 2100. The median scenario of the UN's 2022 World Population Prospects predicts the following populations by region in 2050 compared to population in 2000 and shows the differing growth rates for each over the first half of this century. in 2000 and in 2050 (pie chart size to scale):AsiaAfricaEuropeLatin AmericaNorthern AmericaOceania Projections of population beyond the year 2050 tend to vary depending on the organization making them because each make their own assumptions of the drivers of population change: fertility, mortality and migration. The UN Population Division report of 2022 projects world population to continue growing after 2050, although at a steadily decreasing rate, to peak at 10.4 billion in 2086, and then to start a slow decline to about 10.3 billion in 2100 with a growth rate at that time of -0.1%. This projected growth of population, like all others, depends on assumptions about vital rates. For example, the chart below shows that the UN Population Division assumes that the total fertility rate (TFR), which has been steadily declining since 1963, will continue to decline, at varying paces depending on circumstances in individual regions, to a below-replacement level of 1.8 by 2100. Between now (2020) and 2100, regions with a TFR currently below this rate, for example Europe, will see their TFR rise. Regions with a TFR above this rate will see their TFR continue to decline. Other organizations have published different forecasts. Other assumptions can produce other results. Some of the authors of the 2004 UN report assumed thatlife expectancywould rise slowly and continuously. The projections in the report assume this with no upper limit, though at a slowing pace depending on circumstances in individual countries. By 2100, the report assumed life expectancy to be from 66 to 97 years, and by 2300 from 87 to 106 years, depending on the country. Based on that assumption, they expect that rising life expectancy will produce small but continuing population growth by the end of the projections, ranging from 0.03 to 0.07 percent annually. The hypothetical feasibility (and wide availability) oflife extensionby technological means would further contribute to long term (beyond 2100) population growth. Evolutionary biologyalso suggests that thedemographic transitionmay reverse itself and global population may continue to grow in the long term.In addition, recent evidence suggests birth rates may be rising in the 21st century in the developed world.Some researchers, such as Jane N. O'Sullivan, contend that many recent population projections have underestimated population growth. She notes that in the last decades, \"support for family planning has waned, and global fertility decline has decelerated as a result\". The table below shows that from 2020 to 2050 and beyond to 2100, the bulk of the world's population growth is projected to take place inAfrica. Of the additional 1.9 billion people projected between 2020 and 2050, 1.2 billion will be added in Africa, 0.7 billion in Asia and zero in the rest of the world. Africa's share of global population is projected to grow from 17% in 2020 to 25% in 2050 and 38% by 2100, while the share of Asia will fall from 60% in 2020 to 55% in 2050 and 45% in 2100.The strong growth of the African population will happen regardless of the rate of decrease of fertility, because of the high proportion of young people already living today, who arein, or approaching, their fertile years. For example, the UN projects that the population ofNigeriawill surpass that of theUnited Statesby about 2050. (bn) 2020–2100 (bn) The population of the More Developed regions is slated to remain mostly unchanged, at 1.2-1.3 billion for the remainder of the 21st century. All population growth comes from the Less Developed regions. The table below breaks out the UN's future population growth predictions by region (%/yr) (%/yr) (%/yr) The UN projects that between 2020 and 2100 there will be declines in population growth in all six regions, that by 2100 three of them will be undergoing population decline, and the world will have entered a period of global population decline. The UN Population Division has calculated the future population of the world's countries, based on current demographic trends. The UN's 2024 report projectsworldpopulationto be 8.1 billion in 2024, about 9.6 billion in 2050, and about 10.2 billion in 2100. The following table shows the largest 15 countries by population as of 2024, 2050 and 2100 to show how the rankings will change between now and the end of this century. From 2024 to 2050, the eight highlighted countries are expected to account for about half of the world's projected population increase:India,Nigeria, theDemocratic Republic of the Congo,Pakistan,Ethiopia,Tanzania,Egypt, andIndonesia. Largeurban areasare hubs of economic development and innovation, with larger cities underpinningregional economiesand local and globalsustainabilityinitiatives. As of 2016, 757 million people live in the 101 largest cities;these cities are home to 11% of the world's population.By the end of the century, the world population is projected to grow, with estimates ranging from 6.9 billion to 13.1 billion;the percentage of people living in the 101 largest cities is estimated to be 15% to 23%. The following 101 metropolitan areas with the largest population projections for the years 2025, 2050, 2075, and 2100, according to professors Daniel Hoornweg and Kevin Pope, are listed below.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Human_population_projections", "https://en.wikipedia.org/wiki/Human_population_projections", "https://en.wikipedia.org/wiki/Human_population_projections", "https://en.wikipedia.org/wiki/Extrapolate", "https://en.wikipedia.org/wiki/Human_populations", "https://en.wikipedia.org/wiki/Forecasting", "https://en.wikipedia.org/wiki/Human_development_(economics)", "https://en.wikipedia.org/wiki/Total_fertility_rate"]},
{"id": "05b7eb3ad458", "url": "https://en.wikipedia.org/wiki/Honpa_Hongwanji_Mission_of_Hawaii", "title": "Honpa Hongwanji Mission of Hawaii", "headings": ["Contents", "History", "Locations", "Oahu", "Hawaii (Big Island)", "Maui", "Kauai", "See also", "References", "External links"], "content": "TheHonpa Hongwanji Mission of Hawaii(Japanese:本派本願寺ハワイ別院,Honpa Honganji Hawai Betsuin) is a district of the Nishi (West)Hongwanjibranch ofJodo ShinshuBuddhism, a school ofMahayanaPure LandBuddhism. Jodo Shinshu Buddhism was established in Hawaii as a result of the immigration ofJapanese peopleto work thesugarcaneplantations in Hawaii. The first Hongwanji temple in theHawaiian Islandswas dedicated on March 3, 1889.In 1897, theNishi HongwanjiinKyoto, Japanbegan sending official ministers to establish temples for Japanese immigrants in Hawaii and the mainland United States.The first was Kenjun Miyamoto, who laid the groundwork for the ministry. Honi Satomi was the first priest, serving from 1898 until 1900, when he returned to Japan.Yemyo Imamuratook over for Satomi in 1900, and served until his death in 1932. Since these early days, 36 temples have been established across the Hawaiian Islands, including the Honpa Hongwanji Hawaii Betsuin and the Honpa Hongwanji Hilo Betsuin. The mission operates theHongwanji Mission SchoolandPacific Buddhist Academy.It is administered separately from theBuddhist Churches of America, the umbrella organization of Jodo Shinshu temples in the continentalUnited States. In 1976, insurance executive Paul Yamanaka went to Yoshiaki Fujitani, Bishop of the Mission, with the idea to create a program called \"Living Treasures of Hawai'i\" modeled after the Living National Treasures program of Japan.The purpose of the award is to recognize and honor persons who have demonstrated excellence and high standards of achievement in their particular fields of endeavor and have made significant contributions to humanity toward a more fraternal society.Any person can nominate an individual for the award. This program has honored more than 100 community members to date. Headquarters of the Honpa Hongwanji Mission of Hawaii are located inHonolulu. The following is a list of the organization's affiliated temples.", "combined_text": "Honpa Hongwanji Mission of Hawaii Contents History Locations Oahu Hawaii (Big Island) Maui Kauai See also References External links TheHonpa Hongwanji Mission of Hawaii(Japanese:本派本願寺ハワイ別院,Honpa Honganji Hawai Betsuin) is a district of the Nishi (West)Hongwanjibranch ofJodo ShinshuBuddhism, a school ofMahayanaPure LandBuddhism. Jodo Shinshu Buddhism was established in Hawaii as a result of the immigration ofJapanese peopleto work thesugarcaneplantations in Hawaii. The first Hongwanji temple in theHawaiian Islandswas dedicated on March 3, 1889.In 1897, theNishi HongwanjiinKyoto, Japanbegan sending official ministers to establish temples for Japanese immigrants in Hawaii and the mainland United States.The first was Kenjun Miyamoto, who laid the groundwork for the ministry. Honi Satomi was the first priest, serving from 1898 until 1900, when he returned to Japan.Yemyo Imamuratook over for Satomi in 1900, and served until his death in 1932. Since these early days, 36 temples have been established across the Hawaiian Islands, including the Honpa Hongwanji Hawaii Betsuin and the Honpa Hongwanji Hilo Betsuin. The mission operates theHongwanji Mission SchoolandPacific Buddhist Academy.It is administered separately from theBuddhist Churches of America, the umbrella organization of Jodo Shinshu temples in the continentalUnited States. In 1976, insurance executive Paul Yamanaka went to Yoshiaki Fujitani, Bishop of the Mission, with the idea to create a program called \"Living Treasures of Hawai'i\" modeled after the Living National Treasures program of Japan.The purpose of the award is to recognize and honor persons who have demonstrated excellence and high standards of achievement in their particular fields of endeavor and have made significant contributions to humanity toward a more fraternal society.Any person can nominate an individual for the award. This program has honored more than 100 community members to date. Headquarters of the Honpa Hongwanji Mission of Hawaii are located inHonolulu. The following is a list of the organization's affiliated temples.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Honpa_Hongwanji_Mission_of_Hawaii", "https://en.wikipedia.org/wiki/Honpa_Hongwanji_Mission_of_Hawaii", "https://en.wikipedia.org/wiki/Honpa_Hongwanji_Mission_of_Hawaii", "https://en.wikipedia.org/wiki/Japanese_language", "https://en.wikipedia.org/wiki/Hongwanji", "https://en.wikipedia.org/wiki/Jodo_Shinshu", "https://en.wikipedia.org/wiki/Mahayana", "https://en.wikipedia.org/wiki/Pure_Land"]},
{"id": "b30453952238", "url": "https://en.wikipedia.org/wiki/Northern_and_Shell_Media", "title": "Northern & Shell", "headings": ["Contents", "History", "Building", "References"], "content": "Northern & Shell(holding company name Northern and Shell Network Ltd) was a Britishpublishinggroup, founded in December 1974 and owned since then byRichard Desmond. Formerly a publisher of pornographic magazines includingPenthouseandAsian Babes,it published theDaily Express,Sunday Express,Daily StarandDaily Star Sunday, and the magazinesOK!,New!andStaruntil these were sold toTrinity Mirrorin February 2018. Northern & Shell also owned three entertainmenttelevision channels:Channel 5,5*and5USAuntil 2015. It ownedPortland TV,which operatespornographicTV channels includingTelevision XandRed Hot TV; the company sold Portland in April 2016. Northern & Shell has operatedThe Health Lotteryin the UK since it launched in 2011. Desmond founded Northern & Shell in 1974 and launched a magazine calledInternational Musician and Recording World. In 1983, Northern & Shell obtained the licence to publishPenthousein the United Kingdom which led to its publishing a range of pornographic titles,Asian Babesamong them.The company's business model for pornographic magazines focussed on specialisation and niche publishing, with multiple titles produced at low cost and targeted at particular tastes.These titles were later sold in 2004. It was the first company to move to the revampedDocklandsand thePrincess Royalopened the offices. When the company moved to the Northern & Shell Tower inCanary Wharf, theDuke of Edinburghopened the offices. In the early 1990s Northern & Shell began to publish a wider range of magazines, including comics and the gay lifestyle magazineAttitude. Other titles wereFor Women, a women's magazine launched in 1992 in the style ofCosmopolitanbut with nude male photosets, and the celebrity weeklyOK!,which started as a monthly in 1993. By 1996, the pornographic subsidiary, Fantasy Publications, claimed to be selling 1.5 million copies a month of magazines such asAmateur Video,Real Wives,New TalentandPenthouse.In November 2000, Northern & Shell acquired Express Newspapers fromUnited News & Mediafor £125 million,enlarging the group to include theDailyandSunday Expresstitles, theDaily StarandDaily Star Sunday(which Desmond started), and theIrish Star(owned jointly with the Irish Independent group). TheDailyandSunday Expresseach sell around 700,000 copies per issue.Northern & Shell had borrowed £97 million (approximately US$190 million) for the Express group purchase. Northern & Shell's \"portfolio\" of soft-porn magazines was offered for sale in 2001 in order to provide cash to invest in the then newly acquired Express Newspapers group. Some viewed the sale as an attempt to distance the company from the pornography business, but most analysts believed it to be only a financial move asThe Fantasy Channel, Northern and Shell's adult cable channel, wasn't included in the sale. In 2004, Northern & Shell sought acquisition of additional publications —The SpectatorandThe Daily Telegraph, along with its sister publicationThe Sunday Telegraph. It was unsuccessful in its bid forThe Telegraph, losing out toDavid and Frederick Barclay, who had long sought to own the paper. On 23 July 2010, Northern & Shell bought Channel 5 Broadcasting Limited, which operatesChannel 5,5*and5USAfor €125 million (£103.5 million) from theRTL Group.On 1 May 2014, the channels were sold toViacomfor £450 million (US$759 million). In 2013, Northern & Shell announced that its TV listing magazineTV Pickwould no longer be published. In 2014, Northern & Shell invested in a series of startups under the brand Northern & Shell Ventures.This included investments inOpenRent, Tepilo and Lulu. In February 2018,Trinity Mirrorpurchased Northern & Shell's publishing operations (titles including theDaily Express,Sunday Express,Daily StarandDaily Star Sunday; and three celebrity magazines,OK!,New!, andStar) for £126.7 million. The building at 10 Lower Thames Street was built in 1985and has a distinctive blue glass facade. It is next door to the oldBillingsgatefish market and was first built forSamuel Montagu & Co.It is now partly occupied by N&S and partly rented out as serviced offices. The building featured in the TV series Bergerac, Series 6 Episode 6 \"A man of sorrows\", the building frontage badged as Insurance company Norman Deutscher Greenburg. Inside the building features some interior lifts with panoramic views overlooking the foyer. ", "combined_text": "Northern & Shell Contents History Building References Northern & Shell(holding company name Northern and Shell Network Ltd) was a Britishpublishinggroup, founded in December 1974 and owned since then byRichard Desmond. Formerly a publisher of pornographic magazines includingPenthouseandAsian Babes,it published theDaily Express,Sunday Express,Daily StarandDaily Star Sunday, and the magazinesOK!,New!andStaruntil these were sold toTrinity Mirrorin February 2018. Northern & Shell also owned three entertainmenttelevision channels:Channel 5,5*and5USAuntil 2015. It ownedPortland TV,which operatespornographicTV channels includingTelevision XandRed Hot TV; the company sold Portland in April 2016. Northern & Shell has operatedThe Health Lotteryin the UK since it launched in 2011. Desmond founded Northern & Shell in 1974 and launched a magazine calledInternational Musician and Recording World. In 1983, Northern & Shell obtained the licence to publishPenthousein the United Kingdom which led to its publishing a range of pornographic titles,Asian Babesamong them.The company's business model for pornographic magazines focussed on specialisation and niche publishing, with multiple titles produced at low cost and targeted at particular tastes.These titles were later sold in 2004. It was the first company to move to the revampedDocklandsand thePrincess Royalopened the offices. When the company moved to the Northern & Shell Tower inCanary Wharf, theDuke of Edinburghopened the offices. In the early 1990s Northern & Shell began to publish a wider range of magazines, including comics and the gay lifestyle magazineAttitude. Other titles wereFor Women, a women's magazine launched in 1992 in the style ofCosmopolitanbut with nude male photosets, and the celebrity weeklyOK!,which started as a monthly in 1993. By 1996, the pornographic subsidiary, Fantasy Publications, claimed to be selling 1.5 million copies a month of magazines such asAmateur Video,Real Wives,New TalentandPenthouse.In November 2000, Northern & Shell acquired Express Newspapers fromUnited News & Mediafor £125 million,enlarging the group to include theDailyandSunday Expresstitles, theDaily StarandDaily Star Sunday(which Desmond started), and theIrish Star(owned jointly with the Irish Independent group). TheDailyandSunday Expresseach sell around 700,000 copies per issue.Northern & Shell had borrowed £97 million (approximately US$190 million) for the Express group purchase. Northern & Shell's \"portfolio\" of soft-porn magazines was offered for sale in 2001 in order to provide cash to invest in the then newly acquired Express Newspapers group. Some viewed the sale as an attempt to distance the company from the pornography business, but most analysts believed it to be only a financial move asThe Fantasy Channel, Northern and Shell's adult cable channel, wasn't included in the sale. In 2004, Northern & Shell sought acquisition of additional publications —The SpectatorandThe Daily Telegraph, along with its sister publicationThe Sunday Telegraph. It was unsuccessful in its bid forThe Telegraph, losing out toDavid and Frederick Barclay, who had long sought to own the paper. On 23 July 2010, Northern & Shell bought Channel 5 Broadcasting Limited, which operatesChannel 5,5*and5USAfor €125 million (£103.5 million) from theRTL Group.On 1 May 2014, the channels were sold toViacomfor £450 million (US$759 million). In 2013, Northern & Shell announced that its TV listing magazineTV Pickwould no longer be published. In 2014, Northern & Shell invested in a series of startups under the brand Northern & Shell Ventures.This included investments inOpenRent, Tepilo and Lulu. In February 2018,Trinity Mirrorpurchased Northern & Shell's publishing operations (titles including theDaily Express,Sunday Express,Daily StarandDaily Star Sunday; and three celebrity magazines,OK!,New!, andStar) for £126.7 million. The building at 10 Lower Thames Street was built in 1985and has a distinctive blue glass facade. It is next door to the oldBillingsgatefish market and was first built forSamuel Montagu & Co.It is now partly occupied by N&S and partly rented out as serviced offices. The building featured in the TV series Bergerac, Series 6 Episode 6 \"A man of sorrows\", the building frontage badged as Insurance company Norman Deutscher Greenburg. Inside the building features some interior lifts with panoramic views overlooking the foyer.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Northern_%26_Shell", "https://en.wikipedia.org/wiki/Northern_%26_Shell", "https://en.wikipedia.org/wiki/Northern_%26_Shell", "https://en.wikipedia.org/wiki/Tower_42", "https://en.wikipedia.org/wiki/20_Fenchurch_Street", "https://en.wikipedia.org/wiki/Limited_company", "https://en.wikipedia.org/wiki/Richard_Desmond", "https://en.wikipedia.org/wiki/Thames_Street,_London"]},
{"id": "82bee1c0f111", "url": "https://en.wikipedia.org/wiki/Verena", "title": "Verena of Zurzach", "headings": ["Contents", "Legend", "Veneration", "In popular culture", "References", "External links"], "content": "Verena of Zurzach, also known asSaint Verena(c.260 –c.344),was an early Christianconsecrated virginandhermit. She isveneratedas asaintin theEastern Orthodox Church,Roman Catholic ChurchandOriental Orthodox Churches. She is especially venerated inSwitzerland, where hercultis attested inBad Zurzach, the reported place of her burial, from at least the 5th century. Her feast is on 1 September. The oldest tradition of the life of Verena is found in the so-calledVita priorbyHatto, theabbotofReichenau(and laterbishopofMainz), written in c. 888. The youngerVita posteriorwas most likely written by a monk in Zurzach in the 11th century, the oldest extant copy dating to the 12th century. According to Hatto's account, Verena was born inThebesas the daughter of a notable Christian family. She was educated by a bishop named Chaeremon (Vita prior, ch. 3).\nA bishop Chaeremon of Nilopolis is mentioned byEusebiusas martyred in 250, which would place Verena's birth before that date. After the death of Chaeremon, Verena travelled to Lower Egypt with a group of Christians, where theTheban Legionwas being recruited. With the Theban Legion, she then travelled toMilan(Vita priorch. 4). While still in Milan, she heard of the martyrdom of the Theban Legion (an event of uncertain historicity, traditionally dated to 286, during the reign ofMaximian) and travelled toAgaunum(Saint-Maurice). In later sources, she is said to have buried the martyred legionnaires. Verena then moved on to Salodurum (Solothurn) in ahermitage, and spent her days in fasting and prayer, and working miracles. Hatto presents her as aprototypeof theconsecrated virgin, saying that she attracted a following of young virgins. She was at one point imprisoned by a local governor, andSaint Mauriceappeared to her in jail to console and strengthen her. After she was released, she continued her good works. At the end of her natural days, she retired into a narrow cave. The year of her death was calculated as 344 by Johannes Laurentius Huber (1812–1879),provostat Verenamünster in Zurzach.If her birth before 250 is accepted (based on the identification of her mentor, bishop Chaeremon), this would imply that she was more than 95 years old at the time of her death. The VerenaMinsterin Zurzach was built over the grave of Saint Verena in a Roman cemetery. Her cult became widespread from the 12th century, and Verena was one of the most venerated saints inmedieval Switzerland.ABenedictineabbeyexisted in the 10th century at the site of her burial inBad Zurzach. Themonasterywas replaced by acollegiate churchat some time before 1265, with Saint Verena as itspatroness. In southern Germany, a chapel dedicated to her was present at the site of the minster ofSalem Abbeyin 1137. Theminsterthere includes a niche dedicated to her. TheconventofbeguinesinZürich, established in the mid-13th century, had a chapel dedicated to St. Verena. Verena is often portrayed as amatronwith either bread, or a jar of water in one hand, and a comb in the other, symbols of her care for the poor andlepers. The given nameVerenais not recorded outside of the context of this saint; it has been associated with the nameBerenice(i.e.Veronica).\nIn reference to the saint, Verena came to be a commonly given feminine name in Switzerland, inhypocoristicform [Vreni\" becoming an almostarchetypicallySwiss girls' name (cf.diminutive\"Vreneli\"). \nThe nameVerenaorVreneliwas also transferred to numerous female figures in Swissfolklore and mythology; notable among these is theVrenelisgärtli(\"Verena's garden\") glacier of theGlärnischmassif. TheVerena Gorge Hermitagenorth of Solothurn, ostensibly the site of Verena'shermitage, is known to have been in existence since the 12th century (the older of the two chapels has foundations of the 12th century). The presence of a resident hermit is recorded for 1442. The site featuresStations of the Crossdating from 1613 (restored around 1990). In the 18th century, the gorge was developed as a landscape garden in the style ofRomanticism, notably due to the advocacy of French diplomatLouis Auguste Le Tonnelier de Breteuil. During 1810–1813, the footpath along the gorge was further developed as a partly Roman Catholicpilgrimagesite, and a partly national romantic shrine for the patriciate of Solothurn. In a century-old tradition, the resident hermit is provided for by theBürgergemeindeof the city of Solothurn. The municipality ofStäfaatLake Zürichdisplays Verena in itscoat of arms, from the coat of arms of Stäfabailiwickin use since 1526. In 1986, a delegation from Saint Verena's Church inSwitzerland, brought a part of Saint Verena'srelicstoEgypt. The firstCopticchurchconsecratedin the name of Saint Verena is Saint Maurice and Saint Verena's Church inCairo, which was consecrated byPope Shenouda IIIon 22 February 1994. In October 2004, a delegation from theDiocese of Los Angelesin the United States of America, along withMetropolitan Serapionof Los Angeles, Fr. Joseph Boules and Fr. Gregory Bishay travelled to Switzerland to bring a part of Saint Verena's relics to her churches in Anaheim and Orange. The Anaheim church, now located inYorba Linda, California,now has a shrine dedicated to her relic, as well as the church in Orange. There are numerous references to her as a paragon of Christian patience in the face of adversity in Charlotte M. Yonge's romantic novelThe Heir of Redclyffe(1853).", "combined_text": "Verena of Zurzach Contents Legend Veneration In popular culture References External links Verena of Zurzach, also known asSaint Verena(c.260 –c.344),was an early Christianconsecrated virginandhermit. She isveneratedas asaintin theEastern Orthodox Church,Roman Catholic ChurchandOriental Orthodox Churches. She is especially venerated inSwitzerland, where hercultis attested inBad Zurzach, the reported place of her burial, from at least the 5th century. Her feast is on 1 September. The oldest tradition of the life of Verena is found in the so-calledVita priorbyHatto, theabbotofReichenau(and laterbishopofMainz), written in c. 888. The youngerVita posteriorwas most likely written by a monk in Zurzach in the 11th century, the oldest extant copy dating to the 12th century. According to Hatto's account, Verena was born inThebesas the daughter of a notable Christian family. She was educated by a bishop named Chaeremon (Vita prior, ch. 3).\nA bishop Chaeremon of Nilopolis is mentioned byEusebiusas martyred in 250, which would place Verena's birth before that date. After the death of Chaeremon, Verena travelled to Lower Egypt with a group of Christians, where theTheban Legionwas being recruited. With the Theban Legion, she then travelled toMilan(Vita priorch. 4). While still in Milan, she heard of the martyrdom of the Theban Legion (an event of uncertain historicity, traditionally dated to 286, during the reign ofMaximian) and travelled toAgaunum(Saint-Maurice). In later sources, she is said to have buried the martyred legionnaires. Verena then moved on to Salodurum (Solothurn) in ahermitage, and spent her days in fasting and prayer, and working miracles. Hatto presents her as aprototypeof theconsecrated virgin, saying that she attracted a following of young virgins. She was at one point imprisoned by a local governor, andSaint Mauriceappeared to her in jail to console and strengthen her. After she was released, she continued her good works. At the end of her natural days, she retired into a narrow cave. The year of her death was calculated as 344 by Johannes Laurentius Huber (1812–1879),provostat Verenamünster in Zurzach.If her birth before 250 is accepted (based on the identification of her mentor, bishop Chaeremon), this would imply that she was more than 95 years old at the time of her death. The VerenaMinsterin Zurzach was built over the grave of Saint Verena in a Roman cemetery. Her cult became widespread from the 12th century, and Verena was one of the most venerated saints inmedieval Switzerland.ABenedictineabbeyexisted in the 10th century at the site of her burial inBad Zurzach. Themonasterywas replaced by acollegiate churchat some time before 1265, with Saint Verena as itspatroness. In southern Germany, a chapel dedicated to her was present at the site of the minster ofSalem Abbeyin 1137. Theminsterthere includes a niche dedicated to her. TheconventofbeguinesinZürich, established in the mid-13th century, had a chapel dedicated to St. Verena. Verena is often portrayed as amatronwith either bread, or a jar of water in one hand, and a comb in the other, symbols of her care for the poor andlepers. The given nameVerenais not recorded outside of the context of this saint; it has been associated with the nameBerenice(i.e.Veronica).\nIn reference to the saint, Verena came to be a commonly given feminine name in Switzerland, inhypocoristicform [Vreni\" becoming an almostarchetypicallySwiss girls' name (cf.diminutive\"Vreneli\"). \nThe nameVerenaorVreneliwas also transferred to numerous female figures in Swissfolklore and mythology; notable among these is theVrenelisgärtli(\"Verena's garden\") glacier of theGlärnischmassif. TheVerena Gorge Hermitagenorth of Solothurn, ostensibly the site of Verena'shermitage, is known to have been in existence since the 12th century (the older of the two chapels has foundations of the 12th century). The presence of a resident hermit is recorded for 1442. The site featuresStations of the Crossdating from 1613 (restored around 1990). In the 18th century, the gorge was developed as a landscape garden in the style ofRomanticism, notably due to the advocacy of French diplomatLouis Auguste Le Tonnelier de Breteuil. During 1810–1813, the footpath along the gorge was further developed as a partly Roman Catholicpilgrimagesite, and a partly national romantic shrine for the patriciate of Solothurn. In a century-old tradition, the resident hermit is provided for by theBürgergemeindeof the city of Solothurn. The municipality ofStäfaatLake Zürichdisplays Verena in itscoat of arms, from the coat of arms of Stäfabailiwickin use since 1526. In 1986, a delegation from Saint Verena's Church inSwitzerland, brought a part of Saint Verena'srelicstoEgypt. The firstCopticchurchconsecratedin the name of Saint Verena is Saint Maurice and Saint Verena's Church inCairo, which was consecrated byPope Shenouda IIIon 22 February 1994. In October 2004, a delegation from theDiocese of Los Angelesin the United States of America, along withMetropolitan Serapionof Los Angeles, Fr. Joseph Boules and Fr. Gregory Bishay travelled to Switzerland to bring a part of Saint Verena's relics to her churches in Anaheim and Orange. The Anaheim church, now located inYorba Linda, California,now has a shrine dedicated to her relic, as well as the church in Orange. There are numerous references to her as a paragon of Christian patience in the face of adversity in Charlotte M. Yonge's romantic novelThe Heir of Redclyffe(1853).", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Verena_of_Zurzach", "https://en.wikipedia.org/wiki/Verena_of_Zurzach", "https://en.wikipedia.org/wiki/Verena_of_Zurzach", "https://en.wikipedia.org/wiki/Verena_(disambiguation)", "https://en.wikipedia.org/wiki/Saint", "https://en.wikipedia.org/wiki/Russian_Orthodox", "https://en.wikipedia.org/wiki/Icon", "https://en.wikipedia.org/wiki/Thebes,_Egypt"]},
{"id": "b1b653d51015", "url": "https://en.wikipedia.org/wiki/Proto-Greek_language", "title": "Proto-Greek language", "headings": ["Contents", "Origins", "Diversification", "Phonology", "Phonemes", "Proto-Greek changes", "Post-Proto-Greek changes", "Morphology", "Nouns", "Pronouns", "Verbs", "Numerals", "Summary of numerals in Proto-Hellenic", "See also", "Footnotes", "References", "Further reading"], "content": " Extant Extinct Reconstructed Hypothetical Grammar Other Mainstream Alternative and fringe Pontic Steppe Caucasus East Asia Eastern Europe Northern Europe Bronze AgePontic Steppe Northern/Eastern Steppe Europe South Asia Iron AgeSteppe Europe Caucasus Central Asia India Iron AgeIndo-Aryans Iranians Nuristanis East Asia Europe Middle AgesEast Asia Europe Indo-Aryan Iranian Historical Indo-Aryan Iranian Others European Practices Institutes Publications TheProto-Greek language(also known asProto-Hellenic) is theIndo-European languagewhich was the last common ancestor of all varieties ofGreek, includingMycenaean Greek, the subsequentancient Greek dialects(i.e.,Attic,Ionic,Aeolic,Doric,Arcadocypriot, andancient Macedonian—either a dialect or a closely relatedHellenic language) and, ultimately,Koine,ByzantineandModern Greek(along with itsvariants). Proto-Greek speakers entered Greece sometime between 2200 and 1900BC,with the diversification into a southern and a northern group beginning by approximately 1700BC. Proto-Greek emerged from the diversification of the lateProto-Indo-European language(PIE); a process whose last phase gave rise to the later language families and occurredc.2500 BC.Pre-Proto-Greek, the Indo-European dialect from which Proto-Greek originated, emergedc.2400– c.2200 BC, in an area which bordered pre-Proto-Indo-Iranianto the east and pre-Proto-Armenianand pre-Proto-Phrygianto the west, at the eastern borders of southeastern Europe; according to theKurgan hypothesis.Speakers of what would become Proto-Greek,migratedfrom theirhomeland(which could have been northeast of theBlack Sea), and reached Greece in a date set around the transition of the Early Bronze Age to the Middle Bronze Age.The evolution of Proto-Greek could be considered within the context of an earlyPaleo-Balkansprachbundthat makes it difficult to delineate exact boundaries between individual languages.The characteristically Greek representation of word-initiallaryngealsbyprothetic vowelsis shared, for one, with theArmenian language, which also seems to share some other phonological and morphological peculiarities of Greek; this has led some linguists to propose ahypothetically closer relationship between Greek and Armenian, although evidence remains scant. According to Filos (2014), the emergence of Proto-Greek was a long and continuous linguistic evolution, as the predecessors of Greek speakers were migrating towards the outskirts of Greece, somewhere to the north(-west) of the Greek peninsula proper, where they eventually merged with pre-Greek populations to form the Proto-Greek language.A. L. Katona (2000) places the beginning of the migration from Ukraine towards the southc.2400– c.2300 BC. Their proposed route of migration passed through Romania and the eastern Balkans to theEvrosriver valley from where their main body moved west.As such Katona as well as M.V Sakellariou agree that the main body of Greek speakers settled in a region that included southwestern Illyria, Epirus, northwestern Thessaly and western Macedonia. Older theories like those ofVladimir I. Georgievplaced Proto-Greek in northwestern Greece and adjacent areas (approximately up to the Aulon river to the north), includingParauaea,Tymphaia,Athamania,Dolopia,Amphilochia, andAcarnania, as well as west and northThessaly(Histiaeotis,Perrhaibia,Tripolis), and Pieria in Macedonia, during theLate Neolithic.The boundaries are based on the high concentration of archaic Greek place-names in the region, in contrast to southern Greece which preserves manypre-Greek.Radoslav Katičićconsidered these findings highly significant, and agreed that due to the minimal traces of pre-Greek toponymy in the region, Epirus and western Thessaly must have formed the region of concentration of Proto-Greek speakers, before their spread southwards.However, the dating of proto-Greek in Bronze Age Greece is compatible with the inherited lexicon from the commonProto-Indo-European language, which excludes any possibility of it being present inNeolithic Greece. In modern bibliography, models about the settlement and development of proto-Greek speakers in the Greek peninsula place it in the region at the earliest around 2200–2000 BC, during the Early Helladic III.Asko Parpola and Christian Carpelan (2005) date the arrival of Proto-Greek speakers into the Greek peninsula to 2200BC,whileCarl Blegen(1928) dates it toc.1900 BC. Ivo Hajnaldates the beginning of the diversification of Proto-Greek into the subsequent Greek dialects to a point not significantly earlier than 1700BC.The conventional division of the Greek dialects prior to 1955 differentiated them between a West Greek (consisting of Doric and Northwest Greek) and an East Greek (consisting of Aeolic, Arcado-Cypriot, and Attic-Ionic) group. However, after the decipherment of theLinear Bscript, Walter Porzig andErnst Rischargued for a division between a Northern (consisting of Doric, Northwest Greek, and Aeolic) and a Southern (consisting of Mycenaean, Arcado-Cypriot, and Attic-Ionic) group, which remains fundamental until today. During this period ofc.1700 BC, South Greek-speaking tribes spread to Boeotia, Attica, and the Peloponnese, while North Greek was spoken in Epirus, Thessaly, parts of Central Greece, and perhaps also Macedonia. Proto-Greek is reconstructed with the following phonemes:  The primary sound changes separating Proto-Greek from theProto-Indo-European languageinclude the following. Major changes included: Grassmann's lawwas a process ofdissimilationin words containing multiple aspirates. It caused an initial aspirated sound to lose its aspiration when a following aspirated consonant occurred in the same word. It was a relatively late change in Proto-Greek history, and must have occurred independentlyof the similar dissimilation of aspirates (also known asGrassmann's law) inIndo-Iranian, although it may represent a commonareal feature. The change may have even been post-Mycenaean: Greek is unique among Indo-European languages in reflecting the three differentlaryngealswith distinct vowels. Most Indo-European languages can be traced back to a dialectal variety of late Proto-Indo-European (PIE) in which all three laryngeals had merged (after colouring adjacent short/e/vowels), but Greek clearly cannot. For that reason, Greek is extremely important in reconstructing PIE forms. Greek shows distinct reflexes of the laryngeals in various positions: All of the cases may stem from an early insertion of/e/next to a laryngeal not adjacent to a vowel in the Indo-European dialect ancestral to Greek (subsequently coloured to/e/,/a/,/o/by the particular laryngeal in question) prior to the general merger of laryngeals: A laryngeal adjacent to a vowel develops along the same lines as other Indo-European languages: Consonants followed by consonantal*ywerepalatalized, producing variousaffricate consonants(still represented as a separate sound in Mycenaean) andgeminatedpalatal consonants.Any aspiration was lost in the process. The palatalized consonants later simplified, mostly losing their palatal character. Palatalization occurred in two separate stages. The first stage affected only dental consonants, and the second stage affected all consonants. The first palatalization replaced post-PIE sequences of dental stop +*ywith alveolar affricates: The affricate derived from the first palatalization of*tyand*tʰymerged with the outcome of the inherited clusters*ts,*dsand*tʰs, all becoming*t͡s. After the first palatalization changed*tyand*tʰyinto*t͡s, the consonant*ywas restored  after original*tor*tʰin morphologically transparent formations. The initial outcome of restoration may have been simply*tyand*tʰy, or alternatively, restoration may have yielded an affricate followed by a glide,*t͡sy, in the case of both original*tand original*tʰ.Either way, restored*t(ʰ)ywould go on to merge via the second palatalization with the reflex of*k(ʰ)y, resulting in a distinct outcome from the*t͡sderived from the first palatalization.There may also have been restoration of*yafter original*din the same circumstances, but if so, it apparently merged with the*d͡zthat resulted from the first palatalization before leaving any visible trace. However, restoration is not evident inMycenaean Greek, where the reflex of original*t(ʰ)y(which became a consonant transcribed as ⟨s⟩) is consistently written differently from the reflex of original*k(ʰ)y(which became a consonant transcribed as ⟨z⟩ via the second palatalization). The second palatalization took place following the resolution of syllabic laryngeals and sonorants, and prior to Grassmann's law. It affected all consonants followed by the palatal glide*y. The following table, based on American linguistAndrew Sihler,shows the outcomes of the second palatalization: Sihler reconstructs the palatalized stops (shown in the above table as*ť*ď) with a degree of assibilation and transcribes them as*č*ǰ. The resulting palatal consonants and clusters of Proto-Greek were resolved in varying ways prior to the historical period. The restoration of*yafter original*tor*tʰ(resulting in*ťť) occurred only in morphologically transparent formations, by analogy with similar formations in which*ywas preceded by other consonants. In formations that were morphologically opaque, the restoration did not take place and the*t͡sthat resulted from the first palatalization of*tyand*tʰyremained. Hence, depending on the type of formation, the pre-Proto-Greek sequences*tyand*tʰyhave different outcomes in the later languages. In particular, medial*t(ʰ)ybecomes Attic-s-in opaque formations but-tt-in transparent formations. The outcome of PG medial*tsin Homeric Greek issafter a long vowel, and vacillation betweensandssafter a short vowel:tátēsidat. pl. \"rug\" <tátēt-,possí(n)/posí(n)dat. pl. \"foot\" <pod-. This was useful forthe composer of the Iliad and Odyssey, sincepossíwith doublesscans as long-short, whileposíwith singlesscans as short-short. Thus the writer could use each form in different positions in a line. Examples of initial*t͡s: Examples of medial*t͡s(morphologically opaque forms, first palatalization only): Examples of medial*ťť(morphologically transparent forms, first and second palatalization): For comparison, examples of initial*ťfrom*k(ʰ)yby the second palatalization: For words with original*dy, no distinction is found in any historically attested form of Greek between the outcomes of the first and second palatalizations, and so there is no visible evidence of an opposition between*d͡zand a secondary restored cluster*d͡zy>*ďď. However, it is reasonable to think that words with*dyoriginally underwent parallel treatment to words with original*tyand*tʰy.The reflex of*dyalso merged with the reflex of*g(ʷ)y, with one of the two word-initial reflexes of PIE *y-, and with original*sd,  as in PIE *h₃esdos/osdos >όζος'branch' or PIE *si-sd- > ἵζω 'take a seat'.The merger with*sdwas probably post-Mycenaean, but occurred before the introduction of the Greek alphabet. InProto-Greek, Cowgill's lawsays that a former/o/vowel becomes/u/between aresonant(/r/,/l/,/m/,/n/) and alabial consonant(includinglabiovelars), in either order. Examples: Note that when a labiovelar adjoins an/o/affected by Cowgill's law, the new/u/willcause the labiovelar to lose its labial component(as inGreek:núksandGreek:ónuks/ónukh-, where the usual Greek change*/kʷ/>/p/has not occurred). Proto-Greek retained the Indo-Europeanpitch accent, but developed a number of rules governing it: Sound changes that postdate Proto-Greek, but predate the attested dialects, includingMycenaean Greek, include: The following changes are apparently post-Mycenaean because early stages are represented inLinear B: Note that/w/and/j/, when following a vowel and not preceding a vowel, combined early on with the vowel to form a diphthong and so were not lost. Loss of/h/and/w/after a consonant was often accompanied bycompensatory lengtheningof a preceding vowel. The development of labiovelars varies from dialect to dialect: The results of vowel contraction were complex from dialect to dialect. Such contractions occur in the inflection of a number of different noun and verb classes and are among the most difficult aspects of Ancient Greek grammar. They were particularly important in the large class ofcontracted verbs, denominative verbs formed from nouns and adjectives ending in a vowel. (In fact, the reflex of contracted verbs inModern Greek, the set of verbs derived fromAncient Greekcontracted verbs, represents one of the two main classes of verbs in that language.) Proto-Greek preserved the gender (masculine, feminine, neuter) and number (singular, dual, plural) distinctions of the nominal system of Proto-Indo-European.However, the evidence from Mycenaean Greek is inconclusive with regard to whether all eight cases continued to see complete usage, but this is more secure for the five standard cases of Classical Greek (nominative, genitive, dative, accusative and vocative) and probably also the instrumental in its usual plural suffix -pʰi and the variant /-ṓis/ for o-stem nouns.The ablative and locative are uncertain; at the time of Mycenaean texts they may have been undergoing a merger with the genitive and dative respectively.It is thought that the syncretism between cases proceeded faster for the plural,with dative and locative already merged as-si(the Proto-Indo-European locative plural having been*-su-).This merger may have been motivated by analogy to the locative singular-i-.Nevertheless, seven case distinctions are securely attested in Mycenaean in some domain, with the status of the ablative unclear. Significant developments attributed to the Proto-Greek period include: The Proto-Greek nominal system is thought to have included cases of gender change according to number, heteroclisy and stem alternation (ex. genitive formhúdatosforhúdōr\"water\"). The superlative in-tatosbecomes productive. The peculiar oblique stemgunaik-\"women\", attested from theThebes tabletsis probably Proto-Greek. It appears, at least asgunai-inArmenianas well. (\"Yoke\" in later Proto-Hellenic and both Classical and Modern Greek is masculine due to a gender shift from *-ón to *-ós). The pronounshoûtos,ekeînosandautósare created. The use ofho, hā, toas articles is post-Mycenaean. Proto-Greek inherited the augment, a prefixe-, to verbal forms expressing past tense. That feature is shared only with Indo-Iranian and Phrygian (and to some extent,Armenian), lending some support to a \"Graeco-Aryan\" or \"Inner Proto-Indo-European\" proto-dialect. However, the augment down to the time of Homer remained optional and was probably little more than a free sentence particle, meaning'previously'in Proto-Indo-European, which may easily have been lost by most other branches. Greek, Phrygian,and Indo-Iranian also concur in the absence ofr-endings in themiddle voice, in Greek apparently already lost in Proto-Greek. The first person middle verbal desinences-mai,-mānreplace-ai,-a. The third singularphéreiis an innovation by analogy, replacing the expected Doric*phéreti, Ionic*phéresi(from PIE*bʰéreti). The future tense is created, including a future passive as well as an aorist passive. The suffix-ka-is attached to some perfects and aorists. Infinitives in-ehen,-enaiand-menare created. (*ágowes, *ágowen) (*ágetos, *ágeton) (*ágetos, *ágeton) (*ágomen) (singular) (singular) (singular) (plural) (plural) (plural) Proto-Greek numerals were derived directly from Indo-European. (*ḱm̥tóm: \"100\") Proto-Greek Mycenaean Ancient Koine Medieval Modern", "combined_text": "Proto-Greek language Contents Origins Diversification Phonology Phonemes Proto-Greek changes Post-Proto-Greek changes Morphology Nouns Pronouns Verbs Numerals Summary of numerals in Proto-Hellenic See also Footnotes References Further reading  Extant Extinct Reconstructed Hypothetical Grammar Other Mainstream Alternative and fringe Pontic Steppe Caucasus East Asia Eastern Europe Northern Europe Bronze AgePontic Steppe Northern/Eastern Steppe Europe South Asia Iron AgeSteppe Europe Caucasus Central Asia India Iron AgeIndo-Aryans Iranians Nuristanis East Asia Europe Middle AgesEast Asia Europe Indo-Aryan Iranian Historical Indo-Aryan Iranian Others European Practices Institutes Publications TheProto-Greek language(also known asProto-Hellenic) is theIndo-European languagewhich was the last common ancestor of all varieties ofGreek, includingMycenaean Greek, the subsequentancient Greek dialects(i.e.,Attic,Ionic,Aeolic,Doric,Arcadocypriot, andancient Macedonian—either a dialect or a closely relatedHellenic language) and, ultimately,Koine,ByzantineandModern Greek(along with itsvariants). Proto-Greek speakers entered Greece sometime between 2200 and 1900BC,with the diversification into a southern and a northern group beginning by approximately 1700BC. Proto-Greek emerged from the diversification of the lateProto-Indo-European language(PIE); a process whose last phase gave rise to the later language families and occurredc.2500 BC.Pre-Proto-Greek, the Indo-European dialect from which Proto-Greek originated, emergedc.2400– c.2200 BC, in an area which bordered pre-Proto-Indo-Iranianto the east and pre-Proto-Armenianand pre-Proto-Phrygianto the west, at the eastern borders of southeastern Europe; according to theKurgan hypothesis.Speakers of what would become Proto-Greek,migratedfrom theirhomeland(which could have been northeast of theBlack Sea), and reached Greece in a date set around the transition of the Early Bronze Age to the Middle Bronze Age.The evolution of Proto-Greek could be considered within the context of an earlyPaleo-Balkansprachbundthat makes it difficult to delineate exact boundaries between individual languages.The characteristically Greek representation of word-initiallaryngealsbyprothetic vowelsis shared, for one, with theArmenian language, which also seems to share some other phonological and morphological peculiarities of Greek; this has led some linguists to propose ahypothetically closer relationship between Greek and Armenian, although evidence remains scant. According to Filos (2014), the emergence of Proto-Greek was a long and continuous linguistic evolution, as the predecessors of Greek speakers were migrating towards the outskirts of Greece, somewhere to the north(-west) of the Greek peninsula proper, where they eventually merged with pre-Greek populations to form the Proto-Greek language.A. L. Katona (2000) places the beginning of the migration from Ukraine towards the southc.2400– c.2300 BC. Their proposed route of migration passed through Romania and the eastern Balkans to theEvrosriver valley from where their main body moved west.As such Katona as well as M.V Sakellariou agree that the main body of Greek speakers settled in a region that included southwestern Illyria, Epirus, northwestern Thessaly and western Macedonia. Older theories like those ofVladimir I. Georgievplaced Proto-Greek in northwestern Greece and adjacent areas (approximately up to the Aulon river to the north), includingParauaea,Tymphaia,Athamania,Dolopia,Amphilochia, andAcarnania, as well as west and northThessaly(Histiaeotis,Perrhaibia,Tripolis), and Pieria in Macedonia, during theLate Neolithic.The boundaries are based on the high concentration of archaic Greek place-names in the region, in contrast to southern Greece which preserves manypre-Greek.Radoslav Katičićconsidered these findings highly significant, and agreed that due to the minimal traces of pre-Greek toponymy in the region, Epirus and western Thessaly must have formed the region of concentration of Proto-Greek speakers, before their spread southwards.However, the dating of proto-Greek in Bronze Age Greece is compatible with the inherited lexicon from the commonProto-Indo-European language, which excludes any possibility of it being present inNeolithic Greece. In modern bibliography, models about the settlement and development of proto-Greek speakers in the Greek peninsula place it in the region at the earliest around 2200–2000 BC, during the Early Helladic III.Asko Parpola and Christian Carpelan (2005) date the arrival of Proto-Greek speakers into the Greek peninsula to 2200BC,whileCarl Blegen(1928) dates it toc.1900 BC. Ivo Hajnaldates the beginning of the diversification of Proto-Greek into the subsequent Greek dialects to a point not significantly earlier than 1700BC.The conventional division of the Greek dialects prior to 1955 differentiated them between a West Greek (consisting of Doric and Northwest Greek) and an East Greek (consisting of Aeolic, Arcado-Cypriot, and Attic-Ionic) group. However, after the decipherment of theLinear Bscript, Walter Porzig andErnst Rischargued for a division between a Northern (consisting of Doric, Northwest Greek, and Aeolic) and a Southern (consisting of Mycenaean, Arcado-Cypriot, and Attic-Ionic) group, which remains fundamental until today. During this period ofc.1700 BC, South Greek-speaking tribes spread to Boeotia, Attica, and the Peloponnese, while North Greek was spoken in Epirus, Thessaly, parts of Central Greece, and perhaps also Macedonia. Proto-Greek is reconstructed with the following phonemes:  The primary sound changes separating Proto-Greek from theProto-Indo-European languageinclude the following. Major changes included: Grassmann's lawwas a process ofdissimilationin words containing multiple aspirates. It caused an initial aspirated sound to lose its aspiration when a following aspirated consonant occurred in the same word. It was a relatively late change in Proto-Greek history, and must have occurred independentlyof the similar dissimilation of aspirates (also known asGrassmann's law) inIndo-Iranian, although it may represent a commonareal feature. The change may have even been post-Mycenaean: Greek is unique among Indo-European languages in reflecting the three differentlaryngealswith distinct vowels. Most Indo-European languages can be traced back to a dialectal variety of late Proto-Indo-European (PIE) in which all three laryngeals had merged (after colouring adjacent short/e/vowels), but Greek clearly cannot. For that reason, Greek is extremely important in reconstructing PIE forms. Greek shows distinct reflexes of the laryngeals in various positions: All of the cases may stem from an early insertion of/e/next to a laryngeal not adjacent to a vowel in the Indo-European dialect ancestral to Greek (subsequently coloured to/e/,/a/,/o/by the particular laryngeal in question) prior to the general merger of laryngeals: A laryngeal adjacent to a vowel develops along the same lines as other Indo-European languages: Consonants followed by consonantal*ywerepalatalized, producing variousaffricate consonants(still represented as a separate sound in Mycenaean) andgeminatedpalatal consonants.Any aspiration was lost in the process. The palatalized consonants later simplified, mostly losing their palatal character. Palatalization occurred in two separate stages. The first stage affected only dental consonants, and the second stage affected all consonants. The first palatalization replaced post-PIE sequences of dental stop +*ywith alveolar affricates: The affricate derived from the first palatalization of*tyand*tʰymerged with the outcome of the inherited clusters*ts,*dsand*tʰs, all becoming*t͡s. After the first palatalization changed*tyand*tʰyinto*t͡s, the consonant*ywas restored  after original*tor*tʰin morphologically transparent formations. The initial outcome of restoration may have been simply*tyand*tʰy, or alternatively, restoration may have yielded an affricate followed by a glide,*t͡sy, in the case of both original*tand original*tʰ.Either way, restored*t(ʰ)ywould go on to merge via the second palatalization with the reflex of*k(ʰ)y, resulting in a distinct outcome from the*t͡sderived from the first palatalization.There may also have been restoration of*yafter original*din the same circumstances, but if so, it apparently merged with the*d͡zthat resulted from the first palatalization before leaving any visible trace. However, restoration is not evident inMycenaean Greek, where the reflex of original*t(ʰ)y(which became a consonant transcribed as ⟨s⟩) is consistently written differently from the reflex of original*k(ʰ)y(which became a consonant transcribed as ⟨z⟩ via the second palatalization). The second palatalization took place following the resolution of syllabic laryngeals and sonorants, and prior to Grassmann's law. It affected all consonants followed by the palatal glide*y. The following table, based on American linguistAndrew Sihler,shows the outcomes of the second palatalization: Sihler reconstructs the palatalized stops (shown in the above table as*ť*ď) with a degree of assibilation and transcribes them as*č*ǰ. The resulting palatal consonants and clusters of Proto-Greek were resolved in varying ways prior to the historical period. The restoration of*yafter original*tor*tʰ(resulting in*ťť) occurred only in morphologically transparent formations, by analogy with similar formations in which*ywas preceded by other consonants. In formations that were morphologically opaque, the restoration did not take place and the*t͡sthat resulted from the first palatalization of*tyand*tʰyremained. Hence, depending on the type of formation, the pre-Proto-Greek sequences*tyand*tʰyhave different outcomes in the later languages. In particular, medial*t(ʰ)ybecomes Attic-s-in opaque formations but-tt-in transparent formations. The outcome of PG medial*tsin Homeric Greek issafter a long vowel, and vacillation betweensandssafter a short vowel:tátēsidat. pl. \"rug\" <tátēt-,possí(n)/posí(n)dat. pl. \"foot\" <pod-. This was useful forthe composer of the Iliad and Odyssey, sincepossíwith doublesscans as long-short, whileposíwith singlesscans as short-short. Thus the writer could use each form in different positions in a line. Examples of initial*t͡s: Examples of medial*t͡s(morphologically opaque forms, first palatalization only): Examples of medial*ťť(morphologically transparent forms, first and second palatalization): For comparison, examples of initial*ťfrom*k(ʰ)yby the second palatalization: For words with original*dy, no distinction is found in any historically attested form of Greek between the outcomes of the first and second palatalizations, and so there is no visible evidence of an opposition between*d͡zand a secondary restored cluster*d͡zy>*ďď. However, it is reasonable to think that words with*dyoriginally underwent parallel treatment to words with original*tyand*tʰy.The reflex of*dyalso merged with the reflex of*g(ʷ)y, with one of the two word-initial reflexes of PIE *y-, and with original*sd,  as in PIE *h₃esdos/osdos >όζος'branch' or PIE *si-sd- > ἵζω 'take a seat'.The merger with*sdwas probably post-Mycenaean, but occurred before the introduction of the Greek alphabet. InProto-Greek, Cowgill's lawsays that a former/o/vowel becomes/u/between aresonant(/r/,/l/,/m/,/n/) and alabial consonant(includinglabiovelars), in either order. Examples: Note that when a labiovelar adjoins an/o/affected by Cowgill's law, the new/u/willcause the labiovelar to lose its labial component(as inGreek:núksandGreek:ónuks/ónukh-, where the usual Greek change*/kʷ/>/p/has not occurred). Proto-Greek retained the Indo-Europeanpitch accent, but developed a number of rules governing it: Sound changes that postdate Proto-Greek, but predate the attested dialects, includingMycenaean Greek, include: The following changes are apparently post-Mycenaean because early stages are represented inLinear B: Note that/w/and/j/, when following a vowel and not preceding a vowel, combined early on with the vowel to form a diphthong and so were not lost. Loss of/h/and/w/after a consonant was often accompanied bycompensatory lengtheningof a preceding vowel. The development of labiovelars varies from dialect to dialect: The results of vowel contraction were complex from dialect to dialect. Such contractions occur in the inflection of a number of different noun and verb classes and are among the most difficult aspects of Ancient Greek grammar. They were particularly important in the large class ofcontracted verbs, denominative verbs formed from nouns and adjectives ending in a vowel. (In fact, the reflex of contracted verbs inModern Greek, the set of verbs derived fromAncient Greekcontracted verbs, represents one of the two main classes of verbs in that language.) Proto-Greek preserved the gender (masculine, feminine, neuter) and number (singular, dual, plural) distinctions of the nominal system of Proto-Indo-European.However, the evidence from Mycenaean Greek is inconclusive with regard to whether all eight cases continued to see complete usage, but this is more secure for the five standard cases of Classical Greek (nominative, genitive, dative, accusative and vocative) and probably also the instrumental in its usual plural suffix -pʰi and the variant /-ṓis/ for o-stem nouns.The ablative and locative are uncertain; at the time of Mycenaean texts they may have been undergoing a merger with the genitive and dative respectively.It is thought that the syncretism between cases proceeded faster for the plural,with dative and locative already merged as-si(the Proto-Indo-European locative plural having been*-su-).This merger may have been motivated by analogy to the locative singular-i-.Nevertheless, seven case distinctions are securely attested in Mycenaean in some domain, with the status of the ablative unclear. Significant developments attributed to the Proto-Greek period include: The Proto-Greek nominal system is thought to have included cases of gender change according to number, heteroclisy and stem alternation (ex. genitive formhúdatosforhúdōr\"water\"). The superlative in-tatosbecomes productive. The peculiar oblique stemgunaik-\"women\", attested from theThebes tabletsis probably Proto-Greek. It appears, at least asgunai-inArmenianas well. (\"Yoke\" in later Proto-Hellenic and both Classical and Modern Greek is masculine due to a gender shift from *-ón to *-ós). The pronounshoûtos,ekeînosandautósare created. The use ofho, hā, toas articles is post-Mycenaean. Proto-Greek inherited the augment, a prefixe-, to verbal forms expressing past tense. That feature is shared only with Indo-Iranian and Phrygian (and to some extent,Armenian), lending some support to a \"Graeco-Aryan\" or \"Inner Proto-Indo-European\" proto-dialect. However, the augment down to the time of Homer remained optional and was probably little more than a free sentence particle, meaning'previously'in Proto-Indo-European, which may easily have been lost by most other branches. Greek, Phrygian,and Indo-Iranian also concur in the absence ofr-endings in themiddle voice, in Greek apparently already lost in Proto-Greek. The first person middle verbal desinences-mai,-mānreplace-ai,-a. The third singularphéreiis an innovation by analogy, replacing the expected Doric*phéreti, Ionic*phéresi(from PIE*bʰéreti). The future tense is created, including a future passive as well as an aorist passive. The suffix-ka-is attached to some perfects and aorists. Infinitives in-ehen,-enaiand-menare created. (*ágowes, *ágowen) (*ágetos, *ágeton) (*ágetos, *ágeton) (*ágomen) (singular) (singular) (singular) (plural) (plural) (plural) Proto-Greek numerals were derived directly from Indo-European. (*ḱm̥tóm: \"100\") Proto-Greek Mycenaean Ancient Koine Medieval Modern", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Proto-Greek_language", "https://en.wikipedia.org/wiki/Proto-Greek_language", "https://en.wikipedia.org/wiki/Proto-Greek_language", "https://en.wikipedia.org/wiki/Pre-Greek_substrate", "https://en.wikipedia.org/wiki/Lists_of_ISO_639_codes", "https://en.wikipedia.org/wiki/Hellenic_languages", "https://en.wikipedia.org/wiki/Ancient_Greek_dialects", "https://en.wikipedia.org/wiki/Proto-Indo-European"]},
{"id": "781dbbc3f24b", "url": "https://en.wikipedia.org/wiki/Google_Books", "title": "Google Books", "headings": ["Contents", "Details", "Scanning of books", "Website functionality", "Ngram Viewer", "Content issues and criticism", "Scanning errors", "Errors in metadata", "Language issues", "Google Books versus Google Scholar", "Library partners", "Initial partners", "Additional partners", "History", "Status", "Legal issues", "Similar projects", "See also", "References", "Further reading", "External links"], "content": "Google Books(previously known asGoogle Book Search,Google Print, and by its code-nameProject Ocean)is a service fromGooglethat searches the full text of books and magazines that Google has scanned, converted to text usingoptical character recognition(OCR), and stored in its digital database.Books are provided either by publishers and authors through the Google Books Partner Program, or by Google's library partners through the Library Project.Additionally, Google has partnered with a number of magazine publishers to digitize their archives. The Publisher Program was first known as Google Print when it was introduced at theFrankfurt Book Fairin October 2004. The Google Books Library Project, which scans works in the collections of library partners and adds them to the digital inventory, was announced in December 2004. The Google Books initiative has been hailed for its potential to offer unprecedented access to what may become the largest online body of human knowledgeand promoting thedemocratization of knowledge.However, it has also been criticized for potential copyright violations,and lack of editing to correct the many errors introduced into the scanned texts by the OCR process. As of October 2019, Google celebrated 15 years of Google Books and provided the number of scanned books as more than 40 million titles.Google estimated in 2010 that there were about 130 million distinct titles in the world,and stated that it intended to scan all of them.However, thescanning processin American academic libraries has slowed since the 2000s.Google Book's scanning efforts have been subject to litigation, includingAuthors Guild v. Google, a class-action lawsuit in the United States, decided in Google's favor (see below). This was a major case that came close to changing copyright practices fororphan worksin the United States.A 2023 study by scholars from theUniversity of California, Berkeley, andNortheastern University's business schools found that Google Books's digitization of books has led to increased sales for the physical versions of the books. Results from Google Books show up in both the universalGoogle Searchand in the dedicated Google Books search website (books.google.com). In response to search queries, Google Books allows users to view full pages from books in which the search terms appear if the book is out of copyright or if the copyright owner has given permission. If Google believes the book is still under copyright, a user sees \"snippets\" of text around the queried search terms. All instances of the search terms in the book text appear with a yellow highlight. The four access levels used on Google Books are: In response to criticism from groups such as theAmerican Association of Publishersand theAuthors Guild, Google announced anopt-outpolicy in August 2005, through which copyright owners could provide a list of titles that they do not want scanned, and the request would be respected. The company also stated that it would not scan any in-copyright books between August and 1 November 2005, to provide the owners with the opportunity to decide which books to exclude from the Project. Thus, copyright owners have three choices with respect to any work: Most scanned works are no longer in print or commercially available. In addition to procuring books from libraries, Google also obtains books from its publisher partners, through the \"Partner Program\" – designed to help publishers and authors promote their books. Publishers and authors submit either a digital copy of their book inEPUBorPDFformat, or a print copy to Google, which is made available on Google Books for preview. The publisher can control the percentage of the book available for preview, with the minimum being 20%. They can also choose to make the book fully viewable, and even allow users to download a PDF copy. Books can also be made available for sale on Google Play.Unlike the Library Project, this does not raise any copyright concerns as it is conducted pursuant to an agreement with the publisher. The publisher can choose to withdraw from the agreement at any time. For many books, Google Books displays the original page numbers. However,Tim Parks, writing inThe New York Review of Booksin 2014, noted that Google had stopped providing page numbers for many recent publications (likely the ones acquired through the Partner Program) \"presumably in alliance with the publishers, in order to force those of us who need to prepare footnotes to buy paper editions.\" The project began in 2002 under the codename Project Ocean. Google co-founderLarry Pagehad always had an interest in digitizing books. When he andMarissa Mayerbegan experimenting withbook scanningin 2002, it took 40 minutes for them to digitize a 300-page book. But soon after the technology had been developed to the extent that scanning operators could scan up to 6000 pages an hour. Google established designated scanning centers to which books were transported by trucks. The stations could digitize at the rate of 1,000 pages per hour. The books were placed in a custom-built mechanical cradle that adjusted the book spine in place while an array of lights and optical instruments scanned the two open pages. Each page would have two cameras directed at it capturing the image, while a range finderLIDARoverlaid a three-dimensional laser grid on the book's surface to capture the curvature of the paper. A human operator would turn the pages by hand, using a foot pedal to take the photographs. With no need to flatten the pages or align them perfectly, Google's system not only reached a remarkable efficiency and speed but also helped protect the fragile collections from being over-handled. Afterwards, the crude images went through three levels of processing: first, de-warping algorithms used the LIDAR data fix the pages' curvature. Then,optical character recognition(OCR) software transformed the raw images into text, and, lastly, another round of algorithms extracted page numbers, footnotes, illustrations and diagrams. Many of the books are scanned using a customizedElphel323 cameraat a rate of 1,000 pages per hour.Apatentawarded to Google in 2009 revealed that Google had come up with an innovative system for scanning books that uses two cameras and infrared light to automatically correct for the curvature of pages in a book. By constructing a 3D model of each page and then \"de-warping\" it, Google is able to present flat-looking pages without having to really make the pages flat, which requires the use of destructive methods such asunbindingor glass plates to individually flatten each page, which is inefficient for large scale scanning. Google decided to omit color information in favour of better spatial resolution, as most out-of-copyright books at the time did not contain colors. Each page image was passed through algorithms that distinguished the text and illustration regions. Text regions were then processed via OCR to enable full-text searching. Google expended considerable resources in coming up with optimal compression techniques, aiming for high image quality while keeping the file sizes minimal to enable access by internet users with low bandwidth. For each work, Google Books automatically generates an overview page. This page displays information extracted from the book—its publishing details, a high frequency word map, the table of contents—as well as secondary material, such as summaries, reader reviews (not readable in the mobile version of the website), and links to other relevant texts. A visitor to the page, for instance, might see a list of books that share a similar genre and theme, or they might see a list of current scholarship on the book. This content, moreover, offers interactive possibilities for users signed into theirGoogle account. They can export the bibliographic data andcitationsinstandard formats, write their own reviews, add it to their library to be tagged, organized, and shared with other people.Thus, Google Books collects these more interpretive elements from a range of sources, including the users, third-party sites likeGoodreads, and often the book's author and publisher. In fact, to encourage authors to upload their own books, Google has added several functionalities to the website. The authors can allow visitors to download their ebook for free, or they can set their own purchase price. They can change the price back and forth, offering discounts whenever it suits them. Also, if a book's author chooses to add anISBN,LCCNorOCLCrecord number, the service will update the book's url to include it. Then, the author can set a specific page as the link's anchor. This option makes their book more easily discoverable. The Ngram Viewer is a service connected to Google Books that graphs the frequency of word usage across their book collection. The service is important for historians and linguists as it can provide an inside look into human culture through word use throughout time periods.This program has fallen under criticism because of errors in the metadata used in the program. The project has received criticism that its stated aim of preserving orphaned and out-of-print works is at risk due to scanned data having errors and such problems not being solved. The scanning process is subject to errors. For example, some pages may be unreadable, upside down, or in the wrong order. Scholars have even reported crumpled pages, obscuring thumbs and fingers, and smeared or blurry images.On this issue, a declaration from Google at the end of scanned books says: The digitization at the most basic level is based on page images of the physical books. To make this book available as an ePub formatted file we have taken those page images and extracted the text using Optical Character Recognition (or OCR for short) technology. The extraction of text from page images is a difficult engineering task. Smudges on the physical books' pages, fancy fonts, old fonts, torn pages, etc. can all lead to errors in the extracted text. Imperfect OCR is only the first challenge in the ultimate goal of moving from collections of page images to extracted-text based books. Our computer algorithms also have to automatically determine the structure of the book (what are the headers and footers, where images are placed, whether text is verse or prose, and so forth).\nGetting this right allows us to render the book in a way that follows the format of the original book. Despite our best efforts you may see spelling mistakes, garbage characters, extraneous images, or missing pages in this book. Based on our estimates, these errors should not prevent you from enjoying the content of the book. The technical challenges of automatically constructing a perfect book are daunting, but we continue to make enhancements to our OCR and book structure extraction technologies. In 2009, Google stated that they would start usingreCAPTCHAto help fix the errors found in Google Book scans. This method would only improve scanned words that are hard to recognize because of the scanning process and cannot solve errors such as turned pages or blocked words. Scanning errors have inspired works of art such as published collections of anomalous pages and aTumblrblog. Scholars have frequently reported rampant errors in themetadatainformation on Google Books – including misattributed authors and erroneous dates of publication.Geoffrey Nunberg, a linguist researching on the changes in word usage over time noticed that a search for books published before 1950 and containing the word \"internet\" turned up an unlikely 527 results. Woody Allen is mentioned in 325 books ostensibly published before he was born. Google responded to Nunberg by blaming the bulk of errors on outside contractors. Other metadata errors reported include publication dates before the author's birth (e.g. 182 works by Charles Dickens prior to his birth in 1812); incorrect subject classifications (an edition ofMoby Dickfound under \"computers\", a biography of Mae West classified under \"religion\"), conflicting classifications (10 editions of Whitman'sLeaves of Grassall classified as both \"fiction\" and \"nonfiction\"), incorrectly spelled titles, authors, and publishers (Moby Dick: or the White \"Wall\"), and metadata for one book incorrectly appended to a completely different book (the metadata for an 1818 mathematical work leads to a 1963 romance novel). A review of the author, title, publisher, and publication year metadata elements for 400 randomly selected Google Books records was undertaken. The results show 36% of sampled books in the digitization project contained metadata errors. This error rate is higher than one would expect to find in a typical library online catalog. The overall error rate of 36.75% found in this study suggests that Google Books' metadata has a high rate of error. While \"major\" and \"minor\" errors are a subjective distinction based on the somewhat indeterminate concept of \"findability\", the errors found in the four metadata elements examined in this study should all be considered major. Metadata errors based on incorrect scanned dates has made research using the Google Books Project database difficult. According to a 2009 article by academicGeoffrey NunbergGoogle was aware of these errors and working towards fixing them. Some European politicians and intellectuals have criticized Google's effort onlinguistic imperialismgrounds. They argue that because the vast majority of books proposed to be scanned are in English, it will result in disproportionate representation of natural languages in the digital world. German, Russian, French, and Spanish, for instance, are popular languages in scholarship. The disproportionate online emphasis on English, however, could shape access to historical scholarship, and, ultimately, the growth and direction of future scholarship. Among these critics isJean-Noël Jeanneney, the former president of theBibliothèque nationale de France. While Google Books has digitized large numbers of journal back issues, its scans do not include the metadata required for identifying specific articles in specific issues. This has led the makers ofGoogle Scholarto start their own program to digitize and host older journal articles (in agreement with their publishers). The Google Books Library Project is aimed at scanning and making searchable the collections of several major researchlibraries.Along withbibliographicinformation, snippets of text from a book are often viewable. If a book is out ofcopyrightand in the public domain, the book is fully available to read ordownload. In-copyright books scanned through the Library Project are made available on Google Books for snippet view. Regarding the quality of scans, Google acknowledges that they are \"not always of sufficiently high quality\" to be offered for sale on Google Play. Also, because of supposed technical constraints, Google does not replace scans with higher quality versions that may be provided by the publishers. The project is the subject of theAuthors Guild v. Googlelawsuit, filed in 2005 and ruled in favor of Google in 2013, and again, on appeal, in 2015. Copyright owners can claim the rights for a scanned book and make it available for preview or full view (by \"transferring\" it to their Partner Program account), or request Google to prevent the book text from being searched. The number of institutions participating in the Library Project has grown since its inception. Other institutional partners have joined the project since the partnership was first announced: 2002: A group of team members at Google officially launch the \"secret 'books' project.\"Google foundersSergey BrinandLarry Pagecame up with the idea that later became Google Books while still graduate students at Stanford in 1996. The history page on the Google Books website describes their initial vision for this project: \"in a future world in which vast collections of books are digitized, people would use a 'web crawler' to index the books' content and analyze the connections between them, determining any given book's relevance and usefulness by tracking the number and quality of citations from other books.\"This team visited the sites of some of the larger digitization efforts at that time including the Library of Congress'sAmerican Memory Project,Project Gutenberg, and the Universal Library to find out how they work, as well as the University of Michigan, Page's alma mater, and the base for such digitization projects asJSTORand Making of America. In a conversation with the at that time University PresidentMary Sue Coleman, when Page found out that the university's current estimate for scanning all the library's volumes was 1,000 years, Page reportedly told Coleman that he \"believes Google can help make it happen in six.\" 2003: The team works to develop a high-speed scanning process as well as software for resolving issues in odd type sizes, unusual fonts, and \"other unexpected peculiarities.\" December 2004: Google signaled an extension to its Google Print initiative known as the Google Print Library Project.Google announced partnerships with several high-profile university and public libraries, including theUniversity of Michigan, Harvard (Harvard University Library), Stanford (Green Library), Oxford (Bodleian Library), and theNew York Public Library. According to press releases and university librarians, Google planned to digitize and make available through its Google Books service approximately 15 million volumes within a decade. The announcement soon triggered controversy, as publisher and author associations challenged Google's plans to digitize, not just books in the public domain, but also titles still under copyright. September–October 2005: Two lawsuits against Google charge that the company has not respectedcopyrightsand has failed to properly compensate authors and publishers. One is a class action suit on behalf of authors (Authors Guild v. Google, September 20, 2005) and the other is a civil lawsuit brought by five large publishers and theAssociation of American Publishers. (McGraw Hill v. Google, October 19, 2005) November 2005: Google changed the name of this service from Google Print to Google Book Search.Its program enabling publishers and authors to include their books in the service was renamed Google Books Partner Program,and the partnership with libraries becameGoogle Books Library Project. 2006: Google added a \"download a pdf\" button to all its out-of-copyright, public domain books. It also added a new browsing interface along with new \"About this Book\" pages. August 2006: TheUniversity of California Systemannounced that it would join the Books digitization project. This includes a portion of the 34 million volumes within the approximately 100 libraries managed by the System. September 2006: TheComplutense University of Madridbecame the first Spanish-language library to join the Google Books Library Project. October 2006: TheUniversity of Wisconsin–Madisonannounced that it would join the Book Search digitization project along with theWisconsin Historical SocietyLibrary. Combined, the libraries have 7.2 million holdings. November 2006: TheUniversity of Virginiajoined the project. Its libraries contain more than five million volumes and more than 17 million manuscripts, rare books and archives. January 2007: TheUniversity of Texas at Austinannounced that it would join the Book Search digitization project. At least one million volumes would be digitized from the university's 13 library locations. March 2007: TheBavarian State Libraryannounced a partnership with Google to scan more than a million public domain and out-of-print works in German as well as English, French, Italian, Latin, and Spanish. May 2007: A book digitizing project partnership was announced jointly by Google and theCantonal and University Library of Lausanne. May 2007: TheBoekentorenLibrary ofGhent Universityannounced that it would participate with Google in digitizing and making digitized versions of 19th century books in the French and Dutch languages available online. May 2007:Mysore University announces Google will digitize over 800,000 books and manuscripts–including around 100,000 manuscripts written in Sanskrit or Kannada on both paper and palm leaves. June 2007: TheCommittee on Institutional Cooperation(rebranded as theBig Ten Academic Alliancein 2016) announced that its twelve member libraries would participate in scanning 10 million books over the course of the next six years. July 2007:Keio Universitybecame Google's first library partner inJapanwith the announcement that they would digitize at least 120,000 public domain books. August 2007: Google announced that it would digitize up to 500,000 both copyrighted and public domain items fromCornell University Library. Google would also provide a digital copy of all works scanned to be incorporated into the university's own library system. September 2007: Google added a feature that allows users to share snippets of books that are in the public domain. The snippets may appear exactly as they do in the scan of the book, or as plain text. September 2007: Google debuted a new feature called \"My Library\" which allows users to create personal customized libraries, selections of books that they can label, review, rate, or full-text search. December 2007:Columbia Universitywas added as a partner in digitizing public domain works. May 2008:Microsofttapered off and planned to endits scanning project, which had reached 750,000 books and 80 million journal articles. October 2008: Asettlementwas reached between the publishing industry and Google after two years of negotiation. Google agreed to compensate authors and publishers in exchange for the right to make millions of books available to the public. October 2008: TheHathiTrust\"Shared Digital Repository\" (later known as the HathiTrust Digital Library) is launched jointly by theCommittee on Institutional Cooperationand the 11 university libraries in theUniversity of California system, all of which were Google partner libraries, in order to archive and provide academic access to books from their collections scanned by Google and others. November 2008: Google reached the 7 million book mark for items scanned by Google and by their publishing partners. 1 million were in full preview mode and 1 million were fully viewable and downloadable public domain works. About five million wereout of print. December 2008: Google announced the inclusion of magazines in Google Books. Titles includeNew York Magazine,Ebony, andPopular Mechanics February 2009: Google launched a mobile version of Google Book Search, allowing iPhone and Android phone users to read over 1.5 million public domain works in the US (and over 500,000 outside the US) using a mobile browser. Instead of page images, the plain text of the book is displayed. May 2009: At the annualBookExpoconvention in New York, Google signaled its intent to introduce a program that would enable publishers to sell digital versions of their newest books direct to consumers through Google. December 2009: A French court shut down the scanning of copyrighted books published in France, saying this violated copyright laws. It was the first major legal loss for the scanning project. April 2010: Visual artists were not included in the previous lawsuit and settlement, are the plaintiff groups in another lawsuit, and say they intend to bring more than just Google Books under scrutiny. \"The new class action,\" read the statement, \"goes beyond Google's Library Project, and includes Google's other systematic and pervasive infringements of the rights of photographers, illustrators and other visual artists.\" May 2010: It was reported that Google would launch a digital book store calledGoogle Editions.It would compete with Amazon, Barnes & Noble, Apple and other electronic book retailers with its own e-book store. Unlike others, Google Editions would be completely online and would not require a specific device (such as kindle, Nook, or iPad). June 2010: Google passed 12 million books scanned. August 2010: It was announced that Google intends to scan all known existing 129,864,880 books within a decade, amounting to over 4 billiondigital pagesand 2 trillion words in total. December 2010: Google eBooks (Google Editions) was launched in the US. December 2010: Google launched the Ngram Viewer, which collects and graphs data on word usage across its book collection. March 2011: A federal judge rejected thesettlementreached between the publishing industry and Google. March 2012: Google passed 20 million books scanned. March 2012: Google reached a settlement with publishers. January 2013: The documentaryGoogle and the World Brainwas shown at theSundance Film Festival. November 2013: Ruling inAuthors Guild v. Google, US District JudgeDenny Chinsides with Google, citing fair use.The authors said they would appeal. October 2015: The appeals court sided with Google, declaring that Google did not violate copyright law.According to the New York Times, Google has scanned more than 25 million books. April 2016: The US Supreme Court declined to hear the Authors Guild's appeal, which means the lower court's decision stood, and Google would be allowed to scan library books and display snippets in search results without violating the law. Google has been quite secretive regarding its plans on the future of the Google Books project. Scanning operations had been slowing down since at least 2012, as confirmed by the librarians at several of Google's partner institutions. At University of Wisconsin, the speed had reduced to less than half of what it was in 2006. However, the librarians have said that the dwindling pace could be a natural result of maturation of the project – initially stacks of books were entirely taken up for scanning whereas now only the titles that had not already been scanned needed to be considered.The company's own Google Books timeline page did not mention anything after 2007 even in 2017, and the Google Books blog was merged into the Google Search blog in 2012. Despite winning the decade-long litigation in 2017,The Atlantichas said that Google has \"all but shut down its scanning operation.\"In April 2017,Wiredreported that there were only a few Google employees working on the project, and new books were still being scanned, but at a significantly lower rate. It commented that the decade-long legal battle had caused Google to lose its ambition. Through the project, library books were being digitized somewhat indiscriminately regardless of copyright status, which led to a number of lawsuits against Google. By the end of 2008, Google had reportedly digitized over seven million books, of which only about one million were works in the public domain. Of the rest, one million were in copyright and in print, and five million were in copyright but out of print. In 2005, a group of authors and publishers brought a majorclass-actionlawsuit against Google for infringement on the copyrighted works. Google argued that it was preserving \"orphaned works\" – books still under copyright, but whose copyright holders could not be located. TheAuthors GuildandAssociation of American Publishersseparately sued Google in 2005 for its book project, citing \"massivecopyright infringement.\"Google countered that its project represented afair useand is the digital age equivalent of acard catalogwith every word in the publication indexed.The lawsuits were consolidated, and eventually asettlement was proposed. The settlement received significant criticism on a wide variety of grounds, including antitrust, privacy, and inadequacy of the proposed classes of authors and publishers. The settlement was eventually rejected,and the publishers settled with Google soon after. The Authors Guild continued its case, and in 2011 their proposedclass was certified. Google appealed that decision, with a number ofamiciasserting theinadequacy of the class, and the Second Circuit rejected theclass certificationin July 2013, remanding the case to the District Court for consideration of Google'sfair usedefense. In 2015 Authors Guild filed another appeal against Google to be considered by the 2nd U.S. Circuit Court of Appeals in New York. Google won the case unanimously based on the argument that they were not showing people the full texts but instead snippets, and they are not allowing people to illegally read the book.In a report, courts stated that they did not infringe on copyright laws, as they were protected under the fair use clause. Authors Guild tried again in 2016 to appeal the decision and this time took their case to be considered by the Supreme Court. The case was rejected, leaving the Second Circuit's decision on the case intact, meaning that Google did not violate copyright laws.This case also set a precedent for other similar cases in regards to fair use laws, as it further clarified the law and expanded it. Such clarification affects other scanning projects similar to Google. Other lawsuits followed the Authors Guild's lead. In 2006 a German lawsuit, previously filed, was withdrawn.In June 2006, Hervé de la Martinière,a French publisher known as La Martinière andÉditions du Seuil,announced its intention to sue Google France.In 2009, the Paris Civil Court awarded 300,000EUR(approximately 430,000USD) in damages and interest and ordered Google to pay 10,000 EUR a day until it removes the publisher's books from its database.The court wrote, \"Google violated author copyright laws by fully reproducing and making accessible\" books that Seuil owns without its permissionand that Google \"committed acts of breach of copyright, which are of harm to the publishers\".Google said it will appeal.Syndicat National de l'Edition, which joined the lawsuit, said Google has scanned about 100,000 French works under copyright. In December 2009, Chinese authorMian Mianfiled a civil lawsuit for $8,900 against Google for scanning her novel,Acid Lovers. This is the first such lawsuit to be filed against Google in China.Also, in November that year, the China Written Works Copyright Society (CWWCS) accused Google of scanning 18,000 books by 570 Chinese writers without authorization. Google agreed on Nov 20 to provide a list of Chinese books it had scanned, but the company refused to admit having \"infringed\" copyright laws. In March 2007, Thomas Rubin, associate general counsel for copyright, trademark, and trade secrets at Microsoft, accused Google of violating copyright law with their book search service. Rubin specifically criticized Google's policy of freely copying any work until notified by the copyright holder to stop. Google licensing of public domain works is also an area of concern due to using ofdigital watermarkingtechniques with the books. Some published works that are in the public domain, such as allworks created by the U.S. Federal government, are still treated like other works under copyright, and therefore locked after 1922. Since at least 2014, Google has allowed authors and publishers to remove book previews from Google Books upon request.", "combined_text": "Google Books Contents Details Scanning of books Website functionality Ngram Viewer Content issues and criticism Scanning errors Errors in metadata Language issues Google Books versus Google Scholar Library partners Initial partners Additional partners History Status Legal issues Similar projects See also References Further reading External links Google Books(previously known asGoogle Book Search,Google Print, and by its code-nameProject Ocean)is a service fromGooglethat searches the full text of books and magazines that Google has scanned, converted to text usingoptical character recognition(OCR), and stored in its digital database.Books are provided either by publishers and authors through the Google Books Partner Program, or by Google's library partners through the Library Project.Additionally, Google has partnered with a number of magazine publishers to digitize their archives. The Publisher Program was first known as Google Print when it was introduced at theFrankfurt Book Fairin October 2004. The Google Books Library Project, which scans works in the collections of library partners and adds them to the digital inventory, was announced in December 2004. The Google Books initiative has been hailed for its potential to offer unprecedented access to what may become the largest online body of human knowledgeand promoting thedemocratization of knowledge.However, it has also been criticized for potential copyright violations,and lack of editing to correct the many errors introduced into the scanned texts by the OCR process. As of October 2019, Google celebrated 15 years of Google Books and provided the number of scanned books as more than 40 million titles.Google estimated in 2010 that there were about 130 million distinct titles in the world,and stated that it intended to scan all of them.However, thescanning processin American academic libraries has slowed since the 2000s.Google Book's scanning efforts have been subject to litigation, includingAuthors Guild v. Google, a class-action lawsuit in the United States, decided in Google's favor (see below). This was a major case that came close to changing copyright practices fororphan worksin the United States.A 2023 study by scholars from theUniversity of California, Berkeley, andNortheastern University's business schools found that Google Books's digitization of books has led to increased sales for the physical versions of the books. Results from Google Books show up in both the universalGoogle Searchand in the dedicated Google Books search website (books.google.com). In response to search queries, Google Books allows users to view full pages from books in which the search terms appear if the book is out of copyright or if the copyright owner has given permission. If Google believes the book is still under copyright, a user sees \"snippets\" of text around the queried search terms. All instances of the search terms in the book text appear with a yellow highlight. The four access levels used on Google Books are: In response to criticism from groups such as theAmerican Association of Publishersand theAuthors Guild, Google announced anopt-outpolicy in August 2005, through which copyright owners could provide a list of titles that they do not want scanned, and the request would be respected. The company also stated that it would not scan any in-copyright books between August and 1 November 2005, to provide the owners with the opportunity to decide which books to exclude from the Project. Thus, copyright owners have three choices with respect to any work: Most scanned works are no longer in print or commercially available. In addition to procuring books from libraries, Google also obtains books from its publisher partners, through the \"Partner Program\" – designed to help publishers and authors promote their books. Publishers and authors submit either a digital copy of their book inEPUBorPDFformat, or a print copy to Google, which is made available on Google Books for preview. The publisher can control the percentage of the book available for preview, with the minimum being 20%. They can also choose to make the book fully viewable, and even allow users to download a PDF copy. Books can also be made available for sale on Google Play.Unlike the Library Project, this does not raise any copyright concerns as it is conducted pursuant to an agreement with the publisher. The publisher can choose to withdraw from the agreement at any time. For many books, Google Books displays the original page numbers. However,Tim Parks, writing inThe New York Review of Booksin 2014, noted that Google had stopped providing page numbers for many recent publications (likely the ones acquired through the Partner Program) \"presumably in alliance with the publishers, in order to force those of us who need to prepare footnotes to buy paper editions.\" The project began in 2002 under the codename Project Ocean. Google co-founderLarry Pagehad always had an interest in digitizing books. When he andMarissa Mayerbegan experimenting withbook scanningin 2002, it took 40 minutes for them to digitize a 300-page book. But soon after the technology had been developed to the extent that scanning operators could scan up to 6000 pages an hour. Google established designated scanning centers to which books were transported by trucks. The stations could digitize at the rate of 1,000 pages per hour. The books were placed in a custom-built mechanical cradle that adjusted the book spine in place while an array of lights and optical instruments scanned the two open pages. Each page would have two cameras directed at it capturing the image, while a range finderLIDARoverlaid a three-dimensional laser grid on the book's surface to capture the curvature of the paper. A human operator would turn the pages by hand, using a foot pedal to take the photographs. With no need to flatten the pages or align them perfectly, Google's system not only reached a remarkable efficiency and speed but also helped protect the fragile collections from being over-handled. Afterwards, the crude images went through three levels of processing: first, de-warping algorithms used the LIDAR data fix the pages' curvature. Then,optical character recognition(OCR) software transformed the raw images into text, and, lastly, another round of algorithms extracted page numbers, footnotes, illustrations and diagrams. Many of the books are scanned using a customizedElphel323 cameraat a rate of 1,000 pages per hour.Apatentawarded to Google in 2009 revealed that Google had come up with an innovative system for scanning books that uses two cameras and infrared light to automatically correct for the curvature of pages in a book. By constructing a 3D model of each page and then \"de-warping\" it, Google is able to present flat-looking pages without having to really make the pages flat, which requires the use of destructive methods such asunbindingor glass plates to individually flatten each page, which is inefficient for large scale scanning. Google decided to omit color information in favour of better spatial resolution, as most out-of-copyright books at the time did not contain colors. Each page image was passed through algorithms that distinguished the text and illustration regions. Text regions were then processed via OCR to enable full-text searching. Google expended considerable resources in coming up with optimal compression techniques, aiming for high image quality while keeping the file sizes minimal to enable access by internet users with low bandwidth. For each work, Google Books automatically generates an overview page. This page displays information extracted from the book—its publishing details, a high frequency word map, the table of contents—as well as secondary material, such as summaries, reader reviews (not readable in the mobile version of the website), and links to other relevant texts. A visitor to the page, for instance, might see a list of books that share a similar genre and theme, or they might see a list of current scholarship on the book. This content, moreover, offers interactive possibilities for users signed into theirGoogle account. They can export the bibliographic data andcitationsinstandard formats, write their own reviews, add it to their library to be tagged, organized, and shared with other people.Thus, Google Books collects these more interpretive elements from a range of sources, including the users, third-party sites likeGoodreads, and often the book's author and publisher. In fact, to encourage authors to upload their own books, Google has added several functionalities to the website. The authors can allow visitors to download their ebook for free, or they can set their own purchase price. They can change the price back and forth, offering discounts whenever it suits them. Also, if a book's author chooses to add anISBN,LCCNorOCLCrecord number, the service will update the book's url to include it. Then, the author can set a specific page as the link's anchor. This option makes their book more easily discoverable. The Ngram Viewer is a service connected to Google Books that graphs the frequency of word usage across their book collection. The service is important for historians and linguists as it can provide an inside look into human culture through word use throughout time periods.This program has fallen under criticism because of errors in the metadata used in the program. The project has received criticism that its stated aim of preserving orphaned and out-of-print works is at risk due to scanned data having errors and such problems not being solved. The scanning process is subject to errors. For example, some pages may be unreadable, upside down, or in the wrong order. Scholars have even reported crumpled pages, obscuring thumbs and fingers, and smeared or blurry images.On this issue, a declaration from Google at the end of scanned books says: The digitization at the most basic level is based on page images of the physical books. To make this book available as an ePub formatted file we have taken those page images and extracted the text using Optical Character Recognition (or OCR for short) technology. The extraction of text from page images is a difficult engineering task. Smudges on the physical books' pages, fancy fonts, old fonts, torn pages, etc. can all lead to errors in the extracted text. Imperfect OCR is only the first challenge in the ultimate goal of moving from collections of page images to extracted-text based books. Our computer algorithms also have to automatically determine the structure of the book (what are the headers and footers, where images are placed, whether text is verse or prose, and so forth).\nGetting this right allows us to render the book in a way that follows the format of the original book. Despite our best efforts you may see spelling mistakes, garbage characters, extraneous images, or missing pages in this book. Based on our estimates, these errors should not prevent you from enjoying the content of the book. The technical challenges of automatically constructing a perfect book are daunting, but we continue to make enhancements to our OCR and book structure extraction technologies. In 2009, Google stated that they would start usingreCAPTCHAto help fix the errors found in Google Book scans. This method would only improve scanned words that are hard to recognize because of the scanning process and cannot solve errors such as turned pages or blocked words. Scanning errors have inspired works of art such as published collections of anomalous pages and aTumblrblog. Scholars have frequently reported rampant errors in themetadatainformation on Google Books – including misattributed authors and erroneous dates of publication.Geoffrey Nunberg, a linguist researching on the changes in word usage over time noticed that a search for books published before 1950 and containing the word \"internet\" turned up an unlikely 527 results. Woody Allen is mentioned in 325 books ostensibly published before he was born. Google responded to Nunberg by blaming the bulk of errors on outside contractors. Other metadata errors reported include publication dates before the author's birth (e.g. 182 works by Charles Dickens prior to his birth in 1812); incorrect subject classifications (an edition ofMoby Dickfound under \"computers\", a biography of Mae West classified under \"religion\"), conflicting classifications (10 editions of Whitman'sLeaves of Grassall classified as both \"fiction\" and \"nonfiction\"), incorrectly spelled titles, authors, and publishers (Moby Dick: or the White \"Wall\"), and metadata for one book incorrectly appended to a completely different book (the metadata for an 1818 mathematical work leads to a 1963 romance novel). A review of the author, title, publisher, and publication year metadata elements for 400 randomly selected Google Books records was undertaken. The results show 36% of sampled books in the digitization project contained metadata errors. This error rate is higher than one would expect to find in a typical library online catalog. The overall error rate of 36.75% found in this study suggests that Google Books' metadata has a high rate of error. While \"major\" and \"minor\" errors are a subjective distinction based on the somewhat indeterminate concept of \"findability\", the errors found in the four metadata elements examined in this study should all be considered major. Metadata errors based on incorrect scanned dates has made research using the Google Books Project database difficult. According to a 2009 article by academicGeoffrey NunbergGoogle was aware of these errors and working towards fixing them. Some European politicians and intellectuals have criticized Google's effort onlinguistic imperialismgrounds. They argue that because the vast majority of books proposed to be scanned are in English, it will result in disproportionate representation of natural languages in the digital world. German, Russian, French, and Spanish, for instance, are popular languages in scholarship. The disproportionate online emphasis on English, however, could shape access to historical scholarship, and, ultimately, the growth and direction of future scholarship. Among these critics isJean-Noël Jeanneney, the former president of theBibliothèque nationale de France. While Google Books has digitized large numbers of journal back issues, its scans do not include the metadata required for identifying specific articles in specific issues. This has led the makers ofGoogle Scholarto start their own program to digitize and host older journal articles (in agreement with their publishers). The Google Books Library Project is aimed at scanning and making searchable the collections of several major researchlibraries.Along withbibliographicinformation, snippets of text from a book are often viewable. If a book is out ofcopyrightand in the public domain, the book is fully available to read ordownload. In-copyright books scanned through the Library Project are made available on Google Books for snippet view. Regarding the quality of scans, Google acknowledges that they are \"not always of sufficiently high quality\" to be offered for sale on Google Play. Also, because of supposed technical constraints, Google does not replace scans with higher quality versions that may be provided by the publishers. The project is the subject of theAuthors Guild v. Googlelawsuit, filed in 2005 and ruled in favor of Google in 2013, and again, on appeal, in 2015. Copyright owners can claim the rights for a scanned book and make it available for preview or full view (by \"transferring\" it to their Partner Program account), or request Google to prevent the book text from being searched. The number of institutions participating in the Library Project has grown since its inception. Other institutional partners have joined the project since the partnership was first announced: 2002: A group of team members at Google officially launch the \"secret 'books' project.\"Google foundersSergey BrinandLarry Pagecame up with the idea that later became Google Books while still graduate students at Stanford in 1996. The history page on the Google Books website describes their initial vision for this project: \"in a future world in which vast collections of books are digitized, people would use a 'web crawler' to index the books' content and analyze the connections between them, determining any given book's relevance and usefulness by tracking the number and quality of citations from other books.\"This team visited the sites of some of the larger digitization efforts at that time including the Library of Congress'sAmerican Memory Project,Project Gutenberg, and the Universal Library to find out how they work, as well as the University of Michigan, Page's alma mater, and the base for such digitization projects asJSTORand Making of America. In a conversation with the at that time University PresidentMary Sue Coleman, when Page found out that the university's current estimate for scanning all the library's volumes was 1,000 years, Page reportedly told Coleman that he \"believes Google can help make it happen in six.\" 2003: The team works to develop a high-speed scanning process as well as software for resolving issues in odd type sizes, unusual fonts, and \"other unexpected peculiarities.\" December 2004: Google signaled an extension to its Google Print initiative known as the Google Print Library Project.Google announced partnerships with several high-profile university and public libraries, including theUniversity of Michigan, Harvard (Harvard University Library), Stanford (Green Library), Oxford (Bodleian Library), and theNew York Public Library. According to press releases and university librarians, Google planned to digitize and make available through its Google Books service approximately 15 million volumes within a decade. The announcement soon triggered controversy, as publisher and author associations challenged Google's plans to digitize, not just books in the public domain, but also titles still under copyright. September–October 2005: Two lawsuits against Google charge that the company has not respectedcopyrightsand has failed to properly compensate authors and publishers. One is a class action suit on behalf of authors (Authors Guild v. Google, September 20, 2005) and the other is a civil lawsuit brought by five large publishers and theAssociation of American Publishers. (McGraw Hill v. Google, October 19, 2005) November 2005: Google changed the name of this service from Google Print to Google Book Search.Its program enabling publishers and authors to include their books in the service was renamed Google Books Partner Program,and the partnership with libraries becameGoogle Books Library Project. 2006: Google added a \"download a pdf\" button to all its out-of-copyright, public domain books. It also added a new browsing interface along with new \"About this Book\" pages. August 2006: TheUniversity of California Systemannounced that it would join the Books digitization project. This includes a portion of the 34 million volumes within the approximately 100 libraries managed by the System. September 2006: TheComplutense University of Madridbecame the first Spanish-language library to join the Google Books Library Project. October 2006: TheUniversity of Wisconsin–Madisonannounced that it would join the Book Search digitization project along with theWisconsin Historical SocietyLibrary. Combined, the libraries have 7.2 million holdings. November 2006: TheUniversity of Virginiajoined the project. Its libraries contain more than five million volumes and more than 17 million manuscripts, rare books and archives. January 2007: TheUniversity of Texas at Austinannounced that it would join the Book Search digitization project. At least one million volumes would be digitized from the university's 13 library locations. March 2007: TheBavarian State Libraryannounced a partnership with Google to scan more than a million public domain and out-of-print works in German as well as English, French, Italian, Latin, and Spanish. May 2007: A book digitizing project partnership was announced jointly by Google and theCantonal and University Library of Lausanne. May 2007: TheBoekentorenLibrary ofGhent Universityannounced that it would participate with Google in digitizing and making digitized versions of 19th century books in the French and Dutch languages available online. May 2007:Mysore University announces Google will digitize over 800,000 books and manuscripts–including around 100,000 manuscripts written in Sanskrit or Kannada on both paper and palm leaves. June 2007: TheCommittee on Institutional Cooperation(rebranded as theBig Ten Academic Alliancein 2016) announced that its twelve member libraries would participate in scanning 10 million books over the course of the next six years. July 2007:Keio Universitybecame Google's first library partner inJapanwith the announcement that they would digitize at least 120,000 public domain books. August 2007: Google announced that it would digitize up to 500,000 both copyrighted and public domain items fromCornell University Library. Google would also provide a digital copy of all works scanned to be incorporated into the university's own library system. September 2007: Google added a feature that allows users to share snippets of books that are in the public domain. The snippets may appear exactly as they do in the scan of the book, or as plain text. September 2007: Google debuted a new feature called \"My Library\" which allows users to create personal customized libraries, selections of books that they can label, review, rate, or full-text search. December 2007:Columbia Universitywas added as a partner in digitizing public domain works. May 2008:Microsofttapered off and planned to endits scanning project, which had reached 750,000 books and 80 million journal articles. October 2008: Asettlementwas reached between the publishing industry and Google after two years of negotiation. Google agreed to compensate authors and publishers in exchange for the right to make millions of books available to the public. October 2008: TheHathiTrust\"Shared Digital Repository\" (later known as the HathiTrust Digital Library) is launched jointly by theCommittee on Institutional Cooperationand the 11 university libraries in theUniversity of California system, all of which were Google partner libraries, in order to archive and provide academic access to books from their collections scanned by Google and others. November 2008: Google reached the 7 million book mark for items scanned by Google and by their publishing partners. 1 million were in full preview mode and 1 million were fully viewable and downloadable public domain works. About five million wereout of print. December 2008: Google announced the inclusion of magazines in Google Books. Titles includeNew York Magazine,Ebony, andPopular Mechanics February 2009: Google launched a mobile version of Google Book Search, allowing iPhone and Android phone users to read over 1.5 million public domain works in the US (and over 500,000 outside the US) using a mobile browser. Instead of page images, the plain text of the book is displayed. May 2009: At the annualBookExpoconvention in New York, Google signaled its intent to introduce a program that would enable publishers to sell digital versions of their newest books direct to consumers through Google. December 2009: A French court shut down the scanning of copyrighted books published in France, saying this violated copyright laws. It was the first major legal loss for the scanning project. April 2010: Visual artists were not included in the previous lawsuit and settlement, are the plaintiff groups in another lawsuit, and say they intend to bring more than just Google Books under scrutiny. \"The new class action,\" read the statement, \"goes beyond Google's Library Project, and includes Google's other systematic and pervasive infringements of the rights of photographers, illustrators and other visual artists.\" May 2010: It was reported that Google would launch a digital book store calledGoogle Editions.It would compete with Amazon, Barnes & Noble, Apple and other electronic book retailers with its own e-book store. Unlike others, Google Editions would be completely online and would not require a specific device (such as kindle, Nook, or iPad). June 2010: Google passed 12 million books scanned. August 2010: It was announced that Google intends to scan all known existing 129,864,880 books within a decade, amounting to over 4 billiondigital pagesand 2 trillion words in total. December 2010: Google eBooks (Google Editions) was launched in the US. December 2010: Google launched the Ngram Viewer, which collects and graphs data on word usage across its book collection. March 2011: A federal judge rejected thesettlementreached between the publishing industry and Google. March 2012: Google passed 20 million books scanned. March 2012: Google reached a settlement with publishers. January 2013: The documentaryGoogle and the World Brainwas shown at theSundance Film Festival. November 2013: Ruling inAuthors Guild v. Google, US District JudgeDenny Chinsides with Google, citing fair use.The authors said they would appeal. October 2015: The appeals court sided with Google, declaring that Google did not violate copyright law.According to the New York Times, Google has scanned more than 25 million books. April 2016: The US Supreme Court declined to hear the Authors Guild's appeal, which means the lower court's decision stood, and Google would be allowed to scan library books and display snippets in search results without violating the law. Google has been quite secretive regarding its plans on the future of the Google Books project. Scanning operations had been slowing down since at least 2012, as confirmed by the librarians at several of Google's partner institutions. At University of Wisconsin, the speed had reduced to less than half of what it was in 2006. However, the librarians have said that the dwindling pace could be a natural result of maturation of the project – initially stacks of books were entirely taken up for scanning whereas now only the titles that had not already been scanned needed to be considered.The company's own Google Books timeline page did not mention anything after 2007 even in 2017, and the Google Books blog was merged into the Google Search blog in 2012. Despite winning the decade-long litigation in 2017,The Atlantichas said that Google has \"all but shut down its scanning operation.\"In April 2017,Wiredreported that there were only a few Google employees working on the project, and new books were still being scanned, but at a significantly lower rate. It commented that the decade-long legal battle had caused Google to lose its ambition. Through the project, library books were being digitized somewhat indiscriminately regardless of copyright status, which led to a number of lawsuits against Google. By the end of 2008, Google had reportedly digitized over seven million books, of which only about one million were works in the public domain. Of the rest, one million were in copyright and in print, and five million were in copyright but out of print. In 2005, a group of authors and publishers brought a majorclass-actionlawsuit against Google for infringement on the copyrighted works. Google argued that it was preserving \"orphaned works\" – books still under copyright, but whose copyright holders could not be located. TheAuthors GuildandAssociation of American Publishersseparately sued Google in 2005 for its book project, citing \"massivecopyright infringement.\"Google countered that its project represented afair useand is the digital age equivalent of acard catalogwith every word in the publication indexed.The lawsuits were consolidated, and eventually asettlement was proposed. The settlement received significant criticism on a wide variety of grounds, including antitrust, privacy, and inadequacy of the proposed classes of authors and publishers. The settlement was eventually rejected,and the publishers settled with Google soon after. The Authors Guild continued its case, and in 2011 their proposedclass was certified. Google appealed that decision, with a number ofamiciasserting theinadequacy of the class, and the Second Circuit rejected theclass certificationin July 2013, remanding the case to the District Court for consideration of Google'sfair usedefense. In 2015 Authors Guild filed another appeal against Google to be considered by the 2nd U.S. Circuit Court of Appeals in New York. Google won the case unanimously based on the argument that they were not showing people the full texts but instead snippets, and they are not allowing people to illegally read the book.In a report, courts stated that they did not infringe on copyright laws, as they were protected under the fair use clause. Authors Guild tried again in 2016 to appeal the decision and this time took their case to be considered by the Supreme Court. The case was rejected, leaving the Second Circuit's decision on the case intact, meaning that Google did not violate copyright laws.This case also set a precedent for other similar cases in regards to fair use laws, as it further clarified the law and expanded it. Such clarification affects other scanning projects similar to Google. Other lawsuits followed the Authors Guild's lead. In 2006 a German lawsuit, previously filed, was withdrawn.In June 2006, Hervé de la Martinière,a French publisher known as La Martinière andÉditions du Seuil,announced its intention to sue Google France.In 2009, the Paris Civil Court awarded 300,000EUR(approximately 430,000USD) in damages and interest and ordered Google to pay 10,000 EUR a day until it removes the publisher's books from its database.The court wrote, \"Google violated author copyright laws by fully reproducing and making accessible\" books that Seuil owns without its permissionand that Google \"committed acts of breach of copyright, which are of harm to the publishers\".Google said it will appeal.Syndicat National de l'Edition, which joined the lawsuit, said Google has scanned about 100,000 French works under copyright. In December 2009, Chinese authorMian Mianfiled a civil lawsuit for $8,900 against Google for scanning her novel,Acid Lovers. This is the first such lawsuit to be filed against Google in China.Also, in November that year, the China Written Works Copyright Society (CWWCS) accused Google of scanning 18,000 books by 570 Chinese writers without authorization. Google agreed on Nov 20 to provide a list of Chinese books it had scanned, but the company refused to admit having \"infringed\" copyright laws. In March 2007, Thomas Rubin, associate general counsel for copyright, trademark, and trade secrets at Microsoft, accused Google of violating copyright law with their book search service. Rubin specifically criticized Google's policy of freely copying any work until notified by the copyright holder to stop. Google licensing of public domain works is also an area of concern due to using ofdigital watermarkingtechniques with the books. Some published works that are in the public domain, such as allworks created by the U.S. Federal government, are still treated like other works under copyright, and therefore locked after 1922. Since at least 2014, Google has allowed authors and publishers to remove book previews from Google Books upon request.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Google_Books", "https://en.wikipedia.org/wiki/Google_Books", "https://en.wikipedia.org/wiki/Google_Books", "https://en.wikipedia.org/wiki/Google_Cloud_Print", "https://en.wikipedia.org/wiki/Google_Play_Books", "https://en.wikipedia.org/wiki/The_Google_Book", "https://en.wikipedia.org/wiki/Frankenstein", "https://en.wikipedia.org/wiki/Mary_Shelley"]},
{"id": "10a3fef26ac3", "url": "https://en.wikipedia.org/wiki/Crane_Carrier_Corporation", "title": "Crane Carrier Company", "headings": ["Contents", "History", "Operations", "References", "Additional Reading", "External links"], "content": "Crane Carrier Company(CCC) was a manufacturer that specialized inconstruction truckandgarbage truckchassis. Located inNew Philadelphia, Ohio, it was established by Robert Zeligson in 1946, along with the affiliated Zeligson Trucks. In 2021 CCC was bought byBattle Motors. The primary design of CCC's trucks are Cab-Beside-Engine (CBE) or half-cabs, most notably the Century II Unimixer. Half-cabs have the advantage of being able to carry the booms of cranes, hence the name of the company. CCC began as a firm that remanufacturedWorld War II-era surplus vehicles for civilian crane-carrying use. In 1953 CCC presented their first own truck, and soon evolved into a company that manufactured over-the-road trucks forconcrete mixing,logging,mining, and otherconstructionindustries, including awheeled loader. Though primarily building CBEs, CCC started moving toward the two-seater market during the 1970s, with models such as the Centaur. The Centurion is a series of low-entry trucks, primarily used for garbage collection. The Centurion has an engine mounted behind the cab and was also available with dual controls. CCC manufacturedType D school buschassis during the early to mid-1990s, which were used by bus manufacturersCarpenter Body CompanyandWayne Corporation. CCC sold Zeligson in 1980. It lasted as a separate company for nine years. In 2008, CCC and its parent, CCI Corp., were sold toGlenview, Illinois-basedIllinois Tool Works, which stated its plans to continue operating CCC as a separate company. CCC was acquired by Hines Corporation in June 2013 and the company’s headquarters was relocated to New Philadelphia, Ohio. Under Hines, a strategic merger was initiated to join CCC and Kimble Manufacturing forming Hines Specialty Vehicle Group – manufacturer of custom heavy-duty chassis and purpose built vehicles for the refuse and recycling, infrastructure maintenance, ground support, agriculture, oil and gas, and concrete mixer markets. Crane Carrier Company (CCC) embarked on a brief new chapter by launching as an independent company in 2019. Headquartered in New Philadelphia, Ohio, CCC consisted of two brands, Crane Carrier Company (truck chassis) and Crane Carrier Company Engineered Chassis.The Company was sold to Turnspire Capital Partners later in 2019.In April 2021Battle Motors, a developer of heavy duty trucks, acquired Crane Carrier. In addition to over-the-road trucks and wheeled loaders, CCC also builds trucks foroil drilling,water welldrilling,terminal tractors, andaviation fuelers. As with most American specialty truck manufacturers, the customer's choice of proprietary engines and transmissions have been available.", "combined_text": "Crane Carrier Company Contents History Operations References Additional Reading External links Crane Carrier Company(CCC) was a manufacturer that specialized inconstruction truckandgarbage truckchassis. Located inNew Philadelphia, Ohio, it was established by Robert Zeligson in 1946, along with the affiliated Zeligson Trucks. In 2021 CCC was bought byBattle Motors. The primary design of CCC's trucks are Cab-Beside-Engine (CBE) or half-cabs, most notably the Century II Unimixer. Half-cabs have the advantage of being able to carry the booms of cranes, hence the name of the company. CCC began as a firm that remanufacturedWorld War II-era surplus vehicles for civilian crane-carrying use. In 1953 CCC presented their first own truck, and soon evolved into a company that manufactured over-the-road trucks forconcrete mixing,logging,mining, and otherconstructionindustries, including awheeled loader. Though primarily building CBEs, CCC started moving toward the two-seater market during the 1970s, with models such as the Centaur. The Centurion is a series of low-entry trucks, primarily used for garbage collection. The Centurion has an engine mounted behind the cab and was also available with dual controls. CCC manufacturedType D school buschassis during the early to mid-1990s, which were used by bus manufacturersCarpenter Body CompanyandWayne Corporation. CCC sold Zeligson in 1980. It lasted as a separate company for nine years. In 2008, CCC and its parent, CCI Corp., were sold toGlenview, Illinois-basedIllinois Tool Works, which stated its plans to continue operating CCC as a separate company. CCC was acquired by Hines Corporation in June 2013 and the company’s headquarters was relocated to New Philadelphia, Ohio. Under Hines, a strategic merger was initiated to join CCC and Kimble Manufacturing forming Hines Specialty Vehicle Group – manufacturer of custom heavy-duty chassis and purpose built vehicles for the refuse and recycling, infrastructure maintenance, ground support, agriculture, oil and gas, and concrete mixer markets. Crane Carrier Company (CCC) embarked on a brief new chapter by launching as an independent company in 2019. Headquartered in New Philadelphia, Ohio, CCC consisted of two brands, Crane Carrier Company (truck chassis) and Crane Carrier Company Engineered Chassis.The Company was sold to Turnspire Capital Partners later in 2019.In April 2021Battle Motors, a developer of heavy duty trucks, acquired Crane Carrier. In addition to over-the-road trucks and wheeled loaders, CCC also builds trucks foroil drilling,water welldrilling,terminal tractors, andaviation fuelers. As with most American specialty truck manufacturers, the customer's choice of proprietary engines and transmissions have been available.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Crane_Carrier_Company", "https://en.wikipedia.org/wiki/Crane_Carrier_Company", "https://en.wikipedia.org/wiki/Crane_Carrier_Company", "https://en.wikipedia.org/wiki/New_Philadelphia,_Ohio", "https://en.wikipedia.org/wiki/Crane_(machine)", "https://en.wikipedia.org/wiki/Truck", "https://en.wikipedia.org/wiki/Wheeled_loader", "https://en.wikipedia.org/wiki/Parent_company"]},
{"id": "1aa108afeff2", "url": "https://en.wikipedia.org/wiki/Van_Cortlandt_Park%E2%80%93242nd_Street_station", "title": "Van Cortlandt Park–242nd Street station", "headings": ["Contents", "History", "Construction and opening", "Later years", "Station layout", "Location", "Platforms", "Control house", "Crew quarters", "Exits", "See also", "Notes", "References", "External links"], "content": "   TheVan Cortlandt Park–242nd Street stationis the northernterminal stationof theNew York City Subway'sIRT Broadway–Seventh Avenue Line. Located at the intersection of 242nd Street andBroadway(US Route 9) in theRiverdaleneighborhood ofthe Bronx, it is served by the1train at all times. It is adjacent toVan Cortlandt Parkto the east,Manhattan University, and the240th Street Yardof the subway system, along with the affluent neighborhoods ofFieldstonandRiverdaleto the west. It was built from a design by subway architectsHeins & LaFarge. Today it is the only remainingVictorian Gothicelevatedterminal station on the subway, and contains the subway's only remainingscrolledstation sign among itsdecorativeflourishes. In 2005, it was listed on theNational Register of Historic Places. The station was built as part of the Contract 1 system erected from 1904–1908, connectingLower Manhattanto the Bronx. Originally the northern terminus was intended to be Bailey Avenue and 230th Street, a block southeast of the current station at231st Street. After the completion of theHarlem River Ship Canalat the end of the 19th century, the line was rerouted to a new terminus at 242nd Street. Like many of the other terminal stations in theouter boroughs, it was located near a park. Heins & LaFarge, who had already designed theCathedral of St. John the DivinenearColumbia Universityand theAstor Courtat theBronx Zoo, were commissioned to design the stations. In the early 1890s, the city's transit commissioners had recommended that subway stations be painted and decorated in order to make the experience of using the system pleasant. They took further inspiration from the contemporaryCity Beautiful movement, which called for beautiful public architecture in the hope that it would inspire citizens to act virtuously. Their use of theVictorian Gothicarchitectural stylereflected its popularity at that time for train stations. The six elevated stations they built in that style on the Contract 1 are extensively decorated on their exterior surfaces, complementing the correspondingtileworkandmosaicsin the underground stations. 242nd Street, which opened on August 1, 1908,is the only elevated terminal station left in that style from Contract 1. Within a few years of the station's opening, ridership on the line north of 157th Street increased sharply. In 1913, 3.1 million tickets were sold at the Van Cortlandt Park station. Undeveloped lots along Broadway to the city's northern limit were quickly bought by builders hoping to profit from the boom in luxury houses, which could reach the subway throughstreetcarlines as well. At that time, it was expected that the line would be extended to 262nd Street.TheHorace Mann Schoolwas built to serve this population. To address overcrowding, in 1909, theNew York Public Service Commissionproposed lengthening the platforms at stations along the original IRT subway.As part of a modification to the IRT's construction contracts made on January 18, 1910, the company was to lengthen station platforms to accommodate ten-car express and six-car local trains. In addition to $1.5 million (equivalent to $50.6 million in 2024) spent on platform lengthening, $500,000 (equivalent to $16.9 million in 2024) was spent on building additional entrances and exits. It was anticipated that these improvements would increase capacity by 25 percent.The side platforms at the 242nd Street station were  extended 62 feet (19 m) to the south.Six-car local trains began operating in October 1910,and ten-car express trains began running on the West Side Line on January 24, 1911. In 1947,Jack Kerouacpassed through the station, then a busy trolley hub, at the end of the first leg of his escape from the city in what becameOn the Road. His goal was to reachU.S. Route 6at theBear Mountain Bridgeand use it as a route along which to goWesttoDenver. The attempt failed when he found very little traffic on Route 6 tohitchrides from, and he returned to the city to take a bus instead. The city government took over the IRT's operations on June 12, 1940.The IRT routes were given numbered designations in 1948 with the introduction of\"R-type\" rolling stock, which containedrollsignswith numbered designations for each service.The route to 242nd Street became known as the1.In 1959, all 1 trains became local. In 2019, theMetropolitan Transportation Authorityannounced that this station would becomeADA-accessibleas part of the agency's 2020–2024 Capital Program. A request for proposals was put out on May 18, 2023 for the contract for a project bundle to make 13 stations accessible, including 242nd Street.A contract for one elevator at the station was awarded in December 2023.Construction on the elevator was begun in late September 2024, and is anticipated to be completed and opened in 2025. The station is served by the1at all times.It is the northern terminus of the 1 train; the next stop to the south is238th Street.There are three components to the station: theplatforms, a control house perpendicular to the tracks at the north end, and a crew quarters building spanning the platform at the south end. From the northeast corner anoverpasscrosses the through-traffic lanes of Broadway. Two stairs descend in either direction from its end, matching the two stairs that descend to the sidewalk from the west of the control house. Just south of the station, the line widens to three tracks, which is the configuration up to just beforeDyckman Street. The station is located 29 feet (8.8 m) above the west side of the street, where parking is located on either side of where West 242nd Street intersects from the west. On that side of the street are commercial buildings, including a largeparking garageon the southwest corner; the east side has the track, football field, tennis courts, swimming pools and other athletic facilities ofVan Cortlandt Park. Also in the park nearby, to the northeast, is theVan Cortlandt House Museum, aNational Historic Landmark. The240th Street Yardis beyond the parking garage to the southwest, next to the campus ofManhattan University, a few blocks west of the station. There is oneisland platformand twoside platforms. The station was formerly set up as aSpanish solutionwith alighting passengers using the side platforms and boarding passengers using the island platform. Now, only the center island platform is open to the public for boarding and disembarking from trains.They are floored in concrete and sheltered with a wooden roof covered in standing-seam metal supported bytrussedsteel T-frames on the side platforms and timber in the center. Roundedraftertails project from theeaves. The sides, except for the open southernmost section, have had metal windscreen added. Under the canopies are modern fluorescent lights. On the eastern platform, the original iron railings support original lights, with dish-shaped downlights on a curved stem. At the south end is the onlyscrolledstation sign remaining anywhere in the subway system. The western platform has its original railing and modern lights. The control house is the dominant architectural feature of the station. The copper-cladtimber frameexterior is painted in a vertical,battenseam pattern. It is topped with a lowhipped roofclad in sheet metal and pierced by two ventilatingdormer windowson the east and west side. Afleur-de-lis–patterned group offinialsat the peak. On the northfacade, narrowcasement windowsare echoed by recessed panels below. The groups of five in the section on either side of the projecting centralbay windoware flanked by blind openings. The bay is supported bycorbeledbracketsand topped with a fangableabove the overhanging eaves at the roofline. Its tripartite narrow windows are surrounded by recessed panels with inset circles on the sides and above. At both sides aresteel frameparapetswith wooden decks. These connect the western stairs and overpass to the control house. The stairs combine structural steel and decorativecast iron. Their supports are braced steelTuscancolumns. Gabled standing-seam metal canopies with box fluorescent lighting over the stairs are on narrow supports with slightlyflutedcapitals. At street level are gabled entries whose support columns are decorated with a geometric pattern similar to that on the control house's projecting bay window. C-shaped brackets support the original signage, now painted over. The steel-framed overpass is an architecturally sympathetic addition. Railings are a more restrained version of the original railings found on the platform. It is floored in wood plank and roofed with slats covered by standing seam metal. At its west end is a coveredverandaleading into the control house. On the inside, the control house is floored in wood plank as well. The walls are finished in a mix of solid andtongue and groovewood paneling. Tall riveted steel arches support the ceiling. The main waiting area has niches where modern heaters have replaced the originalpot-bellied stoves. There is a modern steel and glass token booth andturnstilebank, along withMetroCardvending machines. Former restrooms have been converted into utility and storage rooms. The crew quarters building is located at the south end of the platforms. It is a one-story building sided in corrugated metal with a flat roof, elevated over the tracks and platforms at that end. The siding has been given the appearance ofclapboardand painted gray. A beltcoursecorresponding to the top of the windows has been painted red, the color of the Broadway–Seventh Avenue trunk line, on both side elevations; it is augmented with a series of blocks in the same color descending towards the tracks on the north end. At the south end, a series of projecting nested bays descends to an entrance to track level. To its south is an old signal house also sided in metal. The crew quarters can also be entered from the center platform. Its interior is given over to employee-related functions and is not open to the public. At the north end of the station, past fare control, there are four stairs that lead down to Broadway. Two go to the west side of Broadway, and two go to the east side.", "combined_text": "Van Cortlandt Park–242nd Street station Contents History Construction and opening Later years Station layout Location Platforms Control house Crew quarters Exits See also Notes References External links    TheVan Cortlandt Park–242nd Street stationis the northernterminal stationof theNew York City Subway'sIRT Broadway–Seventh Avenue Line. Located at the intersection of 242nd Street andBroadway(US Route 9) in theRiverdaleneighborhood ofthe Bronx, it is served by the1train at all times. It is adjacent toVan Cortlandt Parkto the east,Manhattan University, and the240th Street Yardof the subway system, along with the affluent neighborhoods ofFieldstonandRiverdaleto the west. It was built from a design by subway architectsHeins & LaFarge. Today it is the only remainingVictorian Gothicelevatedterminal station on the subway, and contains the subway's only remainingscrolledstation sign among itsdecorativeflourishes. In 2005, it was listed on theNational Register of Historic Places. The station was built as part of the Contract 1 system erected from 1904–1908, connectingLower Manhattanto the Bronx. Originally the northern terminus was intended to be Bailey Avenue and 230th Street, a block southeast of the current station at231st Street. After the completion of theHarlem River Ship Canalat the end of the 19th century, the line was rerouted to a new terminus at 242nd Street. Like many of the other terminal stations in theouter boroughs, it was located near a park. Heins & LaFarge, who had already designed theCathedral of St. John the DivinenearColumbia Universityand theAstor Courtat theBronx Zoo, were commissioned to design the stations. In the early 1890s, the city's transit commissioners had recommended that subway stations be painted and decorated in order to make the experience of using the system pleasant. They took further inspiration from the contemporaryCity Beautiful movement, which called for beautiful public architecture in the hope that it would inspire citizens to act virtuously. Their use of theVictorian Gothicarchitectural stylereflected its popularity at that time for train stations. The six elevated stations they built in that style on the Contract 1 are extensively decorated on their exterior surfaces, complementing the correspondingtileworkandmosaicsin the underground stations. 242nd Street, which opened on August 1, 1908,is the only elevated terminal station left in that style from Contract 1. Within a few years of the station's opening, ridership on the line north of 157th Street increased sharply. In 1913, 3.1 million tickets were sold at the Van Cortlandt Park station. Undeveloped lots along Broadway to the city's northern limit were quickly bought by builders hoping to profit from the boom in luxury houses, which could reach the subway throughstreetcarlines as well. At that time, it was expected that the line would be extended to 262nd Street.TheHorace Mann Schoolwas built to serve this population. To address overcrowding, in 1909, theNew York Public Service Commissionproposed lengthening the platforms at stations along the original IRT subway.As part of a modification to the IRT's construction contracts made on January 18, 1910, the company was to lengthen station platforms to accommodate ten-car express and six-car local trains. In addition to $1.5 million (equivalent to $50.6 million in 2024) spent on platform lengthening, $500,000 (equivalent to $16.9 million in 2024) was spent on building additional entrances and exits. It was anticipated that these improvements would increase capacity by 25 percent.The side platforms at the 242nd Street station were  extended 62 feet (19 m) to the south.Six-car local trains began operating in October 1910,and ten-car express trains began running on the West Side Line on January 24, 1911. In 1947,Jack Kerouacpassed through the station, then a busy trolley hub, at the end of the first leg of his escape from the city in what becameOn the Road. His goal was to reachU.S. Route 6at theBear Mountain Bridgeand use it as a route along which to goWesttoDenver. The attempt failed when he found very little traffic on Route 6 tohitchrides from, and he returned to the city to take a bus instead. The city government took over the IRT's operations on June 12, 1940.The IRT routes were given numbered designations in 1948 with the introduction of\"R-type\" rolling stock, which containedrollsignswith numbered designations for each service.The route to 242nd Street became known as the1.In 1959, all 1 trains became local. In 2019, theMetropolitan Transportation Authorityannounced that this station would becomeADA-accessibleas part of the agency's 2020–2024 Capital Program. A request for proposals was put out on May 18, 2023 for the contract for a project bundle to make 13 stations accessible, including 242nd Street.A contract for one elevator at the station was awarded in December 2023.Construction on the elevator was begun in late September 2024, and is anticipated to be completed and opened in 2025. The station is served by the1at all times.It is the northern terminus of the 1 train; the next stop to the south is238th Street.There are three components to the station: theplatforms, a control house perpendicular to the tracks at the north end, and a crew quarters building spanning the platform at the south end. From the northeast corner anoverpasscrosses the through-traffic lanes of Broadway. Two stairs descend in either direction from its end, matching the two stairs that descend to the sidewalk from the west of the control house. Just south of the station, the line widens to three tracks, which is the configuration up to just beforeDyckman Street. The station is located 29 feet (8.8 m) above the west side of the street, where parking is located on either side of where West 242nd Street intersects from the west. On that side of the street are commercial buildings, including a largeparking garageon the southwest corner; the east side has the track, football field, tennis courts, swimming pools and other athletic facilities ofVan Cortlandt Park. Also in the park nearby, to the northeast, is theVan Cortlandt House Museum, aNational Historic Landmark. The240th Street Yardis beyond the parking garage to the southwest, next to the campus ofManhattan University, a few blocks west of the station. There is oneisland platformand twoside platforms. The station was formerly set up as aSpanish solutionwith alighting passengers using the side platforms and boarding passengers using the island platform. Now, only the center island platform is open to the public for boarding and disembarking from trains.They are floored in concrete and sheltered with a wooden roof covered in standing-seam metal supported bytrussedsteel T-frames on the side platforms and timber in the center. Roundedraftertails project from theeaves. The sides, except for the open southernmost section, have had metal windscreen added. Under the canopies are modern fluorescent lights. On the eastern platform, the original iron railings support original lights, with dish-shaped downlights on a curved stem. At the south end is the onlyscrolledstation sign remaining anywhere in the subway system. The western platform has its original railing and modern lights. The control house is the dominant architectural feature of the station. The copper-cladtimber frameexterior is painted in a vertical,battenseam pattern. It is topped with a lowhipped roofclad in sheet metal and pierced by two ventilatingdormer windowson the east and west side. Afleur-de-lis–patterned group offinialsat the peak. On the northfacade, narrowcasement windowsare echoed by recessed panels below. The groups of five in the section on either side of the projecting centralbay windoware flanked by blind openings. The bay is supported bycorbeledbracketsand topped with a fangableabove the overhanging eaves at the roofline. Its tripartite narrow windows are surrounded by recessed panels with inset circles on the sides and above. At both sides aresteel frameparapetswith wooden decks. These connect the western stairs and overpass to the control house. The stairs combine structural steel and decorativecast iron. Their supports are braced steelTuscancolumns. Gabled standing-seam metal canopies with box fluorescent lighting over the stairs are on narrow supports with slightlyflutedcapitals. At street level are gabled entries whose support columns are decorated with a geometric pattern similar to that on the control house's projecting bay window. C-shaped brackets support the original signage, now painted over. The steel-framed overpass is an architecturally sympathetic addition. Railings are a more restrained version of the original railings found on the platform. It is floored in wood plank and roofed with slats covered by standing seam metal. At its west end is a coveredverandaleading into the control house. On the inside, the control house is floored in wood plank as well. The walls are finished in a mix of solid andtongue and groovewood paneling. Tall riveted steel arches support the ceiling. The main waiting area has niches where modern heaters have replaced the originalpot-bellied stoves. There is a modern steel and glass token booth andturnstilebank, along withMetroCardvending machines. Former restrooms have been converted into utility and storage rooms. The crew quarters building is located at the south end of the platforms. It is a one-story building sided in corrugated metal with a flat roof, elevated over the tracks and platforms at that end. The siding has been given the appearance ofclapboardand painted gray. A beltcoursecorresponding to the top of the windows has been painted red, the color of the Broadway–Seventh Avenue trunk line, on both side elevations; it is augmented with a series of blocks in the same color descending towards the tracks on the north end. At the south end, a series of projecting nested bays descends to an entrance to track level. To its south is an old signal house also sided in metal. The crew quarters can also be entered from the center platform. Its interior is given over to employee-related functions and is not open to the public. At the north end of the station, past fare control, there are four stairs that lead down to Broadway. Two go to the west side of Broadway, and two go to the east side.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Van_Cortlandt_Park%E2%80%93242nd_Street_station", "https://en.wikipedia.org/wiki/Van_Cortlandt_Park%E2%80%93242nd_Street_station", "https://en.wikipedia.org/wiki/Van_Cortlandt_Park%E2%80%93242nd_Street_station", "https://en.wikipedia.org/wiki/Geographic_coordinate_system", "https://en.wikipedia.org/wiki/1_(New_York_City_Subway_service)", "https://en.wikipedia.org/wiki/The_Bronx", "https://en.wikipedia.org/wiki/Riverdale,_Bronx", "https://en.wikipedia.org/wiki/Fieldston,_Bronx"]},
{"id": "9df7eec05c9b", "url": "https://en.wikipedia.org/wiki/International_organization", "title": "International organization", "headings": ["Contents", "Terminology", "History", "Expansion and growth", "Types and purpose", "Regional organizations", "Participation and involvement", "Privileges and immunities", "United Nations agencies and related organizations", "See also", "References", "Further reading", "External links"], "content": "Aninternational organization, also known as anintergovernmental organization(IGO) or aninternational institution, is anorganizationthat is established by atreatyor other type of instrument governed byinternational lawthat possesses its own legal personality, such as theUnited Nations, theCouncil of Europe,African Union,MercosurandBRICS.International organizations are composed of primarilymember states, but may also include other entities, such as other international organizations, firms, and nongovernmental organizations.Additionally, entities may hold observer status. Within the international relations literature, international organizations facilitate cooperation between states by reducingtransaction costs,providing information,makingcommitments more credible,establishingfocal pointsfor coordination,facilitating the principle of reciprocity,extending the shadow of the future,and enabling interlinkages of issues, which raises the cost of noncompliance.States may comply with the decisions of international organizations, even when they do not want to, forrational cost-benefit calculations(to reap concrete rewards of future cooperation and avoid punishment) andnormative reasons(social learning and socialization). International organizations vary in terms of: inclusive or exclusive membership; broad or narrow scope; equal or unequal control by members; precision and flexibility of rules; hard or soft obligations; and delegation of power to the international organization.Examples of international organizations includeUN General Assembly,World Trade Organization,African Development Bank,UN Economic and Social Council,UN Security Council,Asian Development Bank,International Bank for Reconstruction and Development,International Monetary Fund,International Finance Corporation,Inter-American Development Bank, andUnited Nations Environment Programme. Scottish law professorJames Lorimerhas been credited with coining the term \"international organization\" in a 1871 article in theRevue de Droit International et de Legislation Compare.Lorimer use the term frequently in his two-volumeInstitutes of the Law of Nations(1883, 1884). Other early uses of the term were by law professorWalther Schuckingin works published in 1907, 1908 and 1909, and by political science professorPaul S. Reinschin 1911.In 1935, Pitman B. Potter defined international organization as \"an association or union of nations established or recognized by them for the purpose of realizing a common end\". He distinguished between bilateral and multilateral organizations on one end and customary or conventional organizations on the other end.In his 1922 bookAn Introduction to the Study of International Organization, Potter argued that international organization was distinct from \"international intercourse\" (all relations between states), \"international law\" (which lacks enforcement) andworld government. International Organizations are sometimes referred to asintergovernmental organizations(IGOs), to clarify the distinction frominternational non-governmental organizations(INGOs), which arenon-governmental organizations(NGOs) that operate internationally. These include internationalnonprofit organizationssuch as theWorld Organization of the Scout Movement,International Committee of the Red CrossandMédecins Sans Frontières, as well as lobby groups that represent the interests of multinational corporations. IGOs are established by atreatythat acts as a charter creating the group. Treaties are formed when lawful representatives (governments) of several states go through a ratification process, providing the IGO with an international legal personality. Intergovernmental organizations are an important aspect ofpublic international law. Intergovernmental organizations in a legal sense should be distinguished from simple groupings or coalitions of states, such as theG7or theQuartet. Such groups or associations have not been founded by a constituent document and exist only astask groups. Intergovernmental organizations must also be distinguished from treaties. Many treaties (such as theNorth American Free Trade Agreement, or theGeneral Agreement on Tariffs and Tradebefore the establishment of theWorld Trade Organization) do not establish an independent secretariat and instead rely on the parties for their administration, for example by setting up ajoint committee. Other treaties have established an administrative apparatus which was not deemed to have been granted binding legal authority.The broader concept wherein relations among three or more states are organized according to certain principles they hold in common ismultilateralism. An early prominent example of an international organization is theCongress of Viennaof 1814–1815, which was an international diplomatic conference to reconstitute the European political order after the downfall of the French Emperor Napoleon. States then became the main decision makers who preferred to maintain their sovereignty as of 1648 at the Westphalian treaty that closed the 30 Years' War in Europe. TheCentral Commission for Navigation on the Rhine, founded in 1815, is the world’s oldest international organization still in operation. The oldest international organization established employing a treaty and creating a permanent secretariat with a global membership was theInternational Telecommunication Union, founded in 1865. TheUniversal Postal Union, established in 1874 as the General Postal Union, is the third oldest extant international organization. The first general international organization—addressing a variety of issues—was theLeague of Nations, founded on 10 January 1920 with a principal mission of maintaining world peace after World War I. TheUnited Nationsfollowed this model afterWorld War II. This was signed on 26 June 1945, in San Francisco, at the conclusion of the United Nations Conference on International Organization, and came into force on 24 October 1945.Currently, the UN is the main IGO with its arms such as the United Nations Security Council (UNSC), the General Assembly (UNGA), the International Court of Justice (ICJ), the Secretariat (UNSA), the Trusteeship Council (UNTC) and the Economic and Social Council (ECOSOC). When defined as \"organizations with at least three state parties, a permanent headquarters or secretariat, as well as regular meetings and budgets\", the number of IGOs in the world increased from about 60 in 1940 to about 350 in 1980, after which it has remained roughly constant. Intergovernmental organizations differ in function, membership, and membership criteria. They have various goals and scopes, often outlined in the treaty orcharter. Some IGOs developed to fulfill a need for a neutral forum for debate or negotiation to resolve disputes. Others developed to carry out mutual interests with unified aims to preserve peace throughconflict resolutionand betterinternational relations, promote international cooperation on matters such asenvironmental protection, to promotehuman rights, to promotesocial development(education,health care), to renderhumanitarian aid, and toeconomic development. Some are more general in scope (theUnited Nations) while others may have subject-specific missions (such asINTERPOLor theInternational Telecommunication Unionand otherstandards organizations). Common types include: In regional organizations like theEuropean Union,African Union,NATO,ASEANandMercosur, there are restrictions on membership due to factors such as geography or political regimes. To enter the European Union (EU), the states require different criteria; member states need to be European, liberal-democratic political system, and be a capitalist economy. The oldestregional organizationis theCentral Commission for Navigation on the Rhine, created in 1815 by theCongress of Vienna. There are several different reasons a state may choose membership in an intergovernmental organization. But there are also reasons membership may be rejected. Reasons for participation: Reasons for rejecting membership: Intergovernmental organizations are provided with privileges and immunities that are intended to ensure their independent and effective functioning. They are specified in the treaties that give rise to the organization (such as theConvention on the Privileges and Immunities of the United Nationsand theAgreement on the Privileges and Immunities of the International Criminal Court), which are normally supplemented by further multinational agreements and national regulations (for example theInternational Organizations Immunities Actin the United States). The organizations are thereby immune from the jurisdiction of national courts. Certain privileges and immunities are also specified in theVienna Convention on the Representation of States in their Relations with International Organizations of a Universal Characterof 1975,which however has so far not been signed by 35 states and is thus not yet in force (status: 2022). Rather than by national jurisdiction, legalaccountabilityis intended to be ensured by legal mechanisms that are internal to the intergovernmental organization itselfand access to administrative tribunals. In the course of many court cases where private parties tried to pursue claims against international organizations, there has been a gradual realization that alternative means of dispute settlement are required as states havefundamental human rightsobligations to provide plaintiffs with access to court in view of theirright to a fair trial.Otherwise, the organizations' immunities may be put in question in national and international courts.Some organizations hold proceedings before tribunals relating to their organization to be confidential, and in some instances have threatened disciplinary action should an employee disclose any of the relevant information. Such confidentiality has been criticized as a lack oftransparency. The immunities also extend toemployment law.In this regard, immunity from national jurisdiction necessitates that reasonable alternative means are available to effectively protect employees' rights;in this context, a first instance Dutch court considered an estimated duration of proceedings before theAdministrative Tribunal of the International Labour Organizationof 15 years to be too long.An international organization does not pay taxes, is difficult to prosecute in court and is not obliged to provide information to any parliament. The United Nations focuses on five main areas: \"maintainingpeaceandsecurity, protectinghuman rights, deliveringhumanitarian aid, supportingsustainable development, and upholdinginternational law\".UN agencies, such asUN Relief and Works Agency, are generally regarded as international organizations in their own right. Additionally, the United Nations hasSpecialized Agencies, which are organizations within theUnited Nations Systemthat have their member states (often nearly identical to theUN Member States) and are governed independently by them; examples include international organizations that predate the UN, such as theInternational Telecommunication Union, and theUniversal Postal Union, as well as organizations that were created after the UN such as theWorld Health Organization(which was made up of regional organizations such asPAHOthat predated the UN). A few UN special agencies are very centralized in policy and decision-making, but some are decentralized; for example, the country-based projects or missions' directors and managers can decide what they want to do in the fields. The UN agencies have a variety of tasks based on their specialization and their interests. The UN agencies provide different kinds of assistance tolow-income countriesand middle-income countries, and this assistance would be a good resource for developmental projects in developing countries. The UN has to protect against any kind of human rights violation, and in the UN system, some specialized agencies, like ILO and United Nations High Commissioner for Refugees (UNHCR), work in the human rights' protection fields.The UN agency, ILO, is trying to end any kind of discrimination in the work field and child labor; after that, this agency promotes fundamental labor rights and to get safe and secure for the laborers.United Nations Environment Program(UNEP) is one of the UN's (United Nations) agencies and is an international organization that coordinates U.N. activities on the environment. ", "combined_text": "International organization Contents Terminology History Expansion and growth Types and purpose Regional organizations Participation and involvement Privileges and immunities United Nations agencies and related organizations See also References Further reading External links Aninternational organization, also known as anintergovernmental organization(IGO) or aninternational institution, is anorganizationthat is established by atreatyor other type of instrument governed byinternational lawthat possesses its own legal personality, such as theUnited Nations, theCouncil of Europe,African Union,MercosurandBRICS.International organizations are composed of primarilymember states, but may also include other entities, such as other international organizations, firms, and nongovernmental organizations.Additionally, entities may hold observer status. Within the international relations literature, international organizations facilitate cooperation between states by reducingtransaction costs,providing information,makingcommitments more credible,establishingfocal pointsfor coordination,facilitating the principle of reciprocity,extending the shadow of the future,and enabling interlinkages of issues, which raises the cost of noncompliance.States may comply with the decisions of international organizations, even when they do not want to, forrational cost-benefit calculations(to reap concrete rewards of future cooperation and avoid punishment) andnormative reasons(social learning and socialization). International organizations vary in terms of: inclusive or exclusive membership; broad or narrow scope; equal or unequal control by members; precision and flexibility of rules; hard or soft obligations; and delegation of power to the international organization.Examples of international organizations includeUN General Assembly,World Trade Organization,African Development Bank,UN Economic and Social Council,UN Security Council,Asian Development Bank,International Bank for Reconstruction and Development,International Monetary Fund,International Finance Corporation,Inter-American Development Bank, andUnited Nations Environment Programme. Scottish law professorJames Lorimerhas been credited with coining the term \"international organization\" in a 1871 article in theRevue de Droit International et de Legislation Compare.Lorimer use the term frequently in his two-volumeInstitutes of the Law of Nations(1883, 1884). Other early uses of the term were by law professorWalther Schuckingin works published in 1907, 1908 and 1909, and by political science professorPaul S. Reinschin 1911.In 1935, Pitman B. Potter defined international organization as \"an association or union of nations established or recognized by them for the purpose of realizing a common end\". He distinguished between bilateral and multilateral organizations on one end and customary or conventional organizations on the other end.In his 1922 bookAn Introduction to the Study of International Organization, Potter argued that international organization was distinct from \"international intercourse\" (all relations between states), \"international law\" (which lacks enforcement) andworld government. International Organizations are sometimes referred to asintergovernmental organizations(IGOs), to clarify the distinction frominternational non-governmental organizations(INGOs), which arenon-governmental organizations(NGOs) that operate internationally. These include internationalnonprofit organizationssuch as theWorld Organization of the Scout Movement,International Committee of the Red CrossandMédecins Sans Frontières, as well as lobby groups that represent the interests of multinational corporations. IGOs are established by atreatythat acts as a charter creating the group. Treaties are formed when lawful representatives (governments) of several states go through a ratification process, providing the IGO with an international legal personality. Intergovernmental organizations are an important aspect ofpublic international law. Intergovernmental organizations in a legal sense should be distinguished from simple groupings or coalitions of states, such as theG7or theQuartet. Such groups or associations have not been founded by a constituent document and exist only astask groups. Intergovernmental organizations must also be distinguished from treaties. Many treaties (such as theNorth American Free Trade Agreement, or theGeneral Agreement on Tariffs and Tradebefore the establishment of theWorld Trade Organization) do not establish an independent secretariat and instead rely on the parties for their administration, for example by setting up ajoint committee. Other treaties have established an administrative apparatus which was not deemed to have been granted binding legal authority.The broader concept wherein relations among three or more states are organized according to certain principles they hold in common ismultilateralism. An early prominent example of an international organization is theCongress of Viennaof 1814–1815, which was an international diplomatic conference to reconstitute the European political order after the downfall of the French Emperor Napoleon. States then became the main decision makers who preferred to maintain their sovereignty as of 1648 at the Westphalian treaty that closed the 30 Years' War in Europe. TheCentral Commission for Navigation on the Rhine, founded in 1815, is the world’s oldest international organization still in operation. The oldest international organization established employing a treaty and creating a permanent secretariat with a global membership was theInternational Telecommunication Union, founded in 1865. TheUniversal Postal Union, established in 1874 as the General Postal Union, is the third oldest extant international organization. The first general international organization—addressing a variety of issues—was theLeague of Nations, founded on 10 January 1920 with a principal mission of maintaining world peace after World War I. TheUnited Nationsfollowed this model afterWorld War II. This was signed on 26 June 1945, in San Francisco, at the conclusion of the United Nations Conference on International Organization, and came into force on 24 October 1945.Currently, the UN is the main IGO with its arms such as the United Nations Security Council (UNSC), the General Assembly (UNGA), the International Court of Justice (ICJ), the Secretariat (UNSA), the Trusteeship Council (UNTC) and the Economic and Social Council (ECOSOC). When defined as \"organizations with at least three state parties, a permanent headquarters or secretariat, as well as regular meetings and budgets\", the number of IGOs in the world increased from about 60 in 1940 to about 350 in 1980, after which it has remained roughly constant. Intergovernmental organizations differ in function, membership, and membership criteria. They have various goals and scopes, often outlined in the treaty orcharter. Some IGOs developed to fulfill a need for a neutral forum for debate or negotiation to resolve disputes. Others developed to carry out mutual interests with unified aims to preserve peace throughconflict resolutionand betterinternational relations, promote international cooperation on matters such asenvironmental protection, to promotehuman rights, to promotesocial development(education,health care), to renderhumanitarian aid, and toeconomic development. Some are more general in scope (theUnited Nations) while others may have subject-specific missions (such asINTERPOLor theInternational Telecommunication Unionand otherstandards organizations). Common types include: In regional organizations like theEuropean Union,African Union,NATO,ASEANandMercosur, there are restrictions on membership due to factors such as geography or political regimes. To enter the European Union (EU), the states require different criteria; member states need to be European, liberal-democratic political system, and be a capitalist economy. The oldestregional organizationis theCentral Commission for Navigation on the Rhine, created in 1815 by theCongress of Vienna. There are several different reasons a state may choose membership in an intergovernmental organization. But there are also reasons membership may be rejected. Reasons for participation: Reasons for rejecting membership: Intergovernmental organizations are provided with privileges and immunities that are intended to ensure their independent and effective functioning. They are specified in the treaties that give rise to the organization (such as theConvention on the Privileges and Immunities of the United Nationsand theAgreement on the Privileges and Immunities of the International Criminal Court), which are normally supplemented by further multinational agreements and national regulations (for example theInternational Organizations Immunities Actin the United States). The organizations are thereby immune from the jurisdiction of national courts. Certain privileges and immunities are also specified in theVienna Convention on the Representation of States in their Relations with International Organizations of a Universal Characterof 1975,which however has so far not been signed by 35 states and is thus not yet in force (status: 2022). Rather than by national jurisdiction, legalaccountabilityis intended to be ensured by legal mechanisms that are internal to the intergovernmental organization itselfand access to administrative tribunals. In the course of many court cases where private parties tried to pursue claims against international organizations, there has been a gradual realization that alternative means of dispute settlement are required as states havefundamental human rightsobligations to provide plaintiffs with access to court in view of theirright to a fair trial.Otherwise, the organizations' immunities may be put in question in national and international courts.Some organizations hold proceedings before tribunals relating to their organization to be confidential, and in some instances have threatened disciplinary action should an employee disclose any of the relevant information. Such confidentiality has been criticized as a lack oftransparency. The immunities also extend toemployment law.In this regard, immunity from national jurisdiction necessitates that reasonable alternative means are available to effectively protect employees' rights;in this context, a first instance Dutch court considered an estimated duration of proceedings before theAdministrative Tribunal of the International Labour Organizationof 15 years to be too long.An international organization does not pay taxes, is difficult to prosecute in court and is not obliged to provide information to any parliament. The United Nations focuses on five main areas: \"maintainingpeaceandsecurity, protectinghuman rights, deliveringhumanitarian aid, supportingsustainable development, and upholdinginternational law\".UN agencies, such asUN Relief and Works Agency, are generally regarded as international organizations in their own right. Additionally, the United Nations hasSpecialized Agencies, which are organizations within theUnited Nations Systemthat have their member states (often nearly identical to theUN Member States) and are governed independently by them; examples include international organizations that predate the UN, such as theInternational Telecommunication Union, and theUniversal Postal Union, as well as organizations that were created after the UN such as theWorld Health Organization(which was made up of regional organizations such asPAHOthat predated the UN). A few UN special agencies are very centralized in policy and decision-making, but some are decentralized; for example, the country-based projects or missions' directors and managers can decide what they want to do in the fields. The UN agencies have a variety of tasks based on their specialization and their interests. The UN agencies provide different kinds of assistance tolow-income countriesand middle-income countries, and this assistance would be a good resource for developmental projects in developing countries. The UN has to protect against any kind of human rights violation, and in the UN system, some specialized agencies, like ILO and United Nations High Commissioner for Refugees (UNHCR), work in the human rights' protection fields.The UN agency, ILO, is trying to end any kind of discrimination in the work field and child labor; after that, this agency promotes fundamental labor rights and to get safe and secure for the laborers.United Nations Environment Program(UNEP) is one of the UN's (United Nations) agencies and is an international organization that coordinates U.N. activities on the environment.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/International_organization", "https://en.wikipedia.org/wiki/International_organization", "https://en.wikipedia.org/wiki/International_organization", "https://en.wikipedia.org/wiki/United_Nations_Office_at_Geneva", "https://en.wikipedia.org/wiki/United_Nations", "https://en.wikipedia.org/wiki/Geneva", "https://en.wikipedia.org/wiki/Organization", "https://en.wikipedia.org/wiki/Treaty"]},
{"id": "ffbfd2b56bb9", "url": "https://en.wikipedia.org/wiki/Warren_Publishing", "title": "Warren Publishing", "headings": ["Contents", "Publishing history", "Founding", "Vampirella and international artists", "Line expansion in the 1970s", "Decline and bankruptcy", "Artists and writers", "Milestones", "Chronological list of magazines", "References", "External links"], "content": "Warren Publishingwas an American magazine company founded byJames Warren, who published his first magazines in 1957 and continued in the business for decades. Magazines published by Warren includeAfter Hours,Creepy,Eerie,Famous Monsters of Filmland,Help!, andVampirella. Initially based inPhiladelphia, Pennsylvania, the company moved by 1965 toNew York City. Begun by James Warren, Warren Publishing's initial publications were thehorror-fantasy--science fictionmoviemagazineFamous Monsters of FilmlandandMonster World, both edited byForrest J Ackerman. Warren soon publishedSpacemenmagazine and in 1960Help!magazine, with the first employee of the magazine beingGloria Steinem. After introducing what he called \"Monster Comics\" inMonster World, Warren expanded in 1964 with horror-comicsstories in the sister magazinesCreepyandEerie– black-and-white publications in a standard magazine format, rather than comic-book size, and selling for 35 cents as opposed to the standard comic-book price of 12 cents. Such a format, Warren explained, averted the restrictions of theComics Code Authority, the comic-book industry's self-censorship body: The Comics Code saved the industry from turmoil, but at the same time, it had a cleansing kind of effect on comics, making them \"clean, proper and family-oriented\" ... We would overcome this by saying to the Code Authority, the industry, the printers, and the distributors: 'We are not a comic book; we are a magazine.Creepyis magazine-sized and will be sold on magazine racks, not comic book racks\".Creepy's manifesto was brief and direct: First, it was to be a magazine format, 8½\" × 11\", going to an older audience not subject to the Code Authority.\" By publishing graphic stories in a magazine format to which the Code did not apply, Warren paved the way for such later graphic-story magazines as theAmericanversion ofHeavy Metal;Marvel Comics'Epic Illustrated; andPsychoand other series fromSkywald Publications. Russ Joneswas the founding editor ofCreepyin 1964. A year later,Archie Goodwinsucceeded him, withJoe Orlandoacting as a behind-the-scenes story editor.Goodwin, who would become one of comics' foremost and most influential writers, helped to establish the company as a leader in its field. From 1965 to 1966, Warren also published the four-issueBlazing Combat, awar-comicsmagazine with anti-war themes, controversial at the time. After 17 issues ofCreepyand 11 ofEerie, Goodwin resigned as editor in 1967. The movement of Warren's operations from Philadelphia to New York City, combined with a change in distributors and a downturn in the market imposed a cash flow problem on Warren, and Goodwin along with all of the artists except forTom SuttonandRocke Mastroserio(who soon died) departed the company. During the next two-and-a-half years, Warren's publications consisted primarily of reprints from the early issues.  During this period, a variety of editors ran the magazines includingBill Parente,Nicola Cuti, and Warren himself.  Things started picking up again for Warren in 1969 with the premiere of its third horror magazine,Vampirella.  Many of Warren's original artists returned during this period, as would Goodwin for a period of time in 1970 and 1971. After Goodwin's second departure, editors would includeJ.R. Cochran. The art director wasBilly Graham. In 1971, Warren began using artists from theBarcelonastudio ofSpanishagencySelecciones Illustrada. Over the next few years, Spanish artists would dominate the magazines. Additional Spanish artists from S.I.'sValenciastudio began freelancing for Warren in 1974. In 1973, new editorBill DuBay, who had originally joined the company as an artist early in 1970, transformed Warren's magazines to create a uniform style. The following year, Warren Publishing was dissolved and replaced by Warren Communications, a sister company James Warren had founded in 1972.  Dubay was editor for all three of Warren's horror magazines until 1976, except for a short period of time in 1974 where Goodwin returned to edit four issues ofCreepyand two ofVampirella. During this time, the frequency of Warren's magazines was increased to nine issues a year. In 1974, DuBay oversaw a new black-and-white magazine,The Spirit, which revived acclaimed writer-artistWill Eisner's masked detective of 1940s and early-1950snewspaperSunday supplements, reprinting the character's seven-page, semi-anthological stories for a new generation. The magazine featured new covers by Eisner and an occasional reprint in color.(The Spiritwould later move toKitchen Sink Press.) The same year, Warren debutedComix International, a color magazine reprinting earlier Warren stories. After Dubay's departure,Louise Jones, his former assistant, headed the editorial staff from 1976 to 1980.  Toward the end of Dubay's period of editorship many American artists had returned to the magazines, includingJohn Severin,Alex Toth, andRuss Heathand they contributed many stories during Jones' time as editor.  FormerDC ComicspublisherCarmine Infantinowould also join the company during this period and pencil over 50 stories.  Much like the wave of Spanish artists that dominated throughout the mid-1970s, a number of artists from thePhilippineswould begin contributing during this period. Dubay returned as editor after Jones' departure, using the alias \"Will Richardson\". Toward the end of the 1970s, Warren published two new magazines edited by Dubay: the science-fiction anthology1984, in 1978 (which would change its name to1994two years later); and, in 1979,The Rook, starring atime-travelingadventurer whose stories had appeared inEeriesince 1977. James Warren's bad health, combined with changing tastes and business problems, led to internal turmoil and editorial turnover.The company suspended publishing in late 1981,editor Bill Dubay left in 1982,and Warren declared bankruptcy in 1983.In August 1983,Harris Publicationsacquired company assets at auction,and published new and reprintedVampirellacomics;Creepy#146 (Summer 1985), continuing the numbering of the original series and containing both new and reprinted material,Creepy: The Limited Series, a four-issue miniseries of new stories;and other Warren-related comics.  A 1998 lawsuit by James Warrenresulted in his reacquisition of the rights toCreepyandEerie.Dark Horse Comicsbegan issuing reprints with the ongoing licensed seriesCreepy Archivesin 2008,and began publishing new material withCreepyvol. 2 in 2009andEerievol. 2 in 2012. Illustrators included such established artists as Orlando,Neal Adams,Gene Colan,Frank Frazetta,Angelo Torres,Roy G. Krenkel,Gray Morrow,Al Williamson,Johnny Craig,Reed Crandall,Alex Toth,John Severin,Russ HeathandWally Wood, plus a newer group of talents, includingDan Adkins,Richard Bassford,Roger Brand,Frank Brunner,Rich Buckler,Dave Cockrum,Nicola Cuti,Richard Corben,Ken Kelly,Pepe Moreno,Mike Royer,Tom Sutton, andBerni Wrightson. The Spanish artists fromSelecciones IlustradasincludedEsteban Maroto,José Ortiz,Luis Bermejo,Rafael Aura Leon,Luis Garcia,Jose Gonzalez,Isidro Mones, Martin Salvador,Fernando Fernandez,Leopold Sanchez,Ramon Torrents,Jose Bea,Vicente Alcazar, Jose Gual, Felix Mas and Jaime Brocal. Artists from thePhilippinesincludedAlex Niño,Rudy Nebres,Alfredo AlcalaandAbel Laxamana.  Other international artists who worked for Warren include Gonzalo Mayo (Peru),Pablo Marcos(Peru), Leo Duranona (Argentina) and Paul Neary (U.K.). Cover artists forCreepy,EerieandVampirellaincluded Adkins, Frazetta, Kelly, Morrow, Sutton,Ken Barr,Vaughn Bodé,Pat Boyette, Ron Cobb, Richard Conway,Jack Davis,H.R. Giger,Basil Gogos, Bill Hughes,Terrance Lindall, Gutenberg Monteiro, Albert Nuetzell, Vic Prezo,Sanjulián, Vincente Segrelles, Kenneth Smith, Enrich Torres andBoris Vallejo. Writers included Goodwin, Cuti, Dubay,Al Hewetson,Bruce Jones,Doug Moench,Budd Lewis,Gerry Boudreau,Rich Margopoulos,Don McGregor,Steve Skeates,Jim Stenstrum,Lynn Marron, andT. Casey Brennan. The first-known romanticinterracial kissin mainstream comics (as opposed tounderground comix) occurred in Warren'sCreepy#43 (Jan. 1972), in \"The Men Who Called Him Monster\" by writerDon McGregorand artistLuis Garcia. McGregor said in 2001 that the kiss was actually due to the artist misunderstanding the line \"This is the clincher\" in the script.McGregor would later script color comic books' first known interracial romantic kiss, in the \"Killraven: Warrior of the Worlds\" feature inAmazing Adventures#31 (July 1975). Ongoing publications;one-shotsnot listed", "combined_text": "Warren Publishing Contents Publishing history Founding Vampirella and international artists Line expansion in the 1970s Decline and bankruptcy Artists and writers Milestones Chronological list of magazines References External links Warren Publishingwas an American magazine company founded byJames Warren, who published his first magazines in 1957 and continued in the business for decades. Magazines published by Warren includeAfter Hours,Creepy,Eerie,Famous Monsters of Filmland,Help!, andVampirella. Initially based inPhiladelphia, Pennsylvania, the company moved by 1965 toNew York City. Begun by James Warren, Warren Publishing's initial publications were thehorror-fantasy--science fictionmoviemagazineFamous Monsters of FilmlandandMonster World, both edited byForrest J Ackerman. Warren soon publishedSpacemenmagazine and in 1960Help!magazine, with the first employee of the magazine beingGloria Steinem. After introducing what he called \"Monster Comics\" inMonster World, Warren expanded in 1964 with horror-comicsstories in the sister magazinesCreepyandEerie– black-and-white publications in a standard magazine format, rather than comic-book size, and selling for 35 cents as opposed to the standard comic-book price of 12 cents. Such a format, Warren explained, averted the restrictions of theComics Code Authority, the comic-book industry's self-censorship body: The Comics Code saved the industry from turmoil, but at the same time, it had a cleansing kind of effect on comics, making them \"clean, proper and family-oriented\" ... We would overcome this by saying to the Code Authority, the industry, the printers, and the distributors: 'We are not a comic book; we are a magazine.Creepyis magazine-sized and will be sold on magazine racks, not comic book racks\".Creepy's manifesto was brief and direct: First, it was to be a magazine format, 8½\" × 11\", going to an older audience not subject to the Code Authority.\" By publishing graphic stories in a magazine format to which the Code did not apply, Warren paved the way for such later graphic-story magazines as theAmericanversion ofHeavy Metal;Marvel Comics'Epic Illustrated; andPsychoand other series fromSkywald Publications. Russ Joneswas the founding editor ofCreepyin 1964. A year later,Archie Goodwinsucceeded him, withJoe Orlandoacting as a behind-the-scenes story editor.Goodwin, who would become one of comics' foremost and most influential writers, helped to establish the company as a leader in its field. From 1965 to 1966, Warren also published the four-issueBlazing Combat, awar-comicsmagazine with anti-war themes, controversial at the time. After 17 issues ofCreepyand 11 ofEerie, Goodwin resigned as editor in 1967. The movement of Warren's operations from Philadelphia to New York City, combined with a change in distributors and a downturn in the market imposed a cash flow problem on Warren, and Goodwin along with all of the artists except forTom SuttonandRocke Mastroserio(who soon died) departed the company. During the next two-and-a-half years, Warren's publications consisted primarily of reprints from the early issues.  During this period, a variety of editors ran the magazines includingBill Parente,Nicola Cuti, and Warren himself.  Things started picking up again for Warren in 1969 with the premiere of its third horror magazine,Vampirella.  Many of Warren's original artists returned during this period, as would Goodwin for a period of time in 1970 and 1971. After Goodwin's second departure, editors would includeJ.R. Cochran. The art director wasBilly Graham. In 1971, Warren began using artists from theBarcelonastudio ofSpanishagencySelecciones Illustrada. Over the next few years, Spanish artists would dominate the magazines. Additional Spanish artists from S.I.'sValenciastudio began freelancing for Warren in 1974. In 1973, new editorBill DuBay, who had originally joined the company as an artist early in 1970, transformed Warren's magazines to create a uniform style. The following year, Warren Publishing was dissolved and replaced by Warren Communications, a sister company James Warren had founded in 1972.  Dubay was editor for all three of Warren's horror magazines until 1976, except for a short period of time in 1974 where Goodwin returned to edit four issues ofCreepyand two ofVampirella. During this time, the frequency of Warren's magazines was increased to nine issues a year. In 1974, DuBay oversaw a new black-and-white magazine,The Spirit, which revived acclaimed writer-artistWill Eisner's masked detective of 1940s and early-1950snewspaperSunday supplements, reprinting the character's seven-page, semi-anthological stories for a new generation. The magazine featured new covers by Eisner and an occasional reprint in color.(The Spiritwould later move toKitchen Sink Press.) The same year, Warren debutedComix International, a color magazine reprinting earlier Warren stories. After Dubay's departure,Louise Jones, his former assistant, headed the editorial staff from 1976 to 1980.  Toward the end of Dubay's period of editorship many American artists had returned to the magazines, includingJohn Severin,Alex Toth, andRuss Heathand they contributed many stories during Jones' time as editor.  FormerDC ComicspublisherCarmine Infantinowould also join the company during this period and pencil over 50 stories.  Much like the wave of Spanish artists that dominated throughout the mid-1970s, a number of artists from thePhilippineswould begin contributing during this period. Dubay returned as editor after Jones' departure, using the alias \"Will Richardson\". Toward the end of the 1970s, Warren published two new magazines edited by Dubay: the science-fiction anthology1984, in 1978 (which would change its name to1994two years later); and, in 1979,The Rook, starring atime-travelingadventurer whose stories had appeared inEeriesince 1977. James Warren's bad health, combined with changing tastes and business problems, led to internal turmoil and editorial turnover.The company suspended publishing in late 1981,editor Bill Dubay left in 1982,and Warren declared bankruptcy in 1983.In August 1983,Harris Publicationsacquired company assets at auction,and published new and reprintedVampirellacomics;Creepy#146 (Summer 1985), continuing the numbering of the original series and containing both new and reprinted material,Creepy: The Limited Series, a four-issue miniseries of new stories;and other Warren-related comics.  A 1998 lawsuit by James Warrenresulted in his reacquisition of the rights toCreepyandEerie.Dark Horse Comicsbegan issuing reprints with the ongoing licensed seriesCreepy Archivesin 2008,and began publishing new material withCreepyvol. 2 in 2009andEerievol. 2 in 2012. Illustrators included such established artists as Orlando,Neal Adams,Gene Colan,Frank Frazetta,Angelo Torres,Roy G. Krenkel,Gray Morrow,Al Williamson,Johnny Craig,Reed Crandall,Alex Toth,John Severin,Russ HeathandWally Wood, plus a newer group of talents, includingDan Adkins,Richard Bassford,Roger Brand,Frank Brunner,Rich Buckler,Dave Cockrum,Nicola Cuti,Richard Corben,Ken Kelly,Pepe Moreno,Mike Royer,Tom Sutton, andBerni Wrightson. The Spanish artists fromSelecciones IlustradasincludedEsteban Maroto,José Ortiz,Luis Bermejo,Rafael Aura Leon,Luis Garcia,Jose Gonzalez,Isidro Mones, Martin Salvador,Fernando Fernandez,Leopold Sanchez,Ramon Torrents,Jose Bea,Vicente Alcazar, Jose Gual, Felix Mas and Jaime Brocal. Artists from thePhilippinesincludedAlex Niño,Rudy Nebres,Alfredo AlcalaandAbel Laxamana.  Other international artists who worked for Warren include Gonzalo Mayo (Peru),Pablo Marcos(Peru), Leo Duranona (Argentina) and Paul Neary (U.K.). Cover artists forCreepy,EerieandVampirellaincluded Adkins, Frazetta, Kelly, Morrow, Sutton,Ken Barr,Vaughn Bodé,Pat Boyette, Ron Cobb, Richard Conway,Jack Davis,H.R. Giger,Basil Gogos, Bill Hughes,Terrance Lindall, Gutenberg Monteiro, Albert Nuetzell, Vic Prezo,Sanjulián, Vincente Segrelles, Kenneth Smith, Enrich Torres andBoris Vallejo. Writers included Goodwin, Cuti, Dubay,Al Hewetson,Bruce Jones,Doug Moench,Budd Lewis,Gerry Boudreau,Rich Margopoulos,Don McGregor,Steve Skeates,Jim Stenstrum,Lynn Marron, andT. Casey Brennan. The first-known romanticinterracial kissin mainstream comics (as opposed tounderground comix) occurred in Warren'sCreepy#43 (Jan. 1972), in \"The Men Who Called Him Monster\" by writerDon McGregorand artistLuis Garcia. McGregor said in 2001 that the kiss was actually due to the artist misunderstanding the line \"This is the clincher\" in the script.McGregor would later script color comic books' first known interracial romantic kiss, in the \"Killraven: Warrior of the Worlds\" feature inAmazing Adventures#31 (July 1975). Ongoing publications;one-shotsnot listed", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Warren_Publishing", "https://en.wikipedia.org/wiki/Warren_Publishing", "https://en.wikipedia.org/wiki/Warren_Publishing", "https://en.wikipedia.org/wiki/Comics", "https://en.wikipedia.org/wiki/James_Warren_(publisher)", "https://en.wikipedia.org/wiki/Philadelphia", "https://en.wikipedia.org/wiki/Pennsylvania", "https://en.wikipedia.org/wiki/New_York_City"]},
{"id": "2eb320a83007", "url": "https://en.wikipedia.org/wiki/Walt_Disney_Productions_v._Air_Pirates", "title": "Walt Disney Productions v. Air Pirates", "headings": ["Contents", "Background", "District court proceedings", "Circuit Court opinion", "Impact", "References"], "content": " Walt Disney Productions v. Air Pirates, 581 F.2d 751 (1978), was acopyright lawcase of theUnited States Court of Appeals for the Ninth Circuit,and an important precedent on the use of copyrighted characters for purposes ofparodyorsatire. TheAir Pirateswere a group of cartoonists who published two issues of anunderground comiccalledAir Pirates Funniesin 1971.The comic featured a satirical version ofMickey Mouse(never referred to by his full name) who was positioned as a symbol ofconformisthypocrisyinAmerican culture. The comic also depicted other well-knownDisneycharacters engaging in adult behaviors such as sex and drug consumption. Air Pirates founderDan O'Neillwanted the comic to be noticed by the Disney company and arranged for copies to be smuggled into board meetings.Disney executives became aware of the comic and sued the Air Pirates forcopyright infringement,trademark infringement, andunfair competition. The case was first heard at theUnited States District Court for Northern Californiain 1972. Disney sought aninjunctionagainst further publication and sale of theAir Pirates Funniescomic books featuring depictions of its characters, and for existing copies of the comic books to be destroyed. The Air Pirates claimed that the characters could be used for satirical purposes per thefair usedoctrine ofAmerican copyright law.To raise funds for their defense, the Air Pirates continued to sell copies of the comics plus custom-made artwork satirizing Disney characters atcomic book conventions. The District Court ruled in favor of Disney, O'Neill, the lead artist in theAir Pirates Funniescomics, admitted to drawing the satirical versions of Mickey Mouse and other characters almost exactly like Disney's versions so readers would understand the satire, and to co-opt Disney's claim that the characters represented \"an image of innocent delightfulness\".The company argued that the characters were beloved by children, and depicting those characters engaged in objectionable adult pursuits could damage the company's reputation. Despite noting the satirical value of theAir Pirates Funniesdepictions of several well-known Disney characters, the court held that the depictions were sufficiently similar to the originals to cause confusion among potential readers about the source of the comics. Per theCopyright Act of 1909, this was found to be copyright infringement. The court held that Disney's further claims of trademark infringement and unfair competition weremoot. Tens of thousands of copies ofAir Pirates Funnies, and an associated comic calledThe Tortoise and the Harethat featured the same characters, were seized under a court order in 1972.O'Neill appealed the District Court ruling, and while the case slowly worked its way through the courts, continued to defiantly draw and sell parodies of Disney characters. In 1975, Disney won a $200,000 judgement and arestraining orderagainst Air Pirates for distributing the parodies, which O'Neill continued to ignore.O'Neill maintained that he hoped to lose in court and continually appeal, and perhaps even go to jail, as a statement on Disney's corporate power over popular culture. He gained some sympathetic supporters within the Disney organization and even delivered some of his drawings directly to the corporate offices as part of his campaign against the company. The case finally reached theNinth Circuit Court of Appealsin 1978. The court unanimously upheld the District Court's ruling on copyright infringement, andremandedthe concurrent trademark infringement and unfair competition claims back to the lower court for further discovery (though Disney did not pursue those claims any further).The court rejected the Air Pirates' claim offair usefor satirical purposes, because the depictions of the characters at issue were indistinguishable from Disney's originals. At the Circuit Court, the Air Pirates added afree speechclaim with an argument that copyright infringement lawsuits against satires and parodies wouldchillpublic discussion. The court rejected this argument under the rationale that the Air Pirates could have expressed their opinions about the Disney company without confusingly similar depictions of its characters.O'Neill was also ordered to pay more than $2 million in damages and legal fees to Disney, though the company decided that O'Neill would be unable to pay and settled this matter in 1980, as long as O'Neill promised to no longer infringe on the company's copyrights.Air Pirates appealed the decision to theUnited States Supreme Court, but theirwrit of certioariwas denied and the Circuit Court ruling on copyright infringement stood. While theAir Piratescase worked its way through the courts, it attracted interest from free speech activists and critics of popular culture. Law professor Edward Samuels was skeptical of O'Neill's defiant strategy and later concluded that the saga \"set parody back twenty years\".The dispute has been acknowledged as an important matter in the history ofunderground comics, and was detailed in the 1988 documentary filmComic Book Confidential.The case also resulted in the Disney company gaining a possibly unfair reputation for excessive use of copyright law, though the saga raised awareness of the need for a balance between the interests of rights holders and the creative impulses of satirists. The case is often cited as a formative precedent in copyright law, holding that individual characters can be copyrighted outside of the books or movies in which they appear,while those characters have physical and conceptual qualities that themselves qualify for copyright protection.Meanwhile, simply copying such characters with little alteration for satirical purposes iscopyright infringementand does not qualify asfair use.More fundamentally, the case formed a settled precedent on the copyrightability of cartoon characters,while production companies should receive the benefits from their long-term stewardship of such characters.", "combined_text": "Walt Disney Productions v. Air Pirates Contents Background District court proceedings Circuit Court opinion Impact References  Walt Disney Productions v. Air Pirates, 581 F.2d 751 (1978), was acopyright lawcase of theUnited States Court of Appeals for the Ninth Circuit,and an important precedent on the use of copyrighted characters for purposes ofparodyorsatire. TheAir Pirateswere a group of cartoonists who published two issues of anunderground comiccalledAir Pirates Funniesin 1971.The comic featured a satirical version ofMickey Mouse(never referred to by his full name) who was positioned as a symbol ofconformisthypocrisyinAmerican culture. The comic also depicted other well-knownDisneycharacters engaging in adult behaviors such as sex and drug consumption. Air Pirates founderDan O'Neillwanted the comic to be noticed by the Disney company and arranged for copies to be smuggled into board meetings.Disney executives became aware of the comic and sued the Air Pirates forcopyright infringement,trademark infringement, andunfair competition. The case was first heard at theUnited States District Court for Northern Californiain 1972. Disney sought aninjunctionagainst further publication and sale of theAir Pirates Funniescomic books featuring depictions of its characters, and for existing copies of the comic books to be destroyed. The Air Pirates claimed that the characters could be used for satirical purposes per thefair usedoctrine ofAmerican copyright law.To raise funds for their defense, the Air Pirates continued to sell copies of the comics plus custom-made artwork satirizing Disney characters atcomic book conventions. The District Court ruled in favor of Disney, O'Neill, the lead artist in theAir Pirates Funniescomics, admitted to drawing the satirical versions of Mickey Mouse and other characters almost exactly like Disney's versions so readers would understand the satire, and to co-opt Disney's claim that the characters represented \"an image of innocent delightfulness\".The company argued that the characters were beloved by children, and depicting those characters engaged in objectionable adult pursuits could damage the company's reputation. Despite noting the satirical value of theAir Pirates Funniesdepictions of several well-known Disney characters, the court held that the depictions were sufficiently similar to the originals to cause confusion among potential readers about the source of the comics. Per theCopyright Act of 1909, this was found to be copyright infringement. The court held that Disney's further claims of trademark infringement and unfair competition weremoot. Tens of thousands of copies ofAir Pirates Funnies, and an associated comic calledThe Tortoise and the Harethat featured the same characters, were seized under a court order in 1972.O'Neill appealed the District Court ruling, and while the case slowly worked its way through the courts, continued to defiantly draw and sell parodies of Disney characters. In 1975, Disney won a $200,000 judgement and arestraining orderagainst Air Pirates for distributing the parodies, which O'Neill continued to ignore.O'Neill maintained that he hoped to lose in court and continually appeal, and perhaps even go to jail, as a statement on Disney's corporate power over popular culture. He gained some sympathetic supporters within the Disney organization and even delivered some of his drawings directly to the corporate offices as part of his campaign against the company. The case finally reached theNinth Circuit Court of Appealsin 1978. The court unanimously upheld the District Court's ruling on copyright infringement, andremandedthe concurrent trademark infringement and unfair competition claims back to the lower court for further discovery (though Disney did not pursue those claims any further).The court rejected the Air Pirates' claim offair usefor satirical purposes, because the depictions of the characters at issue were indistinguishable from Disney's originals. At the Circuit Court, the Air Pirates added afree speechclaim with an argument that copyright infringement lawsuits against satires and parodies wouldchillpublic discussion. The court rejected this argument under the rationale that the Air Pirates could have expressed their opinions about the Disney company without confusingly similar depictions of its characters.O'Neill was also ordered to pay more than $2 million in damages and legal fees to Disney, though the company decided that O'Neill would be unable to pay and settled this matter in 1980, as long as O'Neill promised to no longer infringe on the company's copyrights.Air Pirates appealed the decision to theUnited States Supreme Court, but theirwrit of certioariwas denied and the Circuit Court ruling on copyright infringement stood. While theAir Piratescase worked its way through the courts, it attracted interest from free speech activists and critics of popular culture. Law professor Edward Samuels was skeptical of O'Neill's defiant strategy and later concluded that the saga \"set parody back twenty years\".The dispute has been acknowledged as an important matter in the history ofunderground comics, and was detailed in the 1988 documentary filmComic Book Confidential.The case also resulted in the Disney company gaining a possibly unfair reputation for excessive use of copyright law, though the saga raised awareness of the need for a balance between the interests of rights holders and the creative impulses of satirists. The case is often cited as a formative precedent in copyright law, holding that individual characters can be copyrighted outside of the books or movies in which they appear,while those characters have physical and conceptual qualities that themselves qualify for copyright protection.Meanwhile, simply copying such characters with little alteration for satirical purposes iscopyright infringementand does not qualify asfair use.More fundamentally, the case formed a settled precedent on the copyrightability of cartoon characters,while production companies should receive the benefits from their long-term stewardship of such characters.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Walt_Disney_Productions_v._Air_Pirates", "https://en.wikipedia.org/wiki/Walt_Disney_Productions_v._Air_Pirates", "https://en.wikipedia.org/wiki/Walt_Disney_Productions_v._Air_Pirates", "https://en.wikipedia.org/wiki/United_States_Court_of_Appeals_for_the_Ninth_Circuit", "https://en.wikipedia.org/wiki/United_States_District_Court_for_the_Northern_District_of_California", "https://en.wikipedia.org/wiki/Air_Pirates", "https://en.wikipedia.org/wiki/The_Walt_Disney_Company", "https://en.wikipedia.org/wiki/Mickey_Mouse"]},
{"id": "19d081b7e721", "url": "https://en.wikipedia.org/wiki/Debris", "title": "Debris", "headings": ["Contents", "Disaster", "Geological", "Marine", "Meteorological", "Space", "Surgical", "War", "Culinary", "See also", "References", "External links"], "content": "Debris(UK:/ˈdɛbri,ˈdeɪbri/,US:/dəˈbriː/) isrubble, wreckage,ruins,litterand discardedgarbage/refuse/trash, scattered remains of something destroyed, or, as in geology, large rock fragments left by a melting glacier, etc. Depending on context,debriscan refer to a number of different things. The first apparent use of the French word in English is in a 1701 description of the army ofPrince Rupertupon its retreat from a battle with the army of Oliver Cromwell, in England. In disaster scenarios,tornadoesleave behind large pieces of houses and mass destruction overall. This debris also flies around the tornado itself when it is in progress. The tornado's winds capture debris it kicks up in its wind orbit, and spins it inside its vortex. The tornado's wind radius is larger than the funnel itself.Tsunamisandhurricanesalso bring large amounts of debris, such asHurricane Katrinain 2005 andHurricane Sandyin 2012.Earthquakesrock cities to rubble debris. Ingeology, debris usually applies to the remains of geological activity includinglandslides,volcanicexplosions,avalanches,mudflowsorGlacial lake outburst floods(Jökulhlaups) andmoraine,lahars, andlavaeruptions. Geological debris sometimes moves in astreamcalled adebris flow.  When it accumulates at the base of hillsides, it can be called \"talus\" or \"scree\". Inmining, debris calledattleusually consists of rock fragments which contain little or no ore. Marine debrisapplies to floating garbage such asbottles,cans,styrofoam, cruiseshipwaste, offshoreoilandgasexploration and production facilitiespollution, andfishingparaphernalia from professional and recreational boaters. Marine debris is also calledlitterorflotsam and jetsam. Objects that can constitute marine debris include usedautomobiletires,detergentbottles,medical wastes, discarded fishing line andnets, soda cans, andbilgewaste solids. In addition to being unsightly, it can pose a serious threat to marine life,boats,swimmers,divers, and others. For example, each year millions of seabirds, seaturtles,fish, and marinemammalsbecome entangled in marine debris, or ingest plastics which they have mistaken for food. As many as 30,000 northern fur seals per year get caught in abandoned fishing nets and either drown or suffocate.Whalesmistakeplasticbags forsquid, andbirdsmay mistake plastic pellets for fisheggs. At other times, animals accidentally eat the plastic while feeding on natural food. The largest concentration of marine debris is theGreat Pacific Garbage Patch. Marine debris most commonly originates from land-based sources. Various international agencies are currently working to reduce marine debris levels around the world. Inmeteorology, debris usually applies to the remains ofhumanhabitation and naturalfloraafterstormrelated destruction. This debris is also commonly referred to asstorm debris. Storm debris commonly consists of roofing material, downedtreelimbs, downedsigns, downedpower linesand poles, and wind-blown garbage. Storm debris can become a serious problem immediately after a storm, in that it often blocks access to individuals and communities that may require emergency services. This material frequently exists in such large quantities that disposing of it becomes a serious issue for a community. In addition, storm debris is often hazardous by its very nature, since, for example, downed power lines annually account for storm-related deaths. Space debrisusually refers to the remains ofspacecraftthat have either fallen toEarthor are still orbiting Earth. Space debris may also consist of natural components such as chunks ofrockandice. The problem of space debris has grown as various space programs have left legacies of launches, explosions, repairs, and discards in both low Earthorbitand more remote orbits. These orbiting fragments have reached a great enough proportion to constitute a hazard to future space launches of bothsatelliteand crewed vehicles. Various government agencies and international organizations are beginning to track space debris and also research possible solutions to the problem. While many of these items, ranging in size fromnutsandboltsto entire satellites and spacecraft, may fall to Earth, other items located in more remote orbits may stay aloft for centuries. The velocity of some of these pieces of space junk have been clocked in excess of 17,000 miles per hour (27,000 km/h). A piece of space debris falling to Earth leaves a fiery trail, just like ameteor. Adebris diskis a circumstellar disk of dust and debris in orbit around a star. Inmedicine, debris usually refers to biological matter that has accumulated or lodged insurgical instrumentsand is referred to assurgical debris. The presence of surgical debris can result in cross-infections ornosocomial infectionsif not removed and the affected surgical instruments or equipment properlydisinfected. In the aftermath of a war, large areas of the region of conflict are often strewn withwar debrisin the form of abandoned or destroyed hardware and vehicles, mines,unexploded ordnance, bullet casings and other fragments of metal. Much war debris has the potential to be lethal and continues to kill and maim civilian populations for years after the end of a conflict. The risks from war debris may be sufficiently high to prevent or delay the return of refugees. In addition war debris may contain hazardous chemicals or radioactive components that can contaminate the land or poison civilians who come into contact with it. ManyMine clearance agenciesare also involved in the clearance of war debris. Land minesin particular are very dangerous as they can remain active for decades after a conflict, which is why they have been banned by international war regulations. In November 2006 the Protocol on Explosive Remnants of Warcame into effect with 92 countries subscribing to the treaty that requires the parties involved in a conflict to assist with the removal of unexploded ordnance following the end of hostilities. Some of the countries most affected by war debris areAfghanistan,Angola,Cambodia,IraqandLaos. Similarlymilitary debrismay be found in and aroundfiring rangeand military training areas. Debris can also be used as cover for military purposes, depending on the situation. In South Louisiana'sCreoleandCajuncultures, debris (pronounced \"DAY-bree\") refers to chopped organs such as liver, heart, kidneys, tripe, spleen, brain, lungs and pancreas.", "combined_text": "Debris Contents Disaster Geological Marine Meteorological Space Surgical War Culinary See also References External links Debris(UK:/ˈdɛbri,ˈdeɪbri/,US:/dəˈbriː/) isrubble, wreckage,ruins,litterand discardedgarbage/refuse/trash, scattered remains of something destroyed, or, as in geology, large rock fragments left by a melting glacier, etc. Depending on context,debriscan refer to a number of different things. The first apparent use of the French word in English is in a 1701 description of the army ofPrince Rupertupon its retreat from a battle with the army of Oliver Cromwell, in England. In disaster scenarios,tornadoesleave behind large pieces of houses and mass destruction overall. This debris also flies around the tornado itself when it is in progress. The tornado's winds capture debris it kicks up in its wind orbit, and spins it inside its vortex. The tornado's wind radius is larger than the funnel itself.Tsunamisandhurricanesalso bring large amounts of debris, such asHurricane Katrinain 2005 andHurricane Sandyin 2012.Earthquakesrock cities to rubble debris. Ingeology, debris usually applies to the remains of geological activity includinglandslides,volcanicexplosions,avalanches,mudflowsorGlacial lake outburst floods(Jökulhlaups) andmoraine,lahars, andlavaeruptions. Geological debris sometimes moves in astreamcalled adebris flow.  When it accumulates at the base of hillsides, it can be called \"talus\" or \"scree\". Inmining, debris calledattleusually consists of rock fragments which contain little or no ore. Marine debrisapplies to floating garbage such asbottles,cans,styrofoam, cruiseshipwaste, offshoreoilandgasexploration and production facilitiespollution, andfishingparaphernalia from professional and recreational boaters. Marine debris is also calledlitterorflotsam and jetsam. Objects that can constitute marine debris include usedautomobiletires,detergentbottles,medical wastes, discarded fishing line andnets, soda cans, andbilgewaste solids. In addition to being unsightly, it can pose a serious threat to marine life,boats,swimmers,divers, and others. For example, each year millions of seabirds, seaturtles,fish, and marinemammalsbecome entangled in marine debris, or ingest plastics which they have mistaken for food. As many as 30,000 northern fur seals per year get caught in abandoned fishing nets and either drown or suffocate.Whalesmistakeplasticbags forsquid, andbirdsmay mistake plastic pellets for fisheggs. At other times, animals accidentally eat the plastic while feeding on natural food. The largest concentration of marine debris is theGreat Pacific Garbage Patch. Marine debris most commonly originates from land-based sources. Various international agencies are currently working to reduce marine debris levels around the world. Inmeteorology, debris usually applies to the remains ofhumanhabitation and naturalfloraafterstormrelated destruction. This debris is also commonly referred to asstorm debris. Storm debris commonly consists of roofing material, downedtreelimbs, downedsigns, downedpower linesand poles, and wind-blown garbage. Storm debris can become a serious problem immediately after a storm, in that it often blocks access to individuals and communities that may require emergency services. This material frequently exists in such large quantities that disposing of it becomes a serious issue for a community. In addition, storm debris is often hazardous by its very nature, since, for example, downed power lines annually account for storm-related deaths. Space debrisusually refers to the remains ofspacecraftthat have either fallen toEarthor are still orbiting Earth. Space debris may also consist of natural components such as chunks ofrockandice. The problem of space debris has grown as various space programs have left legacies of launches, explosions, repairs, and discards in both low Earthorbitand more remote orbits. These orbiting fragments have reached a great enough proportion to constitute a hazard to future space launches of bothsatelliteand crewed vehicles. Various government agencies and international organizations are beginning to track space debris and also research possible solutions to the problem. While many of these items, ranging in size fromnutsandboltsto entire satellites and spacecraft, may fall to Earth, other items located in more remote orbits may stay aloft for centuries. The velocity of some of these pieces of space junk have been clocked in excess of 17,000 miles per hour (27,000 km/h). A piece of space debris falling to Earth leaves a fiery trail, just like ameteor. Adebris diskis a circumstellar disk of dust and debris in orbit around a star. Inmedicine, debris usually refers to biological matter that has accumulated or lodged insurgical instrumentsand is referred to assurgical debris. The presence of surgical debris can result in cross-infections ornosocomial infectionsif not removed and the affected surgical instruments or equipment properlydisinfected. In the aftermath of a war, large areas of the region of conflict are often strewn withwar debrisin the form of abandoned or destroyed hardware and vehicles, mines,unexploded ordnance, bullet casings and other fragments of metal. Much war debris has the potential to be lethal and continues to kill and maim civilian populations for years after the end of a conflict. The risks from war debris may be sufficiently high to prevent or delay the return of refugees. In addition war debris may contain hazardous chemicals or radioactive components that can contaminate the land or poison civilians who come into contact with it. ManyMine clearance agenciesare also involved in the clearance of war debris. Land minesin particular are very dangerous as they can remain active for decades after a conflict, which is why they have been banned by international war regulations. In November 2006 the Protocol on Explosive Remnants of Warcame into effect with 92 countries subscribing to the treaty that requires the parties involved in a conflict to assist with the removal of unexploded ordnance following the end of hostilities. Some of the countries most affected by war debris areAfghanistan,Angola,Cambodia,IraqandLaos. Similarlymilitary debrismay be found in and aroundfiring rangeand military training areas. Debris can also be used as cover for military purposes, depending on the situation. In South Louisiana'sCreoleandCajuncultures, debris (pronounced \"DAY-bree\") refers to chopped organs such as liver, heart, kidneys, tripe, spleen, brain, lungs and pancreas.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Debris", "https://en.wikipedia.org/wiki/Debris", "https://en.wikipedia.org/wiki/Debris", "https://en.wikipedia.org/wiki/Debris_(disambiguation)", "https://en.wikipedia.org/wiki/Riprap", "https://en.wikipedia.org/wiki/Rubble", "https://en.wikipedia.org/wiki/Joplin_tornado", "https://en.wikipedia.org/wiki/Joplin,_Missouri"]},
{"id": "523c65176c72", "url": "https://en.wikipedia.org/wiki/Jean-Bertrand_Pontalis", "title": "Jean-Bertrand Pontalis", "headings": ["Contents", "Career", "See also", "References"], "content": " Jean-Bertrand Lefèvre-Pontalis(French:[pɔ̃talis];15 January 1924, Paris – 15 January 2013, Paris) was a French philosopher, writer, editor and psychoanalyst. A student ofJean-Paul Sartre, Pontalis became a professor of philosophy in the 1940s, before undergoing an analysis with his associateJacques Lacanthe following decade.He was, however, one of the minority group of disciples/analysands who did not follow Lacan into theÉcole Freudienne de Paris, but rather stayed within the legitimist sphere as founding members of theAssociation Psychanalytique de France,of which he later became president. Together withJean Laplanche, he wrote the influential workThe Language of Psychoanalysisin 1967; while among his later, more literary writings wereWindowsandCrossing the Shadows. His 1993 autobiography,Love of Beginnings, was deliberately ahistorical, emphasising what he called \"holes\" in discourse, where the process of slipping through or evading set formats and ways of thinking opened up new beginnings:\"When words fail, it is because, without realising it, one is about to touch a different earth\".", "combined_text": "Jean-Bertrand Pontalis Contents Career See also References  Jean-Bertrand Lefèvre-Pontalis(French:[pɔ̃talis];15 January 1924, Paris – 15 January 2013, Paris) was a French philosopher, writer, editor and psychoanalyst. A student ofJean-Paul Sartre, Pontalis became a professor of philosophy in the 1940s, before undergoing an analysis with his associateJacques Lacanthe following decade.He was, however, one of the minority group of disciples/analysands who did not follow Lacan into theÉcole Freudienne de Paris, but rather stayed within the legitimist sphere as founding members of theAssociation Psychanalytique de France,of which he later became president. Together withJean Laplanche, he wrote the influential workThe Language of Psychoanalysisin 1967; while among his later, more literary writings wereWindowsandCrossing the Shadows. His 1993 autobiography,Love of Beginnings, was deliberately ahistorical, emphasising what he called \"holes\" in discourse, where the process of slipping through or evading set formats and ways of thinking opened up new beginnings:\"When words fail, it is because, without realising it, one is about to touch a different earth\".", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Jean-Bertrand_Pontalis", "https://en.wikipedia.org/wiki/Jean-Bertrand_Pontalis", "https://en.wikipedia.org/wiki/Jean-Bertrand_Pontalis", "https://en.wikipedia.org/wiki/Jean-Paul_Sartre", "https://en.wikipedia.org/wiki/Jacques_Lacan", "https://en.wikipedia.org/wiki/%C3%89cole_Freudienne_de_Paris", "https://en.wikipedia.org/wiki/Jean_Laplanche", "https://en.wikipedia.org/wiki/Jacques_Derrida"]},
{"id": "2cc86232f629", "url": "https://en.wikipedia.org/wiki/AllMusic", "title": "AllMusic", "headings": ["Contents", "History", "The All Music Guide series", "Reception", "See also", "References", "External links"], "content": " AllMusic(previously known asAll-Music GuideandAMG) is an Americanonline music database. It catalogs more than three millionalbumentries and 30 million tracks, as well as information onmusiciansandbands. Initiated in 1991, the database was first made available on the Internet in 1994.AllMusic is owned byRhythmOne. AllMusic was launched asAll-Music GuidebyMichael Erlewine, a \"compulsive archivist, noted astrologer, Buddhist scholar, and musician\". He became interested in using computers for his astrological work in the mid-1970s and founded a software company, Matrix, in 1977. In the early 1990s, ascompact discs(CDs) replacedLPsandcassettesas the dominant format for recorded music, Erlewine purchased what he thought was a CD of early recordings byLittle Richard. After buying it, he discovered it was a \"flaccid latter-day rehash\".Frustrated with the labeling, he researched usingmetadatato create a music guide.In 1990, inBig Rapids, Michigan, he foundedAll Music Guidewith a goal to create an open-access database that included every recording \"sinceEnrico Carusogave the industry its first big boost\". The firstAll Music Guide, published in 1992, was a 1,200-page reference book, packaged with a CD-ROM, titledAll Music Guide: The Best CDs, Albums & Tapes: The Expert's Guide to the Best Releases from Thousands of Artists in All Types of Music.Its first online version, in 1994, was a text-basedGophersite.It moved to theWorld Wide Webasweb browsersbecame more user-friendly. Erlewine hired a database engineer,Vladimir Bogdanov, to design theAll Music Guideframework, and recruited his nephew, writerStephen Thomas Erlewine, to develop editorial content. In 1993, Chris Woodstra joined the staff as an engineer. A \"record geek\" who had written for alternative weeklies and fanzines, his main qualification was an \"encyclopedic knowledge of music\".Allmusic developed a list of 1,400 subgenres of music, a feature that became central to the site's utility. In a 2016 article inTedium, Ernie Smith wrote: \"AllMusic may have been one of the most ambitious sites of the early-internet era—and it's one that is fundamental to our understanding of pop culture. Because the thing is, it doesn't just track reviews or albums. It tracks styles, genres, and subgenres, along with the tone of the music and the platforms on which the music is sold. It then connects that data together, in a way that can intelligently tell you about an entire type of music, whether a massive genre like classical, or a tiny one likesadcore.\" In 1996, seeking to further develop its web-based businesses, Alliance Entertainment Corp. bought All Music from Erlewine for a reported $3.5 million. He left the company after its sale.Alliance filed for bankruptcy in 1999, and its assets were acquired byRon Burkle's Yucaipa Equity Fund. In 1999, All Music relocated from Big Rapids toAnn Arbor, Michigan, where the staff expanded from 12 to 100 people.By February of that year, 350,000 albums and two million tracks had been cataloged. All Music had published biographies of 30,000 artists, 120,000 record reviews, and 300 essays written by \"a hybrid of historians, critics, and passionate collectors\". In late 2007, AllMusic was purchased for $72 million byTiVo Corporation(known as Macrovision at the time of the sale, and as Rovi from 2009 until 2016).In 2012, AllMusic removed all ofBryan Adams' info from the site per a request from the artist. In 2015, AllMusic was purchased by BlinkX, later known asRhythmOne.The AllMusic database is powered by a combination ofMySQLandMongoDB. The All Media Network produced theAll Music Guide: The Definitive Guide(at first released asThe Experts' Guide),which includes a series of publications about various music genres. It was followed by theRequired Listeningseries, and Annual guides.Vladimir Bogdanovis the president and the main editor of the series. In August 2007,PC Magazineincluded AllMusic in its \"Top 100 Classic Websites\" list.", "combined_text": "AllMusic Contents History The All Music Guide series Reception See also References External links  AllMusic(previously known asAll-Music GuideandAMG) is an Americanonline music database. It catalogs more than three millionalbumentries and 30 million tracks, as well as information onmusiciansandbands. Initiated in 1991, the database was first made available on the Internet in 1994.AllMusic is owned byRhythmOne. AllMusic was launched asAll-Music GuidebyMichael Erlewine, a \"compulsive archivist, noted astrologer, Buddhist scholar, and musician\". He became interested in using computers for his astrological work in the mid-1970s and founded a software company, Matrix, in 1977. In the early 1990s, ascompact discs(CDs) replacedLPsandcassettesas the dominant format for recorded music, Erlewine purchased what he thought was a CD of early recordings byLittle Richard. After buying it, he discovered it was a \"flaccid latter-day rehash\".Frustrated with the labeling, he researched usingmetadatato create a music guide.In 1990, inBig Rapids, Michigan, he foundedAll Music Guidewith a goal to create an open-access database that included every recording \"sinceEnrico Carusogave the industry its first big boost\". The firstAll Music Guide, published in 1992, was a 1,200-page reference book, packaged with a CD-ROM, titledAll Music Guide: The Best CDs, Albums & Tapes: The Expert's Guide to the Best Releases from Thousands of Artists in All Types of Music.Its first online version, in 1994, was a text-basedGophersite.It moved to theWorld Wide Webasweb browsersbecame more user-friendly. Erlewine hired a database engineer,Vladimir Bogdanov, to design theAll Music Guideframework, and recruited his nephew, writerStephen Thomas Erlewine, to develop editorial content. In 1993, Chris Woodstra joined the staff as an engineer. A \"record geek\" who had written for alternative weeklies and fanzines, his main qualification was an \"encyclopedic knowledge of music\".Allmusic developed a list of 1,400 subgenres of music, a feature that became central to the site's utility. In a 2016 article inTedium, Ernie Smith wrote: \"AllMusic may have been one of the most ambitious sites of the early-internet era—and it's one that is fundamental to our understanding of pop culture. Because the thing is, it doesn't just track reviews or albums. It tracks styles, genres, and subgenres, along with the tone of the music and the platforms on which the music is sold. It then connects that data together, in a way that can intelligently tell you about an entire type of music, whether a massive genre like classical, or a tiny one likesadcore.\" In 1996, seeking to further develop its web-based businesses, Alliance Entertainment Corp. bought All Music from Erlewine for a reported $3.5 million. He left the company after its sale.Alliance filed for bankruptcy in 1999, and its assets were acquired byRon Burkle's Yucaipa Equity Fund. In 1999, All Music relocated from Big Rapids toAnn Arbor, Michigan, where the staff expanded from 12 to 100 people.By February of that year, 350,000 albums and two million tracks had been cataloged. All Music had published biographies of 30,000 artists, 120,000 record reviews, and 300 essays written by \"a hybrid of historians, critics, and passionate collectors\". In late 2007, AllMusic was purchased for $72 million byTiVo Corporation(known as Macrovision at the time of the sale, and as Rovi from 2009 until 2016).In 2012, AllMusic removed all ofBryan Adams' info from the site per a request from the artist. In 2015, AllMusic was purchased by BlinkX, later known asRhythmOne.The AllMusic database is powered by a combination ofMySQLandMongoDB. The All Media Network produced theAll Music Guide: The Definitive Guide(at first released asThe Experts' Guide),which includes a series of publications about various music genres. It was followed by theRequired Listeningseries, and Annual guides.Vladimir Bogdanovis the president and the main editor of the series. In August 2007,PC Magazineincluded AllMusic in its \"Top 100 Classic Websites\" list.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/AllMusic", "https://en.wikipedia.org/wiki/AllMusic", "https://en.wikipedia.org/wiki/AllMusic", "https://en.wikipedia.org/wiki/All_Music_(album)", "https://en.wikipedia.org/wiki/Logotype", "https://en.wikipedia.org/wiki/Wordmark", "https://en.wikipedia.org/wiki/List_of_online_music_databases", "https://en.wikipedia.org/wiki/RhythmOne"]},
{"id": "4369630a3fff", "url": "https://en.wikipedia.org/wiki/Virgin_Books", "title": "Virgin Books", "headings": ["Contents", "History", "Imprints", "References", "External links"], "content": " Virgin Booksis a British book publisher 90% owned by the publishing groupRandom House, and 10% owned byVirgin Group, the company originally set up byRichard Bransonas arecord company. Virgin established its book publishing arm in the late 1970s; in the latter part of the 1980s Virgin purchased several existing companies, includingWH Allen, well known amongDoctor Whofans for theirTarget Booksimprint; Virgin Books was incorporated into WH Allen in 1989, but in 1991 WH Allen was renamed Virgin Publishing Ltd. Virgin Publishing's early success came with theDoctor WhoNew Adventuresnovels, officially licensed full-length novels carrying on the story of the popular science-fiction television series following its cancellation in 1989. Virgin published this series from 1991 to 1997, as well as a range ofDoctor Whoreference books from 1992 to 1998 under theDoctor Who Booksimprint. In recent times the company is best known for its commercial non-fiction list, which includes business, health and lifestyle, music, film, and celebrity biographies.Richard Branson's autobiographyLosing My Virginity, released in 1998, was an international best-seller at the time, and continues to sell well. His follow-up titleBusiness Stripped Barewas published in September 2008. Virgin Business Guides included titles byRobert Craven, Paul Barrow and Rachelle Thackray. More recently the company has enjoyed success withRobert H Frank'sThe Economic Naturalist, where the author had his economics students pose interesting questions from everyday life and explain them through economics. Random House, through its United Kingdom division, acquired a 90% stake in the company in March 2007.In November 2009, Virgin became an independent imprint withinEbury Publishing, a division of the Random House Group. Other popular ranges have included variouserotic fictionlines:", "combined_text": "Virgin Books Contents History Imprints References External links  Virgin Booksis a British book publisher 90% owned by the publishing groupRandom House, and 10% owned byVirgin Group, the company originally set up byRichard Bransonas arecord company. Virgin established its book publishing arm in the late 1970s; in the latter part of the 1980s Virgin purchased several existing companies, includingWH Allen, well known amongDoctor Whofans for theirTarget Booksimprint; Virgin Books was incorporated into WH Allen in 1989, but in 1991 WH Allen was renamed Virgin Publishing Ltd. Virgin Publishing's early success came with theDoctor WhoNew Adventuresnovels, officially licensed full-length novels carrying on the story of the popular science-fiction television series following its cancellation in 1989. Virgin published this series from 1991 to 1997, as well as a range ofDoctor Whoreference books from 1992 to 1998 under theDoctor Who Booksimprint. In recent times the company is best known for its commercial non-fiction list, which includes business, health and lifestyle, music, film, and celebrity biographies.Richard Branson's autobiographyLosing My Virginity, released in 1998, was an international best-seller at the time, and continues to sell well. His follow-up titleBusiness Stripped Barewas published in September 2008. Virgin Business Guides included titles byRobert Craven, Paul Barrow and Rachelle Thackray. More recently the company has enjoyed success withRobert H Frank'sThe Economic Naturalist, where the author had his economics students pose interesting questions from everyday life and explain them through economics. Random House, through its United Kingdom division, acquired a 90% stake in the company in March 2007.In November 2009, Virgin became an independent imprint withinEbury Publishing, a division of the Random House Group. Other popular ranges have included variouserotic fictionlines:", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Virgin_Books", "https://en.wikipedia.org/wiki/Virgin_Books", "https://en.wikipedia.org/wiki/Virgin_Books", "https://en.wikipedia.org/wiki/Richard_Branson", "https://en.wikipedia.org/wiki/The_Book_Service", "https://en.wikipedia.org/wiki/Random_House", "https://en.wikipedia.org/wiki/Virgin_Group", "https://en.wikipedia.org/wiki/Random_House"]},
{"id": "8d1e926aa75d", "url": "https://en.wikipedia.org/wiki/Wikipedia_for_World_Heritage", "title": "Wikipedia for World Heritage", "headings": ["Contents", "References", "External links"], "content": "Wikipedia for World Heritagerefers to the efforts put forth to getWikipedialisted as aUNESCOWorld Heritage Site. The idea was originally proposed to theWikimedia chapterby theWikimedia Foundationat the 2011 Wikimedia Conference in Berlin.An online petition was started at the German Wikipedia on May 23, 2011.That same day theEdmonton Journalpublished a piece in which it called the bid 'a long-shot bet' inferring the platform was not a culturally defining artefact.Wikipedia was also argued to be 'lacking the effect or maturity for listing' as World Heritage.The bid is considered to be the first for a digital entity and is expected to be controversial with the list's maintainers who are notably conservative. Jimbo Waleshas stated that \"the basic idea is to recognize that Wikipedia is this amazing global cultural phenomena that has transformed the lives of hundreds of thousands of people.\" If Wikipedia does not get listed as a World Heritage Site, and UNESCO has denied its application as it does not meet most criteria, it has been suggested that they apply forUNESCO Intangible Cultural Heritage Lists.", "combined_text": "Wikipedia for World Heritage Contents References External links Wikipedia for World Heritagerefers to the efforts put forth to getWikipedialisted as aUNESCOWorld Heritage Site. The idea was originally proposed to theWikimedia chapterby theWikimedia Foundationat the 2011 Wikimedia Conference in Berlin.An online petition was started at the German Wikipedia on May 23, 2011.That same day theEdmonton Journalpublished a piece in which it called the bid 'a long-shot bet' inferring the platform was not a culturally defining artefact.Wikipedia was also argued to be 'lacking the effect or maturity for listing' as World Heritage.The bid is considered to be the first for a digital entity and is expected to be controversial with the list's maintainers who are notably conservative. Jimbo Waleshas stated that \"the basic idea is to recognize that Wikipedia is this amazing global cultural phenomena that has transformed the lives of hundreds of thousands of people.\" If Wikipedia does not get listed as a World Heritage Site, and UNESCO has denied its application as it does not meet most criteria, it has been suggested that they apply forUNESCO Intangible Cultural Heritage Lists.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Wikipedia_for_World_Heritage", "https://en.wikipedia.org/wiki/Wikipedia_for_World_Heritage", "https://en.wikipedia.org/wiki/Wikipedia_for_World_Heritage", "https://en.wikipedia.org/wiki/Wikipedia", "https://en.wikipedia.org/wiki/UNESCO", "https://en.wikipedia.org/wiki/World_Heritage_Site", "https://en.wikipedia.org/wiki/Wikimedia_chapter", "https://en.wikipedia.org/wiki/Wikimedia_Foundation"]},
{"id": "bbc73345eedf", "url": "https://en.wikipedia.org/wiki/Auditosensory_cortex", "title": "Auditosensory cortex", "headings": ["Contents", "History", "Structure", "Anatomical position", "Relationship to the transverse temporal gyri", "Function", "Reception and perception of auditory nerve impulses", "Analysis of sound properties", "Linguistic competence", "Clinical significance", "Congenital deafness", "True cortical deafness", "Primary progressive aphasia", "Auditory impairment in concussion", "Auditory hallucination in schizophrenia", "See also", "References"], "content": "Theauditosensory cortexis the part of theauditory systemthat is associated with the sense ofhearingin humans. It occupies the bilateral primaryauditory cortexin thetemporal lobeof the mammalian brain.The term is used to describeBrodmann areas 41 and 42together with thetransverse temporal gyrus.The auditosensory cortex takes part in the reception and processing of auditory nerve impulses, which passes sound information from thethalamusto the brain. Abnormalities in this region are responsible for many disorders in auditory abilities, such ascongenital deafness, true cortical deafness,primary progressive aphasiaandauditory hallucination. The auditosensory cortex defines Brodmann area 42, which is part of the primaryauditory cortex. It is also known as the posterior transverse temporal area,located superiorly within the temporal lobe of thecerebral cortex. The cortical area has been studied in a variety of mammals, including humans. It is a functional region found to serve essential roles in hearing. Previous studies byRichard Ladislaus Heschlfirst revealed the anatomical features of this cortical region in 1878.Heschl found a cortical structure that appeared differently from most of the temporal lobe. The distinct structure occupied Brodmann area 42 and was later named the transverse temporal gyri of Heschl.The discovery provided insight into the anatomical network within the primary cortex. It is the first site to process incoming sound information. Due to the close correspondence, Brodmann area 42 is also referred to as Heschl's gyrus. Mapped by German neurologistKorbinian Brodmannin 1909,the auditosensory cortex is one of the 52 cortical regions identified in the cerebral cortex according to their histological characteristics, density, shape, distribution and cell body size. These subdivided cortical regions are later known as theBrodmann areas. Brodmann was the pioneer of cerebral cortex mapping. He grouped several cortical regions based on their nervous function, two of which are areas 41 and 42 for auditory processing. It has been suggested that Brodmann area 42 is a homotypical acoustic association area. The primary auditory cortex lies medially in thesuperior temporal gyrusof the human brain.It is responsible for receiving signals from themedial geniculate nucleus. Within the primary auditory cortex, the auditosensory cortex extends posteromedially over the gyrus.Brodmann area 42 is an auditory core region bordered medially by Brodmann area 41 and laterally by Brodmann area 22.The auditosensory cortex demarcates the lateral edge of Brodmann area 41. The auditosensory cortex is a differentiated anatomical area within the posterior-medial field of the transverse temporal gyrus of Heschl in thelateral sulcus.The cortex of transverse temporal gyrus of Heschl forms a homogeneous structural region withBrodmann area 22. In contrast to other temporal lobe gyri, the transverse temporal gyrus has a distinct feature of stretching mediolaterally towards the brain centre. The main and most apparent function of the auditosensory cortex is hearing. Hearing is a sense of sound reception and perception. Sound reception is the receiving of sound stimuli. Thesound waveis transmitted to ourauditory apparatusfrom external environment. This sensory signal is then converted to an electrical signal in a process calledsensory transduction.This electrical impulse is carried from theinner earto thebrainstemvia thevestibulocochlear nerve(cranial nerve XIII).Furthermore, the auditory impulse is recognised, organised and interpreted as sensory information. The different properties of sound waves are necessary to help the comprehension of language and sound. The language competence directly correlates with the ability of auditosensory cortex in terms of strength and frequency of neuronal activity. The primary auditory cortex includes the auditosensory cortex (Brodmann area 42) and the auditopsychic cortex (Brodmann area 41). The primary function of the auditosensory cortex is the sense of hearing. It is the initial cortical destination of auditory nerve impulses from thethalamus. The characteristics of neural activities in this cortex correspond with the physical properties ofsound waves. The perception of auditory signals came as a nervous impulse from theinner earto thecochlear nucleiof the brainstem,which is the first relay station. In an ascending pathway, variousacoustic reflexesandsound localisationare regulated via relay stations. The impulse reaches the auditory cortical projections on thesuperior temporal gyrus, which is the auditosensory cortex. This is the first site of unprocessed recognition of sound. The impulse propagates across the auditosensory area, the auditopsychic area and eventually the entiretemporal lobe. Therefore, this allows the formation of memory and comprehension of sound to take place. The posterior auditopsychic region has a site especially for an understanding of speech called theWernicke's area(Brodmann area 22). The auditosensory cortex solely is insufficient for the complete production and reception of language. The subcortical structures, such as the thalamus, are necessary for controlling emotional and cognitive integration, and the cerebellum for coordinating movements. The auditosensory cortex can analyse acrostic characteristics, namelypitch,loudnessandtimbre.A higherfrequencygives a higher pitch, whereas a lower frequency gives a lower pitch. A larger amplitude gives a higher volume, on the contrary, a smaller amplitude gives a lower volume. Amplitude is for determination of intensity. Timbre is the characteristic of a tone to distinguish sound with the same pitch and volume. Factors affecting timbre are theharmonics, vibration andenvelopeof the wave. Thetransverse temporal gyrus, which contains the auditosensory cortex, processes sound impulse in low frequency.Its lateral aspect maps the sound impulse in atonotopic organisationthat produces a mirror image of spatial gradients of frequency sensitivity.It depends on the duration and intensity of the sound stimuli. The early processing of speech recognition requires the ability of the transverse temporal gyrus to discriminate frequency. Hence, this region can distinguish phonetic characteristics of sound. The responsiveness toprosodycorresponds to the sensitivity to the slight variation of frequency and duration of time. Language competence is acquired from the ability of the auditosensory cortex to interpret sound stimuli.The information processing pathway in the transverse temporal gyrus is necessary for recognizing and comprehending speech, and has been referred to as thetwo-streams hypothesis.The ventral pathway is responsible for processing linguisticsemanticinformation that allows the understanding of meaning. The dorsal stream is responsible for processingphonologicalinformation that forms the structure of language. Neuroplasticityincludes our auditory perception. It can be shaped by stimuli from the environment, memory and attentional factors. Neural activities in other brain areas are closely bound up with auditosensory processing in the transverse temporal gyrus. For instance, attention and focus, andface perceptionhave an emphasis on our language competence. There is a strong association between the cerebral cortex and auditory function. Animal studies have shown that extirpation of the auditosensory cortex leads to the loss of responsiveness to previously learnt tones.The locations of auditory cortical neurones and conformations of the primary auditory cortex are unique to every individual. Therefore, any surgical procedure should take these anatomical variations into account to minimise the damage to our auditory and language functions.Functional brain mapping(FBM) is one of the pre-operative procedures. Congenital deafnessis the loss of hearing present at birth. The primary auditory cortex is never stimulated by auditory signals in these patients.This condition also affects the development of the auditory cortex, which gives rise to auditory functional deficits. There are fewer nerve fibres and lessmyelinationin patients' primary auditory cortex, illustrated by the higher grey matter-to-white matter ratios in the Heschl gyrus. The cells and synapses undergo dystrophy in a deafness auditory pathway. If the infants receivecochlear implantsduring the earlycritical period, the neurosensory functions can be restored. A recent study concluded that congenital deafness does not damage the general cortical cytoarchitecture. However, there is anatomical dystrophy of deep layers over higher-order cortical fields. The sensory deprivation of auditory neurones induces dystrophy beyond the primary auditory cortex, namely the dorsal zone of the auditory cortex (DZ) andsecondary auditory cortex(A2). Cortical deafnessis characterised by the unresponsiveness to both verbal and nonverbal sounds due to cortical lesions. However, thissensorineural hearing lossshows no damage to the auditory pathway from thecochleato the upperbrainstem. The onset is usually during childhood, where they have severely impaired ability to distinguish the different vowels and consonant sounds, and impaired capability to comprehend auditory information.They have no subjective experience of hearingas they are unable to process acoustic impulse. They may learn how to identify the meaning of nonverbal sounds correctly. Primary progressive aphasiais characterised by the progressive impairment of speech production, comprehension and communication. It is secondary to neurodegenerative diseases, for instance,Alzheimer's diseaseandfrontotemporal lobar degeneration.The Heschl gyrus undergoes deterioration, as shown by the low activity of the primary auditory cortex after stimulation.The symptoms are difficulty and delay in communication and speech organisation. The patients may become reluctant to communicate or even unable to understand verbal or written language, eventually causing primary progressive aphasia. Difficulty in auditory processing is a complication ofconcussionthat may result in a reduced activation of the primary auditory cortex, as shown byfMRI.The neural communication of the left and right primary auditory cortices are poorly transmitted. As a result, thelateralisationand responsiveness of the cerebral cortex are affected. Thetemporal fine structureprocessing has degenerated as presented by the reduced temporal resolution.It is often due to diffuse axonal injury and demyelination. There may be peripheral and central symptoms, such as reduced auditory understanding in a complex listening environment, central auditory processing disorder andauditory hallucination.Hyperacusis, that is the hypersensitivity to environmental noise can also develop. Auditory hallucination is one of the major symptoms displayed inschizophrenia. Studies supported by functional imaging and electrophysiology have shown a possible correlation between the auditory cortex and auditory hallucinations. In the case of an average individual, speaking-induced suppression is generated due to speaking to reduce the activity in the primary auditory cortex.This acts as a physiological mechanism in the auditory system for the speaker to be more focused on the sounds externally produced. However, this is not demonstrated in individuals with schizophrenia, in contrast, there is an increased activity in the auditory cortex instead of sound suppression. Even in a silent environment without external auditory stimuli, there tends to be abnormal activation of the auditory cortex, leading to auditory hallucinations.The volume of the auditory cortex in those with schizophrenia is much smaller.", "combined_text": "Auditosensory cortex Contents History Structure Anatomical position Relationship to the transverse temporal gyri Function Reception and perception of auditory nerve impulses Analysis of sound properties Linguistic competence Clinical significance Congenital deafness True cortical deafness Primary progressive aphasia Auditory impairment in concussion Auditory hallucination in schizophrenia See also References Theauditosensory cortexis the part of theauditory systemthat is associated with the sense ofhearingin humans. It occupies the bilateral primaryauditory cortexin thetemporal lobeof the mammalian brain.The term is used to describeBrodmann areas 41 and 42together with thetransverse temporal gyrus.The auditosensory cortex takes part in the reception and processing of auditory nerve impulses, which passes sound information from thethalamusto the brain. Abnormalities in this region are responsible for many disorders in auditory abilities, such ascongenital deafness, true cortical deafness,primary progressive aphasiaandauditory hallucination. The auditosensory cortex defines Brodmann area 42, which is part of the primaryauditory cortex. It is also known as the posterior transverse temporal area,located superiorly within the temporal lobe of thecerebral cortex. The cortical area has been studied in a variety of mammals, including humans. It is a functional region found to serve essential roles in hearing. Previous studies byRichard Ladislaus Heschlfirst revealed the anatomical features of this cortical region in 1878.Heschl found a cortical structure that appeared differently from most of the temporal lobe. The distinct structure occupied Brodmann area 42 and was later named the transverse temporal gyri of Heschl.The discovery provided insight into the anatomical network within the primary cortex. It is the first site to process incoming sound information. Due to the close correspondence, Brodmann area 42 is also referred to as Heschl's gyrus. Mapped by German neurologistKorbinian Brodmannin 1909,the auditosensory cortex is one of the 52 cortical regions identified in the cerebral cortex according to their histological characteristics, density, shape, distribution and cell body size. These subdivided cortical regions are later known as theBrodmann areas. Brodmann was the pioneer of cerebral cortex mapping. He grouped several cortical regions based on their nervous function, two of which are areas 41 and 42 for auditory processing. It has been suggested that Brodmann area 42 is a homotypical acoustic association area. The primary auditory cortex lies medially in thesuperior temporal gyrusof the human brain.It is responsible for receiving signals from themedial geniculate nucleus. Within the primary auditory cortex, the auditosensory cortex extends posteromedially over the gyrus.Brodmann area 42 is an auditory core region bordered medially by Brodmann area 41 and laterally by Brodmann area 22.The auditosensory cortex demarcates the lateral edge of Brodmann area 41. The auditosensory cortex is a differentiated anatomical area within the posterior-medial field of the transverse temporal gyrus of Heschl in thelateral sulcus.The cortex of transverse temporal gyrus of Heschl forms a homogeneous structural region withBrodmann area 22. In contrast to other temporal lobe gyri, the transverse temporal gyrus has a distinct feature of stretching mediolaterally towards the brain centre. The main and most apparent function of the auditosensory cortex is hearing. Hearing is a sense of sound reception and perception. Sound reception is the receiving of sound stimuli. Thesound waveis transmitted to ourauditory apparatusfrom external environment. This sensory signal is then converted to an electrical signal in a process calledsensory transduction.This electrical impulse is carried from theinner earto thebrainstemvia thevestibulocochlear nerve(cranial nerve XIII).Furthermore, the auditory impulse is recognised, organised and interpreted as sensory information. The different properties of sound waves are necessary to help the comprehension of language and sound. The language competence directly correlates with the ability of auditosensory cortex in terms of strength and frequency of neuronal activity. The primary auditory cortex includes the auditosensory cortex (Brodmann area 42) and the auditopsychic cortex (Brodmann area 41). The primary function of the auditosensory cortex is the sense of hearing. It is the initial cortical destination of auditory nerve impulses from thethalamus. The characteristics of neural activities in this cortex correspond with the physical properties ofsound waves. The perception of auditory signals came as a nervous impulse from theinner earto thecochlear nucleiof the brainstem,which is the first relay station. In an ascending pathway, variousacoustic reflexesandsound localisationare regulated via relay stations. The impulse reaches the auditory cortical projections on thesuperior temporal gyrus, which is the auditosensory cortex. This is the first site of unprocessed recognition of sound. The impulse propagates across the auditosensory area, the auditopsychic area and eventually the entiretemporal lobe. Therefore, this allows the formation of memory and comprehension of sound to take place. The posterior auditopsychic region has a site especially for an understanding of speech called theWernicke's area(Brodmann area 22). The auditosensory cortex solely is insufficient for the complete production and reception of language. The subcortical structures, such as the thalamus, are necessary for controlling emotional and cognitive integration, and the cerebellum for coordinating movements. The auditosensory cortex can analyse acrostic characteristics, namelypitch,loudnessandtimbre.A higherfrequencygives a higher pitch, whereas a lower frequency gives a lower pitch. A larger amplitude gives a higher volume, on the contrary, a smaller amplitude gives a lower volume. Amplitude is for determination of intensity. Timbre is the characteristic of a tone to distinguish sound with the same pitch and volume. Factors affecting timbre are theharmonics, vibration andenvelopeof the wave. Thetransverse temporal gyrus, which contains the auditosensory cortex, processes sound impulse in low frequency.Its lateral aspect maps the sound impulse in atonotopic organisationthat produces a mirror image of spatial gradients of frequency sensitivity.It depends on the duration and intensity of the sound stimuli. The early processing of speech recognition requires the ability of the transverse temporal gyrus to discriminate frequency. Hence, this region can distinguish phonetic characteristics of sound. The responsiveness toprosodycorresponds to the sensitivity to the slight variation of frequency and duration of time. Language competence is acquired from the ability of the auditosensory cortex to interpret sound stimuli.The information processing pathway in the transverse temporal gyrus is necessary for recognizing and comprehending speech, and has been referred to as thetwo-streams hypothesis.The ventral pathway is responsible for processing linguisticsemanticinformation that allows the understanding of meaning. The dorsal stream is responsible for processingphonologicalinformation that forms the structure of language. Neuroplasticityincludes our auditory perception. It can be shaped by stimuli from the environment, memory and attentional factors. Neural activities in other brain areas are closely bound up with auditosensory processing in the transverse temporal gyrus. For instance, attention and focus, andface perceptionhave an emphasis on our language competence. There is a strong association between the cerebral cortex and auditory function. Animal studies have shown that extirpation of the auditosensory cortex leads to the loss of responsiveness to previously learnt tones.The locations of auditory cortical neurones and conformations of the primary auditory cortex are unique to every individual. Therefore, any surgical procedure should take these anatomical variations into account to minimise the damage to our auditory and language functions.Functional brain mapping(FBM) is one of the pre-operative procedures. Congenital deafnessis the loss of hearing present at birth. The primary auditory cortex is never stimulated by auditory signals in these patients.This condition also affects the development of the auditory cortex, which gives rise to auditory functional deficits. There are fewer nerve fibres and lessmyelinationin patients' primary auditory cortex, illustrated by the higher grey matter-to-white matter ratios in the Heschl gyrus. The cells and synapses undergo dystrophy in a deafness auditory pathway. If the infants receivecochlear implantsduring the earlycritical period, the neurosensory functions can be restored. A recent study concluded that congenital deafness does not damage the general cortical cytoarchitecture. However, there is anatomical dystrophy of deep layers over higher-order cortical fields. The sensory deprivation of auditory neurones induces dystrophy beyond the primary auditory cortex, namely the dorsal zone of the auditory cortex (DZ) andsecondary auditory cortex(A2). Cortical deafnessis characterised by the unresponsiveness to both verbal and nonverbal sounds due to cortical lesions. However, thissensorineural hearing lossshows no damage to the auditory pathway from thecochleato the upperbrainstem. The onset is usually during childhood, where they have severely impaired ability to distinguish the different vowels and consonant sounds, and impaired capability to comprehend auditory information.They have no subjective experience of hearingas they are unable to process acoustic impulse. They may learn how to identify the meaning of nonverbal sounds correctly. Primary progressive aphasiais characterised by the progressive impairment of speech production, comprehension and communication. It is secondary to neurodegenerative diseases, for instance,Alzheimer's diseaseandfrontotemporal lobar degeneration.The Heschl gyrus undergoes deterioration, as shown by the low activity of the primary auditory cortex after stimulation.The symptoms are difficulty and delay in communication and speech organisation. The patients may become reluctant to communicate or even unable to understand verbal or written language, eventually causing primary progressive aphasia. Difficulty in auditory processing is a complication ofconcussionthat may result in a reduced activation of the primary auditory cortex, as shown byfMRI.The neural communication of the left and right primary auditory cortices are poorly transmitted. As a result, thelateralisationand responsiveness of the cerebral cortex are affected. Thetemporal fine structureprocessing has degenerated as presented by the reduced temporal resolution.It is often due to diffuse axonal injury and demyelination. There may be peripheral and central symptoms, such as reduced auditory understanding in a complex listening environment, central auditory processing disorder andauditory hallucination.Hyperacusis, that is the hypersensitivity to environmental noise can also develop. Auditory hallucination is one of the major symptoms displayed inschizophrenia. Studies supported by functional imaging and electrophysiology have shown a possible correlation between the auditory cortex and auditory hallucinations. In the case of an average individual, speaking-induced suppression is generated due to speaking to reduce the activity in the primary auditory cortex.This acts as a physiological mechanism in the auditory system for the speaker to be more focused on the sounds externally produced. However, this is not demonstrated in individuals with schizophrenia, in contrast, there is an increased activity in the auditory cortex instead of sound suppression. Even in a silent environment without external auditory stimuli, there tends to be abnormal activation of the auditory cortex, leading to auditory hallucinations.The volume of the auditory cortex in those with schizophrenia is much smaller.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Auditosensory_cortex", "https://en.wikipedia.org/wiki/Auditosensory_cortex", "https://en.wikipedia.org/wiki/Auditosensory_cortex", "https://en.wikipedia.org/wiki/Auditory_system", "https://en.wikipedia.org/wiki/Hearing", "https://en.wikipedia.org/wiki/Auditory_cortex", "https://en.wikipedia.org/wiki/Temporal_lobe", "https://en.wikipedia.org/wiki/Brodmann_areas_41_and_42"]},
{"id": "b01f742fd071", "url": "https://en.wikipedia.org/wiki/Vandana_Shiva", "title": "Vandana Shiva", "headings": ["Contents", "Early life and education", "Career", "Activism", "Seed freedom", "Golden rice", "GM, India and suicides", "Ecofeminism", "Indian Intelligence Bureau investigation", "Criticism", "Science as legacy of exploitation", "Film", "Selected listing", "BBC Women of the Year list", "Publications", "See also", "References", "External links"], "content": " Vandana Shiva(born 5 November 1952) is an Indianscholar,environmental activist,food sovereigntyadvocate,ecofeministandanti-globalizationauthor.Based inDelhi, Shiva has written more than 20 books.She is often referred to as \"Gandhi of grain\" for her activism associated with theanti-GMOmovement. Shiva is one of the leaders and board members of the International Forum on Globalization (withJerry Mander,Ralph Nader, andHelena Norberg-Hodge), and a figure of the anti-globalisation movement.She has argued in favour of many traditional practices, as in her interview in the bookVedic Ecology(byRanchor Prime). She is a member of the scientific committee of theFundacion IDEAS, Spain'sSocialist Party'sthink tank. She is also a member of the International Organization for a Participatory Society. Vandana Shiva was born inDehradun. Her father was a conservator of forests, and her mother was a farmer with a love for nature. She was educated atSt. Mary's Convent High School, Nainital, and at theConvent of Jesus and Mary, Dehradun. Shiva studied physics atPunjab UniversityinChandigarh, graduating with a Bachelor of Science degree in 1972.After a brief stint at theBhabha Atomic Research Centre, she moved to Canada to pursue a master's degree in thephilosophy of scienceat theUniversity of Guelphin 1977 where she wrote a thesis entitled \"Changes in the concept of periodicity of light\".In 1978, she completed and received her PhD inphilosophyat theUniversity of Western Ontario,focusing onphilosophy of physics. Her dissertation was titled \"Hidden variables and locality in quantum theory\" in which she discussed the mathematical and philosophical implications ofhidden variable theoriesthat fall outside of the purview ofBell's theorem.She later went on to pursue interdisciplinary research in science, technology, andenvironmental policyat theIndian Institute of Scienceand theIndian Institute of ManagementinBangalore. Vandana Shiva has written and spoken extensively about advances in the fields of agriculture and food.Intellectual property rights,biodiversity,biotechnology,bioethics, andgenetic engineeringare among the fields where Shiva has fought through activist campaigns. She has assistedgrassrootsorganisations of theGreen movementin Africa, Asia, Latin America, Ireland, Switzerland, and Austria with opposition to advances in agricultural development via genetic engineering. In 1982, she founded the Research Foundation for Science, Technology and Ecology.This led to the creation ofNavdanyain 1991, a national movement to protect the diversity and integrity of living resources, especially native seed, the promotion of organic farming and fair trade.Navdanya, which translates to \"Nine Seeds\" or \"New Gift\", is an initiative of the RFSTE to educate farmers of the benefits of maintaining diverse and individualised crops rather than accepting offers from monoculture food producers. The initiative established over 40 seed banks across India to provide regional opportunity for diverse agriculture. In 2004 Shiva started Bija Vidyapeeth, an international college forsustainable livingin Doon Valley, Uttarakhand, in collaboration withSchumacher College, UK. In the area of intellectual property rights and biodiversity, Shiva and her team at the Research Foundation for Science, Technology and Ecology challenged thebiopiracyof neem, basmati and wheat. In 1990, she wrote a report for the FAO on Women and Agriculture titled \"Most Farmers in India are Women\". She founded the gender unit at theInternational Centre for Mountain Development(ICIMOD) inKathmanduand was a founding board member of theWomen's Environment & Development Organisation(WEDO).She received theRight Livelihood Awardin 1993, an award established by Swedish-German philanthropistJakob von Uexkull. Shiva's bookMaking Peace With the Earthdiscusses biodiversity and the relationship between communities and nature. \"Accordingly, she aligns the destruction of natural biodiversity with the dismantling of traditional communities—those who 'understand the language of nature'\".David Wright wrote in a review of the book that to Shiva, \"the Village becomes a symbol, almost a metaphor for 'the local' in all nations\". Shiva has also served as an advisor to governments in India and abroad as well as non-governmental organisations, including the International Forum on Globalization, theWomen's Environment & Development Organisationand the Third World Network. She chairs the Commission on the Future of Food set up by the Region ofTuscanyin Italy and is a member of the Scientific Committee that advised former prime minister Zapatero of Spain. Shiva is a member of the Steering Committee of the Indian People's Campaign AgainstWTO. She is a councilor of theWorld Future Council. Shiva serves on Government of India Committees on Organic Farming. She participated in theStock Exchange of Visionsproject in 2007. In 2021, she advised the government of Sri Lanka to ban inorganic fertilizers and pesticidesstating \"This decision will definitely help farmers become more prosperous. Use of organic fertilizer will help provide agri products rich with nutrients while retaining the fertility of the land.\"The policy applied overnight, with the main purpose to save State foreign exchange bills on imported fertilizers,causeda crisiswith a significant reduction of farming output in several sectors, hitting the tea industry in particularand reducing rice yields were by one third.The ban was overturned seven months later. Her work on agriculture started in 1984 after the violence in Punjab and theBhopal disastercaused by a gas leak fromUnion Carbide's pesticide manufacturing plant. Her studies for the UN University led to the publication of her bookThe Violence of the Green Revolution. In an interview withDavid Barsamian, Shiva argues that the seed-chemical package promoted by green revolution agriculture has depleted fertile soil and destroyed living ecosystems.In her work Shiva cites data allegedly demonstrating that today there are over 1400 pesticides that may enter thefood systemacross the world. Shiva is a founding councillor of theWorld Future Council(WFC).  The WFC was formed in 2007 \"to speak on behalf of policy solutions that serve the interests of future generations.\"  Their primary focus has been on climate security. She supports the crime ofecocidebeing introduced to theInternational Criminal Courtstating\"The ideal of limitless growth is leading to limitless violations of the rights of the Earth and of the rights of nature. This is ecocide\". Vandana supports the idea of seed freedom, or the rejection of patents on new plant lines or cultivars. She has campaigned against the implementation of the WTO 1994 Trade Related Intellectual Property Rights(TRIPS) agreement, which broadens the scope of patents to include life forms. Shiva has criticised the agreement as having close ties with the corporate sector and opening the door to further patents on life.Shiva calls the patenting of life 'biopiracy', and has fought against attempted patents of several indigenous plants, such as basmati.In 2005, Shiva's was one of the three organisations that won a 10-year battle in theEuropean Patent Officeagainst the biopiracy ofNeemby theUS Department of Agricultureand the corporationWR Grace.In 1998, Shiva's organisationNavdanyabegan a campaign against the biopiracy of basmati rice by US corporationRiceTecInc. In 2001, following intensive campaigning, RiceTec lost most of its claims to the patent. Shiva strongly opposesgolden rice, a breed of rice that has been genetically engineered to biosynthesise beta-carotene, a precursor of vitamin A. Shiva contends that Golden Rice is more harmful than beneficial in her explanation of what she calls the \"Golden Rice hoax\": \"Unfortunately, Vitamin A rice is a hoax, and will bring further dispute to plant genetic engineering where public relations exercises seem to have replaced science in promotion of untested, unproven and unnecessary technology... This is a recipe for creating hunger and malnutrition, not solving it.\"Adrian Dubock says that golden rice is as cheap as other rice and vitamin A deficiency is the greatest reason for blindness and causes 28% of global preschool child mortality.Shiva has claimed that the women of Bengal grow and eat 150 greens which can do the same,while environmental consultantPatrick Mooresuggests that most of these 250 million children do not eat much else than a bowl of rice a day.In the 2013 report \"The economic power of the Golden Rice opposition\", two economists, Wesseler and Zilberman fromMunich Universityand theUniversity of California, Berkeleyrespectively calculated that the absence of Golden Rice in India had caused the loss of over 1.4 million lives in the previous ten years. In a 2013 opinion piece, Shiva wrote, \"Soaring seed prices in India have resulted in many farmers being mired in debt and turning to suicide.\" She goes on to say that, \"The creation of seed monopolies, the destruction of alternatives, the collection of superprofits in the form of royalties, and the increasing vulnerability of monocultures has created a context for debt, suicides, andagrarian distress.\" She then states that, \"According to data from the Indian government, nearly 75 percent of rural debt is due to purchased inputs. Farmers' debt grows as Monsanto profits grow. It is in this systemic sense that GM seeds are those of suicide.\" International Food Policy Research Institute(IFPRI) twice analysed academic articles and government data and concluded the decrease and that there was no evidence on \"resurgence\" of farmer suicide. Shiva plays a major role in the global ecofeminist movement. According to her 2004 articleEmpowering Women,a more sustainable and productive approach to agriculture can be achieved by reinstating the system of farming in India that is more centred on engaging women. She advocates against the prevalent \"patriarchal logic of exclusion,\" claiming that a woman-focused system would be a great improvement.She believes that ecological destruction and industrial catastrophes threaten daily life, and the maintenance of these problems have become women's responsibility. Cecile Jackson has criticised some of Shiva's views asessentialist. Shiva co-wrote the bookEcofeminismin 1993 with \"German anarchist and radical feminist sociologist\"Maria Mies. It combined Western and Southern feminism with \"environmental, technological and feminist issues, all incorporated under the term ecofeminism\".These theories are combined throughout the book in essays by Shiva and Mies. Stefanie Lay described the book as a collection of thought-provoking essays but also found in it a lack of new ecofeminist theories and contemporary analysis, as well as \"overall failure to acknowledge the work of others\". In June 2014, Indian and international media reported that Navdanya and Vandana Shiva were named in a leaked, classified report byIndia's Intelligence Bureau(IB), which was prepared for theIndian Prime Minister'sOffice. The leaked report says that campaigning activities of Indian NGOs such as Navdanya are hampering India's growth and development. In its report, the IB said that Indian NGOs, including Navdanya, receive money from foreign donors under the 'charitable garb' of campaigning forhuman rightsorwomen's equality, but instead use the money for'nefarious purposes'. \"These foreign donors lead local NGOs to provide field reports which are used to build a record against India and serve as tools for the strategic foreign policy interests of the Western governments,\" the IB report states. Investigative journalistMichael Specter, in an article inThe New Yorkeron 25 August 2014 called \"Seeds of Doubt\",raised concerns over a number of Shiva's claims regarding GMOs and some of her campaigning methods. He wrote: \"Shiva's absolutism about G.M.O.s can lead her in strange directions. In 1999, ten thousand people were killed and millions were left homeless when a cyclone hit India's eastern coastal state of Orissa. When the U.S. government dispatched grain and soy to help feed the desperate victims, Shiva held a news conference inNew Delhiand said that the donation was proof that 'the United States has been using the Orissa victims as guinea pigs' for genetically-engineered products, although she made no mention that those same products are approved and consumed in the United States. She also wrote to the international relief agencyOxfamto say that she hoped it wasn't planning to send genetically modified foods to feed the starving survivors.\" Shiva responded that Specter was \"ill informed\"and that \"for the record, ever since I sued Monsanto in 1999 for its illegal Bt cotton trials in India, I have received death threats\", adding that the \"concerted PR assault on me for the last two years from Lynas, Specter and an equally vocal Twitter group is a sign that the global outrage against the control over our seed and food, by Monsanto through GMOs, is making the biotech industry panic.\"David Remnick, the editor of theNew Yorker, responded by publishing a letter supporting Specter's article. Cases of plagiarism have been pointed out against Shiva. Birendra Nayak noted that Shiva copied verbatim from a 1996 article in Voice Gopalpur in her 1998 bookStronger than Steel,and that in 2016, she plagiarised several paragraphs of an article by S Faizi on the Plachimada/Coca-Cola issue published inThe Statesman. JournalistKeith Kloor, in an article published inDiscoveron 23 October 2014 titled \"The Rich Allure of a Peasant Champion\", revealed that Shiva charges $40,000 per lecture, plus abusiness-classair ticket from New Delhi. Kloor wrote: \"She is often heralded as a tireless 'defender of the poor,' someone who has courageously taken her stand among the peasant farmers of India. Let it be noted, however, that this champion of the downtrodden doesn't exactly live a peasant's lifestyle.\" Stewart BrandinWhole Earth Disciplinedescribed some of Shiva's statements as pseudo-scientific, calling her warnings about \"heritable sterility\" (Stolen Harvest, 2000) a \"biological impossibility\" but also plagiarism from Geri Guidetti, owner of the seed supplier company Ark Institute, and a \"distraction\" created by inflating the potential ofterminator genesbased on a single 1998 patent granted to a US company.Brand also criticised the position of anti-GMO activists, including Shiva, who forcedZambia's government to reject internationally donated corn in 2001-02 because it was \"poisoned\", as well as during the cyclone disaster in India. On the latter Shiva argued, \"emergency cannot be used as market opportunity\", to which Brand responded, \"anyone who encourages other people to starve on principle should do some of the starving themselves\". In 1998 Shiva was also protesting against Bt cotton program in India, calling it \"seeds of suicide, seeds of slavery, seeds of despair\", claiming she was protecting the farmers. Restrictive laws established in India under anti-GMO lobbying, however, led to widespread grassroots \"seed piracy\" where Indian farmers illegally planted seeds ofBt cottonandBt brinjal, obtained either from experimental plantations or fromBangladesh(where they are planted legally) due to increased yield and reduced pesticide usage.As of 2005 over 2.5 million hectares were planted with \"unofficial\" Bt cotton in India, of whichNoel Kingsburysaid: Shiva's \"Operation Cremate Monsanto\" had spectacularly failed, its anti-GM stance borrowed from Western intellectuals had made no headway with Indian farmers, who showed they were not passive recipients of either technology or propaganda, but could take an active role in shaping their lives. What they did is also perhaps more genuinely subversive of multinational capitalism than anything GM's opponents have ever managed. —Noel Kingsbury, Hybrid: The History and Science of Plant Breeding (2009) In India, farmers planting GM crops illegally eventually formed the Shetkari Sanghatana movement, calling for reform of the restrictive laws created under anti-GMO lobbying and as of 2020 an estimated 25% of cotton farmed is GM. Shiva has repeatedly gone on record characterizing science as \"a very narrow, patriarchal project\" that has been around only \"for a short period of history\" and argued that \"we name 'science' what is mechanistic and reductionist.\" She condemns the \"kind of science\" that \"Bacon,Descartes, and others, who are called 'fathers of modern science', have created,\" because scientists, as she claims, \"declare nature as dead\" and then use a \"mechanistic mode\" to analyze it. Shiva assigns the so-called scientific progress of the last centuries to the advance ofcapitalism, a time when the new exploitation needed a knowledge that would justify it.In her 8 March 2017 speech to theEuropean Parliament, Shiva stated that the \"rise of masculinist science with Descartes, Newton, Bacon, led to the domination of [a] reductionist mechanistic science and a subjugation of [the] knowledge systems [that are] based on interconnections and relationships,\" a knowledge, she argued, that \"includes allindigenousknowledge systems, and women’s knowledge.\" Vandana Shiva has been interviewed for a number of documentary films includingFreedom Ahead,Roshni;Deconstructing Supper: Is Your Food Safe?,The Corporation,Thrive,Dirt! The Movie,Normal is Over, andThis is What Democracy Looks Like(a documentary about the SeattleWTO protests of 1999).and Michael Moore and Jeff GibbsPlanet of the Humans. Shiva's focus on water has caused her to appear in a number of films on this topic. These films include \"Ganga From the Ground Up,\" a documentary on water issues in the river Ganges;Blue Gold: World Water WarsbySam Bozzo;Irena Salina's documentaryFlow: For Love of Water(in competition at the 2008Sundance Film Festival), and thePBSNOW documentaryOn Thin Ice. On the topic of genetically modified crops, she was featured in the documentaryFed Up!(2002), on genetic engineering, industrial agriculture and sustainable alternatives; and the documentaryThe World According to Monsanto, a film made by the French independent journalistMarie-Monique Robin. Shiva appeared in a documentary film about theDalai Lama, entitledDalai Lama Renaissance. In 2010, Shiva was interviewed in a documentary abouthoneybeesandcolony collapse disorder, entitledQueen of the Sun. She appears in the French filmsDemainandSolutions locales pour un désordre global. In 2016, she appeared in thevegandocumentary filmH.O.P.E.: What You Eat Matters, where she was critical of theanimal agriculture industryandmeat-intensive diets. She was recognized as one of the BBC's 100 women of 2019.", "combined_text": "Vandana Shiva Contents Early life and education Career Activism Seed freedom Golden rice GM, India and suicides Ecofeminism Indian Intelligence Bureau investigation Criticism Science as legacy of exploitation Film Selected listing BBC Women of the Year list Publications See also References External links  Vandana Shiva(born 5 November 1952) is an Indianscholar,environmental activist,food sovereigntyadvocate,ecofeministandanti-globalizationauthor.Based inDelhi, Shiva has written more than 20 books.She is often referred to as \"Gandhi of grain\" for her activism associated with theanti-GMOmovement. Shiva is one of the leaders and board members of the International Forum on Globalization (withJerry Mander,Ralph Nader, andHelena Norberg-Hodge), and a figure of the anti-globalisation movement.She has argued in favour of many traditional practices, as in her interview in the bookVedic Ecology(byRanchor Prime). She is a member of the scientific committee of theFundacion IDEAS, Spain'sSocialist Party'sthink tank. She is also a member of the International Organization for a Participatory Society. Vandana Shiva was born inDehradun. Her father was a conservator of forests, and her mother was a farmer with a love for nature. She was educated atSt. Mary's Convent High School, Nainital, and at theConvent of Jesus and Mary, Dehradun. Shiva studied physics atPunjab UniversityinChandigarh, graduating with a Bachelor of Science degree in 1972.After a brief stint at theBhabha Atomic Research Centre, she moved to Canada to pursue a master's degree in thephilosophy of scienceat theUniversity of Guelphin 1977 where she wrote a thesis entitled \"Changes in the concept of periodicity of light\".In 1978, she completed and received her PhD inphilosophyat theUniversity of Western Ontario,focusing onphilosophy of physics. Her dissertation was titled \"Hidden variables and locality in quantum theory\" in which she discussed the mathematical and philosophical implications ofhidden variable theoriesthat fall outside of the purview ofBell's theorem.She later went on to pursue interdisciplinary research in science, technology, andenvironmental policyat theIndian Institute of Scienceand theIndian Institute of ManagementinBangalore. Vandana Shiva has written and spoken extensively about advances in the fields of agriculture and food.Intellectual property rights,biodiversity,biotechnology,bioethics, andgenetic engineeringare among the fields where Shiva has fought through activist campaigns. She has assistedgrassrootsorganisations of theGreen movementin Africa, Asia, Latin America, Ireland, Switzerland, and Austria with opposition to advances in agricultural development via genetic engineering. In 1982, she founded the Research Foundation for Science, Technology and Ecology.This led to the creation ofNavdanyain 1991, a national movement to protect the diversity and integrity of living resources, especially native seed, the promotion of organic farming and fair trade.Navdanya, which translates to \"Nine Seeds\" or \"New Gift\", is an initiative of the RFSTE to educate farmers of the benefits of maintaining diverse and individualised crops rather than accepting offers from monoculture food producers. The initiative established over 40 seed banks across India to provide regional opportunity for diverse agriculture. In 2004 Shiva started Bija Vidyapeeth, an international college forsustainable livingin Doon Valley, Uttarakhand, in collaboration withSchumacher College, UK. In the area of intellectual property rights and biodiversity, Shiva and her team at the Research Foundation for Science, Technology and Ecology challenged thebiopiracyof neem, basmati and wheat. In 1990, she wrote a report for the FAO on Women and Agriculture titled \"Most Farmers in India are Women\". She founded the gender unit at theInternational Centre for Mountain Development(ICIMOD) inKathmanduand was a founding board member of theWomen's Environment & Development Organisation(WEDO).She received theRight Livelihood Awardin 1993, an award established by Swedish-German philanthropistJakob von Uexkull. Shiva's bookMaking Peace With the Earthdiscusses biodiversity and the relationship between communities and nature. \"Accordingly, she aligns the destruction of natural biodiversity with the dismantling of traditional communities—those who 'understand the language of nature'\".David Wright wrote in a review of the book that to Shiva, \"the Village becomes a symbol, almost a metaphor for 'the local' in all nations\". Shiva has also served as an advisor to governments in India and abroad as well as non-governmental organisations, including the International Forum on Globalization, theWomen's Environment & Development Organisationand the Third World Network. She chairs the Commission on the Future of Food set up by the Region ofTuscanyin Italy and is a member of the Scientific Committee that advised former prime minister Zapatero of Spain. Shiva is a member of the Steering Committee of the Indian People's Campaign AgainstWTO. She is a councilor of theWorld Future Council. Shiva serves on Government of India Committees on Organic Farming. She participated in theStock Exchange of Visionsproject in 2007. In 2021, she advised the government of Sri Lanka to ban inorganic fertilizers and pesticidesstating \"This decision will definitely help farmers become more prosperous. Use of organic fertilizer will help provide agri products rich with nutrients while retaining the fertility of the land.\"The policy applied overnight, with the main purpose to save State foreign exchange bills on imported fertilizers,causeda crisiswith a significant reduction of farming output in several sectors, hitting the tea industry in particularand reducing rice yields were by one third.The ban was overturned seven months later. Her work on agriculture started in 1984 after the violence in Punjab and theBhopal disastercaused by a gas leak fromUnion Carbide's pesticide manufacturing plant. Her studies for the UN University led to the publication of her bookThe Violence of the Green Revolution. In an interview withDavid Barsamian, Shiva argues that the seed-chemical package promoted by green revolution agriculture has depleted fertile soil and destroyed living ecosystems.In her work Shiva cites data allegedly demonstrating that today there are over 1400 pesticides that may enter thefood systemacross the world. Shiva is a founding councillor of theWorld Future Council(WFC).  The WFC was formed in 2007 \"to speak on behalf of policy solutions that serve the interests of future generations.\"  Their primary focus has been on climate security. She supports the crime ofecocidebeing introduced to theInternational Criminal Courtstating\"The ideal of limitless growth is leading to limitless violations of the rights of the Earth and of the rights of nature. This is ecocide\". Vandana supports the idea of seed freedom, or the rejection of patents on new plant lines or cultivars. She has campaigned against the implementation of the WTO 1994 Trade Related Intellectual Property Rights(TRIPS) agreement, which broadens the scope of patents to include life forms. Shiva has criticised the agreement as having close ties with the corporate sector and opening the door to further patents on life.Shiva calls the patenting of life 'biopiracy', and has fought against attempted patents of several indigenous plants, such as basmati.In 2005, Shiva's was one of the three organisations that won a 10-year battle in theEuropean Patent Officeagainst the biopiracy ofNeemby theUS Department of Agricultureand the corporationWR Grace.In 1998, Shiva's organisationNavdanyabegan a campaign against the biopiracy of basmati rice by US corporationRiceTecInc. In 2001, following intensive campaigning, RiceTec lost most of its claims to the patent. Shiva strongly opposesgolden rice, a breed of rice that has been genetically engineered to biosynthesise beta-carotene, a precursor of vitamin A. Shiva contends that Golden Rice is more harmful than beneficial in her explanation of what she calls the \"Golden Rice hoax\": \"Unfortunately, Vitamin A rice is a hoax, and will bring further dispute to plant genetic engineering where public relations exercises seem to have replaced science in promotion of untested, unproven and unnecessary technology... This is a recipe for creating hunger and malnutrition, not solving it.\"Adrian Dubock says that golden rice is as cheap as other rice and vitamin A deficiency is the greatest reason for blindness and causes 28% of global preschool child mortality.Shiva has claimed that the women of Bengal grow and eat 150 greens which can do the same,while environmental consultantPatrick Mooresuggests that most of these 250 million children do not eat much else than a bowl of rice a day.In the 2013 report \"The economic power of the Golden Rice opposition\", two economists, Wesseler and Zilberman fromMunich Universityand theUniversity of California, Berkeleyrespectively calculated that the absence of Golden Rice in India had caused the loss of over 1.4 million lives in the previous ten years. In a 2013 opinion piece, Shiva wrote, \"Soaring seed prices in India have resulted in many farmers being mired in debt and turning to suicide.\" She goes on to say that, \"The creation of seed monopolies, the destruction of alternatives, the collection of superprofits in the form of royalties, and the increasing vulnerability of monocultures has created a context for debt, suicides, andagrarian distress.\" She then states that, \"According to data from the Indian government, nearly 75 percent of rural debt is due to purchased inputs. Farmers' debt grows as Monsanto profits grow. It is in this systemic sense that GM seeds are those of suicide.\" International Food Policy Research Institute(IFPRI) twice analysed academic articles and government data and concluded the decrease and that there was no evidence on \"resurgence\" of farmer suicide. Shiva plays a major role in the global ecofeminist movement. According to her 2004 articleEmpowering Women,a more sustainable and productive approach to agriculture can be achieved by reinstating the system of farming in India that is more centred on engaging women. She advocates against the prevalent \"patriarchal logic of exclusion,\" claiming that a woman-focused system would be a great improvement.She believes that ecological destruction and industrial catastrophes threaten daily life, and the maintenance of these problems have become women's responsibility. Cecile Jackson has criticised some of Shiva's views asessentialist. Shiva co-wrote the bookEcofeminismin 1993 with \"German anarchist and radical feminist sociologist\"Maria Mies. It combined Western and Southern feminism with \"environmental, technological and feminist issues, all incorporated under the term ecofeminism\".These theories are combined throughout the book in essays by Shiva and Mies. Stefanie Lay described the book as a collection of thought-provoking essays but also found in it a lack of new ecofeminist theories and contemporary analysis, as well as \"overall failure to acknowledge the work of others\". In June 2014, Indian and international media reported that Navdanya and Vandana Shiva were named in a leaked, classified report byIndia's Intelligence Bureau(IB), which was prepared for theIndian Prime Minister'sOffice. The leaked report says that campaigning activities of Indian NGOs such as Navdanya are hampering India's growth and development. In its report, the IB said that Indian NGOs, including Navdanya, receive money from foreign donors under the 'charitable garb' of campaigning forhuman rightsorwomen's equality, but instead use the money for'nefarious purposes'. \"These foreign donors lead local NGOs to provide field reports which are used to build a record against India and serve as tools for the strategic foreign policy interests of the Western governments,\" the IB report states. Investigative journalistMichael Specter, in an article inThe New Yorkeron 25 August 2014 called \"Seeds of Doubt\",raised concerns over a number of Shiva's claims regarding GMOs and some of her campaigning methods. He wrote: \"Shiva's absolutism about G.M.O.s can lead her in strange directions. In 1999, ten thousand people were killed and millions were left homeless when a cyclone hit India's eastern coastal state of Orissa. When the U.S. government dispatched grain and soy to help feed the desperate victims, Shiva held a news conference inNew Delhiand said that the donation was proof that 'the United States has been using the Orissa victims as guinea pigs' for genetically-engineered products, although she made no mention that those same products are approved and consumed in the United States. She also wrote to the international relief agencyOxfamto say that she hoped it wasn't planning to send genetically modified foods to feed the starving survivors.\" Shiva responded that Specter was \"ill informed\"and that \"for the record, ever since I sued Monsanto in 1999 for its illegal Bt cotton trials in India, I have received death threats\", adding that the \"concerted PR assault on me for the last two years from Lynas, Specter and an equally vocal Twitter group is a sign that the global outrage against the control over our seed and food, by Monsanto through GMOs, is making the biotech industry panic.\"David Remnick, the editor of theNew Yorker, responded by publishing a letter supporting Specter's article. Cases of plagiarism have been pointed out against Shiva. Birendra Nayak noted that Shiva copied verbatim from a 1996 article in Voice Gopalpur in her 1998 bookStronger than Steel,and that in 2016, she plagiarised several paragraphs of an article by S Faizi on the Plachimada/Coca-Cola issue published inThe Statesman. JournalistKeith Kloor, in an article published inDiscoveron 23 October 2014 titled \"The Rich Allure of a Peasant Champion\", revealed that Shiva charges $40,000 per lecture, plus abusiness-classair ticket from New Delhi. Kloor wrote: \"She is often heralded as a tireless 'defender of the poor,' someone who has courageously taken her stand among the peasant farmers of India. Let it be noted, however, that this champion of the downtrodden doesn't exactly live a peasant's lifestyle.\" Stewart BrandinWhole Earth Disciplinedescribed some of Shiva's statements as pseudo-scientific, calling her warnings about \"heritable sterility\" (Stolen Harvest, 2000) a \"biological impossibility\" but also plagiarism from Geri Guidetti, owner of the seed supplier company Ark Institute, and a \"distraction\" created by inflating the potential ofterminator genesbased on a single 1998 patent granted to a US company.Brand also criticised the position of anti-GMO activists, including Shiva, who forcedZambia's government to reject internationally donated corn in 2001-02 because it was \"poisoned\", as well as during the cyclone disaster in India. On the latter Shiva argued, \"emergency cannot be used as market opportunity\", to which Brand responded, \"anyone who encourages other people to starve on principle should do some of the starving themselves\". In 1998 Shiva was also protesting against Bt cotton program in India, calling it \"seeds of suicide, seeds of slavery, seeds of despair\", claiming she was protecting the farmers. Restrictive laws established in India under anti-GMO lobbying, however, led to widespread grassroots \"seed piracy\" where Indian farmers illegally planted seeds ofBt cottonandBt brinjal, obtained either from experimental plantations or fromBangladesh(where they are planted legally) due to increased yield and reduced pesticide usage.As of 2005 over 2.5 million hectares were planted with \"unofficial\" Bt cotton in India, of whichNoel Kingsburysaid: Shiva's \"Operation Cremate Monsanto\" had spectacularly failed, its anti-GM stance borrowed from Western intellectuals had made no headway with Indian farmers, who showed they were not passive recipients of either technology or propaganda, but could take an active role in shaping their lives. What they did is also perhaps more genuinely subversive of multinational capitalism than anything GM's opponents have ever managed. —Noel Kingsbury, Hybrid: The History and Science of Plant Breeding (2009) In India, farmers planting GM crops illegally eventually formed the Shetkari Sanghatana movement, calling for reform of the restrictive laws created under anti-GMO lobbying and as of 2020 an estimated 25% of cotton farmed is GM. Shiva has repeatedly gone on record characterizing science as \"a very narrow, patriarchal project\" that has been around only \"for a short period of history\" and argued that \"we name 'science' what is mechanistic and reductionist.\" She condemns the \"kind of science\" that \"Bacon,Descartes, and others, who are called 'fathers of modern science', have created,\" because scientists, as she claims, \"declare nature as dead\" and then use a \"mechanistic mode\" to analyze it. Shiva assigns the so-called scientific progress of the last centuries to the advance ofcapitalism, a time when the new exploitation needed a knowledge that would justify it.In her 8 March 2017 speech to theEuropean Parliament, Shiva stated that the \"rise of masculinist science with Descartes, Newton, Bacon, led to the domination of [a] reductionist mechanistic science and a subjugation of [the] knowledge systems [that are] based on interconnections and relationships,\" a knowledge, she argued, that \"includes allindigenousknowledge systems, and women’s knowledge.\" Vandana Shiva has been interviewed for a number of documentary films includingFreedom Ahead,Roshni;Deconstructing Supper: Is Your Food Safe?,The Corporation,Thrive,Dirt! The Movie,Normal is Over, andThis is What Democracy Looks Like(a documentary about the SeattleWTO protests of 1999).and Michael Moore and Jeff GibbsPlanet of the Humans. Shiva's focus on water has caused her to appear in a number of films on this topic. These films include \"Ganga From the Ground Up,\" a documentary on water issues in the river Ganges;Blue Gold: World Water WarsbySam Bozzo;Irena Salina's documentaryFlow: For Love of Water(in competition at the 2008Sundance Film Festival), and thePBSNOW documentaryOn Thin Ice. On the topic of genetically modified crops, she was featured in the documentaryFed Up!(2002), on genetic engineering, industrial agriculture and sustainable alternatives; and the documentaryThe World According to Monsanto, a film made by the French independent journalistMarie-Monique Robin. Shiva appeared in a documentary film about theDalai Lama, entitledDalai Lama Renaissance. In 2010, Shiva was interviewed in a documentary abouthoneybeesandcolony collapse disorder, entitledQueen of the Sun. She appears in the French filmsDemainandSolutions locales pour un désordre global. In 2016, she appeared in thevegandocumentary filmH.O.P.E.: What You Eat Matters, where she was critical of theanimal agriculture industryandmeat-intensive diets. She was recognized as one of the BBC's 100 women of 2019.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Vandana_Shiva", "https://en.wikipedia.org/wiki/Vandana_Shiva", "https://en.wikipedia.org/wiki/Vandana_Shiva", "https://en.wikipedia.org/wiki/Dehradun", "https://en.wikipedia.org/wiki/Uttar_Pradesh", "https://en.wikipedia.org/wiki/Uttarakhand", "https://en.wikipedia.org/wiki/India", "https://en.wikipedia.org/wiki/Panjab_University,_Chandigarh"]},
{"id": "725d89ae1c7d", "url": "https://en.wikipedia.org/wiki/John_Ralston_Saul", "title": "John Ralston Saul", "headings": ["Contents", "Early life and education", "Career", "PEN International", "The Institute for Canadian Citizenship", "Speaking", "Fiction writing", "Non-fiction writing", "Honours", "Awards", "Archives", "References", "External links"], "content": " John Ralston SaulCCOOnt(born June 19, 1947) is a Canadian writer,political philosopher, and public intellectual. Saul is most widely known for his writings on the nature ofindividualism,citizenshipand thepublic good; the failures of manager-led societies;the confusion betweenleadershipandmanagerialism;military strategy, in particularirregular warfare; the role offreedom of speechand culture; and critiques of the prevailing economicparadigm. He is a champion of freedom of expression and was the International President ofPEN International, an association of writers. Saul is the co-founder and co-chair of the Institute for Canadian Citizenship, a national charity promoting the inclusion of new citizens. He is also the co-founder and co-chair of 6 Degrees,the global forum for inclusion. Saul is also the husband to the former governor generalAdrienne Clarkson, making him theViceregal consort of Canadaduring most of her service (1999–2005). His work is known for being thought-provoking and ahead of its time, leading him to be called a \"prophet\" byTimeand to be included inUtne Reader's list of the world's leading thinkers and visionaries.His works have been translated into 25 languages in 36 countries. Saul is the son of William Saul, an army officer, and a British mother whose family had a long tradition of military service.He was born in Ottawa, but raised in Alberta and Manitoba before graduating fromOakville Trafalgar High SchoolinOakville, Ontario.At a young age, he became fluent in both national languages, French and English. By the time he started university atMcGill University, Montreal, his father was in Paris and Brussels, working as a military adviser to the Canadian ambassador to NATO. After completing his undergraduate degree, Saul was accepted into the foreign service, but the death of his father in 1968 changed Saul's career plans. He left the foreign service to attendKing's College London, where he wrote his thesis on the modernization of France underCharles de Gaulle, and earned hisPhDin 1972. His doctoral thesis,The Evolution of Civil–Military Relations in France after the Algerian War,led him to France for research. There he began to write his first novel,Mort d'un général, a romanticized version of his thesis on de Gaulle's chief of staff. He supported himself by running the French subsidiary of a British investment company. After helping to set up the national oil companyPetro-Canadain 1976, as assistant to its first chair,Maurice F. Strong, Saul published his first novel,The Birds of Prey, in 1977. Strong described Saul as \"an invaluable, though unconventional, member of my personal staff.\" Through the late 1970s into the 1980s, Saul travelled extensively and regularly spent time with guerrilla armies, spending a great deal of time in North Africa and South East Asia. Out of this time came his novels,The Field Trilogy. It was during those extended periods in Northwest Africa and Southeast Asia where he witnessed fellow writers there suffering government suppression of freedom of expression, which caused him to become interested in the work ofPEN International.Between the years of 1990 and 1992, Saul acted as the president of the Canadian centre of PEN International. In 2009, he was elected president of PEN and re-elected for a second and last term in 2012, remaining International President until October 2015. Saul is co-chair of the Institute for Canadian Citizenship, which encourages new Canadians to become active citizens. He is patron and former president of the Canadian Centre ofPEN Internationaland of theCanadian Academy of Independent Scholars. He is also founder and honorary chair of French for the Future, which encourages bilingual French-English education, chair of the advisory board for theLaFontaine-Baldwin Symposiumlecture series, and a patron of Planned Lifetime Advocacy Network. From 1999 until 2006, his wifeAdrienne ClarksonwasGovernor General of Canada, making him Canada'sviceregal consort. During this period he devoted much of his time to issues of freedom of expression, poverty, public education and bilingualism. Saul was elected as the international president ofPEN Internationalfor a three-year term at its Annual Congress in Linz, Austria in October 2009.  He was the first Canadian to be elected to that position, which had previously been held byJohn Galsworthy,Arthur Miller,Heinrich Böll,Mario Vargas Llosaand Homero Aridjis.He campaigned on the need to pay attention to smaller and endangered languages and cultures, arguing that the ultimate removal of freedom of expression was the loss of a language. He put a specific emphasis on endangered indigenous languages. He called for a further decentralization of PEN, which has 144 centres in 102 countries. He argues that literature and freedom of expression are the same thing; that you cannot have one without the other. Saul has testified before the European Parliament Human Rights Commission on the loss of freedom of expression in Tunisia, has spoken before European Council on Refugees in Exile, and has published an essay on writers in exile, which has been translated into several languages. Saul founded, and currently co-chairs, the Institute for Canadian Citizenship (ICC) withAdrienne Clarkson. The ICC is a national, non-profit charity that helps accelerate new citizens' integration into Canadian life through original programs, collaborations and unique volunteer opportunities. While its focus is on encouraging new citizens to take their rightful place in Canada, the ICC aims to encourage all citizens – new or not – to embrace active citizenship in their daily life. In addition to his selection as the 1995 Massey lecturer, Saul has delivered other notable lectures. He gave the Harold Innis Lecture in 1994. In 2000 he gave the inauguralLaFontaine-Baldwin SymposiumLecture. Saul delivered the J.D. Young Memorial Lecture \"A New Era of Irregular Warfare?\" at theRoyal Military College of CanadainKingston, Ontarioon February 4, 2004.He gave the 2005 IDEAS lecture in Brisbane, Australia, the 2007 Captive Mind Lecture in Kraków, Poland, and in 2008 gave the 33rd Sir Winston Scott Memorial Lecture in Barbados. He also delivered the 2009McGill Law Journal's Annual Lectureat the McGill Faculty of Law in Montreal on February 3, 2009.Saul also spoke at theSydney Opera Houseon August 26, 2012, on the subject \"It's Broke: How do we fix it?\" The Birds of Prey(1977) is a political novel based inGaullistFrance. Between 1983 and 1988 Saul then publishedThe Field Trilogy, which deals with the crisis of modern power and its clash with the individual. It includesBaraka, or The Lives, Fortunes and Sacred Honor of Anthony Smith(1983),The Next Best Thing(1986), andThe Paradise Eater(1988), which won thePremio Letterario Internazionalein Italy. De si bons Américains(1994) is apicaresque novelin which he observes the lives of America'snouveaux riches. A vastly reworked and expanded version was published in 2012 asDark Diversions, Saul's first novel in over fifteen years. Saul's non-fiction began with the trilogy comprising the bestsellerVoltaire's Bastards: The Dictatorship of Reason in the West(1992), the polemic philosophical dictionaryThe Doubter's Companion: A Dictionary of Aggressive Common Sense(1994), and the book that grew out of his 1995Massey Lectures,The Unconscious Civilization(1995). The last won the1996 Governor General's Awardfor Non-Fiction Literature. These books deal with themes such as the dictatorship ofreasonunbalanced by other human qualities, how it can be used for any ends especially in a directionless state that rewards the pursuit of power for power's sake. He argues that this leads to deformations of thought such asideologypromoted astruth; the rational but anti-democratic structures ofcorporatism, by which he means the worship of small groups; and the use of language andexpertiseto mask a practical understanding of the harm caused by this, and what else our society might do. He argues that the rise of individualism with no regard for the role of society has not created greater individual autonomy and self-determination, as was once hoped, but isolation and alienation. He calls for a pursuit of a morehumanistideal in which reason is balanced with other human mental capacities such ascommon sense,ethics,intuition, creativity, and memory, for the sake of the common good, and he discusses the importance of unfettered language and practical democracy. These attributes are elaborated upon in his 2001 bookOn Equilibrium. He expanded on these themes as they relate to Canada andits historyandcultureinReflections of a Siamese Twin(1998). In this book, he proposed the idea of Canada being a \"soft\" country, meaning not that the nation is weak, but that it has a flexible and complex identity, as opposed to the unyielding or monolithic identities of other states. He argues that Canada's complex national identity is made up of the \"triangular reality\" of the three nations that compose it:First Peoples,francophones, andanglophones. He emphasizes the willingness of these Canadian nations to compromise with one another, as opposed to resorting to open confrontations. In the same vein, he criticizes both those in theQuebec separatistMontreal School for emphasizing the conflicts in Canadian history and theOrange Orderand theClear Gritstraditionally seeking clear definitions of Canadian-ness and loyalty. Saul's next book,On Equilibrium(2001), is effectively a fourth, concluding volume to his philosophical quartet. He identifies six qualities as common to all people: common sense, ethics, imagination, intuition, memory, and reason. He describes how these inner forces can be used to balance each other, and what happens when they are unbalanced, for example in the case of a \"Dictatorship of Reason\". In an article written forHarper'smagazine's March 2004 issue, titledThe Collapse of Globalism and the Rebirth of Nationalism, he argued that theglobalist ideologywas under attack by counter-movements. Saul rethought and developed this argument inThe Collapse of Globalism and the Reinvention of the World(2005). Far from being an inevitable force, Saul argued thatglobalizationis already breaking down in the face of widespread public opposition and that the world was seeing a rise innationalism. Following theGreat Recessionhe had predicted,The Collapse of Globalismwas re-issued in 2009 with a new epilogue that addressed theeconomic crisis. A Fair Country(2008) is Saul's second major work on Canada. It is organized into four subsections. Saul's contribution toPenguin Canada'sExtraordinary Canadiansseries, of which he serves as general editor, is a double biography ofLouis-Hippolyte LafontaineandRobert Baldwin. In it, he argues that Canada did not begin in1867, but that in fact its foundations were laid by LaFontaine and Baldwin much earlier. The two leaders ofLowerandUpper Canada, respectively, worked together after the1841 Unionto lead a reformist movement forresponsible governmentrun by elected citizens instead of a colonial governor. But it was during the \"Great Ministry\" of 1848–51 that the two politicians implemented laws that Saul argues created a more equitable country. They revamped judicial institutions, created a public education system, made bilingualism official, designed a network of public roads, began a public postal system, and reformed municipal governance. Faced with opposition, and even violence, Saul contends that the two men united behind a set of principles and programs that formed modern Canada. His most recent work,The Comeback: How Aboriginals Are Reclaiming Power and Influence(2014) was a shortlisted nominee for the 2015Shaughnessy Cohen Prize for Political Writing.The \"comeback\" that Saul identifies in this new book emphasizes the strides that Aboriginal people have made in reversing years of population decline and \"cultural oppression\". As recently as seventy years ago it was widely assumed that Indians were disappearing, the victims of disease, starvation and their own ineptitude for modern civilization. Canada's Aboriginal population is growing in numbers and its cultural and political self-confidence seems boundless. In Saul's view, this observation, while obvious to anyone who studies the history, nonetheless needs hammering home. We are far more used to hearing about the dismal lives of Aboriginal people—their family dysfunction, their crime rates, their impoverished communities—than we are to being told they are a success story. Today's Aboriginal population, for all the problems that afflict it, has overcome incredible disadvantages to achieve what Saul calls \"a position of power, influence and civilizational creativity\" in Canadian society. Saul was made aCompanion of the Order of Canada(CC) in 1999.He is also achevalierof theOrdre des Arts et des Lettresof France (1996).His 21 honorary degrees range fromMcGill Universityand theUniversity of OttawatoHerzen UniversityinSaint Petersburg, Russia. On October 16, 2019, he received his latest honorary degree fromKing's College London.  Ribbon bars of John Ralston Saul There is a John Ralston SaulfondsatLibrary and Archives Canada.", "combined_text": "John Ralston Saul Contents Early life and education Career PEN International The Institute for Canadian Citizenship Speaking Fiction writing Non-fiction writing Honours Awards Archives References External links  John Ralston SaulCCOOnt(born June 19, 1947) is a Canadian writer,political philosopher, and public intellectual. Saul is most widely known for his writings on the nature ofindividualism,citizenshipand thepublic good; the failures of manager-led societies;the confusion betweenleadershipandmanagerialism;military strategy, in particularirregular warfare; the role offreedom of speechand culture; and critiques of the prevailing economicparadigm. He is a champion of freedom of expression and was the International President ofPEN International, an association of writers. Saul is the co-founder and co-chair of the Institute for Canadian Citizenship, a national charity promoting the inclusion of new citizens. He is also the co-founder and co-chair of 6 Degrees,the global forum for inclusion. Saul is also the husband to the former governor generalAdrienne Clarkson, making him theViceregal consort of Canadaduring most of her service (1999–2005). His work is known for being thought-provoking and ahead of its time, leading him to be called a \"prophet\" byTimeand to be included inUtne Reader's list of the world's leading thinkers and visionaries.His works have been translated into 25 languages in 36 countries. Saul is the son of William Saul, an army officer, and a British mother whose family had a long tradition of military service.He was born in Ottawa, but raised in Alberta and Manitoba before graduating fromOakville Trafalgar High SchoolinOakville, Ontario.At a young age, he became fluent in both national languages, French and English. By the time he started university atMcGill University, Montreal, his father was in Paris and Brussels, working as a military adviser to the Canadian ambassador to NATO. After completing his undergraduate degree, Saul was accepted into the foreign service, but the death of his father in 1968 changed Saul's career plans. He left the foreign service to attendKing's College London, where he wrote his thesis on the modernization of France underCharles de Gaulle, and earned hisPhDin 1972. His doctoral thesis,The Evolution of Civil–Military Relations in France after the Algerian War,led him to France for research. There he began to write his first novel,Mort d'un général, a romanticized version of his thesis on de Gaulle's chief of staff. He supported himself by running the French subsidiary of a British investment company. After helping to set up the national oil companyPetro-Canadain 1976, as assistant to its first chair,Maurice F. Strong, Saul published his first novel,The Birds of Prey, in 1977. Strong described Saul as \"an invaluable, though unconventional, member of my personal staff.\" Through the late 1970s into the 1980s, Saul travelled extensively and regularly spent time with guerrilla armies, spending a great deal of time in North Africa and South East Asia. Out of this time came his novels,The Field Trilogy. It was during those extended periods in Northwest Africa and Southeast Asia where he witnessed fellow writers there suffering government suppression of freedom of expression, which caused him to become interested in the work ofPEN International.Between the years of 1990 and 1992, Saul acted as the president of the Canadian centre of PEN International. In 2009, he was elected president of PEN and re-elected for a second and last term in 2012, remaining International President until October 2015. Saul is co-chair of the Institute for Canadian Citizenship, which encourages new Canadians to become active citizens. He is patron and former president of the Canadian Centre ofPEN Internationaland of theCanadian Academy of Independent Scholars. He is also founder and honorary chair of French for the Future, which encourages bilingual French-English education, chair of the advisory board for theLaFontaine-Baldwin Symposiumlecture series, and a patron of Planned Lifetime Advocacy Network. From 1999 until 2006, his wifeAdrienne ClarksonwasGovernor General of Canada, making him Canada'sviceregal consort. During this period he devoted much of his time to issues of freedom of expression, poverty, public education and bilingualism. Saul was elected as the international president ofPEN Internationalfor a three-year term at its Annual Congress in Linz, Austria in October 2009.  He was the first Canadian to be elected to that position, which had previously been held byJohn Galsworthy,Arthur Miller,Heinrich Böll,Mario Vargas Llosaand Homero Aridjis.He campaigned on the need to pay attention to smaller and endangered languages and cultures, arguing that the ultimate removal of freedom of expression was the loss of a language. He put a specific emphasis on endangered indigenous languages. He called for a further decentralization of PEN, which has 144 centres in 102 countries. He argues that literature and freedom of expression are the same thing; that you cannot have one without the other. Saul has testified before the European Parliament Human Rights Commission on the loss of freedom of expression in Tunisia, has spoken before European Council on Refugees in Exile, and has published an essay on writers in exile, which has been translated into several languages. Saul founded, and currently co-chairs, the Institute for Canadian Citizenship (ICC) withAdrienne Clarkson. The ICC is a national, non-profit charity that helps accelerate new citizens' integration into Canadian life through original programs, collaborations and unique volunteer opportunities. While its focus is on encouraging new citizens to take their rightful place in Canada, the ICC aims to encourage all citizens – new or not – to embrace active citizenship in their daily life. In addition to his selection as the 1995 Massey lecturer, Saul has delivered other notable lectures. He gave the Harold Innis Lecture in 1994. In 2000 he gave the inauguralLaFontaine-Baldwin SymposiumLecture. Saul delivered the J.D. Young Memorial Lecture \"A New Era of Irregular Warfare?\" at theRoyal Military College of CanadainKingston, Ontarioon February 4, 2004.He gave the 2005 IDEAS lecture in Brisbane, Australia, the 2007 Captive Mind Lecture in Kraków, Poland, and in 2008 gave the 33rd Sir Winston Scott Memorial Lecture in Barbados. He also delivered the 2009McGill Law Journal's Annual Lectureat the McGill Faculty of Law in Montreal on February 3, 2009.Saul also spoke at theSydney Opera Houseon August 26, 2012, on the subject \"It's Broke: How do we fix it?\" The Birds of Prey(1977) is a political novel based inGaullistFrance. Between 1983 and 1988 Saul then publishedThe Field Trilogy, which deals with the crisis of modern power and its clash with the individual. It includesBaraka, or The Lives, Fortunes and Sacred Honor of Anthony Smith(1983),The Next Best Thing(1986), andThe Paradise Eater(1988), which won thePremio Letterario Internazionalein Italy. De si bons Américains(1994) is apicaresque novelin which he observes the lives of America'snouveaux riches. A vastly reworked and expanded version was published in 2012 asDark Diversions, Saul's first novel in over fifteen years. Saul's non-fiction began with the trilogy comprising the bestsellerVoltaire's Bastards: The Dictatorship of Reason in the West(1992), the polemic philosophical dictionaryThe Doubter's Companion: A Dictionary of Aggressive Common Sense(1994), and the book that grew out of his 1995Massey Lectures,The Unconscious Civilization(1995). The last won the1996 Governor General's Awardfor Non-Fiction Literature. These books deal with themes such as the dictatorship ofreasonunbalanced by other human qualities, how it can be used for any ends especially in a directionless state that rewards the pursuit of power for power's sake. He argues that this leads to deformations of thought such asideologypromoted astruth; the rational but anti-democratic structures ofcorporatism, by which he means the worship of small groups; and the use of language andexpertiseto mask a practical understanding of the harm caused by this, and what else our society might do. He argues that the rise of individualism with no regard for the role of society has not created greater individual autonomy and self-determination, as was once hoped, but isolation and alienation. He calls for a pursuit of a morehumanistideal in which reason is balanced with other human mental capacities such ascommon sense,ethics,intuition, creativity, and memory, for the sake of the common good, and he discusses the importance of unfettered language and practical democracy. These attributes are elaborated upon in his 2001 bookOn Equilibrium. He expanded on these themes as they relate to Canada andits historyandcultureinReflections of a Siamese Twin(1998). In this book, he proposed the idea of Canada being a \"soft\" country, meaning not that the nation is weak, but that it has a flexible and complex identity, as opposed to the unyielding or monolithic identities of other states. He argues that Canada's complex national identity is made up of the \"triangular reality\" of the three nations that compose it:First Peoples,francophones, andanglophones. He emphasizes the willingness of these Canadian nations to compromise with one another, as opposed to resorting to open confrontations. In the same vein, he criticizes both those in theQuebec separatistMontreal School for emphasizing the conflicts in Canadian history and theOrange Orderand theClear Gritstraditionally seeking clear definitions of Canadian-ness and loyalty. Saul's next book,On Equilibrium(2001), is effectively a fourth, concluding volume to his philosophical quartet. He identifies six qualities as common to all people: common sense, ethics, imagination, intuition, memory, and reason. He describes how these inner forces can be used to balance each other, and what happens when they are unbalanced, for example in the case of a \"Dictatorship of Reason\". In an article written forHarper'smagazine's March 2004 issue, titledThe Collapse of Globalism and the Rebirth of Nationalism, he argued that theglobalist ideologywas under attack by counter-movements. Saul rethought and developed this argument inThe Collapse of Globalism and the Reinvention of the World(2005). Far from being an inevitable force, Saul argued thatglobalizationis already breaking down in the face of widespread public opposition and that the world was seeing a rise innationalism. Following theGreat Recessionhe had predicted,The Collapse of Globalismwas re-issued in 2009 with a new epilogue that addressed theeconomic crisis. A Fair Country(2008) is Saul's second major work on Canada. It is organized into four subsections. Saul's contribution toPenguin Canada'sExtraordinary Canadiansseries, of which he serves as general editor, is a double biography ofLouis-Hippolyte LafontaineandRobert Baldwin. In it, he argues that Canada did not begin in1867, but that in fact its foundations were laid by LaFontaine and Baldwin much earlier. The two leaders ofLowerandUpper Canada, respectively, worked together after the1841 Unionto lead a reformist movement forresponsible governmentrun by elected citizens instead of a colonial governor. But it was during the \"Great Ministry\" of 1848–51 that the two politicians implemented laws that Saul argues created a more equitable country. They revamped judicial institutions, created a public education system, made bilingualism official, designed a network of public roads, began a public postal system, and reformed municipal governance. Faced with opposition, and even violence, Saul contends that the two men united behind a set of principles and programs that formed modern Canada. His most recent work,The Comeback: How Aboriginals Are Reclaiming Power and Influence(2014) was a shortlisted nominee for the 2015Shaughnessy Cohen Prize for Political Writing.The \"comeback\" that Saul identifies in this new book emphasizes the strides that Aboriginal people have made in reversing years of population decline and \"cultural oppression\". As recently as seventy years ago it was widely assumed that Indians were disappearing, the victims of disease, starvation and their own ineptitude for modern civilization. Canada's Aboriginal population is growing in numbers and its cultural and political self-confidence seems boundless. In Saul's view, this observation, while obvious to anyone who studies the history, nonetheless needs hammering home. We are far more used to hearing about the dismal lives of Aboriginal people—their family dysfunction, their crime rates, their impoverished communities—than we are to being told they are a success story. Today's Aboriginal population, for all the problems that afflict it, has overcome incredible disadvantages to achieve what Saul calls \"a position of power, influence and civilizational creativity\" in Canadian society. Saul was made aCompanion of the Order of Canada(CC) in 1999.He is also achevalierof theOrdre des Arts et des Lettresof France (1996).His 21 honorary degrees range fromMcGill Universityand theUniversity of OttawatoHerzen UniversityinSaint Petersburg, Russia. On October 16, 2019, he received his latest honorary degree fromKing's College London.  Ribbon bars of John Ralston Saul There is a John Ralston SaulfondsatLibrary and Archives Canada.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/John_Ralston_Saul", "https://en.wikipedia.org/wiki/John_Ralston_Saul", "https://en.wikipedia.org/wiki/John_Ralston_Saul", "https://en.wikipedia.org/wiki/John_Ralston_(disambiguation)", "https://en.wikipedia.org/wiki/John_Saul_(disambiguation)", "https://en.wikipedia.org/wiki/Order_of_Canada", "https://en.wikipedia.org/wiki/Order_of_Ontario", "https://en.wikipedia.org/wiki/University_of_Alberta"]},
{"id": "a58d06c7e1bc", "url": "https://en.wikipedia.org/wiki/Islam21c", "title": "Islam21c", "headings": ["Contents", "History", "Topic structure", "References"], "content": " Islam21cis a British Muslim website established in 2006 under the influence ofHaitham al-Haddad. It provides commentary and analysis on religious, social, and political issues relevant to Muslims in the United Kingdom and the widerWesterncontext, presented in an orthodox and scholarly manner. The platform was founded in response to what it viewed as attempts by the British government to imposeBritish valueson Muslim communities. It operates as an independent initiative but is supported by theMuslim Research and Development Foundation. Its stated aim has been to provide a framework for a British Muslim identity rather than focusing on sectarian divisions. In addition to its publications, Islam21c has been involved in advocacy efforts, public campaigns, and protests concerning issues affecting Muslim communities in Britain. Islam21c was established in 2006 by a network associated with Haitham al-Haddad as a platform for Muslim perspectives in Britain, gradually evolving into an independent entity focused on religious and social commentary.In 2015, a government press release under Prime MinisterDavid Camerondescribed its Chief Editor, Salman Butt, as a 'hate preacher,' an accusation later revealed through a parliamentary question to be based on claims that the site hosted content contrary to 'British values.'Butt challenged this designation in court, and after six years of litigation, the UK government issued an apology.In 2024, the Civil Service Muslim Network cited Islam21c as a useful source in Ramadan guidance distributed acrossWhitehall, but the guidance was suspended by Deputy Prime MinisterOliver Dowdenfollowing criticism that events linked to the website had includedantisemitic tropes.Questions about ownership were raised byThe Daily Telegraph, prompting the Muslim Research and Development Foundation (MRDF) to clarify that it did not own or operate the site, despite earlier financial filings describing it as an 'endorsed project,' later revised to a 'supported project.'Butt has since explained that Islam21c operates independently from MRDF to maintain the freedom to engage in activities such as political advocacy, which registered charities are restricted from undertaking.In addition to commentary, Islam21c has been active in civic discussions, participating in government consultations on issues such asRelationship and Sex Education(RSE),homeschooling, and integration, while also organizing public debates—including one on theEU Referendum—and staging demonstrations in response to international crises such as the conflict in Aleppo in 2016. Founded partly in response to perceived efforts by the British government to promote 'British values' among Muslim communities, Islam21c functions as a platform for discussion and analysis of religious, social, and political issues from an orthodox perspective.While its coverage extends to international affairs and wider challenges facing Muslims in Western societies, the website places particular emphasis on issues affecting Muslims in the United Kingdom.Its content is primarily aimed at younger professionals and addresses the development of a distinct British Muslim identity, considering not only religious exclusion but also intersecting forms of marginalization, including racial, economic, and gender-based inequalities.The site has occasionally encouraged political engagement, suggesting that Muslims explore independent representation and participation in formal political processes to better understand governance and advocacy.Some observers, such as theNational Secular Society, have described certain content on the platform as 'hardline' and 'homophobic.'Islam21c has also been critical of the UK government'sPrevent programme, arguing that it may contribute to alienation among young people and increase vulnerability to radicalization.", "combined_text": "Islam21c Contents History Topic structure References  Islam21cis a British Muslim website established in 2006 under the influence ofHaitham al-Haddad. It provides commentary and analysis on religious, social, and political issues relevant to Muslims in the United Kingdom and the widerWesterncontext, presented in an orthodox and scholarly manner. The platform was founded in response to what it viewed as attempts by the British government to imposeBritish valueson Muslim communities. It operates as an independent initiative but is supported by theMuslim Research and Development Foundation. Its stated aim has been to provide a framework for a British Muslim identity rather than focusing on sectarian divisions. In addition to its publications, Islam21c has been involved in advocacy efforts, public campaigns, and protests concerning issues affecting Muslim communities in Britain. Islam21c was established in 2006 by a network associated with Haitham al-Haddad as a platform for Muslim perspectives in Britain, gradually evolving into an independent entity focused on religious and social commentary.In 2015, a government press release under Prime MinisterDavid Camerondescribed its Chief Editor, Salman Butt, as a 'hate preacher,' an accusation later revealed through a parliamentary question to be based on claims that the site hosted content contrary to 'British values.'Butt challenged this designation in court, and after six years of litigation, the UK government issued an apology.In 2024, the Civil Service Muslim Network cited Islam21c as a useful source in Ramadan guidance distributed acrossWhitehall, but the guidance was suspended by Deputy Prime MinisterOliver Dowdenfollowing criticism that events linked to the website had includedantisemitic tropes.Questions about ownership were raised byThe Daily Telegraph, prompting the Muslim Research and Development Foundation (MRDF) to clarify that it did not own or operate the site, despite earlier financial filings describing it as an 'endorsed project,' later revised to a 'supported project.'Butt has since explained that Islam21c operates independently from MRDF to maintain the freedom to engage in activities such as political advocacy, which registered charities are restricted from undertaking.In addition to commentary, Islam21c has been active in civic discussions, participating in government consultations on issues such asRelationship and Sex Education(RSE),homeschooling, and integration, while also organizing public debates—including one on theEU Referendum—and staging demonstrations in response to international crises such as the conflict in Aleppo in 2016. Founded partly in response to perceived efforts by the British government to promote 'British values' among Muslim communities, Islam21c functions as a platform for discussion and analysis of religious, social, and political issues from an orthodox perspective.While its coverage extends to international affairs and wider challenges facing Muslims in Western societies, the website places particular emphasis on issues affecting Muslims in the United Kingdom.Its content is primarily aimed at younger professionals and addresses the development of a distinct British Muslim identity, considering not only religious exclusion but also intersecting forms of marginalization, including racial, economic, and gender-based inequalities.The site has occasionally encouraged political engagement, suggesting that Muslims explore independent representation and participation in formal political processes to better understand governance and advocacy.Some observers, such as theNational Secular Society, have described certain content on the platform as 'hardline' and 'homophobic.'Islam21c has also been critical of the UK government'sPrevent programme, arguing that it may contribute to alienation among young people and increase vulnerability to radicalization.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Islam21c", "https://en.wikipedia.org/wiki/Islam21c", "https://en.wikipedia.org/wiki/Islam21c", "https://en.wikipedia.org/wiki/Community_media", "https://en.wikipedia.org/wiki/Haitham_al-Haddad", "https://en.wikipedia.org/wiki/Haitham_al-Haddad", "https://en.wikipedia.org/wiki/Western_world", "https://en.wikipedia.org/wiki/British_national_identity"]},
{"id": "46029b43672b", "url": "https://en.wikipedia.org/wiki/List_of_student_newspapers_in_the_United_Kingdom", "title": "List of student newspapers in the United Kingdom", "headings": ["Contents", "National", "England", "Northern Ireland", "Scotland", "Wales", "References", "See also"], "content": " This is a list of notable student newspapers in the United Kingdom.", "combined_text": "List of student newspapers in the United Kingdom Contents National England Northern Ireland Scotland Wales References See also  This is a list of notable student newspapers in the United Kingdom.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/List_of_student_newspapers_in_the_United_Kingdom", "https://en.wikipedia.org/wiki/List_of_student_newspapers_in_the_United_Kingdom", "https://en.wikipedia.org/wiki/List_of_student_newspapers_in_the_United_Kingdom", "https://en.wikipedia.org/wiki/Affairs_Today", "https://en.wikipedia.org/wiki/The_Gateway_(student_newspaper)", "https://en.wikipedia.org/wiki/The_National_Student", "https://en.wikipedia.org/wiki/The_Student_Journals", "https://en.wikipedia.org/wiki/Student_Times_(UK_paper)"]},
{"id": "6468227638d7", "url": "https://en.wikipedia.org/wiki/Middle_voice", "title": "Voice (grammar)", "headings": ["Contents", "Overview", "History of the concept of voice", "Voice contrasts", "Voices in topic-prominent languages", "Chinese", "Japanese", "Santali", "Impersonal passive voice", "Finnic languages", "Celtic languages", "Dynamic and static passive", "German", "English", "Swedish", "Spanish", "Italian", "Venetian", "List of voices", "See also", "Notes", "References"], "content": "Ingrammar, thevoice(ordiathesis) of a verb describes the relationship between the action (or state) that the verb expresses and the participants identified by itsarguments(subject, object, etc.).When thesubjectis the agent or doer of the action, the verb is in theactive voice. When the subject is the patient, target or undergoer of the action, the verb is said to be in thepassive voice.When the subject both performs and receives the action expressed by the verb, the verb is in the middle voice. The following pair of examples illustrates the contrast between active and passive voice in English. In sentence (1), the verb formateis in the active voice, but in sentence (2), the verb formwas eatenis in the passive voice. Independent of voice,the catis the Agent (the doer) of the action of eating in both sentences. In atransformationfrom an active-voiceclauseto an equivalent passive-voice construction, the subject and thedirect objectswitch grammatical roles. The direct object getspromotedto subject, and the subjectdemotedto an (optional)adjunct. In the first example above,the mouseserves as the direct object in the active-voice version, but becomes the subject in the passive version. The subject of the active-voice version,the cat, becomes part of a prepositional phrase in the passive version of the sentence, and can be left out entirely;The mouse was eaten. In the grammar of Ancient Greek, voice was calledδιάθεσιςdiáthesis'arrangement'or'condition', with three subcategories: In Latin, two voices were recognized: The active voice is the most commonly used in many languages and represents the \"normal\" case, in which the subject of the verb is the agent. In the active voice, the subject of the sentence performs the action or causes the happening denoted by the verb. Sentence (1) is in active voice, as indicated by the verb formsaw. (1)Roger Bigod saw the castles.  The passive voice is employed in a clause whosesubjectexpresses thethemeorpatientof the verb. That is, it undergoes an action or has its state changed.In the passive voice, the grammatical subject of the verb is the recipient (not the doer) of the action denoted by the verb. In English it serves a variety of functions including focusing on the object, demoting the subject and handling situations where the speaker either wants to suppress information about who the doer of the action is, or in reality does not know their identity, or when the doer is either unimportant or likely to becommon knowledge. There are syntactic, semantic, and pragmatic motivations for choosing the passive voice instead of the active.Some languages, such asEnglishandSpanish, use aperiphrasticpassive voice; that is, it is not a single word form, but rather a construction making use of other word forms. Specifically, it is made up of a form of theauxiliary verbto beand a pastparticipleof the main verb which carries the lexical content of the predicate. In other languages, such asLatin, the passive voice for some tenses is simply marked on the verb byinflection:librum legit\"He reads the book\";liber legitur\"The book is read\". Passives mark this voice in English syntactically as well, which often involves subject–object inversion and the use of 'by'. Sentence (2) is an example of passive voice, where something (the castles) has been (notionally) acted upon by someone (Roger Bigod). (2)The castles were seen by Roger Bigod. The antipassive voice deletes or demotes the object of transitive verbs, and promotes the actor to an intransitive subject. This voice is very common amongergative–absolutive languages(which may feature passive voices as well), but also occurs amongnominative–accusative languages.  Some languages (such asAlbanian,Bengali,Fula,Tamil,Sanskrit,Icelandic,SwedishandAncient Greek) have amiddle voice, which is a set of inflections or constructions which is to some extent different from both the active and passive voices. The subject of such middle voice is like the subject of active voice as well as the subject of passive voice, in that it performs an action, and is also affected by that action.Another difference between middle voice and the other two grammatical voices is that there are middle marked verbs for which no corresponding active verb form exists.In some cases, the middle voice is any grammatical option where the subject of a material process cannot be categorized as either an actor (someone doing something) or a goal (that at which the actor aims their work). For example, while the passive voice expresses a medium (goal) being affected by an external agent (actor) as in sentence (4), the middle voice expresses a medium undergoing change without any external agent as in sentence (5). In English, though the inflection  for middle voice and active voice are the same for these cases, they differ in whether or not they permit the expression of the Agent argument in an oblique by-phrase PP: thus while the by-phrase is possible with passive voice as in sentence (6), it is not possible with middle voice, as shown by the ill-formed sentence (7). (4)The casserole was cooked in the oven(passive voice) (5)The casserole cooked in the oven(middle voice) (6)The casserole was cooked in the oven by Lucy(passive voice) (7) *The casserole cooked in the oven by Lucy(by-phrase ungrammatical when used with middle voice; asterisk (*) indicates ungrammaticality) In ClassicalGreek, the middle voice is often used for material processes where the subject is both the actor (the one doing the action) and the medium (that which is undergoing change) as in \"the man got a shave\", opposing both active and passive voices where the medium is the goal as in \"The barber shaved the man\" and \"The man got shaved by the barber\". Finally, it can occasionally be used in a causative sense, such as \"The father causes his son to be set free\", or \"The father ransoms his son\". In English, there is no verb form for the middle voice, though some uses may be classified by traditional grammarians as middle voice, often resolved via areflexive pronoun, as in \"Fred shaved\", which may be expanded to \"Fred shaved himself\" – contrast with active \"Fred shaved John\" or passive \"John was shaved by Fred\". This need not be reflexive, as in \"My clothes soaked in detergent overnight.\". In English, it is impossible to tell from the morphology whether the verb in Sentence (8) is an active voice unaccusative verb or a middle voice anticausative verb with active morphology.Since middle voice reflexives and dispositional middles are found in English with active morphology by looking at Sentence (9), it can be assumed that at least some middle voice anticausatives with active morphology exist as well. (8)The window broke from the pressure/by itself. (9)This book sells well. English used to have a distinct form, called thepassival, which was displaced over the early 19th century by the progressive passive and is no longer used in modern English.In the passival, one might say \"The house is building.\", which may today be rendered instead as \"The house is being built.\" Likewise \"The meal is eating.\", which is now \"The meal is being eaten.\" The similar \"Fred is shaving\" and \"The meal is cooking\" remain grammatical. It is suggested that the progressive passive was popularized by theRomantic poets, and is connected withBristolusage. Manydeponent verbsinLatin(i.e., verbs passive in form but active in meaning) are descendants of theProto-Indo-Europeanmiddle voice. Some languages have even more grammatical voices. For example,Classical Mongolianfeatures five voices: active, passive, causative, reciprocal, and cooperative. There are also constructions in some languages that appear to change thevalenceof a verb, but in fact do not. So called hierarchical orinversionlanguages are of this sort. Their agreement system will be sensitive to an external person or animacy hierarchy (or a combination of both): 1 > 2 > 3 or Anim > Inan and so forth. E.g., inMeskwaki(an Algonquian language), verbs inflect for both subject and object, but agreement markers do not have inherent values for these. Rather, a third marker, the direct or inverse marker, indicates the proper interpretation: ne- 1- wa:pam look.at -e: -DIR -w -3 -a -3.SG ne- wa:pam -e: -w -a 1- look.at -DIR-3 -3.SG \"I am looking at him.\" ne- 1- wa:pam look.at -ekw -INV -w -3 -a -3.SG ne- wa:pam -ekw -w -a 1- look.at -INV -3 -3.SG \"He is looking at me.\" Some scholars (notably Rhodes) have analyzed this as a kind of obligatory passivization dependent on animacy, while others have claimed it is not a voice at all, but rather see inversion as another type of alignment, parallel tonominative–accusative,ergative–absolutive,split-S, andfluid-Salignments. In general, the grammar of standard Chinese (both including Mandarin and Cantonese) shares many features with other varieties of Chinese. However, there are still some differences between the different varieties. Mandarin active voice sentences have the same verb phrase structure as English active voice sentences.\nThere is a common active construction in Mandarin called Ba(把) construction: “Ba” is acoverb, not a preposition. It is a three-place predicate that subcategorizes for a subject, an object, and a VP complement. 他 ta He 把 ba ACT 橘子 juzi orange 剥了 bo-le peeled-PRF 皮。 pi. peel 他 把 橘子 剥了 皮。 ta ba juzi bo-le pi. He ACT orange peeled-PRF peel 'He peeled the orange skin. ' This Ba construction is also a direct opposition of active voice in passive voice in Mandarin (i.e. Ba construction (= active voice) vs. Bei construction (= passive voice)). The following sentence b) is in contrast to sentence a). 橘子 Juzi Orange 被 bei PASS （他） (ta) (he) 剥了 bo-le peeled-PRF 皮。 pi. peel 橘子 被 （他） 剥了 皮。 Juzi bei (ta) bo-le pi. Orange PASS (he) peeled-PRF peel 'The orange was peeled (by him).' (Both a) and b) are adapted from Her, O. (2009)) Topic-prominent languageslikeMandarintend not to employ the passive voice as frequently.  In general, Mandarin used to be best analyzed using middle voice, but Mandarin-speakers can construct a passive voice by using the coverb被(bèi) and rearranging the usual word order.For example, this sentence using active voice: (The first line is in Traditional Chinese while the second is Simplified Chinese) 一條 一条 Yī-tiáo Α 狗 狗 gǒu dog 咬了 咬了 yǎo-le bite-PRF 這個 这个 zhège this 男人。 男人。 nánrén. man 一條 狗 咬了 這個 男人。 一条 狗 咬了 这个 男人。 Yī-tiáo gǒu yǎo-le zhège nánrén. Α dog bite-PRF this man \"A dog has bitten this man.\" corresponds to the following sentence using passive voice. The agent phrase is optional. 這個 这个 Zhège This 男人 男人 nánrén man 被 被 bèi PASS (狗) (狗) (gǒu) (dog) 咬了。 咬了。 yǎo-le. bite-PRF 這個 男人 被 (狗) 咬了。 这个 男人 被 (狗) 咬了。 Zhège nánrén bèi (gǒu) yǎo-le. This man PASS (dog) bite-PRF \"This man has been bitten (by a dog).\" In addition, through the addition of the auxiliary verb \"to be\"是(shì) the passive voice is frequently used to emphasize the identity of the actor. This example places emphasis on thedog, presumably as opposed to some other animal: 這個 这个 Zhège This 男人 男人 nánrén man 是 是 shì to be 被 被 bèi PASS 狗 狗 gǒu dog 咬 咬 yǎo bite 的。 的。 de. (suffix) 這個 男人 是 被 狗 咬 的。 这个 男人 是 被 狗 咬 的。 Zhège nánrén shì bèi gǒu yǎo de. This man {to be} PASS dog bite {(suffix)} \"This man has been bitten by adog.\" Mandarin also has anobject-retaining passivewhich contains both the object and the topic (mostly the possessor of the object): 他 他 tā He 被 被 bèi PASS 小偷 小偷 xiǎotou thief 偷了 偷了 tōu-le steal-PRF 錢包。 钱包。 qiánbāo. wallet 他 被 小偷 偷了 錢包。 他 被 小偷 偷了 钱包。 tā bèi xiǎotou tōu-le qiánbāo. He PASS thief steal-PRF wallet \"His wallet was stolen by a thief.\" 被 (bèi) as a passive marker is a relatively new addition to the language, introduced as part of the early 20th century language reforms that also added gender-specific pronouns such as 他>她 and 你>妳 and culminated in attempts to Romanize Chinese entirely. There is a  typical passive construction in Mandarin, namely Bei construction.  It is commonly used to indicate result, direction, location, frequency, duration, manner, and appearance.Similar to English, Bei construction can also be analysed by A-movement which is locally restricted. The subject of the Bei clause is included in the complement clause where the “passivized” object controls the verb.Classically, 被 marked an adversative mood, indicating that something bad had happened.  Even today, the following sentence is perfectly acceptable in speech: 蛋糕 蛋糕 dangao cake 吃了。 吃了。 chi-le. eat-PRF 蛋糕 吃了。 蛋糕 吃了。 dangao chi-le. cake eat-PRF \"The cake was eaten.\" Recent development ofbèiconstruction Recently, more syntacticians investigated passive voice in Mandarin. They discovered that passive voice in Mandarin is heavily dependent on the context of the sentence rather than the grammatical forms.Therefore, passive voice can be marked (e.g. by the most broadly used passive marker:bèi被 [mentioned above]) or unmarked (see the \"Notional passive\" section below) in both speech and writing. Those sentences have a passive marker called the long passive, while the ones that do not require a passive marker are called short passive. Here are examples for long passive and short passive: 张三 Zhangsan Zhangsan 被 bei PASS 李四 Lisi Lisi 打 da hit 了。 le. PRF 张三 被 李四 打 了。 Zhangsan bei Lisi da le. Zhangsan PASS Lisi hit PRF 'Zhangsan was hit by Lisi.' 张三 Zhangsan Zhangsan 被 bei PASS 打 da hit 了。 le. PRF 张三 被 打 了。 Zhangsan bei da le. Zhangsan PASS hit PRF 'Zhangsan was hit ∅.' (Both examples are adapted from Huang, C. J., & Liu, N. (2014)) We can see from the examples above, the difference between long passive and short passive depends on whether the agent phrase is presented or not. Bei construction was not often used in Old Chinese, but it is widely used in Modern Chinese. The appearance of Bei construction marks that Modern Chinese is undergoing a new cycle of change. Old Chinese was considerably synthetic and has been gradually changed to analyticity. Later its development peaked during Tang-Song Dynasties. Nowadays, in Modern Chinese, it is mainly analytic but also shows forward tendency toward synthesis.Here are some recent theories that syntacticians have proposed. Ting (1998) proposed that Bei is acting as a verb and it is widely accepted so far. Ting stated that Bei construction is not used uniformly in all passive contexts in Mandarin. Rather, three types of Bei-sentences must be introduced. The main distinction is discovered in A-movement and lexical passive compound verb. To some extent, his theory was also supported by Yip et al. (2016), where they also proposed three different forms of passive Mandarin. Ting's claims were based on his investigation of post-verbal overt pronominal object, locality of selection, occurrence of the particle suo(所) in Bei construction, and the intervention of adverbs within the Bei-V compound (= co-verb). He believed that Bei construction is presented in three types, two of them have different selectional properties, and the other one is lexically derived as Bei-V compound. Here is an example of showing a sentence having different selectional properties in its subject and object: 李四 Lisi Lisi 被 bei PASS 张三 Zhangsan Zhangsan 派 pai sent 我 wo I 抓走了。 zhua-zou-le. catch-PRF. 李四 被 张三 派 我 抓走了。 Lisi bei Zhangsan pai wo zhua-zou-le. Lisi PASS Zhangsan sent I catch-PRF. 'Lisi (was)affected(by) Zhangsan's sending me (to)catch(him).' [Lisi1bei Zhangsan pai wo2[CP [TP PRO2zhua-zou-le [e]1]]] (This example is adapted from Ting, J. (1998)) Huang and Liu (2014) argued that Bei construction is not a special construction that involves the passivization of intransitive verbs. They believe that what is passivized isn't the VP itself (in Bei-VP construction), but actually a null light verb with a causative, putative or activity predicate that takes VP as its complement or adjunct. In their analysis, VP part in Bei-VP construction acquires its categorical feature by an agreement relation with a category-creating light verb, and it serves as the complement or adjunct of that light verb. What makes it different from other constructions is that it doesn't have grammatical active sources (null light verb constructions are abundant in Old Chinese).The head of this construction is a null light verb with the semantics of CAUSE and DO, referring to several causative or executive events. Huang and Liu's theory of Bei construction can explain the usage of Bei in both Modern Chinese and Old Chinese. According to Yip et al. (2016), there are three forms in passive voice depending on the tone and emphasis. They are notional passive, formal passive, and lexical passive. No formal passive marker is needed and carries an expository tone. It is the most common form of passive voice in Mandarin and is extremely colloquial. Passive marker is excluded in notional passive because the sentence relies on the hearer's common sense or their knowledge of the world. Thus, this passive voice is expressed implicitly. Furthermore, notional passive sentences can be representing either positive or negative meanings. Here is an example of notional passive: 问题 Wenti Problem 解决 jiejue solve 了。 le. PRF. 问题 解决 了。 Wenti jiejue le. Problem solve PRF. 'Problem (has)been solved.' In other voices in Mandarin, “object + transitive verb” construction is usually used. However, “topic + explanatory comment” is the common structure for notional passive. There is no surface passive marker in the sentence, but the underlying meaning does carry a passive voice. The negation of notional passive is similar to English negation. Both are achieved by adding the negator “mei(you)没(有)” right before the transitive verb. In fact, in negation, “le” is no longer necessary in the sentence. Here is an example of negation of notional passive: 问题 Wenti Problem 还 hai still 没 mei not 解决。 jiejue. solve. 问题 还 没 解决。 Wenti hai mei jiejue. Problem still not solve. 'Problem (has)not(yet) been solved.' (Both examples are adapted from Yip et al. (2016), Chapter 13) Most objects present in notional passive are inanimate objects because ambiguity can arise if we use animate objects in these sentences. To avoid this problem, formal or lexical passive markers will be introduced in the sentence. A formal passive marker is introduced as \"bei\" and it is usually in narrative tone. It is generally used as the narration or description of an event that has already taken place. Additionally, formal passive sentences can only represent negative meanings, otherwise it is ungrammatical. It can be used in both informal and formal contexts. Here is an example of formal passive: 问题 Wenti Problem 终 zhong finally 被 bei PASS 解决。 jiejue. solve. 问题 终 被 解决。 Wenti zhong bei jiejue. Problem finally PASS solve. 'Problem was finally solved.' (Example is adapted from Yip et al. (2016), Chapter 13) There is a striking feature of formal passive which makes it different from other forms of passives. The formal passive is presented as including “bei” as a co-verb in sentence and acting as a formal passive marker. “Bei” indicates the subject of the sentence is the action receiver. The initiator of this action is usually presented after “bei”. But this initiator could be overt (unstated), covert (revealed), or vague. Here is some examples of showing different identities in initiators: 那个 nage That 警察 jingcha policeman 被 bei PASS 打伤了。 dashang-le. hit-wounded-PRF 那个 警察 被 打伤了。 nage jingcha bei dashang-le. That policeman PASS hit-wounded-PRF 'That policeman was wounded.' 那个 nage That 警察 jingcha policeman 被 bei PASS 人 ren somebody 打伤了。 dashang-le. hit-wounded-PRF 那个 警察 被 人 打伤了。 nage jingcha bei ren dashang-le. That policeman PASS somebody hit-wounded-PRF 'That policeman was wounded (by-somebody).' 那个 nage That 警察 jingcha policeman 被 bei PASS 流氓 liumang hooligan 打伤了。 dashang-le. hit-wounded-PRF 那个 警察 被 流氓 打伤了。 nage jingcha bei liumang dashang-le. That policeman PASS hooligan hit-wounded-PRF 'That policeman was wounded (by-hooligans).' (These are adapted from Yip et al. (2016) Chapter 13, p. 253) Although the most common formal passive marker is “bei”, it can also be replaced by rang让, jiao教, gei给, etc. The identity of the initiator is either overt or vague. “Bei” cannot be used in imperatives, but other formal passive markers can be used in colloquialism. No formal passive marker is present, but the passive voice is introduced by a verb that indicates the subject as the receiver of the action, then the verb is followed by an object. The literary meaning is quite similar to English inverted sentences. It is usually a formal tone. Common indicators are a set of verbs, like dedao得到, shoudao受到, zaodao遭到 (the three most common verbs used in lexical passive), etc. Here is an example of lexical passive: 问题 Wenti Problem 得到 dedao receive 了 le PRF 解决。 jiejue. solution. 问题 得到 了 解决。 Wenti dedao le jiejue. Problem receive PRF solution. 'Solution (was)found for problem.' (Example is adapted from Yip et al. (2016), Chapter 13) The syntactic structure of lexical passive is SVO: The semantic formula: receiver + verb + initiator + nominalised verb. (No additional complement to the nominalised verb is allowed.) In nominal and formal passives, the focus is on the outcome of the action, but for lexical passive, the focus has shifted to emphasize the degree of the action that has been carried out. In other words, the focus is on the initiator and nominalised verb. In general, Chinese employs middle voice.There are still ongoing discussions about where there is a distinct class for middle voice verbs. \nChao believes that ergative (= middle voice) verb is a distinct syntactic verb category. In other words, it isn't purely transitive or intransitive. However, Li et al. (1981), when arguing against Chao's analysis of Mandarin, stated that there is a distinct class of middle voice verbs. They recognize that Mandarin (and Cantonese) verbs as a whole behave the same way. Later, Li et al. (1981) introduced middle voice sentences as examples of topic/comment constructions which lacks an overt subject. Here is an example: 饭 fan Rice 煮焦 zhujiao cook(burnt) 了 le PRF 一点。 yidian. (a)bit. 饭 煮焦 了 一点。 fan zhujiao le yidian. Rice cook(burnt) PRF (a)bit. 'The rice (∅)burnt (a)bit.' (Adapted from Li et al. (1981)) We can see from this example that the characteristic of a topic/comment construction in its implication of a dropped anaphor indicates an agent. While Ting (2006) compared between middles and Ba constructions (= active voice) involving intransitive  V-de (得) resultatives. He also did comparison between middles and inchoatives. He argues that we can treat notional passives in Mandarin as middle constructions. Its underlying grammatical subject position and lack of a syntactically active logical subject are best explained by a presyntactic approach. But, semantically, Chinese middle voice may be interpreted like stative or verbal passives. Here are two examples: *那本 naben That 书 shu book 很 hen very 喜欢。 xihuan. like. *那本 书 很 喜欢。 naben shu hen xihuan. That book very like. 'That book is liked.' 那本 naben That 书 shu book 喜欢得 xihuan-de like-de 要命。 yaoming. dying. 那本 书 喜欢得 要命。 naben shu xihuan-de yaoming. That book like-de dying. 'That book is (extremely)liked.' (Both examples are adapted from Ting (2006)) Ting argues that sentence a) is ungrammatical and indistinguishable from ergatives, and that sentence b) is grammatical and he believes that it must have used middle voice due to their function of defocusing an agent subject. Although Bei construction in passive voice can achieve the same purpose, there is a possibility that associating with Bei construction may be inappropriate in many contexts. Thus, using middle voice is better in this case. Due to the ongoing discussion, we still don't have a uniformed theory in middle voice in Mandarin. InCantonese, those features are quite similar by using thecoverb俾(bei), but the agent phrase is NOT optional, often with a formal agent人(jan): 個 Go The 男人 naamjan man 俾 bei PASS 狗 gau dog 咬咗喇。 ngaau-zo-laa bite-PFV-PRF 個 男人 俾 狗 咬咗喇。 Go3 naam4jan4 bei2 gau2 ngaau5-zo2-laa3 The man PASS dog bite-PFV-PRF \"The man has been bitten by a dog.\" 佢 Keoi 3SG 俾 bei PASS 人 jan someone 食咗喇。 sik-zo-laa eat-PFV-PRF 佢 俾 人 食咗喇。 Keoi5 bei2 jan4 sik6-zo2-laa3 3SG PASS someone eat-PFV-PRF \"He/She/It has been eaten (by someone).\" However, in some dialects ofYue, a passive voice with an optional agent phrase is also available: Qinzhou (Qin-Lian Yue): 佢 Ki 3SG 著 zoek PASS 打喇。 daa-laa beat-PRF 佢 著 打喇。 Ki3 zoek6 daa2-laa3 3SG PASS beat-PRF \"He/She/It has been beaten.\" In the actor-emphasizing passive voice of Cantonese, besides the addition of the auxiliary verb \"to be\"係(hai), theperfectiveevent is also converted to an adjective-like predicative with the suffix嘅(ge) or㗎(gaa), which is a more emphasized one from the liaison of嘅(ge) and啊(aa): 個 Go The 男人 naamjan man 係 hai to be 俾 bei PASS 狗 gau dog 咬 ngaau bite 嘅。 ge (suffix) 個 男人 係 俾 狗 咬 嘅。 Go3 naam4jan4 hai6 bei2 gau2 ngaau5 ge3 The man {to be} PASS dog bite {(suffix)} \"The man was bitten by adog.\" Grammatical voice in Japanese only contains an active and passive voice and does not have a middle voice. Active voice in Japanese is the direct opposition of direct passive voice in Japanese. This is similar to English which also has corresponding active and passive sentences. This is an example of a corresponding active voice and direct passive voice sentence. Active Voice Naomi Naomi ga NOM Ken Ken o ACC nagut-ta. hit-PST. Naomi ga Ken o nagut-ta. Naomi NOM Ken ACC hit-PST. Naomi hit Ken. Direct Passive Ken Ken ga NOM Naomi Naomi ni DAT nagur-are-ta. hit-PASS-PST. Ken ga Naomi ni nagur-are-ta. Ken NOM Naomi DAT hit-PASS-PST. Ken was hit by Naomi. (Both examples are adapted from Shibatani et al. (2017)) Word order in Japanese is more flexible so active voice sentences  can be both SOV (subject + object + verb) and OSV (object + subject + verb) order; however, SOV is typically used more often. Active SOV sentence example: ボート bōto boat が -ga -NOM 漁師 ryōshi fisherman を -o -ACC 運んだ。 hakonda. carried-ACT. ボート が 漁師 を 運んだ。 bōto -ga ryōshi -o hakonda. boat -NOM fisherman -ACC carried-ACT. 'The boat carried the fisherman.' Active OSV sentence example 漁師 ryōshi fisherman を -o -ACC ボート bōto boat が -ga -NOM 運んだ。 hakonda. carried-ACT. 漁師 を ボート が 運んだ。 ryōshi -o bōto -ga hakonda. fisherman -ACC boat -NOM carried-ACT. 'The fisherman, the boat carried.' (Both examples are adapted from Tanaka et al. (2011)) Although a topic-prominent language,Japaneseemploys the passive voice quite frequently, and has two types of passive voice, direct voice which corresponds to that in English and an indirect passive which is not found in English. The passive voice in Japanese is constructed with the verb stem followed by the passive morpheme -(r)are. This synthetic passive morpheme can attach to transitive, ditransitive and some intransitive verbs.The word order in Japanese is more flexible so passive sentences can be both SOV (subject + object + verb) and OSV (object + subject + verb) order; however, SOV is typically used more often.Furthermore, there are two theories about passive voice in Japanese called the uniform and non-uniform theory.These two theories debate whether direct and indirect passives should be treated equally or if they should be treated differently. Examples of passive voice in Japanese: 彼 Kare He は wa TOPIC 泥棒 dorobō thief に ni AGENT 財布 saifu wallet を o OBJECT 盗まれた。 nusumareta. steal-PASSIVE-PAST 彼 は 泥棒 に 財布 を 盗まれた。 Kare wa dorobō ni saifu o nusumareta. He TOPIC thief AGENT wallet OBJECT steal-PASSIVE-PAST \"He got his wallet stolen by a thief.\" 僕 Boku I は wa TOPIC 彼女 kanojo her に ni AGENT 嘘 uso lie を o OBJECT つかれた。 tsukareta. tell-PASSIVE-PAST. 僕 は 彼女 に 嘘 を つかれた。 Boku wa kanojo ni uso o tsukareta. I TOPIC her AGENT lie OBJECT tell-PASSIVE-PAST. \"I was told a lie by her.\" (= \"She lied to me.\") Japanese direct passives have corresponding active sentences which is similar to English passives in that the logical object appears as the grammatical subject. Direct passive examples: Ken Ken ga NOM Naomi Naomi ni DAT nagur-are-ta. hit-PASS-PST. Ken ga Naomi ni nagur-are-ta. Ken NOM Naomi DAT hit-PASS-PST. 'Ken was hit by Naomi.' Ken Ken ga NOM Naomi Naomi ni DAT home-rare-ta. praise-PASS-PST. Ken ga Naomi ni home-rare-ta. Ken NOM Naomi DAT praise-PASS-PST. 'Ken was praised by Naomi.' Yōko Yoko wa TOP Hiroshi Hiroshi ni DAT yasashiku gently nagusame console.IRR -rare AUX/PASS -ta. PST. Yōko wa Hiroshi ni yasashiku nagusame -rare -ta. Yoko TOP Hiroshi DAT gently console.IRR AUX/PASS PST. 'Yoko was gently consoled by Hiroshi.' (Examples are adapted from Shibatani et al. (2017)) In all 3 examples the auxiliary verb (ra)reru is used as a suffix to the active forms of the verb to show the meaning of the direct passive. Indirect passives have two varieties, possessive passives and gapless passives. In possessive passives, the grammatical subject stands in a canonical possessive relation with the direct object and in gapless passives they appear to lack an active counterpart and contain an extra argument is realized as the grammatical subject that is unlicensed by the main verb. Indirect passives can also be used when something undesirable happens to the speaker. Indirect (possessive) passive The subject in possessive passives is in a canonical possessive relation such as kinship, ownership, etc. with the direct object. Ken Ken ga NOM sensei teacher ni DAT musuko son o ACC shikar-are-ta. scold-PASS-PST. Ken ga sensei ni musuko o shikar-are-ta. Ken NOM teacher DAT son ACC scold-PASS-PST. lit. 'Ken was scolded his son by the teacher.' (cf. Ken's son was scolded.) (This example was adapted from Shibatani et al. (2017)) In this example of a possessive passive there is a kinship relation between the grammatical subject which is 'Ken' and the direct object which is the 'musuko' (son). Indirect (gapless) passive Gapless passives unlike possessive passives lack an active counterpart and contain an extra argument that is unlicensed by the main verb. The extra argument is also realized as the grammatical subject. Ken Ken ga NOM Naomi Naomi ni DAT nige-rare-ta. escape-PASS-PST. Ken ga Naomi ni nige-rare-ta. Ken NOM Naomi DAT escape-PASS-PST. lit. 'Ken was escaped from by Naomi.' (cf. Naomi escaped [from Ken].) (Both examples are adapted from Shibatani et al. (2017)) Ni-yotte passives are another type of Japanese passive that contrasts direct and indirect passives which contain a dative ni-phrase. They are similar to direct passives but the instead of the logical subject being realized as a ni-phrase it is realized as a ni-yotte phrase. Ni-yotte passive examples: Kabin vase ga NOM (Ken Ken ni-yotte) DAT-owing kowas-are-ta. break-PASS-PST. Kabin ga (Ken ni-yotte) kowas-are-ta. vase NOM Ken DAT-owing break-PASS-PST. 'The vase was broken (by means of Ken).' Jūtai traffic.jam wa TOP jiko accident ni-yotte DAT-owing oki-ta. occur-PST. Jūtai wa jiko ni-yotte oki-ta. traffic.jam TOP accident DAT-owing occur-PST. 'The traffic jam occurred due to an accident.' (This example is adapted from Shibatani et al. (2017)) In addition, as seen in example 2)ni-yottecan also be used more generally to introduce a cause. This because the-yotteinni-yotteis a form of the verbyor-uwhich means 'owe'. Unlike indirect and direct passive with ni-phrases, ni-yotte\nphrases are not indigenous to Japanese and were created as a way to translate modern Dutch texts because direct translations did not exist. The uniform theory was developed by Kuroda (1965, 1979, 1983) and Howard and Niyejawa-Howard (1976). This theory argues that both direct and indirect passives in Japanese should be treated as the same. In this theory both direct and indirect passives are derived from the same complementation structure with optional control. There is the assumption that the-(r)aremorpheme in direct passives are the same as the ones used in indirect passives meaning that they both have an underlying structure containing the passive morpheme-(r)are. A problem with this theory is that other similar languages such as Korean and Chinese have possessive and direct passives but do not have indirect passives which indicates that possessive passives appear to behave as a natural class from a typological perspective. However, this theory is preferred over the non-uniform theory because the morpheme-(r)arebeing spelled the same for both direct and indirect passives is an unsustainable coincidence. 1) Direct passive Paul-wa Paul-FOC George-ni George-to wagamama selfish dato as hinans-are-ta criticise-PASS-PST Paul-wa George-ni wagamama dato hinans-are-ta Paul-FOC George-to selfish as criticise-PASS-PST 'Paul was criticised for being selfish by George.' Internal direct passive sentence: [Paul ga [George ga Paul wo wagamama dato hinansuru] are ta] 2) Indirect passive Paul-wa Paul-FOC John-ni John-to shin-are-ta die-PASS-PST Paul-wa John-ni shin-are-ta Paul-FOC John-to die-PASS-PST 'Paul was adversely affected by John's death.' Internal indirect passive sentence: [Paul ga [George ga Paul o wagamama dato hinansuru] are ta] (These example is adapted from Toyota (2011). In these examples we can see that the passive morpheme-(r)areis outside of the embedded sentence which shows that-(r)areis part of the underlying structure for both direct and indirect passives. The non-uniform theory has primarily been examined by McCrawley (1976) and Kuno (1973, 1978). The non-uniform theory argues that direct and indirect passives in Japanese are distinct and should be treated differently. This theory hypothesizes that direct and indirect passives have separate underlying structures which are distinct from each other. Direct passives are derived from the transitive underlying structure and do not contain the passive morpheme-(r)arein its underlying structure while the indirect passive does contain-(r)arein its underlying structure.The non-uniform theory argues that direct and indirect passives in Japanese should be treated differently.This theory is criticized by proponents of the uniform theory because the morpheme-(r)areis spelled the same for both direct and indirect passives, and this, they claim, is difficult to pass off as just a coincidence. 1) Direct Passive George-ga George-TOP gitā-o guitar-ACC hik-u play-PRS George-ga gitā-o hik-u George-TOP guitar-ACC play-PRS 'George plays the guitar.' In non-uniform theory-(r)areis not contained within the underlying structure so in this sentence is the result of a subject object shift. 2) Indirect Passive Gitā-ga guitar-TOP George-ni George-by.means. yotte of hik-are-ru play-PASS-PRS Gitā-ga George-ni yotte hik-are-ru guitar-TOP George-by.means. of play-PASS-PRS 'The guitar is played by George.' For indirect passive sentences-(r)areis contained within the underlying structure\n(This example is adapted from Toyota (2011). Santaliand allMunda languagesof theAustroasiatic phylumin general are notoriously messy for their fusion of TAMs and verb stems with the active and middle voices. In the perfective series of Santali, the active suffixes distinguish themselves from the middle suffixes with a final checked consonantˀtthat is conditioned to several morphophonological changes. The active agent of a polyvalent predicate can be passivized by using several stem augments such as-uʔ~oʔin stem alternations or to mark its predicate as middle voice in the imperfective series. 1). Aorist active dal-ke-d-a=ɲ beat-ACT.AOR-TR-FIN=1 dal-ke-d-a=ɲ beat-ACT.AOR-TR-FIN=1 'I beat.' 2). Aorist active with object dal-ke-d-e-a=ɲ beat-ACT.AOR-TR-3-FIN=1 dal-ke-d-e-a=ɲ beat-ACT.AOR-TR-3-FIN=1 'I beat him.' 3). Aorist active with applicative ləi-at-ko-a=e tell-ACT.APPL.AOR-3PL-FIN=3SG ləi-at-ko-a=e tell-ACT.APPL.AOR-3PL-FIN=3SG 'He told them.' 1). Aorist middle hij-en-a=e come-MID.AOR-FIN=3 hij-en-a=e come-MID.AOR-FIN=3 'He came.' 2). Anterior middle with applicative ɲɛl-an-a=e see-MID.APPL.ANT-FIN=3 ɲɛl-an-a=e see-MID.APPL.ANT-FIN=3 'He had seen for himself.' 3). Anterior middle negative iɲ I hola yesterday haːʈ market ba=iɲ NEG=1 tʃala-o(ʔ)-le-n-a go-MID.AUGM.PASS.IPFV-TR.ANT.NEG-INTR/MID-FIN iɲ hola haːʈ ba=iɲ tʃala-o(ʔ)-le-n-a I yesterday market NEG=1 go-MID.AUGM.PASS.IPFV-TR.ANT.NEG-INTR/MID-FIN 'I did not go to the market yesterday.' While in ordinary passive voice, the object of the action becomes the subject of the sentence, inimpersonal passive voice, it remains the grammatical object. The subject can be replaced with an impersonal pronoun, as in FrenchOn lit le journal.or GermanMan liest die Zeitung.(\"The newspaper is (being) read\"). Similar constructions are sometimes used in English, as inOne reads the newspaper;youandtheycan also be used in an impersonal sense. In other languages, the subject is omitted and a specific impersonal form of the verb is used. Verbs in the Finnic languages, such asFinnishandEstonian, have an impersonal voice, often simply called the passive (Finnish:passiivi, Estonian:umbisikuline tegumood), which omits the subject and retains the grammatical role of the object. It has also been called the \"zero person\".In Estonian: In Estonian, the agent can be included by using thepostpositionpoolt, although using such a construction instead of the active voice is criticized as aforeignism(influenced by German, Russian and English) and characteristic ofofficialese. In both Finnish and Estonian, the use of the impersonal voice generally implies that the agent is capable of own initiative. For example, FinnishIkkuna hajotettiin.(\"The window was broken.\") would generally not be used if the window was broken by the wind, rather than a person. In the latter case, one could instead use areflexive(anticausative) verb in the active voice, such asIkkuna hajosi.(\"The window broke.\").  Celtic languageshave an inflection commonly called the \"impersonal\" or \"autonomous\" form,of similar originto the Latin \"passive-impersonal\". This is similar to a passive construction in that the agent of the verb is not specified. However its syntax is different from prototypical passives, in that the object of the action remains in the accusative. It is similar to the use of the pronounonin French (except whereveronis instead used an alternative to\"we\", which is very frequent). It increasingly corresponds to the passive in modern English, in which there is a trend towards avoiding the use of the passive unless it is specifically required to omit the subject. It also appears to be similar to the \"fourth person\" mentioned in the preceding paragraph. However, what is called in Irishan briathar saororthe free verbdoes not suggest passivity but a kind of generalized agency. The construction has equal validity in transitive and intransitive clauses, and the best translation into English is normally by using the \"dummy\" subjects \"they\", \"one\", or impersonal \"you\". For example, the common sign againsttobaccoconsumption has its closest direct translation in English as \"No smoking\": Ná Don't caitear use-IMPERSONAL tabac tobacco. Ná caitear tabac Don't use-IMPERSONAL tobacco.  An example of its use as an intransitive is: Téithear Go-IMPERSONAL go dtí to an sráidbhaile the village go minic often Dé Sathairn Saturday Téithear {go dtí} {an sráidbhaile} {go minic} {Dé Sathairn} Go-IMPERSONAL to {the village} often Saturday \"People often go to the village of a Saturday.\" The difference between the autonomous and a true passive is that while the autonomous focuses on the action and overtly avoids mentioning the actor, there is nonetheless an anonymous agent who may be referred to in the sentence. For instance: Théití go[PAST.HAB.AUT] ag PROG ithe eat béile meal le chéile with each other Théití ag ithe béile {le chéile} go[PAST.HAB.AUT] PROG eat meal {with each other} \"People used to go  eating   a meal  together.\" In English, the formation of the passive allows the optional inclusion of an agent in a prepositional phrase, \"by the man\", etc. Where English would leave out the noun phrase, Irish uses the autonomous; where English includes the noun phrase, Irish uses its periphrastic passive – which can also leave out the noun phrase: Bhí Was an the tabac tobacco caite consumed (ag (by an the bhfear) man) Bhí an tabac caite (ag an bhfear) Was the tobacco consumed (by the man) \"The tobacco was smoked (by the man).\" The impersonal endings have been re-analysed as a passive voice inModern Welshand the agent can be included after the prepositiongan('by'): Some linguists draw a distinction between static (or stative) passive voice and dynamic (or eventive) passive voice in some languages. Examples includeEnglish,German,Swedish,SpanishandItalian. \"Static\" means that an action was, is, or will be done to the subject at a certain point in time that did, does, or will result in a state in the time focused upon, whereas \"dynamic\" means that an action was, is, or will be taking place.   For some speakers of English the dynamic passive constructed withgetis not accepted and is considered colloquial or sub-standard.  Dynamic passive in Swedish is also frequently expressed with the s-ending. Thevarapassive is often synonymous with, and sometimes preferable to, simply using the corresponding adjective: Theblipassive is often synonymous with, and sometimes preferable to, the s-passive: Spanishhas two verbs corresponding to Englishto be:serandestar.Seris used to form the ordinary (dynamic) passive voice: However, this construction is very unidiomatic. The usual passive voice is these pasiva, in which the verb is conjugated in the active voice, but preceded by theseparticle: Estaris used to form what might be termed a static passive voice (not regarded as a passive voice in traditionalSpanish grammar; it describes a state that is the result of an action): In theserandestarcases, the verb's participle is used as the complement (as is sometimes the case in English). Italianuses two verbs (essereandvenire) to translate the static and the dynamic passive: Dynamic passive auxiliary verb:essereandvenire(to beandto come) Static passive auxiliary verb:essere(to be) InVenetian(Vèneto) the difference between dynamic (true) passive and stative (adjectival) passive is more clear cut, usingèser(to be) only for the static passives andvegner(to become, to come) only for the dynamic passive: Static forms represents much more a property or general condition, whereas the dynamic form is a real passive action entailing \"by someone\": Voices found in various languages include: A particular language may use the same construction for several voices, such as the same form for passive and reflexive.", "combined_text": "Voice (grammar) Contents Overview History of the concept of voice Voice contrasts Voices in topic-prominent languages Chinese Japanese Santali Impersonal passive voice Finnic languages Celtic languages Dynamic and static passive German English Swedish Spanish Italian Venetian List of voices See also Notes References Ingrammar, thevoice(ordiathesis) of a verb describes the relationship between the action (or state) that the verb expresses and the participants identified by itsarguments(subject, object, etc.).When thesubjectis the agent or doer of the action, the verb is in theactive voice. When the subject is the patient, target or undergoer of the action, the verb is said to be in thepassive voice.When the subject both performs and receives the action expressed by the verb, the verb is in the middle voice. The following pair of examples illustrates the contrast between active and passive voice in English. In sentence (1), the verb formateis in the active voice, but in sentence (2), the verb formwas eatenis in the passive voice. Independent of voice,the catis the Agent (the doer) of the action of eating in both sentences. In atransformationfrom an active-voiceclauseto an equivalent passive-voice construction, the subject and thedirect objectswitch grammatical roles. The direct object getspromotedto subject, and the subjectdemotedto an (optional)adjunct. In the first example above,the mouseserves as the direct object in the active-voice version, but becomes the subject in the passive version. The subject of the active-voice version,the cat, becomes part of a prepositional phrase in the passive version of the sentence, and can be left out entirely;The mouse was eaten. In the grammar of Ancient Greek, voice was calledδιάθεσιςdiáthesis'arrangement'or'condition', with three subcategories: In Latin, two voices were recognized: The active voice is the most commonly used in many languages and represents the \"normal\" case, in which the subject of the verb is the agent. In the active voice, the subject of the sentence performs the action or causes the happening denoted by the verb. Sentence (1) is in active voice, as indicated by the verb formsaw. (1)Roger Bigod saw the castles.  The passive voice is employed in a clause whosesubjectexpresses thethemeorpatientof the verb. That is, it undergoes an action or has its state changed.In the passive voice, the grammatical subject of the verb is the recipient (not the doer) of the action denoted by the verb. In English it serves a variety of functions including focusing on the object, demoting the subject and handling situations where the speaker either wants to suppress information about who the doer of the action is, or in reality does not know their identity, or when the doer is either unimportant or likely to becommon knowledge. There are syntactic, semantic, and pragmatic motivations for choosing the passive voice instead of the active.Some languages, such asEnglishandSpanish, use aperiphrasticpassive voice; that is, it is not a single word form, but rather a construction making use of other word forms. Specifically, it is made up of a form of theauxiliary verbto beand a pastparticipleof the main verb which carries the lexical content of the predicate. In other languages, such asLatin, the passive voice for some tenses is simply marked on the verb byinflection:librum legit\"He reads the book\";liber legitur\"The book is read\". Passives mark this voice in English syntactically as well, which often involves subject–object inversion and the use of 'by'. Sentence (2) is an example of passive voice, where something (the castles) has been (notionally) acted upon by someone (Roger Bigod). (2)The castles were seen by Roger Bigod. The antipassive voice deletes or demotes the object of transitive verbs, and promotes the actor to an intransitive subject. This voice is very common amongergative–absolutive languages(which may feature passive voices as well), but also occurs amongnominative–accusative languages.  Some languages (such asAlbanian,Bengali,Fula,Tamil,Sanskrit,Icelandic,SwedishandAncient Greek) have amiddle voice, which is a set of inflections or constructions which is to some extent different from both the active and passive voices. The subject of such middle voice is like the subject of active voice as well as the subject of passive voice, in that it performs an action, and is also affected by that action.Another difference between middle voice and the other two grammatical voices is that there are middle marked verbs for which no corresponding active verb form exists.In some cases, the middle voice is any grammatical option where the subject of a material process cannot be categorized as either an actor (someone doing something) or a goal (that at which the actor aims their work). For example, while the passive voice expresses a medium (goal) being affected by an external agent (actor) as in sentence (4), the middle voice expresses a medium undergoing change without any external agent as in sentence (5). In English, though the inflection  for middle voice and active voice are the same for these cases, they differ in whether or not they permit the expression of the Agent argument in an oblique by-phrase PP: thus while the by-phrase is possible with passive voice as in sentence (6), it is not possible with middle voice, as shown by the ill-formed sentence (7). (4)The casserole was cooked in the oven(passive voice) (5)The casserole cooked in the oven(middle voice) (6)The casserole was cooked in the oven by Lucy(passive voice) (7) *The casserole cooked in the oven by Lucy(by-phrase ungrammatical when used with middle voice; asterisk (*) indicates ungrammaticality) In ClassicalGreek, the middle voice is often used for material processes where the subject is both the actor (the one doing the action) and the medium (that which is undergoing change) as in \"the man got a shave\", opposing both active and passive voices where the medium is the goal as in \"The barber shaved the man\" and \"The man got shaved by the barber\". Finally, it can occasionally be used in a causative sense, such as \"The father causes his son to be set free\", or \"The father ransoms his son\". In English, there is no verb form for the middle voice, though some uses may be classified by traditional grammarians as middle voice, often resolved via areflexive pronoun, as in \"Fred shaved\", which may be expanded to \"Fred shaved himself\" – contrast with active \"Fred shaved John\" or passive \"John was shaved by Fred\". This need not be reflexive, as in \"My clothes soaked in detergent overnight.\". In English, it is impossible to tell from the morphology whether the verb in Sentence (8) is an active voice unaccusative verb or a middle voice anticausative verb with active morphology.Since middle voice reflexives and dispositional middles are found in English with active morphology by looking at Sentence (9), it can be assumed that at least some middle voice anticausatives with active morphology exist as well. (8)The window broke from the pressure/by itself. (9)This book sells well. English used to have a distinct form, called thepassival, which was displaced over the early 19th century by the progressive passive and is no longer used in modern English.In the passival, one might say \"The house is building.\", which may today be rendered instead as \"The house is being built.\" Likewise \"The meal is eating.\", which is now \"The meal is being eaten.\" The similar \"Fred is shaving\" and \"The meal is cooking\" remain grammatical. It is suggested that the progressive passive was popularized by theRomantic poets, and is connected withBristolusage. Manydeponent verbsinLatin(i.e., verbs passive in form but active in meaning) are descendants of theProto-Indo-Europeanmiddle voice. Some languages have even more grammatical voices. For example,Classical Mongolianfeatures five voices: active, passive, causative, reciprocal, and cooperative. There are also constructions in some languages that appear to change thevalenceof a verb, but in fact do not. So called hierarchical orinversionlanguages are of this sort. Their agreement system will be sensitive to an external person or animacy hierarchy (or a combination of both): 1 > 2 > 3 or Anim > Inan and so forth. E.g., inMeskwaki(an Algonquian language), verbs inflect for both subject and object, but agreement markers do not have inherent values for these. Rather, a third marker, the direct or inverse marker, indicates the proper interpretation: ne- 1- wa:pam look.at -e: -DIR -w -3 -a -3.SG ne- wa:pam -e: -w -a 1- look.at -DIR-3 -3.SG \"I am looking at him.\" ne- 1- wa:pam look.at -ekw -INV -w -3 -a -3.SG ne- wa:pam -ekw -w -a 1- look.at -INV -3 -3.SG \"He is looking at me.\" Some scholars (notably Rhodes) have analyzed this as a kind of obligatory passivization dependent on animacy, while others have claimed it is not a voice at all, but rather see inversion as another type of alignment, parallel tonominative–accusative,ergative–absolutive,split-S, andfluid-Salignments. In general, the grammar of standard Chinese (both including Mandarin and Cantonese) shares many features with other varieties of Chinese. However, there are still some differences between the different varieties. Mandarin active voice sentences have the same verb phrase structure as English active voice sentences.\nThere is a common active construction in Mandarin called Ba(把) construction: “Ba” is acoverb, not a preposition. It is a three-place predicate that subcategorizes for a subject, an object, and a VP complement. 他 ta He 把 ba ACT 橘子 juzi orange 剥了 bo-le peeled-PRF 皮。 pi. peel 他 把 橘子 剥了 皮。 ta ba juzi bo-le pi. He ACT orange peeled-PRF peel 'He peeled the orange skin. ' This Ba construction is also a direct opposition of active voice in passive voice in Mandarin (i.e. Ba construction (= active voice) vs. Bei construction (= passive voice)). The following sentence b) is in contrast to sentence a). 橘子 Juzi Orange 被 bei PASS （他） (ta) (he) 剥了 bo-le peeled-PRF 皮。 pi. peel 橘子 被 （他） 剥了 皮。 Juzi bei (ta) bo-le pi. Orange PASS (he) peeled-PRF peel 'The orange was peeled (by him).' (Both a) and b) are adapted from Her, O. (2009)) Topic-prominent languageslikeMandarintend not to employ the passive voice as frequently.  In general, Mandarin used to be best analyzed using middle voice, but Mandarin-speakers can construct a passive voice by using the coverb被(bèi) and rearranging the usual word order.For example, this sentence using active voice: (The first line is in Traditional Chinese while the second is Simplified Chinese) 一條 一条 Yī-tiáo Α 狗 狗 gǒu dog 咬了 咬了 yǎo-le bite-PRF 這個 这个 zhège this 男人。 男人。 nánrén. man 一條 狗 咬了 這個 男人。 一条 狗 咬了 这个 男人。 Yī-tiáo gǒu yǎo-le zhège nánrén. Α dog bite-PRF this man \"A dog has bitten this man.\" corresponds to the following sentence using passive voice. The agent phrase is optional. 這個 这个 Zhège This 男人 男人 nánrén man 被 被 bèi PASS (狗) (狗) (gǒu) (dog) 咬了。 咬了。 yǎo-le. bite-PRF 這個 男人 被 (狗) 咬了。 这个 男人 被 (狗) 咬了。 Zhège nánrén bèi (gǒu) yǎo-le. This man PASS (dog) bite-PRF \"This man has been bitten (by a dog).\" In addition, through the addition of the auxiliary verb \"to be\"是(shì) the passive voice is frequently used to emphasize the identity of the actor. This example places emphasis on thedog, presumably as opposed to some other animal: 這個 这个 Zhège This 男人 男人 nánrén man 是 是 shì to be 被 被 bèi PASS 狗 狗 gǒu dog 咬 咬 yǎo bite 的。 的。 de. (suffix) 這個 男人 是 被 狗 咬 的。 这个 男人 是 被 狗 咬 的。 Zhège nánrén shì bèi gǒu yǎo de. This man {to be} PASS dog bite {(suffix)} \"This man has been bitten by adog.\" Mandarin also has anobject-retaining passivewhich contains both the object and the topic (mostly the possessor of the object): 他 他 tā He 被 被 bèi PASS 小偷 小偷 xiǎotou thief 偷了 偷了 tōu-le steal-PRF 錢包。 钱包。 qiánbāo. wallet 他 被 小偷 偷了 錢包。 他 被 小偷 偷了 钱包。 tā bèi xiǎotou tōu-le qiánbāo. He PASS thief steal-PRF wallet \"His wallet was stolen by a thief.\" 被 (bèi) as a passive marker is a relatively new addition to the language, introduced as part of the early 20th century language reforms that also added gender-specific pronouns such as 他>她 and 你>妳 and culminated in attempts to Romanize Chinese entirely. There is a  typical passive construction in Mandarin, namely Bei construction.  It is commonly used to indicate result, direction, location, frequency, duration, manner, and appearance.Similar to English, Bei construction can also be analysed by A-movement which is locally restricted. The subject of the Bei clause is included in the complement clause where the “passivized” object controls the verb.Classically, 被 marked an adversative mood, indicating that something bad had happened.  Even today, the following sentence is perfectly acceptable in speech: 蛋糕 蛋糕 dangao cake 吃了。 吃了。 chi-le. eat-PRF 蛋糕 吃了。 蛋糕 吃了。 dangao chi-le. cake eat-PRF \"The cake was eaten.\" Recent development ofbèiconstruction Recently, more syntacticians investigated passive voice in Mandarin. They discovered that passive voice in Mandarin is heavily dependent on the context of the sentence rather than the grammatical forms.Therefore, passive voice can be marked (e.g. by the most broadly used passive marker:bèi被 [mentioned above]) or unmarked (see the \"Notional passive\" section below) in both speech and writing. Those sentences have a passive marker called the long passive, while the ones that do not require a passive marker are called short passive. Here are examples for long passive and short passive: 张三 Zhangsan Zhangsan 被 bei PASS 李四 Lisi Lisi 打 da hit 了。 le. PRF 张三 被 李四 打 了。 Zhangsan bei Lisi da le. Zhangsan PASS Lisi hit PRF 'Zhangsan was hit by Lisi.' 张三 Zhangsan Zhangsan 被 bei PASS 打 da hit 了。 le. PRF 张三 被 打 了。 Zhangsan bei da le. Zhangsan PASS hit PRF 'Zhangsan was hit ∅.' (Both examples are adapted from Huang, C. J., & Liu, N. (2014)) We can see from the examples above, the difference between long passive and short passive depends on whether the agent phrase is presented or not. Bei construction was not often used in Old Chinese, but it is widely used in Modern Chinese. The appearance of Bei construction marks that Modern Chinese is undergoing a new cycle of change. Old Chinese was considerably synthetic and has been gradually changed to analyticity. Later its development peaked during Tang-Song Dynasties. Nowadays, in Modern Chinese, it is mainly analytic but also shows forward tendency toward synthesis.Here are some recent theories that syntacticians have proposed. Ting (1998) proposed that Bei is acting as a verb and it is widely accepted so far. Ting stated that Bei construction is not used uniformly in all passive contexts in Mandarin. Rather, three types of Bei-sentences must be introduced. The main distinction is discovered in A-movement and lexical passive compound verb. To some extent, his theory was also supported by Yip et al. (2016), where they also proposed three different forms of passive Mandarin. Ting's claims were based on his investigation of post-verbal overt pronominal object, locality of selection, occurrence of the particle suo(所) in Bei construction, and the intervention of adverbs within the Bei-V compound (= co-verb). He believed that Bei construction is presented in three types, two of them have different selectional properties, and the other one is lexically derived as Bei-V compound. Here is an example of showing a sentence having different selectional properties in its subject and object: 李四 Lisi Lisi 被 bei PASS 张三 Zhangsan Zhangsan 派 pai sent 我 wo I 抓走了。 zhua-zou-le. catch-PRF. 李四 被 张三 派 我 抓走了。 Lisi bei Zhangsan pai wo zhua-zou-le. Lisi PASS Zhangsan sent I catch-PRF. 'Lisi (was)affected(by) Zhangsan's sending me (to)catch(him).' [Lisi1bei Zhangsan pai wo2[CP [TP PRO2zhua-zou-le [e]1]]] (This example is adapted from Ting, J. (1998)) Huang and Liu (2014) argued that Bei construction is not a special construction that involves the passivization of intransitive verbs. They believe that what is passivized isn't the VP itself (in Bei-VP construction), but actually a null light verb with a causative, putative or activity predicate that takes VP as its complement or adjunct. In their analysis, VP part in Bei-VP construction acquires its categorical feature by an agreement relation with a category-creating light verb, and it serves as the complement or adjunct of that light verb. What makes it different from other constructions is that it doesn't have grammatical active sources (null light verb constructions are abundant in Old Chinese).The head of this construction is a null light verb with the semantics of CAUSE and DO, referring to several causative or executive events. Huang and Liu's theory of Bei construction can explain the usage of Bei in both Modern Chinese and Old Chinese. According to Yip et al. (2016), there are three forms in passive voice depending on the tone and emphasis. They are notional passive, formal passive, and lexical passive. No formal passive marker is needed and carries an expository tone. It is the most common form of passive voice in Mandarin and is extremely colloquial. Passive marker is excluded in notional passive because the sentence relies on the hearer's common sense or their knowledge of the world. Thus, this passive voice is expressed implicitly. Furthermore, notional passive sentences can be representing either positive or negative meanings. Here is an example of notional passive: 问题 Wenti Problem 解决 jiejue solve 了。 le. PRF. 问题 解决 了。 Wenti jiejue le. Problem solve PRF. 'Problem (has)been solved.' In other voices in Mandarin, “object + transitive verb” construction is usually used. However, “topic + explanatory comment” is the common structure for notional passive. There is no surface passive marker in the sentence, but the underlying meaning does carry a passive voice. The negation of notional passive is similar to English negation. Both are achieved by adding the negator “mei(you)没(有)” right before the transitive verb. In fact, in negation, “le” is no longer necessary in the sentence. Here is an example of negation of notional passive: 问题 Wenti Problem 还 hai still 没 mei not 解决。 jiejue. solve. 问题 还 没 解决。 Wenti hai mei jiejue. Problem still not solve. 'Problem (has)not(yet) been solved.' (Both examples are adapted from Yip et al. (2016), Chapter 13) Most objects present in notional passive are inanimate objects because ambiguity can arise if we use animate objects in these sentences. To avoid this problem, formal or lexical passive markers will be introduced in the sentence. A formal passive marker is introduced as \"bei\" and it is usually in narrative tone. It is generally used as the narration or description of an event that has already taken place. Additionally, formal passive sentences can only represent negative meanings, otherwise it is ungrammatical. It can be used in both informal and formal contexts. Here is an example of formal passive: 问题 Wenti Problem 终 zhong finally 被 bei PASS 解决。 jiejue. solve. 问题 终 被 解决。 Wenti zhong bei jiejue. Problem finally PASS solve. 'Problem was finally solved.' (Example is adapted from Yip et al. (2016), Chapter 13) There is a striking feature of formal passive which makes it different from other forms of passives. The formal passive is presented as including “bei” as a co-verb in sentence and acting as a formal passive marker. “Bei” indicates the subject of the sentence is the action receiver. The initiator of this action is usually presented after “bei”. But this initiator could be overt (unstated), covert (revealed), or vague. Here is some examples of showing different identities in initiators: 那个 nage That 警察 jingcha policeman 被 bei PASS 打伤了。 dashang-le. hit-wounded-PRF 那个 警察 被 打伤了。 nage jingcha bei dashang-le. That policeman PASS hit-wounded-PRF 'That policeman was wounded.' 那个 nage That 警察 jingcha policeman 被 bei PASS 人 ren somebody 打伤了。 dashang-le. hit-wounded-PRF 那个 警察 被 人 打伤了。 nage jingcha bei ren dashang-le. That policeman PASS somebody hit-wounded-PRF 'That policeman was wounded (by-somebody).' 那个 nage That 警察 jingcha policeman 被 bei PASS 流氓 liumang hooligan 打伤了。 dashang-le. hit-wounded-PRF 那个 警察 被 流氓 打伤了。 nage jingcha bei liumang dashang-le. That policeman PASS hooligan hit-wounded-PRF 'That policeman was wounded (by-hooligans).' (These are adapted from Yip et al. (2016) Chapter 13, p. 253) Although the most common formal passive marker is “bei”, it can also be replaced by rang让, jiao教, gei给, etc. The identity of the initiator is either overt or vague. “Bei” cannot be used in imperatives, but other formal passive markers can be used in colloquialism. No formal passive marker is present, but the passive voice is introduced by a verb that indicates the subject as the receiver of the action, then the verb is followed by an object. The literary meaning is quite similar to English inverted sentences. It is usually a formal tone. Common indicators are a set of verbs, like dedao得到, shoudao受到, zaodao遭到 (the three most common verbs used in lexical passive), etc. Here is an example of lexical passive: 问题 Wenti Problem 得到 dedao receive 了 le PRF 解决。 jiejue. solution. 问题 得到 了 解决。 Wenti dedao le jiejue. Problem receive PRF solution. 'Solution (was)found for problem.' (Example is adapted from Yip et al. (2016), Chapter 13) The syntactic structure of lexical passive is SVO: The semantic formula: receiver + verb + initiator + nominalised verb. (No additional complement to the nominalised verb is allowed.) In nominal and formal passives, the focus is on the outcome of the action, but for lexical passive, the focus has shifted to emphasize the degree of the action that has been carried out. In other words, the focus is on the initiator and nominalised verb. In general, Chinese employs middle voice.There are still ongoing discussions about where there is a distinct class for middle voice verbs. \nChao believes that ergative (= middle voice) verb is a distinct syntactic verb category. In other words, it isn't purely transitive or intransitive. However, Li et al. (1981), when arguing against Chao's analysis of Mandarin, stated that there is a distinct class of middle voice verbs. They recognize that Mandarin (and Cantonese) verbs as a whole behave the same way. Later, Li et al. (1981) introduced middle voice sentences as examples of topic/comment constructions which lacks an overt subject. Here is an example: 饭 fan Rice 煮焦 zhujiao cook(burnt) 了 le PRF 一点。 yidian. (a)bit. 饭 煮焦 了 一点。 fan zhujiao le yidian. Rice cook(burnt) PRF (a)bit. 'The rice (∅)burnt (a)bit.' (Adapted from Li et al. (1981)) We can see from this example that the characteristic of a topic/comment construction in its implication of a dropped anaphor indicates an agent. While Ting (2006) compared between middles and Ba constructions (= active voice) involving intransitive  V-de (得) resultatives. He also did comparison between middles and inchoatives. He argues that we can treat notional passives in Mandarin as middle constructions. Its underlying grammatical subject position and lack of a syntactically active logical subject are best explained by a presyntactic approach. But, semantically, Chinese middle voice may be interpreted like stative or verbal passives. Here are two examples: *那本 naben That 书 shu book 很 hen very 喜欢。 xihuan. like. *那本 书 很 喜欢。 naben shu hen xihuan. That book very like. 'That book is liked.' 那本 naben That 书 shu book 喜欢得 xihuan-de like-de 要命。 yaoming. dying. 那本 书 喜欢得 要命。 naben shu xihuan-de yaoming. That book like-de dying. 'That book is (extremely)liked.' (Both examples are adapted from Ting (2006)) Ting argues that sentence a) is ungrammatical and indistinguishable from ergatives, and that sentence b) is grammatical and he believes that it must have used middle voice due to their function of defocusing an agent subject. Although Bei construction in passive voice can achieve the same purpose, there is a possibility that associating with Bei construction may be inappropriate in many contexts. Thus, using middle voice is better in this case. Due to the ongoing discussion, we still don't have a uniformed theory in middle voice in Mandarin. InCantonese, those features are quite similar by using thecoverb俾(bei), but the agent phrase is NOT optional, often with a formal agent人(jan): 個 Go The 男人 naamjan man 俾 bei PASS 狗 gau dog 咬咗喇。 ngaau-zo-laa bite-PFV-PRF 個 男人 俾 狗 咬咗喇。 Go3 naam4jan4 bei2 gau2 ngaau5-zo2-laa3 The man PASS dog bite-PFV-PRF \"The man has been bitten by a dog.\" 佢 Keoi 3SG 俾 bei PASS 人 jan someone 食咗喇。 sik-zo-laa eat-PFV-PRF 佢 俾 人 食咗喇。 Keoi5 bei2 jan4 sik6-zo2-laa3 3SG PASS someone eat-PFV-PRF \"He/She/It has been eaten (by someone).\" However, in some dialects ofYue, a passive voice with an optional agent phrase is also available: Qinzhou (Qin-Lian Yue): 佢 Ki 3SG 著 zoek PASS 打喇。 daa-laa beat-PRF 佢 著 打喇。 Ki3 zoek6 daa2-laa3 3SG PASS beat-PRF \"He/She/It has been beaten.\" In the actor-emphasizing passive voice of Cantonese, besides the addition of the auxiliary verb \"to be\"係(hai), theperfectiveevent is also converted to an adjective-like predicative with the suffix嘅(ge) or㗎(gaa), which is a more emphasized one from the liaison of嘅(ge) and啊(aa): 個 Go The 男人 naamjan man 係 hai to be 俾 bei PASS 狗 gau dog 咬 ngaau bite 嘅。 ge (suffix) 個 男人 係 俾 狗 咬 嘅。 Go3 naam4jan4 hai6 bei2 gau2 ngaau5 ge3 The man {to be} PASS dog bite {(suffix)} \"The man was bitten by adog.\" Grammatical voice in Japanese only contains an active and passive voice and does not have a middle voice. Active voice in Japanese is the direct opposition of direct passive voice in Japanese. This is similar to English which also has corresponding active and passive sentences. This is an example of a corresponding active voice and direct passive voice sentence. Active Voice Naomi Naomi ga NOM Ken Ken o ACC nagut-ta. hit-PST. Naomi ga Ken o nagut-ta. Naomi NOM Ken ACC hit-PST. Naomi hit Ken. Direct Passive Ken Ken ga NOM Naomi Naomi ni DAT nagur-are-ta. hit-PASS-PST. Ken ga Naomi ni nagur-are-ta. Ken NOM Naomi DAT hit-PASS-PST. Ken was hit by Naomi. (Both examples are adapted from Shibatani et al. (2017)) Word order in Japanese is more flexible so active voice sentences  can be both SOV (subject + object + verb) and OSV (object + subject + verb) order; however, SOV is typically used more often. Active SOV sentence example: ボート bōto boat が -ga -NOM 漁師 ryōshi fisherman を -o -ACC 運んだ。 hakonda. carried-ACT. ボート が 漁師 を 運んだ。 bōto -ga ryōshi -o hakonda. boat -NOM fisherman -ACC carried-ACT. 'The boat carried the fisherman.' Active OSV sentence example 漁師 ryōshi fisherman を -o -ACC ボート bōto boat が -ga -NOM 運んだ。 hakonda. carried-ACT. 漁師 を ボート が 運んだ。 ryōshi -o bōto -ga hakonda. fisherman -ACC boat -NOM carried-ACT. 'The fisherman, the boat carried.' (Both examples are adapted from Tanaka et al. (2011)) Although a topic-prominent language,Japaneseemploys the passive voice quite frequently, and has two types of passive voice, direct voice which corresponds to that in English and an indirect passive which is not found in English. The passive voice in Japanese is constructed with the verb stem followed by the passive morpheme -(r)are. This synthetic passive morpheme can attach to transitive, ditransitive and some intransitive verbs.The word order in Japanese is more flexible so passive sentences can be both SOV (subject + object + verb) and OSV (object + subject + verb) order; however, SOV is typically used more often.Furthermore, there are two theories about passive voice in Japanese called the uniform and non-uniform theory.These two theories debate whether direct and indirect passives should be treated equally or if they should be treated differently. Examples of passive voice in Japanese: 彼 Kare He は wa TOPIC 泥棒 dorobō thief に ni AGENT 財布 saifu wallet を o OBJECT 盗まれた。 nusumareta. steal-PASSIVE-PAST 彼 は 泥棒 に 財布 を 盗まれた。 Kare wa dorobō ni saifu o nusumareta. He TOPIC thief AGENT wallet OBJECT steal-PASSIVE-PAST \"He got his wallet stolen by a thief.\" 僕 Boku I は wa TOPIC 彼女 kanojo her に ni AGENT 嘘 uso lie を o OBJECT つかれた。 tsukareta. tell-PASSIVE-PAST. 僕 は 彼女 に 嘘 を つかれた。 Boku wa kanojo ni uso o tsukareta. I TOPIC her AGENT lie OBJECT tell-PASSIVE-PAST. \"I was told a lie by her.\" (= \"She lied to me.\") Japanese direct passives have corresponding active sentences which is similar to English passives in that the logical object appears as the grammatical subject. Direct passive examples: Ken Ken ga NOM Naomi Naomi ni DAT nagur-are-ta. hit-PASS-PST. Ken ga Naomi ni nagur-are-ta. Ken NOM Naomi DAT hit-PASS-PST. 'Ken was hit by Naomi.' Ken Ken ga NOM Naomi Naomi ni DAT home-rare-ta. praise-PASS-PST. Ken ga Naomi ni home-rare-ta. Ken NOM Naomi DAT praise-PASS-PST. 'Ken was praised by Naomi.' Yōko Yoko wa TOP Hiroshi Hiroshi ni DAT yasashiku gently nagusame console.IRR -rare AUX/PASS -ta. PST. Yōko wa Hiroshi ni yasashiku nagusame -rare -ta. Yoko TOP Hiroshi DAT gently console.IRR AUX/PASS PST. 'Yoko was gently consoled by Hiroshi.' (Examples are adapted from Shibatani et al. (2017)) In all 3 examples the auxiliary verb (ra)reru is used as a suffix to the active forms of the verb to show the meaning of the direct passive. Indirect passives have two varieties, possessive passives and gapless passives. In possessive passives, the grammatical subject stands in a canonical possessive relation with the direct object and in gapless passives they appear to lack an active counterpart and contain an extra argument is realized as the grammatical subject that is unlicensed by the main verb. Indirect passives can also be used when something undesirable happens to the speaker. Indirect (possessive) passive The subject in possessive passives is in a canonical possessive relation such as kinship, ownership, etc. with the direct object. Ken Ken ga NOM sensei teacher ni DAT musuko son o ACC shikar-are-ta. scold-PASS-PST. Ken ga sensei ni musuko o shikar-are-ta. Ken NOM teacher DAT son ACC scold-PASS-PST. lit. 'Ken was scolded his son by the teacher.' (cf. Ken's son was scolded.) (This example was adapted from Shibatani et al. (2017)) In this example of a possessive passive there is a kinship relation between the grammatical subject which is 'Ken' and the direct object which is the 'musuko' (son). Indirect (gapless) passive Gapless passives unlike possessive passives lack an active counterpart and contain an extra argument that is unlicensed by the main verb. The extra argument is also realized as the grammatical subject. Ken Ken ga NOM Naomi Naomi ni DAT nige-rare-ta. escape-PASS-PST. Ken ga Naomi ni nige-rare-ta. Ken NOM Naomi DAT escape-PASS-PST. lit. 'Ken was escaped from by Naomi.' (cf. Naomi escaped [from Ken].) (Both examples are adapted from Shibatani et al. (2017)) Ni-yotte passives are another type of Japanese passive that contrasts direct and indirect passives which contain a dative ni-phrase. They are similar to direct passives but the instead of the logical subject being realized as a ni-phrase it is realized as a ni-yotte phrase. Ni-yotte passive examples: Kabin vase ga NOM (Ken Ken ni-yotte) DAT-owing kowas-are-ta. break-PASS-PST. Kabin ga (Ken ni-yotte) kowas-are-ta. vase NOM Ken DAT-owing break-PASS-PST. 'The vase was broken (by means of Ken).' Jūtai traffic.jam wa TOP jiko accident ni-yotte DAT-owing oki-ta. occur-PST. Jūtai wa jiko ni-yotte oki-ta. traffic.jam TOP accident DAT-owing occur-PST. 'The traffic jam occurred due to an accident.' (This example is adapted from Shibatani et al. (2017)) In addition, as seen in example 2)ni-yottecan also be used more generally to introduce a cause. This because the-yotteinni-yotteis a form of the verbyor-uwhich means 'owe'. Unlike indirect and direct passive with ni-phrases, ni-yotte\nphrases are not indigenous to Japanese and were created as a way to translate modern Dutch texts because direct translations did not exist. The uniform theory was developed by Kuroda (1965, 1979, 1983) and Howard and Niyejawa-Howard (1976). This theory argues that both direct and indirect passives in Japanese should be treated as the same. In this theory both direct and indirect passives are derived from the same complementation structure with optional control. There is the assumption that the-(r)aremorpheme in direct passives are the same as the ones used in indirect passives meaning that they both have an underlying structure containing the passive morpheme-(r)are. A problem with this theory is that other similar languages such as Korean and Chinese have possessive and direct passives but do not have indirect passives which indicates that possessive passives appear to behave as a natural class from a typological perspective. However, this theory is preferred over the non-uniform theory because the morpheme-(r)arebeing spelled the same for both direct and indirect passives is an unsustainable coincidence. 1) Direct passive Paul-wa Paul-FOC George-ni George-to wagamama selfish dato as hinans-are-ta criticise-PASS-PST Paul-wa George-ni wagamama dato hinans-are-ta Paul-FOC George-to selfish as criticise-PASS-PST 'Paul was criticised for being selfish by George.' Internal direct passive sentence: [Paul ga [George ga Paul wo wagamama dato hinansuru] are ta] 2) Indirect passive Paul-wa Paul-FOC John-ni John-to shin-are-ta die-PASS-PST Paul-wa John-ni shin-are-ta Paul-FOC John-to die-PASS-PST 'Paul was adversely affected by John's death.' Internal indirect passive sentence: [Paul ga [George ga Paul o wagamama dato hinansuru] are ta] (These example is adapted from Toyota (2011). In these examples we can see that the passive morpheme-(r)areis outside of the embedded sentence which shows that-(r)areis part of the underlying structure for both direct and indirect passives. The non-uniform theory has primarily been examined by McCrawley (1976) and Kuno (1973, 1978). The non-uniform theory argues that direct and indirect passives in Japanese are distinct and should be treated differently. This theory hypothesizes that direct and indirect passives have separate underlying structures which are distinct from each other. Direct passives are derived from the transitive underlying structure and do not contain the passive morpheme-(r)arein its underlying structure while the indirect passive does contain-(r)arein its underlying structure.The non-uniform theory argues that direct and indirect passives in Japanese should be treated differently.This theory is criticized by proponents of the uniform theory because the morpheme-(r)areis spelled the same for both direct and indirect passives, and this, they claim, is difficult to pass off as just a coincidence. 1) Direct Passive George-ga George-TOP gitā-o guitar-ACC hik-u play-PRS George-ga gitā-o hik-u George-TOP guitar-ACC play-PRS 'George plays the guitar.' In non-uniform theory-(r)areis not contained within the underlying structure so in this sentence is the result of a subject object shift. 2) Indirect Passive Gitā-ga guitar-TOP George-ni George-by.means. yotte of hik-are-ru play-PASS-PRS Gitā-ga George-ni yotte hik-are-ru guitar-TOP George-by.means. of play-PASS-PRS 'The guitar is played by George.' For indirect passive sentences-(r)areis contained within the underlying structure\n(This example is adapted from Toyota (2011). Santaliand allMunda languagesof theAustroasiatic phylumin general are notoriously messy for their fusion of TAMs and verb stems with the active and middle voices. In the perfective series of Santali, the active suffixes distinguish themselves from the middle suffixes with a final checked consonantˀtthat is conditioned to several morphophonological changes. The active agent of a polyvalent predicate can be passivized by using several stem augments such as-uʔ~oʔin stem alternations or to mark its predicate as middle voice in the imperfective series. 1). Aorist active dal-ke-d-a=ɲ beat-ACT.AOR-TR-FIN=1 dal-ke-d-a=ɲ beat-ACT.AOR-TR-FIN=1 'I beat.' 2). Aorist active with object dal-ke-d-e-a=ɲ beat-ACT.AOR-TR-3-FIN=1 dal-ke-d-e-a=ɲ beat-ACT.AOR-TR-3-FIN=1 'I beat him.' 3). Aorist active with applicative ləi-at-ko-a=e tell-ACT.APPL.AOR-3PL-FIN=3SG ləi-at-ko-a=e tell-ACT.APPL.AOR-3PL-FIN=3SG 'He told them.' 1). Aorist middle hij-en-a=e come-MID.AOR-FIN=3 hij-en-a=e come-MID.AOR-FIN=3 'He came.' 2). Anterior middle with applicative ɲɛl-an-a=e see-MID.APPL.ANT-FIN=3 ɲɛl-an-a=e see-MID.APPL.ANT-FIN=3 'He had seen for himself.' 3). Anterior middle negative iɲ I hola yesterday haːʈ market ba=iɲ NEG=1 tʃala-o(ʔ)-le-n-a go-MID.AUGM.PASS.IPFV-TR.ANT.NEG-INTR/MID-FIN iɲ hola haːʈ ba=iɲ tʃala-o(ʔ)-le-n-a I yesterday market NEG=1 go-MID.AUGM.PASS.IPFV-TR.ANT.NEG-INTR/MID-FIN 'I did not go to the market yesterday.' While in ordinary passive voice, the object of the action becomes the subject of the sentence, inimpersonal passive voice, it remains the grammatical object. The subject can be replaced with an impersonal pronoun, as in FrenchOn lit le journal.or GermanMan liest die Zeitung.(\"The newspaper is (being) read\"). Similar constructions are sometimes used in English, as inOne reads the newspaper;youandtheycan also be used in an impersonal sense. In other languages, the subject is omitted and a specific impersonal form of the verb is used. Verbs in the Finnic languages, such asFinnishandEstonian, have an impersonal voice, often simply called the passive (Finnish:passiivi, Estonian:umbisikuline tegumood), which omits the subject and retains the grammatical role of the object. It has also been called the \"zero person\".In Estonian: In Estonian, the agent can be included by using thepostpositionpoolt, although using such a construction instead of the active voice is criticized as aforeignism(influenced by German, Russian and English) and characteristic ofofficialese. In both Finnish and Estonian, the use of the impersonal voice generally implies that the agent is capable of own initiative. For example, FinnishIkkuna hajotettiin.(\"The window was broken.\") would generally not be used if the window was broken by the wind, rather than a person. In the latter case, one could instead use areflexive(anticausative) verb in the active voice, such asIkkuna hajosi.(\"The window broke.\").  Celtic languageshave an inflection commonly called the \"impersonal\" or \"autonomous\" form,of similar originto the Latin \"passive-impersonal\". This is similar to a passive construction in that the agent of the verb is not specified. However its syntax is different from prototypical passives, in that the object of the action remains in the accusative. It is similar to the use of the pronounonin French (except whereveronis instead used an alternative to\"we\", which is very frequent). It increasingly corresponds to the passive in modern English, in which there is a trend towards avoiding the use of the passive unless it is specifically required to omit the subject. It also appears to be similar to the \"fourth person\" mentioned in the preceding paragraph. However, what is called in Irishan briathar saororthe free verbdoes not suggest passivity but a kind of generalized agency. The construction has equal validity in transitive and intransitive clauses, and the best translation into English is normally by using the \"dummy\" subjects \"they\", \"one\", or impersonal \"you\". For example, the common sign againsttobaccoconsumption has its closest direct translation in English as \"No smoking\": Ná Don't caitear use-IMPERSONAL tabac tobacco. Ná caitear tabac Don't use-IMPERSONAL tobacco.  An example of its use as an intransitive is: Téithear Go-IMPERSONAL go dtí to an sráidbhaile the village go minic often Dé Sathairn Saturday Téithear {go dtí} {an sráidbhaile} {go minic} {Dé Sathairn} Go-IMPERSONAL to {the village} often Saturday \"People often go to the village of a Saturday.\" The difference between the autonomous and a true passive is that while the autonomous focuses on the action and overtly avoids mentioning the actor, there is nonetheless an anonymous agent who may be referred to in the sentence. For instance: Théití go[PAST.HAB.AUT] ag PROG ithe eat béile meal le chéile with each other Théití ag ithe béile {le chéile} go[PAST.HAB.AUT] PROG eat meal {with each other} \"People used to go  eating   a meal  together.\" In English, the formation of the passive allows the optional inclusion of an agent in a prepositional phrase, \"by the man\", etc. Where English would leave out the noun phrase, Irish uses the autonomous; where English includes the noun phrase, Irish uses its periphrastic passive – which can also leave out the noun phrase: Bhí Was an the tabac tobacco caite consumed (ag (by an the bhfear) man) Bhí an tabac caite (ag an bhfear) Was the tobacco consumed (by the man) \"The tobacco was smoked (by the man).\" The impersonal endings have been re-analysed as a passive voice inModern Welshand the agent can be included after the prepositiongan('by'): Some linguists draw a distinction between static (or stative) passive voice and dynamic (or eventive) passive voice in some languages. Examples includeEnglish,German,Swedish,SpanishandItalian. \"Static\" means that an action was, is, or will be done to the subject at a certain point in time that did, does, or will result in a state in the time focused upon, whereas \"dynamic\" means that an action was, is, or will be taking place.   For some speakers of English the dynamic passive constructed withgetis not accepted and is considered colloquial or sub-standard.  Dynamic passive in Swedish is also frequently expressed with the s-ending. Thevarapassive is often synonymous with, and sometimes preferable to, simply using the corresponding adjective: Theblipassive is often synonymous with, and sometimes preferable to, the s-passive: Spanishhas two verbs corresponding to Englishto be:serandestar.Seris used to form the ordinary (dynamic) passive voice: However, this construction is very unidiomatic. The usual passive voice is these pasiva, in which the verb is conjugated in the active voice, but preceded by theseparticle: Estaris used to form what might be termed a static passive voice (not regarded as a passive voice in traditionalSpanish grammar; it describes a state that is the result of an action): In theserandestarcases, the verb's participle is used as the complement (as is sometimes the case in English). Italianuses two verbs (essereandvenire) to translate the static and the dynamic passive: Dynamic passive auxiliary verb:essereandvenire(to beandto come) Static passive auxiliary verb:essere(to be) InVenetian(Vèneto) the difference between dynamic (true) passive and stative (adjectival) passive is more clear cut, usingèser(to be) only for the static passives andvegner(to become, to come) only for the dynamic passive: Static forms represents much more a property or general condition, whereas the dynamic form is a real passive action entailing \"by someone\": Voices found in various languages include: A particular language may use the same construction for several voices, such as the same form for passive and reflexive.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Voice_(grammar)", "https://en.wikipedia.org/wiki/Voice_(grammar)", "https://en.wikipedia.org/wiki/Voice_(grammar)", "https://en.wikipedia.org/wiki/Grammatical_category", "https://en.wikipedia.org/wiki/Animacy", "https://en.wikipedia.org/wiki/Grammatical_case", "https://en.wikipedia.org/wiki/Dative_construction", "https://en.wikipedia.org/wiki/Dative_shift"]},
{"id": "b67e73e50d93", "url": "https://en.wikipedia.org/wiki/World_Book_Capital", "title": "World Book Capital", "headings": ["Contents", "History", "Activities", "Nomination", "Nomination process", "Nomination criteria", "World Book Capital Cities commitment", "Cities designated World Book Capitals", "Madrid 2001", "Alexandria 2002", "New Delhi 2003", "Antwerp 2004", "Montreal 2005", "Turin 2006", "Bogotá 2007", "Amsterdam 2008", "Beirut 2009", "Ljubljana 2010", "Buenos Aires 2011", "Yerevan 2012", "Bangkok 2013", "Port Harcourt 2014", "Incheon 2015", "Wrocław 2016", "Conakry 2017", "Athens 2018", "Sharjah 2019", "Kuala Lumpur 2020", "Tbilisi 2021", "Sources", "References", "External links"], "content": "TheWorld Book Capital(WBC) is an initiative ofUNESCOwhich recognises cities for promoting books and fostering reading for a year starting on April 23,World Book and Copyright Day. Cities designated as UNESCO World Book Capital carry out activities with the aim of encouraging a culture of reading in all ages and sharing UNESCO's values. The nomination does not provide a financial prize. UNESCO adopted the 31c/Resolution 29, in 2001, establishing the World Book Capital programme and namingMadridas the first WBC city in 2001. The advisory committee is composed of UNESCO, theInternational Publishers Association, theInternational Federation of Library Associations and Institutions, the International Authors Forum and the International Booksellers Federation. Six years after the launching of theWorld Book and Copyright Day(23 April), and following the initiative inMadridin 2001 to create year-round celebrations around the event, the World Book Capital programme was created. UNESCO invited the professional organisations of the book chain: theInternational Publishers Association, theInternational Federation of Library Associations and Institutionsand the International Booksellers Federation to create a programme aimed at promoting books during the period betweenWorld Book and Copyright Days. Following a proposal of Spain, supported by many other countries, the UNESCO General Conference decided, on 2 November 2001, that the Organization would grant its moral and intellectual support to the conception and implementation of this initiative, by inviting the international professional organisations of the book chain to work together. The first UNESCO World Book Capital designated prior to the adoption of 31 C/Resolution 29 was Madrid (Spain) in 2001. An agreement was concluded among the partners that, after Madrid, the subsequent capitals would be Alexandria in 2002 and New Delhi in 2003. Cities designated as UNESCO World Book Capital carry out activities with the aim of encouraging a culture of reading and sharing UNESCO's values in all ages and population groups. Through the World Book Capital programme, UNESCO acknowledges the cities commitment for promoting books and fostering reading during a 12 months period. The programme aims to raise awareness for literacy and reading issues, through its numerous activities. World Book Capital brings together the local and national book industries and creates various initiatives with organisations and other stakeholders. The title is also used to draw national and international attention to the literary heritage of a city and nation. Every year, there is an Open Call for Applications published on the official website of UNESCO. The Open Call for Applications for 2024 was published in February 2022. The nomination does not include any financial prize; it acknowledges the best programmes dedicated to books and reading. The Director-General of UNESCO is responsible for the designation of the cities following both internal and external consultations with the other members of the Advisory Committee. The Advisory Committee is made up of one representative of the International Authors Forum (IAF), the International Federation of Library Associations and Institutions (IFLA), the International Publishers Association (IPA) and one UNESCO representative. The committee meets once a year. To ensure a balanced representation of all regions of the world, the Advisory Committee does not consider consecutive nominations of cities from the same region. Also, the Advisory Committee will only consider an application for a city in a country where another city has been a UNESCO World Book Capital if a period of 10 years or more has elapsed since the previous host city nomination. The nominating committee accepts programmes presented by or endorsed by the mayor of the city making the application that promote and foster reading. The programmes run from one World Book and Copyright Day and the next. Applicants' programme proposals will be evaluated using six criteria: By presenting its application each candidate city commits to: UNESCO and the Advisory Committee assist the chosen capital in the planning and implementation of its activity programme during the two years prior to its mandate as World Book Capital. The city is required to facilitate possible evaluation audits implemented on UNESCO's request.  If the work doesn't meet the panel's expectations, the Advisory Committee may withdraw the title from the city at any time during the monitoring phase, with one month's notice. The city authorities also agree to support the administrative work of the World Book Capital Secretariat by gathering financial contributions from potential donors or participating in the development of fundraising strategies. The following cities have been designated as World Book Capitals: Madridwas the first city to be awarded the title of the \"World Book Capital\". The Spanish capital took the initiative of creating this title and its first events. Numerous activities, around the theme of the popularisation of books and reading, were organised by different companies and organisations which collaborated to support the event. The existing Spanish Bookfair LIBER used Madrid's World Book Capital status as its theme for the year. During the year, the mountain \"La Puerta de Alcalà\" was covered with books. TheGreat Library of AlexandriainAlexandria, Egypt, was one of the largest and most significantlibraries of the ancient world. The library, first constructed in the 3rd Century BC, is the resource of knowledge and the first world centre of arts and sciences. It was the first library to invent a bibliographic system. Although it was destroyed several times, the government of Egypt built a newAlexandria Library. In 2002, the Egyptian city reopened its library and presented the new library theBibliotheca Alexandrina. This project was one of the main reasons Alexandria was selected as WBC, as it encouraged people to have an interest in reading. New Delhiis home to the largest number of publishers inIndia. It launched a programme to promote publishing linked to all professional associations and political and social actors concerned with books, including government services. Various activities were organised throughout the year, including establishments of book kiosks, libraries and a permanent book pavilion at Pragati Maidan. An emphasis was given to promoting literary habits among children. Other events were the Delhi Book Fair in August 2003, the two-day National Convention on \"Making India a Book Reading Society\" and the Children's Book Exhibition at various prominent schools in New Delhi. Theme: ABC 2004 The city ofAntwerpwas selected as World Book Capital for 2004. The chosen theme ABC 2004, evolved to XYZ 2005 in the second part of its programme where four exhibitions were devoted to the written heritage of the city. With a budget of 1.7 million euros, several literary projects took place throughout the year including word festivals, theatre street performances, public readings, celebrations ofauthors, letter-writing contests bymobile phone, publishing of books in collaboration with artists, exhibitions as well as free distribution of blank notebooks to encourage writing. Poems were printed on the wrappers of bread and were made available to the public. In the main hall ofDeSingel, Antwerp's international art and cultural centre, a metal cube was installed which housed a library. Theme: The Gathering Power of Books Montreal World Book Capital 2005 (MWBC) goal was to \"underline the gathering power of books\". The main objectives of MWBC 2005 were to increase reading habits especially among young people, encourage creative writing, stimulate the book industry and strengthenMontreal's position as an international cultural city. The activities were developed under the themes of books and reading, creativity, education and learning, remembrance and heritage, culture, celebration, and festivals. Authors includingMarie Laberge,Réjean Ducharme,Yann Martel,Mordecai Richler,Michel Tremblayhad their books highlighted during the year. Theme: Il Linguaggio dei Segni Turinwas designated World Book Capital, in collaboration withRome, from 22 April 2006 to 22 April 2007. The municipality of Rome contributed to the programme all year long. The additional WBC theme was: Turin, World Book Capital with Rome: cities to leaf through. The city focused its programme on the meaning of the different punctuation signs and was run by Fondazione per il libro, la musica e la cultura of Turin. Activities began in April 2006 with a poetic, literary, and musical evening, the \"Bookstock\". Throughout that day various personalities and artists including writers, poets, musicians, and people from the film industry performed in the city centre with approximately 4,000 spectators attending the event. Many events occurred during the year and the majority of them were under TWBC 2006's theme, the language of signs, which include: \"Il Punto Interrogativo\" (The Question Mark), \"La Virgola\"  (The Comma), \"I Due Punti\" (The Two Points), \"Il Punto exclamativo\" (The Exclamation Mark), \"I Pontini de Sospensione\" (The Suspension Points), \"Il Parentesi\"  (The  Brackets), \"Il Punto\" (The final Point), \"Le Virgolette\" (The Quotation Marks), \"ll Punto e Virgola\" (The semicolon), \"Il @\" (The @). The programme was made up of more than 800 network projects, organised not only in Turin but throughout the region of Piedmont as well. Among these events were book readings, literary festivals and awards, school writing sessions, theatres, opera, etc. Rome implemented cultural exchanges in thelibraries of Baghdad, Buenos Aires, Bogotá, Guatemala and Rwanda. The \"Casa delle Letterature\" (House of Literature), in collaboration with the Italian publisher \"Gorée di Siena\", has promoted the translation of a book produced by the children of Koh Phi Phi inThailand, struck by a tsunami. This book was distributed throughout Italy for the reconstruction of the destroyed school. Theme: We'll get Bogota Reading During the Bogotá World Book Capital, the top priorities were the development of a culture of reading for social inclusion, the promoting reading among children, young people and adults of the city, especially among those who had limited access. The chosen slogan was: \"We'll get Bogota reading.\" The city ofBogotáhosts an International Book Fair, held in April every year since 1988. The fair is considered to be the largest in the reading culture and publishing industry inLatin America. Various other initiatives were implemented on several fronts: the creation of the Consejo Distrital de Fomento de la Lectura (District Council for the Promotion of Reading), responsible for setting reading and writing policies in the city, the improvement of education with the development of a modem public library system, the cooperation with a variety of organisations in the public and private sectors, and the launching of programmes to popularise literature, such as Libro al Viento (\"Book in thé Wind\"). Theme: Open Book, Open Mind The programme ofAmsterdamWorld Book Capital, named 'Open Book, Open Mind', was centred around these three people:Spinoza,Anne FrankandAnnie M. G. Schmidt. In addition to the central theme, the programme carried out events towards the Municipal Council's three objectives: The first Amsterdam \"Book of the Night\" was created on March 20. Libraries, bookshops, the weekly book fair and hotel/catering venues around the Spui were filled with literary performances. Multiple authors and poets recited parts of their work for the people in the public square. Many events were targeted to the younger population and especially to children. From October 2008 to April 2009, citizens were encouraged to engage their children in the Children's Book Capital programme. Poetryalso held a significant part in the programme. During the \"Poetry in the Park\" project, ten city districts hosted poetry activities open to all district residents. An interactive exposition of \"poetry poles\" was held in the Vondelpark. Also, the National Declamation Competition launched on National Poetry Day, the 29th of January, the final round of which was carried out as part of the AWBC closing week. A total number of 298 activities were realised during this period with the aid of public networks and other institutions with 490,000 people taking part. The budget was estimated to reach above €2.7 million with 60% from government organisations and 40% from funds, sponsors and admission revenues. Themes: \"Books are our best friends. This year, Beirut is their capital.\", \"Beirut reads. Beirut writes. Beirut publishes. The triple identity of Beirut.\" The World Book Capital in 2009 wasBeirut, the capital ofLebanon. A series of activities were planned, from literary cafés to specialised fairs, international symposiums and conferences, writing workshops to all kinds of forums with a focus on Lebanese writers. The activities revolved around four themes: \"Books, vectors of culture\", \"Book trades\", \"Promotion of reading and writing\", \"Encourage youth to read\". Exhibitions honouring the great Lebanese and Arab writers also took place during this period. Other events included thematics such as Lebanon and the Alphabet, festivals of poetry, comics, storytelling, a professional book fair, conferences dealing with copyright, the future of books, translation, meetings with Mediterranean booksellers, competitions and prizes. Theme: \"In The Realm of the Book\" The programme incorporated objectives related to the promotion of reading books, the increase in the accessibility of books by all the population, the spread of the culture of reading and the introduction of different literary genres to the public.More than 300 activities were organised during theLjubljanaWorld Book Capital 2010 including: The World Book Capital programme during the year 2011 was held inBuenos AiresinArgentina. The project unit \"Unidad de Proyectos Buenos Aires Capital Mundial de Libro\" was created especially for the occasion and was run by Luciana Blasco. The three pillars of the Buenos Aires 2011 World book Capital were: Traditional yearly events such as the Night of the Bookstores, International Poetry Festival and Night of the Museums were enhanced for the occasion of World Book Capital. During that period 85 events were organised, 80% of which were free of charge. In addition, the suburbs of Buenos Aires organised community libraries and book events for local people. Historical authors, likeBorges,Lorca,Sabato, were celebrated. New event entries were added to theInternational Bookfairand Filba, a Buenos Aires literature festival. Also, international books were showcased, with the main presence ofFrenchandQuebecois literature. Unconventional spaces were utilised to attract new audiences. The Tower of Babel, designed by artist Marta Minujin, was a 25-metre tower made of 30,000 books in languages from all over the world. Approximately 115,000 books were distributed by buses as well as in subways, trams, and theatres. In addition, the tour of the city by bike included themes around poetry and reading Shakespeare. A website was also developed as a dissemination tool and served as a literary events diary for the year. The electronic newsletter managed to attract 20,000 subscribers. The programme was funded by different streams: the Ministry of Culture, civil society or private organisations, as well as the Metropolitan Fund for the Arts and the Patronage system. Theme: Eternity of the word The World Book Capital 2012 inYerevan, Armenia concurred with the country's 500th anniversary of \"Armenian printing\" as it was also celebrated in 2012. The schedule of the Yerevan World Book Capital 2012 programme emphasised \"the role of children and young adults in building knowledgeable societies\". Some of the events aimed at this objective were: \"Give us Books, Wings to Fly\", \"I Am Creating a Book\", \"Returning Books Back to Children\" and \"Colorful Books\". Another priority of the Yerevan World book Capital was to explore new technologies, ideas and innovations. Conferences, symposiums, and exhibitions were organised to discuss issues related to copyright, translation,freedom of speech, humanitarian and societal issues,genocideand internationally distinguished works of literature. Books about cinema, art, music and other art forms were also presented during exhibitions, seminars, and film premieres. Theme: Read for Life TheBangkokWorld Book Capital inThailand2013, the \"Read for Life\" programme focused on nine objectives: Numerous activities were organised all year long to reach these objectives. Bangkok collaborated with numerous organisations from the public and private sectors. Activities were run with departments in Bangkok, including those of education, healthcare, environment, social development, traffic control and 50 others. All sectors were also tied together under another theme, \"Thinking, Doing, Learning, Fixing, and Taking Responsibility Together.\" This stimulated mutual support and contribution from multiple stakeholders and associate networks like TK Park, The Publishers and Booksellers Association of Thailand, SCG, The Mirror Foundation, Chula Book Center, Thai Health Promotion Foundation, and more. Theme: Books: Windows to Our World of Possibilities Port Harcourtis the first city inSub-Saharan Africato win the title. The Rainbow Club organisation, a non-governmental organisation applied and won the bid on behalf of theNigerian Government. The theme of this year \"Books: Windows to Our World of Possibilities\", communicates the concept that reading books provides knowledge and exposure to new mentalities and ideas, as well as that it transports the reader to new worlds. Educating and cultivating citizens aimed at empowering them to protect democracy, promote social justice, and contribute to the development of their communities. Besides the main theme, other main objectives of the Port Harcourt World Book Capital 2014, were promotingNigerianandAfrican literature, fostering a reading culture among children and youth, and improving literacy rates. Book fairs and reading events took place throughout the year. The World Book Capital programme 2014 granted people access to more libraries and more literary activities in the city. The programme encouraged young people to use facts from their lives to tell their own stories, through the usage of technology and social media. This was achieved in several events: The Book Clubs, Reading Tree, Book-of-the-Month, exhibitions, amongst others. Other activities were: \"Library Support Programme\", a voluntary training by other adults and donations to modern school libraries which were recently created, \"Books on the Radio\", \"Television Show: Game Show-\" Know your World\", \" Monthly Drama performances\", \"The walking Book\", \"Ken Saro-Wiwa ‘Writer-Martyr Memorial Square’\", \"Introduction of a writers’ residency program\", \"Possibilities for Nigeria-Essay Contest as Nigeria turns 100\", \"Integration into existing state events\", etc. Theme:\"Books for all\" \"Read and Discover Yourself\" During the designated year, the public and private sectors inIncheon, South Korea, organised projects under the slogans \"Books for All\" and \"Read and Discover Yourself\". A total number of 45 projects were organised in 6 different domains: 1. Reading Culture in Daily Life 2. Invigorating the Publishing Industry 3. Renaissance of Humanities in Incheon 4. A City that Communicates Through Books 5. Commemorative Projects 6. Special Events Large scale events, such as the Korea Reading Festival and the Korean Library Association's General Conference, were organised and were met with extensive participation. The Incheon EduContent Fair introduced a place where education met with digital technology. It constituted a platform for global information sharing on the latest trends in related industries. This fair also presented the future of education with state-of-the-art technologies such as Smart Class and Hologram Class. Local libraries provided reading resources for different social groups, age groups, the less privileged. Events were held aimed to reignite interest in the humanities. People and companies supported the local libraries through book donations and voluntary work. According to the National Survey of Reading Habits, conducted by the Ministry of Culture, Sports and Tourism the number of books read by Incheon citizens in 2015 increased by around 47%. Theme: Read to me Wrocław ThePolishcity ofWrocławis the first city to be awarded both the World Book Capital andEuropean Capital of Culturetitles in the same year. With the slogan \"Read to me Wrocław\", Wrocław planned various cultural activities for participants of all ages. During theWorld Book and Copyright Day, on April 23, the event \"European Literature Night\" took place, which launched a special edition due to World Book Capital celebrations with a focus onWilliam Shakespeare. Excerpts from his works were read and interpreted in places all around the city by renown Polish actors, like: Ewa Skibińska,Magdalena Cielecka,Jan Nowicki,Arkadiusz Jakubikand Bartosz Porczyk. The Polish city of Wrocław also launched a composition competition in order to create a \"world book anthem\".This book hymn featured the words from the work ofTadeusz Rozewicz, the \"Petit cheveu du poète\". Tadeusz Rozewicz, the polish poet and playwright, died in Wrocław in 2014. His work was translated into hundreds of languages. Theme: Make Dreams Come True The capital of Guinea,Conakry, is the first city infrancophone Africato be nominated with the World Book Capital title. Until 2017, only threeAfricancities were appointed with the title:Alexandriain 2002,Port Harcourtin 2014 andConakryin 2017. At the time of Conakry's nomination, 60% of the Guinean population could not read. The project intended to fight illiteracy in Guinea, by helping young people and people from the rural areas get access to books. Higher literacy and stronger reading culture in schools, libraries, institutions and among the general public, were all primary priorities of the programme. Monthly cultural events focused on the country's authors and culture. In addition, a media library was built in each commune of Conakry and reading areas were established in every neighbourhood. Guinea's book industry benefited from the improved infrastructure and access to books, thanks to the new constructions for the World Book Capital programme. Theme: Books Everywhere The World Book Capital in 2018 was the capital ofGreece, Athens.This year's slogan was \"Books Everywhere\". The programme was based on 8 thematics: Each of these eight objectives was aligned with the main goal of the project to make books and culture accessible to everyone, residents or visitors, across all neighbourhoods of Athens. A total of 615 events and activities were realised during the designated year under the themes of; Celebrating Reading (234 events), A world of writers (international writers) (41 events), Greek writers (19 events), Athenian Book Itineraries (48 events), Open Collections and archives (43 events), Educational Activities (81 events), The Book and the Arts (114 events), and Contemporary Narratives (35 events). The programme cooperated with 212 cultural institutions, such as museums, embassies, foreign institutes, international organisations and non-governmental organisations. Inclusive and free of admission events were organised in public and private spaces across the seven municipal districts. Some of the programme initiatives were: moving and pop-up libraries, Bibliobuses- books on wheels, cultural performances and talks by esteemed authors from around the world, poetry readings, installations, festivals, exhibitions and many more. The programme reached about 450.000 residents and visitors of all backgrounds. Theme: Open Books, Open Minds The World Book Capital programme in 2019 was held inSharjah, thethird-most populous cityin theUnited Arab Emirates. The activities were developed under six pillars: The government along with non-government entities formed multiple activities such as poetry readings, singing and storytelling events in industrial workers accommodations. More than fifty libraries with books inUrdu,EnglishandTagalogwere gifted to industrial workers. Book Fairs and campaigns were also part of the programme. The yearlyInternational Book Fairis an 11-day international book fair held annually inSharjah. During the fair \"Give Your Book a New Life\", more than ten thousand books were available at symbolic prices to make reading affordable to people from every socioeconomic background. Also, a Book Donation Campaign was carried out, the \"Kan Ya Ma Kan\", which translates to Once Upon Time. Another popular campaign that combined reading and outdoor activities, was the Sharjah Beach Library campaign. Beach libraries were installed in Sharjah, filled with books for all ages, in various languages. During the year, many public offerings were commissioned, such as the House of Wisdom. This new library and cultural centre combined traditional and digital resources of knowledge, information, interactive learning and contemporary pedagogy. The House of Wisdom provides free and open access to people of all ages and nationalities. It extends over 12,000 square metres and includes two floors of libraries with more than 105,000 books, discussion halls, indoors and outdoors reading areas, as well as an education space designed for children. The Sharjah World book Capital contributed with initiatives and conversations at international book fairs inLondon,Turin, Moscow, as well as in the LIBER International Book Fair in Madrid 2019. Theme: KL Baca: Caring through Reading The World Book Capital 2020 was held inKuala LumpurinMalaysia.Under the slogan KL BACA: Caring through Reading, the organising committee stated that \"a city that reads is a city that cares\". The activities were organised around 5 streams: The overall themes of the initiatives of Kuala Lumpur World Book Capital 2020, besides Caring through Reading, were focused on Diversity and Environmental Rejuvenation. These two pillars were considered necessary in building a strategy aimed at sustainability. Theme: Ok. So your next book is…? The World Book Capital programme inTbilisiprimarily focused on new media and technologies as tools for reading facilitation and book promotion targeted towards young people. Events included book festivals, digital and sustainable book related activities. The main goal was to make reading more popular and accessible throughout each neighbourhood and age group. This article incorporates text from afree contentwork. Licensed under CC BY-SA 3.0 IGO (license statement/permission). Text taken fromUNESCO World Book Capital​, UNESCO. This article incorporates text from afree contentwork. Licensed under CC BY-SA 3.0 IGO (license statement/permission). Text taken fromUNESCO World Book Capital, Call for Applications 2024​, UNESCO.", "combined_text": "World Book Capital Contents History Activities Nomination Nomination process Nomination criteria World Book Capital Cities commitment Cities designated World Book Capitals Madrid 2001 Alexandria 2002 New Delhi 2003 Antwerp 2004 Montreal 2005 Turin 2006 Bogotá 2007 Amsterdam 2008 Beirut 2009 Ljubljana 2010 Buenos Aires 2011 Yerevan 2012 Bangkok 2013 Port Harcourt 2014 Incheon 2015 Wrocław 2016 Conakry 2017 Athens 2018 Sharjah 2019 Kuala Lumpur 2020 Tbilisi 2021 Sources References External links TheWorld Book Capital(WBC) is an initiative ofUNESCOwhich recognises cities for promoting books and fostering reading for a year starting on April 23,World Book and Copyright Day. Cities designated as UNESCO World Book Capital carry out activities with the aim of encouraging a culture of reading in all ages and sharing UNESCO's values. The nomination does not provide a financial prize. UNESCO adopted the 31c/Resolution 29, in 2001, establishing the World Book Capital programme and namingMadridas the first WBC city in 2001. The advisory committee is composed of UNESCO, theInternational Publishers Association, theInternational Federation of Library Associations and Institutions, the International Authors Forum and the International Booksellers Federation. Six years after the launching of theWorld Book and Copyright Day(23 April), and following the initiative inMadridin 2001 to create year-round celebrations around the event, the World Book Capital programme was created. UNESCO invited the professional organisations of the book chain: theInternational Publishers Association, theInternational Federation of Library Associations and Institutionsand the International Booksellers Federation to create a programme aimed at promoting books during the period betweenWorld Book and Copyright Days. Following a proposal of Spain, supported by many other countries, the UNESCO General Conference decided, on 2 November 2001, that the Organization would grant its moral and intellectual support to the conception and implementation of this initiative, by inviting the international professional organisations of the book chain to work together. The first UNESCO World Book Capital designated prior to the adoption of 31 C/Resolution 29 was Madrid (Spain) in 2001. An agreement was concluded among the partners that, after Madrid, the subsequent capitals would be Alexandria in 2002 and New Delhi in 2003. Cities designated as UNESCO World Book Capital carry out activities with the aim of encouraging a culture of reading and sharing UNESCO's values in all ages and population groups. Through the World Book Capital programme, UNESCO acknowledges the cities commitment for promoting books and fostering reading during a 12 months period. The programme aims to raise awareness for literacy and reading issues, through its numerous activities. World Book Capital brings together the local and national book industries and creates various initiatives with organisations and other stakeholders. The title is also used to draw national and international attention to the literary heritage of a city and nation. Every year, there is an Open Call for Applications published on the official website of UNESCO. The Open Call for Applications for 2024 was published in February 2022. The nomination does not include any financial prize; it acknowledges the best programmes dedicated to books and reading. The Director-General of UNESCO is responsible for the designation of the cities following both internal and external consultations with the other members of the Advisory Committee. The Advisory Committee is made up of one representative of the International Authors Forum (IAF), the International Federation of Library Associations and Institutions (IFLA), the International Publishers Association (IPA) and one UNESCO representative. The committee meets once a year. To ensure a balanced representation of all regions of the world, the Advisory Committee does not consider consecutive nominations of cities from the same region. Also, the Advisory Committee will only consider an application for a city in a country where another city has been a UNESCO World Book Capital if a period of 10 years or more has elapsed since the previous host city nomination. The nominating committee accepts programmes presented by or endorsed by the mayor of the city making the application that promote and foster reading. The programmes run from one World Book and Copyright Day and the next. Applicants' programme proposals will be evaluated using six criteria: By presenting its application each candidate city commits to: UNESCO and the Advisory Committee assist the chosen capital in the planning and implementation of its activity programme during the two years prior to its mandate as World Book Capital. The city is required to facilitate possible evaluation audits implemented on UNESCO's request.  If the work doesn't meet the panel's expectations, the Advisory Committee may withdraw the title from the city at any time during the monitoring phase, with one month's notice. The city authorities also agree to support the administrative work of the World Book Capital Secretariat by gathering financial contributions from potential donors or participating in the development of fundraising strategies. The following cities have been designated as World Book Capitals: Madridwas the first city to be awarded the title of the \"World Book Capital\". The Spanish capital took the initiative of creating this title and its first events. Numerous activities, around the theme of the popularisation of books and reading, were organised by different companies and organisations which collaborated to support the event. The existing Spanish Bookfair LIBER used Madrid's World Book Capital status as its theme for the year. During the year, the mountain \"La Puerta de Alcalà\" was covered with books. TheGreat Library of AlexandriainAlexandria, Egypt, was one of the largest and most significantlibraries of the ancient world. The library, first constructed in the 3rd Century BC, is the resource of knowledge and the first world centre of arts and sciences. It was the first library to invent a bibliographic system. Although it was destroyed several times, the government of Egypt built a newAlexandria Library. In 2002, the Egyptian city reopened its library and presented the new library theBibliotheca Alexandrina. This project was one of the main reasons Alexandria was selected as WBC, as it encouraged people to have an interest in reading. New Delhiis home to the largest number of publishers inIndia. It launched a programme to promote publishing linked to all professional associations and political and social actors concerned with books, including government services. Various activities were organised throughout the year, including establishments of book kiosks, libraries and a permanent book pavilion at Pragati Maidan. An emphasis was given to promoting literary habits among children. Other events were the Delhi Book Fair in August 2003, the two-day National Convention on \"Making India a Book Reading Society\" and the Children's Book Exhibition at various prominent schools in New Delhi. Theme: ABC 2004 The city ofAntwerpwas selected as World Book Capital for 2004. The chosen theme ABC 2004, evolved to XYZ 2005 in the second part of its programme where four exhibitions were devoted to the written heritage of the city. With a budget of 1.7 million euros, several literary projects took place throughout the year including word festivals, theatre street performances, public readings, celebrations ofauthors, letter-writing contests bymobile phone, publishing of books in collaboration with artists, exhibitions as well as free distribution of blank notebooks to encourage writing. Poems were printed on the wrappers of bread and were made available to the public. In the main hall ofDeSingel, Antwerp's international art and cultural centre, a metal cube was installed which housed a library. Theme: The Gathering Power of Books Montreal World Book Capital 2005 (MWBC) goal was to \"underline the gathering power of books\". The main objectives of MWBC 2005 were to increase reading habits especially among young people, encourage creative writing, stimulate the book industry and strengthenMontreal's position as an international cultural city. The activities were developed under the themes of books and reading, creativity, education and learning, remembrance and heritage, culture, celebration, and festivals. Authors includingMarie Laberge,Réjean Ducharme,Yann Martel,Mordecai Richler,Michel Tremblayhad their books highlighted during the year. Theme: Il Linguaggio dei Segni Turinwas designated World Book Capital, in collaboration withRome, from 22 April 2006 to 22 April 2007. The municipality of Rome contributed to the programme all year long. The additional WBC theme was: Turin, World Book Capital with Rome: cities to leaf through. The city focused its programme on the meaning of the different punctuation signs and was run by Fondazione per il libro, la musica e la cultura of Turin. Activities began in April 2006 with a poetic, literary, and musical evening, the \"Bookstock\". Throughout that day various personalities and artists including writers, poets, musicians, and people from the film industry performed in the city centre with approximately 4,000 spectators attending the event. Many events occurred during the year and the majority of them were under TWBC 2006's theme, the language of signs, which include: \"Il Punto Interrogativo\" (The Question Mark), \"La Virgola\"  (The Comma), \"I Due Punti\" (The Two Points), \"Il Punto exclamativo\" (The Exclamation Mark), \"I Pontini de Sospensione\" (The Suspension Points), \"Il Parentesi\"  (The  Brackets), \"Il Punto\" (The final Point), \"Le Virgolette\" (The Quotation Marks), \"ll Punto e Virgola\" (The semicolon), \"Il @\" (The @). The programme was made up of more than 800 network projects, organised not only in Turin but throughout the region of Piedmont as well. Among these events were book readings, literary festivals and awards, school writing sessions, theatres, opera, etc. Rome implemented cultural exchanges in thelibraries of Baghdad, Buenos Aires, Bogotá, Guatemala and Rwanda. The \"Casa delle Letterature\" (House of Literature), in collaboration with the Italian publisher \"Gorée di Siena\", has promoted the translation of a book produced by the children of Koh Phi Phi inThailand, struck by a tsunami. This book was distributed throughout Italy for the reconstruction of the destroyed school. Theme: We'll get Bogota Reading During the Bogotá World Book Capital, the top priorities were the development of a culture of reading for social inclusion, the promoting reading among children, young people and adults of the city, especially among those who had limited access. The chosen slogan was: \"We'll get Bogota reading.\" The city ofBogotáhosts an International Book Fair, held in April every year since 1988. The fair is considered to be the largest in the reading culture and publishing industry inLatin America. Various other initiatives were implemented on several fronts: the creation of the Consejo Distrital de Fomento de la Lectura (District Council for the Promotion of Reading), responsible for setting reading and writing policies in the city, the improvement of education with the development of a modem public library system, the cooperation with a variety of organisations in the public and private sectors, and the launching of programmes to popularise literature, such as Libro al Viento (\"Book in thé Wind\"). Theme: Open Book, Open Mind The programme ofAmsterdamWorld Book Capital, named 'Open Book, Open Mind', was centred around these three people:Spinoza,Anne FrankandAnnie M. G. Schmidt. In addition to the central theme, the programme carried out events towards the Municipal Council's three objectives: The first Amsterdam \"Book of the Night\" was created on March 20. Libraries, bookshops, the weekly book fair and hotel/catering venues around the Spui were filled with literary performances. Multiple authors and poets recited parts of their work for the people in the public square. Many events were targeted to the younger population and especially to children. From October 2008 to April 2009, citizens were encouraged to engage their children in the Children's Book Capital programme. Poetryalso held a significant part in the programme. During the \"Poetry in the Park\" project, ten city districts hosted poetry activities open to all district residents. An interactive exposition of \"poetry poles\" was held in the Vondelpark. Also, the National Declamation Competition launched on National Poetry Day, the 29th of January, the final round of which was carried out as part of the AWBC closing week. A total number of 298 activities were realised during this period with the aid of public networks and other institutions with 490,000 people taking part. The budget was estimated to reach above €2.7 million with 60% from government organisations and 40% from funds, sponsors and admission revenues. Themes: \"Books are our best friends. This year, Beirut is their capital.\", \"Beirut reads. Beirut writes. Beirut publishes. The triple identity of Beirut.\" The World Book Capital in 2009 wasBeirut, the capital ofLebanon. A series of activities were planned, from literary cafés to specialised fairs, international symposiums and conferences, writing workshops to all kinds of forums with a focus on Lebanese writers. The activities revolved around four themes: \"Books, vectors of culture\", \"Book trades\", \"Promotion of reading and writing\", \"Encourage youth to read\". Exhibitions honouring the great Lebanese and Arab writers also took place during this period. Other events included thematics such as Lebanon and the Alphabet, festivals of poetry, comics, storytelling, a professional book fair, conferences dealing with copyright, the future of books, translation, meetings with Mediterranean booksellers, competitions and prizes. Theme: \"In The Realm of the Book\" The programme incorporated objectives related to the promotion of reading books, the increase in the accessibility of books by all the population, the spread of the culture of reading and the introduction of different literary genres to the public.More than 300 activities were organised during theLjubljanaWorld Book Capital 2010 including: The World Book Capital programme during the year 2011 was held inBuenos AiresinArgentina. The project unit \"Unidad de Proyectos Buenos Aires Capital Mundial de Libro\" was created especially for the occasion and was run by Luciana Blasco. The three pillars of the Buenos Aires 2011 World book Capital were: Traditional yearly events such as the Night of the Bookstores, International Poetry Festival and Night of the Museums were enhanced for the occasion of World Book Capital. During that period 85 events were organised, 80% of which were free of charge. In addition, the suburbs of Buenos Aires organised community libraries and book events for local people. Historical authors, likeBorges,Lorca,Sabato, were celebrated. New event entries were added to theInternational Bookfairand Filba, a Buenos Aires literature festival. Also, international books were showcased, with the main presence ofFrenchandQuebecois literature. Unconventional spaces were utilised to attract new audiences. The Tower of Babel, designed by artist Marta Minujin, was a 25-metre tower made of 30,000 books in languages from all over the world. Approximately 115,000 books were distributed by buses as well as in subways, trams, and theatres. In addition, the tour of the city by bike included themes around poetry and reading Shakespeare. A website was also developed as a dissemination tool and served as a literary events diary for the year. The electronic newsletter managed to attract 20,000 subscribers. The programme was funded by different streams: the Ministry of Culture, civil society or private organisations, as well as the Metropolitan Fund for the Arts and the Patronage system. Theme: Eternity of the word The World Book Capital 2012 inYerevan, Armenia concurred with the country's 500th anniversary of \"Armenian printing\" as it was also celebrated in 2012. The schedule of the Yerevan World Book Capital 2012 programme emphasised \"the role of children and young adults in building knowledgeable societies\". Some of the events aimed at this objective were: \"Give us Books, Wings to Fly\", \"I Am Creating a Book\", \"Returning Books Back to Children\" and \"Colorful Books\". Another priority of the Yerevan World book Capital was to explore new technologies, ideas and innovations. Conferences, symposiums, and exhibitions were organised to discuss issues related to copyright, translation,freedom of speech, humanitarian and societal issues,genocideand internationally distinguished works of literature. Books about cinema, art, music and other art forms were also presented during exhibitions, seminars, and film premieres. Theme: Read for Life TheBangkokWorld Book Capital inThailand2013, the \"Read for Life\" programme focused on nine objectives: Numerous activities were organised all year long to reach these objectives. Bangkok collaborated with numerous organisations from the public and private sectors. Activities were run with departments in Bangkok, including those of education, healthcare, environment, social development, traffic control and 50 others. All sectors were also tied together under another theme, \"Thinking, Doing, Learning, Fixing, and Taking Responsibility Together.\" This stimulated mutual support and contribution from multiple stakeholders and associate networks like TK Park, The Publishers and Booksellers Association of Thailand, SCG, The Mirror Foundation, Chula Book Center, Thai Health Promotion Foundation, and more. Theme: Books: Windows to Our World of Possibilities Port Harcourtis the first city inSub-Saharan Africato win the title. The Rainbow Club organisation, a non-governmental organisation applied and won the bid on behalf of theNigerian Government. The theme of this year \"Books: Windows to Our World of Possibilities\", communicates the concept that reading books provides knowledge and exposure to new mentalities and ideas, as well as that it transports the reader to new worlds. Educating and cultivating citizens aimed at empowering them to protect democracy, promote social justice, and contribute to the development of their communities. Besides the main theme, other main objectives of the Port Harcourt World Book Capital 2014, were promotingNigerianandAfrican literature, fostering a reading culture among children and youth, and improving literacy rates. Book fairs and reading events took place throughout the year. The World Book Capital programme 2014 granted people access to more libraries and more literary activities in the city. The programme encouraged young people to use facts from their lives to tell their own stories, through the usage of technology and social media. This was achieved in several events: The Book Clubs, Reading Tree, Book-of-the-Month, exhibitions, amongst others. Other activities were: \"Library Support Programme\", a voluntary training by other adults and donations to modern school libraries which were recently created, \"Books on the Radio\", \"Television Show: Game Show-\" Know your World\", \" Monthly Drama performances\", \"The walking Book\", \"Ken Saro-Wiwa ‘Writer-Martyr Memorial Square’\", \"Introduction of a writers’ residency program\", \"Possibilities for Nigeria-Essay Contest as Nigeria turns 100\", \"Integration into existing state events\", etc. Theme:\"Books for all\" \"Read and Discover Yourself\" During the designated year, the public and private sectors inIncheon, South Korea, organised projects under the slogans \"Books for All\" and \"Read and Discover Yourself\". A total number of 45 projects were organised in 6 different domains: 1. Reading Culture in Daily Life 2. Invigorating the Publishing Industry 3. Renaissance of Humanities in Incheon 4. A City that Communicates Through Books 5. Commemorative Projects 6. Special Events Large scale events, such as the Korea Reading Festival and the Korean Library Association's General Conference, were organised and were met with extensive participation. The Incheon EduContent Fair introduced a place where education met with digital technology. It constituted a platform for global information sharing on the latest trends in related industries. This fair also presented the future of education with state-of-the-art technologies such as Smart Class and Hologram Class. Local libraries provided reading resources for different social groups, age groups, the less privileged. Events were held aimed to reignite interest in the humanities. People and companies supported the local libraries through book donations and voluntary work. According to the National Survey of Reading Habits, conducted by the Ministry of Culture, Sports and Tourism the number of books read by Incheon citizens in 2015 increased by around 47%. Theme: Read to me Wrocław ThePolishcity ofWrocławis the first city to be awarded both the World Book Capital andEuropean Capital of Culturetitles in the same year. With the slogan \"Read to me Wrocław\", Wrocław planned various cultural activities for participants of all ages. During theWorld Book and Copyright Day, on April 23, the event \"European Literature Night\" took place, which launched a special edition due to World Book Capital celebrations with a focus onWilliam Shakespeare. Excerpts from his works were read and interpreted in places all around the city by renown Polish actors, like: Ewa Skibińska,Magdalena Cielecka,Jan Nowicki,Arkadiusz Jakubikand Bartosz Porczyk. The Polish city of Wrocław also launched a composition competition in order to create a \"world book anthem\".This book hymn featured the words from the work ofTadeusz Rozewicz, the \"Petit cheveu du poète\". Tadeusz Rozewicz, the polish poet and playwright, died in Wrocław in 2014. His work was translated into hundreds of languages. Theme: Make Dreams Come True The capital of Guinea,Conakry, is the first city infrancophone Africato be nominated with the World Book Capital title. Until 2017, only threeAfricancities were appointed with the title:Alexandriain 2002,Port Harcourtin 2014 andConakryin 2017. At the time of Conakry's nomination, 60% of the Guinean population could not read. The project intended to fight illiteracy in Guinea, by helping young people and people from the rural areas get access to books. Higher literacy and stronger reading culture in schools, libraries, institutions and among the general public, were all primary priorities of the programme. Monthly cultural events focused on the country's authors and culture. In addition, a media library was built in each commune of Conakry and reading areas were established in every neighbourhood. Guinea's book industry benefited from the improved infrastructure and access to books, thanks to the new constructions for the World Book Capital programme. Theme: Books Everywhere The World Book Capital in 2018 was the capital ofGreece, Athens.This year's slogan was \"Books Everywhere\". The programme was based on 8 thematics: Each of these eight objectives was aligned with the main goal of the project to make books and culture accessible to everyone, residents or visitors, across all neighbourhoods of Athens. A total of 615 events and activities were realised during the designated year under the themes of; Celebrating Reading (234 events), A world of writers (international writers) (41 events), Greek writers (19 events), Athenian Book Itineraries (48 events), Open Collections and archives (43 events), Educational Activities (81 events), The Book and the Arts (114 events), and Contemporary Narratives (35 events). The programme cooperated with 212 cultural institutions, such as museums, embassies, foreign institutes, international organisations and non-governmental organisations. Inclusive and free of admission events were organised in public and private spaces across the seven municipal districts. Some of the programme initiatives were: moving and pop-up libraries, Bibliobuses- books on wheels, cultural performances and talks by esteemed authors from around the world, poetry readings, installations, festivals, exhibitions and many more. The programme reached about 450.000 residents and visitors of all backgrounds. Theme: Open Books, Open Minds The World Book Capital programme in 2019 was held inSharjah, thethird-most populous cityin theUnited Arab Emirates. The activities were developed under six pillars: The government along with non-government entities formed multiple activities such as poetry readings, singing and storytelling events in industrial workers accommodations. More than fifty libraries with books inUrdu,EnglishandTagalogwere gifted to industrial workers. Book Fairs and campaigns were also part of the programme. The yearlyInternational Book Fairis an 11-day international book fair held annually inSharjah. During the fair \"Give Your Book a New Life\", more than ten thousand books were available at symbolic prices to make reading affordable to people from every socioeconomic background. Also, a Book Donation Campaign was carried out, the \"Kan Ya Ma Kan\", which translates to Once Upon Time. Another popular campaign that combined reading and outdoor activities, was the Sharjah Beach Library campaign. Beach libraries were installed in Sharjah, filled with books for all ages, in various languages. During the year, many public offerings were commissioned, such as the House of Wisdom. This new library and cultural centre combined traditional and digital resources of knowledge, information, interactive learning and contemporary pedagogy. The House of Wisdom provides free and open access to people of all ages and nationalities. It extends over 12,000 square metres and includes two floors of libraries with more than 105,000 books, discussion halls, indoors and outdoors reading areas, as well as an education space designed for children. The Sharjah World book Capital contributed with initiatives and conversations at international book fairs inLondon,Turin, Moscow, as well as in the LIBER International Book Fair in Madrid 2019. Theme: KL Baca: Caring through Reading The World Book Capital 2020 was held inKuala LumpurinMalaysia.Under the slogan KL BACA: Caring through Reading, the organising committee stated that \"a city that reads is a city that cares\". The activities were organised around 5 streams: The overall themes of the initiatives of Kuala Lumpur World Book Capital 2020, besides Caring through Reading, were focused on Diversity and Environmental Rejuvenation. These two pillars were considered necessary in building a strategy aimed at sustainability. Theme: Ok. So your next book is…? The World Book Capital programme inTbilisiprimarily focused on new media and technologies as tools for reading facilitation and book promotion targeted towards young people. Events included book festivals, digital and sustainable book related activities. The main goal was to make reading more popular and accessible throughout each neighbourhood and age group. This article incorporates text from afree contentwork. Licensed under CC BY-SA 3.0 IGO (license statement/permission). Text taken fromUNESCO World Book Capital​, UNESCO. This article incorporates text from afree contentwork. Licensed under CC BY-SA 3.0 IGO (license statement/permission). Text taken fromUNESCO World Book Capital, Call for Applications 2024​, UNESCO.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/World_Book_Capital", "https://en.wikipedia.org/wiki/World_Book_Capital", "https://en.wikipedia.org/wiki/World_Book_Capital", "https://en.wikipedia.org/wiki/UNESCO", "https://en.wikipedia.org/wiki/Madrid", "https://en.wikipedia.org/wiki/Rio_de_Janeiro", "https://en.wikipedia.org/wiki/UNESCO", "https://en.wikipedia.org/wiki/World_Book_Day"]},
{"id": "225afc582e95", "url": "https://en.wikipedia.org/wiki/List_of_soft-skinned_vehicles_of_the_US_military", "title": "List of soft-skinned vehicles of the US military", "headings": ["Contents", "Vehicles", "See also", "Notes", "References", "Citations", "Bibliography"], "content": " Thislist of soft-skinned vehicles of the United States militaryis a list ofsoft-skinned vehiclemodelsthat have seen active service in theUnited States Armed Forces, includingmilitary trucks,motorcycles,side-by-sidesandtractors.", "combined_text": "List of soft-skinned vehicles of the US military Contents Vehicles See also Notes References Citations Bibliography  Thislist of soft-skinned vehicles of the United States militaryis a list ofsoft-skinned vehiclemodelsthat have seen active service in theUnited States Armed Forces, includingmilitary trucks,motorcycles,side-by-sidesandtractors.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/List_of_soft-skinned_vehicles_of_the_US_military", "https://en.wikipedia.org/wiki/List_of_soft-skinned_vehicles_of_the_US_military", "https://en.wikipedia.org/wiki/List_of_soft-skinned_vehicles_of_the_US_military", "https://en.wikipedia.org/wiki/Red_Ball_Express", "https://en.wikipedia.org/wiki/Soft-skinned_vehicle", "https://en.wikipedia.org/wiki/United_States_Armed_Forces", "https://en.wikipedia.org/wiki/Motorcycle", "https://en.wikipedia.org/wiki/Side-by-side_(vehicle)"]},
{"id": "3a75e7572948", "url": "https://en.wikipedia.org/wiki/List_of_National_Historic_Landmarks_in_New_York", "title": "List of National Historic Landmarks in New York", "headings": ["Contents", "Overview", "Current National Historic Landmarks in Upstate and Long Island", "Current NHLs in New York City", "Historic areas in the United States National Park System", "NHLs formerly located in New York", "Former NHLs in New York", "See also", "Notes", "References", "External links"], "content": "  This is a list ofNational Historic Landmarksand comparable other historic sites designated by the U.S. government in the U.S. state ofNew York.  The United States National Historic Landmark (NHL) program operates under the auspices of theNational Park Service, and recognizes buildings, structures, objects, sites and districts of resources according to a list of criteria of national significance.There are 277 NHLs inNew Yorkstate, which is more than 10 percent of all the NHLs nationwide, and the most of any state.The National Park Service also has listed 20 National Monuments, National Historic Sites, National Memorials, and other sites as being historic landmarks of national importance,of which 7 are also designated NHLs. All of these historic landmarks are covered in this list. There are 139 NHLs inupstate New York, 13 onLong Island, and 116 withinNew York City(NYC).  Three counties have ten or more NHLs:New York County(Manhattan) has 86;Westchester County, just north of NYC, has 19; andErie Countyin western New York has 10. Twelve other counties have five to nine NHLs, eight have three or four, 27 counties have one or two, and the remaining twelve ofthe state's 62 countieshave none. The first New York NHLs were eight designated on October 9, 1960; the latest was designated on January 13, 2021. The NHLs and other landmarks outside NYC are listed below; the NHLs in NYC are inthis companion article. Seven NHL sites are among the 20 National Park System historic areas in New York state.The other 13 National Park Service areas are also historic landmark sites of national importance, but are already protected by Federal ownership and administration, so NHL designation is unnecessary. A list of these National Park Service areas that conserve historic sites in New York State is also provided. Finally, three former NHLs in the state are also listed. New York State NHLs include ten prehistoric or otherarcheological sites,12 historical Dutch farmhouses, manors, and historic districts,and 21 architecturally and/or historically important churches or houses of worship.Fully 26 NHLs are primarily military, including 13 fort sites (five standing forts, three fortified houses, and five ruins),five other battlegrounds,seven military headquarters, training facilities, arsenals and armories,and one military shipwreck site.One of these NHLs is associated with theAmerican Civil War,while all the rest of these forts and other military places are associated with theFrench and Indian Warand/or theAmerican Revolutionary War. There are nine NHL ships, including a warship and a tugboat that served inWorld War II, one warship that saw combat in theVietnam War, three sailing boats, twofireboatsand alightvessel.Salient in the list are 24 mansions,and four sites primarily significant for their architectural landscaping.Many properties, numbering in the thousands, arecontributing or non-contributing structuresin the state's nineNational Historic Landmark Districts.Intellectual accomplishments of New Yorkers are associated with 22 sites, including nine university buildings,ten other NHLs associated with inventions, inventors or scientists,and four engineering landmarks, including two bridges that were once the longest of their types.Commercial accomplishments include 11 historic skyscrapers, five of which were once the tallest in the world,seven stock exchanges and other buildings important incommercial history,two bank buildings,five industrial facilities,and three water-basedcivil engineeringworks.Two are architectural oddities. Political and social accomplishments are represented by four former mental care institutions (a legacy of the state's leading role in mental health care),14 sites associated withsuffragettesor other women leaders,fiveUnderground Railroador other sites associated withabolitionists,six sites associated with African-American leaders,three sites associated with labor rights,and four sites associated with other social activism.In addition, there are 21 homes of other national leaders,and six government buildings that are significant on a national scale.Community, arts and entertainment accomplishments represented include twoutopiancommunes,theAdirondack Parkand four of itsGreat Camps,and five other retreat sites.No fewer than nine artist homes or studios are landmarked,as well as nine homes of writers and composers.There are four club buildings, of which two are historical societies,and eight entertainment venues or sites associated with entertainers.Sixteen others are unique sites that are difficult to classify. Notable architects whose work is represented in the NHLs of the state include:Alexander Jackson Davis(7 sites),Andrew Jackson Downing(2),William West Durant(2),Leopold Eidlitz(2),Cass Gilbert(2),Henry J. Hardenbergh(2),Raymond Hood(3),Philip Hooker(2),Minard Lafever(7),John McComb Jr.(3),Frederick Law Olmsted(3),Isaac G. Perry(2),George B. Post(3),James Renwick Jr.(4),Henry Hobson Richardson(2),Louis Sullivan(2),Richard Upjohn(6),Calvert Vaux(6),andFrederick Clarke Withers(2).The firmMcKim, Mead, and Whiteparticipated in design of at least six buildings later declared to be NHLs.It was also that firm's work,Pennsylvania Station, whose pending demolition in 1963 launched a historic preservation movement in New York City and led to creation of theNew York City Landmarks Preservation Commissionin 1965. TheStateofNew York, exclusive of NYC, is home to 155 of these landmarks, which are tabulated here.  Twenty-three of these are also State Historic Sites (SHS), and fourteen are National Park System areas; these designations are indicated in italics. New York City alone is home to 116 NHLs. The earliest was designated on October 9, 1960; the latest was designated on November 2, 2016.  Many of the NHLs in NYC are also landmarked individually or as part of districts by theNew York City Landmarks Preservation Commission. SeeList of New York City Designated Landmarks. National Historic Sites, National Historic Parks, National Memorials, and certain otherareas listed in the National Park systemare historic landmarks of national importance that are highly protected already, often before the inauguration of the NHL program in 1960.  There are 20 of these in New York State.  The legislation establishing the National Historic Landmark program does not prevent these from being designated,but in practice these are not often named NHLsper se, due to administrative costs of their nomination and to the low preservation value of designating them. For the first 16 years of the National Historic Landmarks program, the National Park Service did not consider any sites already within the National Park system for NHL designation, and in fact if an NHL-designated site came into the NPS system it was de-designated. In New York State, theWilliam Floyd Housewithin theFire Island National SeashoreandEllis Islandwithin theStatue of Liberty National Monumentwere both deemed NHL-eligible by the advisory board but were not designated. It was not until 1977 that a policy was promulgated that would allow for designation of a National Historic Landmark \"whose primary significance is not related to its park's purpose\".TheJacob Riis Housein Queens was de-designated in 1973. The National Park Service identifies 18 historic sites within national park units in New York State, and lists these together with the NHLs in the state,and there are also two National Historic Sites that are \"affiliated areas,\" receiving National Park Service support but not directly administered by it.Seven of the 20 were declared National Historic Landmarks, in several instances before receiving the higher protection designation, and retain their NHL standing.  Four of these are listed above and three are included withinthe New York City list of NHLs.  The 13 others are: There are four other National Park Service areas in New York State that do not have historic standing. The following Landmarks were located in New York at the time they were declared National Historic Landmarks, but have since moved to other states. The following sites in New York were formerly National Historic Landmarks but were delisted.", "combined_text": "List of National Historic Landmarks in New York Contents Overview Current National Historic Landmarks in Upstate and Long Island Current NHLs in New York City Historic areas in the United States National Park System NHLs formerly located in New York Former NHLs in New York See also Notes References External links   This is a list ofNational Historic Landmarksand comparable other historic sites designated by the U.S. government in the U.S. state ofNew York.  The United States National Historic Landmark (NHL) program operates under the auspices of theNational Park Service, and recognizes buildings, structures, objects, sites and districts of resources according to a list of criteria of national significance.There are 277 NHLs inNew Yorkstate, which is more than 10 percent of all the NHLs nationwide, and the most of any state.The National Park Service also has listed 20 National Monuments, National Historic Sites, National Memorials, and other sites as being historic landmarks of national importance,of which 7 are also designated NHLs. All of these historic landmarks are covered in this list. There are 139 NHLs inupstate New York, 13 onLong Island, and 116 withinNew York City(NYC).  Three counties have ten or more NHLs:New York County(Manhattan) has 86;Westchester County, just north of NYC, has 19; andErie Countyin western New York has 10. Twelve other counties have five to nine NHLs, eight have three or four, 27 counties have one or two, and the remaining twelve ofthe state's 62 countieshave none. The first New York NHLs were eight designated on October 9, 1960; the latest was designated on January 13, 2021. The NHLs and other landmarks outside NYC are listed below; the NHLs in NYC are inthis companion article. Seven NHL sites are among the 20 National Park System historic areas in New York state.The other 13 National Park Service areas are also historic landmark sites of national importance, but are already protected by Federal ownership and administration, so NHL designation is unnecessary. A list of these National Park Service areas that conserve historic sites in New York State is also provided. Finally, three former NHLs in the state are also listed. New York State NHLs include ten prehistoric or otherarcheological sites,12 historical Dutch farmhouses, manors, and historic districts,and 21 architecturally and/or historically important churches or houses of worship.Fully 26 NHLs are primarily military, including 13 fort sites (five standing forts, three fortified houses, and five ruins),five other battlegrounds,seven military headquarters, training facilities, arsenals and armories,and one military shipwreck site.One of these NHLs is associated with theAmerican Civil War,while all the rest of these forts and other military places are associated with theFrench and Indian Warand/or theAmerican Revolutionary War. There are nine NHL ships, including a warship and a tugboat that served inWorld War II, one warship that saw combat in theVietnam War, three sailing boats, twofireboatsand alightvessel.Salient in the list are 24 mansions,and four sites primarily significant for their architectural landscaping.Many properties, numbering in the thousands, arecontributing or non-contributing structuresin the state's nineNational Historic Landmark Districts.Intellectual accomplishments of New Yorkers are associated with 22 sites, including nine university buildings,ten other NHLs associated with inventions, inventors or scientists,and four engineering landmarks, including two bridges that were once the longest of their types.Commercial accomplishments include 11 historic skyscrapers, five of which were once the tallest in the world,seven stock exchanges and other buildings important incommercial history,two bank buildings,five industrial facilities,and three water-basedcivil engineeringworks.Two are architectural oddities. Political and social accomplishments are represented by four former mental care institutions (a legacy of the state's leading role in mental health care),14 sites associated withsuffragettesor other women leaders,fiveUnderground Railroador other sites associated withabolitionists,six sites associated with African-American leaders,three sites associated with labor rights,and four sites associated with other social activism.In addition, there are 21 homes of other national leaders,and six government buildings that are significant on a national scale.Community, arts and entertainment accomplishments represented include twoutopiancommunes,theAdirondack Parkand four of itsGreat Camps,and five other retreat sites.No fewer than nine artist homes or studios are landmarked,as well as nine homes of writers and composers.There are four club buildings, of which two are historical societies,and eight entertainment venues or sites associated with entertainers.Sixteen others are unique sites that are difficult to classify. Notable architects whose work is represented in the NHLs of the state include:Alexander Jackson Davis(7 sites),Andrew Jackson Downing(2),William West Durant(2),Leopold Eidlitz(2),Cass Gilbert(2),Henry J. Hardenbergh(2),Raymond Hood(3),Philip Hooker(2),Minard Lafever(7),John McComb Jr.(3),Frederick Law Olmsted(3),Isaac G. Perry(2),George B. Post(3),James Renwick Jr.(4),Henry Hobson Richardson(2),Louis Sullivan(2),Richard Upjohn(6),Calvert Vaux(6),andFrederick Clarke Withers(2).The firmMcKim, Mead, and Whiteparticipated in design of at least six buildings later declared to be NHLs.It was also that firm's work,Pennsylvania Station, whose pending demolition in 1963 launched a historic preservation movement in New York City and led to creation of theNew York City Landmarks Preservation Commissionin 1965. TheStateofNew York, exclusive of NYC, is home to 155 of these landmarks, which are tabulated here.  Twenty-three of these are also State Historic Sites (SHS), and fourteen are National Park System areas; these designations are indicated in italics. New York City alone is home to 116 NHLs. The earliest was designated on October 9, 1960; the latest was designated on November 2, 2016.  Many of the NHLs in NYC are also landmarked individually or as part of districts by theNew York City Landmarks Preservation Commission. SeeList of New York City Designated Landmarks. National Historic Sites, National Historic Parks, National Memorials, and certain otherareas listed in the National Park systemare historic landmarks of national importance that are highly protected already, often before the inauguration of the NHL program in 1960.  There are 20 of these in New York State.  The legislation establishing the National Historic Landmark program does not prevent these from being designated,but in practice these are not often named NHLsper se, due to administrative costs of their nomination and to the low preservation value of designating them. For the first 16 years of the National Historic Landmarks program, the National Park Service did not consider any sites already within the National Park system for NHL designation, and in fact if an NHL-designated site came into the NPS system it was de-designated. In New York State, theWilliam Floyd Housewithin theFire Island National SeashoreandEllis Islandwithin theStatue of Liberty National Monumentwere both deemed NHL-eligible by the advisory board but were not designated. It was not until 1977 that a policy was promulgated that would allow for designation of a National Historic Landmark \"whose primary significance is not related to its park's purpose\".TheJacob Riis Housein Queens was de-designated in 1973. The National Park Service identifies 18 historic sites within national park units in New York State, and lists these together with the NHLs in the state,and there are also two National Historic Sites that are \"affiliated areas,\" receiving National Park Service support but not directly administered by it.Seven of the 20 were declared National Historic Landmarks, in several instances before receiving the higher protection designation, and retain their NHL standing.  Four of these are listed above and three are included withinthe New York City list of NHLs.  The 13 others are: There are four other National Park Service areas in New York State that do not have historic standing. The following Landmarks were located in New York at the time they were declared National Historic Landmarks, but have since moved to other states. The following sites in New York were formerly National Historic Landmarks but were delisted.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/List_of_National_Historic_Landmarks_in_New_York", "https://en.wikipedia.org/wiki/List_of_National_Historic_Landmarks_in_New_York", "https://en.wikipedia.org/wiki/List_of_National_Historic_Landmarks_in_New_York", "https://en.wikipedia.org/wiki/List_of_National_Historic_Landmarks_in_New_York_City", "https://en.wikipedia.org/wiki/New_York_State_Capitol", "https://en.wikipedia.org/wiki/National_Historic_Landmark", "https://en.wikipedia.org/wiki/National_Historic_Landmark", "https://en.wikipedia.org/wiki/New_York_State"]},
{"id": "b9e426dffd99", "url": "https://en.wikipedia.org/wiki/Two_Morrows_Publishing", "title": "TwoMorrows Publishing", "headings": ["Contents", "List of magazines", "History", "Jack Kirby Collector", "Other magazines", "Books and DVDs", "References", "External links"], "content": " TwoMorrows Publishingis a publisher of magazines about comic books, founded in 1994 by John and Pam Morrow out of their small advertising agency inRaleigh, North Carolina, United States. Its products also include books and DVDs. TwoMorrows publishes the following magazines: Defunct magazines include After the death of comics creatorJack Kirby, lifelong Kirby fan John Morrow and his wife Pam contacted Roz Kirby, the artist's widow, about an ongoing magazine devoted to her husband's work and legacy. She gave it her authorization. Jack Kirby Collectorwas first published in limited quantities as a small, black-and-white magazine focusing on Kirby artwork and articles by Morrow and a few fellow collectors and fans. As each issue grew in size, it began to include rare or previously unpublished Kirby art, as well asuninkedpencil versions of published art. Soon the magazine was being published on better paper, with glossy color covers. New and veteran comics artists were given the chance to ink reproductions of Kirby's original pencil work. Each issue carried the notation \"Fully Authorized by the Kirby Estate\". The magazine went on to be nominated for several awards. First issue was published September 5, 1994. The Morrows launched fundraiser projects to fund the preservation of thethermostaticcopies of Kirby's uninked pencils by scanning over 5,000 pages and cleaning them for future researchers and readers. Jack Kirby CollectorcontributorJon B. Cookeapproached the two Morrows about launching another magazine that would cover the comics of the 1960s and 1970s. This magazine,Comic Book Artist, launched under the TwoMorrows imprint in 1998 and would go on to win severalEisner Awards. TwoMorrows also picked upComicology, a magazine devoted to current comics, and which lasted four issues. TwoMorrows expanded again with a revival of former Marvel editor-in-chiefRoy Thomas1960s fanzine,Alter Ego— initially as aflip bookwithComic Book Artist, then in 1999 as a standalone publication. In 2001, TwoMorrows launchedDraw!a magazine edited by animation and comics artistMike Manleythat centered on how-to and related articles for cartoonists and animators. At the same time, comics author and editorDanny FingerothstartedWrite Now, a magazine of how to write comics and animation. In 2003, Jon B. Cooke left TwoMorrows to takeComic Book Artistto another publisher,Top Shelf Productions. The Morrows hired former comics writer and editorMichael Eury, author of the bookCaptain Action, to launch a successor publication. The new title,Back Issue!, debuted in 2003.Rough Stuffmagazine, a spin-off ofBack Issue!, focusing on previously unpublished penciled pages, preliminary sketches, detailed layouts and unused inked artwork debuted in July 2006. TwoMorrows has also published several books devoted to comics and comic history. The first  was the Eisner Award-winningtrade paperbackStreetwise, a collection of autobiographical stories by such creators asJack Kirby,Sergio Aragones,Sam Glanzman,Murphy Anderson, andNick Cardy. Others includeTheWarrenCompanionandTheFawcettCompanion, chronicling the histories of the defunct publishers;Kimota! TheMiraclemanCompanion, about theBritish comic bookcharacter;G-Force Animated: The OfficialBattle of the Planetsbook, detailing the animated TV series; and threeThe All Star Companionsby Roy Thomas,The Legion Companion, andThe  Justice League Companion, and several other books devoted toGolden AgeandSilver Age of comic bookstitles and heroes. Along with books devoted to such artists asMurphy Anderson,Dick Giordano,George Tuska,Gene Colan,Wally Wood, andKurt Schaffenberger, as well as to writerAlan Moore, TwoMorrows has published books about how comics are created,  such asPanel Discussions,Comics Above Ground, andActing with a Pencil. Additionally, the company has published three collections of columns on comics by writerMark Evanier; checklists of the works of Kirby and Wood; and the \"Modern Masters\" series by writer-editor Eric Nolan-Weathington. In 2006, TwoMorrows expanded into DVDs by producing an art-instruction video, and a DVD version of the company'sGeorge PérezModern Mastersbook.", "combined_text": "TwoMorrows Publishing Contents List of magazines History Jack Kirby Collector Other magazines Books and DVDs References External links  TwoMorrows Publishingis a publisher of magazines about comic books, founded in 1994 by John and Pam Morrow out of their small advertising agency inRaleigh, North Carolina, United States. Its products also include books and DVDs. TwoMorrows publishes the following magazines: Defunct magazines include After the death of comics creatorJack Kirby, lifelong Kirby fan John Morrow and his wife Pam contacted Roz Kirby, the artist's widow, about an ongoing magazine devoted to her husband's work and legacy. She gave it her authorization. Jack Kirby Collectorwas first published in limited quantities as a small, black-and-white magazine focusing on Kirby artwork and articles by Morrow and a few fellow collectors and fans. As each issue grew in size, it began to include rare or previously unpublished Kirby art, as well asuninkedpencil versions of published art. Soon the magazine was being published on better paper, with glossy color covers. New and veteran comics artists were given the chance to ink reproductions of Kirby's original pencil work. Each issue carried the notation \"Fully Authorized by the Kirby Estate\". The magazine went on to be nominated for several awards. First issue was published September 5, 1994. The Morrows launched fundraiser projects to fund the preservation of thethermostaticcopies of Kirby's uninked pencils by scanning over 5,000 pages and cleaning them for future researchers and readers. Jack Kirby CollectorcontributorJon B. Cookeapproached the two Morrows about launching another magazine that would cover the comics of the 1960s and 1970s. This magazine,Comic Book Artist, launched under the TwoMorrows imprint in 1998 and would go on to win severalEisner Awards. TwoMorrows also picked upComicology, a magazine devoted to current comics, and which lasted four issues. TwoMorrows expanded again with a revival of former Marvel editor-in-chiefRoy Thomas1960s fanzine,Alter Ego— initially as aflip bookwithComic Book Artist, then in 1999 as a standalone publication. In 2001, TwoMorrows launchedDraw!a magazine edited by animation and comics artistMike Manleythat centered on how-to and related articles for cartoonists and animators. At the same time, comics author and editorDanny FingerothstartedWrite Now, a magazine of how to write comics and animation. In 2003, Jon B. Cooke left TwoMorrows to takeComic Book Artistto another publisher,Top Shelf Productions. The Morrows hired former comics writer and editorMichael Eury, author of the bookCaptain Action, to launch a successor publication. The new title,Back Issue!, debuted in 2003.Rough Stuffmagazine, a spin-off ofBack Issue!, focusing on previously unpublished penciled pages, preliminary sketches, detailed layouts and unused inked artwork debuted in July 2006. TwoMorrows has also published several books devoted to comics and comic history. The first  was the Eisner Award-winningtrade paperbackStreetwise, a collection of autobiographical stories by such creators asJack Kirby,Sergio Aragones,Sam Glanzman,Murphy Anderson, andNick Cardy. Others includeTheWarrenCompanionandTheFawcettCompanion, chronicling the histories of the defunct publishers;Kimota! TheMiraclemanCompanion, about theBritish comic bookcharacter;G-Force Animated: The OfficialBattle of the Planetsbook, detailing the animated TV series; and threeThe All Star Companionsby Roy Thomas,The Legion Companion, andThe  Justice League Companion, and several other books devoted toGolden AgeandSilver Age of comic bookstitles and heroes. Along with books devoted to such artists asMurphy Anderson,Dick Giordano,George Tuska,Gene Colan,Wally Wood, andKurt Schaffenberger, as well as to writerAlan Moore, TwoMorrows has published books about how comics are created,  such asPanel Discussions,Comics Above Ground, andActing with a Pencil. Additionally, the company has published three collections of columns on comics by writerMark Evanier; checklists of the works of Kirby and Wood; and the \"Modern Masters\" series by writer-editor Eric Nolan-Weathington. In 2006, TwoMorrows expanded into DVDs by producing an art-instruction video, and a DVD version of the company'sGeorge PérezModern Mastersbook.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/TwoMorrows_Publishing", "https://en.wikipedia.org/wiki/TwoMorrows_Publishing", "https://en.wikipedia.org/wiki/TwoMorrows_Publishing", "https://en.wikipedia.org/wiki/Raleigh,_North_Carolina", "https://en.wikipedia.org/wiki/Diamond_Book_Distributors", "https://en.wikipedia.org/wiki/Raleigh,_North_Carolina", "https://en.wikipedia.org/wiki/Alter_Ego_(magazine)", "https://en.wikipedia.org/wiki/Back_Issue!"]},
{"id": "b0d7201cc08e", "url": "https://en.wikipedia.org/wiki/You_Wouldn%27t_Steal_a_Car", "title": "You Wouldn't Steal a Car", "headings": ["Contents", "Copyright concerns", "In popular culture", "See also", "References", "Further reading"], "content": " \"You Wouldn't Steal a Car\" is the first sentence and commonly used name of apublic service announcementthat debuted on July 12, 2004 in theaters,and July 27 on home media, which was part of the anti-copyright infringementcampaign \"Piracy. It's a crime.\" It was a co-production between theFederation Against Copyright Theftand theMotion Picture Association of America(now the MPA) in collaboration with theIntellectual Property Office of Singapore,and appeared in theaters internationally from 2004 until 2008, and on many commercial DVDs during the same period as an ad preceding themain menu, as either an unskippable or skippable video. The announcement depicts either a teenage girl trying to illegally download a film, or two women attempting to buy DVDs from abootleggeron the streets. In both versions, clips are interwoven of a man committingtheftof various objects (which include a car, handbag, and DVD in both versions, plus a television or mobile phone depending on the version), and equates these crimes to theunauthorized duplication and distributionof copyrighted materials, such as films. The ad ends with either a message that downloading pirated films is stealing, or buying pirated copies of films is stealing, which is against the law.The girl ultimately cancels the download and the couple choose not to purchase any of the bootleg DVDs. According to theCanadian Internet Policy and Public Interest Clinic, the announcement was unsuccessful and was largely a source of ridicule.Likewise, a 2022behavioral economicspaper published inThe Information Societyfound the PSAs may, in fact, have increased piracy rates.By 2009, over 100 parodies of the announcement had been created. It was reported that the music in the announcement was itself used without permission.However, one source disputes this, saying the reporting is the result ofconflationregarding a different anti-piracy ad that used stolen music composed in 2006. The \"ransom note\" typeface used in the campaign was FF Confidential, designed by the Dutch typographerJust van Rossum. Concerns have been expressed that the copy of the font used to design the commercial may not have been properly licensed.In April 2025,Sky Newsconfirmed via extraction from old campaign PDFs that the actual font used was Xband-Rough, a widely-distributed pirated version of FF Confidential. Van Rossum was aware of the font Xband-Rough, but unaware that the advert has used the pirated font and described its use as \"hilarious.” TheFederation Against Copyright Theftresponded by saying that everyone involved in the creation of the announcement was no longer at the organization. The advertisement has been parodied inInternet memes, including those using the phrase \"You wouldn't download a car.\" In 2007,The IT Crowdepisode \"Moss and the German\" parodied the advertisement, mirroring its initial points before comparing copyright infringement to increasingly ludicrous crimes and consequences.Finlo Rohrer of theBBCconsidered this version to be \"perhaps the best known\" of over 100 parodies of the ad that had been created by 2009.In 2021, the olddomain nameused by the campaign (piracyisacrime.com) was purchased andredirectedto a YouTube upload of the parody, possibly inspired by aRedditdiscussion. An advertisement for the 2008 filmFuturama: Bender's Gameparodied the campaign by havingBenderrepeatedly interrupt the narrator to say he would do the crimes described. The advertisement was titled \"Downloading Often Is Terrible\", or \"D.O.I.T\". TheGreens–European Free Alliance, in association withRafilm, released their own parody version of the film to oppose the media industry and government views on existing copyright laws, as well as to educate the public on alternative views about intellectual property. In 2017,The Juice Mediaproduced a controversial parody of the video forAustralia Day. The video compared the celebration of Australia Day, which marks the arrival of theFirst Fleetand is often referred to as \"Invasion Day\" by Indigenous Australians, to celebrating theNazis'Final Solution, dropping theatomic bomb on Hiroshimaand theSeptember 11 attacks. \"You wouldn't screenshot an NFT\" is a variant of the \"You wouldn't steal a car\" meme that satirizesnon-fungible tokens,based on the idea that the ease of making digital copies of the work of art associated with an NFT undermines the value of purchasing the NFT.", "combined_text": "You Wouldn't Steal a Car Contents Copyright concerns In popular culture See also References Further reading  \"You Wouldn't Steal a Car\" is the first sentence and commonly used name of apublic service announcementthat debuted on July 12, 2004 in theaters,and July 27 on home media, which was part of the anti-copyright infringementcampaign \"Piracy. It's a crime.\" It was a co-production between theFederation Against Copyright Theftand theMotion Picture Association of America(now the MPA) in collaboration with theIntellectual Property Office of Singapore,and appeared in theaters internationally from 2004 until 2008, and on many commercial DVDs during the same period as an ad preceding themain menu, as either an unskippable or skippable video. The announcement depicts either a teenage girl trying to illegally download a film, or two women attempting to buy DVDs from abootleggeron the streets. In both versions, clips are interwoven of a man committingtheftof various objects (which include a car, handbag, and DVD in both versions, plus a television or mobile phone depending on the version), and equates these crimes to theunauthorized duplication and distributionof copyrighted materials, such as films. The ad ends with either a message that downloading pirated films is stealing, or buying pirated copies of films is stealing, which is against the law.The girl ultimately cancels the download and the couple choose not to purchase any of the bootleg DVDs. According to theCanadian Internet Policy and Public Interest Clinic, the announcement was unsuccessful and was largely a source of ridicule.Likewise, a 2022behavioral economicspaper published inThe Information Societyfound the PSAs may, in fact, have increased piracy rates.By 2009, over 100 parodies of the announcement had been created. It was reported that the music in the announcement was itself used without permission.However, one source disputes this, saying the reporting is the result ofconflationregarding a different anti-piracy ad that used stolen music composed in 2006. The \"ransom note\" typeface used in the campaign was FF Confidential, designed by the Dutch typographerJust van Rossum. Concerns have been expressed that the copy of the font used to design the commercial may not have been properly licensed.In April 2025,Sky Newsconfirmed via extraction from old campaign PDFs that the actual font used was Xband-Rough, a widely-distributed pirated version of FF Confidential. Van Rossum was aware of the font Xband-Rough, but unaware that the advert has used the pirated font and described its use as \"hilarious.” TheFederation Against Copyright Theftresponded by saying that everyone involved in the creation of the announcement was no longer at the organization. The advertisement has been parodied inInternet memes, including those using the phrase \"You wouldn't download a car.\" In 2007,The IT Crowdepisode \"Moss and the German\" parodied the advertisement, mirroring its initial points before comparing copyright infringement to increasingly ludicrous crimes and consequences.Finlo Rohrer of theBBCconsidered this version to be \"perhaps the best known\" of over 100 parodies of the ad that had been created by 2009.In 2021, the olddomain nameused by the campaign (piracyisacrime.com) was purchased andredirectedto a YouTube upload of the parody, possibly inspired by aRedditdiscussion. An advertisement for the 2008 filmFuturama: Bender's Gameparodied the campaign by havingBenderrepeatedly interrupt the narrator to say he would do the crimes described. The advertisement was titled \"Downloading Often Is Terrible\", or \"D.O.I.T\". TheGreens–European Free Alliance, in association withRafilm, released their own parody version of the film to oppose the media industry and government views on existing copyright laws, as well as to educate the public on alternative views about intellectual property. In 2017,The Juice Mediaproduced a controversial parody of the video forAustralia Day. The video compared the celebration of Australia Day, which marks the arrival of theFirst Fleetand is often referred to as \"Invasion Day\" by Indigenous Australians, to celebrating theNazis'Final Solution, dropping theatomic bomb on Hiroshimaand theSeptember 11 attacks. \"You wouldn't screenshot an NFT\" is a variant of the \"You wouldn't steal a car\" meme that satirizesnon-fungible tokens,based on the idea that the ease of making digital copies of the work of art associated with an NFT undermines the value of purchasing the NFT.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/You_Wouldn%27t_Steal_a_Car", "https://en.wikipedia.org/wiki/You_Wouldn%27t_Steal_a_Car", "https://en.wikipedia.org/wiki/You_Wouldn%27t_Steal_a_Car", "https://en.wikipedia.org/wiki/Public_service_announcement", "https://en.wikipedia.org/wiki/Copyright_infringement", "https://en.wikipedia.org/wiki/Federation_Against_Copyright_Theft", "https://en.wikipedia.org/wiki/Motion_Picture_Association", "https://en.wikipedia.org/wiki/Intellectual_Property_Office_of_Singapore"]},
{"id": "aadceabb1f66", "url": "https://en.wikipedia.org/wiki/Woody_debris_(disambiguation)", "title": "Woody debris", "headings": ["Contents", "See also"], "content": "Woody debrismay refer to:", "combined_text": "Woody debris Contents See also Woody debrismay refer to:", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Woody_debris", "https://en.wikipedia.org/wiki/Woody_debris", "https://en.wikipedia.org/wiki/Woody_debris", "https://en.wikipedia.org/wiki/Slash_(logging)", "https://en.wikipedia.org/wiki/Coarse_woody_debris", "https://en.wikipedia.org/wiki/Large_woody_debris", "https://en.wikipedia.org/wiki/Log_jam", "https://en.wikipedia.org/wiki/Dead_wood_(disambiguation)"]},
{"id": "9ed78b9f4ba3", "url": "https://en.wikipedia.org/wiki/North_Atlantic_Treaty_Organization", "title": "NATO", "headings": ["Contents", "History", "20th century", "21st century", "Military operations", "Early operations", "Bosnia and Herzegovina intervention", "Kosovo intervention", "War in Afghanistan", "Iraq training mission", "Gulf of Aden anti-piracy", "Libya intervention", "Turkish border", "Eastern flank", "Membership", "Special arrangements", "Enlargement", "NATO defence expenditure", "Partnerships with third countries", "Structure", "Legal authority of NATO commanders", "See also", "Similar organizations", "References", "Works cited", "Further reading", "External links"], "content": " TheNorth Atlantic Treaty Organization(NATO/ˈneɪtoʊ/NAY-toh;French:Organisation du traité de l'Atlantique Nord,OTAN), also called theNorth Atlantic Alliance, is anintergovernmentalmilitary alliancebetween32 member states—30 inEuropeand 2 inNorth America. Founded in theaftermath of World War II, NATO was established with the signing of theNorth Atlantic Treatyin 1949. The organization serves as a system ofcollective security, whereby its independent member states agree to mutual defence in response to an attack by any outside party. This is enshrined in Article 5 of the treaty, which states that an armed attack against one member shall be considered an attack against them all. Throughout theCold War, NATO's primary purpose was to deter and counter the threat posed by theSoviet Unionand itssatellite states, which formed the rivalWarsaw Pactin 1955. Following thedissolution of the Soviet Unionin 1991, the alliance adapted, conducting its first major military interventionsin Bosnia and Herzegovina(1992–1995) andYugoslavia(1999). Article 5 was invoked for the first and only time after theSeptember 11 attacks, leading to the deployment of NATO troops toAfghanistanas part of theInternational Security Assistance Force(ISAF). The alliance has since been involved in a range of roles, includingtraining in Iraq,intervention in Libyain 2011, andcountering piracy. Since the end of the Cold War, the alliance hasaccepted sixteen new members, incorporating formerWarsaw Pactcountries andpost-Soviet states. NATO and Russiahave co-operated, but Russian leaders have called this eastward enlargement a threat to its security interests, andoppose Ukraine joiningNATO.  TheRussian annexation of Crimeain 2014 prompted strong condemnation from NATO and a renewed focus on collective defence. Russia'sfull-scale invasion of Ukrainein 2022 led to a major reinforcement of NATO's eastern flank and causedFinlandandSwedento abandon their neutral status and join the alliance. NATO recognizesBosnia and Herzegovina,UkraineandGeorgiaas aspiring members. NATO's main headquartersare inBrussels, Belgium, whileits military headquartersare nearMons, Belgium. The combined militaries of all NATO members include approximately 3.5 million soldiers and personnel. Their combined military spending constitutes over half of theglobal total. Members have committed to a target of spending at least 5% of theirgross domestic product(GDP) on defence to ensure the alliance's continued military readiness. NATO has its roots in theAtlantic Charter, a 1941 agreement between the United States and United Kingdom.  The Charter laid out a framework for international cooperation without territorial expansion afterWorld War II.On 4 March 1947, theTreaty of Dunkirkwas signed by France and the United Kingdom during theaftermath of World War IIand thestart of the Cold Waras aTreaty of Alliance and Mutual Assistancein the event of possible attacks by Germany. In March 1948, this alliance was expanded in theTreaty of Brusselsto include theBeneluxcountries, forming the Brussels Treaty Organization, commonly known as theWestern Union.Talks for a wider military alliance, which could include North America, also began that month in the United States, where their foreign policy under theTruman Doctrineset out in 1947 promoted international solidarity against actions they saw as communist aggression, such as theFebruary 1948 coup d'état in Czechoslovakia. These talks resulted in the signature of theNorth Atlantic Treatyon 4 April 1949 by the member states of the Western Union plus the United States, Canada, Portugal, Italy, Norway, Denmark, and Iceland.Canadian diplomatLester B. Pearsonwas a key author and drafter of the treaty. The North Atlantic Treaty was largely dormant until theKorean Warinitiated the establishment of NATO to implement it with an integrated military structure. This included the formation ofSupreme Headquarters Allied Powers Europe(SHAPE) in 1951, which adopted many of the Western Union's military structures and plans,including theiragreements on standardizing equipmentandagreements on stationing foreign military forcesin European countries. In 1952, the post ofSecretary General of NATOwas established as the organization's chief civilian. That year also saw the first major NATOmaritime exercises,Exercise Mainbraceand the accession ofGreeceandTurkeyto the organization.Following theLondon and Paris Conferences,West Germanywas permitted to rearm militarily, as they joined NATO in May 1955, which was, in turn, a major factor in the creation of the Soviet-dominatedWarsaw Pact, delineating the two opposing sides of theCold War. The building of theBerlin Wallin 1961 marked a height in Cold War tensions, when 400,000 US troops were stationed in Europe.Doubts over the strength of the relationship between the European states and the United States ebbed and flowed, along with doubts over the credibility of the NATO defence against a prospective Soviet invasion – doubts that led to the development of theindependent French nuclear deterrentand the withdrawal ofFrancefrom NATO's military structure in 1966.In 1982, the newly democratic Spain joined the alliance. TheRevolutions of 1989in Europe led to a strategic re-evaluation of NATO's purpose, nature, tasks, and focus on the continent. In October 1990,East Germanybecame part of the Federal Republic of Germanyand the alliance, and in November 1990, the alliance signed theTreaty on Conventional Armed Forces in Europe(CFE) in Paris with the Soviet Union. It mandated specific military reductions across the continent, which continued after the collapse of theWarsaw Pactin February 1991 and thedissolution of the Soviet Unionthat December, which removed thede factomain adversaries of NATO.This began a drawdown of military spending and equipment in Europe. The CFE treaty allowed signatories to remove 52,000 pieces of conventional armaments in the following sixteen years,and allowed military spending by NATO's European members to decline by 28 percent from 1990 to 2015.In 1990, several Western leaders gave assurances toMikhail Gorbachevthat NATO would not expand further east, as revealed by memoranda of private conversations. In the 1990s, the organization extended its activities into political and humanitarian situations that had not formerly been NATO concerns.During thebreakup of Yugoslavia, the organization conducted its firstmilitary interventionsinBosnia from 1992 to 1995and laterYugoslavia in 1999. Politically, the organization sought better relations with the newly autonomousCentral and Eastern Europeanstates, and diplomatic forums for regional cooperation between NATO and its neighbours were set up during this post-Cold War period, including thePartnership for Peaceand theMediterranean Dialogueinitiative in 1994, theEuro-Atlantic Partnership Councilin 1997, and theNATO–Russia Permanent Joint Councilin 1998. At the1999 Washington summit,Hungary,Poland, and theCzech Republicofficially joined NATO, and the organization also issued new guidelines for membership with individualized \"Membership Action Plans\". These plans governed the subsequent addition of new alliance members. Article 5 of the North Atlantic treaty, requiring member states to come to the aid of any member state subject to an armed attack, was invoked for the first and only time after theSeptember 11 attacks,after which troops were deployed toAfghanistanunder the NATO-ledISAF. The organization has operated a range of additional roles since then, including sendingtrainers to Iraq, assisting incounter-piracy operations. The election of French presidentNicolas Sarkozyin 2007 led to a major reform of France's military position, culminating with the return to full membership on 4 April 2009, which also included France rejoining theNATO Military Command Structure, while maintaining an independent nuclear deterrent. The 2014Russian annexation of Crimealed to strong condemnation by all NATO members,and was one of the seven times thatArticle 4, which calls for consultation among NATO members, has been invoked. Prior times included during theIraq WarandSyrian civil war.At the2014 Wales summit, the leaders of NATO's member states formally committed for the first time to spend the equivalent of at least two percent of theirgross domestic productson defence by 2024, which had previously been only an informal guideline. At the2016 Warsaw summit, NATO countries agreed on the creation ofNATO Enhanced Forward Presence, which deployed four multinational battalion-sized battlegroups in Estonia, Latvia, Lithuania, and Poland.Before and during the2022 Russian invasion of Ukraine, several NATO countries sent ground troops, warships and fighter aircraft to reinforce the alliance's eastern flank, and multiple countries again invoked Article 4.In March 2022, NATO leaders met at Brussels for anextraordinary summitwhich also involvedGroup of Sevenand European Union leaders.NATO member states agreed to establish four additional battlegroups in Bulgaria, Hungary, Romania, and Slovakia,and elements of theNATO Response Forcewere activated for the first time in NATO's history. As of June 2022, NATO had deployed 40,000 troops along its 2,500-kilometre-long (1,550 mi) Eastern flank to deter Russian aggression. More than half of this number have been deployed in Bulgaria, Romania, Hungary, Slovakia, and Poland, which five countries muster a considerable combined ex-NATO force of 259,000 troops. To supplement Bulgaria's Air Force, Spain sentEurofighter Typhoons, the Netherlands sent eightF-35attack aircraft, and additional French and US attack aircraft would arrive soon as well.In 2025, Germany stationed a full armoured brigade in Lithuania. No military operations were conducted by NATO during the Cold War. Following the end of the Cold War, the first operations,Anchor Guardin 1990 andAce Guardin 1991, were prompted by theIraqi invasion of Kuwait. Airborne early warning aircraft were sent to provide coverage of southeastern Turkey, and later a quick-reaction force was deployed to the area. TheBosnian Warbegan in 1992, as a result of thebreakup of Yugoslavia. The deteriorating situation led toUnited Nations Security Council Resolution 816on 9 October 1992, authorizing its member-states to enforce a previously declaredno-fly zoneunder theUnited Nations Protection Forceover central Bosnia and Herzegovina. NATO complied and started enforcing the ban on 12 April 1993 withOperation Deny Flight. From June 1993 until October 1996,Operation Sharp Guardadded maritime enforcement of thearms embargoandeconomic sanctionsagainst theFederal Republic of Yugoslavia. On 28 February 1994, NATO took its first wartime action byshooting down four Bosnian Serb aircraftviolating the no-fly zone. On 10 and 11 April 1994, the United Nations Protection Force called in air strikes to protect theGoraždesafe area, resulting in the bombing of a Bosnian Serb military command outpost near Goražde by two USF-16jets acting under NATO direction.In retaliation, Serbs took 150 U.N. personnel hostage on 14 April.On 16 April a BritishSea Harrierwas shot down over Goražde by Serb forces. In August 1995, a two-week NATO bombing campaign,Operation Deliberate Force, began against theArmy of the Republika Srpska, after theSrebrenica genocide.Further NATO air strikes helped bring theYugoslav Warsto an end, resulting in theDayton Agreementin November 1995.As part of this agreement, NATO deployed a UN-mandated peacekeeping force, underOperation Joint Endeavor, namedIFOR. Almost 60,000 NATO troops were joined by forces from non-NATO countries in this peacekeeping mission. This transitioned into the smallerSFOR, which started with 32,000 troops initially and ran from December 1996 until December 2004, when operations were then passed onto theEuropean Union Force Althea.Following the lead of its member states, NATO began to award a service medal, theNATO Medal, for these operations. In an effort to stopSlobodan Milošević's Serbian-led crackdown onKLAseparatists and Albanian civilians inKosovo, theUnited Nations Security CouncilpassedResolution 1199on 23 September 1998 to demand a ceasefire. Negotiations under US Special EnvoyRichard Holbrookebroke down on 23 March 1999, and he handed the matter to NATO,which acted on protecting regional security and started a 78-day bombing campaign on 24 March 1999.Operation Allied Force targeted the military capabilities of what was then theFederal Republic of Yugoslavia. During the crisis, NATO also deployed one of its international reaction forces, theACE Mobile Force (Land), to Albania as the Albania Force (AFOR), to deliver humanitarian aid to refugees from Kosovo. The campaign was and has been criticized overits civilian casualties, including the bombing of theChinese embassy in Belgrade, and overwhether it had legitimacy. The US, the UK, and most other NATO countries opposed efforts to require the UN Security Council to approve NATO military strikes, such as the action against Serbia in 1999, while France and some othersclaimed that the alliance needed UN approval.The US/UK side claimed that this would undermine the authority of the alliance, and they noted that Russia and China would have exercised their Security Council vetoes to block the strike onYugoslavia, and could do the same in future conflicts where NATO intervention was required, thus nullifying the entire potency and purpose of the organization. Recognizing the post-Cold War military environment, NATO adopted the Alliance Strategic Concept during itsWashington summitin April 1999 that emphasized conflict prevention and crisis management. Milošević finally accepted the terms of an international peace plan on 3 June 1999, ending theKosovo War. On 11 June, Milošević further acceptedUN resolution 1244, under the mandate of which NATO then helped establish theKFORpeacekeeping force. Nearly one million refugees had fled Kosovo, and part of KFOR's mandate was to protect the humanitarian missions, in addition to deterring violence.In August–September 2001, the alliance also mountedOperation Essential Harvest, a mission disarming ethnic Albanian militias in the Republic of Macedonia.As of 2023, around 4,500 KFOR soldiers, representing 27 countries, continue to operate in the area. TheSeptember 11 attacksin the United States caused NATO to invokeArticle 5of the NATO Charter for the first time in the organization's history.The Article states that an attack on any member shall be considered to be an attack on all. The invocation was confirmed on 4 October 2001 when NATO determined that the attacks were indeed eligible under the terms of the North Atlantic Treaty.The eight official actions taken by NATO in response to the attacks includedOperation Eagle AssistandOperation Active Endeavour, a naval operation in the Mediterranean Sea designed to prevent the movement of terrorists or weapons of mass destruction, and to enhance the security of shipping in general, which began on 4 October 2001. The alliance showed unity: on 16 April 2003, NATO agreed to take command of theInternational Security Assistance Force(ISAF), which included troops from 42 countries. The decision came at the request of Germany and the Netherlands, the two countries leading ISAF at the time of the agreement, and all nineteen NATO ambassadors approved it unanimously. The handover of control to NATO took place on 11 August, and marked the first time in NATO's history that it took charge of a mission outside the north Atlantic area. ISAF was initially charged with securingKabuland surrounding areas from theTaliban,al Qaedaand factional warlords, so as to allow for the establishment of theAfghan Transitional Administrationheaded byHamid Karzai. In October 2003, the UN Security Council authorized the expansion of the ISAF mission throughout Afghanistan,and ISAF subsequently expanded the mission in four main stages over the whole of the country. On 31 July 2006, the ISAF additionally took overmilitary operations in the south of Afghanistanfrom a US-led anti-terrorism coalition.Due to the intensity of the fighting in the south, in 2011 France allowed a squadron ofMirage 2000fighter/attack aircraft to be moved into the area, toKandahar, in order to reinforce the alliance's efforts.During its2012 Chicago Summit, NATO endorsed a plan to end the Afghanistan war and to remove the NATO-led ISAF Forces by the end of December 2014.ISAF was disestablished in December 2014 and replaced by the follow-on trainingResolute Support Mission. On 14 April 2021, NATO Secretary GeneralJens Stoltenbergsaid the alliance had agreed to startwithdrawing its troops from Afghanistanby 1 May.Soon after the withdrawal of NATO troops started, the Taliban launched anoffensive against the Afghan government, quickly advancing in front of collapsingAfghan Armed Forces.By 15 August 2021, Taliban militants controlled the vast majority of Afghanistan and had encircled the capital city ofKabul.Some politicians in NATO member states have described the chaotic withdrawal of Western troops from Afghanistan and thecollapse of the Afghan governmentas the greatest debacle that NATO has suffered since its founding. In August 2004, during theIraq War, NATO formed theNATO Training Mission – Iraq, a training mission to assist the Iraqi security forces in conjunction with the US-ledMNF-I.The NATO Training Mission-Iraq (NTM-I) was established at the request of theIraqi Interim Governmentunder the provisions ofUnited Nations Security Council Resolution 1546. The aim of NTM-I was to assist in the development of Iraqi security forces training structures and institutions so that Iraq can build an effective and sustainable capability that addresses the needs of the country. NTM-I was not a combat mission but is a distinct mission, under the political control of theNorth Atlantic Council. Its operational emphasis was on training and mentoring. The activities of the mission were coordinated with Iraqi authorities and the US-led Deputy Commanding General Advising and Training, who was also dual-hatted as the Commander of NTM-I. The mission officially concluded on 17 December 2011. Turkey invoked the first Article 4 meetings in 2003 at the start of theIraq War. Turkey also invoked this article twice in 2012 during theSyrian civil war, after thedowningof an unarmed TurkishF-4 reconnaissance jet, and after a mortar was fired at Turkey from Syria,and again in 2015 after threats byIslamic State of Iraq and the Levantto its territorial integrity. In 2008 theUnited Nations Secretary-Generalcalled on member-states to protect the ships ofOperation Allied Provider[de;no;ru;uk], which was distributing aid as part of theWorld Food Programmemission in Somalia. TheNorth Atlantic Counciland other countries, including Russia, China and South Korea,formedOperation Ocean Shield. The operation sought to dissuade and interrupt pirate attacks, protect vessels, and to increase the general level of security in the region.Beginning on 17 August 2009, NATO deployed warships in an operation to protect maritime traffic in theGulf of Adenand the Indian Ocean fromSomali pirates, and help strengthen the navies and coast guards of regional states. During theLibyan Civil War, violence between protesters and the Libyan government under ColonelMuammar Gaddafiescalated, and on 17 March 2011 led to the passage ofUnited Nations Security Council Resolution 1973, which called for a ceasefire, and authorized military action to protect civilians.A coalition that included several NATO members began enforcing a no-fly zone over Libya shortly afterwards, beginning withOpération Harmattanby theFrench Air Forceon 19 March. On 20 March 2011, NATO states agreed on enforcing an arms embargo against Libya withOperation Unified Protectorusing ships from NATOStanding Maritime Group 1andStanding Mine Countermeasures Group 1,and additional ships and submarines from NATO members.They would \"monitor, report and, if needed,interdictvessels suspected of carrying illegal arms ormercenaries\". On 24 March, NATO agreed to take control of the no-fly zone from the initial coalition, while command of targeting ground units remained with the coalition's forces.NATO began officially enforcing the UN resolution on 27 March 2011 with assistance from Qatar and the United Arab Emirates.By June, reports of divisions within the alliance surfaced as only eight of the 28 member states were participating in combat operations,resulting in a confrontation between US Defense SecretaryRobert Gatesand countries such as Poland, Spain, the Netherlands, Turkey, and Germany with Gates calling on the latter to contribute more and the latter believing the organization has overstepped its mandate in the conflict.In his final policy speech in Brussels on 10 June, Gates further criticized allied countries in suggesting their actions could cause the demise of NATO.The German foreign ministry pointed to \"a considerable [German] contribution to NATO and NATO-led operations\" and to the fact that this engagement was highly valued by President Obama. While the mission was extended into September, Norway that day (10 June) announced it would begin scaling down contributions and complete withdrawal by 1 August.Earlier that week it was reportedDanish air fighterswere running out of bombs.The following week, the head of theRoyal Navysaid the country's operations in the conflict were not sustainable.By the end of the mission in October 2011, after the death of Colonel Gaddafi, NATO planes had flown about 9,500 strike sorties against pro-Gaddafi targets.A report from the organizationHuman Rights Watchin May 2012 identified at least 72 civilians killed in the campaign. Following acoup d'état attemptin October 2013, Libyan Prime MinisterAli Zeidanrequested technical advice and trainers from NATO to assist with ongoing security issues. Use ofArticle 5has been threatened multiple times and four out of seven officialArticle 4consultations have been called due tospilloverin Turkey from theSyrian civil war. In April 2012, Turkish Prime MinisterRecep Tayyip Erdoğanconsidered invoking Article 5 of the NATO treaty to protect Turkish national security in a dispute over the Syrian civil war.The alliance responded quickly, and a spokesperson said the alliance was \"monitoring the situation very closely and will continue to do so\" and \"takes it very seriously protecting its members.\" Afterthe shooting down of a Turkish military jet by Syriain June 2012 andSyrian forces shelling Turkish citiesin October 2012resulting in two Article 4 consultations, NATO approvedOperation Active Fence. In the past decade the conflict has only escalated. In response to the2015 Suruç bombing, which Turkey attributed toISIS, and other security issues along its southern border,Turkey called foran emergency meeting. The latest consultation happened in February 2020, as part of increasing tensions due to theNorthwestern Syria offensive, which involvedSyrian and suspected Russian airstrikes on Turkish troops, and risked direct confrontation between Russia and a NATO member. Operation Eastern Sentry is a NATO military initiative launched in response toRussian drone incursionsinto Polish airspace in September 2025.The operation aims to strengthen the alliance'seastern flankand deter further aggression. Multiple member states are contributing military assets, including fighter jets and naval units, to enhance air and ground defense capabilities. Eastern Sentry is designed to provide a flexible and agile response to threats, with a focus on countering drone technology. The 32 NATO members are: NATO has thirty-two members, mostly in Europe with two in North America. NATO's \"area of responsibility\", within which attacks on member states are eligible for an Article 5 response, is defined under Article 6 of theNorth Atlantic Treatyto include member territory in Europe, North America, Turkey, and islands in the North Atlantic north of theTropic of Cancer. Attacks on vessels, aircraft and other forces in the North Atlantic (again, north of the Tropic of Cancer) and the Mediterranean Sea may also provoke an Article 5 response.During the original treaty negotiations, the United States insisted that colonies such as theBelgian Congobe excluded from the treaty.French Algeriawas, however, covered untilits independenceon 3 July 1962.Twelve of these thirty-two are original members who joined in 1949, while the other twenty joined in one of ten enlargement rounds. The three Nordic countries which joined NATO as founding members, Denmark, Iceland, and Norway, chose to limit their participation in three areas: there would be no permanent peacetime bases, no nuclear warheads and no Allied military activity (unless invited) permitted on their territory. However, Denmark allows theU.S. Space Forceto maintainPituffik Space Base, in Greenland. From the mid-1960s to the mid-1990s, France pursued a military strategy of independence from NATO under a policy dubbed \"Gaullo-Mitterrandism\".Nicolas Sarkozynegotiated the return of France to the integrated military command and the Defence Planning Committee in 2009, the latter being disbanded the following year. France remains the only NATO member outside the Nuclear Planning Group and, unlike the United States and the United Kingdom, will not commit its nuclear-armed submarines to the alliance. NATO was established on 4 April 1949 by the signing of theNorth Atlantic Treaty(Washington Treaty). The 12 founding members of the alliance were Belgium, Canada, Denmark, France, Iceland, Italy, Luxembourg, the Netherlands, Norway, Portugal, the United Kingdom, and the United States. Four new members joined during the Cold War: Greece (1952), Turkey (1952),West Germany(1955) and Spain (1982). Following thedissolution of the Soviet Union, many formerWarsaw Pactandpost-Soviet statessought membership. In 1990, the territory of the formerEast Germanywas added with thereunification of Germany. At the1999 Washington summit, Hungary, Poland, and the Czech Republic officially joined, and NATO issued new guidelines for membership, with individualized \"Membership Action Plans\". These plans governed the addition of new members: Bulgaria, Estonia, Latvia, Lithuania, Romania, Slovakia, and Slovenia in 2004, Albania and Croatia in 2009, Montenegro in 2017, and North Macedonia in 2020.Finland and Sweden are the newest members, joining in 2023 and 2024 respectively, spurred on byRussia's invasion of Ukraine. Ukraine's relationship with NATObegan with the NATO–Ukraine Action Plan in 2002.In 2005, Russian presidentVladimir Putinsaid that if Ukraine joined NATO, \"we will respect their choice, because it is their sovereign right to decide their own defence policy, and this will not worsen relations between our countries\".However, since his2007 Munich speech, Putin has strongly opposed further enlargement. In 2010, under PresidentViktor Yanukovych, Ukraine re-affirmed its non-aligned status and renounced aspirations of joining NATO.During the2014 Ukrainian Revolution, Russiaoccupied Crimeaand supportedarmed separatists in eastern Ukraine. Because of this, in December 2014 Ukraine's parliament voted to end its non-aligned status,and in 2019 it enshrined the goal of NATO membership in theConstitution.At the June2021 Brussels Summit, NATO leaders affirmed that Ukraine would eventually join, and supported Ukraine's right to self-determination without interference.In late 2021, there was another massiveRussian military buildupon Ukraine's borders. Russian president Putin warned that Ukraine joining NATO, and the deployment ofmissile defense systemsor long-range missiles in Ukraine, wouldcross a red line. However, Ukraine was a long way from potential membership, and there were no such plans to deploy missiles.The Russian Foreign Ministry drafted a treaty that would forbid Ukraine or any former Soviet state from ever joining NATO.Secretary-General Stoltenberg replied that the decision is up to Ukraine and NATO members, adding \"Russia has no veto...and Russia has no right to establish asphere of influenceto try to control their neighbors\".NATO offered to improve communications with Russia and discuss missile placements and military exercises, as long as Russia withdrew troops from Ukraine's borders.Instead,Russia invaded Ukrainein February 2022. Ukraine applied for NATO membership in September 2022 after Russia proclaimed it hadannexed the country's southeast. Georgia was promised \"future membership\" during the 2008 summit in Bucharest,but US presidentBarack Obamasaid in 2014 that the country was not \"currently on a path\" to membership. Russian leaders have said that NATO enlargement went against informal understandings between Soviet leaderMikhail Gorbachevand European and US negotiators that allowed for peaceful German reunification.A June 2016Levada Centerpoll found that 68 percent of Russians think that deploying NATO troops in theBaltic statesand Poland – former Eastern bloc countries bordering Russia – is a threat to Russia.In contrast, 65 percent of Poles surveyed in a 2017Pew Research Center report identified Russia as a \"major threat\", with an average of 31 percent saying so across all NATO countries,and 67 percent of Poles surveyed in 2018favour US forces being based in Poland.Of non-CISEastern European countries surveyed by Gallup in 2016,all butSerbiaandMontenegrowere more likely than not to view NATO as a protective alliance rather than a threat.A 2006 study in the journalSecurity Studiesargued that NATO enlargement contributed todemocratic consolidationin Central and Eastern Europe.Chinaalso opposes further expansion. Member states pay for NATO's three common funds (the civil and military budgets and the security investment programme) based on a cost-sharing formula that includes per capita gross national income and other factors.In 2023–2024, the United States and Germany were the biggest contributors to the NATO budget at 16.2% each. Member states pay for and maintain their own troops and equipment.They contribute to NATO operations and missions by committing troops and equipment on a voluntary basis.Since 2006, the goal has been for each country to spend at least 2 percent of its gross domestic product on its own defence; in 2014, a NATO declaration said that countries not meeting the goal would \"aim to move towards the 2 percent guideline within a decade\".In July 2022, NATO estimated that 11 members would meet the target in 2023.On 14 February 2024, NATO Secretary GeneralJens Stoltenbergsaid that 18 member states would meet the 2% target in 2024.On 17 June 2024, prior to the2024 Washington summit, Stoltenberg updated that figure and announced that a record 23 of 32 NATO member states were meeting their defense spending targets of 2% of their country's GDP.NATO added that defense spending for European member states and Canada was up 18% in the past year alone.As of 2024, the following countries were not meeting the 2% contribution goal: Spain (1.28%), Luxembourg (1.29%), Slovenia (1.29%), Belgium (1.3%), Canada (1.37%), Italy (1.49%), Portugal (1.55%), and Croatia (1.81%). ThePartnership for Peace(PfP) programme was established in 1994 and is based on individual bilateral relations between each partner country and NATO: each country may choose the extent of its participation.Members include all current and former members of theCommonwealth of Independent States.TheEuro-Atlantic Partnership Council(EAPC) was first established on 29 May 1997, and is a forum for regular coordination, consultation and dialogue between all fifty participants.The PfP programme is considered the operational wing of the Euro-Atlantic Partnership.Other third countries have also been contacted for participation in some activities of the PfP framework, such as Afghanistan. The European Union (EU) signed a comprehensive package of arrangements with NATO under theBerlin Plus agreementon 16 December 2002. With this agreement, the EU was given the possibility of using NATO assets if it wanted to act independently in an international crisis, on the condition that NATO itself did not want to act – the so-called \"right of first refusal\".For example, Article 42(7) of the 1982Treaty of Lisbonspecifies that \"If a Member State is the victim of armed aggression on its territory, the other Member States shall have towards it an obligation of aid and assistance by all the means in their power\". The treaty applies globally to specified territories, whereas NATO is restricted under its Article 6 to operations north of theTropic of Cancer. It provides a \"double framework\" for the EU countries that are also linked with the PfP programme. Additionally, NATO cooperates and discusses its activities with numerous other non-NATO members. TheMediterranean Dialoguewas established in 1994 to coordinate in a similar way withIsraeland countries in North Africa. TheIstanbul Cooperation Initiativewas announced in 2004 as a dialogue forum for the Middle East along the same lines as the Mediterranean Dialogue. The four participants are also linked through theGulf Cooperation Council.In June 2018, Qatar expressed a wish to join NATO,who ruled it out, saying that only additional European countries could join according toArticle 10 of NATO's founding treaty.Qatar and NATO had earlier signed a joint security agreement, in January 2018. Political dialogue with Japan began in 1990, and since then, the Alliance has gradually increased its contact with countries that do not form part of any of these cooperation initiatives.In 1998, NATO established a set of general guidelines that do not allow for a formal institutionalization of relations, but reflect the Allies' desire to increase cooperation. Following extensive debate, the term \"Contact Countries\" was agreed by the Allies in 2000. By 2012, the Alliance had broadened this group, which meets to discuss issues such as counter-piracy and technology exchange, under the names \"global partners\" or \"partners across the globe\".Australia and New Zealand, both global partners,are also members of theAUSCANNZUKUSstrategic alliance, and similar regional or bilateral agreements between contact countries and NATO members also aid cooperation. NATO Secretary GeneralJens Stoltenbergstated that NATO needs to \"address therise of China\", by closely cooperating with Australia, New Zealand, Japan and South Korea.Colombia is NATO's latest partner and has access to the full range of cooperative activities offered; it is the first and onlyLatin Americancountry to cooperate with NATO. All agencies and organizations of NATO are integrated into either the civilian administrative or military executive roles. For the most part, they perform roles and functions that directly or indirectly support the security role of the alliance as a whole. The civilian structure includes: The military structure includes: NATO is an alliance of 32 sovereign states and their individual sovereignty is unaffected by participation in the alliance. NATO has no parliaments, no laws, no enforcement, and no power to punish individual citizens. As a consequence of this lack of sovereignty the power and authority of a NATO commander are limited. NATO commanders cannot punish offences such as failure to obey a lawful order; dereliction of duty; or disrespect to a senior officer.NATO commanders expect obedience but sometimes need to subordinate their desires or plans to the operators who are themselves subject to sovereign codes of conduct like theUCMJ. A case in point was the clash between GeneralSir Mike Jacksonand GeneralWesley ClarkoverKFOR actions at Pristina Airport. NATO commanders can issue orders to their subordinate commanders in the form of operational plans (OPLANs), operational orders (OPORDERs), tactical direction, or fragmental orders (FRAGOs) and others. The joint rules of engagement must be followed, and theLaw of Armed Conflictmust be obeyed at all times. Operational resources \"remain under national command but have been transferred temporarily to NATO. Although these national units, through the formal process of transfer of authority, have been placed under the operational command and control of a NATO commander, they never lose their national character.\" Senior national representatives, likeCDS, \"are designated as so-called red-cardholders\". Caveats are restrictions listed \"nation by nation... that NATO Commanders... must take into account\".", "combined_text": "NATO Contents History 20th century 21st century Military operations Early operations Bosnia and Herzegovina intervention Kosovo intervention War in Afghanistan Iraq training mission Gulf of Aden anti-piracy Libya intervention Turkish border Eastern flank Membership Special arrangements Enlargement NATO defence expenditure Partnerships with third countries Structure Legal authority of NATO commanders See also Similar organizations References Works cited Further reading External links  TheNorth Atlantic Treaty Organization(NATO/ˈneɪtoʊ/NAY-toh;French:Organisation du traité de l'Atlantique Nord,OTAN), also called theNorth Atlantic Alliance, is anintergovernmentalmilitary alliancebetween32 member states—30 inEuropeand 2 inNorth America. Founded in theaftermath of World War II, NATO was established with the signing of theNorth Atlantic Treatyin 1949. The organization serves as a system ofcollective security, whereby its independent member states agree to mutual defence in response to an attack by any outside party. This is enshrined in Article 5 of the treaty, which states that an armed attack against one member shall be considered an attack against them all. Throughout theCold War, NATO's primary purpose was to deter and counter the threat posed by theSoviet Unionand itssatellite states, which formed the rivalWarsaw Pactin 1955. Following thedissolution of the Soviet Unionin 1991, the alliance adapted, conducting its first major military interventionsin Bosnia and Herzegovina(1992–1995) andYugoslavia(1999). Article 5 was invoked for the first and only time after theSeptember 11 attacks, leading to the deployment of NATO troops toAfghanistanas part of theInternational Security Assistance Force(ISAF). The alliance has since been involved in a range of roles, includingtraining in Iraq,intervention in Libyain 2011, andcountering piracy. Since the end of the Cold War, the alliance hasaccepted sixteen new members, incorporating formerWarsaw Pactcountries andpost-Soviet states. NATO and Russiahave co-operated, but Russian leaders have called this eastward enlargement a threat to its security interests, andoppose Ukraine joiningNATO.  TheRussian annexation of Crimeain 2014 prompted strong condemnation from NATO and a renewed focus on collective defence. Russia'sfull-scale invasion of Ukrainein 2022 led to a major reinforcement of NATO's eastern flank and causedFinlandandSwedento abandon their neutral status and join the alliance. NATO recognizesBosnia and Herzegovina,UkraineandGeorgiaas aspiring members. NATO's main headquartersare inBrussels, Belgium, whileits military headquartersare nearMons, Belgium. The combined militaries of all NATO members include approximately 3.5 million soldiers and personnel. Their combined military spending constitutes over half of theglobal total. Members have committed to a target of spending at least 5% of theirgross domestic product(GDP) on defence to ensure the alliance's continued military readiness. NATO has its roots in theAtlantic Charter, a 1941 agreement between the United States and United Kingdom.  The Charter laid out a framework for international cooperation without territorial expansion afterWorld War II.On 4 March 1947, theTreaty of Dunkirkwas signed by France and the United Kingdom during theaftermath of World War IIand thestart of the Cold Waras aTreaty of Alliance and Mutual Assistancein the event of possible attacks by Germany. In March 1948, this alliance was expanded in theTreaty of Brusselsto include theBeneluxcountries, forming the Brussels Treaty Organization, commonly known as theWestern Union.Talks for a wider military alliance, which could include North America, also began that month in the United States, where their foreign policy under theTruman Doctrineset out in 1947 promoted international solidarity against actions they saw as communist aggression, such as theFebruary 1948 coup d'état in Czechoslovakia. These talks resulted in the signature of theNorth Atlantic Treatyon 4 April 1949 by the member states of the Western Union plus the United States, Canada, Portugal, Italy, Norway, Denmark, and Iceland.Canadian diplomatLester B. Pearsonwas a key author and drafter of the treaty. The North Atlantic Treaty was largely dormant until theKorean Warinitiated the establishment of NATO to implement it with an integrated military structure. This included the formation ofSupreme Headquarters Allied Powers Europe(SHAPE) in 1951, which adopted many of the Western Union's military structures and plans,including theiragreements on standardizing equipmentandagreements on stationing foreign military forcesin European countries. In 1952, the post ofSecretary General of NATOwas established as the organization's chief civilian. That year also saw the first major NATOmaritime exercises,Exercise Mainbraceand the accession ofGreeceandTurkeyto the organization.Following theLondon and Paris Conferences,West Germanywas permitted to rearm militarily, as they joined NATO in May 1955, which was, in turn, a major factor in the creation of the Soviet-dominatedWarsaw Pact, delineating the two opposing sides of theCold War. The building of theBerlin Wallin 1961 marked a height in Cold War tensions, when 400,000 US troops were stationed in Europe.Doubts over the strength of the relationship between the European states and the United States ebbed and flowed, along with doubts over the credibility of the NATO defence against a prospective Soviet invasion – doubts that led to the development of theindependent French nuclear deterrentand the withdrawal ofFrancefrom NATO's military structure in 1966.In 1982, the newly democratic Spain joined the alliance. TheRevolutions of 1989in Europe led to a strategic re-evaluation of NATO's purpose, nature, tasks, and focus on the continent. In October 1990,East Germanybecame part of the Federal Republic of Germanyand the alliance, and in November 1990, the alliance signed theTreaty on Conventional Armed Forces in Europe(CFE) in Paris with the Soviet Union. It mandated specific military reductions across the continent, which continued after the collapse of theWarsaw Pactin February 1991 and thedissolution of the Soviet Unionthat December, which removed thede factomain adversaries of NATO.This began a drawdown of military spending and equipment in Europe. The CFE treaty allowed signatories to remove 52,000 pieces of conventional armaments in the following sixteen years,and allowed military spending by NATO's European members to decline by 28 percent from 1990 to 2015.In 1990, several Western leaders gave assurances toMikhail Gorbachevthat NATO would not expand further east, as revealed by memoranda of private conversations. In the 1990s, the organization extended its activities into political and humanitarian situations that had not formerly been NATO concerns.During thebreakup of Yugoslavia, the organization conducted its firstmilitary interventionsinBosnia from 1992 to 1995and laterYugoslavia in 1999. Politically, the organization sought better relations with the newly autonomousCentral and Eastern Europeanstates, and diplomatic forums for regional cooperation between NATO and its neighbours were set up during this post-Cold War period, including thePartnership for Peaceand theMediterranean Dialogueinitiative in 1994, theEuro-Atlantic Partnership Councilin 1997, and theNATO–Russia Permanent Joint Councilin 1998. At the1999 Washington summit,Hungary,Poland, and theCzech Republicofficially joined NATO, and the organization also issued new guidelines for membership with individualized \"Membership Action Plans\". These plans governed the subsequent addition of new alliance members. Article 5 of the North Atlantic treaty, requiring member states to come to the aid of any member state subject to an armed attack, was invoked for the first and only time after theSeptember 11 attacks,after which troops were deployed toAfghanistanunder the NATO-ledISAF. The organization has operated a range of additional roles since then, including sendingtrainers to Iraq, assisting incounter-piracy operations. The election of French presidentNicolas Sarkozyin 2007 led to a major reform of France's military position, culminating with the return to full membership on 4 April 2009, which also included France rejoining theNATO Military Command Structure, while maintaining an independent nuclear deterrent. The 2014Russian annexation of Crimealed to strong condemnation by all NATO members,and was one of the seven times thatArticle 4, which calls for consultation among NATO members, has been invoked. Prior times included during theIraq WarandSyrian civil war.At the2014 Wales summit, the leaders of NATO's member states formally committed for the first time to spend the equivalent of at least two percent of theirgross domestic productson defence by 2024, which had previously been only an informal guideline. At the2016 Warsaw summit, NATO countries agreed on the creation ofNATO Enhanced Forward Presence, which deployed four multinational battalion-sized battlegroups in Estonia, Latvia, Lithuania, and Poland.Before and during the2022 Russian invasion of Ukraine, several NATO countries sent ground troops, warships and fighter aircraft to reinforce the alliance's eastern flank, and multiple countries again invoked Article 4.In March 2022, NATO leaders met at Brussels for anextraordinary summitwhich also involvedGroup of Sevenand European Union leaders.NATO member states agreed to establish four additional battlegroups in Bulgaria, Hungary, Romania, and Slovakia,and elements of theNATO Response Forcewere activated for the first time in NATO's history. As of June 2022, NATO had deployed 40,000 troops along its 2,500-kilometre-long (1,550 mi) Eastern flank to deter Russian aggression. More than half of this number have been deployed in Bulgaria, Romania, Hungary, Slovakia, and Poland, which five countries muster a considerable combined ex-NATO force of 259,000 troops. To supplement Bulgaria's Air Force, Spain sentEurofighter Typhoons, the Netherlands sent eightF-35attack aircraft, and additional French and US attack aircraft would arrive soon as well.In 2025, Germany stationed a full armoured brigade in Lithuania. No military operations were conducted by NATO during the Cold War. Following the end of the Cold War, the first operations,Anchor Guardin 1990 andAce Guardin 1991, were prompted by theIraqi invasion of Kuwait. Airborne early warning aircraft were sent to provide coverage of southeastern Turkey, and later a quick-reaction force was deployed to the area. TheBosnian Warbegan in 1992, as a result of thebreakup of Yugoslavia. The deteriorating situation led toUnited Nations Security Council Resolution 816on 9 October 1992, authorizing its member-states to enforce a previously declaredno-fly zoneunder theUnited Nations Protection Forceover central Bosnia and Herzegovina. NATO complied and started enforcing the ban on 12 April 1993 withOperation Deny Flight. From June 1993 until October 1996,Operation Sharp Guardadded maritime enforcement of thearms embargoandeconomic sanctionsagainst theFederal Republic of Yugoslavia. On 28 February 1994, NATO took its first wartime action byshooting down four Bosnian Serb aircraftviolating the no-fly zone. On 10 and 11 April 1994, the United Nations Protection Force called in air strikes to protect theGoraždesafe area, resulting in the bombing of a Bosnian Serb military command outpost near Goražde by two USF-16jets acting under NATO direction.In retaliation, Serbs took 150 U.N. personnel hostage on 14 April.On 16 April a BritishSea Harrierwas shot down over Goražde by Serb forces. In August 1995, a two-week NATO bombing campaign,Operation Deliberate Force, began against theArmy of the Republika Srpska, after theSrebrenica genocide.Further NATO air strikes helped bring theYugoslav Warsto an end, resulting in theDayton Agreementin November 1995.As part of this agreement, NATO deployed a UN-mandated peacekeeping force, underOperation Joint Endeavor, namedIFOR. Almost 60,000 NATO troops were joined by forces from non-NATO countries in this peacekeeping mission. This transitioned into the smallerSFOR, which started with 32,000 troops initially and ran from December 1996 until December 2004, when operations were then passed onto theEuropean Union Force Althea.Following the lead of its member states, NATO began to award a service medal, theNATO Medal, for these operations. In an effort to stopSlobodan Milošević's Serbian-led crackdown onKLAseparatists and Albanian civilians inKosovo, theUnited Nations Security CouncilpassedResolution 1199on 23 September 1998 to demand a ceasefire. Negotiations under US Special EnvoyRichard Holbrookebroke down on 23 March 1999, and he handed the matter to NATO,which acted on protecting regional security and started a 78-day bombing campaign on 24 March 1999.Operation Allied Force targeted the military capabilities of what was then theFederal Republic of Yugoslavia. During the crisis, NATO also deployed one of its international reaction forces, theACE Mobile Force (Land), to Albania as the Albania Force (AFOR), to deliver humanitarian aid to refugees from Kosovo. The campaign was and has been criticized overits civilian casualties, including the bombing of theChinese embassy in Belgrade, and overwhether it had legitimacy. The US, the UK, and most other NATO countries opposed efforts to require the UN Security Council to approve NATO military strikes, such as the action against Serbia in 1999, while France and some othersclaimed that the alliance needed UN approval.The US/UK side claimed that this would undermine the authority of the alliance, and they noted that Russia and China would have exercised their Security Council vetoes to block the strike onYugoslavia, and could do the same in future conflicts where NATO intervention was required, thus nullifying the entire potency and purpose of the organization. Recognizing the post-Cold War military environment, NATO adopted the Alliance Strategic Concept during itsWashington summitin April 1999 that emphasized conflict prevention and crisis management. Milošević finally accepted the terms of an international peace plan on 3 June 1999, ending theKosovo War. On 11 June, Milošević further acceptedUN resolution 1244, under the mandate of which NATO then helped establish theKFORpeacekeeping force. Nearly one million refugees had fled Kosovo, and part of KFOR's mandate was to protect the humanitarian missions, in addition to deterring violence.In August–September 2001, the alliance also mountedOperation Essential Harvest, a mission disarming ethnic Albanian militias in the Republic of Macedonia.As of 2023, around 4,500 KFOR soldiers, representing 27 countries, continue to operate in the area. TheSeptember 11 attacksin the United States caused NATO to invokeArticle 5of the NATO Charter for the first time in the organization's history.The Article states that an attack on any member shall be considered to be an attack on all. The invocation was confirmed on 4 October 2001 when NATO determined that the attacks were indeed eligible under the terms of the North Atlantic Treaty.The eight official actions taken by NATO in response to the attacks includedOperation Eagle AssistandOperation Active Endeavour, a naval operation in the Mediterranean Sea designed to prevent the movement of terrorists or weapons of mass destruction, and to enhance the security of shipping in general, which began on 4 October 2001. The alliance showed unity: on 16 April 2003, NATO agreed to take command of theInternational Security Assistance Force(ISAF), which included troops from 42 countries. The decision came at the request of Germany and the Netherlands, the two countries leading ISAF at the time of the agreement, and all nineteen NATO ambassadors approved it unanimously. The handover of control to NATO took place on 11 August, and marked the first time in NATO's history that it took charge of a mission outside the north Atlantic area. ISAF was initially charged with securingKabuland surrounding areas from theTaliban,al Qaedaand factional warlords, so as to allow for the establishment of theAfghan Transitional Administrationheaded byHamid Karzai. In October 2003, the UN Security Council authorized the expansion of the ISAF mission throughout Afghanistan,and ISAF subsequently expanded the mission in four main stages over the whole of the country. On 31 July 2006, the ISAF additionally took overmilitary operations in the south of Afghanistanfrom a US-led anti-terrorism coalition.Due to the intensity of the fighting in the south, in 2011 France allowed a squadron ofMirage 2000fighter/attack aircraft to be moved into the area, toKandahar, in order to reinforce the alliance's efforts.During its2012 Chicago Summit, NATO endorsed a plan to end the Afghanistan war and to remove the NATO-led ISAF Forces by the end of December 2014.ISAF was disestablished in December 2014 and replaced by the follow-on trainingResolute Support Mission. On 14 April 2021, NATO Secretary GeneralJens Stoltenbergsaid the alliance had agreed to startwithdrawing its troops from Afghanistanby 1 May.Soon after the withdrawal of NATO troops started, the Taliban launched anoffensive against the Afghan government, quickly advancing in front of collapsingAfghan Armed Forces.By 15 August 2021, Taliban militants controlled the vast majority of Afghanistan and had encircled the capital city ofKabul.Some politicians in NATO member states have described the chaotic withdrawal of Western troops from Afghanistan and thecollapse of the Afghan governmentas the greatest debacle that NATO has suffered since its founding. In August 2004, during theIraq War, NATO formed theNATO Training Mission – Iraq, a training mission to assist the Iraqi security forces in conjunction with the US-ledMNF-I.The NATO Training Mission-Iraq (NTM-I) was established at the request of theIraqi Interim Governmentunder the provisions ofUnited Nations Security Council Resolution 1546. The aim of NTM-I was to assist in the development of Iraqi security forces training structures and institutions so that Iraq can build an effective and sustainable capability that addresses the needs of the country. NTM-I was not a combat mission but is a distinct mission, under the political control of theNorth Atlantic Council. Its operational emphasis was on training and mentoring. The activities of the mission were coordinated with Iraqi authorities and the US-led Deputy Commanding General Advising and Training, who was also dual-hatted as the Commander of NTM-I. The mission officially concluded on 17 December 2011. Turkey invoked the first Article 4 meetings in 2003 at the start of theIraq War. Turkey also invoked this article twice in 2012 during theSyrian civil war, after thedowningof an unarmed TurkishF-4 reconnaissance jet, and after a mortar was fired at Turkey from Syria,and again in 2015 after threats byIslamic State of Iraq and the Levantto its territorial integrity. In 2008 theUnited Nations Secretary-Generalcalled on member-states to protect the ships ofOperation Allied Provider[de;no;ru;uk], which was distributing aid as part of theWorld Food Programmemission in Somalia. TheNorth Atlantic Counciland other countries, including Russia, China and South Korea,formedOperation Ocean Shield. The operation sought to dissuade and interrupt pirate attacks, protect vessels, and to increase the general level of security in the region.Beginning on 17 August 2009, NATO deployed warships in an operation to protect maritime traffic in theGulf of Adenand the Indian Ocean fromSomali pirates, and help strengthen the navies and coast guards of regional states. During theLibyan Civil War, violence between protesters and the Libyan government under ColonelMuammar Gaddafiescalated, and on 17 March 2011 led to the passage ofUnited Nations Security Council Resolution 1973, which called for a ceasefire, and authorized military action to protect civilians.A coalition that included several NATO members began enforcing a no-fly zone over Libya shortly afterwards, beginning withOpération Harmattanby theFrench Air Forceon 19 March. On 20 March 2011, NATO states agreed on enforcing an arms embargo against Libya withOperation Unified Protectorusing ships from NATOStanding Maritime Group 1andStanding Mine Countermeasures Group 1,and additional ships and submarines from NATO members.They would \"monitor, report and, if needed,interdictvessels suspected of carrying illegal arms ormercenaries\". On 24 March, NATO agreed to take control of the no-fly zone from the initial coalition, while command of targeting ground units remained with the coalition's forces.NATO began officially enforcing the UN resolution on 27 March 2011 with assistance from Qatar and the United Arab Emirates.By June, reports of divisions within the alliance surfaced as only eight of the 28 member states were participating in combat operations,resulting in a confrontation between US Defense SecretaryRobert Gatesand countries such as Poland, Spain, the Netherlands, Turkey, and Germany with Gates calling on the latter to contribute more and the latter believing the organization has overstepped its mandate in the conflict.In his final policy speech in Brussels on 10 June, Gates further criticized allied countries in suggesting their actions could cause the demise of NATO.The German foreign ministry pointed to \"a considerable [German] contribution to NATO and NATO-led operations\" and to the fact that this engagement was highly valued by President Obama. While the mission was extended into September, Norway that day (10 June) announced it would begin scaling down contributions and complete withdrawal by 1 August.Earlier that week it was reportedDanish air fighterswere running out of bombs.The following week, the head of theRoyal Navysaid the country's operations in the conflict were not sustainable.By the end of the mission in October 2011, after the death of Colonel Gaddafi, NATO planes had flown about 9,500 strike sorties against pro-Gaddafi targets.A report from the organizationHuman Rights Watchin May 2012 identified at least 72 civilians killed in the campaign. Following acoup d'état attemptin October 2013, Libyan Prime MinisterAli Zeidanrequested technical advice and trainers from NATO to assist with ongoing security issues. Use ofArticle 5has been threatened multiple times and four out of seven officialArticle 4consultations have been called due tospilloverin Turkey from theSyrian civil war. In April 2012, Turkish Prime MinisterRecep Tayyip Erdoğanconsidered invoking Article 5 of the NATO treaty to protect Turkish national security in a dispute over the Syrian civil war.The alliance responded quickly, and a spokesperson said the alliance was \"monitoring the situation very closely and will continue to do so\" and \"takes it very seriously protecting its members.\" Afterthe shooting down of a Turkish military jet by Syriain June 2012 andSyrian forces shelling Turkish citiesin October 2012resulting in two Article 4 consultations, NATO approvedOperation Active Fence. In the past decade the conflict has only escalated. In response to the2015 Suruç bombing, which Turkey attributed toISIS, and other security issues along its southern border,Turkey called foran emergency meeting. The latest consultation happened in February 2020, as part of increasing tensions due to theNorthwestern Syria offensive, which involvedSyrian and suspected Russian airstrikes on Turkish troops, and risked direct confrontation between Russia and a NATO member. Operation Eastern Sentry is a NATO military initiative launched in response toRussian drone incursionsinto Polish airspace in September 2025.The operation aims to strengthen the alliance'seastern flankand deter further aggression. Multiple member states are contributing military assets, including fighter jets and naval units, to enhance air and ground defense capabilities. Eastern Sentry is designed to provide a flexible and agile response to threats, with a focus on countering drone technology. The 32 NATO members are: NATO has thirty-two members, mostly in Europe with two in North America. NATO's \"area of responsibility\", within which attacks on member states are eligible for an Article 5 response, is defined under Article 6 of theNorth Atlantic Treatyto include member territory in Europe, North America, Turkey, and islands in the North Atlantic north of theTropic of Cancer. Attacks on vessels, aircraft and other forces in the North Atlantic (again, north of the Tropic of Cancer) and the Mediterranean Sea may also provoke an Article 5 response.During the original treaty negotiations, the United States insisted that colonies such as theBelgian Congobe excluded from the treaty.French Algeriawas, however, covered untilits independenceon 3 July 1962.Twelve of these thirty-two are original members who joined in 1949, while the other twenty joined in one of ten enlargement rounds. The three Nordic countries which joined NATO as founding members, Denmark, Iceland, and Norway, chose to limit their participation in three areas: there would be no permanent peacetime bases, no nuclear warheads and no Allied military activity (unless invited) permitted on their territory. However, Denmark allows theU.S. Space Forceto maintainPituffik Space Base, in Greenland. From the mid-1960s to the mid-1990s, France pursued a military strategy of independence from NATO under a policy dubbed \"Gaullo-Mitterrandism\".Nicolas Sarkozynegotiated the return of France to the integrated military command and the Defence Planning Committee in 2009, the latter being disbanded the following year. France remains the only NATO member outside the Nuclear Planning Group and, unlike the United States and the United Kingdom, will not commit its nuclear-armed submarines to the alliance. NATO was established on 4 April 1949 by the signing of theNorth Atlantic Treaty(Washington Treaty). The 12 founding members of the alliance were Belgium, Canada, Denmark, France, Iceland, Italy, Luxembourg, the Netherlands, Norway, Portugal, the United Kingdom, and the United States. Four new members joined during the Cold War: Greece (1952), Turkey (1952),West Germany(1955) and Spain (1982). Following thedissolution of the Soviet Union, many formerWarsaw Pactandpost-Soviet statessought membership. In 1990, the territory of the formerEast Germanywas added with thereunification of Germany. At the1999 Washington summit, Hungary, Poland, and the Czech Republic officially joined, and NATO issued new guidelines for membership, with individualized \"Membership Action Plans\". These plans governed the addition of new members: Bulgaria, Estonia, Latvia, Lithuania, Romania, Slovakia, and Slovenia in 2004, Albania and Croatia in 2009, Montenegro in 2017, and North Macedonia in 2020.Finland and Sweden are the newest members, joining in 2023 and 2024 respectively, spurred on byRussia's invasion of Ukraine. Ukraine's relationship with NATObegan with the NATO–Ukraine Action Plan in 2002.In 2005, Russian presidentVladimir Putinsaid that if Ukraine joined NATO, \"we will respect their choice, because it is their sovereign right to decide their own defence policy, and this will not worsen relations between our countries\".However, since his2007 Munich speech, Putin has strongly opposed further enlargement. In 2010, under PresidentViktor Yanukovych, Ukraine re-affirmed its non-aligned status and renounced aspirations of joining NATO.During the2014 Ukrainian Revolution, Russiaoccupied Crimeaand supportedarmed separatists in eastern Ukraine. Because of this, in December 2014 Ukraine's parliament voted to end its non-aligned status,and in 2019 it enshrined the goal of NATO membership in theConstitution.At the June2021 Brussels Summit, NATO leaders affirmed that Ukraine would eventually join, and supported Ukraine's right to self-determination without interference.In late 2021, there was another massiveRussian military buildupon Ukraine's borders. Russian president Putin warned that Ukraine joining NATO, and the deployment ofmissile defense systemsor long-range missiles in Ukraine, wouldcross a red line. However, Ukraine was a long way from potential membership, and there were no such plans to deploy missiles.The Russian Foreign Ministry drafted a treaty that would forbid Ukraine or any former Soviet state from ever joining NATO.Secretary-General Stoltenberg replied that the decision is up to Ukraine and NATO members, adding \"Russia has no veto...and Russia has no right to establish asphere of influenceto try to control their neighbors\".NATO offered to improve communications with Russia and discuss missile placements and military exercises, as long as Russia withdrew troops from Ukraine's borders.Instead,Russia invaded Ukrainein February 2022. Ukraine applied for NATO membership in September 2022 after Russia proclaimed it hadannexed the country's southeast. Georgia was promised \"future membership\" during the 2008 summit in Bucharest,but US presidentBarack Obamasaid in 2014 that the country was not \"currently on a path\" to membership. Russian leaders have said that NATO enlargement went against informal understandings between Soviet leaderMikhail Gorbachevand European and US negotiators that allowed for peaceful German reunification.A June 2016Levada Centerpoll found that 68 percent of Russians think that deploying NATO troops in theBaltic statesand Poland – former Eastern bloc countries bordering Russia – is a threat to Russia.In contrast, 65 percent of Poles surveyed in a 2017Pew Research Center report identified Russia as a \"major threat\", with an average of 31 percent saying so across all NATO countries,and 67 percent of Poles surveyed in 2018favour US forces being based in Poland.Of non-CISEastern European countries surveyed by Gallup in 2016,all butSerbiaandMontenegrowere more likely than not to view NATO as a protective alliance rather than a threat.A 2006 study in the journalSecurity Studiesargued that NATO enlargement contributed todemocratic consolidationin Central and Eastern Europe.Chinaalso opposes further expansion. Member states pay for NATO's three common funds (the civil and military budgets and the security investment programme) based on a cost-sharing formula that includes per capita gross national income and other factors.In 2023–2024, the United States and Germany were the biggest contributors to the NATO budget at 16.2% each. Member states pay for and maintain their own troops and equipment.They contribute to NATO operations and missions by committing troops and equipment on a voluntary basis.Since 2006, the goal has been for each country to spend at least 2 percent of its gross domestic product on its own defence; in 2014, a NATO declaration said that countries not meeting the goal would \"aim to move towards the 2 percent guideline within a decade\".In July 2022, NATO estimated that 11 members would meet the target in 2023.On 14 February 2024, NATO Secretary GeneralJens Stoltenbergsaid that 18 member states would meet the 2% target in 2024.On 17 June 2024, prior to the2024 Washington summit, Stoltenberg updated that figure and announced that a record 23 of 32 NATO member states were meeting their defense spending targets of 2% of their country's GDP.NATO added that defense spending for European member states and Canada was up 18% in the past year alone.As of 2024, the following countries were not meeting the 2% contribution goal: Spain (1.28%), Luxembourg (1.29%), Slovenia (1.29%), Belgium (1.3%), Canada (1.37%), Italy (1.49%), Portugal (1.55%), and Croatia (1.81%). ThePartnership for Peace(PfP) programme was established in 1994 and is based on individual bilateral relations between each partner country and NATO: each country may choose the extent of its participation.Members include all current and former members of theCommonwealth of Independent States.TheEuro-Atlantic Partnership Council(EAPC) was first established on 29 May 1997, and is a forum for regular coordination, consultation and dialogue between all fifty participants.The PfP programme is considered the operational wing of the Euro-Atlantic Partnership.Other third countries have also been contacted for participation in some activities of the PfP framework, such as Afghanistan. The European Union (EU) signed a comprehensive package of arrangements with NATO under theBerlin Plus agreementon 16 December 2002. With this agreement, the EU was given the possibility of using NATO assets if it wanted to act independently in an international crisis, on the condition that NATO itself did not want to act – the so-called \"right of first refusal\".For example, Article 42(7) of the 1982Treaty of Lisbonspecifies that \"If a Member State is the victim of armed aggression on its territory, the other Member States shall have towards it an obligation of aid and assistance by all the means in their power\". The treaty applies globally to specified territories, whereas NATO is restricted under its Article 6 to operations north of theTropic of Cancer. It provides a \"double framework\" for the EU countries that are also linked with the PfP programme. Additionally, NATO cooperates and discusses its activities with numerous other non-NATO members. TheMediterranean Dialoguewas established in 1994 to coordinate in a similar way withIsraeland countries in North Africa. TheIstanbul Cooperation Initiativewas announced in 2004 as a dialogue forum for the Middle East along the same lines as the Mediterranean Dialogue. The four participants are also linked through theGulf Cooperation Council.In June 2018, Qatar expressed a wish to join NATO,who ruled it out, saying that only additional European countries could join according toArticle 10 of NATO's founding treaty.Qatar and NATO had earlier signed a joint security agreement, in January 2018. Political dialogue with Japan began in 1990, and since then, the Alliance has gradually increased its contact with countries that do not form part of any of these cooperation initiatives.In 1998, NATO established a set of general guidelines that do not allow for a formal institutionalization of relations, but reflect the Allies' desire to increase cooperation. Following extensive debate, the term \"Contact Countries\" was agreed by the Allies in 2000. By 2012, the Alliance had broadened this group, which meets to discuss issues such as counter-piracy and technology exchange, under the names \"global partners\" or \"partners across the globe\".Australia and New Zealand, both global partners,are also members of theAUSCANNZUKUSstrategic alliance, and similar regional or bilateral agreements between contact countries and NATO members also aid cooperation. NATO Secretary GeneralJens Stoltenbergstated that NATO needs to \"address therise of China\", by closely cooperating with Australia, New Zealand, Japan and South Korea.Colombia is NATO's latest partner and has access to the full range of cooperative activities offered; it is the first and onlyLatin Americancountry to cooperate with NATO. All agencies and organizations of NATO are integrated into either the civilian administrative or military executive roles. For the most part, they perform roles and functions that directly or indirectly support the security role of the alliance as a whole. The civilian structure includes: The military structure includes: NATO is an alliance of 32 sovereign states and their individual sovereignty is unaffected by participation in the alliance. NATO has no parliaments, no laws, no enforcement, and no power to punish individual citizens. As a consequence of this lack of sovereignty the power and authority of a NATO commander are limited. NATO commanders cannot punish offences such as failure to obey a lawful order; dereliction of duty; or disrespect to a senior officer.NATO commanders expect obedience but sometimes need to subordinate their desires or plans to the operators who are themselves subject to sovereign codes of conduct like theUCMJ. A case in point was the clash between GeneralSir Mike Jacksonand GeneralWesley ClarkoverKFOR actions at Pristina Airport. NATO commanders can issue orders to their subordinate commanders in the form of operational plans (OPLANs), operational orders (OPORDERs), tactical direction, or fragmental orders (FRAGOs) and others. The joint rules of engagement must be followed, and theLaw of Armed Conflictmust be obeyed at all times. Operational resources \"remain under national command but have been transferred temporarily to NATO. Although these national units, through the formal process of transfer of authority, have been placed under the operational command and control of a NATO commander, they never lose their national character.\" Senior national representatives, likeCDS, \"are designated as so-called red-cardholders\". Caveats are restrictions listed \"nation by nation... that NATO Commanders... must take into account\".", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/NATO", "https://en.wikipedia.org/wiki/NATO", "https://en.wikipedia.org/wiki/NATO", "https://en.wikipedia.org/wiki/NATO_(disambiguation)", "https://en.wikipedia.org/wiki/OTAN_(disambiguation)", "https://en.wikipedia.org/wiki/Flag_of_NATO", "https://en.wikipedia.org/wiki/Military_alliance", "https://en.wikipedia.org/wiki/City_of_Brussels"]},
{"id": "ac6ab6766384", "url": "https://en.wikipedia.org/wiki/Debris_fallout", "title": "Debris fallout", "headings": ["Contents", "Mechanism", "Examples", "See also", "References"], "content": "Debris falloutrefers to debris lofted into the air by atornadothat falls back to the ground, and that can persist well after a tornado has lifted. Debris lofted by stronger tornadoes has been known to travel significant distances, upwards of 200 mi (320 km) on rare occasions. Debris fallout events can be detected on radar usingdual polarizationproducts, notablycorrelation coefficient. Most debris in excess of 1 lb (0.45 kg) is not moved a great distance; however, lighter objects—especiallypapergoods—can be absorbed by the storm'supdraftand moved into itsforward-flank downdraftwhere they can be transported further by non-tornadic downdraft winds. The basic mechanism of debris fallout is debris lofted by a tornado'supdraftwinds high into the atmosphere.Charles E. Andersoncompleted the first study focusing on debris fallout on the F51984 Barneveld tornado, which produced a large survey revealing a trail of paper debris as wide as 23 mi (37 km) at 110 mi (180 km) from Barneveld and a roughly 85 mi (137 km) long path of heavy debris (>1 lb (0.45 kg)).A later study focusing on debris fallout discovered that debris from an intense tornado was lofted potentially as high as 12 km (7.5 mi) into the atmosphere over the 15–20 minutes after the tornado striking a location, before debris was moved further into the tornado's forward-flank downdraft. A photograph had been traced and discovered to have an average speed of 18 m/s (40 mph; 65 km/h) over 30 minutes.A 1993 analysis byThomas P. Grazulisof 12,651 tornadoes found only 86 had reports of debris being transported over 5 mi (8.0 km) from its origin. The height of atornado debris signatureis positively and non-linearly correlated with the speed of updraft winds, which is likely compounded by fallout.Debris that falls directly over the vortex can result in an increase in the size of thetornado debris signatureon radar.", "combined_text": "Debris fallout Contents Mechanism Examples See also References Debris falloutrefers to debris lofted into the air by atornadothat falls back to the ground, and that can persist well after a tornado has lifted. Debris lofted by stronger tornadoes has been known to travel significant distances, upwards of 200 mi (320 km) on rare occasions. Debris fallout events can be detected on radar usingdual polarizationproducts, notablycorrelation coefficient. Most debris in excess of 1 lb (0.45 kg) is not moved a great distance; however, lighter objects—especiallypapergoods—can be absorbed by the storm'supdraftand moved into itsforward-flank downdraftwhere they can be transported further by non-tornadic downdraft winds. The basic mechanism of debris fallout is debris lofted by a tornado'supdraftwinds high into the atmosphere.Charles E. Andersoncompleted the first study focusing on debris fallout on the F51984 Barneveld tornado, which produced a large survey revealing a trail of paper debris as wide as 23 mi (37 km) at 110 mi (180 km) from Barneveld and a roughly 85 mi (137 km) long path of heavy debris (>1 lb (0.45 kg)).A later study focusing on debris fallout discovered that debris from an intense tornado was lofted potentially as high as 12 km (7.5 mi) into the atmosphere over the 15–20 minutes after the tornado striking a location, before debris was moved further into the tornado's forward-flank downdraft. A photograph had been traced and discovered to have an average speed of 18 m/s (40 mph; 65 km/h) over 30 minutes.A 1993 analysis byThomas P. Grazulisof 12,651 tornadoes found only 86 had reports of debris being transported over 5 mi (8.0 km) from its origin. The height of atornado debris signatureis positively and non-linearly correlated with the speed of updraft winds, which is likely compounded by fallout.Debris that falls directly over the vortex can result in an increase in the size of thetornado debris signatureon radar.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Debris_fallout", "https://en.wikipedia.org/wiki/Debris_fallout", "https://en.wikipedia.org/wiki/Debris_fallout", "https://en.wikipedia.org/wiki/2021_Western_Kentucky_tornado", "https://en.wikipedia.org/wiki/Tornado", "https://en.wikipedia.org/wiki/Dual_polarization", "https://en.wikipedia.org/wiki/Correlation_coefficient", "https://en.wikipedia.org/wiki/Paper"]},
{"id": "ac9f06b726cc", "url": "https://en.wikipedia.org/wiki/Riverfront_Times", "title": "Riverfront Times", "headings": ["Contents", "History", "See also", "References", "External links"], "content": " TheRiverfront Times(RFT) was a free progressiveweekly newspaperinSt. Louis,Missouri, that consisted of local politics, music, arts, and dining news in the print edition, and daily updates toblogsand photo galleries on its website. As of June 2008,theRiverfront Timeshad anABC-audited weekly circulation of 81,276 copies.A 2024 sale immediately ended print distribution and resulted in the layoffs of all staff. The only remaining element of the publication is a website which primarily features aggregated content andOnlyFanspromotions. The paper was founded in 1977 by Ray Hartmannwho, along with co-owner Mark Vittert, sold the newspaper in 1998 to New Times Media(later known, following a 2006 merger, asVillage Voice Media).In September 2012, Village Voice Media executives Scott Tobias, Christine Brennan and Jeff Mars agreed to purchase Village Voice Media's papers and associated web properties from its founders and formedVoice Media Group.In 2015,Euclid Media Groupacquired theTimesfrom Voice Media Group. The paper received more than three dozen awards from theMissouri Press Association, along with the group's Gold Cup.The paper and website featured a weeklysyndicated columnby relationship and sexadvice writerDan Savage. In the past, the paper carried Chuck Sheppard'sNews of the Weirdcolumn. Former journalists that wrote for the paper include Suzanne Langlois, who won the 1994 Con Lee Kelliher award for distinguished achievement. In June 2019, editor-in-chief Sarah Fenske announced her departure after being selected to hostSt. Louis on the AironSt. Louis Public Radio.News editor Doyle Murphy was selected as interim editor-in-chief.Murphy served as editor-in-chief until he announced in the February 9, 2022, edition that he would be leaving the paper to work forSt. Louis Public Radio.Ben Westhoff, the executive editor of Euclid Media Group,served as interim editor-in-chieffollowing Murphy's resignation, but announced on February 24, 2022, that Rosalind Early, who was then serving as deputy managing editor forWashington MagazineatWashington University in St. Louis, would be the paper's next editor in chief, starting in March. In August 2023, Euclid Media Group dissolved and the newspaper was sold to Chris Keating, operating under the name Big Lou Holdings LLC.The paper was sold again in May 2024 to an unnamed buyer and all staff were laid off.The buyers were revealed to be individuals who promoteOnlyFanscontent creators under the LLCs Ready Set Cam and FanFox registered in Texas.", "combined_text": "Riverfront Times Contents History See also References External links  TheRiverfront Times(RFT) was a free progressiveweekly newspaperinSt. Louis,Missouri, that consisted of local politics, music, arts, and dining news in the print edition, and daily updates toblogsand photo galleries on its website. As of June 2008,theRiverfront Timeshad anABC-audited weekly circulation of 81,276 copies.A 2024 sale immediately ended print distribution and resulted in the layoffs of all staff. The only remaining element of the publication is a website which primarily features aggregated content andOnlyFanspromotions. The paper was founded in 1977 by Ray Hartmannwho, along with co-owner Mark Vittert, sold the newspaper in 1998 to New Times Media(later known, following a 2006 merger, asVillage Voice Media).In September 2012, Village Voice Media executives Scott Tobias, Christine Brennan and Jeff Mars agreed to purchase Village Voice Media's papers and associated web properties from its founders and formedVoice Media Group.In 2015,Euclid Media Groupacquired theTimesfrom Voice Media Group. The paper received more than three dozen awards from theMissouri Press Association, along with the group's Gold Cup.The paper and website featured a weeklysyndicated columnby relationship and sexadvice writerDan Savage. In the past, the paper carried Chuck Sheppard'sNews of the Weirdcolumn. Former journalists that wrote for the paper include Suzanne Langlois, who won the 1994 Con Lee Kelliher award for distinguished achievement. In June 2019, editor-in-chief Sarah Fenske announced her departure after being selected to hostSt. Louis on the AironSt. Louis Public Radio.News editor Doyle Murphy was selected as interim editor-in-chief.Murphy served as editor-in-chief until he announced in the February 9, 2022, edition that he would be leaving the paper to work forSt. Louis Public Radio.Ben Westhoff, the executive editor of Euclid Media Group,served as interim editor-in-chieffollowing Murphy's resignation, but announced on February 24, 2022, that Rosalind Early, who was then serving as deputy managing editor forWashington MagazineatWashington University in St. Louis, would be the paper's next editor in chief, starting in March. In August 2023, Euclid Media Group dissolved and the newspaper was sold to Chris Keating, operating under the name Big Lou Holdings LLC.The paper was sold again in May 2024 to an unnamed buyer and all staff were laid off.The buyers were revealed to be individuals who promoteOnlyFanscontent creators under the LLCs Ready Set Cam and FanFox registered in Texas.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Riverfront_Times", "https://en.wikipedia.org/wiki/Riverfront_Times", "https://en.wikipedia.org/wiki/Riverfront_Times", "https://en.wikipedia.org/wiki/Alternative_weekly", "https://en.wikipedia.org/wiki/Tabloid_(newspaper_format)", "https://en.wikipedia.org/wiki/St._Louis", "https://en.wikipedia.org/wiki/Missouri", "https://en.wikipedia.org/wiki/United_States"]},
{"id": "328250e23610", "url": "https://en.wikipedia.org/wiki/Virgin_Earth_Challenge", "title": "Virgin Earth Challenge", "headings": ["Contents", "The challenge", "Competing technologies", "Biochar", "BECCS (Bio-energy with carbon capture and storage)", "Direct air capture", "Enhanced weathering", "Grassland restoration", "Discontinuance", "Similar competitions", "See also", "References", "External links"], "content": " TheVirgin Earth Challengewas a competition offering a $25 million prize for whoever could demonstrate a commercially viable design which results in thepermanent removalofgreenhouse gasesout of theEarth's atmosphereto contribute materially inglobal warmingavoidance.The prize was conceived byRichard Branson, and was announced inLondonon 9 February 2007 by Branson and formerUSVice PresidentAl Gore. Among more than 2600 applications, 11 finalists were announced on 2 November 2011. These were Biochar Solutions, from the US;Biorecro, Sweden; Black Carbon, Denmark;Carbon Engineering, Canada;Climeworks, Switzerland; COAWAY, US; Full Circle Biochar, US; Global Thermostat, US; Kilimanjaro Energy, US; Smartstones – Olivine Foundation, Netherlands, and The Savory Institute, US. The prize was never awarded. In 2019, Virgin took the prize website offline after having kept the 11 finalists in suspension for eight years. Al Gore had withdrawn from the jury earlier and commented that he was not part of the decision to discontinue the contest. The Prize was to be awarded to \"a commercially viable design which, achieves or appears capable of achieving thenet removalof significant volumes of anthropogenic, atmosphericGHGseach year for at least 10 years\", with significant volumes specified as \"should be scalable to a significant size in order to meet the informal removal target of 1 billion tonnes of carbon-equivalent per year\".One tonne ofcarbon-equivalent(C) equals 3.67 tonnes ofcarbon dioxide(CO2). (Because of the relationship between theiratomic weights, more precisely 44/12.) At present,fossil fuelemissions are around 6.3 gigatons of carbon. The prize would initially only be open for five years, with ideas assessed by a panel of judges including Richard Branson, Al Gore andCrispin Tickell(Britishdiplomat), as well asscientistsJames E. Hansen,James LovelockandTim Flannery. The prize term was extended until 2019. Around two hundred billion metric tons of carbon dioxide have accumulated in the atmosphere since the beginning of theIndustrial Revolution, raising concentrations by more than 100 parts per million (ppm), from 280 to more than 380 ppm.  The Virgin Earth Challenge was intended to inspireinventorsto find ways of bringing that back down again to avoid the dangerous levels ofglobal warmingandsea level risepredicted by organisations such as theIntergovernmental Panel on Climate Change. The Virgin Earth Challenge was similar in concept to other high technology competitions, such as theOrteig Prizefor flying across theAtlantic, and theAnsari X Prizeforspaceflight. The eleven finalists represent five competing technologies, some being represented by multiple finalists. Biochar, created bypyrolysisof biomass. Pyrolysis is a process where biomass is partially combusted in an oxygen-limited environment, which produces a char rich in carbon. This char can be distributed in soils as asoil amendment. Finalists competing with biochar designs: Bio-energy with carbon capture and storage(BECCS) combines combustion or processing of biomass withgeologiccarbon capture and storage. BECCS is applied to industries such as electrical power, combined heat and power, pulp and paper, ethanol production, andbiogasproduction. There is 550 000 tonnes CO2/year in total BECCS capacity operating, divided between three different facilities (as of January 2012). BECCS was pointed out in theIPCC Fourth Assessment Reportby theIntergovernmental Panel on Climate Change(IPCC) as a key technology for reaching low carbon dioxide atmospheric concentration targets.The negative emissions that can be produced by BECCS has been estimated by theRoyal Societyto be equivalent to a 50 to 150ppmdecrease inglobal atmospheric carbon dioxide concentrationsand according to theInternational Energy Agency, the BLUE mapclimate change mitigation scenariocalls for more than 2gigatonnesof negative CO2emissions per year with BECCS in 2050.According to theOECD, \"Achieving lower concentration targets (450 ppm) depends significantly on the use ofBECCS\". Thesustainabletechnical potential for net negative emissions with BECCS has been estimated to 10Gtof CO2equivalent annually, with an economic potential of up to 3.5 Gt of CO2equivalent annually at a cost of less than 50 €/tonne, and up to 3.9 Gt of CO2equivalent annually at a cost of less than 100 €/tonne. Imperial College London, the UKMet OfficeHadley Centre for Climate Prediction and Research, theTyndall Centre for Climate Change Research, the Walker Institute for Climate System Research, and theGrantham Institute for Climate Changeissued a joint report on carbon dioxide removal technologies as part of theAVOID: Avoiding dangerous climate changeresearch program, stating that \"Overall, of the technologies studied in this report,BECCShas the greatest maturity and there are no major practical barriers to its introduction into today’s energy system. The presence of a primary product will support early deployment.\" Finalist competing with BECCS design: Direct Air Captureis the process of capturing carbon dioxide directly from ambient air using solvents, filters or other methods. Subsequent to being captured, the carbon dioxide would be stored withcarbon capture and storagetechnologies to keep it permanently out of the atmosphere. Finalists competing with direct air capture designs: Enhanced weatheringrefers to a chemical approach to in-situ carbonation of silicates, where carbon dioxide is combined through natural weathering processes with mined minerals, such asolivine. The idea was based on the work of Dutch geoscientist Olaf Schuiling, whose ideas continue to be explored in the Netherlands, with promising results. Finalist competing with enhanced weathering design: Changedmanagement methods for grasslandscan  significantly increase the uptake of carbon dioxide into the soil, creating acarbon sink. This and other land use change methods is not generally considered amongnegative emissiontechnologies because of uncertain long-term sequestration permanence. Finalist competing with grassland restoration design:  The finalists who were announced in 2011 were kept in suspension for nine years, with many additional requests for information and data, as contestant Global Thermostat reported.Another contestant,Carbon Engineeringreceived notification in 2019 that they fulfilled all technical criteria and were selected for the final judgment.Subsequently they were informed that the prize was \"indefinitely put on hold\". At the end of 2019, the prize was discontinued and the website taken offline. Carbon Engineering was informed by the Virgin Earth Challenge that \"the market conditions necessary to support commercial and sustainable investment in the relevantcarbon removaltechniques were not foreseeable\". Nevertheless, Carbon Engineering had raised 95 million dollar in investments by other parties, including Bill Gates. ContestantGraciela ChichilniskyofGlobal Thermostat, anotherdirect air capturecontestant, who had raised 60 million dollars in investments from other parties, expressed strong criticism in Dutch daily Volkskrant: \"If you want to encourage scientific progress with a prize, it's not enough to open your mouth and say \"25 million dollars.\" None of the 11 finalists received any funding or concrete help from Virgin during the 13 years of assessment. Since the Virgin Earth Challenge, two new multimillion climate technology contests have been announced. In 2015,NRG COSIA Carbon XPRIZEwas launched. It awards $20 million to \"breakthrough technologies to convert CO2emissions into usable products\". The prize focuses on commercial exploitation of the carbon capture process. The prize will be awarded in the winter of 2021.In 2021,Elon MuskofTesla Incannounced a $100 million prize for development of the best technology to capture carbon dioxide emissions.", "combined_text": "Virgin Earth Challenge Contents The challenge Competing technologies Biochar BECCS (Bio-energy with carbon capture and storage) Direct air capture Enhanced weathering Grassland restoration Discontinuance Similar competitions See also References External links  TheVirgin Earth Challengewas a competition offering a $25 million prize for whoever could demonstrate a commercially viable design which results in thepermanent removalofgreenhouse gasesout of theEarth's atmosphereto contribute materially inglobal warmingavoidance.The prize was conceived byRichard Branson, and was announced inLondonon 9 February 2007 by Branson and formerUSVice PresidentAl Gore. Among more than 2600 applications, 11 finalists were announced on 2 November 2011. These were Biochar Solutions, from the US;Biorecro, Sweden; Black Carbon, Denmark;Carbon Engineering, Canada;Climeworks, Switzerland; COAWAY, US; Full Circle Biochar, US; Global Thermostat, US; Kilimanjaro Energy, US; Smartstones – Olivine Foundation, Netherlands, and The Savory Institute, US. The prize was never awarded. In 2019, Virgin took the prize website offline after having kept the 11 finalists in suspension for eight years. Al Gore had withdrawn from the jury earlier and commented that he was not part of the decision to discontinue the contest. The Prize was to be awarded to \"a commercially viable design which, achieves or appears capable of achieving thenet removalof significant volumes of anthropogenic, atmosphericGHGseach year for at least 10 years\", with significant volumes specified as \"should be scalable to a significant size in order to meet the informal removal target of 1 billion tonnes of carbon-equivalent per year\".One tonne ofcarbon-equivalent(C) equals 3.67 tonnes ofcarbon dioxide(CO2). (Because of the relationship between theiratomic weights, more precisely 44/12.) At present,fossil fuelemissions are around 6.3 gigatons of carbon. The prize would initially only be open for five years, with ideas assessed by a panel of judges including Richard Branson, Al Gore andCrispin Tickell(Britishdiplomat), as well asscientistsJames E. Hansen,James LovelockandTim Flannery. The prize term was extended until 2019. Around two hundred billion metric tons of carbon dioxide have accumulated in the atmosphere since the beginning of theIndustrial Revolution, raising concentrations by more than 100 parts per million (ppm), from 280 to more than 380 ppm.  The Virgin Earth Challenge was intended to inspireinventorsto find ways of bringing that back down again to avoid the dangerous levels ofglobal warmingandsea level risepredicted by organisations such as theIntergovernmental Panel on Climate Change. The Virgin Earth Challenge was similar in concept to other high technology competitions, such as theOrteig Prizefor flying across theAtlantic, and theAnsari X Prizeforspaceflight. The eleven finalists represent five competing technologies, some being represented by multiple finalists. Biochar, created bypyrolysisof biomass. Pyrolysis is a process where biomass is partially combusted in an oxygen-limited environment, which produces a char rich in carbon. This char can be distributed in soils as asoil amendment. Finalists competing with biochar designs: Bio-energy with carbon capture and storage(BECCS) combines combustion or processing of biomass withgeologiccarbon capture and storage. BECCS is applied to industries such as electrical power, combined heat and power, pulp and paper, ethanol production, andbiogasproduction. There is 550 000 tonnes CO2/year in total BECCS capacity operating, divided between three different facilities (as of January 2012). BECCS was pointed out in theIPCC Fourth Assessment Reportby theIntergovernmental Panel on Climate Change(IPCC) as a key technology for reaching low carbon dioxide atmospheric concentration targets.The negative emissions that can be produced by BECCS has been estimated by theRoyal Societyto be equivalent to a 50 to 150ppmdecrease inglobal atmospheric carbon dioxide concentrationsand according to theInternational Energy Agency, the BLUE mapclimate change mitigation scenariocalls for more than 2gigatonnesof negative CO2emissions per year with BECCS in 2050.According to theOECD, \"Achieving lower concentration targets (450 ppm) depends significantly on the use ofBECCS\". Thesustainabletechnical potential for net negative emissions with BECCS has been estimated to 10Gtof CO2equivalent annually, with an economic potential of up to 3.5 Gt of CO2equivalent annually at a cost of less than 50 €/tonne, and up to 3.9 Gt of CO2equivalent annually at a cost of less than 100 €/tonne. Imperial College London, the UKMet OfficeHadley Centre for Climate Prediction and Research, theTyndall Centre for Climate Change Research, the Walker Institute for Climate System Research, and theGrantham Institute for Climate Changeissued a joint report on carbon dioxide removal technologies as part of theAVOID: Avoiding dangerous climate changeresearch program, stating that \"Overall, of the technologies studied in this report,BECCShas the greatest maturity and there are no major practical barriers to its introduction into today’s energy system. The presence of a primary product will support early deployment.\" Finalist competing with BECCS design: Direct Air Captureis the process of capturing carbon dioxide directly from ambient air using solvents, filters or other methods. Subsequent to being captured, the carbon dioxide would be stored withcarbon capture and storagetechnologies to keep it permanently out of the atmosphere. Finalists competing with direct air capture designs: Enhanced weatheringrefers to a chemical approach to in-situ carbonation of silicates, where carbon dioxide is combined through natural weathering processes with mined minerals, such asolivine. The idea was based on the work of Dutch geoscientist Olaf Schuiling, whose ideas continue to be explored in the Netherlands, with promising results. Finalist competing with enhanced weathering design: Changedmanagement methods for grasslandscan  significantly increase the uptake of carbon dioxide into the soil, creating acarbon sink. This and other land use change methods is not generally considered amongnegative emissiontechnologies because of uncertain long-term sequestration permanence. Finalist competing with grassland restoration design:  The finalists who were announced in 2011 were kept in suspension for nine years, with many additional requests for information and data, as contestant Global Thermostat reported.Another contestant,Carbon Engineeringreceived notification in 2019 that they fulfilled all technical criteria and were selected for the final judgment.Subsequently they were informed that the prize was \"indefinitely put on hold\". At the end of 2019, the prize was discontinued and the website taken offline. Carbon Engineering was informed by the Virgin Earth Challenge that \"the market conditions necessary to support commercial and sustainable investment in the relevantcarbon removaltechniques were not foreseeable\". Nevertheless, Carbon Engineering had raised 95 million dollar in investments by other parties, including Bill Gates. ContestantGraciela ChichilniskyofGlobal Thermostat, anotherdirect air capturecontestant, who had raised 60 million dollars in investments from other parties, expressed strong criticism in Dutch daily Volkskrant: \"If you want to encourage scientific progress with a prize, it's not enough to open your mouth and say \"25 million dollars.\" None of the 11 finalists received any funding or concrete help from Virgin during the 13 years of assessment. Since the Virgin Earth Challenge, two new multimillion climate technology contests have been announced. In 2015,NRG COSIA Carbon XPRIZEwas launched. It awards $20 million to \"breakthrough technologies to convert CO2emissions into usable products\". The prize focuses on commercial exploitation of the carbon capture process. The prize will be awarded in the winter of 2021.In 2021,Elon MuskofTesla Incannounced a $100 million prize for development of the best technology to capture carbon dioxide emissions.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Virgin_Earth_Challenge", "https://en.wikipedia.org/wiki/Virgin_Earth_Challenge", "https://en.wikipedia.org/wiki/Virgin_Earth_Challenge", "https://en.wikipedia.org/wiki/Negative_carbon_dioxide_emission", "https://en.wikipedia.org/wiki/Greenhouse_gas", "https://en.wikipedia.org/wiki/Earth%27s_atmosphere", "https://en.wikipedia.org/wiki/Global_warming", "https://en.wikipedia.org/wiki/Richard_Branson"]},
{"id": "ad50762d623f", "url": "https://en.wikipedia.org/wiki/List_of_wikis", "title": "List of wikis", "headings": ["Contents", "Table", "See also", "References", "External links"], "content": "This article contains a list of notablewikis, which arewebsitesthat usewiki software, allowing users to collaboratively edit content and view old versions of the content. These websites useseveral different wiki software packages. 550,069", "combined_text": "List of wikis Contents Table See also References External links This article contains a list of notablewikis, which arewebsitesthat usewiki software, allowing users to collaboratively edit content and view old versions of the content. These websites useseveral different wiki software packages. 550,069", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/List_of_wikis", "https://en.wikipedia.org/wiki/List_of_wikis", "https://en.wikipedia.org/wiki/List_of_wikis", "https://en.wikipedia.org/wiki/Wiki", "https://en.wikipedia.org/wiki/Website", "https://en.wikipedia.org/wiki/Wiki_software", "https://en.wikipedia.org/wiki/Comparison_of_wiki_software", "https://en.wikipedia.org/wiki/AboutUs"]},
{"id": "57f9c3722630", "url": "https://en.wikipedia.org/wiki/Noise_health_effects", "title": "Health effects from noise", "headings": ["Contents", "Noise induced hearing loss", "Tinnitus", "Cardiovascular effects", "Other physical health effects", "Psychological impacts of noise", "Stress", "Annoyance", "Child physical development", "Cognitive development", "Prevention", "Regulations", "See also", "References", "External links"], "content": "Noise health effectsare the physical and psychologicalhealthconsequences of regular exposure to consistent elevatedsound levels. Noise from traffic, in particular, is considered by the World Health Organization to be one of the worst environmental stressors for humans, second only toair pollution.Elevatedworkplaceorenvironmental noisecan causehearing impairment, tinnitus,hypertension,ischemic heart disease,annoyance, andsleep disturbance.Changes in theimmune systemandbirth defectshave been also attributed to noise exposure. Although age-related health effects (presbycusis) occur naturally with age,in many countries the cumulative impact of noise is sufficient to impair the hearing of a large fraction of the population over the course of a lifetime.Noise exposure has been known to inducenoise-induced hearing loss,tinnitus,hypertension,vasoconstriction, and othercardiovascularadverse effects.Chronic noise exposure has been associated with sleep disturbances and increased incidence of diabetes. Adverse cardiovascular effects occur from chronic exposure to noise due to the sympathetic nervous system's inability to habituate. The sympathetic nervous system maintains lighter stages of sleep when the body is exposed to noise, which does not allow blood pressure to follow the normal rise and fall cycle of an undisturbedcircadian rhythm. Stress from time spent around elevated noise levels has been linked with increasedworkplace accidentrates, aggression, and other anti-social behaviors.The most significant sources are vehicles, aircraft, prolonged exposure toloud music, and industrial noise.Prolonged exposure to noise at home has been linked to decreased mental health. There are approximately 10,000 deaths per year as a result of noise in the European Union. Noise-induced hearing loss is a permanent shift in pure-tone thresholds, resulting in sensorineural hearing loss. The severity of a threshold shift is dependent on duration and severity of noise exposure. Noise-induced threshold shifts are seen as a notch on an audiogram from 3000 to 6000 Hz, but most often at 4000 Hz. Exposure to loud noises, either in a single traumatic experience or over time, can damage the auditory system and result in hearing loss and sometimestinnitusas well. Traumatic noise exposure can happen at work (e.g., loud machinery), at play (e.g., loud sporting events, concerts, recreational activities), and/or by accident (e.g., a backfiring engine.) Noise induced hearing loss is sometimesunilateraland typically causes patients to lose hearing around the frequency of the triggering sound trauma. Tinnitusis an auditory disorder characterized by the perception of a sound (ringing, chirping, buzzing, etc.) in the ear in the absence of an external sound source. There are two types of tinnitus: subjective and objective. Subjective is the most common and can only be heard \"in the head\" by the person affected. Objective tinnitus can be heard from those around the affected person and the audiologist can hear it using a stethoscope. Tinnitus can also be categorized by the way it sounds in one's ear, pulsatile tinnituswhich is caused by the vascular nature ofGlomus tumorsand non-pulsatile tinnitus which usually sounds like crickets, the sea and bees. Though the pathophysiology of tinnitus is not known, noise exposure can be a contributing factor, therefore tinnitus can be associated with hearing loss, generated by the cochlea and central nervous system (CNS). High frequency hearing loss causes a high pitched tinnitus and low frequency hearing loss causes a roaring tinnitus.Noise-induced tinnitus can be temporary or permanent depending on the type and amount of noise a person was exposed to. Noise has been associated with importantcardiovascularhealth problems, particularlyhypertension, as it causes an increase in levels of stress hormones and vascularoxidative stress.Noise levels of 50dB(A)or greater at night may increase the risk ofmyocardial infarctionby chronically elevatingcortisolproduction. Traffic noise has several negative effects, including increased risk forcoronary artery disease, with night-time exposure to noise possibly more harmful than day-time exposure.It has also been shown to increase blood pressure in individuals within the surrounding residential areas, with railways causing the greatest cardiovascular effects.Roadway noise levels are sufficient to constrict arterial blood flow and lead toelevated blood pressure.Vasoconstriction can result from elevatedadrenalinelevels or throughmedical stressreactions. Long-term exposure to noise is correlated to increase in cortisol and angiotensin-II levels which are respectively associated with oxidative stress and vascular inflammation.Individuals subject to greater than 80 dB(A) in the workplace are at increased risk of having increased blood pressure. A 2021 systematic review on the effect of occupational exposure to noise on ischemic heart disease (IHD), stroke and hypertension, coordinated by theWorld Health Organization(WHO) and theInternational Labour Organization(ILO)  located 17 studies that met the inclusion criteria, comprising a total of 534,688 participants (7.47% females) in 11 countries and in three WHO regions (the Americas, Europe, and the Western Pacific).The study found the low quality of evidence the effect of occupational exposure to intense noise (≥85 dBA), compared to occupational exposure below 85 dBA (<85 dBA). They concluded that there is an inadequate evidence of harmfulness for the studied outcomes with the exception for the risk of acquiring IHD, which was 29% higher for those exposed to noise in their workplace. Traffic noise may also increase the risk of sleep disturbances, stroke, diabetes, and becoming overweight.Noise pollution is anenvironmental healthconcern since it is often a risk factor for developing other diseases like tinnitus or impaired speech discrimination. Causal relationships have been discovered between noise and psychological effects such as annoyance, psychiatric disorders, and effects on psychosocial well-being.Exposure to intense levels of noise can cause personality changes and violent reactions.Noise has also been shown to be a factor attributed to violent reactions.The psychological impacts of noise also include an addiction to loud music. This was researched in a study where non-professional musicians were found to have loudness addictions more often than non-musician control subjects. Psychological health effects from noise also include depression and anxiety. Individuals who have hearing loss, including noise induced hearing loss, may have their symptoms alleviated with the use of hearing aids. Individuals who do not seek treatment for their loss are 50% more likely to have depression than their aided peers.These psychological effects can lead to detriments in physical care in the form of reduced self-care, work-tolerance, and increased isolation. Auditory stimuli can also serve as psychological triggers for individuals with post traumatic stress disorder (PTSD). Research commissioned byRockwool, a multi-nationalinsulationmanufacturer headquartered inDenmark, reveals that in the UK one third (33%) of victims of domestic disturbances claim that loud parties have left them unable to sleep or made them stressed in the last two years. Around one in eleven (9%)of those affected by domestic disturbances claims it has left them continually disturbed and stressed. More than 1.8 million people claim noisy neighbours have made their life a misery and they cannot enjoy their own homes. The impact of noise on health is potentially a significant problem across the UK given that more than 17.5 million Britons (38%) have been disturbed by the inhabitants of neighbouring properties in the last two years. For almost one in ten (7%) Britons this is a regular occurrence. The extent of the problem of noise pollution for public health is reinforced by figures collated by Rockwool from local authority responses to aFreedom of Information Act(FOI) request. This research reveals in the period April 2008 – 2009UK councilsreceived 315,838 complaints about noise pollution from private residences. This resulted in environmental health officers across the UK serving 8,069noise abatementnotices, or citations under the terms of the Anti-Social Behaviour (Scotland) Act. Westminster City Councilhas received more complaints per head of population than any other district in the UK with 9,814 grievances about noise, which equates to 42.32 complaints per thousand residents. Eight of the top 10 councils ranked by complaints per 1,000 residents were inLondon. Sudden impulse noises are typically perceived as more bothersome than noise from traffic of equal volume.Annoyance effects of noise are minimally affected by demographics, but fear of the noise source and sensitivity to noise both strongly affect the 'annoyance' of a noise.Sound levels as low as 40 dB(A) can generate noise complaintsand the lower threshold for noise producingsleep disturbanceis 45 dB(A) or lower. Other factors that affect the annoyance level of sound include beliefs about noise prevention and the importance of the noise source, and annoyance at the cause (i.e., non-noise related factors) of the noise.Many of the interpretations of the level of annoyance and the relationship between noise levels and resulting health symptoms could be influenced by the quality of interpersonal relationships at the workplace, as well as the stress level generated by the work itself.Evidence for impact on annoyance of long-term noise versus recent changes is uncertain. Approximately 35% to 40% of office workers find noise levels from 55 to 60 dB(A) extremely irritating.The noise standard in Germany for mentally stressful tasks is set at 55 dB(A),however, if the noise source is continuous, the threshold level for tolerability among office workers is lower than 55 dB(A). TheU.S. Environmental Protection Agencyauthored a pamphlet in 1978 that suggested a correlation between low-birthweight (using theWorld Health Organizationdefinition of less than 2,500 grams (88 oz)) and high sound levels, and also high rates ofbirth defectsin places where expectant mothers are exposed to elevated sound levels, such as typicalairportenvironments. Specific birth abnormalities includedharelip,cleft palate, and defects in thespine. According to Lester W. Sontag of The Fels Research Institute (as presented in the same EPA study): \"There is ample evidence that environment has a role in shaping the physique, behavior, and function of animals, including man, fromconceptionand not merely frombirth. Thefetusis capable of perceiving sounds and responding to them by motor activity and cardiac rate change.\" The effects of noise exposure are highest when it occurs between 15 and 60 days after conception, a period in which major internalorgansand thecentral nervous systemare formed. Later developmental effects occur as vasoconstriction in the mother reduces blood flow and thereforeoxygenand nutrition to the fetus. Low birth weights and noise were also associated with lower levels of certainhormonesin the mother. These hormones are thought to affect fetal growth and to be good indicators ofproteinproduction. The difference between the hormone levels of pregnant mothers in noisy versus quiet areas increased as birth approached. In a 2000 publication, a review of studies on birthweight and noise exposure note that while some older studies suggest that when women are exposed to >65 dB aircraft noise, a small decrease in birthweight occurs, in a more recent study of 200 Taiwanese women including noise dosimetry measurements of individual noise exposure, the authors found no significant association between noise exposure and birth weight after adjusting for relevant confounders, e.g. social class, maternal weight gain during pregnancy, etc. When young children are regularly exposed to levels of noise that interfere with speech, they may develop speech or reading difficulties, because auditory processing functions are compromised. Children continue to develop their speech perception abilities until they reach their teens. Evidence has shown that when children learn in noisier classrooms, they have more difficulties understanding speech than those who learn in quieter settings. In a study conducted by Cornell University in 1993, children exposed to noise in learning environments experienced trouble with word discrimination, as well as various cognitive developmental delays.In particular, the writing learning impairmentdysgraphiais commonly associated with environmentalstressorsin the classroom. High noise levels have also been known to damage the physical health of small children.  Children from noisy residences often have a heart rate that is significantly higher (by 2 beats/min on average) than those of children from quieter homes. A hearing protection device (HPD) is anear protectiondevice worn in or over the ears while exposed to hazardousnoiseto help preventnoise-induced hearing loss. HPDs reduce (not eliminate) the level of the noise entering the ear. HPDs can also protect against other effects of noise exposure such astinnitusandhyperacusis. Proper hygiene and care of HPDs may reduce chances of outer ear infections.There are many different types of HPDs available for use, includingearmuffs,earplugs, electronic hearing protection devices, and semi-insert devices.One can measure the personal attenuation rating through ahearing protection fit-testingsystem. Earmuff style hearing protection devices are designed to fit over the outer ear, orpinna. Earmuff HPDs typically consist of two ear cups and a head band.Earplug style hearing protection devices are designed to fit in theear canal. Earplugs come in a variety of different subtypes.Some HPDs reduce the sound reaching theeardrumthrough a combination of electronic and structural components. Electronic HPDs are available in both earmuff and custom earplug styles. Electronic microphones, circuitry, and receivers performactive noise reduction, also known asnoise-cancelling, in which a signal that is 180-degrees out-of-phase of the noise is presented, which in theory cancels the noise.Canal caps are similar to earplugs in that they consists of soft tip that is inserted into the opening of the ear canal. OSHArequires the use ofhearing protection. But the HPD (without individual selection, training andfit testing) does not significantly reduce the risk of hearing loss.For example, one study covered more than 19 thousand workers, some of whom usually used hearing protective devices, and some did not use them at all. There was no statistically significant difference in the risk of noise-induced hearing loss. Environmentalnoise regulationsusually specify a maximum outdoor noise level of 60 to 65dB(A), while occupational safety organizations recommend that the maximum exposure to noise is 40 hours per week at 85 to 90 dB(A). For every additional 3 dB(A), the maximum exposure time is reduced by a factor 2, e.g. 20 hours per week at 88 dB(A). Sometimes, a factor of two per additional 5 dB(A) is used, however, these occupational regulations are acknowledged by the health literature as inadequate to protect againsthearing lossand other health effects. In an effort to prevent noise-induced hearing loss, many programs and initiative have been created, like theBuy Quietprogram, which encourages employers to purchase quieter tools and equipment, and theSafe-In-Sound Award, which recognizes organizations with successful hearing loss prevention strategies. With regard to indoor noise pollution in residences, the U.S.Environmental Protection Agency(EPA) has not set any restrictions on limits to the level of noise. Rather, it has provided a list of recommended levels in itsModel Community Noise Control Ordinance, which was published in 1975. For instance, the recommended noise level for indoor residences is less than or equal to 45 dB. Noise pollutioncontrol in residences is not funded by the federal government in part because of the disagreements in establishing causal links between sounds and health risks, since the effect of noise is often psychological and also, because it leaves no singular tangible trace of damage on the human body. For instance, hearing loss could be attributed to a variety of factors including age, rather than solely due to excessive exposure to noise.A state or local government is able to regulate indoor residential noise, however, such as when excessive noise from within a home causes disturbances to nearby residences.", "combined_text": "Health effects from noise Contents Noise induced hearing loss Tinnitus Cardiovascular effects Other physical health effects Psychological impacts of noise Stress Annoyance Child physical development Cognitive development Prevention Regulations See also References External links Noise health effectsare the physical and psychologicalhealthconsequences of regular exposure to consistent elevatedsound levels. Noise from traffic, in particular, is considered by the World Health Organization to be one of the worst environmental stressors for humans, second only toair pollution.Elevatedworkplaceorenvironmental noisecan causehearing impairment, tinnitus,hypertension,ischemic heart disease,annoyance, andsleep disturbance.Changes in theimmune systemandbirth defectshave been also attributed to noise exposure. Although age-related health effects (presbycusis) occur naturally with age,in many countries the cumulative impact of noise is sufficient to impair the hearing of a large fraction of the population over the course of a lifetime.Noise exposure has been known to inducenoise-induced hearing loss,tinnitus,hypertension,vasoconstriction, and othercardiovascularadverse effects.Chronic noise exposure has been associated with sleep disturbances and increased incidence of diabetes. Adverse cardiovascular effects occur from chronic exposure to noise due to the sympathetic nervous system's inability to habituate. The sympathetic nervous system maintains lighter stages of sleep when the body is exposed to noise, which does not allow blood pressure to follow the normal rise and fall cycle of an undisturbedcircadian rhythm. Stress from time spent around elevated noise levels has been linked with increasedworkplace accidentrates, aggression, and other anti-social behaviors.The most significant sources are vehicles, aircraft, prolonged exposure toloud music, and industrial noise.Prolonged exposure to noise at home has been linked to decreased mental health. There are approximately 10,000 deaths per year as a result of noise in the European Union. Noise-induced hearing loss is a permanent shift in pure-tone thresholds, resulting in sensorineural hearing loss. The severity of a threshold shift is dependent on duration and severity of noise exposure. Noise-induced threshold shifts are seen as a notch on an audiogram from 3000 to 6000 Hz, but most often at 4000 Hz. Exposure to loud noises, either in a single traumatic experience or over time, can damage the auditory system and result in hearing loss and sometimestinnitusas well. Traumatic noise exposure can happen at work (e.g., loud machinery), at play (e.g., loud sporting events, concerts, recreational activities), and/or by accident (e.g., a backfiring engine.) Noise induced hearing loss is sometimesunilateraland typically causes patients to lose hearing around the frequency of the triggering sound trauma. Tinnitusis an auditory disorder characterized by the perception of a sound (ringing, chirping, buzzing, etc.) in the ear in the absence of an external sound source. There are two types of tinnitus: subjective and objective. Subjective is the most common and can only be heard \"in the head\" by the person affected. Objective tinnitus can be heard from those around the affected person and the audiologist can hear it using a stethoscope. Tinnitus can also be categorized by the way it sounds in one's ear, pulsatile tinnituswhich is caused by the vascular nature ofGlomus tumorsand non-pulsatile tinnitus which usually sounds like crickets, the sea and bees. Though the pathophysiology of tinnitus is not known, noise exposure can be a contributing factor, therefore tinnitus can be associated with hearing loss, generated by the cochlea and central nervous system (CNS). High frequency hearing loss causes a high pitched tinnitus and low frequency hearing loss causes a roaring tinnitus.Noise-induced tinnitus can be temporary or permanent depending on the type and amount of noise a person was exposed to. Noise has been associated with importantcardiovascularhealth problems, particularlyhypertension, as it causes an increase in levels of stress hormones and vascularoxidative stress.Noise levels of 50dB(A)or greater at night may increase the risk ofmyocardial infarctionby chronically elevatingcortisolproduction. Traffic noise has several negative effects, including increased risk forcoronary artery disease, with night-time exposure to noise possibly more harmful than day-time exposure.It has also been shown to increase blood pressure in individuals within the surrounding residential areas, with railways causing the greatest cardiovascular effects.Roadway noise levels are sufficient to constrict arterial blood flow and lead toelevated blood pressure.Vasoconstriction can result from elevatedadrenalinelevels or throughmedical stressreactions. Long-term exposure to noise is correlated to increase in cortisol and angiotensin-II levels which are respectively associated with oxidative stress and vascular inflammation.Individuals subject to greater than 80 dB(A) in the workplace are at increased risk of having increased blood pressure. A 2021 systematic review on the effect of occupational exposure to noise on ischemic heart disease (IHD), stroke and hypertension, coordinated by theWorld Health Organization(WHO) and theInternational Labour Organization(ILO)  located 17 studies that met the inclusion criteria, comprising a total of 534,688 participants (7.47% females) in 11 countries and in three WHO regions (the Americas, Europe, and the Western Pacific).The study found the low quality of evidence the effect of occupational exposure to intense noise (≥85 dBA), compared to occupational exposure below 85 dBA (<85 dBA). They concluded that there is an inadequate evidence of harmfulness for the studied outcomes with the exception for the risk of acquiring IHD, which was 29% higher for those exposed to noise in their workplace. Traffic noise may also increase the risk of sleep disturbances, stroke, diabetes, and becoming overweight.Noise pollution is anenvironmental healthconcern since it is often a risk factor for developing other diseases like tinnitus or impaired speech discrimination. Causal relationships have been discovered between noise and psychological effects such as annoyance, psychiatric disorders, and effects on psychosocial well-being.Exposure to intense levels of noise can cause personality changes and violent reactions.Noise has also been shown to be a factor attributed to violent reactions.The psychological impacts of noise also include an addiction to loud music. This was researched in a study where non-professional musicians were found to have loudness addictions more often than non-musician control subjects. Psychological health effects from noise also include depression and anxiety. Individuals who have hearing loss, including noise induced hearing loss, may have their symptoms alleviated with the use of hearing aids. Individuals who do not seek treatment for their loss are 50% more likely to have depression than their aided peers.These psychological effects can lead to detriments in physical care in the form of reduced self-care, work-tolerance, and increased isolation. Auditory stimuli can also serve as psychological triggers for individuals with post traumatic stress disorder (PTSD). Research commissioned byRockwool, a multi-nationalinsulationmanufacturer headquartered inDenmark, reveals that in the UK one third (33%) of victims of domestic disturbances claim that loud parties have left them unable to sleep or made them stressed in the last two years. Around one in eleven (9%)of those affected by domestic disturbances claims it has left them continually disturbed and stressed. More than 1.8 million people claim noisy neighbours have made their life a misery and they cannot enjoy their own homes. The impact of noise on health is potentially a significant problem across the UK given that more than 17.5 million Britons (38%) have been disturbed by the inhabitants of neighbouring properties in the last two years. For almost one in ten (7%) Britons this is a regular occurrence. The extent of the problem of noise pollution for public health is reinforced by figures collated by Rockwool from local authority responses to aFreedom of Information Act(FOI) request. This research reveals in the period April 2008 – 2009UK councilsreceived 315,838 complaints about noise pollution from private residences. This resulted in environmental health officers across the UK serving 8,069noise abatementnotices, or citations under the terms of the Anti-Social Behaviour (Scotland) Act. Westminster City Councilhas received more complaints per head of population than any other district in the UK with 9,814 grievances about noise, which equates to 42.32 complaints per thousand residents. Eight of the top 10 councils ranked by complaints per 1,000 residents were inLondon. Sudden impulse noises are typically perceived as more bothersome than noise from traffic of equal volume.Annoyance effects of noise are minimally affected by demographics, but fear of the noise source and sensitivity to noise both strongly affect the 'annoyance' of a noise.Sound levels as low as 40 dB(A) can generate noise complaintsand the lower threshold for noise producingsleep disturbanceis 45 dB(A) or lower. Other factors that affect the annoyance level of sound include beliefs about noise prevention and the importance of the noise source, and annoyance at the cause (i.e., non-noise related factors) of the noise.Many of the interpretations of the level of annoyance and the relationship between noise levels and resulting health symptoms could be influenced by the quality of interpersonal relationships at the workplace, as well as the stress level generated by the work itself.Evidence for impact on annoyance of long-term noise versus recent changes is uncertain. Approximately 35% to 40% of office workers find noise levels from 55 to 60 dB(A) extremely irritating.The noise standard in Germany for mentally stressful tasks is set at 55 dB(A),however, if the noise source is continuous, the threshold level for tolerability among office workers is lower than 55 dB(A). TheU.S. Environmental Protection Agencyauthored a pamphlet in 1978 that suggested a correlation between low-birthweight (using theWorld Health Organizationdefinition of less than 2,500 grams (88 oz)) and high sound levels, and also high rates ofbirth defectsin places where expectant mothers are exposed to elevated sound levels, such as typicalairportenvironments. Specific birth abnormalities includedharelip,cleft palate, and defects in thespine. According to Lester W. Sontag of The Fels Research Institute (as presented in the same EPA study): \"There is ample evidence that environment has a role in shaping the physique, behavior, and function of animals, including man, fromconceptionand not merely frombirth. Thefetusis capable of perceiving sounds and responding to them by motor activity and cardiac rate change.\" The effects of noise exposure are highest when it occurs between 15 and 60 days after conception, a period in which major internalorgansand thecentral nervous systemare formed. Later developmental effects occur as vasoconstriction in the mother reduces blood flow and thereforeoxygenand nutrition to the fetus. Low birth weights and noise were also associated with lower levels of certainhormonesin the mother. These hormones are thought to affect fetal growth and to be good indicators ofproteinproduction. The difference between the hormone levels of pregnant mothers in noisy versus quiet areas increased as birth approached. In a 2000 publication, a review of studies on birthweight and noise exposure note that while some older studies suggest that when women are exposed to >65 dB aircraft noise, a small decrease in birthweight occurs, in a more recent study of 200 Taiwanese women including noise dosimetry measurements of individual noise exposure, the authors found no significant association between noise exposure and birth weight after adjusting for relevant confounders, e.g. social class, maternal weight gain during pregnancy, etc. When young children are regularly exposed to levels of noise that interfere with speech, they may develop speech or reading difficulties, because auditory processing functions are compromised. Children continue to develop their speech perception abilities until they reach their teens. Evidence has shown that when children learn in noisier classrooms, they have more difficulties understanding speech than those who learn in quieter settings. In a study conducted by Cornell University in 1993, children exposed to noise in learning environments experienced trouble with word discrimination, as well as various cognitive developmental delays.In particular, the writing learning impairmentdysgraphiais commonly associated with environmentalstressorsin the classroom. High noise levels have also been known to damage the physical health of small children.  Children from noisy residences often have a heart rate that is significantly higher (by 2 beats/min on average) than those of children from quieter homes. A hearing protection device (HPD) is anear protectiondevice worn in or over the ears while exposed to hazardousnoiseto help preventnoise-induced hearing loss. HPDs reduce (not eliminate) the level of the noise entering the ear. HPDs can also protect against other effects of noise exposure such astinnitusandhyperacusis. Proper hygiene and care of HPDs may reduce chances of outer ear infections.There are many different types of HPDs available for use, includingearmuffs,earplugs, electronic hearing protection devices, and semi-insert devices.One can measure the personal attenuation rating through ahearing protection fit-testingsystem. Earmuff style hearing protection devices are designed to fit over the outer ear, orpinna. Earmuff HPDs typically consist of two ear cups and a head band.Earplug style hearing protection devices are designed to fit in theear canal. Earplugs come in a variety of different subtypes.Some HPDs reduce the sound reaching theeardrumthrough a combination of electronic and structural components. Electronic HPDs are available in both earmuff and custom earplug styles. Electronic microphones, circuitry, and receivers performactive noise reduction, also known asnoise-cancelling, in which a signal that is 180-degrees out-of-phase of the noise is presented, which in theory cancels the noise.Canal caps are similar to earplugs in that they consists of soft tip that is inserted into the opening of the ear canal. OSHArequires the use ofhearing protection. But the HPD (without individual selection, training andfit testing) does not significantly reduce the risk of hearing loss.For example, one study covered more than 19 thousand workers, some of whom usually used hearing protective devices, and some did not use them at all. There was no statistically significant difference in the risk of noise-induced hearing loss. Environmentalnoise regulationsusually specify a maximum outdoor noise level of 60 to 65dB(A), while occupational safety organizations recommend that the maximum exposure to noise is 40 hours per week at 85 to 90 dB(A). For every additional 3 dB(A), the maximum exposure time is reduced by a factor 2, e.g. 20 hours per week at 88 dB(A). Sometimes, a factor of two per additional 5 dB(A) is used, however, these occupational regulations are acknowledged by the health literature as inadequate to protect againsthearing lossand other health effects. In an effort to prevent noise-induced hearing loss, many programs and initiative have been created, like theBuy Quietprogram, which encourages employers to purchase quieter tools and equipment, and theSafe-In-Sound Award, which recognizes organizations with successful hearing loss prevention strategies. With regard to indoor noise pollution in residences, the U.S.Environmental Protection Agency(EPA) has not set any restrictions on limits to the level of noise. Rather, it has provided a list of recommended levels in itsModel Community Noise Control Ordinance, which was published in 1975. For instance, the recommended noise level for indoor residences is less than or equal to 45 dB. Noise pollutioncontrol in residences is not funded by the federal government in part because of the disagreements in establishing causal links between sounds and health risks, since the effect of noise is often psychological and also, because it leaves no singular tangible trace of damage on the human body. For instance, hearing loss could be attributed to a variety of factors including age, rather than solely due to excessive exposure to noise.A state or local government is able to regulate indoor residential noise, however, such as when excessive noise from within a home causes disturbances to nearby residences.", "links": ["https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Main_Page", "https://en.wikipedia.org/wiki/Health_effects_from_noise", "https://en.wikipedia.org/wiki/Health_effects_from_noise", "https://en.wikipedia.org/wiki/Health_effects_from_noise", "https://en.wikipedia.org/wiki/Health", "https://en.wikipedia.org/wiki/Sound_exposure_level", "https://en.wikipedia.org/wiki/Air_pollution", "https://en.wikipedia.org/wiki/Industrial_noise", "https://en.wikipedia.org/wiki/Environmental_noise"]}
]